[{"title": "小鹏公布增程与纯电体系，智驾将推Robotaxi车型｜最前线", "link": "https://36kr.com/p/3025873081623815?f=rss", "description": "<p>文｜李安琪</p>\n  <p>编辑｜李勤</p>\n  <p>11月6日小鹏汽车AI科技日上，董事长、CEO何小鹏首次披露了小鹏鲲鹏超级电动体系，主打“一车双能”战略。其中“鲲”代表超级增程系统，采用下一代增程技术；“鹏”代表着小鹏一直以来的纯电体系。</p>\n  <p>同时，小鹏还公布了智能化方面的进展，自动驾驶品牌正式升级为“小鹏图灵AI智驾”；自研的智驾芯片正式亮相，未来还可以支撑AI汽车、AI机器人、飞行汽车多个应用场景。面向长期，小鹏还在研发面向Robotaxi领域的Ultra车型，拥有L4级智能驾驶能力。</p>\n  <p>会上何小鹏直言，未来小鹏汽车要做面向全球的AI汽车公司。</p>\n  <p>在今天汽车市场的价格踩踏中，车企们需清晰找准自己的优势，保证产品进入市场时一击必中。小鹏此前发布的MONA系列M03车型，就凭借吸睛造型、性价比定价、以及智能功能等，拿到了月销量过万成绩。</p>\n  <p>但随着竞争环境更加激烈，小鹏需要更强的产品来撬动市场。推出增程车型，是小鹏的策略之一。</p>\n  <p>在会后的沟通环节中，何小鹏称，对增程其实思考了很多年，他认为还是要用不同的技术来获得不同的客户价值。纯电车依然有不足之处：在补能基建缓慢的地区，纯电可能无法满足用户需求；同时纯电最高做到800km续航，但如果用户想要超1000km续航，还是要换一种能源方式。</p>\n  <p>为此，小鹏推出了鲲鹏超级电动体系。该体系融合了小鹏在纯电领域的积累：800V高压碳化硅平台，5C超充能力，以及AI电池医生等。</p>\n  <p>基于这些技术，小鹏未来的增程新车的纯电续航达430km，综合续航里程超1400km；同时5C超充AI电池可实现“1秒充电1公里”，仅需12分钟即可充满80%。这些能力，都让增程车的使用体验，无限贴近当下的纯电车使用体验。</p>\n  <p>此外，小鹏还发布了全新一代混合碳化硅同轴电驱，电驱CLTC效率高达93.5%，体积仅为上一代电驱的三分之一，为车内腾出更多空间。</p>\n  <p>推出“一车双能”战略后，小鹏还在持续扩大补能体系。目前，小鹏在全国范围内建成1641座充电自营站，其中超充站为1307座。小鹏还计划在2025年面向中国和全球加速建设S5超级充电站。</p>\n  <p>而在智能化方面，小鹏的自动驾驶品牌升级为“图灵AI智驾”体系，涵盖了自研的云端和车端大模型、面向大模型开发的AI芯片和底层架构。</p>\n  <p>在云端大模型领域，小鹏称采用了与Open AI相同的训练框架，参数量是车端大模型的80倍。小鹏认为，通过将云端大模型蒸馏的方式，可以得到上限更高的车端大模型。这是小鹏端到端智驾的持续演进方式。</p>\n  <p>会上，何小鹏还分享了智驾芯片的最新进展：今年10月，小鹏图灵AI芯片已跑通最新版本的智驾功能。该芯片专门为大模型定制，拥有40核处理器，能够支持高达30B参数的大模型运行。</p>\n  <p>除此之外，小鹏还面向未来的L4自动驾驶车辆有更多设计。比如为自动驾驶车辆设计了车辆底层架构——沧海底座，涵盖核心计算平台、基础软件平台以及智能车控应用平台，例如可将整车总通讯带宽提升33倍、摄像头出图速度提升12倍，同时实现L4级别的安全冗余。</p>\n  <p>长期来看，小鹏已经在研发拥有Robotaxi形态的「Ultra」车型，该车将搭载多颗小鹏图灵AI芯片和小鹏沧海底座，整车算力高达3000TOPS，拥有L4级智能驾驶能力。</p>\n  <p>座舱方面，小鹏的天玑AIOS系统还计划将百亿参数大模型部署在本地，提供更自然、无感的人机交互。</p>\n  <p>在增程和纯电两种能源形式加持下，小鹏有机会获得更大市场版图；而构建的AI汽车体系，也会将小鹏的智能汽车推向更远处。</p>", "published": "2024-11-07 06:47:27", "id": "e0064afc-71b0-4d2d-99bf-7223f328634b", "source": "36氪", "section": "综合资讯"}, {"title": "国科恒泰：股东拟减持股份比例合计不超7.01%", "link": "https://36kr.com/newsflashes/3026202142139906?f=rss", "description": "36氪获悉，国科恒泰公告，股东国丰鼎嘉、西藏国科鼎奕、国科嘉和金源计划在公告披露15个交易日后的3个月内，共减持公司股份不超过3274万股，合计减持比例不超过公司总股本的7.01%。其中，国丰鼎嘉计划减持不超过1017.21万股，占总股本的2.18%；国科鼎奕计划减持不超过383.68万股，占总股本的0.8216%；国科嘉和金源计划减持不超过1873.11万股，占总股本的4.01%。此次减持系股东正常资金需求，不会对公司治理结构及持续经营产生重大影响。", "published": "2024-11-07 11:17:50", "id": "acaf4b77-e26e-49a7-841d-427a38a2a02c", "source": "36氪", "section": "综合资讯"}, {"title": "10连板华映科技：控股股东卖出0.61%公司股份", "link": "https://36kr.com/newsflashes/3026150030878213?f=rss", "description": "36氪获悉，华映科技发布股票交易异常波动公告，公司控股股东福建省电子信息集团于2024年11月6日-11月7日期间，通过集中竞价卖出16,750,000股华映科技股票，占华映科技总股本约0.61%。", "published": "2024-11-07 10:10:57", "id": "c8e65854-d166-4cb3-acc1-5183f0a48612", "source": "36氪", "section": "综合资讯"}, {"title": "“战略性放手”外卖？抖音攻向即时零售", "link": "https://36kr.com/newsflashes/3026184167105792?f=rss", "description": "近日，抖音外卖业务再经调整。抖音生活服务学习中心发布公告称，原“团购配送”业务将于11月1日起逐步向“随心团”业务迁移，即同一件团购商品既支持用户到店核销，也支持配送到家。对此，接近抖音外卖业务的人士乔木（化名）表示，这次调整可以被视为抖音对外卖业务的“战略性放手”。“（外卖业绩）一直没有增长，始终没法进行履约。”对于此次调整的原因，截至发稿，抖音方面暂未回应。（每经）", "published": "2024-11-07 10:33:43", "id": "bfa8db7c-cb29-4b0e-aa6b-0685e5f69440", "source": "36氪", "section": "综合资讯"}, {"title": "传网易游戏多名高管陷贪腐风波被带走调查，官方暂无回应", "link": "https://36kr.com/newsflashes/3026207977416201?f=rss", "description": "据媒体报道，近日网易游戏内部严查贪腐，涉及营销线多名高管，网易游戏市场部总经理向某等人已被带走调查。报道称，此次被带走高管多数出自市场部。在内部行业交流群里，有消息称，此次调查事件涉及金额上亿。就此向网易游戏求证，截至发稿官方暂未回应。（新浪科技）", "published": "2024-11-07 10:57:56", "id": "652a915b-be0c-4bc5-83bb-861cf6bc78df", "source": "36氪", "section": "综合资讯"}, {"title": "9连板华夏幸福：鉴于公司股票价格短期涨幅较大，敬请注意二级市场交易风险", "link": "https://36kr.com/newsflashes/3026145309877512?f=rss", "description": "36氪获悉，华夏幸福发布股票交易异常波动暨严重异常波动公告，公司股票自2024年10月28日至11月7日，已连续九个交易日涨停，鉴于公司股票价格短期涨幅较大，公司敬请广大投资者注意二级市场交易风险，理性决策，审慎投资。", "published": "2024-11-07 10:14:29", "id": "5f592113-8fb6-4e58-8a4d-90529fd38f01", "source": "36氪", "section": "综合资讯"}, {"title": "证监会10月期货公司名录新增摩根士丹利期货（中国）有限公司", "link": "https://36kr.com/newsflashes/3026174600422920?f=rss", "description": "36氪获悉，中国证监会公布“期货公司名录（2024年10月）”，期货公司数量由此前的150家变更为151家，新增机构为“摩根士丹利期货（中国）有限公司”。", "published": "2024-11-07 10:33:58", "id": "36623b29-b533-4561-be36-825a93804ec7", "source": "36氪", "section": "综合资讯"}, {"title": "皖通高速：发行不超50亿元公司债券获得注册批复", "link": "https://36kr.com/newsflashes/3026199504561672?f=rss", "description": "36氪获悉，皖通高速公告，公司近日收到中国证监会出具的批复，同意公司向专业投资者公开发行面值总额不超过50亿元公司债券的注册申请。该批复24个月内有效，公司在注册有效期内可以分期发行。", "published": "2024-11-07 11:00:14", "id": "3f60ef4f-9acb-4e01-b854-654c6921058b", "source": "36氪", "section": "综合资讯"}, {"title": "求购摩尔线程股份；转让半导体光刻机头部企业LP份额｜资情留言板第149期", "link": "https://36kr.com/p/3025846948816134?f=rss", "description": "<p>“资情留言板”是36氪推出的新栏目。</p>\n  <p>资产交易市场，信息瞬息万变，消息真假难辨，即使买卖双方花费大量的时间、精力，推动成交往往困难重重。为了能够帮助买卖双方更快速链接市场信息和潜在交易对手，避免不必要的投入与浪费，我们特地打造了这样一档栏目。</p>\n  <p>本文是这个栏目的第149期，我们汇总了当下市场上的一些资产供需信息。如果你对本文提到的相关的交易线索感兴趣，希望接触这些潜在的交易对手，或者如果你手中直接握有希望交易的资金或者资产，欢迎与我们联系（邮箱：zcjy@36kr.com）</p>\n  <p>9月份，我们已经举办了两场家办线下聚会，聚焦于二级市场海外资产配置和大类资产配置的主题，引起了参与热潮。如果您也对此类交流感兴趣，请联系我们：zcjy@36kr.com。</p>\n  <h2><strong>一、本月新增</strong></h2>\n  <h2><strong>1、转让半导体光刻机头部企业LP份额（预期估值约220亿人民币）</strong></h2>\n  <p>交易价格：预期估值约220亿人民币</p>\n  <p>当前轮次：Pre-IPO轮</p>\n  <p>资产规模：约5000万人民币份额</p>\n  <p>交易方式：LP份额</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>2、转让Shein公司股份（预期估值约500亿美元）</strong></h2>\n  <p>交易价格：预期估值约500亿美元</p>\n  <p>当前轮次：Pre-IPO轮</p>\n  <p>资产规模：约3000万美元份额</p>\n  <p>交易方式：显名SPV份额，可以拆分</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>3、求购摩尔线程公司股份（预期估值面议）</strong></h2>\n  <p>买家性质：直接买家</p>\n  <p>交易价格：预期估值面议</p>\n  <p>交易额度：2000万人民币份额</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>二、 资产求购</strong></h2>\n  <h2><strong>1、求购星动纪元公司股份（预期估值</strong>12<strong>亿人民币）</strong></h2>\n  <p><strong>买家性质：直接买家</strong></p>\n  <p><strong>交易价格：预期估值</strong>12<strong>亿人民币</strong></p>\n  <p><strong>交易额度：约</strong>1000<strong>万人民币</strong></p>\n  <p><strong>联系方式：</strong>zcjy@36kr.com</p>\n  <h2><strong>2、求购人形机器人领域公司股份（预期估值面谈）</strong></h2>\n  <p><strong>买家性质：直接买家</strong></p>\n  <p><strong>交易价格：预期估值面谈</strong></p>\n  <p><strong>交易额度：单一项目约</strong>2000-3000<strong>万人民币</strong></p>\n  <p><strong>联系方式：</strong>zcjy@36kr.com</p>\n  <h2><strong>3、寻求医疗、科技板块并购标的（预期估值面议）</strong></h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议</p>\n  <p>并购要求：过去三年累计利润7000-8000万人民币</p>\n  <p>交易方式：控股并购、现金并购</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>4、求购长鑫存储老股（预期估值面议）</strong></h2>\n  <p><strong>买家性质：直接买家</strong>&nbsp;</p>\n  <p><strong>交易价格：预期估值面议，按照市场公允价格</strong></p>\n  <p><strong>资产规模：</strong>3000-4000<strong>万人民币</strong></p>\n  <p><strong>交易方式：要求显名股东</strong></p>\n  <h2><strong>5、求购Shopee老股（预期估值面议）</strong></h2>\n  <p><strong>买家性质：直接买家</strong>&nbsp;</p>\n  <p><strong>交易价格：预期估值面议，按照市场公允价格</strong></p>\n  <p><strong>资产规模：</strong>1000<strong>万美金</strong></p>\n  <p><strong>交易方式：优先显名转让份额</strong></p>\n  <h2><strong>6、寻求医疗器械上下游并购标的（预期估值面议）</strong></h2>\n  <p>买家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议，要求有盈利</p>\n  <p>并购要求：1、江苏省内（苏锡常大市内更优）2、疼痛治疗耗材、介入治疗耗材（含内镜）、外科手术耗材、创面创新治疗耗材、麻醉类等生命支持耗材等与林华业务相关的六大领域；3、有源也考虑，以耗材为主（兼设备系统），影像大设备除外；4、有核心团队全职投入。</p>\n  <p>交易方式：3000-5000万投资实现至少51%控股，提供1-2亿资金和免费的办公室及厂房，通过公司300家壁垒商和3000+经销商为企业提供渠道网络。</p>\n  <h2><strong>7、寻求直播带货MCN并购标的（预期估值面议）</strong></h2>\n  <p>买家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议</p>\n  <p>并购要求：希望有快手、小红书、腾讯视频号或者tiktok其中任一平台成熟经验</p>\n  <p>交易方式：控股并购、现金并购，预计可投入过亿资金体量</p>\n  <h2><strong>8、求购阜阳欣奕华材料公司股份（预期估值28-29亿）</strong></h2>\n  <p>买家性质：LP买家</p>\n  <p>交易价格：预期估值28-29亿</p>\n  <p>交易额度：600万人民币份额</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>9、求购小红书公司股份（预期估值180亿美金）</strong></h2>\n  <p>买家性质：直接买家</p>\n  <p>交易价格：预期估值180亿美金</p>\n  <p>交易额度：约500-1000万美金份额，可以有结构</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>10、求购小红书公司股份（预期估值180亿美金）</strong></h2>\n  <p>买家性质：直接买家</p>\n  <p>交易价格：预期估值180亿美金</p>\n  <p>交易额度：约500万美金份额</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>11、求购SpaceX公司股份（预期估值每股112美金）</strong></h2>\n  <p>买家性质：LP买家</p>\n  <p>交易价格：预期估值每股112美金</p>\n  <p>交易额度：约2000万美金份额，需要单层结构</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>12、求购字节跳动公司股份（预期估值2300亿美金）</strong></h2>\n  <p>买家性质：LP买家</p>\n  <p>交易价格：预期估值2300亿美金</p>\n  <p>交易额度：约3000万美金份额</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>13、寻求伺服电机领域上下游并购标的（预期估值面议）</strong></h2>\n  <p>买家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议，要求有盈利</p>\n  <p>并购要求：伺服电机、永磁同步电机、伺服驱动器上下游企业</p>\n  <p>交易方式：控股并购、现金并购</p>\n  <h2><strong>14、寻求小家电领域上下游并购标的（预期估值面议）</strong></h2>\n  <p>买家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议，20亿之内</p>\n  <p>并购要求：要求有盈利</p>\n  <p>交易方式：控股并购、现金并购，也考虑战略投资</p>\n  <h2><strong>15、求购人型机器人领域老股（预期估值面议）</strong></h2>\n  <p>买家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议，按照市场价格</p>\n  <p>资产规模：2000万-3000万人民币</p>\n  <p>交易方式：优先显名转让份额</p>\n  <h2><strong>16、求购能量奇点公司股份（预期估值面议）</strong></h2>\n  <p>买家性质：LP买家</p>\n  <p>交易价格：预期估值面议</p>\n  <p>交易额度：500万人民币份额</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>17、寻求汽车领域上下游并购标的（预期估值面议）</strong></h2>\n  <p>买家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议，要求有盈利</p>\n  <p>并购要求：汽车智能座舱类、汽车空调及热管理；汽车车灯相关、汽车电机、电驱、电控相关；</p>\n  <p>交易方式：控股并购、现金并购</p>\n  <h2><strong>18、求购追觅科技股份（预期估值面议）</strong></h2>\n  <p>买家性质：直接买家</p>\n  <p>交易价格：预期估值面议</p>\n  <p>交易额度：千万人民币份额</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>19、求购头部茶饮企业老股份额</strong></h2>\n  <p>卖家性质：直接卖家</p>\n  <p>交易价格：面议</p>\n  <p>资产规模：1000-2000万人民币份额</p>\n  <p>交易方式：显名股东直接转让</p>\n  <h2><strong>20、寻求智慧城市板块并购标的（预期估值面议）</strong></h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议</p>\n  <p>并购要求：智慧城市相关，软硬件均可</p>\n  <p>交易方式：控股并购、现金并购</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>21、求购上海微电子股份（预期估值面议）</strong></h2>\n  <p>买家性质：直接买家</p>\n  <p>交易价格：预期估值面议</p>\n  <p>交易额度：1000-2000万人民币份额</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>22、寻求护肤品、美妆等赛道并购标的（预期估值面议）</strong>&nbsp;</h2>\n  <p>买家性质：直接机构买家</p>\n  <p>交易价格：预期估值面议</p>\n  <p>寻求标的画像：护肤品类、化妆品类、调味品，年利润在3000万人民币</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>23、寻求电子信息赛道并购标的（预期估值面议）</strong>&nbsp;</h2>\n  <p>买家性质：直接机构买家</p>\n  <p>交易价格：预期估值面议 ，约10亿人民币&nbsp;</p>\n  <p>寻求标的画像：电子信息行业标的，年利润在2000万人民币以上&nbsp;</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>24、寻求文旅赛道并购标的（预期估值面议）</strong>&nbsp;</h2>\n  <p>买家性质：直接机构买家</p>\n  <p>交易价格：预期估值面议 ，约10亿人民币&nbsp;</p>\n  <p>寻求标的画像：文旅上下游企业，年利润在2000万人民币以上</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>25、寻求办公软件赛道并购标的（预期估值面议）</strong>&nbsp;</h2>\n  <p>买家性质：直接机构买家</p>\n  <p>交易价格：预期估值面议 ，约10亿人民币</p>\n  <p>寻求标的画像：办公软件上下游企业，有利润。</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>26、寻求卤味食品、连锁餐饮板块并购标的（预期估值面议）</strong></h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议</p>\n  <p>并购要求：有盈利，有规模性收入，连锁店</p>\n  <p>交易方式：控股并购、现金并购</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>27、寻求精密制造领域板块并购标的（预期估值面议）</strong></h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议</p>\n  <p>并购要求：制造业，如离合器等汽车零部件，或未来有IPO上市潜质的中后期企业；要求有规模化收入</p>\n  <p>交易方式：控股并购、现金并购</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>28、寻求工业涂料、工业重防腐板块并购标的（预期估值面议）</strong></h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议</p>\n  <p>并购要求：航天航空高科技涂料、工业重防腐（基础设施，风电，港机，工业装备）；已经商业化；</p>\n  <p>交易方式：控股并购或战略投资、现金并购</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>29、寻求智能传感板块并购标的（预期估值面议）</strong></h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议</p>\n  <p>并购要求：需要具备传感器研发能力和制造能力的完整团队</p>\n  <p>交易方式：控股并购、现金并购</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>30、求购头部扫地机器人股份（预期估值面议）</strong></h2>\n  <p>买家性质：直接买家</p>\n  <p>交易价格：预期估值面议</p>\n  <p>交易额度：千万人民币份额</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>31、寻求农业、供应链和食品板块并购标的（预期估值面议）</strong></h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议</p>\n  <p>并购要求：要求有规模化利润和盈利，团队完整，净利润在千万以上。</p>\n  <p>交易方式：控股并购或者战略投资、现金并购</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>32、求购星动纪元机器人股份（估值面议）</strong>&nbsp;</h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：估值面议</p>\n  <p>资产规模：千万人民币左右</p>\n  <p>交易方式：要求上股东名册</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>33、求购智元机器人股份（估值面议）&nbsp;</strong></h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：估值面议</p>\n  <p>资产规模：千万人民币左右</p>\n  <p>交易方式：要求上股东名册</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>34、寻求正负极材料板块并购标的（预期估值面议）</strong></h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议</p>\n  <p>并购要求：有一定规模的商业化收入</p>\n  <p>交易方式：控股并购、现金并购</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>35、寻求新能源上下游赛道并购标的（预期估值面议）</strong></h2>\n  <p>卖家性质：直接买家&nbsp;</p>\n  <p>交易价格：预期估值面议</p>\n  <p>并购要求：有一定规模的商业化收入，有5000万人民币以上的利润</p>\n  <p>交易方式：控股并购、现金并购</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>&nbsp;三、 资产出让/增资</strong></h2>\n  <h2><strong>1、转让头部境内外一体化国家粮油交易平台企业基金LP份额（预期估值面议）</strong></h2>\n  <p><strong>卖家性质：直接卖家</strong>&nbsp;</p>\n  <p><strong>交易价格：面议</strong></p>\n  <p><strong>资产规模：</strong>5000<strong>万人民币份额</strong>&nbsp;</p>\n  <p><strong>交易方式：管理费</strong>2%<strong>，</strong>carry20%&nbsp;</p>\n  <p><strong>其他说明：</strong>LP<strong>份额，一层结构</strong></p>\n  <h2><strong>2、转让国产焊接工业龙头企业专项基金</strong>LP<strong>份额（预期估值面议）</strong></h2>\n  <p><strong>资产亮点：公司是国内唯一机器人控制器起家的机器人本体企业，转型前曾是国内最大的第三方机器人控制器供应商，市占率</strong>50%<strong>以上，奠定了深厚的机器人技术基础。</strong>&nbsp;19<strong>年转型做焊接机器人，连续多年获得国产焊接机器人出货量第一，并持续至今。</strong></p>\n  <p><strong>卖家性质：直接卖家</strong>&nbsp;</p>\n  <p><strong>交易价格：面议</strong></p>\n  <p><strong>资产规模：</strong>2000<strong>万人民币份额</strong>&nbsp;</p>\n  <p><strong>交易方式：管理费</strong>2%<strong>，</strong>carry20%&nbsp;</p>\n  <p><strong>其他说明：</strong>LP<strong>份额，一层结构</strong></p>\n  <h2><strong>3、转让创新药领域生成式</strong>Ai<strong>头部企业专项基金</strong>LP<strong>份额（预期估值面议）</strong></h2>\n  <p><strong>卖家性质：直接卖家</strong>&nbsp;</p>\n  <p><strong>交易价格：面议</strong></p>\n  <p><strong>资产规模：</strong>1000<strong>万人民币份额</strong>&nbsp;</p>\n  <p><strong>交易方式：管理费</strong>2%<strong>，</strong>carry20%&nbsp;</p>\n  <p><strong>其他说明：</strong>LP<strong>份额，一层结构</strong></p>\n  <h2><strong>4、转让商业航天头部企业老股份额（预期估值面议）</strong></h2>\n  <p><strong>卖家性质：直接卖家</strong>&nbsp;</p>\n  <p><strong>交易价格：面议</strong></p>\n  <p><strong>资产规模：</strong>5000<strong>万人民币份额</strong>&nbsp;</p>\n  <p><strong>交易方式：</strong>&nbsp;<strong>显名股东份额转让</strong></p>\n  <h2><strong>5、转让UHMWPE高强度纤维赛道头部项目专项基金LP份额（预期估值38亿人民币）</strong></h2>\n  <p>资产亮点：公司生产的UHMWPE高强度纤维，填补了此产品国内空白。此前同类材料全世界只有荷兰帝斯曼与美 国霍尼韦尔可以生产，目前公司在产品性能、生产技术、环保、成本等全方面已实现全面超越。产销均为行业世界绝对龙头。</p>\n  <p>卖家性质：直接卖家&nbsp;</p>\n  <p>交易价格：38亿人民币&nbsp;</p>\n  <p>资产规模：3000万人民币份额&nbsp;</p>\n  <p>交易方式：管理费2%，carry20%&nbsp;</p>\n  <p>其他说明：LP份额，一层结构</p>\n  <h2><strong>6、转让智能驾驶头部企业纵目驾驶专项基金LP份额</strong></h2>\n  <p>卖家性质：直接卖家&nbsp;</p>\n  <p>交易价格：投前90亿人民币&nbsp;</p>\n  <p>当前轮次：Pre-IPO轮&nbsp;</p>\n  <p>资产规模：2000万人民币份额&nbsp;</p>\n  <p>交易方式：管理费2%，carry20%&nbsp;</p>\n  <p>其他说明：LP份额，一层结构，显名直投</p>\n  <h2><strong>7、转让母婴电商平台头部企业妈妈网份额</strong></h2>\n  <p>卖家性质：直接卖家&nbsp;</p>\n  <p>交易价格：投前15亿人民币&nbsp;</p>\n  <p>资产规模：1500万人民币份额&nbsp;</p>\n  <p>交易方式：显名股东直接转让</p>\n  <h2><strong>8、转让肿瘤免疫治疗药物领域头部企业股份（预期估值约32亿人民币）</strong></h2>\n  <p>资产介绍：公司是新一代携带免疫刺激因子的溶瘤病毒药物上的突破，成为了肿瘤免疫治疗领域新技术新药物研发的领先者</p>\n  <p>交易价格：预期估值约32亿人民币</p>\n  <p>当前轮次：Pre-IPO轮</p>\n  <p>资产规模：约2亿人民币份额</p>\n  <p>交易方式：显名直投</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>9、转让双特异性抗体药物领域头部企业股份（预期估值约32亿人民币）</strong></h2>\n  <p>资产介绍：公司自主知识产权的双抗技术平台FIT-Ig已突破生产工艺难题，并初步展示出良好成药效果&nbsp;</p>\n  <p>交易价格：预期估值约35亿人民币</p>\n  <p>当前轮次：Pre-IPO轮</p>\n  <p>资产规模：约2亿人民币份额</p>\n  <p>交易方式：显名直投</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>10、转让半导体硅片领域头部企业股份（预期估值面谈）</strong></h2>\n  <p>资产介绍：公司拥有国内技术和规模领先的200mm半导体硅片生产基地，以及行业内先进的300mm半导体硅片全自动智能化生产线，已成为中国大陆大尺寸硅片生产与销售的领先企业之一。</p>\n  <p>交易价格：预期估值面谈</p>\n  <p>资产规模：约1500万人民币份额</p>\n  <p>交易方式：LP份额</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>11、转让电池正极材料领域头部企业股份（预期估值约36亿人民币）</strong></h2>\n  <p>资产介绍：公司一直从事电池正极材料及特殊领域电池制造业务，是国内领先的三元前驱体生产企业</p>\n  <p>交易价格：预期估值约36亿人民币</p>\n  <p>当前轮次：Pre-IPO轮</p>\n  <p>资产规模：约4亿人民币份额</p>\n  <p>交易方式：显名直投</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>12、转让呼吸领域头部企业股份（预期估值约44.5亿人民币）</strong></h2>\n  <p>资产介绍：公司是一家专注于呼吸领域用药的研发、生产并在全球市场进行注册和销售的高端制剂企业</p>\n  <p>交易价格：预期估值约44.5亿人民币</p>\n  <p>当前轮次：Pre-IPO轮</p>\n  <p>资产规模：约1亿人民币份额</p>\n  <p>交易方式：显名直投</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>13、转让伺服电机领域头部企业股份（预期估值约40亿人民币）</strong></h2>\n  <p>资产介绍：公司是一家伺服电机、永磁同步电机和伺服驱动器的生产企业，并为客户提供定制化解决方案，业务涵盖自动化控制、运动控制和能量转换等多个领域</p>\n  <p>交易价格：预期估值约40亿人民币</p>\n  <p>当前轮次：Pre-IPO轮</p>\n  <p>资产规模：约3亿人民币份额</p>\n  <p>交易方式：显名直投</p>\n  <p>联系方式：zcjy@36kr.com</p>\n  <h2><strong>**</strong></h2>\n  <p>说明1</p>\n  <p>需要说明的是：“资情留言板”栏目的相关信息均为动态信息，可能因市场情况变化或者交易完成而失效。36氪仅提供相关交易信息，具体交易需交易相关方另行协商并签署有关协议，交易各方必须依靠自己的法律、审计和税务专家的专业知识来处理法律、监管、审计和税务问题，36氪无意为交易各方提供承销服务或任何需持有特定资质或牌照方可从事的服务。</p>\n  <p>咨询更多份额请联系：zcjy@36kr.com</p>\n  <p>说明2</p>\n  <p>2021年6月开始，36氪资情留言板上线，已发布148期内容。</p>\n  <p>第1期：《<a href=\"https://36kr.com/p/1277884127217416\" rel=\"noopener noreferrer\" target=\"_blank\">转让字节跳动老股、求购估值5亿元以内的保险科技类标的｜资情留言板第1期</a>》</p>\n  <p>第2期：<a href=\"https://36kr.com/p/1291631775156616\" rel=\"noopener noreferrer\" target=\"_blank\">《 持有《个人本外币兑换特许业务经营许可证》（全国仅65张）公司股权转让，市场价格求购字节跳动、Shein、小红书股份｜资情留言板第2期 》</a></p>\n  <p>第3期：<a href=\"https://36kr.com/p/1317158918867458\" rel=\"noopener noreferrer\" target=\"_blank\">《 一手卖家转让持有字节跳动股份的单标基金份额，市场价格求购大疆、地平线股份｜资情留言板第3期》</a></p>\n  <p>第4期：<a href=\"https://36kr.com/p/1327352884123908\" rel=\"noopener noreferrer\" target=\"_blank\">《转让商汤科技股份，直接买家求购大疆股份（综合成本不高于185亿美元）｜资情留言板第4期》</a>。</p>\n  <p>第5期：<a href=\"https://36kr.com/p/1338356062427401\" rel=\"noopener noreferrer\" target=\"_blank\">《转让喜马拉雅股份，转让持有互联网视听许可证（基本涵盖所有业务）公司股权｜资情留言板第5期》</a></p>\n  <p>第6期：<a href=\"https://36kr.com/p/1348269397154052\" rel=\"noopener noreferrer\" target=\"_blank\">《转让商汤、Impossible Foods、Strip老股，求购大疆、极兔、地平线股份｜资情留言板第6期》</a></p>\n  <p>第7期：<a href=\"https://36kr.com/p/1358232131404934\" rel=\"noopener noreferrer\" target=\"_blank\">《转让中星微、华氏医药老股，求购地平线、小红书、大疆股份｜资情留言板第7期》</a></p>\n  <p>第8期：<a href=\"https://36kr.com/p/1368060909482117\" rel=\"noopener noreferrer\" target=\"_blank\">《转让菜鸟网络、地平线、集创北方股份；求购Tims咖啡、小红书、大疆股份｜资情留言板第8期》</a></p>\n  <p>第9期：<a href=\"https://36kr.com/p/1378147207265664\" rel=\"noopener noreferrer\" target=\"_blank\">《转让香港主板某上市公司壳等股份，求购喜茶、得物、Paytm、货拉拉等股份｜资情留言板第9期》</a></p>\n  <p>第10期：<a href=\"https://36kr.com/p/1388213970025224\" rel=\"noopener noreferrer\" target=\"_blank\">《转让喜马拉雅、能链集团等股份；求购京颐、大疆、元气森林等股份｜资情留言板第10期》</a></p>\n  <p>第11期：<a href=\"https://36kr.com/p/1398089461807872\" rel=\"noopener noreferrer\" target=\"_blank\">《求购极兔速递、地平线、小红书等股份，转让大疆等公司股份｜资情留言板第11期》</a></p>\n  <p>第12期：<a href=\"https://36kr.com/p/1408254496707971\" rel=\"noopener noreferrer\" target=\"_blank\">《求购得物、小红书、SHEIN股份；转让大疆、速递物流头部公司股份｜资情留言板第12期》</a></p>\n  <p>第13期：<a href=\"https://36kr.com/p/1417859267083651\" rel=\"noopener noreferrer\" target=\"_blank\">《求购小红书、地平线、得物股份；转让喜马拉雅、大疆、同城货运某头部公司股份｜资情留言板第13期》</a></p>\n  <p>第14期：<a href=\"https://36kr.com/p/1437689795640962\" rel=\"noopener noreferrer\" target=\"_blank\">《求购微牛证券、小红书公司股份；转让中星微、大疆、持有教育类视听证某公司股份｜资情留言板第14期》</a></p>\n  <p>第15期：<a href=\"https://36kr.com/p/1447717278967682\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X股份的基金LP份额（按940亿美元估值计算）；某家族办公室寻求得物、微牛证券股份｜资情留言板第15期》</a></p>\n  <p>第16期：<a href=\"https://36kr.com/p/1457874440447881\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、飞骧科技、中星微等公司股份的基金份额；求购得物股份｜资情留言板第16期》</a></p>\n  <p>第17期：<a href=\"https://36kr.com/p/1467631889976322\" rel=\"noopener noreferrer\" target=\"_blank\">《某家族办公室求购得物股份；转让持有飞骧科技、Space X股份的基金份额｜资情留言板第17期》</a></p>\n  <p>第18期：<a href=\"https://36kr.com/p/1477502150046471\" rel=\"noopener noreferrer\" target=\"_blank\">《转让香港创业板某上市壳公司（地产板块）股份；求购小红书股份｜资情留言板第18期》</a></p>\n  <p>第19期：<a href=\"https://36kr.com/p/1487237997412485\" rel=\"noopener noreferrer\" target=\"_blank\">《某知名家电上市公司寻求并购标的，转让某头部商业地产公司老股｜资情留言板第19期》</a></p>\n  <p>第20期：<a href=\"https://36kr.com/p/1497161276160135\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Epic Games股份的单项股权基金份额；某知名母婴平台旗下垂直电商业务寻求产业并购｜资情留言板第20期》</a></p>\n  <p>第21期：<a href=\"https://36kr.com/p/1507335103975425\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有中星微、商汤科技股份的专项基金份额；某家族办公室寻求Discord、Neuralink、Toss等股份｜资情留言板第21期》</a></p>\n  <p>第22期：<a href=\"https://36kr.com/p/1517466949380869\" rel=\"noopener noreferrer\" target=\"_blank\">《某知名母婴平台旗下垂直电商业务寻求出售机会；转让中星微、商汤科技专项基金份额｜资情留言板第22期》</a></p>\n  <p>第23期：<a href=\"https://36kr.com/p/1526819961777794\" rel=\"noopener noreferrer\" target=\"_blank\">《转让某知名食品饮料赛道头部公司股份（按最新估值约八折计算）、转让Upbit老股｜资情留言板第23期》</a></p>\n  <p>第24期：<a href=\"https://36kr.com/p/1536887060975878\" rel=\"noopener noreferrer\" target=\"_blank\">《某知名母婴平台旗下垂直电商业务寻求出售机会；转让某知名食品饮料赛道头部公司股份｜资情留言板第24期》</a></p>\n  <p>第25期：<a href=\"https://36kr.com/p/1546844074535169\" rel=\"noopener noreferrer\" target=\"_blank\">《转让国内某TOP跨境物流服务商老股、某知名食品饮料赛道头部公司股份｜资情留言板第25期》</a></p>\n  <p>第26期：<a href=\"https://36kr.com/p/1556807793725062\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X股份的专项基金LP份额、某知名食品饮料赛道头部公司股份｜资情留言板第26期》</a></p>\n  <p>第27期：<a href=\"https://36kr.com/p/1566733202624133\" rel=\"noopener noreferrer\" target=\"_blank\">《转让Space X股份、护肤品牌AnesSens代理权、某知名食品饮料赛道头部公司股份｜资情留言板第27期》</a></p>\n  <p>第28期：<a href=\"https://36kr.com/p/1576652946361091\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Neuralink、Space X股份的专项基金LP份额；护肤品牌AnesSens代理权转让｜资情留言板第28期》</a></p>\n  <p>第29期：<a href=\"https://36kr.com/p/1587347581127433\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有龙头封测企业QZKJ股份、Neuralink股份、Space X股份的专项基金LP份额｜资情留言板第29期》</a></p>\n  <p>第30期：<a href=\"https://36kr.com/p/1606269802367488\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Neuralink、Open Sea、Space X股份的专项基金份额，转让艾博生物老股｜资情留言板第30期》</a></p>\n  <p>第31期：<a href=\"https://36kr.com/p/1616482907008520\" rel=\"noopener noreferrer\" target=\"_blank\">《某知名母婴平台旗下垂直电商业务寻求产业并购；转让持有Neuralink、Space X股份的专项基金份额｜资情留言板第31期》</a></p>\n  <p>第32期：<a href=\"https://36kr.com/p/1626139209463556\" rel=\"noopener noreferrer\" target=\"_blank\">《转让某知名食品饮料赛道头部公司股份；转让持有Discord、Epic Games股份的专项基金份额｜资情留言板第32期》</a></p>\n  <p>第33期：<a href=\"https://36kr.com/p/1636328946229126\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Neuralink、Space X、某智能终端电子芯片ZXW股份的专项基金份额｜资情留言板第33期》</a></p>\n  <p>第34期：<a href=\"https://36kr.com/p/1646173976109959\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Animoca Brands、某国产GPGPU、某密码技术龙头公司股份的专项基金LP份额｜资情留言板第34期》</a></p>\n  <p>第35期：<a href=\"https://36kr.com/p/1656742227261576\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Blockdaemon、Space X、某龙头密码公司、Neuralink股份的基金份额｜资情留言板第35期》</a></p>\n  <p>第36期：<a href=\"https://36kr.com/p/1666174507128836\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有文远知行、Space X、某智能终端电子芯片ZXW股份的专项基金LP份额｜资情留言板第36期》</a></p>\n  <p>第37期：<a href=\"https://36kr.com/p/1676524003157253\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Epic Games、某龙头封测企业QZKJ股份的专项基金LP份额｜资情留言板第37期》</a></p>\n  <p>第38��：<a href=\"https://36kr.com/p/1686615381376772\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、某智能终端电子芯片ZXW、文远知行股份的专项基金LP份额｜资情留言板第38期》</a></p>\n  <p>第39期：<a href=\"https://36kr.com/p/1695404923498114\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Shein、途虎养车、某头部智能驾驶公司等股份的专项基金LP份额｜资情留言板第39期》</a></p>\n  <p>第40期：<a href=\"https://36kr.com/p/1705723293144839\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有SpaceX、Shein、某头部智能驾驶公司专项基金LP份额｜资情留言板第40期》</a></p>\n  <p>第41期：<a href=\"https://36kr.com/p/1715459202249480\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Animoca Brands、Discord、某龙头封测公司股份的专项基金LP份额｜资情留言板第41期》</a></p>\n  <p>第42期：<a href=\"https://36kr.com/p/1725488387980545\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Epic Games、某国产GPGPU龙头公司股份的专项基金LP份额｜资情留言板第42期》</a></p>\n  <p>第43期：<a href=\"https://36kr.com/p/1734953390390537\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Shein、Discord股份的专项基金份额；求购Space X股份（500万美元以上需求）｜资情留言板第43期》</a></p>\n  <p>第44期：<a href=\"https://36kr.com/p/1745981826068358\" rel=\"noopener noreferrer\" target=\"_blank\">《转让某全球知名物流服务商、某食品饮料赛道头部公司老股；求购Space X股份｜资情留言板第44期》</a></p>\n  <p>第45期：<a href=\"https://36kr.com/p/1755786870718084\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Shein、某头部智能驾驶公司股份的专项基金LP份额｜资情留言板第45期》</a></p>\n  <p>第46期：<a href=\"https://36kr.com/p/1764960240384256\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Shein公司股份的专项基金份额；护肤品牌AnesSens代理权转让｜资情留言板第46期》</a></p>\n  <p>第47期：<a href=\"https://36kr.com/p/1775051861412232\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Discord、某头部智能驾驶公司股份的专项基金LP份额｜资情留言板第47期》</a></p>\n  <p>第48期：<a href=\"https://36kr.com/p/1784806224858503\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有 Space X、Cybereason 公司股份的专项基金份额；求购 Flexport 股份｜资情留言板第48期》</a></p>\n  <p>第49期：<a href=\"https://36kr.com/p/1795407331836163\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Shein、Space X、某知名食品饮料赛道头部公司股份的专项基金份额｜资情留言板第49期》</a></p>\n  <p>第50期：<a href=\"https://36kr.com/p/1805356388008961\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X股份的基金LP份额、驴奶护肤品牌AnesSens代理权｜资情留言板第50期》</a></p>\n  <p>第51期：<a href=\"https://36kr.com/p/1814451335939456\" rel=\"noopener noreferrer\" target=\"_blank\">《转让某互联网物流行业、知名食品饮料赛道、自动驾驶领域等头部公司老股｜资情留言板第51期》</a></p>\n  <p>第52期：<a href=\"https://36kr.com/p/1825134672496133\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Shein股份的基金份额，某头部智能驾驶、物流公司老股转让｜资情留言板第52期》</a></p>\n  <p>第53期：<a href=\"https://36kr.com/p/1834219714486787\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Discord、某头部机器人、双碳公司股份的专项基金LP份额｜资情留言板第53期》</a></p>\n  <p>第54期：<a href=\"https://36kr.com/p/1844355176221573\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Neuralink、Space X、某头部自动驾驶公司股份的专项基金LP份额｜资情留言板第54期》</a></p>\n  <p>第55期：<a href=\"https://36kr.com/p/1853772342759048\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Neuralink、某头部自动驾驶、碳酸锂公司股份的专项基金LP份额｜资情留言板第55期》</a></p>\n  <p>第56期：<a href=\"https://36kr.com/p/1865006619136512\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Shein、某头部自动驾驶公司股份的专项基金LP份额｜资情留言板第56期》</a></p>\n  <p>第57期：<a href=\"https://36kr.com/p/1874062900677769\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Neuralink、某头部芯片、商业航天公司股份的专项基金LP份额｜资情留言板第57期》</a></p>\n  <p>第58期：<a href=\"https://36kr.com/p/1884787991833732\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Shein、某头部汽车、双碳领域等公司股份的专项基金LP份额｜资情留言板第58期》</a></p>\n  <p>第59期：<a href=\"https://36kr.com/p/1893678719160836\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Neuralink、某知名食品饮料赛道头部公司股份的专项基金LP份额｜资情留言板第59期》</a></p>\n  <p>第60期：<a href=\"https://36kr.com/p/1904408157972873\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Neuralink、某头部物流及汽车领域公司股份的专项基金LP份额｜资情留言板第60期》</a></p>\n  <p>第61期：<a href=\"https://36kr.com/p/1914429503311877\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Shein、某头部氢能、自动驾驶等公司股份的专项基金LP份额｜资情留言板第61期》</a></p>\n  <p>第62期：<a href=\"https://36kr.com/p/1924326637288194\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Neuralink、Shein、Discord股份的专项基金LP份额｜资情留言板第62期》</a></p>\n  <p>第63期：<a href=\"https://36kr.com/p/1933426489624960\" rel=\"noopener noreferrer\" target=\"_blank\">《求购国内一线美元基金LP份额 ；转让持有Space X、Neuralink的专项基金LP份额｜资情留言板第63期》</a></p>\n  <p>第64期：<a href=\"https://36kr.com/p/1953994189166726\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Neuralink老股 ；转让持有Space X、某食品饮料头部公司的基金份额｜资情留言板第64期》</a></p>\n  <p>第65期：<a href=\"https://36kr.com/p/1964156597611011\" rel=\"noopener noreferrer\" target=\"_blank\">《求购极兔、小红书老股；转让持有Space X、某自动驾驶头部公司的基金份额｜资情留言板第65期》</a></p>\n  <p>第66期：<a href=\"https://36kr.com/p/1974011563712899\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Neuralink、小红书老股；转让持有Shein、某氢能头部公司股份的基金份额｜资情留言板第66期》</a></p>\n  <p>第67期：<a href=\"https://36kr.com/p/1983915551032576\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Neuralink、Shein公司股份的基金份额；求购极兔、小红书老股｜资情留言板第67期》</a></p>\n  <p>第68期：<a href=\"https://36kr.com/p/1993784431145475\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Discord公司股份的基金份额；求购Neuralink、小���书老股｜资情留言板第68期》</a></p>\n  <p>第69期：<a href=\"https://36kr.com/p/2003816544309382\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Space X、小红书老股；转让持有Neuralink、某头部物流公司股份的基金份额｜资情留言板第69期》</a></p>\n  <p>第70期：<a href=\"https://36kr.com/p/2013638157730312\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Neuralink、某头部自动驾驶公司股份的基金份额｜资情留言板第70期》</a></p>\n  <p>第71期：<a href=\"https://36kr.com/p/2023681544400136\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Shein、某头部物流公司股份的专项基金份额｜资情留言板第71期》</a></p>\n  <p>第72期：<a href=\"https://36kr.com/p/2033420631223553\" rel=\"noopener noreferrer\" target=\"_blank\">《求购OpenAI股份（ChatGPT的母公司）；转让持有Space X、Shein公司股份的基金份额｜资情留言板第72期》</a></p>\n  <p>第73期：<a href=\"https://36kr.com/p/2043326810491907\" rel=\"noopener noreferrer\" target=\"_blank\">《求购OpenAI、Neuralink股份；转让持有Space X、Shein公司股份的基金份额｜资情留言板第73期》</a></p>\n  <p>第74期：<a href=\"https://36kr.com/p/2053224417636869\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有OpenAI、Shein公司股份的基金份额；求购Space X、Neuralink老股｜资情留言板第74期》</a></p>\n  <p>第75期：<a href=\"https://36kr.com/p/2062958054920072\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Space X、Neuralink老股；转让持有Shein、某头部物流公司股份的基金份额｜资情留言板第75期》</a></p>\n  <p>第76期：<a href=\"https://36kr.com/p/2073220743232648\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Space X、Neuralink老股；转让持有Shein、OpenAI的基金份额｜资情留言板第76期》</a></p>\n  <p>第77期：<a href=\"https://36kr.com/p/2082911478493955\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有OpenAI、某头部物流公司的基金份额；求购Space X、Neuralink老股｜资情留言板第77期》</a></p>\n  <p>第78期：<a href=\"https://36kr.com/p/2093033295446149\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Space X、Neuralink老股；转让持有Shein、某头部物流公司的基金份额｜资情留言板第78期》</a></p>\n  <p>第79期：<a href=\"https://36kr.com/p/2112625351887237\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Neuralink、OpenAI、某头部自动驾驶公司的专项基金份额｜资情留言板第79期》</a></p>\n  <p>第80期：<a href=\"https://36kr.com/p/2122439613073800\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Neuralink老股；转让持有OpenAI、Space X、某头部物流公司的专项基金份额｜资情留言板第80期》</a></p>\n  <p>第81期：<a href=\"https://36kr.com/p/2132613012925446\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Space X、Neuralink老股；转让持有Shein、某头部自动驾驶公司的基金份额｜资情留言板第81期》</a></p>\n  <p>第82期：<a href=\"https://36kr.com/p/2142445875446279\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Neuralink、Shein、某头部物流公司的专项基金份额｜资情留言板第82期》</a></p>\n  <p>第83期：<a href=\"https://36kr.com/p/2152151366717952\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、OpenAI、Discord、某头部物流公司的专项基金份额｜资情留言板第83期》</a></p>\n  <p>第84期：<a href=\"https://36kr.com/p/2162341785694473\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Neuralink、Space X老股；转让持有OpenAI、某自动驾驶公司的基金份额｜资情留言板第84期》</a></p>\n  <p>第85期：<a href=\"https://36kr.com/p/2172248012992773\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Shein、OpenAI、某自动驾驶公司的专项基金份额｜资情留言板第85期》</a></p>\n  <p>第86期：<a href=\"https://36kr.com/p/2182121328277504\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有OpenAI、Space X、Discord、某自动驾驶公司的专项基金份额｜资情留言板第86期》</a></p>\n  <p>第87期：<a href=\"https://36kr.com/p/2192114415485317\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Neuralink、Shein、某头部物流公司的专项基金份额｜资情留言板第87期》</a></p>\n  <p>第88期：<a href=\"https://36kr.com/p/2201946256796549\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Open AI老股；转让持有Space X、Neuralink、Shein的专项基金份额｜资情留言板第88期》</a></p>\n  <p>第89期：<a href=\"https://36kr.com/p/2211741658756484\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Space X、Open AI老股；转让持有Neuralink、某头部自动驾驶公司的基金份额｜资情留言板第89期》</a></p>\n  <p>第90期：<a href=\"https://36kr.com/p/2221758417404548\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Open AI、医疗大健康类资产；转让持有Space X、Neuralink的基金份额｜资情留言板第90期》</a></p>\n  <p>第91期：<a href=\"https://36kr.com/p/2231964007624322\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Discord、Shein的基金份额；求购Open AI、医疗大健康类资产｜资情留言板第91期》</a></p>\n  <p>第92期：<a href=\"https://36kr.com/p/2251668094791300\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Space X、Open AI老股；转让持有Neuralink、Shein的基金份额｜资情留言板第92期》</a></p>\n  <p>第93期：<a href=\"https://36kr.com/p/2261384425107080\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Space X、Open AI老股；转让持有Neuralink、Shein的基金份额｜资情留言板第93期》</a></p>\n  <p>第94期：<a href=\"https://36kr.com/p/2271402958036740\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Space X、Open AI老股；转让持有Neuralink、Discord的基金份额｜资情留言板第94期》</a></p>\n  <p>第95期：<a href=\"https://36kr.com/p/2281294735022081\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Open AI、Neuralink、Discord与某头部机器人公司的基金份额｜资情留言板第95期》</a></p>\n  <p>第96期：<a href=\"https://36kr.com/p/2290992515127044\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Open AI、Space X老股；转让持有Shein、Discord公司的专项基金份额｜资情留言板第96期》</a></p>\n  <p>第97期：<a href=\"https://36kr.com/p/2300816066653192\" rel=\"noopener noreferrer\" target=\"_blank\">《转让持有Space X、Open AI、Shein、Neuralink公司的专项基金份额｜资情留言板第97期》</a></p>\n  <p>第98期：<a href=\"https://36kr.com/p/2310985178803712\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Space X、Neuralink、Open AI股份；转让500亿美元估值的Shein老股｜资情留言板第98期》</a></p>\n  <p>第99期：<a href=\"https://36kr.com/p/2320926749918341\" rel=\"noopener noreferrer\" target=\"_blank\">《转让Space X、Open AI、某500亿美元估值的Shein老股份额｜资情留言板第99期》</a></p>\n  <p>第100期：<a href=\"https://36kr.com/p/2329231138627205\" rel=\"noopener noreferrer\" target=\"_blank\">《转让Space X、菜鸟网络、约200万美元额度的Open AI老股份额｜资情留言板第100期》</a></p>\n  <p>第101期：<a href=\"https://36kr.com/p/2340604657618433\" rel=\"noopener noreferrer\" target=\"_blank\">《转让Space X、菜鸟网络、Open AI老股份额｜资情留言板第101期》</a></p>\n  <p>第102期：<a href=\"https://36kr.com/p/2350465130813955\" rel=\"noopener noreferrer\" target=\"_blank\">《转让Animoca Brands、Open AI、Space X专项基金LP份额｜资情留言板第102期》</a></p>\n  <p>第103期：<a href=\"https://36kr.com/p/2360470848863746\" rel=\"noopener noreferrer\" target=\"_blank\">《转让Neuralink、Open AI、Space X专项基金LP份额｜资情留言板第103期》</a></p>\n  <p>第104期：<a href=\"https://36kr.com/p/2369648059706247\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Shein、元气森林股份；转让Neuralink、Open AI股份｜资情留言板第104期》</a></p>\n  <p>第105期：<a href=\"https://36kr.com/p/2380255544536065\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Open AI股份；转让Shein、Space X专项基金LP份额｜资情留言板第105期》</a></p>\n  <p>第106期：<a href=\"https://36kr.com/p/2389495610364547\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Shein、Open AI股份；转让Space X专项基金LP份额｜资情留言板第106期》</a></p>\n  <p>第107期：<a href=\"https://36kr.com/p/2399270604480134\" rel=\"noopener noreferrer\" target=\"_blank\">《求购菜鸟网络老股；转让Neuralink、Space X专项基金LP份额｜资情留言板第107期》</a></p>\n  <p>第108期：<a href=\"https://36kr.com/p/2409860518224647\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Neuralink、元气森林公司股份；转让Animoca Brands、Open AI专项基金LP份额｜资情留言板第108期》</a></p>\n  <p>第109期：<a href=\"https://36kr.com/p/2419787613758472\" rel=\"noopener noreferrer\" target=\"_blank\">《求购喜茶股份；转让中科富海、Shein、Open AI基金LP份额｜资情留言板第109期》</a></p>\n  <p>第110期：<a href=\"https://36kr.com/p/2429655630696834\" rel=\"noopener noreferrer\" target=\"_blank\">《求购菜鸟、比亚迪半导体股份；转让Shein、Open AI基金LP份额｜资情留言板第110期》</a></p>\n  <p>第111期：<a href=\"https://36kr.com/p/2438931564384901\" rel=\"noopener noreferrer\" target=\"_blank\">《求购小红书股份；转让Neuralink、OpenAI、Space X专项基金LP份额｜资情留言板第111期》</a></p>\n  <p>第112期：<a href=\"https://36kr.com/p/2449552473069443\" rel=\"noopener noreferrer\" target=\"_blank\">《求购喜茶、小红书、比亚迪半导体股份；转让大疆创新股份｜资情留言板第112期》</a></p>\n  <p>第113期：<a href=\"https://36kr.com/p/2469298519955329\" rel=\"noopener noreferrer\" target=\"_blank\">《求购小红书、OpenAI股份；转让Neuralink专项基金LP份额、大疆创新股份��资情留言板第113期》</a></p>\n  <p>第114期：<a href=\"https://36kr.com/p/2479274329085832\" rel=\"noopener noreferrer\" target=\"_blank\">《求购OpenAI股份；转让Animoca Brands、Discord股份专项基金LP份额｜资情留言板第114期》</a></p>\n  <p>第115期：<a href=\"https://36kr.com/p/2488605245249665\" rel=\"noopener noreferrer\" target=\"_blank\">《求购菜鸟网络老股、小红书股份；转让某头部生物公司股份、互联网医疗企业老股、Neuralink股份的专项基金LP份额｜资情留言板第115期》</a></p>\n  <p>第116期：<a href=\"https://36kr.com/p/2498445508974471\" rel=\"noopener noreferrer\" target=\"_blank\">《求购小红书、喜茶股份；转让持有Shein份额的基金LP份额｜资情留言板第116期》</a></p>\n  <p>第117期：<a href=\"https://36kr.com/p/2509054117331203\" rel=\"noopener noreferrer\" target=\"_blank\">《求购OpenAI公司股份；转让持有Animoca Brands股份的专项基金LP份额｜资情留言板第117期》</a></p>\n  <p>第118期：<a href=\"https://36kr.com/p/2519052482979336\" rel=\"noopener noreferrer\" target=\"_blank\">《求购比亚迪半导体公司股份；转让持有Discord股份的专项基金LP份额｜资情留言板第118期》</a></p>\n  <p>第119期：<a href=\"https://mp.weixin.qq.com/s/sV_tqrxzE9KH6DYraA6i_g\" rel=\"noopener noreferrer\" target=\"_blank\">《求购小红书、Space X股份；转让持有Animoca Brands股份的专项基金LP份额｜资情留言板第119期》</a></p>\n  <p>第120期：<a href=\"https://36kr.com/p/2538716575753989\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Shein公司股份；转让某自动驾驶领域头部公司2000万美元老股｜资情留言板第120期》</a></p>\n  <p>第121期：<a href=\"https://36kr.com/p/2548633435740550\" rel=\"noopener noreferrer\" target=\"_blank\">《求购比亚迪半导体股份；转让持有DJI股份、Cohere股份的专项基金LP份额｜资情留言板第121期》</a></p>\n  <p>第122期:<a href=\"https://36kr.com/p/2557976476310916?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Neuralink公司股份；转让某自动驾驶领域头部公司2000万美元老股｜资情留言板第122期<strong>》</strong></a></p>\n  <p>第123期：<a href=\"https://mp.weixin.qq.com/s/8Z_eQX8Q10dvcoD0tpfMHQ\" rel=\"noopener noreferrer\" target=\"_blank\">《求购地平线股份；转让持有Discord股份的专项基金LP份额｜资情留言板第123期》</a></p>\n  <p>第124期：<a href=\"https://36kr.com/p/2578472678630789\" rel=\"noopener noreferrer\" target=\"_blank\">《寻求护肤品、美妆等赛道并购标的；转让光学器件产品研发、制造和销售商公司老股｜资情留言板第124期》</a></p>\n  <p>第125期：<a href=\"https://36kr.com/p/2588256386873984?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">《寻求电子信息赛道并购标的；寻求护肤品、美妆等赛道并购标的｜资情留言板第125期》</a></p>\n  <p>第126期：<a href=\"https://36kr.com/p/2598366766758787\" rel=\"noopener noreferrer\" target=\"_blank\">《寻求文旅赛道并购标的；寻求护肤品、美妆等赛道并购标的｜资情留言板第126期》</a></p>\n  <p>第127期：<a href=\"https://36kr.com/p/2607499254609153\" rel=\"noopener noreferrer\" target=\"_blank\">《寻求办公软件赛道并购标的；寻求电子信息赛道并购标的｜资情留言板第127期》</a></p>\n  <p>第128期：<a href=\"https://36kr.com/p/2617428246714496\" rel=\"noopener noreferrer\" target=\"_blank\">《寻求护肤品、美妆等赛道并购标的；转让合源生物公司老股｜资情留言板第128期》</a></p>\n  <p>第129期：<a href=\"https://36kr.com/p/2626418763152521\" rel=\"noopener noreferrer\" target=\"_blank\">《求购蓝箭航天老股；寻求办公软件赛道并购标的｜资情留言板第129期》</a></p>\n  <p>第130期：<a href=\"https://mp.weixin.qq.com/s/bSZCXb_Nv6wfKk2Y83GhbA\" rel=\"noopener noreferrer\" target=\"_blank\">《转让Space X、Shein股份；寻求文旅赛道并购标的｜资情留言板第130期》</a></p>\n  <p>第131期：<a href=\"https://36kr.com/p/2657609599582465\" rel=\"noopener noreferrer\" target=\"_blank\">《寻求护肤品、美妆赛道并购标的；转让持有Space X股份的专项基金LP份额｜资情留言板第131期》</a></p>\n  <p>第132期:<a href=\"https://36kr.com/p/2677421269890563\" rel=\"noopener noreferrer\" target=\"_blank\">《求购比亚迪半导体股份；转让某头部茶饮连锁企业的专项基金LP份额｜资情留言板第132期》</a></p>\n  <p>第133期<a href=\"https://36kr.com/p/2695914338708872?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">:《求购xAI股份；转让某头部人型机器人老股份额｜资情留言板第133期》</a></p>\n  <p>第134期:《<a href=\"https://36kr.com/p/2717282174056577?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">求购智元机器人股份；寻求新能源上下游赛道并购标的｜资情留言板第134期》</a></p>\n  <p>第135期:<a href=\"https://36kr.com/p/2735576770275842?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">《转让无晶圆厂芯片设计企业专项基金LP份额；求购星动纪元机器人股份｜资情留言板第135期》</a></p>\n  <p>第136期:<a href=\"https://36kr.com/p/2755592122628865?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">《寻求卤味食品、连锁餐饮板块并购标的；寻求精密制造领域板块并购标的｜资情留言板第136期》</a></p>\n  <p>第137期：<a href=\"https://mp.weixin.qq.com/s/G_UpXoJz9mLcos-EegannQ\" rel=\"noopener noreferrer\" target=\"_blank\">《转让喜茶专项基金LP份额；寻求智能传感板块并购标的丨资情留言板第137期》</a></p>\n  <p>第138期：<a href=\"https://36kr.com/p/2796326631059080?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">《<strong>转让智能驾驶头部企业专项基金LP份额；转让某母婴电商企业份额｜资情留言板第138期》</strong></a></p>\n  <p>第139期：<a href=\"https://36kr.com/p/2816376053762568?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">《<strong>寻求智慧城市板块并购标的；求购上海微电子股份｜资情留言板第139期》</strong></a></p>\n  <p>第140期：<a href=\"https://36kr.com/p/2836215354231426\" rel=\"noopener noreferrer\" target=\"_blank\">《寻求汽车领域上下游并购标的；转让伺服电机领域头部企业股份｜资情留言板第140期》</a></p>\n  <p>第141期：<a href=\"https://36kr.com/p/2855894553693064?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">《求购人型机器人领域老股；转让肿瘤免疫治疗药物领域头部企业股份｜资情留言板第141期》</a></p>\n  <p>第142期：<a href=\"https://36kr.com/p/2875878933287305\" rel=\"noopener noreferrer\" target=\"_blank\">《求购小红书股份；转让双特异性抗体药物领域头部企业股份｜资情留言板第142期》</a></p>\n  <p>第143期：<a href=\"https://36kr.com/p/2895397176302468\" rel=\"noopener noreferrer\" target=\"_blank\">《求购阜阳欣奕华材料公司股份；寻求小家电领域上下游并购标的｜资情留言板第143期》</a></p>\n  <p>第144期:<a href=\"https://36kr.com/p/2914682117806723?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">《<strong>寻求直播带货MCN并购标的；寻求医疗器械上下游并购标的｜资情留言板第144期》</strong></a></p>\n  <p>第145期:<a href=\"https://36kr.com/p/2935408242629510?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">《<strong>寻求生物医药上下游并购标的；寻求伺服电机上下游标的｜资情留言板第145期》</strong></a></p>\n  <p>第146期:<a href=\"https://36kr.com/p/2964763593969921?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">《<strong>求购长鑫存储老股；转让创新药领域生成式Ai头部企业专项基金LP份额｜资情留言板第146期》</strong></a></p>\n  <p>第147期：<a href=\"https://mp.weixin.qq.com/s/HsbctABTGdalKnKm4e4vLQ\" rel=\"noopener noreferrer\" target=\"_blank\">《求购Shopee老股；转让头部境内外一体化国家粮油交易平台企业基金LP份额｜资情留言板第147期》</a></p>\n  <p>第148期：《<a href=\"https://36kr.com/p/3004669087752194?channel=copy_url\" rel=\"noopener noreferrer\" target=\"_blank\">求购星动纪元公司股份；求购人形机器人公司股份｜资情留言板第148期</a><strong>》</strong></p>\n  <p>截止目前共计收到九千余封咨询邮件（zcjy@36kr.com），经过我们筛选排查后筛选出上千家有真实交易需求的机构、公司，并帮助其进行对接，目前交易仍在进行中，我们也会持续关注。另外，目前36氪已经与知名基金建立了合作关系。</p>\n  <p>如果你希望通过我们的资情留言板栏目发布求购或者出售资产信息，也欢迎与我们联系（zcjy@36kr.com）</p>", "published": "2024-11-07 05:17:37", "id": "9cecd81a-b7eb-4cb1-bfe0-a7e3e7e9a1f1", "source": "36氪", "section": "综合资讯"}, {"title": "挪威央行按兵不动，挪威克朗兑欧元升至10日高点", "link": "https://36kr.com/newsflashes/3026159695914499?f=rss", "description": "挪威央行如经济学家预期那样按兵不动后，挪威克朗兑欧元维持在10月28日以来的高点附近。欧元/挪威克朗跌0.5%至11.8198。挪威央行表示，经济前景没有发生重大变化。挪威克朗/瑞典克朗涨0.4%至0.9831；稍早一度升至0.9842，为8月16日以来最高水平。（新浪财经）", "published": "2024-11-07 10:19:47", "id": "068ffd47-e106-4283-a6eb-dc3d10f94a90", "source": "36氪", "section": "综合资讯"}, {"title": "祥明智能：股东拟合计减持不超7.7%的公司股份", "link": "https://36kr.com/newsflashes/3026177992959240?f=rss", "description": "36氪获悉，祥明智能公告称，股东杨剑芬、祥光投资、昆山超辉拟合计减持不超7.7%的公司股份。", "published": "2024-11-07 10:38:25", "id": "31b6b97d-88a1-4212-89fe-849938d203e2", "source": "36氪", "section": "综合资讯"}, {"title": "中芯国际：第三季度净利润10.6亿元，同比增长56.4%", "link": "https://36kr.com/newsflashes/3026215207003654?f=rss", "description": "36氪获悉，中芯国际发布三季报，第三季度营收156.09亿元，同比增长32.5%；归属于上市公司股东净利润10.6亿元，同比增长56.4%。", "published": "2024-11-07 11:05:18", "id": "646edb0c-1264-4cca-84a9-98fc1716cc9b", "source": "36氪", "section": "综合资讯"}, {"title": "三花智控：终止境外发行全球存托凭证并在瑞士证券交易所挂牌上市的计划", "link": "https://36kr.com/newsflashes/3026201390212610?f=rss", "description": "36氪获悉，三花智控公告，拟终止境外发行全球存托凭证（GDR）并在瑞士证券交易所（SIX Swiss Exchange）挂牌上市的计划。2024年11月4日，公司与保荐人中信证券向深交所提交了撤回申请文件。近日，公司收到深交所出具的决定，深交所决定终止对公司申请发行GDR境内新增基础股票的审核。", "published": "2024-11-07 11:11:08", "id": "05bab742-a1a0-4760-aadd-cd2cad0416ef", "source": "36氪", "section": "综合资讯"}, {"title": "特朗普获胜引众车厂担忧，宁德时代大举推进全固态电池｜海外日报", "link": "https://36kr.com/p/3026153040782598?f=rss", "description": "<h2><strong>「 Top 3 News 」</strong><br />&nbsp;</h2>\n  <h3><strong>特朗普获胜，汽车制造商担忧，但宝马表示不会有事</strong></h3>\n  <p><strong>要点：</strong></p>\n  <p>随着特朗普再次当选美国总统，市场对其可能带来的政策变化充满担忧，尤其是关税上调和对外国车企的限制。欧洲车企普遍担心特朗普将继续提高进口税，尤其是对电动车的进口关税，这将冲击其在美业务。然而，宝马表示，其在美国拥有大规模生产设施，尤其是位于南卡罗来纳州斯帕坦堡的工厂，使其有信心应对可能的政策变化。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_3570cc84ee694b0abfcd1f78615d5855@6130289_oswg200035oswg684oswg341_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">宝马5系（来源：BMW）</p>\n  <p><strong>观点：</strong></p>\n  <p>宝马第三季度财报显示，由于中国市场销量下滑，公司利润下降了61%，但电动车销量仍保持增长。宝马对特朗普连任的乐观态度展示了其在全球布局方面的优势。凭借在美国的大型工厂，宝马能够在一定程度上规避进口关税的影响，从而保持在美业务的稳定发展。然而，其他依赖出口的欧洲车企或将面临更多挑战。如果特朗普政府继续推行高关税和保护主义政策，尤其是在清洁能源和电动车方面，可能会抑制美国电动车市场的增长。</p>\n  <h3><strong>梅赛德斯-奔驰预告即将推出的 CLA 电动车</strong></h3>\n  <p><strong>要点：</strong></p>\n  <p>奔驰在近日首次揭示了即将推出的CLA电动版，这款新车计划在2025年上市，成为奔驰入门级电动车阵营中的主打车型。CLA电动版借鉴了奔驰未来设计理念，采用EQXX概念车的部分设计元素，其主要特征包括高效电动平台和独特的空气动力学设计，以最大化续航和性能表现。据悉，该车型将搭载模块化平台，支持纯电动和混合动力配置，符合未来电动车需求。同时，CLA电动版将配备全新的MB.OS系统，允许驾驶者通过人工智能辅助的MBUX虚拟助手，享受更加智能化的交互体验。此外，奔驰也将通过CLA电动版进一步实现入门级豪华电动车市场的细分定位，让更广泛的消费者能够体验高端电动技术。CLA电动版的设计和配置展示了奔驰对未来电动出行方式的远见。奔驰计划通过这一入门级电动车吸引年轻消费群体，同时满足环保意识高的用户群需求。新车的续航能力和充电效率将成为关键卖点，而AI智能交互系统则使其更具吸引力。CLA电动版将体现出奔驰在电动车领域的创新，展示未来电动出行的高性能、科技感与豪华感的融合。随着发布日的临近，CLA电动版的市场反应值得期待，这款车或将成为奔驰在入门级电动车市场中的一大成功力作。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_a619febfb5754b9f90e08f2b220b8745@6130289_oswg257693oswg603oswg388_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">CLA电动车（来源：Electriccarsreport）</p>\n  <p><strong>观点：</strong></p>\n  <p>奔驰CLA电动版的推出不仅展现了传统豪华品牌对电动车市场的积极探索，也凸显了其在技术和设计方面的与时俱进。这款车型定位入门级豪华电动车，迎合了年轻消费者对智能化、高性能与豪华体验的多重需求。在设计上，CLA电动版延续了奔驰一贯的优雅和创新风格，同时大幅提升了用户体验。高效的模块化电动平台和新MB.OS操作系统相结合，为用户提供了更高续航、更灵活的充电方式，以及更加智能的交互体验。对于关注环保和智能出行的消费者来说，这无疑是一个令人期待的选择。奔驰选择在入门级市场推出电动版CLA，这一策略表明其不仅关注高端市场，也重视电动车普及化带来的潜在用户。其AI支持的虚拟助手将成为亮点，使车辆更具人性化。而续航能力与性能的提升，将为用户提供更长距离的出行保障，进一步打消消费者对电动车的“里程焦虑”。不过，CLA电动版的最终市场表现还将取决于其价格、实际续航和用户体验的平衡度。奔驰若能实现高性价比，CLA电动版有望成为电动车市场中的标杆，助力品牌在电动化转型中获得新竞争力。</p>\n  <h3><strong>沃尔沃确认其最畅销的 EX30 电动 SUV 将于 2024 年底前登陆美国</strong></h3>\n  <p><strong>要点：</strong></p>\n  <p>沃尔沃近日确认，其最新电动SUV EX30将在2024年年底前登陆美国市场。原计划在2025年交付的EX30因美国市场需求强劲而提前交付，尤其是高性能版EX30 Twin Motor车型备受关注。EX30 Twin Motor版起价为44,900美元，搭载422马力，百公里加速仅需3.4秒，续航为253英里。单电机版EX30价格为34,950美元，续航则可达275英里。这款SUV在充电性能方面也有所提升，支持153kW快充，可在25分钟内将电量从10%充至80%。此前，因美国针对中国制造的电动车征收高额关税，EX30计划推迟至2025年。然而，为满足市场需求，沃尔沃决定加速比利时工厂的生产，以避免进口关税影响。EX30融合了Google内置系统、无线Apple CarPlay等高科技配置，使其成为沃尔沃旗下技术和性价比最高的电动SUV之一。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_770daa0d4b354c4382ad9768c14e3767@6130289_oswg276234oswg693oswg343_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">沃尔沃EX30（来源：Electrek）</p>\n  <p><strong>观点：</strong></p>\n  <p>沃尔沃EX30的提前交付展现了沃尔沃应对市场需求的敏捷性，同时也展示了其在电动汽车领域的全球布局。在美国，特斯拉和其他品牌占据了较大市场份额，沃尔沃此举可能意在借EX30的高性能和性价比优势吸引更多年轻消费者。EX30 Twin Motor的性能参数确实出色，但对于日常通勤者而言，性价比更高、续航更长的单电机版更具吸引力。此外，沃尔沃通过比利时工厂规避关税，为美国市场供货的策略也显示了其灵活应变能力。总的来说，EX30有望在竞争激烈的美国电动SUV市场中脱颖而出，但其成败还将取决于售后服务和充电网络的完善。沃尔沃需继续优化供应链和客户体验，以进一步增强在北美市场的竞争力。</p>\n  <h2><strong>「 大事件 」</strong></h2>\n  <h3><strong>特斯拉 Model S Plaid 成为全球速度最快的警用巡逻车</strong></h3>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_ffb05388d1f7467794de84f85aa3c00a@6130289_oswg396787oswg664oswg329_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">特斯拉Model S Plaid（来源：Electrek）</p>\n  <p>近日，特斯拉Model S Plaid在经过Unplugged Performance的定制后，成为全球速度最快的警用巡逻车。这款改装后的电动车被命名为UP.FIT Plaid Pursuit，将配备于洛杉矶县警察局，服务于警队的社区联络和执法需求。UP.FIT Plaid Pursuit依托Model S Plaid的高性能平台，拥有惊人的0-60英里/小时加速时间，仅需2秒。这款警车在应对高速追击任务中表现突出，同时也为警察部门提供了零排放的环保选择。其设计特别强化了制动系统，并增加了创新的外部照明配置，提升警用车辆在各种追击场景中的实用性和安全性。此外，Unplugged Performance为该车配备了侧裙灯、前后玻璃嵌入式警示灯以及高低频警报器，以符合加州交通法规的要求。据悉，Plaid Pursuit的续航里程可达345英里，成为传统汽油车的理想替代方案，有望帮助节省大量燃油开支，降低维护成本，同时也传递了环保理念。Unplugged Performance CEO Ben Schaffer表示，UP.FIT Plaid Pursuit完美诠释了电动警车在性能、经济性及环保方面的优势，将进一步推动全球电动车在公共服务领域的应用。这款改装车不仅加速表现卓越，还具有较长的续航里程，有助于提升执法效率与公众安全。</p>\n  <h3><strong>Cybertruck 双轮皮卡、起亚越野概念车和电动 Mopars 亮相 SEMA</strong></h3>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_a268cc453e5145d89704b5600c461859@6130289_oswg1089832oswg1080oswg657_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">电动Mopars(来源：YouTube）</p>\n  <p>在2024年的SEMA改装车展上，特斯拉的Cybertruck双后轮越野版成为焦点，展示出其针对越野和拖曳需求的设计。起亚则推出两款全电动概念车EV9 ADVNTR和PV5 WKNDR，以迎合户外探险和家庭出行的需求，标志着未来电动SUV的新潮流。此外，Stellantis公司展示了一款Mopar品牌的电动版经典街车Plymouth，通过电动转换包重新演绎经典车款。多样化的电动改装选择显示了车企在电动化浪潮下的创新尝试，反映出行业对多元电动出行方案的重视。SEMA展览中的这些电动概念车与改装车展示了电动汽车在满足不同用户需求方面的巨大潜力。特斯拉Cybertruck双后轮越野版的推出无疑吸引了大量越野爱好者的关注。特斯拉在这方面继续展现出强大的品牌号召力，而Cybertruck的双轮设计可能会为重型电动卡车带来新方向。</p>\n  <h3><strong>通用汽车再次召回雪佛兰 Bolt</strong></h3>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_53028eb16393442fb480776e8d3b8a30@6130289_oswg347349oswg679oswg331_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">雪佛兰 Bolt（来源：Electrek）</p>\n  <p>近日，美国国家公路交通安全管理局（NHTSA）宣布通用汽车（GM）再次召回部分雪佛兰Bolt EV和EUV电动车，涉及2020至2022年款的107辆汽车。这批车辆曾因火灾风险在此前召回并维修，但新安装的电池诊断软件被发现存在缺陷，未能准确检测电池故障，从而可能导致电池在充电至接近满电时引发火灾。通用表示，尚无因这一问题而导致的火灾报告，召回措施为免费重新安装软件。同时，NHTSA建议车主避免将电池充满，设置目标充电水平为90%，并在充电后将车辆停放在室外。这次召回引发关注，因为通用汽车在2020至2021年因电池问题多次召回Bolt，且在2021年宣布由LG化学负责更换电池模块。据悉，LG化学对电池缺陷负责，为通用承担了19亿美元的召回成本。Bolt车型的召回历程令用户对其安全性有所担忧，影响了消费者对这款车的信心。随着通用逐步退出Bolt生产线并转向新一代Ultium电池平台，Bolt的未来市场定位将迎来调整。不过，通用计划在2025年推出基于Ultium平台的下一代Bolt。</p>\n  <h3><strong>宁德时代推进全固态电动汽车电池</strong></h3>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_8b0d0f2e28f84b2ca3eadcdeb66e0a9f@6130289_oswg336328oswg675oswg334_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">宁德时代展台（来源：Electrek）</p>\n  <p>全球最大的电动汽车（EV）电池制造商宁德时代（CATL）正在推进一种新型电池的研发，这种电池承诺具有更高的能量密度。据报道，CATL正在大力投资并扩大其员工队伍，以将全固态电动汽车电池推向市场。试验生产已经启动，我们可能会比预期更早看到CATL推出全固态EV电池。CATL已经进入20 Ah样本的试验生产阶段，并且今年为其研发团队增加了超过1000名员工。该公司目前专注于最终的硫化物阶段，并已开始20 Ah样本的试验生产。CATL的解决方案在锂三元电池中的能量密度高达500 Wh/kg，比现有电池高出40%。然而，报告指出充电速度和循环寿命尚未达到理想状态。在20 Ah时，电池解决方案已经最终确定，并准备进入下一阶段，即生产技术探索。</p>\n  <h2><strong>「 酷产品 」</strong></h2>\n  <h3><strong>AC Ace Classic跑车</strong></h3>\n  <p>在2024年拉斯维加斯的SEMA车展上，AC汽车公司推出了全新的电动版AC Ace Classic跑车。这款车延续了1950年代经典车型的设计风格，并搭载了由TREMEC提供的300马力（225千瓦）电动动力系统。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_eb42e358a52943a5b1e254bc7d176355@6130289_oswg303793oswg620oswg352_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">AC Ace Classic 电动车（来源：Electriccarsreport)</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_a5a98a3255c449f2ba2f32dcec7e6dc5@6130289_oswg149911oswg607oswg313_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">AC Ace Classic 电动车（来源：Electriccarsreport)</p>\n  <p>其碳纤维车身不仅轻盈且坚固，同时0-100公里加速仅需4.9秒，续航里程可达200英里（约322公里）。这款车体现了英美合作下的创新设计精神，车身支持多种颜色选择并配有高级内饰，售价从27.5万美元（约21.2万英镑）起，预计2025年开始交付。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_f34600ee016d4a67a09e75a0f93956be@6130289_oswg202282oswg530oswg356_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">AC Ace Classic 电动车（来源：Electriccarsreport)</p>", "published": "2024-11-07 10:11:34", "id": "e5864654-9e7d-4f81-bdb6-2b702c834da1", "source": "36氪", "section": "综合资讯"}, {"title": "最前线｜加拿大政府又下禁令，狂奔的TikTok再蒙阴影", "link": "https://36kr.com/p/3026207441790211?f=rss", "description": "<p>文｜兰杰</p>\n  <p>编辑｜乔芊</p>\n  <p>TikTok面临的危机还在加剧。</p>\n  <p>当地时间11月6日，加拿大政府发布公告表示，已下令终止TikTok&nbsp;Technology Canada, Inc.在加拿大的业务。</p>\n  <p>具体来讲，TikTok位于加拿大的办公室将被解散，但加拿大用户仍可以访问TikTok，并在平台上进行内容创作。</p>\n  <p>加拿大创新、科学和工业部部长François-Philippe Champagne在公告中表示，政府是依据《加拿大投资法》（Investment Canada Act）做出这一决策的。该法案允许政府对有可能损害加拿大国家安全的外国投资进行审查。François-Philippe Champagne补充表示，“虽然加拿大欢迎外国投资，但当投资威胁到我们的国家安全时，政府将果断采取行动。”</p>\n  <p>对此，TikTok加拿大发言人丹妮尔·摩根（Danielle Morgan）回应称，“关闭TikTok加拿大办公室将毁掉数百个当地高薪工作岗位，不符合任何人的最佳利益，公司将在法庭上挑战这一命令。TikTok平台仍将帮助创作者寻找观众、探索新商机，并帮助企业茁壮成长。”</p>\n  <p>这并不是TikTok在加拿大的第一次遇挫。</p>\n  <p>早在2023年2月，加拿大政府已经禁止所有政府设备使用TikTok，并于同年晚些时候下令对该应用程序进行国家安全审查，如今再出禁令，也可以说是靴子落地。</p>\n  <p>为了应对相关危机，TikTok也在加速海外本土化进程。今年1月18日，据接近字节跳动的人士透露，公司正在加拿大、澳大利亚等地筹建研发中心，未来将支持TikTok、CapCut、Lemon8等多个海外业务研发。但这些没能改变欧美地区对于TikTok的封禁决策。</p>\n  <p>即便国际形势日益严峻，TikTok还是逐步成为字节跳动新的收入增长引擎。据The Information于当地时间11月4日报道，字节跳动2024年上半年的国际收入（以TikTok为主）增长超60%，达到约170亿美元（约合人民币1209.15亿元）——在禁令的阴影下，TikTok的商业化发展仍很强劲。</p>\n  <p>此外，加拿大并非TikTok的主要市场。据第三方数据机构Statista，截至2024年4月，TikTok在全球有15.6亿月活跃用户，其中美国用户数量最多，约1.5亿人。</p>\n  <p>那么，TikTok在最主要市场上的命运如何？</p>\n  <p>同样是当地时间11月6日，特朗普在佛罗里达州棕榈滩会议中心发表讲话，宣布在2024年美国总统选举中获胜。特朗普此次胜选，与TikTok的命运息息相关。</p>\n  <p>早在今年4月，众议院和参议院接连通过了TikTok的“不卖就禁”法案，并由当时的美国总统拜登签署生效。法案生效后，留给TikTok的时间还有一年——包括最新版法案规定的270天的剥离时间，以及美国总统确认TikTok出售进展后还可以进一步延长的90天。</p>\n  <p>如今这一期限已经过去了半数，期间关键性的变量就是美国新一任总统的决策。而在竞选期间，特朗普曾于当地时间7月16日向外媒《彭博商业周刊》表示，反对拜登政府签署的TikTok“不卖就禁”法案，并声称会支持这家短视频平台公司。</p>\n  <p>但早在2020年，彼时执政的特朗普也曾以国家安全为借口，试图封禁TikTok，因此这位新任美国总统是否会兑现承诺仍需观望。如今加拿大对TikTok的封禁政策再进一步，无疑是一种糟糕的信号。</p>", "published": "2024-11-07 11:20:21", "id": "91694bf2-822b-4dab-b2e3-2ddc7a6fac3a", "source": "36氪", "section": "综合资讯"}, {"title": "李迅雷：非常期待接下来的财政政策，中央财政仍有很大的加杠杆空间", "link": "https://36kr.com/newsflashes/3026175623521801?f=rss", "description": "在天弘基金20周年策略会上，中国首席经济学家论坛理事长李迅雷表示，非常期待接下来的财政政策。“方方面面的政策力度还会进一步加大，尤其是在昨天美国大选结果出来之后。”他认为，中国后续会进一步扩大内需、扩大消费，这是一个新的变量。（澎湃）", "published": "2024-11-07 10:25:02", "id": "cdc159fc-033b-4d99-a36e-d2194dd8cbbc", "source": "36氪", "section": "综合资讯"}, {"title": "中国债券纳入彭博指数四周年，权重升至9.7%成第三大计价货币债券", "link": "https://36kr.com/newsflashes/3026190065821185?f=rss", "description": "彭博公布的最新数据显示，截至2024年11月初，彭博全球综合指数中包含325只中国债券，在该指数68万亿美元的市值中的权重达到9.7%，较四年前增长3.7个百分点。同时，人民币计价的中国债券成为全球综合指数中的第三大计价货币债券，仅次于美元（45.4%）和欧元（22.3%），略领先于日元（9.6%）。 （证券时报）", "published": "2024-11-07 10:39:43", "id": "bd77068b-8e2c-4c2b-8f03-8068c7e61df5", "source": "36氪", "section": "综合资讯"}, {"title": "6连板浩欧博：市盈率显著高于行业市盈率水平", "link": "https://36kr.com/newsflashes/3026200836842753?f=rss", "description": "36氪获悉，浩欧博发布股票交易异常波动暨严重异常波动公告，根据中证指数有限公司发布的公司最新市盈率为127.50倍，最新滚动市盈率为171.15倍，公司所处的医药制造业最近一个月平均滚动市盈率为27.03倍。公司市盈率显著高于行业市盈率水平。", "published": "2024-11-07 11:05:36", "id": "be00da64-1954-4214-921b-ec9e6ef02340", "source": "36氪", "section": "综合资讯"}, {"title": "欧元区9月零售销售环比增长0.5%", "link": "https://36kr.com/newsflashes/3026172655232265?f=rss", "description": "欧元区9月零售销售环比增长0.5%，同比增长2.9%。（界面）", "published": "2024-11-07 10:29:52", "id": "a07fdb8b-1a38-4c8c-a3a6-29bb6019b046", "source": "36氪", "section": "综合资讯"}, {"title": "氪星晚报 ｜哪吒汽车否认裁员规模高达70%；字节跳动AI助手豆包开启视频生成内测报告：全国职业主播超1500万人，2025年直播人才缺口将超1900万", "link": "https://36kr.com/p/3026111429977606?f=rss", "description": "<h2>大公司：</h2>\n  <p><strong>JOOCYEE酵色首家线下门店于长沙开业</strong></p>\n  <p>36氪获悉，JOOCYEE酵色首家线下门店于11月3日在长沙核心商圈国金街开业。未来，酵色将继续加大线下渠道的拓展力度。</p>\n  <p><strong>天猫在宁波成立电子商务新公司</strong></p>\n  <p>36氪获悉，爱企查App显示，近日，宁波喵电电子商务有限公司成立，法定代表人为张倩，注册资本100万元人民币，经营范围包括互联网销售、通信设备销售、二手日用百货销售、日用百货销售、新能源汽车整车销售、电池零配件销售、充电桩销售、新能源汽车电附件销售等。股东信息显示，该公司由浙江天猫技术有限公司全资持股。</p>\n  <p><strong>哪吒汽车否认裁员规模高达70%</strong><br />针对哪吒汽车启动大规模裁员，比例或将高达70%的传闻，哪吒汽车向36氪予以否认。官方回应表示，公司正在通过精简业务、聚焦核心、组织优化和薪酬绩效改革等措施，构建更集中高效的组织架构。分部门按业务要求和未来发展需要进行整合。推动资源的集约化投入，进一步提升企业的竞争力和运营效率。</p>\n  <p><strong>比亚迪申请注册来杯迪小饮商标</strong><br />36氪获悉，爱企查App显示，近日，比亚迪股份有限公司申请注册“吾迪小饮”“来杯迪小饮”商标，国际分类为餐饮住宿，当前商标状态均为等待实质审查。比亚迪股份有限公司成立于1995年2月，法定代表人、董事长、执行董事、总裁为王传福，注册资本约29.11亿元人民币，由HKSCC NOMINEES LIMITED、王传福、吕向阳、融捷投资控股集团有限公司等共同持股。</p>\n  <p><strong>奇瑞集团10月出口突破11万，本月将首次突破年出口100万辆</strong></p>\n  <p>36氪获悉，据奇瑞控股官微，奇瑞控股集团10月出口汽车111922辆，同比增长18.8%，创造历史新纪录。1-10月份累计出口销量941275辆，同比增长23.8%，预计本月将迎来年内出口突破百万辆的新里程碑。目前，奇瑞集团累计全球汽车用户超过1510万，其中海外用户超过420万。</p>\n  <p><strong>宁德时代获UL Solutions授权第一方UL9540A认可目击实验室</strong></p>\n  <p>36氪获悉，据宁德时代官微，近日，宁德时代储能技术研发验证中心启用暨UL9540A实验室授牌仪式在宁德正式举行，该实验室成为全球首个获得UL Solutions授权的第一方“UL9540A认可目击实验室（WTDP）（Module、Unit）”。储能技术研发验证中心安全实验室具备大型储能产品热失控火灾蔓延评估验证等测试能力，是对集装箱及以下层级样品的UL9450A、储能国标GB/T36276等标准的热失控测试及各项安全滥用测试能力的补充，进一步升级完善了宁德时代的测试验证体系，可极大缩短储能产品出口欧美等地区的UL9540A认证周期。</p>\n  <h2>投融资：</h2>\n  <p><strong>AI搜索创企Perplexity据悉将融资5亿美元，公司估值有望达90亿美元</strong></p>\n  <p>据路透11月5日消息，知情人士称，人工智能搜索初创公司Perplexity将在新一轮融资中筹集5亿美元，使该公司估值达到90亿美元。拥有Perplexity董事会席位的风投公司Institutional Venture Partners将领投这轮融资。（界面）</p>\n  <p><strong>斯达领动完成数千万元Pre-A轮融资</strong></p>\n  <p>近日，上海斯达领动完成了数千万元Pre-A轮融资。本轮融资由共进股份、乾德电子和汽车领域专家个人投资，资金将主要用于新产品的研发和新业务的拓展。 斯达领动成立于2023年，致力于毫米波雷达产品的开发及规模化应用，主要产品包括单芯片4D毫米波雷达。（斯达领动）</p>\n  <h2>新产品：</h2>\n  <p><strong>字节跳动AI助手豆包开启视频生成内测</strong></p>\n  <p>字节跳动旗下大模型AI助手豆包正式推出视频生成内测，意味着继快手、商汤、Minimax等公司后，字节跳动正式杀入AI视频生成领域。豆包官网称，豆包视频生成，支持图片文字一键成片，“能将信息转化为生动逼真的视频内容。 支持酷炫的动态和运镜，多镜头保持一致，风格比例随意挑选。”（财联社）今日观点：</p>\n  <p><strong>宁德时代董事长曾毓群：储能行业不能乱，但也绝不能慢</strong></p>\n  <p>11月7日，“2024世界储能大会”在宁德召开，开幕式上，宁德时代董事长曾毓群发表了演讲。“作为新能源转型的关键基础设施，储能行业不能乱，但能源转型需求也要求我们绝不能慢，行业必须在快速增长中同步实现高质量发展。”曾毓群说，如何实现高质量发展，行业需要做到高可靠性、高价值性和全场景。（每日经济新闻）</p>\n  <h2>其他值得关注的新闻：</h2>\n  <p><strong>报告：全国职业主播超1500万人，2025年直播人才缺口将超1900万</strong></p>\n  <p>36氪获悉，中国演出行业协会网络表演（直播）分会联合快手平台发布《网络主播新职业发展报告》。《报告》显示，截至2023年12月，有1508万人把网络主播当成主业，预计到2025年我国直播行业的人才缺口将达到1941.5万人。调研显示，六成以上职业网络主播每周直播四天以上，八成以上职业网络主播平均月收入在8000元以下，近九成职业网络主播愿意长期从事网络主播这一职业。网络主播呈现出职业化、多元化、专业化的发展趋势。</p>\n  <p><strong>机构：2028年中国数字化转型总体市场规模将超7300亿美元</strong></p>\n  <p>36氪获悉，国际数据公司（IDC）近日发布了2024年V2版本《全球数字化转型支出指南》。IDC最新数据显示，2023年全球数字化转型投资规模超过2.1万亿美元，2028年预计达到4.4万亿美元，2023-2028年五年复合增长率（CAGR）为15.4%。随着全球数字化转型市场蓬勃发展，云计算、人工智能、大数据、5G等技术的应用范围不断扩大，全球企业的数字化转型已经来到了持续发展阶段，这也促使了企业不断加大其在数字化转型的投入。</p>", "published": "2024-11-07 11:07:50", "id": "8c5727a0-826b-4026-bff8-db0aeab88d10", "source": "36氪", "section": "综合资讯"}, {"title": "机构今日抛售同花顺等20股，买入中国软件8.34亿元", "link": "https://36kr.com/newsflashes/3026159814321668?f=rss", "description": "盘后数据显示，11月7日龙虎榜中，共44只个股出现了机构的身影，24只股票呈现机构净买入，20只股票呈现机构净卖出。当天机构净买入前三的股票分别是中国软件、金杯汽车、厦钨新能，净买入金额分别是8.34亿元、4.48亿元、1.81亿元。当天机构净卖出前三的股票分别是同花顺、中国长城、泸州老窖，净流出金额分别是6.41亿元、1.47亿元、1.15亿元。（第一财经）", "published": "2024-11-07 10:25:54", "id": "0e309fa2-6f52-41a8-9b7e-cfc1e00efc07", "source": "36氪", "section": "综合资讯"}, {"title": "中国软件：除2024年度向特定对象发行A股股票外，未筹划重大事项", "link": "https://36kr.com/newsflashes/3026181680735488?f=rss", "description": "36氪获悉，中国软件公告，公司股票交易连续3个交易日内日收盘价格涨幅偏离值累计达25.32%，已构成股票交易异常波动。公司日常经营情况及外部环境未发生重大变化，不存在应披露而未披露的重大事项。截至2024年11月7日，公司股票静态市盈率为-218.18倍、市净率23.38倍。截至2024年11月7日，除公司2024年度向特定对象中国电子、中电金投发行A股股票，募集资金用于子公司麒麟软件有限公司实施研发项目事项外，公司、控股股东及实际控制人未筹划涉及上市公司的重大资产重组、股份发行、重大交易类事项、业务重组、股份回购、股权激励、破产重整、重大业务合作、引进战略投资者等重大事项。", "published": "2024-11-07 10:43:09", "id": "f0eeb34b-280b-4e44-978a-470b1d2aaefd", "source": "36氪", "section": "综合资讯"}, {"title": "广汽AION RT：没MONA M03便宜，想卖的一样好", "link": "https://36kr.com/p/3024979125462528?f=rss", "description": "<p>文｜韩永昌&nbsp;</p>\n  <p>编辑｜张博文</p>\n  <p>11.98万元，与小鹏MONA M03低配版同价，埃安RT在价格上没有太大惊喜。</p>\n  <p>这款“大眼小帕梅”，宣传图上十分惊艳，现场实车略显平庸，更像是比亚迪海豹的翻版，跟帕梅仍有不小差距，也没有MONA 03发布时给人震撼。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241106/v2_181f11393f2e4728b7d3070ea98c1c58@15545321_oswg738672oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">埃安RT宣传图</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241106/v2_3f57eeac556b408da88ee8303b021b2b@15545321_oswg822410oswg1080oswg791_img_000?x-oss-process=image/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">RT发布会实车图</p>\n  <p>埃安给RT的定位是：新颜智驾轿车。顾名思义，颜值抗打，智驾出众。这几乎是贴着小鹏MONA M03做对标。但在颜值上，RT就已经略输一筹。</p>\n  <p>智驾能力上，RT的表现不错。搭载激光雷达的车型版本，支持无图城市NDA。在发布会的展示上，无论是城中村道路、乡村道路、石墩窄路等，RT都能一把通过。</p>\n  <p>发布会还介绍说，RT的自动泊车支持超过300种常见+极端车位，泊入成功率高达99%。</p>\n  <p>广汽埃安副总经理肖勇甚至喊出了，埃安RT的高阶智驾，是最懂中国路的高阶智驾，埃安智驾已经进入中国第一梯队。他也承诺，高阶智驾上市即交付。</p>\n  <p>埃安搭载高阶智驾的两个版本，售价分别为15.58万元和16.58万元。而小鹏 MONA M03 的顶配版，同样支持城区领航，售价同样是15.58万元。</p>\n  <p>RT还给出了现金权益是，99元意向金抵3000元购车款，但仅限发布会当晚24点前，只有3小时便结束。</p>\n  <p>“为全球年轻人提供人生第一次高阶智驾体验”，是RT的宣传口号。但这一点小鹏 MONA M03 似乎已经做到。</p>\n  <p>RT与M03在智驾上的区别是，后者走纯视觉路线，靠自研，而前者则搭载了激光雷达，与供应商合作开发。</p>\n  <p>M03搭载了21个智能硬件，埃安RT则有27个，包括英伟达Orin-X。用成本更高的传感器，可能是RT价格难以降到更低的原因。</p>\n  <p>更高的成本，与MONA M03同价，埃安确实给出了诚意。</p>\n  <p>但作为一款纯电车型，在厮杀最激烈的A级轿车市场，埃安RT与MONA M03同价竞争，还能再造一个销量奇迹吗？</p>\n  <p><strong>「&nbsp;新车有卖点，但纯电车市场空间有限&nbsp;」</strong></p>\n  <p>发布会一开始，肖勇就宣布，埃安RT已经斩获了30000台预售订单。</p>\n  <p>在预售价定为11.98万元时，市场似乎认定了这款车的起售价要比MONA M03更便宜。但实际上预售价与售价一样。</p>\n  <p>如今，MONA M03的订单量已在冲击10万，埃安RT这款对标车型，在上市后是否还能保证订单量，还需要时间检验。</p>\n  <p>埃安RT有520km与650km两个续航版本，依旧搭载广汽弹匣电池，最大电量65度。与高阶智驾相搭配，共有五个配置可供选择。</p>\n  <p>RT的520激光雷达版与MONA M03的580超长续航MAX版同价，都是15.58万元，两款车型都有高阶智驾。</p>\n  <p>RT还多推出了一个650激光雷达版本，续航增加130km，贵1万，16.58万元。</p>\n  <p>在补能上，埃安RT基于碳化硅技术打造了400V平台，可以做到3C快充，10分钟补能可达200km。这样的补能速度在当下完全够用，也是MONA M03未做到的水平。</p>\n  <p>虽然没能做到比MONA M03价格更低，但埃安RT也拿出了诚意。这款车是埃安“全村的希望”，甚至是“最后的希望”。</p>\n  <p>消费者购车的主要因素就三个，外观，价格、品牌。这款A级纯电轿车，颜值过关，价位够低。最大的短板，在品牌上。</p>\n  <p>埃安的问题几乎所有人都清楚：TO B战略过于成功，以至于成为了一个网约车品牌。RT虽然设计前卫，但也很难突破这个刻板印象。</p>\n  <p>埃安做出过努力，昊铂的出现就是为了改变窘境，不管是鸥翼门，还是超跑，几乎所有能吸引眼球，拔高品牌调性的设计，在昊铂身上都有体现。但还是成效甚微。今年10月，昊铂品牌的销量只有2805辆，这还是四连涨之后的数据。</p>\n  <p>埃安RT是一款有诚意的车，但想要做到更高销量，并不容易。尤其是在纯电车销售增速放缓的情况下。</p>\n  <p>A级纯电轿车市场，除了MONA MO3以外，基本没人能创造奇迹。小鹏大概率也未预料到MONA 03如此火爆，以至于出现了爆单后延迟交付的“幸福的烦恼”。</p>\n  <p>以RT与MO3的价格区间来看，同级别的车型厮杀过于激烈，秦L DM，海豹06 DM-i都是月销超过4万台的选手，单车型销量比埃安和昊铂加起来还多。</p>\n  <p>而经典油车，如轩逸、朗逸、速腾等经久不衰的车型，在新能源渗透率不高，充电基础设施并不完善的北方广大地区，仍有市场，单月销量依然维持2-3万左右，且价格更为便宜。</p>\n  <p>A级轿车从来都是厮杀最激烈的市场区间，每一个选手都极具竞争力，并有自己固定的消费群体，纯电车型想要突围太难。</p>\n  <p>但埃安RT的出现，能看出广汽埃安已经迈出了改变品牌形象的关键一步。埃安，乃至于广汽，也亟需一款新车来扭转局面。</p>\n  <h3><strong>「&nbsp;埃安需要“爆款”，广汽更需要&nbsp;」</strong></h3>\n  <p>2023年3月埃安销量首次超过4万辆，且其当月销量超“蔚小理”交付量总和。按照广汽埃安官方说法，“埃安由此迈入规模效应新阶段”。</p>\n  <p>但一直到刚刚结束的10月份，埃安全球销量仍然在4万辆，19个月后，埃安销量又回到了原点。</p>\n  <p>销量没能保持稳定增长，因为车型更新换代太慢。</p>\n  <p>广汽埃安总经理古惠南在年初接受媒体采访时提到，为了支持昊铂发展，埃安已经有两年没有发布新车，去年的新车基本都给了昊铂，到今年上半年埃安都没有新车发布。</p>\n  <p>过去两年，埃安一直在为昊铂让位，打造高端品牌。但结果显而易见，去年全年，昊铂品牌累计销量只有8087辆。</p>\n  <p>没有新车的埃安，只能靠B端市场的AION S和AION Y撑起销量数据。</p>\n  <p>今年埃安品牌唯一的看点是，下半年上市的新车AION V霸王龙在10月份销量近万，这也预示着埃安的车型换代终于开始。</p>\n  <p>埃安需要一个爆款，来提振销量和信心，毕竟在当下车市价格战持续的情况下，纯电车的价格不断下移，原本属于埃安车型的市场空间，正在被老对手比亚迪，以及新对手吉利银河、小鹏MONA等不断挤压，销量不振也是无奈。</p>\n  <p>如果放大到广汽集团，一个爆款车型，则更加重要。</p>\n  <p>数据显示，广汽集团第三季度营收282.33亿元，同比下降21.73%；净利润亏损13.96亿元，同比下降190.40%。</p>\n  <p>放大到前三季度，更为惨烈。广汽集团前三季度营收740.4亿元，同比下降24.18%；归母净利润只有1.2亿元，同比下降97.34%，创下了上市 14 年来最差的财务表现。</p>\n  <p>销量层面上，广汽集团今年已连续9个月出现销量同比下滑的情况。今年1-9月，广汽集团累计销量为133.51万辆，同比下降25.59%。</p>\n  <p>分品牌来看，目前广汽集团超六成的销量，都是来自于旗下的广汽丰田和广汽本田。不过，两大合资品牌，今年前九个月都经历了超过20%的销量同比下滑。</p>\n  <p>国内车市价格战已如烈火烹油，广汽丰田、本田等合资车企首当其冲，单车价格不断下调，这是广汽集团业绩如此难看的主要原因。</p>\n  <p>曾经广汽集团用合资两田的利润为埃安输血，传祺自负盈亏，短短数年便打造出了埃安月销4万的奇迹。到了如今，这样的手段已经失灵。</p>\n  <p>价格战下，合资车企愈发艰难。比亚迪董事长兼总裁王传福甚至预言，未来3-5年，合资品牌份额将从40%降到10%。</p>\n  <p>比亚迪出牌，自主品牌势必跟进，中国市场的内卷仍未结束，甚至还有进一步升级的可能。</p>\n  <p>曾经依靠合资品牌的广汽，需要新的增长极，来支撑集团在新能源时代存活下去。埃安显然要扛起这一任务，成为广汽的中流砥柱。</p>\n  <p>如今，RT上市，满配低价，诚意十足，埃安已经在竭尽全力。当然，如果这款车出师未捷，也会让埃安，乃至广汽陷入更加痛苦的深渊。</p>", "published": "2024-11-07 00:00:00", "id": "3f4e3f60-0649-4c98-ad6e-ee349e49cad6", "source": "36氪", "section": "综合资讯"}, {"title": "圣农发展：10月销售收入15.83亿元 同比增长7.51%", "link": "https://36kr.com/newsflashes/3026198857721344?f=rss", "description": "36氪获悉，圣农发展公告，10月实现销售收入15.83亿元，较去年同期增长7.51%，较上月环比下降2.3%。销量方面，10月份家禽饲养加工板块鸡肉销量为12.62万吨，同比增长5.4%，环比增长0.35%；深加工肉制品板块产品销量为3.08万吨，同比增长17.05%，环比下降8.62%。10月，公司创下过去10个月的单月最佳盈利水平，同时较去年10月增长超400%，1—10月累计盈利同比降幅收窄。在降本增效的积极推动下，公司综合造肉成本稳步下降，产量和销量稳步增长。", "published": "2024-11-07 10:54:37", "id": "553831bb-fe01-48c9-b4ce-0660731ad12c", "source": "36氪", "section": "综合资讯"}, {"title": "在香港，出海企业找到了新「钱途」？｜氪金·出海", "link": "https://36kr.com/p/3025644074329603?f=rss", "description": "<p>作者&nbsp;|&nbsp;王晗玉</p>\n  <p>编辑&nbsp;|&nbsp;黄绎达</p>\n  <p>出海大潮中，中小企业融资难、融资贵的问题似乎正出现最新解。</p>\n  <p>今年8月，蚂蚁数科与朗新集团合作发行一单跨境RWA（实物资产通证化），证明了实物资产以数字形式在区块链上发行、融资的可行性。</p>\n  <p>不久前举办的香港金融科技周上，与会各方对Web3、RWA等话题的热议，又凸显了这一融资新途径未来将大规模为出海企业所用的可能性。</p>\n  <p>业内人士认为，RWA是Web3与实体产业融合的基石。而透过香港监管层近年对RWA所持的开放态度和创新实践，可以预见一众奋力出海的内地企业有望率先在香港打开融资新通道。</p>\n  <h3><strong>01 香港：企业出海第一站</strong></h3>\n  <p>现下，东南亚、南美、中东、非洲等地区均是国内企业出海的热门选择。而作为国内企业走出本土市场的过渡地和中间站，香港有其得天独厚的现实条件。</p>\n  <p>首先，香港与内地共享同样的语言文化，同时又与国际市场接轨，有助于内地企业更好地理解和适应国际商业规则，从而促进海外业务的发展。</p>\n  <p>其次，香港国际金融中心和贸易中心的定位令其在商业法规、国际贸易等方面优势成熟，一向是国内外企业设立管理离岸贸易和区域总部的优先选择地。</p>\n  <p>尽管向外看去，新加坡与香港定位类似，马来西亚也与中国内地也有相似的语言文化背景，但从地理位置和金融体量上看，更适合内地企业“打前站”的仍是香港。</p>\n  <p>在区位上，<strong>香港离内地更近，有多项互联互通政策。</strong>如今年4月，证监会发布5项资本市场对港合作措施，包括放宽沪深港通ETF合格范围、REITs纳入沪深港通、支持内地企业赴港上市等。</p>\n  <p>并且，<strong>香港面向内地的人才政策更为灵活。</strong>如通过香港优才计划、高才通计划等方式取得香港居民身份的内地居民，不影响其内地社保缴纳，有条件者可申请回内地定居等。数据显示，2023年香港共收到约20万宗定居申请，超过12万宗获批，已有约7万人抵港。</p>\n  <p>而在金融体量上，香港的区位优势相比新加坡、马来西亚更加直观。</p>\n  <p>以股市为例，Wind数据显示，截至今年9月底新加坡交易所总市值约6659.5亿美元；马来西亚吉隆坡交易所总市值约2.04万亿林吉特，约合4638.4亿美元；相比之下，香港联合交易所同期总市值约36.88万亿港元，约合47420.1亿美元。</p>\n  <p>香港股市这一规模得益于背靠中国大陆。Wind数据显示当前港股市场共有1224只中资股，在港股全部上市公司中占比超过46%。</p>\n  <p>此前一段时间内地企业赴港IPO数量虽有回落，但自多项互联互通政策发布后，趋势有所好转。投中研究院报告显示，今年第三季度共有13家内地企业在港IPO，募资金额共计327亿元，同比上涨4.45倍，环比上涨3.36倍。</p>\n  <p>这显示，<strong>香港仍是中国内地企业首选的国际投融资平台。</strong></p>\n  <p>与此同时，在《行政长官2024年施政报告》中，香港特别行政区行政长官李家超曾提到，截至今年7月，香港特区政府已与超过100家有潜力和具代表性的重点创科企业洽谈好在港落户或扩展业务，为香港带来共计超过520亿港元的投资额，创造超过15200个就业机会。</p>\n  <p>内地企业纷纷赴港，这一过程中，<strong>金融科技企业作为底座上的一环，也正扮演“加速器”的角色。</strong></p>\n  <p>如本届香港金融科技周上，蚂蚁数科已宣布未来3年将投入10亿元，推进粤港澳数字技术联合创新，助力本地客户、生态伙伴加速数字化转型。而在该活动展区，也常见蚂蚁数科、度小满、腾讯等企业方的演讲或金融科技业务展台。</p>\n  <p>这或表明，在出海大潮中，金融科技企业正形成一股推动力，利用自身在内地市场磨练的技术能力，推动企业实现数字化转型，提升出海效率。</p>\n  <p>另外，在此次金融科技周上，有超半数主题活动涉及Web3、RWA。这一现象也预示着RWA有望成为企业跨境融资的新渠道。</p>\n  <h3><strong>02 Web 3：跨境融资新拐点</strong></h3>\n  <p>金融科技周期间，蚂蚁数科旗下蚂蚁链首次公开“两链一桥”平台是其中一大公司动态。这一动态背后，则是多数企业在出海进程中面对大数据爆发等新形势露出了新痛点。</p>\n  <p>回看to B企业的出海征程，大致可分为三个阶段。</p>\n  <p>2000年初，华为、中兴通讯等通信技术公司凭借在ICT领域的影响力，将通信设备出口到海外市场，参与多国电信基础设施建设，为当地数字化发展奠定了基础。</p>\n  <p>其后，传统企业开启数字化转型，致力于通过云计算等技术手段提升IT效率。自2015年起，阿里云、腾讯云等云计算厂商开始随着这些企业全球化的步伐，顺势打开自己的海外市场。</p>\n  <p>来到当下，大数据爆发，产业链上下游协同愈发紧密，提升数字化协作效率成为关键需求；当数据成为核心资产，建立高效、透明、安全的交易流程又成为新的命题。</p>\n  <p>而也是在这个阶段，区块链等Web 3新技术恰好迎来发展红利。</p>\n  <p>以出海企业境外融资为例，传统的融资方式多依赖企业主体信用，能获得当地银行等机构资金支持的企业少之又少。而借助区块链，RWA可把实物资产拆分为多份“链上”数字资产，方便投资者评估资产信用、企业实现异地融资，再借助全球区块链网络的互通性，为实物资产带来更多流动性。</p>\n  <p>如蚂蚁数科与朗新集团合作发行的跨境RWA，即是以朗新在内地运营的实物资产“充电桩”作为RWA锚定资产，通过“两链一桥”平台在香港完成了约1亿元的融资。</p>\n  <p>“两链一桥”具体指“资产链”、“交易链”及“蚂蚁链可信跨链桥”。</p>\n  <p>36氪从蚂蚁数科Web3业务产品负责人张晨光处了解到，“资产链”在内地的应用，使得企业的实体资产能够被数字化和标准化，从而转化为可交易的金融产品。“交易链”则侧重于将资金通证化，特别是来自传统金融机构的资金，通过区块链技术实现资金的高效流转和交易。</p>\n  <p>实物资产“上链”，<strong>区块链技术为资产的安全性、透明性和不可篡改性，以及提升流动性提供了保障。</strong>同时作为一项金融创新，这或也为企业，尤其是企业在境外提高融资效率、降低融资成本打开了新思路。</p>\n  <h3><strong>03 本地化：金融创新的挑战</strong></h3>\n  <p>在借助区块链等技术帮助出海企业解决融资等层面的难题时，提出此类创新的金融科技企业亦有自己的挑战。</p>\n  <p>如当下较为火热的RWA，据蚂蚁数科介绍，其与朗新集团合作完成的该单1亿元融资是国内首单基于新能源实体资产的RWA。这意味着，相关探索还处于早期，伴随进一步发展，或将有新问题显露出来。</p>\n  <p>业内首要担忧的是合规问题。</p>\n  <p>尽管香港一地对虚拟资产交易持积极态度，并出台相关规则加以引导，如去年6月香港证监会正式实施新的虚拟资产交易平台监管规定，今年8月香港金管局又推出名为“Ensemble”的沙盒计划，旨在利用实验型代币化货币促进银行同业结算。</p>\n  <p>但放眼全球市场，多数地区对RWA的监管规则尚不明晰，是否合规也并不明确，这仍为国内企业未来能否在海外市场复制这一融资方式增添了不确定性。不过另一方面，国内企业在这一方向的前期探索或也可成为其参与制定相关行业标准的优势。</p>\n  <p>此外，跳出RWA的视角，国内企业在走向香港，乃至由香港走��更分散的国际市场时，诸多本地化适应所需的基础设施，仍在建设当中。<strong>尤其对于开发金融级应用的科技企业而言，其面对的局面更加复杂。</strong></p>\n  <p>在被问及前往更广阔的国际市场有何难点时，蚂蚁数科副总裁、中国区业务发展部总经理孙磊特别提到三点。一是如何就基础性事项做好本地化适应，如官网展示、技术阐述等更符合当地社会的语言习惯和思维方式；二是如何做好产品形态的本地化展示，如根据当地市场的特征调整产品的呈现、跟进当地市场变化调整产品算力等。</p>\n  <p>而与前两者相比更难的是，<strong>如何在当地重新建立起合作伙伴的体系。</strong>进入一个全新的市场，诸如软件开发商、分销商、咨询机构等合作方都需从头梳理，为此国内企业还需探索制定多方共赢的公司政策才能推动合作伙伴长期携手。</p>\n  <p>“这些（合作伙伴体系）真正建设起来，我们这个市场才算完全打开。这三项挑战做好了，才能一个一个区域地去复制。”孙磊说。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_bb75434f9b1e4d53994848f5a5e51ef9@5623968_oswg104094oswg901oswg518_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">关注获取更多资讯</p>", "published": "2024-11-07 01:27:41", "id": "521212d0-07e6-430b-9d40-8db20bcb28c5", "source": "36氪", "section": "综合资讯"}, {"title": "动力源：被美国财政部OFAC列入SDN清单", "link": "https://36kr.com/newsflashes/3026158216291848?f=rss", "description": "36氪获悉，动力源公告，公司于近日获悉，美国财政部OFAC将公司列入SDN清单。被列入清单的实体在与美国实体之间的交易、海外资产转移、外汇结算等方面将面临限制。公司自成立起便秉承自主研发的技术路线，致力于电力电子技术在数据通信、绿色出行和氢能源等领域电能转换与能源利用的研发和应用。公司与海外客户之间的贸易属于正常的业务往来，并严格遵守生产经营等活动涉及的相关法律法规及国际商业惯例。公司此次被列入“SDN清单”将可能对公司国际业务及部分商业银行合作等方面产生较大影响。", "published": "2024-11-07 10:07:19", "id": "e30c0695-decc-4a07-a431-1fdc6a51215c", "source": "36氪", "section": "综合资讯"}, {"title": "巴西亚马孙地区毁林面积创9年来新低", "link": "https://36kr.com/newsflashes/3026147351078405?f=rss", "description": "巴西政府官员6日说，巴西境内亚马孙雨林区最近一个统计年度的森林砍伐面积同比下降30.6%，毁林规模为9年来最低纪录。巴西国家太空研究院的数据显示，2023年8月1日至2024年7月30日，巴西亚马孙地区森林砍伐面积为6288平方公里，比去年同期下降30.6%。研究院主管吉尔万·奥利韦拉说，这一森林损失量为“过去9年来最低”水平。（新华社）", "published": "2024-11-07 10:04:12", "id": "9bc0661c-371c-4504-93c1-c91852978e89", "source": "36氪", "section": "综合资讯"}, {"title": "9轮融资，深圳杀出一个明星IPO", "link": "https://36kr.com/p/3026176178513161?f=rss", "description": "<p>距离上一家互联网医疗公司健康之路递表不到两个月的时间，港股又迎来一家同行冲击上市。</p>\n  <p>由于商业模式的特殊性，互联网医疗公司普遍面临盈利难的困境。“<strong>在中国做互联网医疗的公司，那些不卖货的都亏钱。</strong>”这是某头部互联网医疗公司CEO曾经对互联网医疗行业的定性。</p>\n  <p>梳理了不少互联网医疗公司的财报之后，这个观点屡次被证实。</p>\n  <p>不久前，健康160国际有限公司（以下简称“健康160”）向港交所二次递表，公司在9月获得证监会的境外发行上市备案通知书，申万宏源香港和清科资本是联席保荐人；早在2023年年底，这家公司就已递交过一次上市申请了。</p>\n  <p>健康160成立于2005年，总部位于广东省深圳市，其前身是深圳宁远科技；公司建立并运营中国最大的数字医疗健康服务平台，并专注于提供云端SaaS服务。</p>\n  <p>递表前，健康160一共有9轮融资，不少知名投资机构都参与了押注，包括深圳市国资委旗下的远致投资、投控东海、啟赋资本、盈信国富等。</p>\n  <p>在2023年11月28日的E轮融资中，LSJC Holdings以5000万元的投资额获得公司1.72%的股权，据此简单计算，<strong>健康160在一级市场的估值大约为29.06亿元</strong>。目前罗宁政是公司的实际控制人，他通过直接和间接的方式合计控制公司37.86%的表决权。</p>\n  <p>互联网医疗赛道在过去十多年的发展中，一直让投资人又爱又恨，爱的是互联网的魔力，嫁接到任何一个传统行业都能焕发新的生机；恨的是其他行业的经验似乎在医疗行业不管用了，各路战绩斐然的机构在互联网医疗赛道上屡次吃瘪。</p>\n  <p>不久前的健康之路也是吸引了包括百度在内的不少明星投资机构参与，但是也迟迟没有盈利，最近顶着重重压力，硬着头皮第三次递表港交所。</p>\n  <p>那么此次健康160的招股书中，是否能有一些新的发现呢？</p>\n  <h2><strong>01 行业竞争比想象中要激烈</strong></h2>\n  <p>健康160有两项业务：医药健康用品销售、数字医疗健康解决方案。</p>\n  <p>医药健康用品销售包括批发和零售，主要从事医药健康用品的销售。</p>\n  <p>报告期内，医药健康用品销售始终占据公司主要收入来源的地位。2024年1-6月，医药健康用品销售所产生的收入占比为71.9%，其中，批发占到67.2%。</p>\n  <p>数字医疗健康解决方案主要包括：1、针对医疗健康机构和第三方商户的在线营销解决方案；2、针对医疗健康机构的数字医院解决方案；及3、针对个人用户的在线健康服务。</p>\n  <p>数字医疗健康解决方案业务主要依托健康160平台，通过这个平台，可以整合在线及线下渠道的医疗健康服务，连接医疗健康机构、医护人员及个人用户。2024年1-6月，数字医疗健康解决方案所得收入占公司总收入的28.1%。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_a2628a97e22146038bf9e60cbd6b21d3@5091053_oswg216825oswg831oswg439_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">公司按业务线划分的收入明细，来源：招股书</p>\n  <p>中国的医疗健康行业主要包括两个部分：</p>\n  <p>1、健康产品分销行业，涉及在药店、医院及基层医疗卫生机构销售医疗产品；</p>\n  <p>2、医疗健康服务行业，包括健康保持、恢复和改善相关的服务。</p>\n  <p>根据弗若斯特沙利文的资料，中国医疗健康行业的市场规模由2017年的6.5万亿元增加至2023年的11万亿元，复合年增长率为9.1%，并预期将于2030年达到人民币21.5万亿，2023年至2030年的复合年增长率为10.1%。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_66967d9eaa724f30b0340e0938e8ca60@5091053_oswg103593oswg781oswg508_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">中国数字健康综合服务行业规模，来源：招股书</p>\n  <p>从竞争格局来看，中国医药健康用品分销和数字医疗健康综合服务行业的竞争都比较激烈。</p>\n  <p>2023年中国健康用品批发市场参与者共有1.48万家，五大参与者合计持有约55.2%的市场份额，大部分为大型或国有医药贸易公司，例如国药系、上海医药、华润医药等。<strong>健康160在2023年的收入排名第500位左右，占中国健康产品批发市场份额不足0.1%。</strong></p>\n  <p>在数字医疗健康综合服务行业，健康160也面临来自市场上成熟参与方及新进入者的激烈竞争，<strong>行业头部参与者包括京东健康、阿里健康、平安好医生、微医、智云健康等。</strong></p>\n  <p>不过，招股书称，根据沙利文的资料，按2023年通过平台挂号的数量、截至2023年12月31日合作的医院数量、合作的三级医院数量、接入平台的医护人员人数这几项指标计算，健康160是2023年中国数字医疗健康综合服务行业最大的数字医疗健康服务平台。</p>\n  <h2><strong>02 为企业、医院及患者提供服务</strong></h2>\n  <p>通过医药健康用品销售和数字医疗健康解决方案这两项服务，健康160可以服务于中国医疗保健市场的多个利益相关方：</p>\n  <p>首先，企业客户可以向健康160采购医药健康用品，公司承诺及时交付，并提供售后服务支持。</p>\n  <p>第二，针对医院等医疗健康机构，公司可以提供量身定制的解决方案，帮助实现数字化运营，提高运营效率及提升品牌知名度。与医疗健康机构的合作是公司业务的核心。</p>\n  <p>第三，针对医生和患者，健康160建立的在线服务平台支持在线健康服务、患者管理和个人品牌推广，使医护人员受益匪浅。个人用户可通过公司的在线健康服务门户，轻松地获取在线健康服务以及医药健康用品。</p>\n  <p>最后，除了为主要平台参与方提供产品及服务外，公司还运营着服务于第三方商户的在线平台。</p>\n  <p>基于深圳的资源，健康160构建了一个数字医疗健康服务平台，打破了线下医疗健康服务通常存在的时间和空间限制。截至2024年6月30日，公司的服务范围已扩展至全国260多个城市。</p>\n  <p>截至2024年6月30日，健康160的平台已连接了超过3.37万家医疗健康机构，其中包括超过1.42万家医院（包括3363家三级医院）及超过1.94万家基层医疗卫生机构。同时，公司也与超过74万名医护人员建立合作关系，注册个人用户达到了4890万名，平均月活跃用户约300万名。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_a3b4487fb6e04f59a8c7824e4eb1a697@5091053_oswg88385oswg831oswg229_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">截至2024年6月30日公司关键运营数据，来源：招股书</p>\n  <p>然而值得注意的是，<strong>公司在线平台的平均月活用户呈逐年下降态势</strong>，2021年至2024年上半年，平均月活用户分别为390万人、330万人、310万人和300万人。并且报告期内<strong>客单价也呈现下降的趋势</strong>，在线营销解决方案、数字医院解决方案、在线健康服务三大业务板块均有所下降。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_716af2ddb7824ae59d352604dfcb282a@5091053_oswg277498oswg731oswg684_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">主要经营指标，来源：招股书</p>\n  <h2><strong>03 增收不增利，三年半亏损4.6亿元</strong></h2>\n  <p>通过业务扩展及变现机制，健康160的营收实现了一定增长。</p>\n  <p>2021年、2022年、2023年以及2024年1-6月，公司营业收入分别为4.23亿元、5.26亿元、6.29亿元、及2.74亿元。</p>\n  <p>但是与互联网医疗行业内的其他公司一样，盈利始终是摆在公司面前的一道难题。</p>\n  <p>报告期内，公司来自持续经营的亏损分别为1.5亿元、1.19亿元、1.11亿元、8326万元，<strong>三年半累计亏损约4.6亿元。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_29cc9fa291254452a69a1699a40cf812@5091053_oswg263283oswg831oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">财务数据概况，来源：招股书</p>\n  <p>从毛利率来看，报告期内，健康160的数字医疗健康解决方案的毛利率分别为76.6%、72.8%、72.4%、及76.4%。</p>\n  <p>相比之下，医药健康用品销售，也就是线上药品零售业务，作为占据健康160主要创收比重的板块，其创利能力实在不理想，报告期内这块业务的毛利率分别为4.0%、4.1%、1.9%及1.9%。</p>\n  <p>据Wind数据显示，2023年25家A股上市医药流通企业毛利率的平均值为13.8%，2024年上半年平均值为13.76%。港股上市的三家头部互联网医药公司（京东健康、阿里健康、平安好医生）2023年的毛利率落在了21%到32%之间。所以，无论是和线上销售还是线下销售相比，健康160线上药品零售业务的毛利率都不如人意。</p>\n  <p>整体上看，随着医药健康用品销售的收入比例不断扩大，尤其是来自批发模式的收入的比例扩大，公司整体毛利率呈现下降趋势。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_409f643e0775428eb21f7581ffb29dfe@5091053_oswg43631oswg763oswg279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>另外，不仅仅是毛利率低的问题，公司的各项费用也面临压力。健康160在招股书中称，公司仍处于业务发展及变现的早期阶段，在开发产品及服务、扩大医疗资源以及增加平台流量的过程中，产生了大量的成本及费用，尤其是存货成本及僱员福利开支，导致公司录得持续经营亏损。</p>\n  <p>体现到报表上，就是公司的三大费用都不低，2023年，销售费用、研发费用、财务费用分别达到1.02亿、0.42亿元、0.9亿元，总计2.44亿元，远高于公司实现的毛利额。</p>\n  <p>实际上，健康160的 IOS第一版APP上线时间可以追溯到2013年，时至今日已经运营了11年，如今仍然说处于发展和变现的早期阶段，足可以见这个行业变现的难度之大。</p>\n  <p>当然，这并非个例，不久前递表的健康之路三年半也累计亏损了7.8亿元。</p>\n  <p>在持续亏损下，<strong>健康160负债压力较大</strong>。2022年，公司负债净额达3.9亿元；招股书称，2022年之前，公司的净负债状况主要归因于发行附带赎回权的普通股导致的赎回负债。</p>\n  <p>不过2023年在终止与相关投资者的所有优先权后，公司依然录得净负债；截至2024年6月30日，负债净额达7790万元。</p>\n  <p>接下来，上市成功与否对公司经营至关重要。可是，就算上市成功了，公司能否走出困局呢？</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/auE9omCqgWtW6Q_xLbJZkA\" rel=\"noopener noreferrer\" target=\"_blank\">“格隆汇新股”</a>，作者：发哥说新股，36氪经授权发布。</p>", "published": "2024-11-07 10:30:47", "id": "955ffe16-cdb1-4ec3-8666-e4b973c1b1f6", "source": "36氪", "section": "文章资讯"}, {"title": "省广集团11月7日缩量上涨10.03%；省广集团联合发布《2024快手白酒行业洞察报告》", "link": "https://36kr.com/p/3026195047867654?f=rss", "description": "", "published": "2024-11-07 10:45:06", "id": "91597c6b-374a-4d69-a3eb-5d96d1351d84", "source": "36氪", "section": "文章资讯"}, {"title": "中国联通11月7日放量上涨2.32%；中国联通5G+AI智慧赋能第七届进博会", "link": "https://36kr.com/p/3026178247795972?f=rss", "description": "", "published": "2024-11-07 10:28:04", "id": "8b7c8403-487a-49fa-9b4e-165a4f1a7387", "source": "36氪", "section": "文章资讯"}, {"title": "中油资本11月7日缩量上涨3.39%", "link": "https://36kr.com/p/3026212628997632?f=rss", "description": "", "published": "2024-11-07 11:02:54", "id": "4f1aaa1c-e792-4f4c-90e8-d7f7fd65a904", "source": "36氪", "section": "文章资讯"}, {"title": "壶化股份11月7日放量上涨6.65%", "link": "https://36kr.com/p/3026217012553219?f=rss", "description": "", "published": "2024-11-07 11:07:22", "id": "3bb0d18e-3bed-4985-9f96-6c0db041ff33", "source": "36氪", "section": "文章资讯"}, {"title": "字节跳动反腐细节曝光，腾讯、美团如何清理“蛀虫”？", "link": "https://36kr.com/p/3026201213416323?f=rss", "description": "<p>日前，字节跳动内部发布了年内第四份《企业纪律与职业道德委员会通报》。通报显示，103人因违法违规行为被辞退(含外包及实习生)，其中11人因涉嫌构成刑事犯罪，被公安机关立案侦查。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_b914381fbac245d1970d6d0b74a2b789@813924438_oswg655297oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>据通报，上述涉嫌构成刑事犯罪的11人中，从涉嫌罪名来看，其中1人涉嫌职务侵占罪，5人涉嫌非国家工作人员受贿罪，另有5人未披露具体涉嫌罪名。从涉及业务和部门来看，11人中涉及电商业务3人、生活服务3人、抖音2人，企业服务、人力与管理、财经各1人。</p>\n  <p>在任何企业违法违规都是非常严重的问题，其实，不只是字节跳动，像小米、vivo、荣耀等企业也爆出了反腐案件，那么他们是怎么调查出来的呢?</p>\n  <h2><strong>字节跳动反腐辞退103人，11人立案</strong></h2>\n  <p>可以看出，此次字节跳动在反腐的力度上还是非常大的，而且从人员分布来看，涉及公司内部众多业务和部门。</p>\n  <p>众所周知，利用职务便利谋取不正当利益的行为，很大一部分发生在采购、竞标等环节。在字节跳动的通报中披露，电商前员工徐某某、抖音前员工董某某、企业服务前员工徐某某等，在采购、竞标环节，或以明显高于市场价的价格采购，或为供应商提供倾向性资源扶持等方式，为供应商谋取利益并以此收取好处费。目前，三人均因涉嫌构成刑事犯罪，被公安机关立案侦查。</p>\n  <p>另外，泄露公司保密信息也是通报中的多发行为，其中，王某某直接向外界售卖公司的保密信息，从而，因涉嫌刑事犯罪，也已被公安机关立案侦查。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_0a6877d9fd5d40e2ab1a2441cf56d7f5@813924438_oswg259394oswg728oswg433_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在通报中，字节跳动特别提示了管理者的责任，如果有人对疏于履行监管、审批等责任的管理者，公司将追究相应管理责任;对于触犯刑事法律的员工，公司将默认追究涉案员工直属上级的管理责任(管理者主动发现并上报违法违规情形的除外)。</p>\n  <p>值得注意的是，除了金钱的贪腐外，这份通报还披露了近期备受关注的实习生破坏模型训练事件。今年10月19日，字节跳动大模型训练被实习生攻击的新闻一度冲上热搜。</p>\n  <p>起因是2024年6月至7月，商业产品与技术部门的前实习员工田某某因对团队资源分配不满，编写和篡改代码恶意攻击团队的模型训练任务，这一攻击造成公司资源损耗。目前，字节跳动已与田某某解除实习协议，并将该事件同步至阳光诚信联盟、企业反舞弊联盟及其就读学校进行处理。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_84f855b9e29543bd8a7473c269b0d1b6@813924438_oswg532859oswg1080oswg686_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>从上述的案例中，我们已经看到字节跳动在反腐方面的力度，其实，这已经不是他们在今年第一次实施反腐了。</p>\n  <p>2024年3月，字节跳动企业纪律与职业道德委员会对内发文，对公司近期查处的多起违规案件进行通报。文中提到的违规行为主要包括涉嫌构成刑事犯罪、违反廉政诚信制度、违反信息安全制度和违反职场尊重政策等，时间周期在2021年至2023年，所涉及的员工均已被辞退。</p>\n  <p>2024年4月28日，字节跳动纪律与职业道德委员会发布2024年2号通报，涉及61起员工违法违纪案件。</p>\n  <p>其中，4名员工因涉嫌刑事犯罪被公安机关立案侦查，并采取了刑事拘留或取保候审的强制措施。有32名员工利用工作职务便利，为外部人员提供帮助并收受好处以及使用虚假材料违规报销、违规打车和获取房补等行为。有8名员工违反字节跳动的利益冲突制度。有17人存在违规获取、保存、泄露公司内部信息及将包含敏感数据的公司内部系统交由外部人员使用等行为。</p>\n  <p>2024年8月，字节跳动旗下抖音集团发布通报，2024年上半年共查处舞弊类违规案件125起，其中 88人因触犯廉洁红线被辞退，17人因涉嫌违法犯罪被移送司法机关。</p>\n  <p>在其公布的案例中，电商前员工李某等三人、抖音前员工陆某等两人利用职务便利，为外部达人或服务商谋取不当利益并收受好处费，被辞退且移送公安机关。</p>\n  <p>科技旋涡认为，像字节跳动这样的企业，内部腐败损失的不仅是利润，还连带损失了企业的竞争力、战斗力和公信力，并影响到相关客户乃至消费者的利益。对于反腐而言，360创始人周鸿祎曾发朋友圈称：“要用最锋利的刀子将这些腐烂的肉切掉”。而这也是我们的态度。</p>\n  <h2><strong>互联网企业反腐成为常态</strong></h2>\n  <p>其实，各个企业反贪腐的脚步一直没有停歇过，尤其是大型的互联网、科技企业，他们的反腐决心是值得提倡的。</p>\n  <p>今年5月，荣耀研发管理部总裁、“技术掌门人”邓斌因违反公司商业行为准则(BCG)被荣耀除名。邓斌作为荣耀研发部门的负责人，一直负责着公司产品研发的管理工作。此次被除名，对荣耀的研发团队无疑是一次重大打击。但荣耀还是根据公司规定被荣耀除名。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_213b905231c84c17a444c61f988a2366@813924438_oswg419719oswg1080oswg716_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>6月份，小米内部也发布了一起违规违纪案件通报。通报涉及的两位管理人员均归属于小米国际业务部，分别是原小米集团国际业务部西欧地区部总经理欧文和原小米集团国际业务部拉美地区部总经理陈丙旭。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_1107b2db0c6445ccbd229a7125570d29@813924438_oswg578355oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>据通报，欧文因虚构外包业务，涉案金额巨大，被公司辞退并启动刑事及民事维权;而陈丙旭则因向合作商索要巨额贿赂、收受名贵财物、接受奢侈招待等违规行为，同样被公司辞退并没收期权，同时需要赔偿公司损失。</p>\n  <p>另外，腾讯在2023年全年共查处触犯“腾讯高压线”案件70余起，120余人被解聘，近20人因涉嫌犯罪被移送公安机关处理。典型案例中，原CSIG云业务拓展部高某和原CSIG云产品部王某在职期间利用职务便利非法侵占公司资产，被法院判处有期徒刑并处罚金。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_19e97114162040898e07a2f30ccb9e1e@813924438_oswg1245822oswg1080oswg660_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>另一家互联网巨头美团对于贪腐也不手软，他们在2023年全年协助公安立案侦办涉嫌犯罪的内外部人员93人，其中，多数案件发生在生鲜商品等采购环节，涉及多个业务部门。</p>\n  <p>华为早在2005年就开始通过宣誓方式要求所有干部杜绝腐败，并多次召开企业业务经销商反腐大会，对内部员工的腐败行为进行严肃处理。</p>\n  <p>科技旋涡认为，无论是从人力、物力还是机制上，科技企业之所以不遗余力地反腐，核心还是企业希望自身能够基业长青，根基不被腐败侵蚀。从上述互联网企业的案例我们也可以看到，他们对于反腐的决心，可以预见之后在反腐方面，他们还将继续不遗余力，这不仅为了企业良性发展，也为了肃清职场环境中的不正之风。</p>\n  <h2><strong>写在最后</strong></h2>\n  <p>现在整个国家和市场环境都在追求高质量发展，即使是头部企业，在激烈的市场竞争中往往赢得半个身位已属不易。如此惨烈拼杀得来的江山，怎么能甘心一些“蛀虫”毁掉长城。</p>\n  <p>因此，要进一步提升对企业反腐败重要性的认识，不断完善企业腐败犯罪的惩防体系。而且，还需要各级政府为企业提供良好的反腐败协助，促进企业透明化运行，促进制定企业员工职业操守准则，为企业提供良好的审计服务。未来，我们希望互联网巨头们的反腐力度继续加强，从而让“蛀虫”越来越少。</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/0bvApWTPdc0cTwF-E3LEkQ\" rel=\"noopener noreferrer\" target=\"_blank\">“科技旋涡”</a>，作者：元时文化 贾桂鹏，36氪经授权发布。</p>", "published": "2024-11-07 11:13:09", "id": "c645188d-7ccd-4624-82e8-e548382971c7", "source": "36氪", "section": "文章资讯"}, {"title": "腾讯投资40亿，飞行汽车第一股Lilium要破产了", "link": "https://36kr.com/p/3026193168917763?f=rss", "description": "<p>飞行汽车作为未来交通方式的代表，承载着人们对未来出行的美好憧憬，但现实的发展并非一帆风顺。&nbsp;</p>\n  <p>就在近日，被誉为飞行汽车界“特斯拉”的Lilium发布公告称，由于未能筹集到足够的资金来运营，已向德国拜仁州当地法院提出破产申请。有意思的是，就在宣告破产前夕，Lilium还宣布取得了革命性的进展：已完成全电 Lilium Jet 的首次系统启动。&nbsp;</p>\n  <p>Lilium申请破产的消息发酵后，立刻在全球科技行业引起了轰动。要知道，这家成立九年，有着众多明星资本参与、累计融资超百亿的行业头部玩家，就这样一夜之间“化为乌有”，的确令人感到震惊、唏嘘。&nbsp;</p>\n  <p>然而戏剧性的是，同处一个赛道，诸如海外的Joby、Archer，以及国内的小鹏汇天、沃飞长空，它们却是发展与Lilium截然相反，既有巨额融资，也有技术突破、新品发布......&nbsp;</p>\n  <p>这种明显的割裂感，正让低空经济产业变得有趣起来。而无论未来怎样，走向深渊的Lilium，都为整个低空经济领域敲响了警钟。&nbsp;</p>\n  <h2><strong>1 飞行汽车第一股的破产之路</strong></h2>\n  <p>Lilium成立于2015年，彼时低空经济尚未爆发。&nbsp;</p>\n  <p>凭借“新故事”、“新概念”，Lilium迅速得到了资本市场的关注，并顺利获得了欧洲知名投资机构Freigeist Capital的种子轮融资。仅隔一年后，又迅速完成了1070万美元的A轮融资。&nbsp;</p>\n  <p>两次融资的资金支持，让Lilium的技术取得了一定进展。2017年4月，Lilium宣布其飞行器原型Lilium Jet已完成首次测试飞行。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_15b5b9aa4385472ba9681dcf92d2b34e@5091053_oswg165128oswg951oswg490_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图：Lilium Jet试飞</p>\n  <p>与此同时，低空经济概念已经彻底爆发，各路资本疯狂融入，而作为行业早期玩家、头部玩家，Lilium自然获得了更多的资金支持。同年9月，Lilium完成了9000万美元的B轮融资，并且该轮融资是由腾讯领投。</p>\n  <p>值得一提的是， <strong>据不完全统计，腾讯至少参与了Lilium7轮融资，其中有至少3轮是由腾讯领投，合计投资高达约5.7亿美元（约40亿元）。</strong></p>\n  <p>有了钱，Lilium的产品也实现了“早产”。2019年Lilium宣布生产出世界上第一架全电动喷气式五座飞机原型机，并完成首次试飞。就在同一年，Lilium又完成了超2.4亿美元的融资，估值达到10亿美元，跻身独角兽行列。&nbsp;</p>\n  <p>此后，Lilium的融资步伐并未停歇。&nbsp;</p>\n  <p>2021年，Lilium通过“借壳”在纳斯达克成功上市，估值33亿美元（投资人累计提供14.5亿美元），成为继亿航和Joby后第三家在美上市的电动航空企业，也成了美国华尔街分析师们口中的“飞行汽车一股”。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_e4846e8d46ea448f96a9ff17eb906557@5091053_oswg810992oswg1080oswg718_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图：Lilium上市</p>\n  <p>按理说，获得这么多投资，应该把能够载人的飞行汽车造出来了吧？但Lilium创始人Daniel如同贾跃亭附体，一直声称还有很多“难题”，需要更多的资金才能解决。于是在2022年、2023年，Lilium又先后获得了1.19亿美元、2.92亿美元融资。</p>\n  <p><strong>时间过了一年又一年，资金给了一波又一波。</strong> 可Daniel依旧声称只要再获得一些资金支持，便能在2024年下半年，实现首次载人飞行这一宏伟目标。然而，资本的耐心总是有限的，已经没有机构再相信Daniel Wiegand画下的大饼了。&nbsp;</p>\n  <p>今年，Lilium筹集一笔德国复兴信贷银行约1亿欧元贷款，因德国联邦政府拒绝为其提供担保而宣告失败。随后Lilium表示子公司将根据德国法律申请破产。&nbsp;</p>\n  <p>子公司计划申请破产很可能会导致Lilium最终从纳斯达克全球精选市场退市，或被停牌。目前，Lilium股价已跌至0.052美元/股，市值仅为3289.73万美元。&nbsp;</p>\n  <p>从整个发展历程来看，Lilium的倒下并不令人惋惜。超百亿的资金支持下，从19年 原型机 试飞，到24年都还不能载人飞行，这已经很能说明问题了。&nbsp;</p>\n  <h2><strong>2 低空经济融资“冰火两重天”</strong></h2>\n  <p>所谓低空经济，是指在1000米以下的低空空域内，围绕各类有人驾驶和无人驾驶航空器的低空飞行活动及相关服务与技术所形成的经济体系。&nbsp;</p>\n  <p>它包括无人机、直升机、eVTOL（飞行汽车）、热气球等各种航空器及其在物流、农业、环保、城市建设、影视制作、应急救援等领域的广泛应用。&nbsp;</p>\n  <p>一场航拍婚礼、无人机送外卖、几台无人机开展低空农林植保作业，这些都是低空经济的具体体现。&nbsp;</p>\n  <p>诚然，低空经济目前没有统一的定义，但毋庸置疑的是，低空经济距离实现大规模商业化尚有很长的路要走，目前尚无国家达成此目标，整个行业正处于技术不断革新与升级之中。简而言之， <strong>整个产业目前仍处于“烧钱”阶段，而这对玩家们的融资能力也构成了极大的考验。</strong></p>\n  <p>不过与Lilium的破产形成鲜明对比，低空经济领域的其他企业却呈现出不同的融资状态，一些具有创新技术和商业模式的企业获得了资本的持续青睐。&nbsp;</p>\n  <p>以空中出租车公司Joby为例，与Lilium同样呈现巨大亏损。其在2024年上半年运营亏损高达2.9亿美元，净亏损为2.18亿美元，上年同期的净亏损达4亿美元。不过与Lilium相反的是，Joby抱上了足够粗壮的“大腿”。&nbsp;</p>\n  <p>就在不久前，丰田汽车和空中出租车公司Joby同时宣布，丰田将额外投资5亿美元来支持Joby电动空中出租车的认证和商业生产，旨在实现两家公司共同的空中交通愿景。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_889ac0932b8349ffbbad27310ccd5545@5091053_oswg252589oswg660oswg412_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图：丰田投资Joby</p>\n  <p>不止是Joby，美国的Archer同样获得了巨额资金，其中包括美国联合航空公司签订的价值10亿美元（约77亿元）的200架eVTOL飞机订单，并且可选择再订购100架。</p>\n  <p><strong>看完国外，国内低空经济领域也迎来了投资热潮，越来越多其他赛道的领军者加入。</strong></p>\n  <p>比如今年6月份，吉利旗下子公司沃飞长空，宣布完成B轮数亿元融资，策源资本领投，中科创星、华控资本等原股东继续追投，创下了近两年国内eVTOL行业单笔融资的最高纪录。&nbsp;</p>\n  <p>再比如8月份，电池巨头宁德时代也选择入局低空经济，投资了峰飞航空数亿美元，打算共同合作研发eVTOL航空电池。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_13cfcd00446f41e3890e9cfe5bcbf185@5091053_oswg197043oswg730oswg477_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图：吉利沃飞长空首款飞行汽车AE200</p>\n  <p>据启信宝数据显示，近五年来全国低空经济产业企业共获得728次创投融资，公开融资金额的事件占比达到35.58%。</p>\n  <p><strong>破产的破产，融资的融资。</strong> “冰火两重天”的低空经济正让玩家们意识到，这似乎不仅仅是一个有钱就能玩的游戏。&nbsp;</p>\n  <h2><strong>3 有钱、有政策、有产业链，国内玩家持续加速</strong></h2>\n  <p>Lilium子公司的破产，以及此前载人产品的持续“难产”，除了企业本身的问题，缺乏产业链、政策的支持，也是客观因素。&nbsp;</p>\n  <p>有观点认为，Lilium的破产与其在产业链的投资储备分不开，从2023年起，业内人士就逐渐意识到供应链的重要性，只有供应链上下游协同发展，才能推动整机发展，但海外市场在这方面有着明显的不足。&nbsp;</p>\n  <p>此外在10月24日的发布声明中，Lilium表示之所以有如今的局面，最大的原因在于“政府没有大力支持”。&nbsp;</p>\n  <p><strong>不同于Lilium所面临的情况，随着国内对低空空域的政策环境逐步松动，加上产业链的逐步完善，国内玩家们显然得到了更大的发展空间。</strong></p>\n  <p>在eVTOL细分赛道，以小鹏汽车的生态企业的小鹏汇天来说，近年来取得了显著进展。&nbsp;</p>\n  <p>就在近日，小鹏汇天宣布自主研发的“陆地航母”飞行体首次实现载人试飞。另一个相关消息是，小鹏汇天飞行汽车智造基地，也正式在广州开发区、黄埔区破土动工，据悉这将是全球首个利用现代化流水线，进行大规模量产的飞行汽车工厂。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_a0450d34ea684c7e9a64b6473ee04256@5091053_oswg1101463oswg1080oswg667_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">小鹏汇天飞行汽车智造基地动工 来源：广州创新</p>\n  <p><strong>在资本持续发力、玩家相互竞争的同时，国内不少地方政府也纷纷给予巨大的支持。</strong></p>\n  <p>截至目前，安徽、广州、武汉、北京等多个省市已发起设立低空经济产业基金，基金规模从10亿元至200亿元不等，其中，贵阳、武汉和苏州三地更是以基金集群的形式设立低空经济产业基金。&nbsp;</p>\n  <p>以广州为例，据统计目前开发区、黄埔区已集聚50多家低空经济领域企业，涵盖产业链上中下游，包括研发设计与原材料、零部件制造和集成、应用与服务等环节，年产值/营收规模约130亿元。此外，广州还率先出台“低空10条”产业支持政策、发布低空经济应用场景典型案例和应用场景清单。&nbsp;</p>\n  <p><strong>融资、产业链、政策支持，不管从哪方面来看，国内低空产业都具备较大优势，但这并不意味着，国内玩家们就能轻松应对接下来的挑战。</strong></p>\n  <p>无论国内外，就目前的整体发展情况而言，低空经济玩家依旧还有很长的路要走。&nbsp;</p>\n  <p>首要的一点是低空经济的监管政策尚未完全明确，企业在市场拓展和商业化运营方面存在一定的不确定性。同时，主控芯片、精密元器件、飞行控制、智能避障、故障诊断等关键核心零部件、技术的巨大突破，难度之大堪比“登天”。&nbsp;</p>\n  <p>总而言之，对于国内外低空经济玩家们而言，都应该吸取Lilium破产的经验教训，更加注重技术创新与商业化落地的结合。毕竟长路漫漫，急不得......&nbsp;</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/tQKglqt_SrGyKwFz_lI9lQ\" rel=\"noopener noreferrer\" target=\"_blank\">“锌财经”</a>，作者：路世明，编辑：大风，36氪经授权发布。</p>", "published": "2024-11-07 10:46:28", "id": "f9c23c2a-71ec-4ad5-95a4-ac205713b57c", "source": "36氪", "section": "文章资讯"}, {"title": "莱美药业11月7日放量上涨4.72%", "link": "https://36kr.com/p/3026172512462085?f=rss", "description": "", "published": "2024-11-07 10:22:05", "id": "75b4b939-23db-49b9-8ae0-c5e1324bbac3", "source": "36氪", "section": "文章资讯"}, {"title": "一条视频点赞128W，“小众赛道”在小红书逆袭", "link": "https://36kr.com/p/3026165739300105?f=rss", "description": "<p>10月小红书涨粉榜已出，我们先来一起看榜：</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_9d777e0a078a442295bd9125eee5b6df@000000_oswg280912oswg750oswg3426_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>总体来看，<strong>小红书博主们10月的涨粉情况与9月份类似，即涨粉量处在全年平均水平之上。</strong>具体到单个博主分析，10月拿下涨粉榜TOP1的是新闻账号@人民网，总计涨粉63.93W，也是本月唯一一个涨粉量级在50W+的账号。</p>\n  <p>排在第二位的是服饰商家号@黄吉吉，单月涨粉数达到36.78W。事实上，这个账号在上个月已经登上过涨粉榜，但相比之下，10月的数据更为亮眼。在仔细浏览了@黄吉吉 的账号后，卡思发现其日常笔记内容和直播间运营方式都有很多值得学习的地方。</p>\n  <p>从笔记内容来看，账号独特之处在于会模仿普通博主的发文风格，让模特将服装穿上身后进行动态展示。视频中，模特们会模拟生活场景下的穿衣情况，背景音则会在一旁结合模特动作点出用户日常穿着类似服饰时遇到的各种问题，并表明自家产品完全不会有类似情况，以此突出自身优势。<strong>这样的商品笔记更具场景感和说服力，对用户的种草效果也更强。</strong></p>\n  <p>而在直播间运营上，@黄吉吉 不仅做到了每天六点坚持开播，保证超长的直播时长，还在主播话术中特别强调了自家产品的回购率，以此吸引新粉丝下单。更值得一提的是，其每场直播都会推出比常规商品价格低50元左右的“秒杀品”，顾客只有在关注账号后才有资格购买，这一策略也有效提升了账号的涨粉速度。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_e0a9ec7ac8044d97a03adfdab7ea0473@000000_oswg125813oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">@黄吉吉&nbsp;小红书截图</p>\n  <p>排在10月涨粉榜第三位的是女明星@赵露思，上月涨粉29.29W，目前账号累计粉丝数已达到1832.6W，是当之无愧的“小红书顶流”。前三之外，还有四位博主的涨粉量级在20-30W区间，其余十三位博主的涨粉数则都在10-20W区间，从绝对数字来看这样的数据表现并不算优秀。但让人眼前一亮的是，<strong>10月涨粉榜中涌现出了不少此前未出现过的新面孔，展现了小红书内容生态的蓬勃生命力。</strong></p>\n  <p>从上榜账号类型来看，10月共覆盖了新闻、明星、服饰、测评、摄影、剧情、教育、美妆、家居等9个垂类，各赛道账号的上榜情况比较平均，没有哪一类型展现出特别明显的优势。</p>\n  <p>接下来，卡思将对涨粉榜中比较有特色的账号进行更深入的分析。</p>\n  <h2><strong>@不知名鸽子：00后摄影师玩转中式美学</strong></h2>\n  <p>@不知名鸽子 的账号主理人是一个00后摄影师，其笔记也一直以“创意摄影”为主要内容。</p>\n  <p>与众不同的是，他不会和常规摄影账号一样直接分享美照，而是<strong>会将自己创作这组图的灵感、主题整理成一个个小故事，并拍摄成短小的剧情电影发布，照片成品则会在故事推进过程中以电影画面定格的形式展现</strong>，使得观众更能理解这张照片想要表达的涵义。</p>\n  <p>除了内容形式的创新外，鸽子的摄影风格也很有自己的特色——照片的布景、氛围有着浓浓的中式风格，但模特的妆容、表情又常常十分诡异，<strong>使得整个画面在精致中透露着一些恐怖和怪诞，主打中式恐怖美学，有一种割裂的美感。</strong></p>\n  <p>也正因为这样的风格特色，其作品中常常能看到一些作者对社会现实问题的思考。</p>\n  <p>比如，在《名为封建的脐带，勒了我一辈子》的视频中，母亲没有逃过封建社会下的“父母之命”，一出生就别无选择的被指给他人为妻，而掀起盖头后已为人妻的母亲生下的孩子，又立即被指婚给下一个人。“脐带还未剪下，就已经活成了母亲的样子”，在封建社会的代代传承中，每个女人都只能进入无法掌控的轮回。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_16a0742dbd4945a2ba575f483dde6c0b@000000_oswg146606oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">@不知名鸽子&nbsp;小红书截图</p>\n  <p>评论区里，观众们对于这条视频的讨论非常激烈，不少人表示短短几个片段就让自己看得毛骨悚然，作者拍摄的照片所展现出的超强表现力和冲击力，也激起了很多人对于健康婚姻和女性生存环境的思考。</p>\n  <p>10月，其发布的最新作品《山茶花在我的胸口朵朵盛开》，则是通过“花吐症”这一新颖设定，讲述女主人公在多段爱情中成长的经历，最后她终于意识到“爱自己才是开花的意义”，点明主题的同时也给更多观众以启发。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_1bcd8a8569d044c0aef1f6287670c144@000000_oswg113435oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">@不知名鸽子&nbsp;小红书截图</p>\n  <p>这支作品开篇充满悬疑、奇幻的色彩，成功吸引了观众的停留；中间又用多个爱情故事增加浪漫元素，配合着恰到好处的BGM将情绪层层推进；最终在视频末尾将主题升华，展现了女性应该拥有的强大精神内核，让众多用户豁然开朗。目前该笔记已经获得了128W点赞，超21W人收藏。</p>\n  <p>总地说来，<strong>@不知名鸽子 的作品都是从现实生活取材，基于传统却不拘泥于传统，通过艺术化的表达，向观众展现美的同时，触发大众情感，引发强烈共鸣，</strong>作品的传播力和影响力也由此大大增加。</p>\n  <h2><strong>@马俊达Mars：讲园林讲出15w粉丝，小众专业在小红书大放异彩</strong></h2>\n  <p>博主@马俊达Mars 是一位专注于风景园林与中式建筑领域的科普博主，他在个人主页上清晰地列出了自己的求学经历——风景园林本科、UCL巴院景观建筑硕士，并担任过艺术机构的景观建筑老师，这些tag迅速为他树立起一个较为专业的形象。</p>\n  <p>根据卡思观察，今年6月，马俊达在小红书上发布了账号的首支视频，主题是外国电影的中文翻译。随后，他又连续发布了关于苏轼的千古绝唱、陆游与唐婉的爱情故事等选题，可以看出，<strong>他一开始就将自己作品的主题锁定在中国传统文化元素上，希望通过这些元素来打造出账号内容的独特性。</strong></p>\n  <p>对于一个新博主来说，这些作品的数据表现还算不错，但还远没有达到“爆款”“破圈”的程度。并且，或许是因为这些内容并非他最擅长的领域，所以在部分内容的讲解上有时会显得有些生硬。</p>\n  <p>10月8日，他发布了一支以照片拍摄技巧为引入的视频，详细讲解了古人设计造园时常用的“夹景”技巧，并延伸出这种审美对后世在动画、电影、海报等作品制作方式的影响。这条笔记迅速获得了观众们的喜爱，截至目前点赞已经突破3.8万，由此成为了作者内容创作的转折点。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_67104a5423dd4250a0e05194e5ff55d6@000000_oswg177353oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">@马俊达Mars&nbsp;小红书截图</p>\n  <p>从这条笔记开始，<strong>马俊达的内容开始聚焦于古典建筑</strong>，标题中也常常带有“老祖宗”等词汇，以此来强化重点，并逐渐形成了较为固定的视频模式和个人标签。</p>\n  <p>现在翻看他的作品会发现，其发布的大部分视频通常以“来，给你看个好玩的”为开头，然后对某一风景园林知识进行深入讲解。</p>\n  <p>除了主题独特之外，<strong>马俊达还非常注重内容的易懂性</strong>。由于他科普的内容相对专业，不太为大众所熟知，<strong>因此他的作品中运用了很多图表、动画等辅助手段来简化复杂的知识点，使其变得易于理解。</strong></p>\n  <p>比如在《中式传统建筑有这么多，到底应该怎么分辨呢》中，刚开始他用一个小黑方片代指房子——</p>\n  <p>“假如这里是一个房子，我把它的墙拿掉，盖一个好看的屋顶，这就是公园里的亭子，所以你会发现亭子一般都建在好看的景色里，再把四边的墙都掏空。如果再给亭子加一个石座，这个样子有点像曹操的那个铜雀台，对这就是“台”；如果把这个台建在水中，这个就是水榭……”</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_25094acbb29e4337ae7dfba5eb02ac7a@000000_oswg98384oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">@马俊达Mars&nbsp;小红书截图</p>\n  <p>配合着自己的画外音讲解，博主一边用自己做的模型进行生动变形，一边又贴出实际的建筑物图片方便观众理解。在短短75秒的视频中，向观众们讲清楚了中国传统建筑的代表——亭台楼阁榭舫轩。<strong>虽然知识量极大，但却丝毫不会让人觉得无法理解，反而有了清晰的知识脉络。</strong></p>\n  <p>值得关注的是，他不仅会在作品中介绍中式建筑的外观和构造，还会和大家科普相关的文化内涵和历史背景，使观众不仅能了解建筑方面的知识，<strong>还能关注这背后的文化价值，由此激发了很多观众对中华文化的认同感和自豪感。</strong></p>\n  <p>有人在他的评论区留言“从没想过风景园林也能走新媒体的道路”，关于此的回复大多是对博主的支持和认可，认为这样的内容有利于传播中式美学，并对孩子的审美教育起到积极作用。</p>\n  <p>除了上面两位博主之外，从十月涨粉榜中，卡思还观察到一个比较新颖的创作趋势——营销号式自我介绍。</p>\n  <p>这类型视频通常运用营销号惯用的背景音乐和解说配音，节奏欢快活泼，充满活力。在内容方面，博主们会精心挑选自己过往较为满意的作品，集合在这条视频中一并展示给观众，<strong>旨在短时间内全方位地呈现自己的各项优势。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_53850842165745a489dc0f28e4d04194@000000_oswg169981oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">@闫不闲@谢反反@玲玲教美妆&nbsp;小红书截图</p>\n  <p>这种“整活视频”让博主们以颇为巧妙的方式向观众进行自我介绍，不仅不会令人感到厌烦，反而在用户群体中收获了很好的反响。例如，本期涨粉榜上的@谢反反 和 @玲玲教美妆，以及上月涨粉榜中的@闫不闲，都通过这种形式制作出了数十万赞的视频。</p>\n  <p>以上就是本期涨粉榜的全部内容，后续小红书还会涌现出哪些内容黑马，卡思会持续关注。</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s?__biz=MzUzMjI1MzkyNw==&amp;mid=2247539441&amp;idx=1&amp;sn=55ec18c3e2887e891f027933393f298f&amp;chksm=fb0b1a9dc321c2ff1f8f2580930cf20e02a3209c9a79c453cb767816738dbfa542809d0b9f86&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“卡思数据”（ID：caasdata6）</a>，作者：江北，36氪经授权发布。</p>", "published": "2024-11-07 10:28:43", "id": "0c55107d-10bf-466a-abf3-02cebec53270", "source": "36氪", "section": "文章资讯"}, {"title": "疯狂卷投流的大模型应用们，到底哪款最好用？", "link": "https://36kr.com/p/3026213234947206?f=rss", "description": "<p>最近几个月里，你有没有发现在刷抖音、B站的时候被突然插入的大模型应用广告打个措手不及的频率越来越高了？</p>\n  <p>近日，一篇有关大模型应用投流“买”用户的文章被不少人看到，大模型公司在二十天中动辄几千万甚至上亿的广告投放费用令人咋舌。也被媒体报道为“美国AI公司依然专注于前沿AI模型技术研究，中国AI大模型则踏上了‘卷’算力、‘卷’价格、‘卷’获客、‘卷’变现能力的道路。”</p>\n  <p>此后，虽然有大模型企业出面表示相关数据统计有所不实，但也未具体透露真实投放金额。而据钛媒体App独家获悉，截至10月29日，kimi智能助手、字节跳动豆包、腾讯元宝等所有AI应用10月全网广告投放（投流）支出超过3亿元人民币。</p>\n  <p>在日渐增加的投流费用的背后，其实是当前各家大模型在应用体验层面难以做出颠覆性创新的事实，那么，<strong>当前市面上最主要的和增速最快的大模型应用有哪些？在从烧钱扩大市场到用户心智教育的这一节点，这些主流的大模型应用做出差异化了吗？</strong></p>\n  <p>而对于哪些是最主要的大模型应用、哪些是增速最快的大模型应用，新识研究所测评了《AI产品榜》统计的数据，9月份AMU前五或增速超过30%的大模型应用豆包、文小言、Kimi、讯飞星火、天工AI与最近异军突起的腾讯元宝。体验了这些火热的大模型应用的效果如何。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_ede3f9f8f90d43b9b479823719be7451@6062471_oswg136642oswg732oswg630_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">数据来源：公众号@AI产品榜</p>\n  <h2><strong>第一部分：字节“专宠”豆包月活真的高，好用吗？</strong></h2>\n  <p><strong>作为当下最火热的AI产品，豆包10月的MAU达到了惊人的5000万+的月活，这一成绩也相当于榜单第二到第九的10月月活人数之和</strong>，其中虽然有据多方业内人士透露，抖音封杀了所有的大模型广告，只留下了豆包一家，让豆包拥有最大短视频社交平台的独家支持的功劳，但作为有如此大基数还在持续保持月活稳定增长的大模型应用，豆包在使用体验上也确实很好。</p>\n  <p>具体来看，不同于Kimi与天工AI这种在创始与发展过程中逐渐将搜索当作落地能力与获客招牌的大模型应用，在字节跳动手握国内最优质数据库的支持之下，豆包几乎涵盖了当前市面上所有已经上量使用的大模型应用，<strong>包括AI搜索、AI写作、图像生成、AI阅读、第三方创建的智能体以及其特有的语音通话</strong>。</p>\n  <p>在AI搜索功能中，豆包同市面上所有的大模型应用相同，提供了简便搜索与深入搜索两类搜索模式，深入搜索会根据更多的信源，来对问题进行更加全面和深度的总结，但同Kimi这样专打在思考中搜索、在搜索的过程中思考的对手来说，豆包的AI搜索更像一个更大号的的信息处理器，但相比起其他的AI应用也算是用的过去。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_22c4bd75b8ee48d5af0588e93a3f1b1b@6062471_oswg80810oswg1110oswg776_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在接下来AI写作方面，豆包就展示出了远超平均水平的实力，在文章的体裁选择方面有着34种提前预设好的场景，覆盖了当前文字需求的绝大多数甚至全部的用途。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_352c4650b797477aa195262c16a98068@6062471_oswg116438oswg1162oswg735_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>更好用的是，在选择写一篇文章的时候，除了主题之外，针对不同平台的写作特点，豆包也会使用不同的写作风格进行改变；同时，在直接生成文章之外，你还可以选择在其中增加书写大纲一步，在勾选后，豆包会给出将要生成文章的大纲，用户可以确认大纲是否正确、对大纲的参考来源进行更改与增减后之后再进行输出，这样就避免了用户坐在电脑前花上几十秒甚至一两分钟的时间，最后得到一篇根本不符合最初设想的文章。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_70fec48f1c35460d90c54e13c5e2ab81@6062471_oswg155136oswg1024oswg709_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>这样的AI生成步骤，在月活最高的几个大模型应用中，只有豆包提供了这样的选择，说其绝对领先也没有什么问题。</p>\n  <p>图像生成方面，豆包的功能也是最齐全的那个，除了简单的文生图之外，一些去除背景、擦除、区域重绘和扩图功能也同样提供给了用户，相比于只有图像生成的友商，优点也一目了然，并且其中使用频率最高的擦除与去除背景功能，还真的意外地好用，并不会出现奇奇怪怪的填充。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_6f4087da6bbd4030b79f531e3a957848@6062471_oswg732539oswg1067oswg679_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>而在AI阅读方面，在进行了多个文档的总结提炼后，或是由于字节的能力，又或者是由于该用途的天花板不高，在实际使用中没有看到明显优于其他大模型应用的地方。</p>\n  <p>在总结文档之外，豆包也提供了AI看视频的功能，用户可以去B站等提供字幕的视频网站，登录后即可使用，但在尝试过数个视频之后，只能说豆包的想法是好的，但把B站某位up主有关美国大选的视频，用AI总结成蔡徐坤被软封禁之后的二三事，也相差实在是太大太大了，这样的功能虽然有的时候效果还算不错，但面临稍微复杂一点的视频，只能说还是不用为上。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_c35213d0dcb64fe98c9001d23adca454@6062471_oswg595271oswg1265oswg525_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>此外，豆包的语音通话也是比较特色的功能，英语口语陪练、心情树洞、模拟面试、成语接龙功能，虽然在使用中无法只有英语陪练和模拟面试有点作用，但还是无法很好地模拟真实场景，不过对于有对多模态沟通需求的人群来说，也是迈出了一大步，值得肯定。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_17787647a4da487b82551c8faa56f43b@6062471_oswg69087oswg674oswg1407_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在PC端下载豆包后，在框选相关文字后，豆包的助手也会以小浮窗形式出现，也起到了日常工作使用的助手插件功能，支持快速使用。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_b821596a23d74bf2952b5886d6d99644@6062471_oswg130984oswg1265oswg637_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>总结下来，就是作为一个经常有长板出现但没有短板的大模型应用，在友商竞品们都有的功能中，豆包都有着强于平均水平并且偶有高光表现。而在豆包特有的功能中，虽然在使用上经常出现奇奇怪怪的问题，但迈出一步也是值得肯定的。在字节的优质数据支持下，也希望可以快速完善。而作为月活绝对第一的大模型应用，豆包也确实“德可配位”。</p>\n  <h2><strong>第二部分：文小言、讯飞和腾讯元宝，蒙上logo差不多？</strong></h2>\n  <p>在豆包之后，月活排名第二的则是在最初领先的文小言（文心一言），当初文心一言刚刚面世之时的热度可以说红极一时，还需要去申请排队，但从先发到目前的月活仅有豆包的四分之一来看，文小言确实落后了不少。</p>\n  <p>其中的主要原因，同付费离不开干系，在友商们快速烧钱抢市场的时候，百度却率先推出了付费功能，也成为当前市面上主流的大模型应用唯一打开收费通道的一家。相比于竞对们快速迭代的新功能与畅通无阻使用的最新一代大模型，文心大模型4.0实在没有任何的不可替代性，再加上投放的不积极，这也成为了其逐渐落后的原因。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_c8fe959f3c2d46feb5752ba4670b9662@6062471_oswg494619oswg1249oswg895_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>不过，虽然文小言在充值上被诟病，但作为起步最早的大模型应用，其中的某些功能还是有着一些亮点的。</p>\n  <p>譬如，在AI创作方面，文小言就提供了给出主题撰写成文之外的其他选择，由于给出了更多、更全提示词，文小言无论是文章优化、日常办公、专业文稿还是在其他一些用途的文章中表现都更好。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_3c87fde1738f45a9b8d95f812813afdd@6062471_oswg176889oswg901oswg1108_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>但是，文小言也并没有做到完美，就比如在体验过了豆包、元宝这些可以先生成大纲再根据更改后的大纲生成文章的大模型应用后，文小言在直接成文还是会出现成文后才发现方向错误而浪费时间的情况，也希望可以在相关方向进行跟进。</p>\n  <p>而在AI创作之外的文档分析（总结文档）、图像生成、AI修图这些竞对们都拥有的功能方面，文小言也确实没有明显的效果上的差距，它能提供的服务友商都能提供，它能达成的效果友商也没有差到哪里去。反倒是友商的一些新奇功能如文生视频等，文小言却只能望而兴叹。</p>\n  <p><strong>综合体验下来，文小言当前的确算得上是一个合格的大模型产品，其中提供的各类服务也完全足够用户使用。但要说，文小言比竞品有哪些明显优势的地方也无从谈起，反倒是充值的价格着实不低。</strong></p>\n  <p><strong>在文小言之外，没有开通充值的那些主打大模型能力的讯飞星火与最近异军突起的腾讯元宝也几乎面临着同样的境况。</strong>AI搜索、图像生成、AI阅读、总结文档是大家共有的内容，用户想要获得更加优质、更专业的增量，只能从官方或他人创建的智能体库中寻找，但要说有什么实在不可替代的内容也确实没有。</p>\n  <p>这其实也是当前C端大模型应用竞争的真实情况。<strong>大模型早已不再局限于初期的性能较量，而是扩展到了多样化的应用领域。这些“拼爹”拼不过、流量处于第二梯队，还没有自身鲜明特点的综合性大模型应用，其实有些“无助”。</strong></p>\n  <p>而对于市场来说，普通用户所需要的应用暂时已经满足，文小言、星火、元宝们也只能去完善一下末端能力、卷卷投流了，但面对头上用绝对月活压死大伙的豆包来说，实在有些进退两难。</p>\n  <h2><strong>第三部分：Kimi和天工，在AI搜索杀出一片天</strong></h2>\n  <p>除了体验了“综合”的大模型应用，榜单上的Kimi与天工AI我们也体验测评了一番。Kimi与天工AI，更倾向做出绝对的长板，成为用户们在这一方向上的“唯一指定合作伙伴”。</p>\n  <p><strong>其中Kimi就以长文本与搜索见长。</strong></p>\n  <p>除了Kimi+中提供的少数对话模板外，Kimi的页面显得实在是有些家徒四壁。AI音乐、图像生成什么的都无从使用，但这却一点不影响Kimi受到部分用户的追捧。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_90fa4315c2cc4555b66caee6b9292c40@6062471_oswg84045oswg1199oswg554_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>作为AI大模型的独角兽企业，月之暗面更加看重技术带来的体验升级。</p>\n  <p>据智小广，Kimi作为自研大模型，在基座模型领域独树一帜。在多数厂商遵循OpenAI路径，即增加参数规模与多模态功能的同时。Kimi认识到，当前阶段模型参数虽大，但真正决定效能的是其处理复杂问题的能力。其核心在于“注意力机制（Transformer）”，它如同鱼的记忆，专注于有限范围的上下文信息。</p>\n  <p>而结果则是Kimi凭借其独特的长上下文处理能力，赢得了用户的青睐，成为大模型领域的佼佼者。</p>\n  <p>此外，上个月Kimi推出的探索版，也着实让其又火了一把。</p>\n  <p>不同于搜集信息总结再输出，Kimi探索版和GPT-o1都采用了类人的思考，多级分解复杂问题，执行深度搜索，并即时反思改进结果，提供更全面和准确的答案，帮助你更高效地完成分析调研等复杂任务。</p>\n  <p>更直接一点，就是Kimi探索版会自主规划策略，将一个复杂的问题分解为层次化的子问题，建立清晰的任务结构，然后分步来执行。之后再借助超大的容量优势，并行搜索几十个不同但相关的关键词，大大增加可参考的内容。此外，在生成答案的过程中，还可以主动进行回溯，检查最初的回答是否存在缺失和矛盾，再补充提供多方视角的信息供参考决策。</p>\n  <p>这样专精于搜索的打法，碰上了喜欢把大模型应用当作搜索软件的用户自然是一拍即合，也获得了以学生和白领为代表的重度和高要求使用者青睐。</p>\n  <p><strong>天工AI，也走上了相似的道路。</strong></p>\n  <p>天工AI虽然没有Kimi那么“极端”，提供了综合大模型应用都有的功能，并且相关效果还不错，但真正让其出圈的还是搜索。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_0410d030606b41b1a4c03371c6060c1f@6062471_oswg97264oswg1265oswg447_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>作为国内第一个AI搜索产品，天工AI也算是吃上了AI搜索的红利。</p>\n  <p>在天工3.0大模型的支持下，天工AI和Kimi探索版相同，都采用了类人思考的方法，会把用户提出的问题自动规划和拆解，将其分解为多个简单的小任务并逐步解决。在解决过程中，天工AI在生成结果的过程中，同样会检查每一步的执行情况，确保最终结果的准确性。</p>\n  <p>此外，天工也在AI高级搜索上不断深入，将金融与科研作为进一步深化的方向。</p>\n  <p>譬如在财报阅读方面，天工AI给出的功能包括金融政策查询、指标查询、财务数据对比、财报分析、公司分析、研报解读、投资理财，虽然比起券商们的研报没有主观的方向与信息增量，但给出的相关分析相比于某些互联网交易软件的大模型来说还是优秀了太多。</p>\n  <p>在科研领域，天工AI接入了全球范围内的学术数据库，包括arXiv等权威论文网站，可以实时抓取最新的科研成果。其新增的文献分析功能，支持按研究背景、方法、实验设计等维度对论文进行全面解读。用户可以通过天工AI深入理解论文中的技术细节，甚至是数学公式和实验数据。</p>\n  <p>而天工的用户画像，则也与Kimi相似，同样是对搜索和对某些方向有高要求的用户。</p>\n  <p>不过，虽然Kimi和天工AI做出了差异化，作为独角兽企业与非大厂玩家，在当前这个时点也留存下了不少的优质用户，但AI搜索赛道中的优势需要长期的技术迭代与资金支持才能维系，那些传统大厂们，也已经突入这些差异化玩家的产品腹地。据Tech星球报道，截至目前，抖音、阿里、快手、百度都已推出了自己或独立或内置的AI搜索产品或服务。</p>\n  <p><strong>而在大厂们入局后，不出意外地，只有那些对搜索有着高要求的用户才会留存在Kimi与天工AI之上，这两家也急需在AI搜索之外做出新的增量，摆在他们两个面前尤其是除AI搜索之外其他功能相对“匮乏”的Kimi来说，用户留存与商业化压力巨大。</strong></p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/wEeUZEEJhUReY61yLh8-yw\" rel=\"noopener noreferrer\" target=\"_blank\">“新识研究所”</a>，作者：杨启隆，编辑：丁力，36氪经授权发布。</p>", "published": "2024-11-07 11:12:07", "id": "5706c5dc-1ec2-4b96-be4b-f0d93e396210", "source": "36氪", "section": "文章资讯"}, {"title": "出海速递｜奇瑞尹同跃：中国车企在海外市场不能“反客为主” /消息称宁德时代全固态电池开始样品验证，团队达上千人", "link": "https://36kr.com/p/3026058811336199?f=rss", "description": "<p><strong>访问36氪出海网站</strong><a href=\"https://letschuhai.com/?utm_source=36kr&amp;utm_medium=sayhi&amp;utm_campaign=link\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>letschuhai.com</strong></a><strong>，获取更多全球商业相关资讯。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241024/v2_fee19a355a014f148029b67c2ebd07fe@11918142_oswg186017oswg1965oswg846_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2>今日好文</h2>\n  <h3><a href=\"https://letschuhai.com/f32af2c8?utm_source=36kr&amp;poster\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>小鹏公布增程与纯电体系，智驾将推 Robotaxi 车型</strong></a></h3>\n  <p>小鹏要做面向全球的 AI 汽车公司。</p>\n  <h3><a href=\"https://letschuhai.com/d267193a?utm_source=36kr&amp;poster\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>对话李开复：如果美国形成 AGI 霸权，我们应该怎么办？</strong></a></h3>\n  <p>“如果 AGI 必然发生，假设是7年以后，到了那天OpenAI ‘一统天下’的时候，它想要来碾压我们，我们至少还有抵抗的余地。”</p>\n  <h3><a href=\"https://letschuhai.com/1a26efd7?utm_source=36kr&amp;poster\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>卡塔尔与中国双边贸易十年间增幅超130%</strong></a></h3>\n  <p>中国和卡塔尔已经形成了以能源合作为主要支柱，以基础设施建设为重点领域，以金融投资和高科技领域为新兴增长点的高度互补、互利互惠、前景广阔的合作新模式。</p>\n  <h3><a href=\"https://letschuhai.com/b0c3db24?utm_source=36kr&amp;poster\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>速卖通“宣城合伙人”集体出海，4年闯出200家企业15家工厂</strong></a></h3>\n  <p>4年前，一位创业者把速卖通开店经验带回了安徽老家，速卖通上出现了第一家注册在宣城的店铺。4年后，这个数字变成了200多家。</p>\n  <h2>热点快讯</h2>\n  <h3><strong>消息称宁德时代全固态电池开始样品验证，团队达上千人</strong></h3>\n  <p>晚点6日晚报道称，宁德时代在今年增加了对全固态电池的研发投入，已将全固态电池研发团队扩充至超1000人。宁德时代目前主攻硫化物路线，在近期已进入20 Ah样品试制阶段。一位知情人士称，宁德时代目前的方案能将三元锂电池的能量密度做到500 Wh/kg，比现有电池提升40%以上，但充电速度和循环寿命还未达预期。（界面新闻）</p>\n  <h3><strong>宁德时代董事长曾毓群：储能行业不能乱，但也绝不能慢</strong></h3>\n  <p>11月7日，“2024世界储能大会”在宁德召开，开幕式上，宁德时代董事长曾毓群发表了演讲。“作为新能源转型的关键基础设施，储能行业不能乱，但能源转型需求也要求我们绝不能慢，行业必须在快速增长中同步实现高质量发展。”曾毓群说，如何实现高质量发展，行业需要做到高可靠性、高价值性和全场景。（每日经济新闻）</p>\n  <h3><strong>奇瑞尹同跃：中国车企在海外市场不能“反客为主”</strong></h3>\n  <p>11月6日，奇瑞汽车董事长尹同跃在第七届中国国际进口博览会“全球新能源汽车的未来”论坛上建议，中国车企现在都要非常积极地走出去，“在国内打不过比亚迪，我们可以在外面换个环境”。他还称，“中国汽车公司在海外是做客的，不能反客为主。”（财新网）</p>\n  <h3><strong>奇瑞集团10月出口突破11万，本月将首次突破年出口100万辆</strong></h3>\n  <p>2024年11月7日消息，据奇瑞控股官微，奇瑞控股集团10月出口汽车111922辆，同比增长18.8%，创造历史新纪录。1-10月份累计出口销量941275辆，同比增长23.8%，预计本月将迎来年内出口突破百万辆的新里程碑。目前，奇瑞集团累计全球汽车用户超过1510万，其中海外用户超过420万。（36氪）</p>\n  <h3><strong>哪吒汽车启动大比例裁员</strong></h3>\n  <p>从多个独立信源处获悉，哪吒汽车今日启动大规模裁员。对此，哪吒汽车相关负责人确认，公司正在进行组织架构调整，比例未知。10月29日，哪吒汽车正式启动公司全员股权激励计划，同时宣布将实施机构精简、裁汰冗员、业务聚焦、扁平管理等一系列降本增效的举措。（财联社）</p>\n  <h3><strong>小鹏汽车发布&nbsp;AI&nbsp;人形机器人</strong></h3>\n  <p>11月6日，小鹏汽车在广州正式发布了其自主研发的全新AI人形机器人——Iron。Iron 机器人以真人1：1的比例打造，身高达到178厘米，体重70公斤；在身体构造上，它拥有62个全身主动自由度和15个手部可动自由度。公司称，Iron 机器人目前已经进入工厂工作，率先聚焦工厂、门店等场景。（财新网）</p>\n  <h3><strong>零一万物称国内聚焦企业级市场</strong></h3>\n  <p>11月6日，李开复牵头的大模型创业公司零一万物在其战略发布会上表示，在国内将首先专注于企业级市场，提供模型训练和部署解决方案、面向零售等行业的产品、面向智算中心和政务场景的软件方案三种服务。（财新网）</p>\n  <h3><strong>OpenAI&nbsp;买下域名 chat.com</strong></h3>\n  <p>据 TechCrunch，在买下 ai.com 之后，OpenAI 又买下域名 chat.com。相较于前者，chat.com 更符合 ChatGPT 聊天的调性。如今，进入 ChatGPT，只需6/8个字符就可以了。据网友猜测，Altman 大概会花费1500-2000美金拿下这个URL。而 chat.com 也成为史上售价最高的域名之一。（财联社）</p>\n  <h3><strong>谷歌计划在沙特建立&nbsp;AI&nbsp;中心</strong></h3>\n  <p>11月7日消息，据 TechCrunch 报道，谷歌正在与沙特阿拉伯公共投资基金合作，于沙特阿拉伯建立一座 AI 中心，用于支持阿拉伯语人工智能模型和 “沙特特定人工智能应用”的研究。谷歌和沙特公共投资基金尚未透露 “针对沙特的人工智能应用”具体是何种应用。不过，考虑到化石燃料在沙特经济中的重要作用，谷歌可能会在石油和天然气生产中应用人工智能算法。2020年，谷歌曾表示，将停止为石油天然气行业提供定制化人工智能或机器学习工具。（界面新闻）</p>\n  <h3><strong>AI&nbsp;搜索创企&nbsp;Perplexity&nbsp;据悉将融资5亿美元，公司估值有望达90亿美元</strong></h3>\n  <p>2024年11月7日消息，据路透11月5日消息，知情人士称，人工智能搜索初创公司 Perplexity 将在新一轮融资中筹集5亿美元，使该公司估值达到90亿美元。拥有 Perplexity 董事会席位的风投公司 Institutional Venture Partners 将领投这轮融资。（界面新闻）</p>\n  <h3><strong>外贸平稳增长，今年前10个月我国进出口总值36.02万亿元</strong></h3>\n  <p>海关总署今天（7日）对外公布，今年前10个月，我国货物贸易进出口总值36.02万亿元，外贸实现平稳增长。据海关统计，今年前10个月，我国货物贸易进出口总值36.02万亿元，同比增长5.2%。其中，出口20.8万亿元，增长6.7%；进口15.22万亿元，增长3.2%。（央视新闻）</p>\n  <h3><strong>海关总署：前10个月我国出口机电产品12.36万亿元，同比增长8.5%</strong></h3>\n  <p>据海关统计，2024年前10个月，我国出口机电产品12.36万亿元，同比（下同）增长8.5%，占我出口总值的59.4%。其中，自动数据处理设备及其零部件1.2万亿元，增长10.9%；集成电路9311.7亿元，增长21.4%；手机7539.7亿元，下降0.9%；汽车6985.4亿元，增长20%。同期，出口劳密产品3.38万亿元，增长3.2%，占16.7%。（证券时报）</p>\n  <h3><strong>9月中国汽车商品进出口总额为266亿美元，同比增长4.8%</strong></h3>\n  <p>据中国汽车工业协会整理的海关总署数据显示，截止到今年9月，汽车商品进出口总额同比呈现小幅增长。2024年9月，汽车商品进出口总额为266亿美元，环比下降5%，同比增长4.8%。其中进口金额57.3亿美元，环比下降18.3%，同比下降16.5%；出口金额208.7亿美元，环比下降0.5%，同比增长12.7%。2024年1-9月，全国汽车商品累计进出口总额为2268.2亿美元，同比增长7.9%。其中进口金额531.7亿美元，同比下降5.3%；出口金额1736.5亿美元，同比增长12.8%。（36氪）</p>\n  <h3><strong>海外双11来临，有速卖通厂家备货10万件</strong></h3>\n  <p>2024年11月7日消息，海外双11来临，AliExpress 速卖通投入翻倍，跨境商家迎来全年最大增长机会。以安徽宣城为例，2024年，宣城本地在速卖通平台从事跨境电商经营的服饰企业也从1家变成了200多家。厂家透露，为迎接速卖通双11，自己的2家工厂已经备货10万件。（36氪）</p>\n  <h3><strong>腾讯刷掌技术出海</strong></h3>\n  <p>11月6日，在第九届新加坡金融科技节现场，腾讯刷掌技术的出海计划正式发布，并宣布与 Visa 合作，将刷掌技术引入国际支付市场，首站将落地新加坡。（财新网）</p>\n  <h2><strong>近期活动</strong></h2>\n  <h3><a href=\"https://letschuhai.com/551f8a3e\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>活动｜抓住出海卡塔尔机遇！中国-卡塔尔投资合作高峰洽谈会即将落地北京、深圳</strong></a></h3>\n  <p>为了帮助中国企业更好地了解卡塔尔市场的特点和机遇，<strong>36氪出海联合卡塔尔投资促进局、北京及深圳贸促会、盈科律师事务所，于11月12日和15日，分别在北京、深圳举办中国-卡塔尔投资合作高峰洽谈会。</strong>洽谈会旨在为中卡两国企业提供深度合作与交流的平台，助力企业探索新的商业机会。如果您关注出海卡塔尔的商业机遇，希望深入了解卡塔尔的利好政策、营商环境及合作生态，欢迎您扫描下方二维码，填写表单，报名参加本次活动。<strong>我们将根据话题相关度，对报名申请进行筛选。通过活动审核的用户，我们将有专人联系通知。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_ce6518282db7433cb0fa33d1ba134422@11918142_oswg649262oswg3930oswg1918_img_jpeg?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h3><a href=\"https://letschuhai.com/10094bc6\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>活动｜如何获取海外市场的信任？探索品牌建设的必经之路</strong></a></h3>\n  <p><strong>36氪出海将于11月21日下午2:00在北京举办一场主题交流活动。</strong>此次活动特邀来自 <strong>XREAL、Renata LLC 和 TikTok for Business</strong> 的重磅嘉宾，他们将基于丰富的品牌出海经验，分享在国际化与本地化品牌建设中的深刻见解。通过分析成功出海品牌的案例，并结合最新的市场营销趋势，为志在全球化的企业提供极具价值的品牌策略参考。<strong>如果您关注出海企业的全球化品牌策略，希望深入探讨出海品牌建设之道，欢迎您扫描下方二维码，填写表单，报名参与活动。</strong>活动报名将于2024年11月20日中午12:00截止。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_a11858fc827440e8a1373c39aa70476b@11918142_oswg2456130oswg7860oswg3836_img_jpeg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2><strong>加入36氪出海学习交流群</strong></h2>\n  <p>目前，36氪出海学习交流群已经吸引超过15,000位出海人加入，他们来自国内外初创企业、行业巨头、投资机构等。在出海社群里，我们为成员挑选整理每日全球跨境资讯，帮助出海人把握最新动态；定期组织出海交流活动，链接出海生态圈，寻找潜在合作伙伴。欢迎添加36氪出海小助手微信（ID：wow36krchuhai-xzs2）申请入群，一同出海！</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20240807/v2_f52db430543641d8a09efb8dcea3b06f@11918142_oswg15715968oswg16518oswg10313_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>", "published": "2024-11-07 10:58:57", "id": "8474bd6d-28a6-4c8a-a499-58b58535db43", "source": "36氪", "section": "文章资讯"}, {"title": "“以创新致未来，以初心致消费者” —— 宝洁六赴进博之约，携近百款创新产品精彩亮相", "link": "https://36kr.com/p/3026185229296904?f=rss", "description": "<p>【2024年11月6日，在上海】随着第七届中国国际进口博览会拉开帷幕，以“LifeLab 以创新致未来， 以初心致消费者”为主题的宝洁展区也举行了盛大的开幕仪式。今年，宝洁连续第六年奔赴进博之约，携旗下十大品类，20多个品牌的近百款创新产品重磅亮相。在这场面向全球、开放共享的盛会中，宝洁将聚焦产品、技术和可持续三大领域，全方面地展示宝洁如何持续提升创新的质量，并携手全行业一同挖掘和释放中国市场的“新机遇”。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_544c3c5526dc48fa91f0c97a98a868da@5318352_oswg4683377oswg3050oswg1853_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">嘉宾共同揭幕第七届进博会宝洁展区</p>\n  <p>“为中国消费者创造有价值的创新，是宝洁引领品类增长的第一引擎，也是激发消费活力的题中之义。” 在宝洁展区开幕式致辞中，宝洁大中华区董事长兼首席执行官许敏女士指出：“今年是宝洁连续第六年奔赴进博之约，作为进博会的‘老朋友’，我们总能在这里感受到中国市场的‘新机遇’。中国市场的新机遇意味着，中国消费者对美，对健康，对高质量生活的更高追求；新机遇意味着，宝洁所处的行业规模将会在不远的将来，从今天的七千亿突破万亿；新机遇意味着，我们对中国市场充满长期信心和战略定力。”</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_6a09e36a9759494597a3f83827551cd2@5318352_oswg2824007oswg1920oswg1280_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">宝洁大中华区董事长兼首席执行官许敏在开幕仪式上致辞</p>\n  <p>商务部投资促进事务局、中国国际进口博览局、上海市商务委员会、广东省市场监督管理局、广州开发区管委会、浦东新区三林镇、广州市商务局外资管理处、上海食品安全协会进口化妆品分会、国家卫生健康委科学技术研究所的相关领导也莅临了本次开幕仪式。其中，商务部投资促进事务局副局长唐颂发表致辞并表示：“宝洁的产品深入中国消费者生活的方方面面，期待宝洁在中国市场用卓越的创新满足更多消费者对美好生活的向往。”国家卫生健康委科学技术研究所研究员贺媛发言指出：“今年是健康中国行动的五周年。宝洁公司的产品是大健康产业的重要组成部分，是实现健康中国战略重要且积极的力量，期待携手宝洁为国民健康事业和经济社会发展做出更大的贡献。”</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_55f9526ae13a4ff78f6e42356116419c@5318352_oswg2457950oswg2275oswg1279_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">左为：商务部投资促进事务局副局长唐颂&nbsp;右为：国家卫生健康委科学技术研究所研究员贺媛</p>\n  <h2><strong>创新提质，系于以消费者为中心的初心</strong></h2>\n  <p>对于宝洁而言，每年参与进博会犹如一次&nbsp;“赶考”，而这场考试的阅卷人正是中国消费者。六年来，宝洁借助进博会这一开放平台，首发了众多品牌及产品，收获了来自外界的积极反馈。</p>\n  <p>一直以来，宝洁致力于提升创新的质量，旨在为中国消费者创造有价值的创新。为此，宝洁以消费者为中心，不断深化、优化消费者洞察，并转化为产品的功能价值和情感价值。</p>\n  <p>针对不同的消费者痛点，宝洁不断地在产品细分领域追求极致。本次进博会上，中国首发、进博首展的潘婷&nbsp;PRO-V 维他命晶莹露是潘婷首款空气感免洗护精华，蕴含潘婷品牌传奇成分PRO-&nbsp;V维他命原B5，添加30倍高浓精华构建发芯结构，修护从发根到发尾的损伤，清爽不油腻；碧浪和汰渍均带来中国首发的洗衣免搓粉，无需费力手搓，帮助中国消费者轻松洁净衣物；OLAY基于18年衰老细胞研究，精准洞察“抗老产品效果不够根源、成分不够温和、白天无法使用”这三大痛点，从衰老细胞根源出发，带来专属亚洲肌肤的抗老解决方案——强效温和的OLAY淡纹黑管精华，“酸A肽”强效抗老成分复配，有效淡化3区6大纹；全球知名牙医推荐品牌欧乐-B重磅推出新品iO2柔波双净刷，专为敏感牙和电动牙刷新手设计，在确保清洁效果同时实现温和体验；首次亮相进博会的品牌息可舒展出宝宝舒缓膏，采用非药物配方，专为3个月以上的婴幼儿研发，在快速起效的同时也保障宝宝的安全和舒适。</p>\n  <p>此外，宝洁的产品力求做到从能用到好用，为消费者带来愉悦体验和情感共鸣，回应不同人群在不同场景的多元需求。本次进博会首展的舒肤佳新品——净透系列乌木玫瑰香沐浴露，从上百种香氛中甄选，经过20多道工序，邀请300+消费者盲选测评，最终配比5重植物精油。结合“微胶囊爆香技术”，能够做到遇水瞬间爆香、层层释香，24小时持久留香。除了提供毛孔级净澈体验，也令消费者在沐浴时拥有多重感官的愉悦体验；国际高端护肤品牌SK-II携匠心打造的致臻奢美LXP匠心系列重磅新品首次亮相本届进博，本次新品展示中，SK-II首次以至高含量与至高浓缩度PITERA™精华加入面霜，帮助肌肤一天焕颜，一瓶打破肌肤瓶颈期，同时也将传统陶瓷修复的技艺之美融入其设计灵感中，向大家展示了时间与美相伴而生的灵感来源。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_1967c0340f5f4a1cb99336032e72e9e5@5318352_oswg1432842oswg1220oswg658_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">第七届进博会宝洁展区</p>\n  <h2><strong>智能探索，让科技成为创新提质提速的“推进器”</strong></h2>\n  <p>宝洁积极投身数字化和智能化浪潮，将前沿科技视为提升创新质量的“推进器”。在研发进程中，宝洁巧妙运用大数据和小数据，深度挖掘新兴子品类潜藏的市场需求，成功将产品研发周期从以往的&nbsp;18 至 24 个月大幅缩减至 6 个月以内，显著加快产品迭代速率，同步实现产品质量水平的提升。</p>\n  <p>本届进博会，宝洁首次设立“智能仪器展示区”，全面展示从消费者测试、产品设计生产到质量监控全流程中，智能技术如何助力创新质量的提升。</p>\n  <p>在消费者测试方面，OLAY HAPSENSE肤感测试仪（OLAY watch）可将皮肤触感数据化，将护肤品对皮肤影响的分析速度加快多达10倍，极大地提升了研究效率；在产品设计方面，自适应机器人能够通过与&nbsp;3D 打印机结合，缩短测试时间并提升灵活性，机械臂技术已广泛应用于多领域；在帮宝适，产品质量不是检测出来的，而是生产工艺控制的产物。帮宝适智能检测仪作为生产线的缩微模型，展示了智能化生产如何采集生产工艺参数和产品监测指标，并利用智能控制塔和人工智能模型，实时分析和预测潜在的质量问题，确保每一片纸尿裤的卓越质量。帮宝适全新推出的首款添加类胎脂¹精华的一级帮纸尿裤，就是经过这样严苛的安全和质量管控而生产的。</p>\n  <p>此外，海飞丝头皮健康检测仪能够高清可视化分析头皮状况，清晰度领先且结果可靠，并借人工智能算法定量分析健康参数；SK - II 肌肤光透镜可基于大数据多维分析肌肤，5 秒无接触精准捕捉状况。这些前沿科技设备，都是宝洁创新产品背后强有力的“推进器”。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_5027012e28b843299f9efaeca4afc7c8@5318352_oswg2857457oswg1707oswg1280_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">宝洁“智能仪器展示区”&nbsp;</p>\n  <h2><strong>创新向善，为现在和未来的世世代代创造美好生活</strong></h2>\n  <p>&nbsp;长久以来，宝洁都是可持续发展的先行者、践行者和倡导者。本届进博会上，宝洁公布了“使命2030”可持续发展目标全球最新进展，并发布三个方面的举措，展示宝洁不仅从自身做起，而且通过优质的产品和上下游协作，将可持续发展的理念传递给消费者和整个行业。</p>\n  <p>首先，宝洁致力于减少运营和供应链对环节的影响。宝洁的“净零2040”目标覆盖了宝洁的整体运营和供应链，并拆解落实到每一个地区、品类和运营部门。在中国，宝洁已经有7家工厂100%使用绿电，所有工厂实现废弃物0填埋。</p>\n  <p>其次，宝洁帮助消费者减少日常生活中对环境的影响。宝洁通过升级配方、改善产品包装等方式来减少排放，为消费者提供兼顾功效与环保的优质产品。今年多款环保创新产品亮相进博，包括去除炭黑，包装通体可回收的OLAY全新淡纹黑管家族；100%可回收纸盒包装、单片节约20%吸收材料的护舒宝液体卫生巾、减少75%废弃塑料和金属产生的吉列极光刀、生产制造工厂100%使用绿电，五年免费质保，倡导产品经久使用，99%包装可循环，废弃物0填埋。博朗9系巅峰版剃须刀等等。此外，还有宝洁Versa系列绿色电商包装三品齐发，线下绿色包装“即展”可重复使用PDQ（Products Display Quickly）展示箱全球首秀。</p>\n  <p>同时，宝洁也积极推动行业的协同创新来减少对环境的影响。宝洁所有创新包装均获专利认证，但全面向全行业开放共享。同时，宝洁也在和行业积极推进塑料包装的回收网络共建，于2012年启动“软塑新生”项目，联合行业提高塑料软包装的回收率。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_f2f381c49c914dafa275d14f6e334f73@5318352_oswg4270695oswg3163oswg2108_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">宝洁“环境可持续发展展区”</p>\n  <p>宝洁始终以服务好中国消费者为目标，不断升级五大核心优势，包括出色的产品、包装、品牌沟通、零售体验，客户和消费者价值，希望不仅带动自身业务发展，更能够携手零售商和上下游合作伙伴，实现共赢和价值创造，引领品类和市场的增长，从而带动中国消费品行业的发展。</p>\n  <p>未来，宝洁将继续坚守服务中国消费者的初心，以数字化和智能化等前沿科技为强劲“推进器”，持续提升创新的质量，同时携手行业一起挖掘和释放中国消费的巨大潜力，为中国消费者更加美好的生活做出贡献。</p>\n  <p>&nbsp;</p>\n  <h4>&nbsp;1 维他命原B5指泛醇</h4>\n  <h4>&nbsp;2 30倍浓度，指对比潘婷乳液修护润发精华素</h4>\n  <h4>&nbsp;3 指衰老细胞是造成纹路的根源之一，配方中的PHCA成分（羟基肉桂酸）能有效减少衰老细胞</h4>\n  <h4>&nbsp;4 指衰老细胞是造成纹路的根源之一，配方中的PHCA成分（羟基肉桂酸）能有效减少衰老细胞</h4>\n  <h4>&nbsp;5 指香精添加香柠檬果油（佛手柑精油），依兰花油（依兰精油），小豆蔻籽油&nbsp;（豆蔻精油），酸橙果皮油（甜橙精油），柠檬果皮油（柠檬精油）</h4>\n  <h4>&nbsp;6 数据来源于第三方100名消费者连续使用产品的测试效果，实际效果因人而异</h4>\n  <h4>&nbsp;7 首次指品牌内</h4>\n  <h4>&nbsp;8 首次指品牌内</h4>\n  <h4>&nbsp;9 至高指品牌内</h4>\n  <h4>&nbsp;10 至高指品牌内</h4>\n  <h4>&nbsp;11 SK-II特有成分名，是注册商标，由一种特殊酵母菌株专⻔发酵后获得的半乳糖酵母样菌发酵产物滤液</h4>\n  <h4>&nbsp;12 瓶颈期指受试者现有皮肤状态，此功效仅指&nbsp;SK-I1金缮匠心面霜</h4>\n  <h4>&nbsp;13 对比护舒宝普通卫生巾吸收材料</h4>\n  <h4>&nbsp;14 指博朗上海闵行工厂</h4>\n  <h4>&nbsp;15 对于2023年1月1日(含)之后购买博朗全系列剃须刀产品的消费者，至高提供五年免费质保服务。</h4>\n  <h4>&nbsp;16 产品外包装99%用纸质材料</h4>\n  <h4>&nbsp;17 博朗全球工厂实现废弃物0填埋</h4>", "published": "2024-11-07 10:36:58", "id": "9a08e292-92aa-401d-be8b-bab2bde9072a", "source": "36氪", "section": "文章资讯"}, {"title": "光线传媒11月7日缩量上涨1.31%", "link": "https://36kr.com/p/3026217720587781?f=rss", "description": "", "published": "2024-11-07 11:08:05", "id": "4299191a-f130-448b-a670-f90f17c3471b", "source": "36氪", "section": "文章资讯"}, {"title": "国中水务11月7日放量上涨4.88%", "link": "https://36kr.com/p/3026219253605634?f=rss", "description": "", "published": "2024-11-07 11:09:37", "id": "2a9902de-7f0f-41c4-8022-a1fe1d31cd91", "source": "36氪", "section": "文章资讯"}, {"title": "重庆钢铁11月7日放量上涨5.92%", "link": "https://36kr.com/p/3026172173886978?f=rss", "description": "", "published": "2024-11-07 10:21:45", "id": "6c27fdd5-0152-45d5-b8e0-382c95a45f47", "source": "36氪", "section": "文章资讯"}, {"title": "创始人被限高，每周关一家店，Seesaw的故事讲不下去了？", "link": "https://36kr.com/p/3026171225204226?f=rss", "description": "<p>又一个精品咖啡品牌陷入困境。</p>\n  <p>近日，茶咖观察发现，Seesaw Coffee（以下简称“Seesaw”）主体公司及其法定代表人、创始人吴晓梅被限高。</p>\n  <p>据上海市奉贤区人民法院10月29日向上海西舍电子商务有限公司（Seesaw主体公司，以下简称“上海西舍”）发出的限制消费令，法院于2024年10月16日立案执行申请人游仁信息科技（上海）有限公司申请执行服务合同纠纷一案，因上海西舍未按执行通知书指定的期间履行生效法律文书确定的给付义务，对上海西舍采取限制消费措施，限制单位及单位法定代表人吴晓梅不得实施高消费及非生活和工作必需的消费行为。</p>\n  <p><strong>换句话说，就是Seesaw欠了供应商的钱，导致公司及公司法人被限高。</strong></p>\n  <p>除了被限高，企查查显示，今年与Seesaw相关联的法律纠纷就有14起，其中涉及买卖合同、房屋租赁合同、侵害作品信息网络传播权等纠纷，部分法律诉讼已开庭审理。</p>\n  <p>今年3月，曾有媒体报道Seesaw疑似拖欠供应商货款，Seesaw相关工作人员澄清称消息不实，是“属于正常商业纠纷，不存在拖欠供应商货款的情况。”然而，从这次被限高，以及公司陷入多起法律纠纷的情况看，Seesaw所面临的经营挑战显而易见。</p>\n  <p>而且，Seesaw的门店数量也在不断下滑。据壹览商业此前统计，今年1月，Seesaw的门店存量为102家，而现在，这个数字变为76家，同时，今年Seesaw共开出了22家门店。这也意味着，今年以来，Seesaw关闭了48家门店，每周至少关1家店。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_fbce89d0619642eabc21d9dba34ddec2@5091053_oswg76273oswg1080oswg1034_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>而2021年，Seesaw创始人吴晓敏公开表示过，Seesaw要在未来五年将门店扩张至500-1000家，经历了三次融资，背后投资方包括百福控股、喜茶、黑蚁资本、基石资本等，总计融资金额超亿元，估值一度达10亿。</p>\n  <p>那么，是什么导致曾备受宠爱的Seesaw沦落到如此境地？</p>\n  <h2><strong>1 中国精品咖啡的代表品牌</strong></h2>\n  <p>精品咖啡爱好者们对于Seesaw这个品牌应该都不陌生。</p>\n  <p>2012年，Seesaw在上海成立，首店落地上海愚园路433号静安设计中心。当时，星巴克算是仅存的高端咖啡象征，本土连锁精品咖啡的发展，几乎处于空白的状态。是Seesaw将“精品咖啡豆”“手冲咖啡单品”等概念展现给了国内消费者，弥补了国内咖啡市场的空缺。</p>\n  <p>而且，由于Seesaw有完善的咖啡培训体系，一度吸引了非常多的咖啡从业者加入，也为行业培养了大批人才，因此，其也有着咖啡界的黄埔军校之称，进而奠定了它的行业地位。</p>\n  <p>这也吸引了资本的关注。2017年6月，Seesaw完成4500万元A轮融资，投资方为百福控股；在2021年7月，Seesaw完成A+轮过亿元融资，喜茶入股，老股东弘毅百福跟投；2022年2月，Seesaw再获A++轮数亿元融资，黑蚁资本领投，基石资本跟投。在完成三轮融资后，Seesaw的品牌估值达到10亿。</p>\n  <p>资本入局后，Seesaw也加快了扩张步伐。食品内参报道，2017—2021年间，品牌的门店总数从7家增至30余家，极海数据显示，到了2022年底，Seesaw的门店总数就超过了160家，一年时间新开超百家门店。</p>\n  <p>而后，Seesaw的门店增长就开始陷入停滞，始终未能破200家店，到了2023下半年，Seesaw开始关店调整，闭店近三分之一，现在仅剩70余家门店，门店数量几乎腰斩。</p>\n  <p>Seesaw的发展，更像是精品咖啡这个品类的缩影。</p>\n  <h2><strong>2 精品咖啡退潮</strong></h2>\n  <p>不只是Seesaw，还有不少精品咖啡品牌也面临着闭店困扰。今年8月，开业刚满半年的%Arabica上海丰盛里店关闭，皮爷咖啡绍兴银泰店关闭；10月，%Arabica布达拉宫店关闭；Lavazza拉瓦萨咖啡的门店数量由年初的125家下降至9月的108家……</p>\n  <p>除此以外，独立门店也在不断减少。2024年，象征“精品”的独立社区咖啡店首次在上海出现下降，在总店铺数量中的占比，由2023年的60.1%，下滑到了55%。</p>\n  <p>门店变化是了解一个餐饮品牌的重要指标，门店数量下滑能够在一定程度上反映品牌策略的变化，并体现经营状况的改变。那么，为何这么多精品咖啡品牌开始闭店了？</p>\n  <p><strong>首先，精品咖啡的变化与整个咖啡市场环境息息相关。近年来，中国的咖啡市场呈现出蓬勃发展的态势，竞争愈发白热化。</strong></p>\n  <p>“老大哥”星巴克不断下沉，最新财报显示新进入78个县级市场，门店数量突破8000家；瑞幸开出了20000家门店，在海外也开始扩张步伐；“搅局”的库迪也有超7000家店，还准备再开4万家店；打组合拳的Tims天好咖啡门店数量也已突破1000家……</p>\n  <p>越来越多的咖啡品牌涌入，疯狂攻城略地。这些品牌从一线城市往外延伸，或者抓住下沉市场，或者进攻医院、学校、高速这类特殊点位，打造出紧密的门店网络。随着市场的快速扩张，咖啡的“祛魅”现象日益明显，稀缺性不复存在，价格底线被不断打破，消费者的心理价位也随之重塑。</p>\n  <p><strong>但是，精品咖啡卖的不只是一杯饮品，还是咖啡背后所代表的价值与文化，对消费者的品鉴能力提出了一定的要求。</strong>他们的目标客户喝咖啡不只是为了提神，还追求不同咖啡豆带来的不同风味，对于咖啡的产地和历史有着浓厚的兴趣，愿意为这种体验和认同感而支付更高的价格。</p>\n  <p>这也就限制了精品咖啡的扩张步伐与选址点位。但一些精品咖啡品牌在前期的扩张过程中，可能过于乐观地估计了市场需求，因此，当面临高昂的运维成本和激烈的市场竞争时，不得不关闭部分门店。而且，随着瑞幸、库迪进军全国各个城市，普通消费者简单地将咖啡与9.9元画上等号，这就导致精品咖啡的生存空间越来越小。</p>\n  <p><strong>其次，不少精品咖啡品牌面临巨大的成本压力。</strong>它们的门店多位于一线商场或热门商圈，房租高昂；同时，装修风格独特，装修成本也不菲。这些前期的高成本增加了运营的难度。</p>\n  <p><strong>再者，高品质的咖啡依赖于咖啡师，</strong>而优秀的咖啡师数量少且难以复制，还有不少咖啡师有着“自己开店”的梦想，后期运营和管理的难度也在不断上升，随着连锁精品咖啡不断铺开，这一成本也会不断提高。</p>\n  <p><strong>最后，精品咖啡强调风味，对比普通的咖啡品牌，精品咖啡在咖啡豆层面有着更高的要求。</strong>但无论是国际市场还是中国市场，优秀咖啡豆的获取都面临着挑战。</p>\n  <p><strong>在国际市场上，</strong>优秀咖啡豆的产地往往被巨头批发商掌控，随着咖啡市场的火热，价格上涨难以避免。而且，“黑天鹅”事件也会影响到国际货源，如2021年巴西咖啡产区遇到百年一遇干旱，紧接其后的又是霜冻，这导致咖啡豆减产明显，价格一路飙升。而这种价格波动，很可能会让一些初创公司面临灭顶之灾。</p>\n  <p><strong>在中国市场上，</strong>优秀咖啡豆基本产于云南。相比于巴西和非洲等产区，云南咖啡豆没有关税和海运影响，这意味着更低的成本。</p>\n  <p>但云南的咖啡豆产量并不高。数据显示，2023年，云南省咖啡种植面积约达120万亩，生豆产量高达14.6万吨，但仅占全球面积的0.82%和产量的1.08%。&nbsp;而且，优质农场和精品豆更加稀缺。在大部分农场里，精品豆的产量可能不足全农场10%，&nbsp;这些头部农场中的精品豆，正是精品咖啡品牌争夺的焦点。</p>\n  <p>综上所述，精品咖啡需要文化氛围支撑，咖啡师也需满足用户情绪价值和社交需求，是一门特别重且难以规模化复制的圈层生意。</p>\n  <p>而且，现在的咖啡市场淘汰速度也不断加快，头部品牌的扩张步伐也开始放缓。据壹览商业不完全统计，但今年的二、三季度开店数量明显不及去年，且整体呈现下滑趋势，第三季度开店数量已经腰斩，同比下滑51.60%，环比下降6.71%。</p>\n  <p>不过，即便如此，精品咖啡也不是没有机会。经历了这些年的市场教育，中国消费者对咖啡的需求和品位在进阶。如今，越来越多的消费者学会了品鉴咖啡，对精品咖啡的需求也随之水涨船高，这也为精品咖啡们提供了发展契机，如蓝瓶咖啡、Grid Coffee等品牌都在不断扩张。</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/ZwDP0N8uj3eq1PqUzvRZJA\" rel=\"noopener noreferrer\" target=\"_blank\">“茶咖观察”</a>，作者：蒙嘉怡，编辑：木鱼，36氪经授权发布。</p>", "published": "2024-11-07 10:46:04", "id": "5b750f11-a0e6-461e-8924-51802a89e2dd", "source": "36氪", "section": "文章资讯"}, {"title": "塔塔汽车：“印度国民神车”如何炼成？", "link": "https://36kr.com/p/3026209025041672?f=rss", "description": "<p>刚刚过去的10月，“印度第一财团”塔塔集团前董事长拉坦·塔塔（Ratan Tata）与世长辞。</p>\n  <p>他曾因通过一系列跨国并购将印度最大的车企塔塔汽车（Tata Motors）推向世界舞台，而名满世界。</p>\n  <p>公开资料显示，印度公路上每10辆车里就有7辆出自塔塔汽车。塔塔汽车出产的小型轿车印迪卡（Indica）曾在上市短时间内接到超过11万订单，创下印度汽车史上的销售纪录。</p>\n  <p>2004年9月，塔塔汽车在纽约证券交易所IPO，成为印度汽车行业首家在美股上市的公司。此后，塔塔汽车因斥巨资将韩国大宇、英国路虎和捷豹等汽车品牌收至麾下，轰动全球汽车界。截至2024年秋，塔塔汽车的市值一度高达500亿美元，成为印度市值最高的车企，且几度晋级世界十大市值车企。</p>\n  <p>成立至今约80年的时间，塔塔汽车在印度犹如神话般的存在。那么，这家“印度国民车企”是如何炼成的？在全球新能源车企争霸的时代，塔塔汽车能否续写神话呢？</p>\n  <h2><strong>名列全球十大车企，印度国内一骑绝尘</strong></h2>\n  <p>2024年10月24日，一则捷豹路虎联合市场营销与售后服务机构（IMSS）裁员的消息在中国市场广为流传。据称，该公司的裁员比例或超过50%，市场部高级经理以上几乎都被裁，留下的高级经理则接受降级。</p>\n  <p>捷豹路虎这些外资豪车品牌在中国市场算是家喻户晓，但中国消费者对其上层的控股公司印度塔塔汽车或许鲜有耳闻。</p>\n  <p>2024年《财富》世界500强排行榜显示，塔塔汽车以536.349亿美元的营收规模排在第271位。与其名次接近的中国企业包括，排名267的中国远洋海运集团、排名277名的美的集团。</p>\n  <p>iFind资料显示，1945年成立之后，塔塔汽车最早于1955年8月在孟买证券交易所上市，之后其又于1998年在印度国家证券交易所主板挂牌，股票代码为TATAMOTORS.NS。2004年9月，塔塔汽车在纽交所主板IPO。</p>\n  <p>Wind显示，截至2024年一季度末，Tata Sons Private Limited持有塔塔汽车43.69%股份，为第一大股东，其���东阵营还包括印度人寿险、英国保诚、花旗集团、新加坡政府等国际知名投资机构。</p>\n  <p>2024年10月13日，塔塔汽车曾以412.39亿美元市值跻身世界十大车企，同时也是全球市值Top20车企中唯一一家印度车企（表1）。不过，截至2024年10月25日收盘，塔塔汽车总市值已缩水至374.77亿美元，被412.35亿美元市值的STELLANTIS挤出了世界十大车企阵营。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_8f12279432764ee18d7e54db728333cb@5091053_oswg238871oswg1080oswg552_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>参照表1估算，塔塔汽车的市值仅为特斯拉的5.92%、丰田的15.14%、比亚迪的34.64%。不过，这一市值的悬殊对比与塔塔汽车的低估值有关。塔塔汽车的市盈率仅有1.4倍，远低于特斯拉的56.17倍、比亚迪的26.68倍，位列全球Top10车企的极低值。</p>\n  <p>2023年年报数据显示，塔塔汽车的营业收入为415.89亿美元，排名全球第17位，同期，上汽集团为1044.43亿美元、比亚迪为851.2亿美元。资产规模方面，塔塔汽车以404.1亿美元排名全球第18位，同期，上汽集团为1421.48亿美元、比亚迪为959.45亿美元。</p>\n  <p>尽管塔塔汽车体量仅为比亚迪的一半，但塔塔汽车在印度国内乃是当之无愧的巨无霸，其市值在汽车板块堪称一骑绝尘（表2）。印度市值排名第二名的车企是1958年创立民营车企FORCE MOTORS，其市值仅有9.68亿美元。并且，印度国内其余8家上市车企市值总和仅有15.52亿美元，相当于塔塔汽车的3.76%。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_a1064126c7e447f8aa955cb012847057@5091053_oswg223005oswg1080oswg554_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>塔塔汽车与马恒达（Mahindra &amp; Mahindra），是印度本土仅有两家销售量过万的汽车公司之一。“印度公路上每10辆卡车里有7辆来自塔塔”，塔塔汽车在印度的风靡程度可见一斑。塔塔汽车在2023年年报称，其印度四轮电动汽车（EV）的市场份额也已超过70%。</p>\n  <p>早在1998年，塔塔汽车推出了首款在印度设计和制造的小型轿车——印迪卡（Indica）。这款斜背式超小型汽车因优雅、时尚的外观和低廉价格，在上市短时间内接到超过11万订单，一度创下印度汽车的销售神话。</p>\n  <p>2002年，以Indica为主体改款的轿车印迪戈（Indigo）正式推出，印迪卡和印迪戈两大品牌，一度占到印度中小汽车市场1/4的份额。</p>\n  <p>2009年3月，Nano在印度开始上市，整车售价仅为10万卢比（约1.36万元人民币），一举突破了中国奇瑞QQ、比亚迪F1低至3万元的价格极限，被称作“世界上最便宜的汽车”。不过，由于最初的安全问题和营销失误，这款车销量不佳，在推出10年后停产。</p>\n  <p>官方资料显示，塔塔汽车旗下包括生产商用车、乘用车、军车、中重型货车等产品，旗下员工队伍最高达到8.28万人。截至2024年一季度末，塔塔汽车实现营业收入525.35亿美元，净利润37.67亿美元，资产规模为444.66亿美元。</p>\n  <p>在普通民众仍以火车作为首选出行方式的印度，资本对汽车工业的关注度仍然较低，汽车走红或仍待时日。在这一国民文化环境下，塔塔汽车是如何维持80年长虹的？</p>\n  <h2><strong>后发制人：赶上重工业化时代，借德系车技术起步</strong></h2>\n  <p>1945年9月1日在印度孟买成立的塔塔工程与机动车公司（Tata Motors），这是塔塔汽车最初的模样。</p>\n  <p>在其之前，1942年，印度斯坦汽车公司（Hindustan Motors）正式成立，已成为印度本土第一家汽车公司。而紧接着Premier、马恒达也宣告建立。</p>\n  <p>可以说，塔塔汽车能在竞争激烈的印度能生存下来并脱颖而出，首先受益于母公司塔塔集团的显赫背景。</p>\n  <p>塔塔集团在印度的地位可堪比三星在韩国、李嘉诚在中国香港，其营收规模与中国移动相当、高于华为公司，约占印度GDP的6%、旗下总市值占印度股票市场的约7%，其业务涵盖能源、工程、汽车、通信、纺织、信息技术、材料、服务、消费、化工等领域。</p>\n  <p>塔塔集团在世界80多个国家和地区拥有约45.6万名员工，截至2024年3月31日，其营业额超过1680亿美元，旗下29家上市公司总市值达4030亿美元。</p>\n  <p>塔塔集团于1868年在印度孟买成立，其创始人贾姆谢特吉（Jamsetji Tata）与美国“钢铁大王”卡耐基、“石油大王”洛克菲勒、金融巨子J.P.摩根是同时代的商业巨擘。2021年胡润全球世纪慈善家榜单显示，贾姆塞特吉塔塔以6700亿元捐赠额成为最近100多年中全球捐赠价值最高的慈善家，远超比尔·盖茨与沃伦·巴菲特。</p>\n  <p>在“抵制英货，保护国货”的运动推动下，塔塔集团快速发展为印度当时最富有的家族。到20世纪30年代，该财团已传承至贾姆谢特吉的侄孙——贾罕吉·塔塔（JRD Tata）掌舵。</p>\n  <p>1940年代，印度开国总理尼赫鲁上台之后，政府大力执行社会主义化产业政策，同时以重工业化改革推动经济发展。</p>\n  <p>为了与尼赫鲁保持“良好的私交”，贾罕吉·塔塔毅然接下了助力国家加速实现重工业化的重任，塔塔集团宣布进军汽车工业，塔塔汽车正是在这一历史背景下诞生。比较来看，这一背景与日后朴正熙带领韩国实现“汉江奇迹”，财阀快速崛起的时代颇有几分相似。</p>\n  <p>彼时的印度，一方面奉行社会主义和贸易保护主义，国产的大使车成了那个年代的身份象征；另一方面又渴望利用外资打造本土汽车工业。</p>\n  <p>1947年之后，印度政府与私营部门开始建立本国汽车零部件制造业。同时，为保护本土汽车工业，政府又于1952年成立首个关税委员会。1954年，印度政府出台了“不许外国企业插足印度汽车工业，对整车及进口汽车零部件等实行高关税”等举措，以扶持本国汽车行业发展。</p>\n  <p>找不到商业机会的公司被迫迁出印度，这顺势给塔塔汽车腾出了成长空间。</p>\n  <p>1954年，塔塔汽车宣布与德国戴姆勒·奔驰合作，这成为其发展史上的里程碑事件。在奔驰的技术带动之下，到1969年，塔塔汽车已能够独立设计出自己的产品。</p>\n  <p>事实上，对于没有技术积淀的印度车企，引入外资合作办厂、用市场换技术或是其当时的最优路径。在塔塔汽车的带动效应之下，不少印度本土车企走上了“合资模式”。</p>\n  <p>1971年，马鲁蒂汽车正式成立，时任印度总理英迪拉·甘地（Indira Priyadarshini Gandhi）的次儿、时年25岁的桑贾伊·甘地（Sanjay Gandhi）出任该公司创始人兼总经理。</p>\n  <p>1980年6月，桑贾伊不幸坠机逝世。但此后在英迪拉·甘地的撮合之下，印度政府与日本铃木于1982年成立了合资公司——马鲁蒂铃木（Maruti Suzuki）。“铃木把日本的劳动文化移植到了印度。”</p>\n  <p>马鲁蒂铃木最终在1983年12月推出了售价仅5.25万卢比的马鲁蒂800。这款“人民的小汽车”销售火爆，交付上市两个月订单突破10万辆，市场份额最高时达76%。不仅如此，其之后推出的的马鲁蒂Gypsy也成为印度军警车市场的主力车型。如今的马鲁蒂铃木，已成为印度最大的车企之一。</p>\n  <p>粗略来看，印度车企的发展，隐隐有中国昔日的影子。而塔塔汽车早期的起步，既受益于塔塔集团的高举高打，也验证了印度汽车工业“后发制人”策略的成功。</p>\n  <h2><strong>上下通吃：研制世界最便宜汽车，收购英国高端品牌</strong></h2>\n  <p>塔塔汽车的强势崛起应从1990年代拉坦·塔塔的接班算起。</p>\n  <p>1991年，贾罕吉·塔塔的侄子拉坦·塔塔接任董事长，成为塔塔家族第四代掌门人。这位掌舵者天生聪慧、能力出众，先后毕业于美国康奈尔大学、哈佛大学，其通过一系列大刀阔斧的改革将塔塔汽车推向世界舞台。</p>\n  <p>事实上，当时的时代背景是，受1990年的海湾战争影响，印度爆发外汇危机继而引发严峻经济危机。时任印度总理纳拉辛哈·拉奥（Narasimha Rao）上位之后，开始推行自由化、私有化、全球化经济政策，私企、外企进入更多产业领域。</p>\n  <p>由于印度汽车行业降低准入门槛，取消股份比例限制，雷诺、福特、通用丰田、本田等车企相继入主印度。彼时，在习惯在印度国内吃“垄断饭”、受政策红利连年旱涝保收的塔塔集团瞬间遭遇到巨大挑战。</p>\n  <p>数据显示，2000-2001年，塔塔集团进入空前的低迷时期，损失了将近50亿卢比。换句话说，拉坦·塔塔彼时接班，颇有几分临危受命之意。</p>\n  <p>为抓住新一轮全球产业变革机遇、推动家族企业的脱胎换骨，拉坦·塔塔牵头对塔塔集团展开了一系列的改革重组，其喊出了“强化总部”的口号，通过强化中央集权解决企业多年扩张积累的“大企业病”。</p>\n  <p>在拉坦·塔塔的主导下，塔塔集团主动退出纺织、水泥等激烈竞争领域，同时强化在汽车市场的竞争力。在集团的统一布局之下，塔塔汽车一方面集中精力扩大其优势项目，推出一系列新产品，另一方面则借力资本运作，跨国并购英韩等车企品牌，大举向海外扩张。</p>\n  <p>公开资料显示，自1994年开始，塔塔汽车自主研发设计了一批“性价比”极高的面包车和微型车，Sumo、Indica、Indigo、Indigo Marina、Safari、Winger等新产品正好切中了印度当时市场的口味，很快在印度市场走红。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_215fd3be0da540ae93cdba5d755398e5@5091053_oswg274847oswg1080oswg565_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>为打破马恒达的垄断，塔塔汽车于1994年推出了一款新型越野车Sumo。相较于当时市面上还都是二战风格的马恒达Jeep，塔塔Sumo酷似奔驰G级的外观让印度消费者有了眼前一亮的感觉。加之其更强的动力及不俗的越野能力，Sumo一经问世就迅速打开了印度的公务车市场，成为军警单位的主力车型之一。</p>\n  <p>与主流车企聚焦赚富人群体的钱不同，塔塔汽车通过推出全球最低价产品、靠大量低收入者消费来刺激内需。面对竞争的激烈，塔塔汽车尝试以“欧洲车的质量，中国车的价格”的策略占领市场，为此，塔塔汽车提出了降低产品成本、研发新产品及提高售后服务等计划。</p>\n  <p>1998年，塔塔汽车推出了首款在印度设计和制造的小型轿车——印迪卡（Indica）。这款车在上市短时间内创下印度汽车的销售神话。而印迪卡是拉坦·塔塔亲自下场设计的产品。</p>\n  <p>2002年，塔塔汽车推出了以Indica为主体改款的轿车印迪戈（Indigo），印迪卡和印迪戈两大品牌，一度占到印度中小汽车市场1/4的份额。</p>\n  <p>2008年1月，塔塔汽车在新德里汽车展上发布的新款汽车——Nano。这款车没有空调、电动车窗和助力转向等配置可五人搭乘，被视作“专为穷人设计的汽车”，整车售价仅为10万卢比。在排量上，该车型的排量仅为0.62升，与摩托车的排量相当。</p>\n  <p>为压缩成本，Nano车的供应商从一开始就参与到设计过程中来。据悉，罗伯特·博世公司删除了其发动机控制模块1000个功能元件中的700个。在设计阶段中，印度的发动机组和汽缸头铸造商Rico公司对塔塔提出了有关发动机尺寸的建议。</p>\n  <p>塔塔工程师全程充满了控制成本的意识——为什么卡车每一个车轮都需要刹车片，或许只安装三块刹车片就够用了？空调、收音机等也都可以统统抛弃。而这些或也符合印度的安全法规。</p>\n  <p>另一边，2000年开始，印度政府通过新的外汇管理政策、放松境外投资限制之后，塔塔集团顶住亏损、加大杠杆开启了对外收购之路，其海外营收占比过半，成为全球化集团。2000年至2011年拉坦·塔塔暂时退休，塔塔汽车在进行了多项全球性的收购（表4）。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_70d979468e184e30a3bf34211ce6804c@5091053_oswg170661oswg1080oswg396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>2008年3月，塔塔汽车耗资23亿美元，收购了福特汽车旗下的英国高端汽车品牌捷豹、路虎，此举一度引发全球市场轰动。这也意味着，印度背景的塔塔汽车趁着英国经济的低潮期，完成了对英资品牌的反向收购。</p>\n  <p>通过前述并购手笔，塔塔汽车快速打开国际市场。2005年，塔塔就通过控制西班牙巴士制造和设计公司Hispano Carrocera S.A的21%股份，获取了西班牙的部分巴士市场，随后转向其他国家出口。</p>\n  <p>作为全球最重要的新兴市场，中国自然是塔塔汽车的战略布局重点。</p>\n  <p>2004年8月，塔塔汽车公司就与华晨控股签署了一项谅解备忘录，希望能将塔塔汽车引进中国。不过，两方合作未果之后，塔塔又与奇瑞接洽，但最后也不了了之。</p>\n  <p>2006年8月，塔塔公司在北京开设了一个办事处，由詹宏钰任中国区总裁。2007年1月，塔塔汽车零部件公司在南京投资1200万美元成立独资企业，专门从事汽车零部件的生产，向上海通用汽车和长安福特马自达供应塑料内饰件。</p>\n  <p>最终来看，收购捷豹和路虎成为塔塔汽车打开了中国市场的最关键项目。Wind资料显示，截至2024年一季度末，塔塔汽车旗下有109家参控股公司，其在中国境内有2家全资子公司Jaguar Land Rover (China) Investment Co Ltd、Shanghai Jaguar Land Rover Automotive Service Co. Ltd。</p>\n  <p>如今回头看，这位酷似韩国三星李健熙的掌舵者拉坦·塔塔，其一系列的资本运作不仅大幅扩张了公司规模体量，更奠定了塔塔汽车当下的基本盘。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_4977a0782e6142ad9ccfe91257ff7508@5091053_oswg252880oswg1080oswg731_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在捷豹路虎汽车的带动之下，塔塔的汽车畅销全球，其在美国市场的收入一度占比达到19.82%，而中国大陆市场最高为之贡献过17.85%的营业收入。</p>\n  <p>2020-2024年的数据显示（表5），塔塔汽车如今超过2/3的收入是由旗下的捷豹路虎汽车品牌贡献，其借力跨国并购开拓的中国、欧洲等市场，已占其营收规模的约半壁江山。</p>\n  <h2><strong>停滞不前：债务缠身，扩张之后积弊难消</strong></h2>\n  <p>连年高速扩张过后，塔塔汽车已手握完整的汽车业版图，旗下拥有商用车、轿车、豪华车等全车系产品，同时凭借比中国更为低廉的劳动力优势，在全球市场上继续攻城略地。据介绍，塔塔汽车已在肯尼亚建立大型客车制造厂，为肯尼亚、乌干达、坦桑尼亚、卢旺达、苏丹、埃塞俄比亚、布隆迪、马拉维和赞比亚在内的中部非洲市场提供服务。</p>\n  <p>2011年，拉坦·塔塔卸任塔塔集团董事长一职，从台前走向幕后，这成为塔塔汽车发展的一个转折点。</p>\n  <p>与传奇CEO杰克·韦尔奇（Jack Welch）相似，他选择了家族外的职业经理人——印度建筑大亨帕朗吉·米斯特里的次子塞勒斯·米斯特里（Cyrus Mistry）作为新任掌门。</p>\n  <p>米斯特里的接班与杰夫·伊梅尔特（Jeffrey R. Immelt）相似，其因补不上杰克·韦尔奇在推动GE高速发展时留下的“大窟窿”而下马。</p>\n  <p>在米斯特里看来，全球收购之后塔塔汽车已成为一个累积下巨额债务的草台班子，暴雷风险很大，其接班后一直试图将经营策略从全球扩张转向谨慎经营。</p>\n  <p>不过，其出售资产缓解债务的战略转向激起了老领导拉坦·塔塔及其他公司股东的不满。2016年10月，米斯特里被董事会拉下马，拉坦·塔塔复职临时主席。截至目前，钱德拉·塞卡兰（N Chandrasekaran）接任了塔塔汽车董事长。</p>\n  <p>Wind数据显示，2015-2023年，塔塔汽车的营业收入和资产规模连年保持在400亿美元上下的体量，徘徊不前，而同期的净利润规模从20.51亿美元逐年下滑，尤其2019年创下42.38亿美元的破纪录巨亏，直至2023年一季度才扭亏为盈。</p>\n  <p>同时，2015-2023年，塔塔汽车的资产负债率从70.69%持续上升至最高85.23%，同期，其销售净利润率一直维持在-9.76%至4.92%之间。其当时的处境，或许与暴雷前的中国恒大也相差无几。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_19ed3965d0e443c386778b96ae3e2550@5091053_oswg17347oswg1035oswg594_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>事实上，塔塔汽车的困境已在其扩张中埋下了伏笔。</p>\n  <p>拉坦·塔塔曾表示，“希望塔塔能成为国际品牌，但也希望塔塔能够呆在金字塔的最底层”。塔塔汽车通过Nano式产品抢占低端市场，同时依靠收购捷豹、路虎等奢华品牌占领高端市场，这种上下通吃的战略让塔塔汽车驾驭起来颇为疲惫。</p>\n  <p>公开资料显示，塔塔汽车在收购捷豹、路虎之时，不仅向银行借贷还在印度国内发行债券融资。这些杠杆操作折射出，塔塔汽车的实力并不如想象的雄厚。在宏观经济的复杂环境下，塔塔汽车不免陷入债务困境中。</p>\n  <p>有业内人士称，美国福特汽车都无法驾驭捷豹、路虎，塔塔汽车似乎也没有特别的禀赋。塔塔作为廉价低端汽车代表，甚至进一步导致消费者无法认可捷豹路虎的豪华属性，构成品牌和战略的冲突。这些持续烧钱的“无底洞”，无助于塔塔汽车在印度卖出更多汽车，其也难以指望从这些并购中获利。</p>\n  <p>总体来看，塔塔汽车最近一个年轮在着力消化前期并购积累的弊病，但债务缠身、利润微薄，公司规模体量在原地打转。管理层的动荡过后，塔塔汽车的处境更为艰难。2019-2023年期间，塔塔汽车遭遇了营收下滑、利润亏损，度过了颇为艰难的一段时光。</p>\n  <p>而在外部，最近10年，全球汽车市场的环境也早已今非昔比。</p>\n  <p>“寡头垄断、铃木独大、微车乐园”，券商如此概括印度车市。可如今，印度汽车消费市场已较早前升级，高收入群体和置换车主的比重在逐渐增加。“微型汽车消费市场正逐渐萎缩，难以引起众多整车厂的兴趣。”</p>\n  <p>受新冠肺炎疫情肆虐及俄乌冲突的影响，印度近年中低收入群体的工作不稳定，被迫消耗储蓄。同时，受原料价格、芯片短缺等市场因素影响，汽车价格上涨了三成，动摇了这些价格敏感人群的消费信心。</p>\n  <p>如同中国当初的微型车霸主奥拓、夏利逐渐衰落，中大型车和SUV逐渐崛起，塔塔汽车如何适应印度市场快速变化的市场需求，正构成其新的挑战。</p>\n  <h2><strong>电车时代：塔塔汽车能否持续引领印度市场？</strong></h2>\n  <p>长期“垂帘听政”的拉坦·塔塔去世之后，塔塔汽车的走势变得扑朔迷离。在全球新能源车企争霸的时代，塔塔汽车能否继续引领印度汽车市场发展，这成为投资者们当下的关切。</p>\n  <p>近年，塔塔汽车在新能源汽车市场大举布局且成效显著。公开资料显示，仅在2023财年，塔塔汽车就售出了6.42万辆电动汽车，较上一财年大涨了66%。</p>\n  <p>目前，为巩固领先的市场地位，塔塔汽车设定了宏伟的目标，包括在电动汽车与屋顶太阳能（RTS）之间建立协同效应，其目标是在2030年前将拥有屋顶太阳能的塔塔电动汽车用户比例从目前的“10%-15%”提高到50%。</p>\n  <p>到2030年，塔塔汽车计划通过推出iCNG Nexon等新产品，以及在2026财年前发布10款新型电动汽车，来进一步加强其在压缩天然气（CNG）和电动汽车领域的市场份额。</p>\n  <p>此外，塔塔汽车还与捷豹路虎合作开发高端纯电动Avinya车型，并利用EMA共享平台加速进入印度高端电动车市场。塔塔汽车旗下另一家子公司Agratas则专注于提高电池安全性并降低成本，为塔塔汽车提供电池技术优势。</p>\n  <p>2023年年报披露，塔塔汽车提出了“3Es”战略——扩张（Expansion）、电动汽车生态系统（EV Ecosystem）和电动汽车渠道（EV Channel），来推动电动汽车销售、支持印度的电气化进程。</p>\n  <p>塔塔汽车计划在2025财年前推出新产品Tata Curvv.ev和Harrier.ev，在2026财年推出Sierra.ev和Avinya。同时，其试图通过Acti.ev和EMA等平台来解决电动汽车的续航里程和技术等难点。</p>\n  <p>为提升电动汽车生态系统，塔塔汽车与ChargeZone、惠普、塔塔电力、巴拉特石油公司（BPCL）及壳牌等能源公司建立了常态化合作。</p>\n  <p>此外，塔塔汽车透露了将旗下乘用车业务拆分为印度本土电动汽车部门和捷豹路虎两个部分的计划，其或将印度本土业务和全球高端市场独立运作。业内人士称，此举或可挑战马鲁蒂铃木在印度市场的霸主地位。</p>\n  <p>事实上，汽车工业是塑造“印度制造”的重要一环，印度政府想趁着汽车电动化浪潮、传统技术革新换代之际，提振本土汽车产业链地位及制造业的技术水平，增强出口竞争力，解决国内就业问题。</p>\n  <p>2022年3月，时任印度工商部长的皮尤什·戈亚尔（Piyush Goyal）称，印度汽车工业价值超过1000亿美元，占印度GDP的2.3%。</p>\n  <p>印度前任的能源部长皮尤什·戈亚尔（Piyush Goyal）、交通部长加德卡里（Nitin Gadkari）接连对外喊出印度电动车计划，“2030年，路上开的都要是电动车。”</p>\n  <p>印度新能源汽车的雄心也一度吸引了特斯拉、比亚迪等外资车企的关注。</p>\n  <p>不过，印度汽车业在全球的产业分工链条上的不可替代性仍较弱。同时，印度政府持续对进口电动车征收高额关税，其将规模化生产、车型丰富、价格极具竞争力的外国车挡在门外，而国内生产的混合动力和纯电动车价格又一直居高不下。</p>\n  <p>生长在矛盾纠结的政策与市场环境之下，塔塔汽车如何顺势而为、再创佳绩，这或考验管理层的智慧。</p>\n  <p><strong>参考资料：</strong></p>\n  <p>[1] 张霖郁.终身未娶的塔塔集团前董事长去世.汽车商业评论.2024年</p>\n  <p>[2] 塔塔汽车-A：2023 Annual Report.Wind.2024年</p>\n  <p>[3] 塔塔汽车-A：2024 Q1 Report.Wind.2024年</p>\n  <p>[4] 程佳静.塔塔汽车：想要通吃不容易.上海经济.2012年</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/CEIgUo_fsFMHBAgn2LF7Vw\" rel=\"noopener noreferrer\" target=\"_blank\">“嘉宾商学”</a>，作者：杜冬东，36氪经授权发布。</p>", "published": "2024-11-07 11:12:48", "id": "5a5f3584-e003-45d2-81b8-f358e6460b46", "source": "36氪", "section": "文章资讯"}, {"title": "智飞生物11月7日放量上涨4.43%；智飞生物三季度营收首降 存货新高债务规模大", "link": "https://36kr.com/p/3026171704321286?f=rss", "description": "", "published": "2024-11-07 10:21:19", "id": "2f91a677-27a2-49c3-be5a-fbe596291bac", "source": "36氪", "section": "文章资讯"}, {"title": "常山北明11月7日放量下跌7.18%；常山北明高位股持续杀跌 十余股竞价跌停", "link": "https://36kr.com/p/3026216704534025?f=rss", "description": "", "published": "2024-11-07 11:07:09", "id": "23ff074f-5f20-45c6-8cb8-3798ff862191", "source": "36氪", "section": "文章资讯"}, {"title": "海尔智家11月7日缩量上涨1.92%；海尔智家回购115万H股并注销", "link": "https://36kr.com/p/3026184740136448?f=rss", "description": "", "published": "2024-11-07 10:34:43", "id": "1c3866f9-932d-4939-bbd1-3007e0c19780", "source": "36氪", "section": "文章资讯"}, {"title": "三峡水利11月7日放量上涨2.05%", "link": "https://36kr.com/p/3026170147628293?f=rss", "description": "", "published": "2024-11-07 10:19:40", "id": "96d010cc-3cfe-4248-af0b-b0b7df55bc0f", "source": "36氪", "section": "文章资讯"}, {"title": "三大电商开启包邮大战，去香港做快递机遇何在？", "link": "https://36kr.com/p/3026173912376840?f=rss", "description": "<p>双11大战渐入佳境，继淘宝、京东把中国香港纳入包邮区后，拼多多也出手了。</p>\n  <p>日前，拼多多宣布推出香港包邮服务，商家无需承担从集运中转仓至香港收货地址的二段运输费用，由平台进行补贴，试图吸引更多香港用户购物。</p>\n  <p>在物流拆墙的同时，老对手阿里、京东相继重金砸向香港市场。对比增速已经放缓的内地电商市场，<strong>香港电商市场增速处于高位，</strong>成为下一个兵家必争之地。无论是电商还是快递，想做好国际业务，香港市场是那扇必须推开的门。</p>\n  <h2><strong>01、</strong>赴港装备竞赛提速</h2>\n  <p>亿豹网发现，从去年双11开始，各巨头就对港澳市场不断加码。去年双11前，京东快递升级港澳地区时效，实现最快四小时送达，并提供送货上门及夜间派送等服务。物流升级后效果显著，今年京东618期间，港澳地区销量同比增长了300%。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_88e83bac81324ba98ab4d61c8d11a0ad@000000_oswg81332oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>阿里自然不甘落后。去年11月，淘宝香港站推出淘宝Plus服务，为指定商品提供满额包邮至香港的服务。进入今年10月，物流战进一步升级。淘宝在9月底官宣将投入10亿元上线“满99包邮香港”服务，到货时间也大幅缩短至3-4日。</p>\n  <p>京东同样迅速跟进宣布，将投入15亿元推出自营满299元送货上门服务，服务范围包括电子产品、家电家具、服饰美妆、宠物用品等自营全品类商品，最快可实现次日达。</p>\n  <p>跨境电商增势迅猛，<strong>快递企业也在力拼香港市场。</strong>10月30日，顺丰航空开通“鄂州往返香港”全货运航线，这是鄂州首条飞往香港的货运航线，链接两座世界级货运机场，为两地电商快件的运输渠道扩容提速。</p>\n  <p>此前，顺丰推出“深港半日达”服务，京东物流宣布在港开设多个运营中心，菜鸟也正式开通香港本地快递服务。到如今，拼多多也加入了这场物流战，各大平台为史上最长双11增大全球市场投入，国内存量厮杀中增长已现疲态的电商平台，谋求在香港找到新的增长点。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_a798b161951d416988a2427a3e73dc9b@000000_oswg69025oswg800oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>数据显示，2024年1月至7月期间，<strong>香港的网上销售占比均在10%以下，</strong>最高时也仅为8.5%。相比之下，据市场研究公司eMarketer的数据显示，2023年中国内地的电商渗透率已经高达47%。这一数据差距无疑为电商巨头们提供了广阔的想象空间和机遇。</p>\n  <p>不止于香港，双11前夕，菜鸟联合淘宝将境外包邮区扩至10站，涵盖新加坡、马来西亚、越南等地，包邮商品也从服饰逐步扩展到美妆母婴、3C数码、运动户外、家居潮玩、小家电等多个领域。</p>\n  <h2><strong>02、</strong>自提点周末开始营业</h2>\n  <p>长期以来，商家们要想将货物发往香港，有三种方式：官方集运、官方直送、商家或消费者自行寻找物流承运商运输，无论哪种方式，邮费都不低，而且售后及服务都无法保障。</p>\n  <p>各个巨头发力后，港人从内地电商平台购物的收货时间显著缩短。此前，从淘宝购买内地商品到香港需要3-10天的寄送时间，<strong>如今平均时效缩至3-4天，</strong>京东则最快次日达。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_8889c41314604368b6b9de4da49b50c6@000000_oswg32798oswg600oswg337_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>亿豹网了解到，以菜鸟铜锣湾摩理臣山道自提点为例，平时日均包裹量在400-500件，双11期间已飙升到600-700件。国家邮政局数据显示，1-9月，国际/港澳台快递业务量累计完成26.7亿件，同比增长24.9%。</p>\n  <p>香港快递行业同样面临人手紧缺的情况，上述自提点的一张招聘广告显示，菜鸟正在全港范围招聘驿站店务员、仓务、派货司机等。其中，驿站店务员负责自提点店铺日常运作，如包裹上架、帮助客人取件等，<strong>平均月薪为港币15K-16K。</strong></p>\n  <p>在香港，出于消费者工作繁忙、物业管理、保护隐私等缘故，很多快递没有办法送货上门。<strong>而快递到家则需要额外支付20港元起步的“宅配费”，</strong>因此大多数消费者会倾向于选择自提。</p>\n  <p>以菜鸟为例，在港目前布局超过1000个自提点（含自提柜），接近半数周末正常营业，极大地满足了消费者的不同时间需求。</p>\n  <p>以前香港的自提点周六和周日均不营业，周末要有两天时间休息，包括晚上可能七八点就已经下班。菜鸟通过建立奖惩机制，自提点实现了周末与夜间营业，普遍营业至21点，慢慢把站点的服务能力提升起来。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_da8300511b1549e798b4c82796761919@000000_oswg51668oswg751oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>与内地自助式驿站不同，香港菜鸟自提点的包裹取货区并不对消费者开放，而是根据货号，由工作人员帮忙取货。快递在自提点仅可免费存放三天，超时需要收取滞留费，每天10港元。</p>\n  <p>亿豹网认为，随着巨头的加码，香港快递正在迎来新一轮提效。不同于竞争白热化的内地，<strong>无论是末端网点、社区驿站，还是最后一公里派送，</strong>应该说香港的快递市场还充满着机遇。</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MzU3MzQ2OA==&amp;mid=2652795143&amp;idx=1&amp;sn=040883c50fab021a87185c419414a03a&amp;chksm=bc3efad2427476748c57000a06f6d45e240a1e1e6f0aa554d3413ad246f908750f73e44d5760&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“快递观察家”（ID：exobserver）</a>，作者：亿豹网，36氪经授权发布。</p>", "published": "2024-11-07 10:45:13", "id": "48211141-11ef-4fe5-9f48-98ea56e52b64", "source": "36氪", "section": "文章资讯"}, {"title": "这届年轻人选择“穷养自己，富养宠物”", "link": "https://36kr.com/p/3026155037160327?f=rss", "description": "<p>这届年轻人算是把“再苦不能苦孩子”这句话玩明白了。</p>\n  <p>磷虾、三文鱼、鹅肝、乳鸽....</p>\n  <p>你以为这些东西是年轻人买给自己吃的？非也，这些食材早就变成了宠物食品的配料，然后以动辄50元/斤的价格被年轻人追捧。 如果要用一句话概括这些年轻人的消费心理，那大概就是“我可以用黑色液体勺吃9.9的国潮外卖，但我的崽绝对不行。”</p>\n  <h2><strong>01 穷养自己 富养猫咪</strong></h2>\n  <p>《2023-2024年中国宠物行业白皮书（消费报告）》指出，我国在2023年的宠物犬数量为5175万只，宠物猫数量为6980万只。</p>\n  <p>在饲主画像层面，90后人群在2020-2023年间连续占比第一，且在2023年凭借46.6%的人群占比遥遥领先其他年龄群体，成为了名副其实的养宠主力军。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_1e118445bd3f4f64a3fd6b200401f4f3@5322854_oswg394428oswg734oswg475_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在宏观消费数据层面，我国2023年城镇宠物消费市场规模为2793亿，预计在2026年达到3613亿。</p>\n  <p>在微观消费数据层面，有85.24%受访者为宠物花过钱，46.9%的受访者经常为宠物购买玩具，44.3%的受访者曾为宠物支付高额医疗费，超70%的年轻人喜欢高消费养宠。</p>\n  <p>可以说在年轻一代成为养宠主力军后，社会上持有“人吃什么，宠物就吃什么”“养宠物只要给口饭，不养死就行”等观点的人群占比正快速下降。对年轻人而言，宠物更像是家人和朋友。自己不仅要让对方吃饱，还愿意付出更多的金钱、精力来提升毛孩子们的生活质量。</p>\n  <p>在这样的背景下，抖音话题科学养宠攻略、科学养宠的播放量分别超过了269亿、26亿，内容涵盖宠物食谱分享、宠物行为分析、宠物医疗科普等多个方向。而在更注重“仪式感”的小红书上，网友们则开辟了宠物生日这个新赛道。目前与宠物生日相关的笔记总量已经超过了55万篇，内容涵盖生日蛋糕、生日布置、拍照攻略等多个方向。</p>\n  <p>从注重科学饲养确保宠物健康，再到为宠物过生日强化情绪反馈。这些年轻人正在用行动打响“育婴式养宠”这个词的知名度，用钱包来推动宠物市场二次进化。</p>\n  <h2><strong>02 育婴式饲宠成了新商机</strong></h2>\n  <p>《2024—2025年中国宠物行业运行状况及消费市场监测报告》指出，我国在2023年的宠物经济产业规模为5928亿，预计在2028年增长到11500亿。</p>\n  <p>年轻养宠人高昂的消费欲望不仅促进了市场规模的增加，还促进了宠物市场的领域细分化。让原有的宠物食品、宠物用品、宠物医疗、宠物培训赛道释放出了宠物补剂、宠物智能硬件、宠物保险、宠物婚介等全新的子级赛道。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_401cb62b413640afacb6642ea9ac9484@5322854_oswg229582oswg691oswg404_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>拿宠物用品举个例子。</p>\n  <p>因为有人担心水质问题影响宠物的泌尿系统健康，所以市场上出现了有过滤系统的智能宠物饮水机；因为有人担心宠物上厕所后不卫生，所以市场上出现了有自动清理功能的智能宠物厕所；因为有人担心降温后宠物生病，所以市场上出现了有恒温系统智能宠物箱......</p>\n  <p>对众厂商而言，当下宠物市场的消费趋势已经发生了变化。作为饲宠主力的年轻人不仅消费欲望高，而且还清醒地明白自己想要什么。</p>\n  <p>这时如果有厂商想吃掉“育婴式饲宠”这波版本红利，那么最好的做法不是去搞营销也不是去打价格战，因为这样只能让自己陷入同质化竞争的泥潭。 去主动迎合年轻用户的需求，尝试在细分领域打出差异化优势才是更加明智的选择。</p>\n  <p>毕竟只要“年轻人把宠物当做孩子来养”这个前置条件存在一天，那大部分在人身上获得成功的商业创意就可以拿过来尝试一天。</p>\n  <h2><strong>03 爱是一切消费行为的起点</strong></h2>\n  <p>猫狗等常规宠物也罢，蜥蜴蜘蛛等小众异宠也好。为什么近年来身边养宠物的年轻人越来越多？为什么这些年轻人还总是把宠物当做家人看待？</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_99cb00f1e6f3436c9e1f4bf1f6d1b979@5322854_oswg339176oswg764oswg491_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>我想这个问题的答案可能就在“情绪价值”和“社交需求”的身上。</p>\n  <p>在年轻一代宠物饲主里，有很多人都是刚刚毕业的大学生。他们一个人住在出租屋里，不得不独自面对初入社会的不适感。这时候养一只小猫或是小狗，不仅能帮他们摆脱独居生活带来的孤独感，还为那些工作上的压力提供了宣泄口。</p>\n  <p>除了充当“心理安慰剂”外，宠物们还充当了“社交润滑剂”的作用。</p>\n  <p>社交媒体的存在放大了我们的社交需求，分享宠物照片、饲宠日常等行为除了更容易收到“赞”或“分享”外，还能够充当年轻人对话途中的话题，放大他们交友成功的几率。</p>\n  <p>除此以外，不同品种的宠物也是加入不同圈子的“门票”。人们可以在网上寻找和自己饲养同款宠物的网友并参与不同的宠物主题活动，借机获取集体归属感和身份认同感，就像那些买车后第一件事就是加入车友会的人一样。</p>\n  <p>年轻人投入精力和金钱，宠物用情绪价值反哺年轻人。</p>\n  <p>对这些孤独的饲主而言，是宠物的存在让他们重拾了对生活的掌控感，让他们在高压的环境下拥有了自己的避风港。</p>\n  <p>这种互相需要关系，也促使年轻人把毛孩子们当做了自己的家人，用投入更多金钱和精力的方式，为宠物谋求更好的生活环境。也许在围观者眼里，他们这种“自己节衣缩食，宠物满汉全席”的行为很不明智。但在养宠人眼里，爱不仅是这一切的出发点，更是宠物对自己最好的回报。</p>\n  <p><strong>参考</strong>：</p>\n  <p>电商在线：1小时卖超1.5亿元，富养“毛孩子”带飞它经济</p>\n  <p>泉州网：养己式养宠 年轻人情绪价值新代餐 小心“宠物依赖症”</p>\n  <p>商业数据派：消费降级的年轻人，让宠物先奔小康</p>\n  <p>大河网：花“Young”新经济丨市场规模有望过万亿 “宠物经济”何以拉动消费新引擎？</p>\n  <p>新京报：青年消费趋势⑤｜宠物生活“家人化” 超85%受访者为宠物花钱</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s?__biz=MzA5MTI5NDgxNA==&amp;tempkey=MTI5NV9JVlEreFB1Rkt0bDN2bDBKbmFPUWp0TTdMWXdEdUw2X1RVNFFlMkNPQS1IT20yRXlQbHhLWmozdFBEemVyczVDeXZQTlBURVhjWVRPZTFtWXpsS2ZfUWtwZXcwaXF6MjJhY1psUVAwX2NLNmJkZHNqZkIzb1FRVVZEZ1hqcU9jcXcyYTJnVkRIaVMxRjEzSUVadFpCQklOZWdsOURlckFZdVNtVUZnfn4%3D&amp;chksm=0afe11043d89981290bba720103950fa51f44a6ca660cddf664a517041d84a1e8a33c4726f00&amp;scene=0&amp;xtrack=1&amp;previewkey=KfFnGGhybQDvEfaRHhuGuZ1iJUUG%252F7eLf7OA%252FVEtaJE%253D&amp;subscene=7#wechat_redirect\" rel=\"noopener noreferrer\" target=\"_blank\">“互联网那些事”</a>，作者：互联网那些事，36氪经授权发布。</p>", "published": "2024-11-07 10:30:08", "id": "a3200a68-6823-459a-b3e0-349ed383c3dd", "source": "36氪", "section": "文章资讯"}, {"title": "士兰微11月7日缩量上涨0.37%；上交所发布并购重组典型案例汇编", "link": "https://36kr.com/p/3026188129330440?f=rss", "description": "", "published": "2024-11-07 10:38:05", "id": "f51c3ae0-d934-4b92-9171-98e3248e920a", "source": "36氪", "section": "文章资讯"}, {"title": "李书福的第10个IPO，要讲一个新故事", "link": "https://36kr.com/p/3026177183573251?f=rss", "description": "<p>今年4月，背靠吉利集团的网约车平台曹操出行，首次向港交所递交招股书，拟在香港主板上市。近日，曹操出行再次更新港交所招股书，向IPO发起了最后的冲刺，<strong>并有望成为吉利旗下第十家上市公司，也是在新出行领域的首家上市公司。</strong></p>\n  <p>此前吉利控股集团已经有吉利汽车、沃尔沃、极星、力帆科技、钱江摩托、亿咖通、汉马科技、路特斯、极氪等九家上市公司。</p>\n  <p>吉利的这些上市公司，绝大多数核心业务皆是与汽车制造业相关，曹操出行相对离制造最远。根据曹操出行招股书，<strong>曹操出行的定位是由吉利集团孵化的网约车平台，核心业务是提供全面出行服务。</strong></p>\n  <p>此前如祺出行、嘀嗒出行等网约车平台相继登陆港股，作为商业模式趋同的的曹操出行，要想讲好一个不同的故事，在资本市场中表现出众，并不是特别容易。</p>\n  <p>在招股书中，曹操出行开篇就提到了与吉利集团的战略合作以及对定制车的掌控。借此表达其核心价值在于，<strong>通过向司机提供低成本定制车，一方面承接吉利定制运营车市场，另一方面也为用户提供更具性价比的出行服务，并提前为未来的出行布局，在李书福的汽车生态之中扮演非常特殊的角色。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_478fa87c24d74f5485b24b4369a86a13@5091053_oswg58686oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2><strong>01 用定制车辆模式破解行业难题？</strong></h2>\n  <p>在招股书中曹操出行引用了一些数据，2023年，共享出行行业的市场规模是2821亿元，渗透率3.8%。同时考虑到私家车的用车成本和一些限制性用车问题，共享出行的市场会进一步攀升。到2028年，市场规模预计达到7513亿元，渗透率提高到7.3%。</p>\n  <p>尽管市场前景看好，但曹操出行提到了行业中的普通挑战：<strong>用户体验差，司机收入低，运营者成本高难赚钱。</strong>其中难赚钱这点，可以从从曹操出行这几年的营收利润情况看出来。</p>\n  <p>截至2023年12月31日止三个年度2021、2022、2023及2023、2024年前6个月，曹操出行的收入分别约为人民币71.53亿元、76.31亿元、106.68亿元、49.39亿元及61.6亿元，年复合增长率为22.13%，单从营收增长看还是不错的。</p>\n  <p>其中毛利分别约为人民币-17.47亿元、-3.39亿元、6.15亿元、1.6亿元及4.3亿元；净利润分别约为人民币-30.07亿元、-20.07亿元、-19.81亿元、-12.72亿元及-7.8亿元。</p>\n  <p>不过，从2023年开始，曹操出行毛利首次转正，净亏损连续两年收窄，2024年前6个月，公司毛利同比增长超160%，净亏损收窄51%。</p>\n  <p>对于毛利增长，曹操出行的解释是市场需求增长；<strong>定制车车队不断扩大，公司减少了司机及乘客补贴措施；通过AI优化订单分配效率，运营时长也有增加。</strong>从2022年到2024年上半年，定制车GTV（总交易额）占总GTV的5.3%、20.1%及26.4%。目前曹操出行拥有全国最大的定制车车队，覆盖83个城市，月活用户近2000万。</p>\n  <p><strong>“定制车能降低TCO（总拥车成本）……车辆能在60秒完成换电，大幅增加车辆运营时间，能增加司机收入。根据弗若斯特沙利文数据，与共享出行中的典型纯电车相比，我们的定制车平均TCO低36.4%。”</strong></p>\n  <p>从司机的层面来看，定制车的确是绑定司机的一种好方式。更低的TCO对冲了部分补贴，变相提升了司机收入。比如2022年司机平均每小时收入30.9元，2024年上半年增长至37.2元。而平均月司机留存率相对2022年的68.9%，有小幅提升，2023年为75.1%，2024年上半年为71.9%。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_c8fdf1eaccac40dfbc584a38ade699c5@5091053_oswg213375oswg1080oswg681_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>能看到曹操出行的商业逻辑是，<strong>通过换电的定制车辆，同时能够达成成本降低、司机收入提升以及利润提升，用户体验也更好，解决行业的几大问题。以此来表明这是一种能够跑通的、不同于行业中依靠于补贴来提升司机和用户黏性的独特的B2C商业模式。</strong></p>\n  <p>在曹操出行之后，享道出行、T3出行、如祺出行等等后来的网约车平台，都和曹操出行一样，选择从B2C模式开始。不过迄今为止网约车行业的绝对主导者，依旧是采用传统C2C且具有先发优势的滴滴。</p>\n  <h2><strong>02 与第三方聚合平台的关系愈发紧密</strong></h2>\n  <p><strong>从用户的角度来看，对于选择怎样的网约车品牌，是B2C还是C2C根本不在考虑范围，最主要是方便快捷以及低价。</strong>这也是此前网约车屡试不爽的获客手段，说到底就是低价补贴。</p>\n  <p>但补贴显然是不可持续的，所以对于新的获客方式，曹操出行提到一个很重要的点：<strong>从第三方聚合平台获得更多用户流量。</strong></p>\n  <p>根据招股书中的数据，2021年、2022年及2023年以及截至2024年6月30日止六個月，来自聚合平台的订单分别占整体GTV的43.8%、49.9%、73.2%及82.6%。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_335764d4806d411fa9496886f36c47d5@5091053_oswg222325oswg1080oswg594_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>聚合平台能够为网约车平台提供流量与场景上的支持，自然也要赚取网约车平台的服务费。从2021年到2023年，曹操出行付给聚合平台的佣金分别为2.77亿元、3.22亿元和6.67亿元，占整体销售及营销开支的54.7%、50.3%和79.7%。这无疑进一步压缩了曹操出行的盈利空间。</p>\n  <p>根据弗若斯特沙利文数据，2023年国内前五大网约车平台共占据90.6%的市场份额，其中滴滴拥有75.5%的市场份额，2023年GTV约达1924亿元，T3出行和曹操出行分布以158亿元和122亿元，位列第二和第三。</p>\n  <p><strong>曹操出行也意识到与第一名之间的鸿沟，既然短时间内撼动不了市场格局，就选择聚焦减少亏损，并集中优势资源在能快速增长的领域，早日实现盈利。</strong></p>\n  <p>所以在其招股书中，曹操出行明确，<strong>未来无论是在获客、订单甚至品牌经营，都会更多向第三方平台倾斜。</strong></p>\n  <p>对第三方聚合平台的依赖，如同一把双刃剑，虽然能迅速为曹操出行带来了大量用户和订单，但即便不考虑佣金的问题，<strong>从更长远的运营而言，也意味着曹操出行在逐步放弃其入口和主导的位置，网约车平台越来越像为聚合平台提供运力的供应商，在产业链中不断远离用户，往上游迁移。</strong></p>\n  <p>这种影响不仅是针对用户层面，同样针对司机层面的运营。而且网约车从聚合平台得到的订单越多，失去的用户和自有流量就越多，自有平台用户黏性就越弱。到最后，<strong>不仅仅是曹操出行，滴滴之外的所有网约车平台，似乎也只能选择更为强势的聚合平台，并且要尽量和平台建立更为稳定和长远的关系。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_a75f9bf1e3194687be7f08be6c287f78@5091053_oswg363738oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在招股书中，曹操出行提到“会通过AI驱动的「曹操大脑」，在不同的聚合平台策略性地分配运力，并动态调整派单和补贴实现运营优化。通过聚合平台促成的订单持续增加，提供有效的用户流量转化，同时留住忠实用户。由于我们与该平台建立的关系为未来持续合作奠定坚实基础，故我们认为此方法可行。”</p>\n  <p>如果说网约车行业上半场是滴滴、快的、T3出行、曹操出行等网约车之间的跑马圈地、兼并收购，那如今的下半场，就是在运力饱和、供大于求的市场环境下，流量聚合平台对网约车平台主导权的日渐蚕食，最终还是逃不过「得流量者得天下」的定律。</p>\n  <h2><strong>03 有一点不一样的新故事</strong></h2>\n  <p>和已经盈利的嘀嗒出行不同，一直亏损的如祺出行上市前，在招股书中花了很大的篇幅来描绘自动驾驶和Robotaxi所带来的新机遇。</p>\n  <p>如祺出行引用弗若斯特沙利文的数据，按2022年的交易额计，如祺出行是大湾区第二大出行服务平台，且在2022年推出了“全球首个开放性Robotaxi运营科技平台”，成为全球首个在混合运营模式下提供有人驾驶网约车与Robotaxi服务的出行服务平台，在Robotaxi商业化方面具有先发优势。</p>\n  <p>为推动Robotaxi的开发及商业化，如祺出行先后和广汽、文远知行、小马智行等达成了合作，引入L4级别以上自动驾驶，并引入了小马智行作为战略股东。当时如祺出行还因此被一些媒体称作「自动驾驶运营科技第一股」。</p>\n  <p>在不同赛道选手都在涌入Robotaxi的当下，曹操出行也讲了一个自动驾驶和Robotaxi的新故事。在招股书中，<strong>曹操出行提到一部分募集资金将用于自动驾驶的投资，推广自动驾驶开放平台，未来会部署前装量产的L4级自动驾驶系统的车辆，并推动Robotaxi计划。这都有望成为新的增长点。</strong></p>\n  <p>其实更早之前，曹操出行已经宣布过要进入自动驾驶领域，并且已经开始与自动驾驶技术公司元戎启行、小马智行，以及吉利等公司开始了对自动驾驶的研发和合作。</p>\n  <p>最近曹操出行CEO龚昕透露，<strong>曹操出行将在两年内推出完全定制化Robotaxi车型；同时，公司将构建覆盖全场景的自动化运营系统，应用将于2025年上线，2026年正式开放。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_69639cd775d04842b610b1be56ec311c@5091053_oswg578943oswg831oswg554_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在自动驾驶和Robotaxi之上，曹操出行还叠加了一个生态的故事。在四五年前，<strong>曹操出行就推出了其N立方战略，即New Car（定制车）、New Power（新能源）、New Ecosystem（生态体系），将车辆、能源和生态体系解决方案，一起打包进自己的竞争策略中。</strong></p>\n  <p>这一战略的背后当然是吉利。在招股书中，曹操出行很明确地提及了吉利集团能够带来的便利和支持。<strong>除了吉利的车辆硬件技术，还有吉利的智能驾驶技术，统一的车辆体系，完善的出行生态等等，也将有助于曹操出行在共享出行赛道的脱颖而出。</strong></p>\n  <p>当然，曹操出行的这个新故事并不是短期就能实现的，无论是自动驾驶、Robotaxi还是生态体系，都是超长跑，而这就要考验市场对曹操出行的预期了。</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/Hgvx8qkL2-taKBy4rujdGQ\" rel=\"noopener noreferrer\" target=\"_blank\">“车云”</a>，作者：Jaden，编辑：Cong，36氪经授权发布。</p>", "published": "2024-11-07 10:45:50", "id": "8e062116-ec0f-49de-a5b9-f937d8d1386c", "source": "36氪", "section": "文章资讯"}, {"title": "老牌国货蜂花玩梗营销翻车，丑化女性遭抵制?", "link": "https://36kr.com/p/3026191911990152?f=rss", "description": "<p>近日，有网友发现蜂花在社交平台上发布了题为《看清什么是真假闺蜜》的漫画，并质疑上述漫画内容刻意丑化女性。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_55a02f9a214140abb2c4168e614cda23@813924438_oswg588410oswg1080oswg537_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>从不温不火，“穷”的四处捡快递箱发货，到如今营销翻车，蜂花到底经历了什么?</p>\n  <h2><strong>热搜第一，蜂花玩梗营销翻车了?</strong></h2>\n  <p>近期，老牌国货“蜂花”官方账号在社交平台上转载了一幅漫画，漫画题为《看清什么是真假闺蜜》，内容运用了夸张对比手法，被网友质疑丑化女性。随后，“蜂花 真假闺蜜”等多条话题冲上热搜。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_6a6330db546449bd9785ea3600e06d2a@813924438_oswg76217oswg619oswg441_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>蜂花这则漫画一共七张图片，其中争议最大的是第一张，漫画中展现了一女子在闺蜜男朋友面前“搔首弄姿”，被闺蜜吐槽：“是个男的就往上贴”。许多网友认为该漫画内容不当，涉嫌丑化女性形象，纷纷给蜂花留言，要求品牌道歉。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_7c2fc50ac3754363a51c8b9003cfcf86@813924438_oswg324069oswg769oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>面对舆论压力，11月7日午间，蜂花官方账号发布了道歉声明。蜂花表示，此次事件充分暴露出我们在内容把控以及审核流程方面存在严重漏洞。我们已经第一时间启动了全面的整改程序，目前不当图文已删除，并严肃整顿该账号的运营。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_cdfadfa98d9640f69e8d4b0f988c037e@813924438_oswg332045oswg960oswg889_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>尽管蜂花已发表道歉并承诺内部处理，但这次事件仍对其品牌形象造成了影响。部分网友对蜂花的道歉依旧表示不满，并直言“拉黑了，不会再买被刺女性的产品”，但也有部分网友认为，这是针对绿茶的呼吁网友不要太敏感。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_04875bbabced4687becb9b8d25f218dd@813924438_oswg74310oswg729oswg204_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>科技旋涡认为，此次事件对蜂花的品牌形象造成了一定的影响，作为一个有着近四十年历史的老国货品牌，蜂花需要在宣传营销方面把控好尺度问题。</p>\n  <h2><strong>泼天的富贵是一时，但蜂花想要永久</strong></h2>\n  <p>据蜂花官网介绍，上海蜂花日用品有限公司创建于1985年，是一家集设计、研发、生产、销售于一体的洗护发专业企业，主要生产“蜂花”牌洗发水、护发素，以及护肤、清洁系列用品。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_6d6bb28dbe904a8f8309bfe45a606e29@813924438_oswg731786oswg800oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在当年，蜂花和许多“老字号”一样,也面临着市场上同类产品的激烈竞争。从90年代中期开始,随着一些外资合资品牌“攻城略地”,推出一系列洗护“二合一”产品;加上超市等新业态的出现,蜂花原有的全国各地批发市场“大批发大流通”的销售渠道被挤压，这使得其销量一度大幅度滑坡,甚至面临亏损。此后蜂花虽然通过一系列举措稳步发展，但在大众视野里却名声不显。</p>\n  <p>直到2021年，蜂花频频登上热搜，才开始成为网友热议的焦点。2021年11月，面对倒闭传闻，蜂花迅速回应，凭借36年无任何处罚记录的清白家底，赢得了大量网友的同情与支持，掀起了一波“野性消费”浪潮。同年8月，蜂花正式进军抖音直播带货，仅数月后，其抖音销售额便突破千万，翻了数倍，展现了强大的市场号召力。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_e33d918fceb641bba71244d82ef0e5d7@813924438_oswg188409oswg717oswg537_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>2022年，5月，一则“董事长含泪直播”的假消息再次将其推上风口浪尖，尽管随后澄清，但这一波操作无疑加深了消费者对品牌的关注与记忆。</p>\n  <p>2023年九月份，老牌国货“蜂花”走红网络，不仅两天涨粉79万，产品更是卖断了货。其凭借“79元5斤半”的极致性价比打了一场“朴实的商战”这与国潮机遇以及其营销手段离不开关系。据统计，活动期间，蜂花相关关键词搜索量同比增长14倍，用户访问量更是暴增260%，洗发护发商品成交额同比增长超3倍，单日直播GMV破千万，堪称“借势营销”的经典案例。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_5a22c1354eb84330b49dfd9d8fafcbaf@813924438_oswg730212oswg1080oswg929_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>另外，蜂花还曾因为“穷到捡纸箱”而爆火网络。此前，蜂花因为自家的外包装箱不够了，就用了其他品牌的箱子给消费者发货了。结果，网友收到货后都懵了，纷纷吐槽：一个大老爷们从小姐姐手里接过一箱“七度空间”，想想就很社死!</p>\n  <p>在日本排放核污水消息爆出后，有网友在蜂花官方账号问了句：“你家有日本原料吗?”还没等蜂花官方反应过来，蜂花粉丝就帮着回了句：“他进不起，哈哈哈哈哈哈哈哈”，因为穷到进不起进口原料，蜂花被整整嘲笑了3天。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_c9392861392e47739978551193a60ed5@813924438_oswg266071oswg1080oswg492_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>纵观蜂花近些年的崛起，有很多的所谓大动作似乎都是在发生社会热点后，蜂花紧随其后所做出的“回应”，而不是蜂花精心策划的“事件”。但是蜂花总是能在热点发生后，迅速作出反应，并且将热点的热度“独揽”一部分流量到自己的品牌社交圈中。</p>\n  <p>科技旋涡认为，互联网营销有时Get对了点就是泼天的富贵，Get错了就可能起到反效果。如今国货浪潮已然褪去，蜂花也深知自己需要增强营销能力才能保住这泼天的富贵，但这次“闺蜜和敌蜜”事件，显然是步子迈得太大，险些翻车。</p>\n  <h2><strong>国货营销宁愿犯错，也不愿什么都不做</strong></h2>\n  <p>面对日益激烈的市场竞争，众多国产品牌为了在市场中脱颖而出，纷纷探索并采用各种创新的营销策略。从紧跟热点趋势到巧妙运用网络梗文化，虽然偶有翻车，但也为自己开辟出一片新的天地。</p>\n  <p>椰树集团经常走在被罚的前线，多次因另类营销冲上热搜，被处以罚款，原因大多绕不开被质疑低俗广告、争议宣传。但换来的是2023年，全年总销量70万吨，同比增长10.26%;销售额50亿元，同比增长3.08%;上缴税金6.82亿元，同比增长15.39%。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_cc1fef998a1d46b7a8ae50be8b9cf011@813924438_oswg832889oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>此前，两个国货彩妆品牌——FLORTTE花洛莉亚和HYNTOOR黑兔也因涉嫌低俗营销，引发舆论危机。花洛莉亚小蝴蝶结系列成膜唇蜜，其唇蜜刷头的形状设计易引发其他联想。在黑兔一款云朵双色提亮膏的争议海报中，产品被设计成置于两只粉红色气球的中央，被指恶俗擦边。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_dcfae30afd9345d7be0bb0c43aa9f981@813924438_oswg550301oswg1080oswg609_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>去年5月，一家名为五个女博士的企业投放的一则电梯广告引发争议，被网友质疑制造容貌年龄焦虑、侮辱女性。但也迅速实现黑红，吸引了大量的关注。不过在收获流量的同时，这则广告在网上引发了争议，甚至是相关部门的介入。最终，北京市朝阳区市场监管局责令，当事人停止发布相关广告，并处罚款40万元。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_89634c6d6aa54437a7ce45c6078c34c8@813924438_oswg443087oswg1080oswg460_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>去年，某企领导牵手门事件引发外界关注。抖音“格力官方旗舰店”女主播在直播卖货时，身穿此前引发网络热议的某企高管牵手门的同款“免职裙”。事发时直播间网友纷纷发弹幕吐槽“格力变low了”、“不应该用小三裙博眼球”、“换衣服”……随着矛盾激化，格力主播穿免职裙的事件甚至冲上了微博热搜。对此，格力官方回复称：公司并不支持，该主播属于外包团队，是她的个人行为。但是客观来说，的确损伤了品牌在路人心中的印象。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_d1ce2a4fbc004e4cabe14bcfc9244a72@813924438_oswg877073oswg975oswg549_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>科技旋涡认为，国货趋向于年轻化的营销方式展现了它们对于增强自身宣传与营销能力的迫切需求，也体现了国货品牌寻求突破、积极进取的态度。虽然更新自己的产品和营销方式，确实是“救亡图存”的上佳选择，但其中尺度过大的风险仍旧不可忽视。</p>\n  <h2><strong>写在最后</strong></h2>\n  <p>消费者早已不满足于产品好用便宜这样简单的诉求，他们更在意品牌背后的价值观。当国货的行为与大众认知的价值观产生偏差时,信任就会崩塌。</p>\n  <p>国货的翻红，不仅仅是产品质量的胜利，更是品牌理念的胜利。品牌要想保持住热度，需要的是稳中求进的宣传营销方式，而非一味追求曝光量就忽视主流价值观。</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/wy8VV-Xrru1wpSiRvLl7-Q\" rel=\"noopener noreferrer\" target=\"_blank\">“科技旋涡”</a>，作者：元时文化 孙浩南，36氪经授权发布。</p>", "published": "2024-11-07 11:13:27", "id": "9ad16a25-a0f3-4036-a353-2c564bf62544", "source": "36氪", "section": "文章资讯"}, {"title": "沃尔玛或要复制山姆的“前置仓”模式开小店", "link": "https://36kr.com/p/3026188606187009?f=rss", "description": "<p>11月6日，据《联商网》报道，沃尔玛或在深圳和云南开始进行小店模型测试，这些小店可能会借鉴和模仿山姆云仓的形式，以沃尔玛大店为依托，优选品项，以前置仓的模式拓展线上业务。11月7日，界面新闻就此向沃尔玛方面求证，暂未获得回应。</p>\n  <p>事实上，沃尔玛在2018年曾尝试社区店小店模式，三年间在广州、深圳等地开设了10家左右的“社区店”，但到2021年关停了这一业态。</p>\n  <p>上述报道中沃尔玛的小店形式，大概率是前置仓模式，尽管眼下没有哪家大卖场涉足前置仓模式，但沃尔玛公司旗下的会员店品牌山姆已经把这一模式玩得熟练。</p>\n  <p>自2018年起，山姆开始实施“门店+云仓”模式，实现了多城市全覆盖。目前，山姆在全国范围内拥有近500个前置仓，每个仓库的日均订单量约为1000单，客单价超过200元。根据山姆推出的便捷电商配送服务，会员可通过山姆APP享受“极速达”、“全城配”及“全国配”等多种配送选项，实现线上下单、快速送达的便捷购物体验。</p>\n  <p>这些前置仓，依托山姆门店，已经连续多年为沃尔玛带来了业绩回报。</p>\n  <p>8月15日，沃尔玛公布了2025财年第二季度业绩。具体到中国市场，该季度净销售额为46亿美元，同比增长17.7%，增幅连续两年持续扩大，其中电商业务净销售额增长23%。在销售方面，山姆会员商店和线上业务持续加强，电子商务渗透率达49%，与去年同期相比增长超过200个基点。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_bc0b97f146914487be8f53210479a0b6@5091053_oswg96710oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图片来源：界面图库</p>\n  <p>与之相反的是，过去5年，沃尔玛中国的门店数量持续下滑，过往财年数据显示，沃尔玛在中国的门店数量从2020财年的412家已经滑落至2024财年（截止到2024年1月31日）的296家，5年时间门店数量减少116家。</p>\n  <p>每个财年，沃尔玛在中国的业绩的负增长都靠另一个业态山姆填平。沃尔玛财报多次表述，中国业绩的拉动主要来自山姆和电商业务。</p>\n  <p>这与中国大卖场受到线下客流萎缩、商品同质化所致的整体萧条相关，上市零售公司也普遍遭遇亏损，永辉超市（SH:601933）2023年归母净利润-13.2亿元，大润发母公司高鑫零售（HK:06808）2023财年营业收入836亿元，净利润则为1.09亿元。</p>\n  <p>为了改善亏损现状，大卖场纷纷进入调整升级阶段。今年1月，向外宣布，全国首批8城29家大卖场门店完成升级，升级动作包括通过商品方面更细分的运营、折扣化策略，以及售卖渠道拓展到全渠道的方式，逐步恢复此前的运转。</p>\n  <p>今年6月，沃尔玛也被爆出有探索其他零售生态的可能，零售自媒体《商业观察家》报道，沃尔玛近期在筹划做一个面向三线市场的新业态，该业态将“放弃”以生鲜为主要引流品类来做超市的思路，与山姆会员店会有互补，借助山姆已有的供应链，做更小包装的商品。</p>\n  <p>彼时沃尔玛对此向界面新闻回应，上述消息不实。</p>\n  <p>如果此次沃尔玛选择试水前置仓模式，很可能是看到了前置仓的玩家们最近向好的业绩。以专做前置仓的叮咚买菜为例，其前置仓通常位于人口密集的社区附近，通过研发具有差异化的爆品（自营预制菜、时令食品等）和较低的配送门槛获取线上客户，为了保障30分钟以内的配送时效，叮咚买菜的做法是将商品会提前放到相应的仓库里，消费者下单后，商品从最近的仓库里配送，以缩短配送时间。</p>\n  <p>尽管早期这一模式因为成本高昂，致使叮咚买菜连年亏损，但近两年随着线上下单人群增多以及关停亏损城市网点，叮咚买菜迎来盈利。最新的2024年第三季度财报显示，叮咚买菜GMV为72.7亿元，同比增长28.3%，营收为65.38亿元，同比增长27.2%。在Non-GAAP（非公认会计准则）口径下的净利润为1.61亿元，同比增长超9倍。叮咚买菜预计，第四季度也将实现可观的同比增长。</p>\n  <p>此外，美团小象超市、山姆云仓、朴朴超市都是前置仓玩家当中的佼佼者。</p>\n  <p>借助山姆的经验，沃尔玛涉足前置仓的逻辑便成立了，但挑战在于，山姆的商品品质和稳定的会员群体，本身在山姆会员商店就得到了验证，而沃尔玛前置仓需要从一众前置仓玩家中走出，具有差异化的商品力、供应链逻辑，以及如何在这一渠道上显示出后发优势并不容易。</p>\n  <p>本文来自<a href=\"https://www.jiemian.com/article/11955274.html\" rel=\"noopener noreferrer\" target=\"_blank\">“界面新闻”</a>，记者：赵晓娟，编辑：牙韩翔，36氪经授权发布。</p>", "published": "2024-11-07 10:42:19", "id": "85927bfc-5abc-41d3-8766-41891ef99375", "source": "36氪", "section": "文章资讯"}, {"title": "周鸿祎投的新造车也扛不住了，被曝大规模裁员，上千名员工或降薪", "link": "https://36kr.com/p/3026210610013447?f=rss", "description": "<p>被传裁员降薪，哪吒汽车陷入困境。&nbsp;</p>\n  <p>车东西11月7日消息，据财联社记者从多个独立信源处获悉，哪吒汽车启动大规模裁员，比例最高或达到70%。&nbsp;</p>\n  <p>报道中还显示，有哪吒汽车内部人士表示：“正在分部门沟通，各部门有差异，总体比例没那么高”。&nbsp;</p>\n  <p>对此， 哪吒汽车向媒体予以否认，官方回应表示，公司正在通过精简业务、聚焦核心、组织优化和薪酬绩效改革等措施，构建更集中高效的组织架构。&nbsp;</p>\n  <p>但是从官方的回应来看，哪吒汽车的裁员与降薪应该是确认的，只是具体比例没有透露。&nbsp;</p>\n  <p>而近日，有哪吒内部员工向媒体透露，哪吒开始实施面向全部研发人员的降薪计划，各部门员工已陆续收到降薪通知，涉及的员工约一千多人。&nbsp;</p>\n  <p>有自称哪吒汽车员工的网友在社交媒体上发帖表示，哪吒汽车此次降薪幅度按梯度划分，年薪100万元以上的员工降薪30%，年薪50万元至100万元降薪20%，年薪30万元至50万元降薪10%，年薪30万元以下的员工降薪5%。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_fc9eb36eaea34632abb0fa86b9a082cd@5091053_oswg142316oswg1000oswg616_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">▲网传哪吒汽车降薪比例</p>\n  <p>对此，哪吒汽车向媒体回应称，哪吒正式启动公司全员股权激励计划，将拿出5%的股份（估值约20亿元），作为股权激励分配给全体员工，还在内部宣布了工资及绩效考核的新方案。&nbsp;</p>\n  <p>同时，哪吒汽车也在回应中强调，在“金九银十”汽车消费旺季，哪吒超额完成了销售任务，目前手持订单充足，公司内部经营生产一切正常，日常工作有序开展中，正在积极向用户交付新车。&nbsp;</p>\n  <p>但是截至目前，哪吒汽车还未公布10月销量，而哪吒汽车CEO的社交媒体官方账号也已经有近1个月没有更新。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_6f3eca34094b4e75b5054b77e245b535@5091053_oswg487800oswg1000oswg844_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">▲哪吒汽车CEO社交媒体官方账号</p>\n  <h2><strong>01.此前被传降薪 最大降幅30%</strong></h2>\n  <p>根据媒体报道，有哪吒汽车员工称，其在10月29日接到了领导的口头通知降薪和降薪比例，而哪吒汽车提到的股权激励，是看媒体报道后才知道。&nbsp;</p>\n  <p>该员工还强调，除了口头通知外，目前没有收到任何书面通知，也没有签订新的劳动合同和股权激励合同。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_0bea96b141a34195ae26862f1d436993@5091053_oswg365635oswg1000oswg1605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">▲网传哪吒汽车降薪为口头通知</p>\n  <p>此外，有哪吒汽车员工表示，除了上文提到的降薪方案，如果员工工资仍比“ 岗位工资 ”高的话，要再降10% ，该员工表示此前根本没有听说过“ 岗位工资 ” 的说法。&nbsp;</p>\n  <p>还有哪吒汽车员工表示，哪吒汽车此前一般是在每月15日发放上月薪资，但在10月16日，有员工表示收到了哪吒汽车发布的工资延迟发放的群发短信。&nbsp;</p>\n  <p>根据短信中的内容，哪吒汽车将部分员工的薪资先按照50%发放，剩余部分待方案通过之后补发。&nbsp;</p>\n  <p>还有消息称哪吒内部已经建立了多个讨薪维权群，将在11月15日观察公司是否会正常发薪，据传已有哪吒汽车员工已经在找律师准备维权。&nbsp;</p>\n  <p>对此有媒体向哪吒汽车询问具体情况，哪吒汽车相关负责人向该媒体介绍，各部门领导有接到调薪比例的书面文件，因为各部门不同，所以暂时没有全员发放。&nbsp;</p>\n  <p>“HR部门正在陆续签订新的合同，具体到各部门的进度会有不同。股权激励的协议则是在谈好薪资之后再另签。”自称哪吒汽车员工向媒体表示。&nbsp;</p>\n  <h2><strong>02.曾为新势力车企年交付量第一，IPO前估值超450亿元</strong></h2>\n  <p>根据此前的数据，哪吒汽车2022年累计交付15.2073万辆，同比增长118%，实现了15万辆的既定目标，同时成为了当年的新势力车企交付量第一。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_5e24be8460094721bf05e8d42fe79af2@5091053_oswg423534oswg1000oswg584_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">▲哪吒汽车2022年累计交付15.2073万辆</p>\n  <p>然而在2023年，哪吒汽车累计交付12.7496万辆汽车，同比下滑约16%。&nbsp;</p>\n  <p>在2024年，根据哪吒汽车发布数据显示，哪吒汽车9月全系整车交付10118辆，与8月交付的11005辆相比略有下滑。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_41a9f3b3f49f44f9a96b3d658a8a8004@5091053_oswg215967oswg1000oswg788_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">▲哪吒汽车9月全系整车交付10118辆</p>\n  <p>同时哪吒汽车前9个月交付量为8.59万辆，同比下降12.13%，前9个月仅完成了全年30万交付目标的约28.6%。&nbsp;</p>\n  <p>销量情况不断下滑的哪吒汽车，选择了用上市的方法筹集资金来自救，今年6月26日，哪吒汽车主体合众新能源汽车向港交所递交上市申请。&nbsp;</p>\n  <p>7月10日，中国证监会接收其上市备案申请，而按照规定，IPO批准有效期为6个月。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_61301d76f2cf40d0957d130b61b7f6e8@5091053_oswg438492oswg1000oswg1081_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">▲哪吒汽车主体合众新能源汽车IPO文件</p>\n  <p>根据哪吒汽车主体合众新能源汽车的招股书中显示，自2017年以来，合众新能源共完成10轮融资，融资总额达228.44亿元，股东包括了宁德时代和360集团等企业。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_8149824aa81846ce9b3d0362c9dbc344@5091053_oswg82325oswg1000oswg299_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">▲宁德时代对哪吒汽车主体合众新能源汽车投资</p>\n  <p>在最后一轮融资里，其每股价格为16.15元，总股本为28.37亿元，IPO前估值超过450亿元。&nbsp;</p>\n  <p>同时根据招股��显示，2021年至2023年，其净亏损分别为48.40亿、66.66亿、68.67亿元，三年累计亏损183.73亿。&nbsp;</p>\n  <p>而在近日，哪吒汽车主体合众新能源香港主板代码变更，此前临时代码为810613，名称为合众新能源，变更后正式代码为H1940，名称为合众汽车。&nbsp;</p>\n  <p>有媒体关于此事询问哪吒汽车，哪吒汽车相关人士表示不予置评。&nbsp;</p>\n  <p>至于上市带来的资金能否拯救近期频繁被传出裁员和降薪的哪吒汽车，甚至降薪等事件是否会影响哪吒汽车上市计划，还需要时间来观察。&nbsp;</p>\n  <h2><strong>03.结语：哪吒汽车降薪裁员自救</strong></h2>\n  <p>总的来看，哪吒汽车近期面临一系列挑战，包括裁员和降薪的传闻，以及组织架构的调整。&nbsp;</p>\n  <p>尽管公司启动了全员股权激励计划，并强调在汽车消费旺季超额完成了销售任务，但实际销量的下滑仍是不容忽视的问题。&nbsp;</p>\n  <p>哪吒汽车正在通过上市筹集资金以自救，但上市带来的资金是否能够解决当前的困境，以及降薪等事件是否会影响其上市计划，这些问题仍需时间来揭晓答案。&nbsp;</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/WHHdStDLnBq0TN4oIGsGCA\" rel=\"noopener noreferrer\" target=\"_blank\">“车东西”</a>，作者：R，编辑：志豪，36氪经授权发布。</p>", "published": "2024-11-07 11:12:25", "id": "585d0c2b-41ed-4c48-b575-6948a280c3a0", "source": "36氪", "section": "文章资讯"}, {"title": "国投电力11月7日缩量上涨0.33%；国投电力为ICOL公司提供担保额度进展公告", "link": "https://36kr.com/p/3026169871082754?f=rss", "description": "", "published": "2024-11-07 10:19:26", "id": "6f228fc1-2c53-4a54-bf8f-2aa91b50fc0d", "source": "36氪", "section": "文章资讯"}, {"title": "完美世界11月7日缩量价平0.00%", "link": "https://36kr.com/p/3026211794626056?f=rss", "description": "", "published": "2024-11-07 11:02:02", "id": "4a3ef66f-4949-4925-87fb-1ee5cae962fb", "source": "36氪", "section": "文章资讯"}, {"title": "双十一，远去的财富神话", "link": "https://36kr.com/p/3026173699663365?f=rss", "description": "<p>今年双十一开始前，在淘宝运营一家女装店的沐歌就发现，淘天小二 （客服） 的沟通积极性和服务态度比之前好多了。&nbsp;</p>\n  <p>在天猫和拼多多经营洗护用品的梅先生也告诉我们，两个平台的小二与他们的对接比以往更为频繁，服务体验有所提升。“ （小二） 一直在引导 （如何参加活动） ，包括教我们怎么把量做起来，让我们报哪些活动等等。链接都给发好了，以前是不会的。”&nbsp;</p>\n  <p>工作人员的友善更像是今年平台对商家态度的一个缩影。早在七八月，淘天就宣布松绑“仅退款”策略，这在当时被认为是淘天安抚商家、在消费者体验和商家权益之间寻找平衡的有益探索。&nbsp;</p>\n  <p>优待商家的不止淘天。8月底，拼多多宣布正式启动“百亿减免”计划，未来一年减免商家100亿元交易手续费。此前一个月内，拼多多已先后推出多项费用退免权益，比如下调店铺保证金以及提现门槛、免除商家偏远地区物流中转费等。&nbsp;</p>\n  <p>眼下的双十一大促，成了各平台商家策略的一次集中体现，包括淘天的“百亿投入”和“百亿减免”、抖音电商的运费险优惠、京东的“免报名”机制、“厂货百亿补贴”、直播补贴、广告金奖励等等。&nbsp;</p>\n  <p>在平台密集的补贴和利好策略护航下，商家今年的双十一能赚得更多吗？&nbsp;</p>\n  <p>对这个问题，品牌商和“个体户”的体感是不同的。平台陆续发布的战报中， <strong>越来越多的大品牌正在不断刷新着销售纪录，而一些中小商家的回答却并不乐观</strong>。 这些曾经跟着平台一路成长、吃过双十一红利的中小商家们，在如今的竞争环境下，正在失去对双十一的期待。&nbsp;</p>\n  <p>在有着十几年经验的电商从业者贾真看来，双十一已经失去了他原本存在的意义。 <strong>“之前双十一就是为了拉新客户，让更多客户知道网上购物，让更多品牌知道电商的巨大威力，但现在两个目的都已经达到了。”</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_f253e169059240ef8e201ae295e3452c@5091053_oswg962503oswg1080oswg1070_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">&nbsp; 淘天和拼多多为商家减负的系列举措；图源/淘天、拼多多&nbsp;</p>\n  <h2><strong>1 双十一神话难再</strong></h2>\n  <p>双十一最开始的那几年，参与的平台少，报名的商家也少。一些早早上车的中小商家伴随着平台和电商市场的疯狂生长，吃到不少红利。&nbsp;</p>\n  <p>2009年，阿里第一次推出“双十一”的购物狂欢，参与的商家只有27家，销售额只有5000万元。2010年，双十一的销售额已经达到了9.36亿元，达到上一年的近20倍。到了2016年，在用户心智被双十一的概念潜移默化地影响了七八年后，销售额开始突破千亿关口，达到1207亿元。&nbsp;</p>\n  <p>贾真对双十一的初印象始于2010年。他当时运营着一家3c数码产品的c店，同楼层还有另外两家做淘宝商城 （也就是后来的天猫） 的数码店，哪家做得好，看门口堆的发货量就知道了。他家每天几百件，另外两家大概分别有几十件和一两百件。突然有一天，出货量只有几十件的那家店门口堆了一堆货，老板告诉贾真：“报双十一了。”&nbsp;</p>\n  <p>梅先生说，之前商家们都盼着双十一，“因为确实能出量”。他八九年前曾做过“白牌”食品，日常只有三四千元的销售额，双十一当天能卖30多万元。那时的双十一是商家和消费者共同的狂欢，大家都能很轻易做到销售额几十倍的增长。&nbsp;</p>\n  <p><strong>因为经历过曾经的辉煌，贾真更能意识到，如今的电商已经从增量市场变成存量市场。“之前大促是为了拉新，现在大促已经拉不到新了。”</strong> 他提到，之前有大量的人口在线下购物，不知道线上或者没有线上的账号，但现在几乎所有人都会线上购物，来到了一个存量市场，很难增长了。&nbsp;</p>\n  <p>同时，平台的规则也在不断变化。店铺早期的流量主要来自搜索，而搜索的主要权重来自销量，所以双十一期间的销量增多后，店铺在搜索结果里面就会优先展示，拿到的流量就会更多。但贾真告诉我们，现在多以付费流量为主，不投流就很难换来销售额。 <strong>“参加双十一跟不参加双十一对于流量的影响几乎微乎其微了。”</strong></p>\n  <p>就目前的情况，贾真分析说，商品如果有差不多50%以上的毛利，通过双十一还能赚到钱，但毛利低于30%就没有参加双十一的必要了。“双十一有一个满300减50的优惠券，再打个9折，再加上运费险，再加上付费的成本，30%根本兜不住。”&nbsp;</p>\n  <p><strong>所以，很多以利润为导向的电商卖家可能会主动放弃双十一。如果说此前亏钱参加双十一还有意义，可以带来之后日常销量的提升，但现在亏钱就完全没意义了，“反正都是付费流量。”</strong></p>\n  <p>此外，活动时间的拉长也令很多商家为难。广东的服装商家张达提到，以前10月才开始考虑双十一，现在9月就要开始考虑。但与只有一天活动时相比，周期延长却没给销量带来什么明显的提升。张达认为，现在的双十一等于把以前双十一当天的量平摊到预热+活动的长周期中。&nbsp;</p>\n  <p>同时由于平台促销活动的常态化，双十一的价值也不再那么突出。“现在一年的活动做个不停，有没有双十一性质一样。”张达说道。&nbsp;</p>\n  <p>电商平台尽管已经将促销做到了常态化，但庄帅认为双十一大促就像过年，其他节日可以简单纪念，但春节却最为盛大，影响力也最大。整体来看双十一还是一年当中电商促销力度最大、范围最广的活动。&nbsp;</p>\n  <p>当不少商家在追忆过去的“美好”时，庄帅却表示不想再回到过去电商无序发展的时代。过去十几年的发展和竞争为消费者带来了更高性价比的产品和服务，这是良性竞争的产物。在存量竞争的环境中，优胜劣汰是一种必然。&nbsp;</p>\n  <p>庄帅依然对互联网零售抱有信心：国内市场在存量竞争，国际市场却仍然广阔。今年双十一有个变化，以阿里为主，各平台也在加大海外市场的拓展力度，打通全品类的出海路径。他还提到，目前国内头部平台已经逐渐互联互通，在国内 （电商） 结成一块“铁板”的前提下，再拿着国内“铁板”去国外竞争。&nbsp;</p>\n  <h2><strong>2 风向变了，但大小商家体感不同</strong></h2>\n  <p>在电商的生态中，商家与消费者站在天平的两端，平台在中间维系和调节二者。在过去很长的一段时间里，平台为了争夺用户资源，一面向下压低商品价格，一面向上提升用户服务体验，使商家的利润空间不断被压缩。&nbsp;</p>\n  <p>2023年双十一，各平台的低价内卷进入白热化。很多商家反映 <strong>利润空间被压缩，流量带来了热度和销售额，却没什么盈利。</strong></p>\n  <p>沐歌在实际运营中发现，平台之间的低价竞争让消费者购物时更容易进行同类型店铺比价，以及不同平台间的比价。 <strong>比来比去的结果就是流量越来越贵，运营效率变得更差。这让运营压力本就很大的中小商家变得更难。</strong></p>\n  <p>双十一之后，淘宝和京东相继效仿拼多多，宣布推行仅退款政策。天平向消费者一端的倾斜愈发明显。&nbsp;</p>\n  <p>但是，到了2024年，各个平台又不约而同地“回调”，提出了对商家的各种优待政策。梅先生认为，卷低价、仅退款等做法，不可避免地招致了大量商家的不满，平台也需要适当安抚商家。&nbsp;</p>\n  <p>从长期视角来看，平台之间一味的低价竞争对消费者也并不一定是好事。山东大学数字经济与平台竞争研究中心主任曲创提到，电商平台的“唯低价”模式导致了片面要求商家低价、忽视商品质量、商家权益被侵害等问题，这也引起了公众和监管部门的关注。&nbsp;</p>\n  <p>7月30日，中共中央政治局召开会议，分析研究当前经济形势和经济工作，首次提出“要强化行业自律，防止‘内卷式’恶性竞争”。阿里巴巴集团副总裁、淘宝平台事业部总裁处端坦言了政策对他们的影响：政府明确提出行业反内卷，在整个大政策的指引下，淘天做了很多思考和行动。&nbsp;</p>\n  <p>处端提到，过去消费者和商家确实存在利益失衡的问题， （平台） 有一边倒的倾向。淘天也正在通过解决“仅退款”“退货运费成本高”“低价内卷”这三个“顽疾”，来改善商家的营商环境。京东、拼多多、抖音等平台也相继发布了诸多或直接补贴、或间接改善的策略，来为商家减负。&nbsp;</p>\n  <p>经此一番，商家的压力会有所缓解吗？&nbsp;</p>\n  <p>梅先生告诉我们，淘天和拼多多这些为改善营商环境所推行的举措均有落地，但因为品类和规模的不同，商家们对此感受不一。 <strong>“平台的优惠活动（对我们中小商家而言）感觉都不太直观，补贴可能也就占到销售额的千分之一左右。”他直言。“不过蚊子腿也是肉，前两年都没有（补贴）。”</strong></p>\n  <p>梅先生在电商行业十余年，深谙大小商家处境的不同。平台的补贴看上去是普适性的，但很多都设置了无形的门槛。比如百亿补贴——参加这项活动的商品需要来自黑标店铺。他们可以借助平台的部分补贴来提升销售，大多数中小商家的商品是无法进入百亿补贴频道的。再比如，平台在松绑仅退款政策时提到的“对优质商家不主动介入”，多指大商家。&nbsp;</p>\n  <p>梅先生曾在滴露这样的行业头部品牌工作过。他说，平台大促时会有切实的补贴给品牌，品牌再进一步为消费者让利。但像现在自己做的这种c店 （个人店铺），实则是卖家自己压缩利润空间给消费者。某天猫女装店铺老板如冰也提到，满减、优惠券都是扣商家的钱，商家要跟着平台的活动让利。&nbsp;</p>\n  <p>“无论是流量方面还是经济方面，说实话我是一点都没有感受到。”一位在天猫和淘宝均有开店的女装人士说到。&nbsp;</p>\n  <p>贾真向我们解释说，现在平台的补贴大多是消耗性补贴，商家花得越多，得到的补贴也会相应多一些。比如付费买流量，大商家买得多，返还数额也会更大。而大多数小商家因为花得少，对这方面感触不深。&nbsp;</p>\n  <p>沐歌运营着包括如冰的店铺在内的三家淘宝女装店铺，年销售额在几百万到数千万元不等。他提到，这几家店铺的流量和平台扶持力度都不一样，大店得到的会更多一些。&nbsp;</p>\n  <p>在今年的双十一“抢先购”阶段，郭升经营的培育钻石品牌做到了同品类天猫销售第一，成交额对比去年同期增加了212%。郭升提到，他们一直在进行持续的优化，包括视觉、产品的迭代。并且随着客户评价和口碑的积累，品牌的护城河也在不断加深。&nbsp;</p>\n  <p>零售行业专家、百联咨询创始人庄帅提到，不同规模的商家肯定对平台政策的感知不同。而且从平台管理和发展的角度来看， <strong>平台主要去扶持那些优质的、有进取心的、愿意创新的、风险较低的商家。</strong></p>\n  <h2><strong>3 竞争加剧，中小商家承压</strong></h2>\n  <p>日常经营和大促中，中小商家们不免因品类和规模等因素感受到差别对待，但多位商家们向我们表示，他们更在意的是平台上的经营生态。&nbsp;</p>\n  <p>今年淘天举起了优化营商环境的大旗以吸引商家，从8月的松绑仅退款开始，释放出越来越多利好商家的信号。&nbsp;</p>\n  <p>淘天方面发布消息称，今年平台新开店铺累计超过600万，三季度天猫新入驻品牌数环比大涨70%。其中，9月入驻品牌最多，环比8月大增239%，明显有大量新商家希望双十一能在淘宝天猫的主场爆量增长。另外还有越来越多的海外品牌也在持续加码中国市场。数据显示，今年前三季度有1700多海外商家在天猫国际开出中国首店。&nbsp;</p>\n  <p>梅先生却也为此担忧， <strong>他觉得今年消费大盘并没有明显扩大，而商家的增多必将使竞争更加激烈。</strong> 尤其是在双十一这样的大促期间，商家们的投流和推广力度更大，获客成本就会更高。梅先生的店铺获客成本要比平时高1倍左右。如今更多竞争者的加入，让他担心吃到的“蛋糕”会更少。&nbsp;</p>\n  <p>前述女装人士并没有通过今年双十一的大促活动看到什么希望：“我和身边的几位同行卖得都不好，只有去年的一半吧。”今年以来，他感觉到访客数量比去年更少了，经营成本变得更高。强制运费险、店铺扣点，以及各种付费服务的开通，让他的经营负担越来越重。&nbsp;</p>\n  <p>社交平台上抱怨双十一数据惨淡的中小商家不在少数，也有很多人干脆没有报名参与，置身于电商平台的热闹之外。但在另一边，双十一的气氛被电商平台一份份的战报和App上的一片红火烘托得正盛，头部商家和品牌们的业绩喜人。&nbsp;</p>\n  <p>10月25日，2024年天猫发布了双十一第一阶段 （10月21日-10月24日） 品牌成交排行榜，有超1.2万个品牌成交增速超100%，近6000个品牌增速超500%。11月1日，新一轮战报显示，天猫双十一从开启到10月31日，累计373个品牌成交破亿。10月31日晚，京东也发布战报，提到超1.6万个品牌成交额同比增长超三倍，成交额破亿的品牌数量同比增长超40%，订单量同比增长超过5倍的商家超过1.7万家。&nbsp;</p>\n  <p>作为品类头部品牌的经营者，郭升认为，当 （培育钻石） 行业秩序尚未规范时，品牌的力量会更加重要。同时，今年在平台的引导下，他家店铺开始由预售转现货，现货模式帮助他筛掉了很多低价及不备货的同行。&nbsp;</p>\n  <p>从2022年双十一开始，淘天和京东便不再披露具体GMV数据。头部品牌的成交额和增速，以及各品类榜单的更新成了平台宣传的重点。这在当时被解读为，电商平台对于双十一的关注点从单纯的交易额比拼转向了更多维度的价值展示，如用户体验、服务质量、商家支持等，也是电商行业在成熟阶段的转型和升级。在庄帅看来，电商平台确实需要不断通过各种规则和工具来优胜劣汰，吸引和留住优质商家。&nbsp;</p>\n  <p>从现阶段来看，电商行业仍然处在高度竞争的状态，头部商家和品牌们往往有更多的资源、更强的综合实力来应对，但数量庞大的中小商家抗风险能力相对较差，竞争中的筹码也更少，相对来讲会在竞争中面临更大的压力。&nbsp;</p>\n  <p>*文中如冰、沐歌、张达为化名&nbsp;</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/6j-eVfpc53m0NrEkI1IdXQ\" rel=\"noopener noreferrer\" target=\"_blank\">“半熟财经”</a>，作者：李莹 杨立赟 郑可书，编辑：余乐，36氪经授权发布。</p>", "published": "2024-11-07 10:29:23", "id": "241ee149-a7c9-4c5a-a800-cb83fb0bd14d", "source": "36氪", "section": "文章资讯"}, {"title": "云从科技11月7日缩量上涨2.65%", "link": "https://36kr.com/p/3026193515635975?f=rss", "description": "", "published": "2024-11-07 10:43:26", "id": "237b14fd-f13a-4351-a712-845dc43afe50", "source": "36氪", "section": "文章资讯"}, {"title": "三羊马11月7日放量上涨4.96%", "link": "https://36kr.com/p/3026169892906498?f=rss", "description": "", "published": "2024-11-07 10:19:26", "id": "1ed32eda-ba24-407d-81df-8a08f9a68cce", "source": "36氪", "section": "文章资讯"}, {"title": "三花智控11月7日缩量上涨1.95%；三花智控重点发展仿生机器人机电执行器业务", "link": "https://36kr.com/p/3026193049691399?f=rss", "description": "", "published": "2024-11-07 10:43:08", "id": "8775b7cc-33c2-4079-870e-aa9baf63e041", "source": "36氪", "section": "文章资讯"}, {"title": "慈星股份11月7日缩量上涨1.02%", "link": "https://36kr.com/p/3026184971609601?f=rss", "description": "", "published": "2024-11-07 10:34:46", "id": "7b990b46-5096-4dcd-a982-1b0cacc2a5a1", "source": "36氪", "section": "文章资讯"}, {"title": "一汽解放11月7日缩量上涨2.75%；一汽解放10月销量同比增长119%", "link": "https://36kr.com/p/3026189499262215?f=rss", "description": "", "published": "2024-11-07 10:39:27", "id": "0cbf5057-bd7e-4bdc-898e-21c2abb9bcf6", "source": "36氪", "section": "文章资讯"}, {"title": "氪星晚报 ｜哪吒汽车否认裁员规模高达70%；字节跳动AI助手豆包开启视频生成内测报告：全国职业主播超1500万人，2025年直播人才缺口将超1900万", "link": "https://36kr.com/p/3026111429977606?f=rss", "description": "<h2>大公司：</h2>\n  <p><strong>JOOCYEE酵色首家线下门店于长沙开业</strong></p>\n  <p>36氪获悉，JOOCYEE酵色首家线下门店于11月3日在长沙核心商圈国金街开业。未来，酵色将继续加大线下渠道的拓展力度。</p>\n  <p><strong>天猫在宁波成立电子商务新公司</strong></p>\n  <p>36氪获悉，爱企查App显示，近日，宁波喵电电子商务有限公司成立，法定代表人为张倩，注册资本100万元人民币，经营范围包括互联网销售、通信设备销售、二手日用百货销售、日用百货销售、新能源汽车整车销售、电池零配件销售、充电桩销售、新能源汽车电附件销售等。股东信息显示，该公司由浙江天猫技术有限公司全资持股。</p>\n  <p><strong>哪吒汽车否认裁员规模高达70%</strong><br />针对哪吒汽车启动大规模裁员，比例或将高达70%的传闻，哪吒汽车向36氪予以否认。官方回应表示，公司正在通过精简业务、聚焦核心、组织优化和薪酬绩效改革等措施，构建更集中高效的组织架构。分部门按业务要求和未来发展需要进行整合。推动资源的集约化投入，进一步提升企业的竞争力和运营效率。</p>\n  <p><strong>比亚迪申请注册来杯迪小饮商标</strong><br />36氪获悉，爱企查App显示，近日，比亚迪股份有限公司申请注册“吾迪小饮”“来杯迪小饮”商标，国际分类为餐饮住宿，当前商标状态均为等待实质审查。比亚迪股份有限公司成立于1995年2月，法定代表人、董事长、执行董事、总裁为王传福，注册资本约29.11亿元人民币，由HKSCC NOMINEES LIMITED、王传福、吕向阳、融捷投资控股集团有限公司等共同持股。</p>\n  <p><strong>奇瑞集团10月出口突破11万，本月将首次突破年出口100万辆</strong></p>\n  <p>36氪获悉，据奇瑞控股官微，奇瑞控股集团10月出口汽车111922辆，同比增长18.8%，创造历史新纪录。1-10月份累计出口销量941275辆，同比增长23.8%，预计本月将迎来年内出口突破百万辆的新里程碑。目前，奇瑞集团累计全球汽车用户超过1510万，其中海外用户超过420万。</p>\n  <p><strong>宁德时代获UL Solutions授权第一方UL9540A认可目击实验室</strong></p>\n  <p>36氪获悉，据宁德时代官微，近日，宁德时代储能技术研发验证中心启用暨UL9540A实验室授牌仪式在宁德正式举行，该实验室成为全球首个获得UL Solutions授权的第一方“UL9540A认可目击实验室（WTDP）（Module、Unit）”。储能技术研发验证中心安全实验室具备大型储能产品热失控火灾蔓延评估验证等测试能力，是对集装箱及以下层级样品的UL9450A、储能国标GB/T36276等标准的热失控测试及各项安全滥用测试能力的补充，进一步升级完善了宁德时代的测试验证体系，可极大缩短储能产品出口欧美等地区的UL9540A认证周期。</p>\n  <h2>投融资：</h2>\n  <p><strong>AI搜索创企Perplexity据悉将融资5亿美元，公司估值有望达90亿美元</strong></p>\n  <p>据路透11月5日消息，知情人士称，人工智能搜索初创公司Perplexity将在新一轮融资中筹集5亿美元，使该公司估值达到90亿美元。拥有Perplexity董事会席位的风投公司Institutional Venture Partners将领投这轮融资。（界面）</p>\n  <p><strong>斯达领动完成数千万元Pre-A轮融资</strong></p>\n  <p>近日，上海斯达领动完成了数千万元Pre-A轮融资。本轮融资由共进股份、乾德电子和汽车领域专家个人投资，资金将主要用于新产品的研发和新业务的拓展。 斯达领动成立于2023年，致力于毫米波雷达产品的开发及规模化应用，主要产品包括单芯片4D毫米波雷达。（斯达领动）</p>\n  <h2>新产品：</h2>\n  <p><strong>字节跳动AI助手豆包开启视频生成内测</strong></p>\n  <p>字节跳动旗下大模型AI助手豆包正式推出视频生成内测，意味着继快手、商汤、Minimax等公司后，字节跳动正式杀入AI视频生成领域。豆包官网称，豆包视频生成，支持图片文字一键成片，“能将信息转化为生动逼真的视频内容。 支持酷炫的动态和运镜，多镜头保持一致，风格比例随意挑选。”（财联社）今日观点：</p>\n  <p><strong>宁德时代董事长曾毓群：储能行业不能乱，但也绝不能慢</strong></p>\n  <p>11月7日，“2024世界储能大会”在宁德召开，开幕式上，宁德时代董事长曾毓群发表了演讲。“作为新能源转型的关键基础设施，储能行业不能乱，但能源转型需求也要求我们绝不能慢，行业必须在快速增长中同步实现高质量发展。”曾毓群说，如何实现高质量发展，行业需要做到高可靠性、高价值性和全场景。（每日经济新闻）</p>\n  <h2>其他值得关注的新闻：</h2>\n  <p><strong>报告：全国职业主播超1500万人，2025年直播人才缺口将超1900万</strong></p>\n  <p>36氪获悉，中国演出行业协会网络表演（直播）分会联合快手平台发布《网络主播新职业发展报告》。《报告》显示，截至2023年12月，有1508万人把网络主播当成主业，预计到2025年我国直播行业的人才缺口将达到1941.5万人。调研显示，六成以上职业网络主播每周直播四天以上，八成以上职业网络主播平均月收入在8000元以下，近九成职业网络主播愿意长期从事网络主播这一职业。网络主播呈现出职业化、多元化、专业化的发展趋势。</p>\n  <p><strong>机构：2028年中国数字化转型总体市场规模将超7300亿美元</strong></p>\n  <p>36氪获悉，国际数据公司（IDC）近日发布了2024年V2版本《全球数字化转型支出指南》。IDC最新数据显示，2023年全球数字化转型投资规模超过2.1万亿美元，2028年预计达到4.4万亿美元，2023-2028年五年复合增长率（CAGR）为15.4%。随着全球数字化转型市场蓬勃发展，云计算、人工智能、大数据、5G等技术的应用范围不断扩大，全球企业的数字化转型已经来到了持续发展阶段，这也促使了企业不断加大其在数字化转型的投入。</p>", "published": "2024-11-07 11:07:50", "id": "42594146-7d07-4d5e-a903-4f44f77b6afc", "source": "36氪", "section": "文章资讯"}, {"title": "保利发展11月7日放量上涨2.73%；保利发展成功发行25亿短期融资券", "link": "https://36kr.com/p/3026175256815111?f=rss", "description": "", "published": "2024-11-07 10:25:04", "id": "6277f486-13ce-4ae0-b78e-162d5f7c7265", "source": "36氪", "section": "文章资讯"}, {"title": "诺基亚酸了？摩托罗拉创下十年新高，老牌手机也有春天？", "link": "https://36kr.com/p/3026064115856258?f=rss", "description": "<p>在2005年吾酷组合发行的歌曲《我赚钱了》歌词中，赚到钱后做的第一件事就是左手买个诺基亚，右手买个摩托罗拉。<strong>的确，在那个时代，诺基亚与摩托罗拉是手机行业的霸主。</strong>然而王朝没有永恒，智能手机时代到来后，对于行业变革不够敏感的诺基亚与摩托罗拉王朝轰然崩塌。</p>\n  <p>到如今，诺基亚智能手机销量极低，只能在低端智能机和功能机市场混日子。与诺基亚不同，经历过低谷期的摩托罗拉，被联想收购后，竟然迎来了第二春。</p>\n  <p>市场研究和技术分析公司TechInsights最新报告显示，2024年第三季度，全球智能手机出货量同比增长3.8%至3.077亿部。其中，联想-摩托罗拉销量位列全球第七，并且以26%的增长率领跑全场，创下了近十年的市场份额新纪录。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_910e97e232aa4b34a3b0be2281f31c7b@1547419282_oswg46070oswg897oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">（图源：联想-摩托罗拉）&nbsp;</p>\n  <p><strong>同为旧时代的王者，诺基亚在智能手机领域近乎销声匿迹，即便是微软也未能拯救诺基亚。可摩托罗拉凭什么能够销量进入全球前十，实现了销量复兴？</strong></p>\n  <h2>摩托罗拉逆袭，只因“背靠联想好乘凉”？</h2>\n  <p>塞班系统失去竞争力后，诺基亚也选择拥抱安卓，但大企业普遍存在船大难掉头的情况，转型不会任由CEO决策，需要得到股东的支持，有时企业内各部门还会互相掣肘，导致公司业务发展不畅。放眼手机行业，诺基亚、摩托罗拉、索尼等企业，大多出现过类似的情况。</p>\n  <p><strong>毫无疑问，面对行业竞争与变革，选择与实力同样重要，摩托罗拉能够破茧成蝶，原因也在于此。</strong>联想-摩托罗拉的选择与实力，体现在市场布局、产品规划两大方面。</p>\n  <p>联想收购摩托罗拉，堪比吉利收购沃尔沃、上汽收购MG，成功帮助其打开了海外市场。要知道，自主品牌虽不断开拓海外市场，但目前海外销量主要集中在东南亚和南亚等亚洲地区。借助摩托罗拉的影响力，联想-摩托罗拉在拉丁美洲、非洲、中东地区、亚太地区等，均取得了不错的销量成绩，北美地区更是以12%的份额位列第三。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_66d658a7acb74188814316c4014cac6c@1547419282_oswg301488oswg1706oswg1279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">（图源：雷科技摄制）&nbsp;</p>\n  <p>另外，联想-摩托罗拉还进军日本，而且收购了当地手机品牌富士通。基于富士通在当地的影响力，以及联想-摩托罗拉的实力，富士通品牌首次进入日本市场智能手机销量前四。<strong>收购海外市场本土品牌并融合的方案，能够迅速提升品牌影响力，减少营销所需的时间和费用，再加上联想-摩托罗拉本身的技术实力，开拓海外市场难度自然大幅下降。</strong></p>\n  <p>产品方面，联想-摩托罗拉在手机领域底蕴可能已不如苹果、三星、小米、OPPO、vivo等巨头，但吃到了智能手机时代转型的苦，摩托罗拉面对新事物比大多数智能手机巨头更积极。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_3077a192cf0841a584ddb374fb93f9b8@1547419282_oswg213445oswg1706oswg1279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">（图源：雷科技摄制）&nbsp;</p>\n  <p>以折叠屏手机为例，2019年折叠屏手机刚刚诞生，联想-摩托罗拉就迅速跟进，解决了铰链难题，并推出了竖折手机moto razr 2019。随后数年内，横折手机都是主流，竖折手机少之又少，销量也较为一般。随着技术的升级迭代，竖折手机愈发被消费者认可，第三季度小米凭借竖折手机MIX Flip进入国内折叠屏手机销量前三。</p>\n  <p>率先入场的联想-摩托罗拉，通过多年时间经营，今年第二季度以30.8%的市场份额位列全球竖折手机销量第一。到如今，moto S/X/G/razr等多个系列已实现了不同价位、不同类型产品覆盖。</p>\n  <p>基于联想、摩托罗拉双方的技术实力与影响力，摩托罗拉似乎触摸到了重回巅峰的希望，现阶段销量全球第四，只是联想-摩托罗拉复兴的中间环节。<strong>整个智能手机市场正在向AI时代迈进，行业即将迎来新的变革，抓住时代的机遇，摩托罗拉才能乘风而起。</strong></p>\n  <h2>加码AI，摩托罗拉能否焕发第二春？</h2>\n  <p>经历智能手机、3G、4G、5G等多个时代后，当前手机行业已进入了AI时代，面对新时代的诸多挑战，联想-摩托罗拉也及时为产品加入了AI能力。以moto razr 50 Ultra AI元启版为例，其内置的AI智能体联想小天可以精准识别自然语言，实现调控设置、应用等操作，还可以进行文档续写、总结、润色、翻译。</p>\n  <p>AI画师、AI通话、AI出行等功能，能够根据用户的生活习惯，计算出行时间、进行通话内容摘要记录，提高工作效率和生活便捷度。此外，摩托罗拉还将深度布局AI PC、AI平板、AI耳机等品类，提高智能设备跨平台、跨设备协同工作能力，为用户提供“一体多端”体验。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_b094d27d7c394da9ae9eb64f32b6c254@1547419282_oswg247918oswg1920oswg1174_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">（图源：联想-摩托罗拉）&nbsp;</p>\n  <p>联想Tech World 2024大会上，联想-摩托罗拉还透露了将大型动作模型（LAM）与moto AI结合的相关信息。基于该技术，联想-摩托罗拉的LAM将能够学习用户的行为，提供个性化交互与辅助能力。</p>\n  <p>具体到产品方面，如今联想－摩托罗拉的手机、笔记本电脑等设备已经实现了互联互通，PC可调用手机App，在PC平台多屏操作和文件跨端传输。在更多设备和AI技术的加持下，未来联想-摩托罗拉的AI智能体将会更懂用户，从而打造出符合用户使用习惯的终极AI助手。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_56b1209abbf649b593ded53b0d5fdd81@1547419282_oswg226534oswg1920oswg1126_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">（图源：联想-摩托罗拉）</p>\n  <p>相对于OPPO、vivo等部分头部手机品牌，得到联想加持的摩托罗拉，实际上在生态方面更具优势，尤其是平板和PC两大办公、学习利器，传统手机厂商欠缺品牌影响力和技术底蕴。<strong>全产品线布局，将成为未来摩托罗拉手机全球份额进一步提升的重要因素。</strong></p>\n  <p>市场布局方面，依然是摩托罗拉的优势。开拓亚洲以外市场难度很高，进军北美市场难度就更高了，而摩托罗拉是少有可以在全球畅行无阻的品牌，美国大本营北美地区，摩托罗拉份额已有12%。<strong>以中国为中心开拓东南亚、南亚、中东地区，以美国为中心开拓拉美市场，然后再向欧洲进发，联想-摩托罗拉发展空间可能比国内头部手机品牌更大。</strong></p>\n  <p><strong>评价一个企业的韧性，不只是看它辉煌之时能够登上多高的巅峰，而是看它跌入谷底后能否再次攀上高峰。</strong>摩托罗拉与诺基亚都曾经历过辉煌与低谷，如今诺基亚手机业务回天乏术，依靠专利技术和通信业务，存活倒不是问题。而于逆境中浴火重生的摩托罗拉，有机会再次登上新高峰。</p>\n  <h2>想要回归舞台中心，摩托还需加倍努力</h2>\n  <p>美国《财富》杂志的统计数据显示，美国62%的企业寿命不足5年，只有2%的企业能够活过50年。但对于今天的创业者而言，这个数据还是过于乐观了，进入21世纪之前，全球科技与经济飞速发展，且没有那么多巨头阻碍小型企业发展。现在全球各行各业竞争激烈，每一个巨头都有垄断行业的野心，中小型企业发展壮大的难度比之前更大。</p>\n  <p>创业困难，中兴又何尝不是。借助联想和摩托罗拉的影响力，联想-摩托罗拉手机销量虽位居全球第七，并且增长率在前十品牌中首屈一指，<strong>但这也意味着联想-摩托罗拉欲更进一步，就需要击败全三星、苹果、小米、OPPO、vivo，以及非洲之王传音等智能手机巨头。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_aa5df99659e24b95bc8d93ac469a0d0e@1547419282_oswg1071634oswg1706oswg1279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">（图源：雷科技摄制）&nbsp;</p>\n  <p>这些手机行业的头部企业，哪个没有两把刷子，即便是老牌手机厂商摩托罗拉与PC厂商联想联手，超越他们也难如登天。好在，拥有市场优势的联想-摩托罗拉，可发展空间大于其他国产品牌。</p>\n  <p>收购富士通后，联想-摩托罗拉大概率也将向日本进军。古板的日本市场，向来被认为是智能手机行业的孤岛，OPPO、华为等国产品牌也曾进军日本，至今没能取得太好的成绩。拥有富士通这个马甲的联想-摩托罗拉，已成功跻身日本市场前四，仅次于苹果、谷歌、夏普，凭借联想和摩托罗拉的技术，在日本销量超越夏普和谷歌指日可待。</p>\n  <p><strong>不过手机行业竞争激烈，且存在诸多变数，联想-摩托罗拉能否战胜重重困难，重回巅峰，还需要时间来验证。</strong></p>\n  <p>本文来自“雷科技”，36氪经授权发布。</p>", "published": "2024-11-07 10:45:27", "id": "95bea449-4b2d-4db6-a516-3aafbf32474f", "source": "36氪", "section": "文章资讯"}, {"title": "明月镜片11月7日缩量上涨2.64%", "link": "https://36kr.com/p/3026190121985289?f=rss", "description": "", "published": "2024-11-07 10:40:01", "id": "8131d43d-a31d-4d4b-b64c-eae8736d9306", "source": "36氪", "section": "文章资讯"}, {"title": "最前线｜加拿大政府又下禁令，狂奔的TikTok再蒙阴影", "link": "https://36kr.com/p/3026207441790211?f=rss", "description": "<p>文｜兰杰</p>\n  <p>编辑｜乔芊</p>\n  <p>TikTok面临的危机还在加剧。</p>\n  <p>当地时间11月6日，加拿大政府发布公告表示，已下令终止TikTok&nbsp;Technology Canada, Inc.在加拿大的业务。</p>\n  <p>具体来讲，TikTok位于加拿大的办公室将被解散，但加拿大用户仍可以访问TikTok，并在平台上进行内容创作。</p>\n  <p>加拿大创新、科学和工业部部长François-Philippe Champagne在公告中表示，政府是依据《加拿大投资法》（Investment Canada Act）做出这一决策的。该法案允许政府对有可能损害加拿大国家安全的外国投资进行审查。François-Philippe Champagne补充表示，“虽然加拿大欢迎外国投资，但当投资威胁到我们的国家安全时，政府将果断采取行动。”</p>\n  <p>对此，TikTok加拿大发言人丹妮尔·摩根（Danielle Morgan）回应称，“关闭TikTok加拿大办公室将毁掉数百个当地高薪工作岗位，不符合任何人的最佳利益，公司将在法庭上挑战这一命令。TikTok平台仍将帮助创作者寻找观众、探索新商机，并帮助企业茁壮成长。”</p>\n  <p>这并不是TikTok在加拿大的第一次遇挫。</p>\n  <p>早在2023年2月，加拿大政府已经禁止所有政府设备使用TikTok，并于同年晚些时候下令对该应用程序进行国家安全审查，如今再出禁令，也可以说是靴子落地。</p>\n  <p>为了应对相关危机，TikTok也在加速海外本土化进程。今年1月18日，据接近字节跳动的人士透露，公司正在加拿大、澳大利亚等地筹建研发中心，未来将支持TikTok、CapCut、Lemon8等多个海外业务研发。但这些没能改变欧美地区对于TikTok的封禁决策。</p>\n  <p>即便国际形势日益严峻，TikTok还是逐步成为字节跳动新的收入增长引擎。据The Information于当地时间11月4日报道，字节跳动2024年上半年的国际收入（以TikTok为主）增长超60%，达到约170亿美元（约合人民币1209.15亿元）——在禁令的阴影下，TikTok的商业化发展仍很强劲。</p>\n  <p>此外，加拿大并非TikTok的主要市场。据第三方数据机构Statista，截至2024年4月，TikTok在全球有15.6亿月活跃用户，其中美国用户数量最多，约1.5亿人。</p>\n  <p>那么，TikTok在最主要市场上的命运如何？</p>\n  <p>同样是当地时间11月6日，特朗普在佛罗里达州棕榈滩会议中心发表讲话，宣布在2024年美国总统选举中获胜。特朗普此次胜选，与TikTok的命运息息相关。</p>\n  <p>早在今年4月，众议院和参议院接连通过了TikTok的“不卖就禁”法案，并由当时的美国总统拜登签署生效。法案生效后，留给TikTok的时间还有一年——包括最新版法案规定的270天的剥离时间，以及美国总统确认TikTok出售进展后还可以进一步延长的90天。</p>\n  <p>如今这一期限已经过去了半数，期间关键性的变量就是美国新一任总统的决策。而在竞选期间，特朗普曾于当地时间7月16日向外媒《彭博商业周刊》表示，反对拜登政府签署的TikTok“不卖就禁”法案，并声称会支持这家短视频平台公司。</p>\n  <p>但早在2020年，彼时执政的特朗普也曾以国家安全为借口，试图封禁TikTok，因此这位新任美国总统是否会兑现承诺仍需观望。如今加拿大对TikTok的封禁政策再进一步，无疑是一种糟糕的信号。</p>", "published": "2024-11-07 11:20:21", "id": "f85f84e0-8914-45d9-ab6f-44406daabcff", "source": "36氪", "section": "文章资讯"}, {"title": "再升科技11月7日缩量上涨2.91%", "link": "https://36kr.com/p/3026171724129541?f=rss", "description": "", "published": "2024-11-07 10:21:17", "id": "af265613-e260-4947-b2d2-acc65910e7e0", "source": "36氪", "section": "文章资讯"}, {"title": "中油工程11月7日放量上涨2.96%；中油工程子公司获批55亿低利率贷款", "link": "https://36kr.com/p/3026214263432711?f=rss", "description": "", "published": "2024-11-07 11:04:40", "id": "e601d330-e04b-46fd-a48a-a9a66237321a", "source": "36氪", "section": "文章资讯"}, {"title": "中国铁物11月7日放量上涨2.8%", "link": "https://36kr.com/p/3026189776070153?f=rss", "description": "", "published": "2024-11-07 10:39:40", "id": "24cb2a66-0ef8-4608-a087-dfc623a829b9", "source": "36氪", "section": "文章资讯"}, {"title": "万达电影11月7日缩量上涨1.26%；万达电影第三季度业绩受票房影响，期待票房修复带来业绩增长", "link": "https://36kr.com/p/3026168289502472?f=rss", "description": "", "published": "2024-11-07 10:17:53", "id": "bf6001a7-d41f-4e5f-9d93-cdc284f42268", "source": "36氪", "section": "文章资讯"}, {"title": "为啥全球富豪都爱“买买买”球队？篮网让蔡崇信赚翻了", "link": "https://36kr.com/p/3026126362518790?f=rss", "description": "<blockquote>\n   <p>‍许多超级富豪都喜欢收集豪华轿车，抢购度假屋，购买越来越大的游艇。其中，购买球队便是一些超级富豪热衷的“爱好”之一。</p>\n   <p>我们发现，世界上许多亿万富豪都非常执着于买球队。今日，家办新智点盘点了部分热衷于买球队的超级富豪，并分析了他们爱买球队的核心原因。</p>\n  </blockquote>\n  <h2><strong>1 蔡崇信的“野心”</strong></h2>\n  <p>多年来，蔡崇信一直都作为马云的“副手”出现，但他有自己的“野心”。</p>\n  <p>出生于中国台湾的蔡崇信（Joseph Tsai），13岁时，被送往美国新泽西州劳伦斯维尔的劳伦斯维尔学校就读。在那里，他打长曲棍球和橄榄球（内线卫）。少年时，他的大部分时间都在费城附近为NBA76人队的布鲁克林篮网队加油。渐渐地，他对拥有这支球队有了渴望。</p>\n  <p>机会出现在2017年，当时布鲁克林篮网的老板米哈伊尔·普罗霍罗夫 (Mikhail Prokhorov) 打算出售49%的球队股份，蔡崇信最终以10亿美元拿下了这笔交易。</p>\n  <p>但当代表他的投资银行家向他转发交易条款清单时，蔡崇信决定重新考虑之前的做法。</p>\n  <p>“我投入了（球队价值的）一半资金，然后我得到了一份条款清单，他们对待我就像只拥有1%一样。我当时想，‘拜托，我是个律师。我知道如何阅读条款清单，这并没有给我任何权利，’”蔡崇信在一次视频通话中回忆道。“在那之后，我很快就决定转变方向，直接进入这个过程。”</p>\n  <p>蔡崇信毕业于耶鲁大学和耶鲁法学院，他很快召集了自己的“杂牌团队”，这也是他给自己的核心圈子起的名字，成员包括陶哲轩（Rich Tao，耶鲁大学法学博士，蓝池资本总裁）、奥利弗·韦斯伯格（Oliver Weisberg，现任蓝池资本CEO、NBA布鲁克林篮网队替补总裁、J Tsai Sports的首席执行官）和亨利·李（Henry Li，蓝池资本总法律顾问）。</p>\n  <p>帮助管理蔡崇信家族办公室蓝池资本的陶哲轩表示：“如果你提交了一个很大的数字，就像我们做的那样，但在几个小时内没有收到回复，那么你显然不是名单上的第一个人。”</p>\n  <p>蔡崇信说：“这个过程让我明白，作为球队的少数股东并不是一件有趣的事情。”</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_5a6a7fe599b749548e056243c1ed12e5@000000_oswg578273oswg700oswg467_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">喜爱体育活动的蔡崇信（中），常亲自到现场关心自家球队表现</p>\n  <p>碰巧的是，普罗霍罗夫还想出售篮网队剩余的51%股份，并可选择在2021年之前购买剩余股份。2019年，蔡崇信行使了该选择权，以13.5亿美元收购了剩余股份。</p>\n  <p><strong>至于为什么要买NBA，“篮球是一项全球性的运动，光是在中国，我听过的篮球观众估算，从三亿人到七亿人都有；NBA已经是中国收视人口最大的运动赛事，甚至还超过足球。”</strong>蔡崇信曾表示。</p>\n  <p>“亚洲，尤其是中国，对NBA而言是一个不断扩张的市场，Joe（蔡崇信）是一个可以帮助球队和联盟的切入点。”一位运动传媒公司创始人透露道。</p>\n  <p>自从买下篮网队后，蔡崇信就开始在体育方面进行疯狂的投资。2019年，他收购了WNBA（美国职业女篮）纽约自由队。</p>\n  <p>此外，他还拥有两支长曲棍球队——国家袋棍球联盟(NLL)圣地亚哥海豹队和拉斯维加斯沙漠犬队、国家美式足球联盟(NFL)卡罗纳黑豹队(部分股权)、美国职业足球大联盟(MLS)洛杉矶足球俱乐部队(部分股权)等。</p>\n  <p>此外，蔡崇信还是J Tsai Sports的董事长，该公司投资了新兴的长曲棍球联盟、英超长曲棍球联盟等。</p>\n  <p>2024年6月，科赫家族（据《福布斯》估计其资产达652亿美元）将以6.88亿美元买下NBA篮网队15%股权。投资完成后，布鲁克林篮网队和纽约自由人队的总估值约为60亿美元，打破NBA历史纪录。</p>\n  <p>据悉，10月，蔡崇 信将联合私募股权公司 Ares Management 买下迈阿密海豚队少数股权。</p>\n  <p>据了解谈判情况的人士透露，该交易还包括硬石体育场、迈阿密大奖赛 F1 赛事的经营权以及大约一半的迈阿密公开赛，资产价值为 81 亿美元。一位接近谈判的消息人士向透露，这些资产的控制性估值将超过 100 亿美元。</p>\n  <p>此时的蔡崇信从阿里隐退后，又回归了阿里，并从马云的“阴影”下走到了“台前”。他现在是阿里巴巴主席，同时是菜鸟集团董事长、淘天集团及阿里国际数字商业集团董事、蚂蚁集团的董事。</p>\n  <h2><strong>2 鲍尔默的“避税”</strong></h2>\n  <p>2014年，微软前CEO史蒂文·安东尼·鲍尔默（Steven Anthony Ballmer）以20亿美元收购了NBA的洛杉矶快船队（the LA Clippers）。《福布斯》目前对该球队的估值为46.5亿美元。</p>\n  <p>购买球队，可以让鲍尔默等球队老板享受球队资产的各种减税优惠，从媒体交易到球员合同，就像工业家享受工厂设备减税优惠一样。这帮助他们缴纳的税率低于球员甚至体育场工作人员。</p>\n  <p><strong>2019年，鲍尔默报告的收入为6.56亿美元，需纳税7800万美元。据一审查记录显示，他的联邦所得税税率仅为12%，税率如此之低，部分原因是美国税法的一项规定：</strong></p>\n  <p><strong>当有人购买一家企业时，他们通常能够在接下来的几年中从收入中扣除几乎全部的销售价格，这样就可以少交税。</strong></p>\n  <p><strong>其基本逻辑是，购买价格由资产（建筑物、设备、专利等）组成，这些资产会随着时间的推移而贬值，应计入费用。</strong></p>\n  <p><strong>这使得鲍尔默可以施展一种财务“魔术”。</strong>如果他从快船队获利，便可以合法地向美国国税局报告他正在亏损，从而节省大量税款；如果快船队在某一年没有盈利，他可以告诉美国国税局他的亏损要大得多。</p>\n  <p>快船队近年来已上报了7亿美元的税务损失。鲍尔默不仅无需为快船队的任何实际利润纳税，还可以使用税收减免来抵消他的其他收入。</p>\n  <p>然而实际上，从快船队的实际财务业绩来看，这家公司经常盈利。这些业绩包括鲍尔默收购球队前美国银行报告中披露的审计财务数据，以及鲍尔默成为球队老板后泄露的NBA记录。</p>\n  <p>鲍尔默并不是唯一一个这么做的人。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_49ea36fb58484e8c81154f870fef62a4@000000_oswg967517oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>一些球队老板报告的球队收入比实际收入低数百万美元，包括汽车大亨沙希德·汗 (Shahid Khan)，尽管他的足球队一直被预测每年能带来数百万美元的收入，但他却从杰克逊维尔美洲虎队的股份中损失了至少7900万美元；</p>\n  <p>以及新泽西州房地产开发商伦纳德·威尔夫 (Leonard Wilf) 与家人共同拥有明尼苏达维京人队，他从球队的少数股权中损失6600万美元等。</p>\n  <p>亿万富翁通过避开应纳税的收入类型，向政府缴纳的税款少得惊人。</p>\n  <p>球队所有权作为一种避税方式的历史可以追溯到近一个世纪前。20世纪40年代克利夫兰印第安人队和后来的芝加哥白袜队老板比尔·维克在他的回忆录中直言不讳：“你看，我们在每场比赛前都会播放星条旗。你还想让我们缴纳所得税吗？”</p>\n  <p>几十年前，曾担任多伦多蓝鸟队总裁和美国职棒大联盟总裁的保罗·比斯顿（Paul Beeston）曾如此说道，“根据公认会计原则，我可以将400万美元的利润变成200万美元的亏损，而且我可以让每一家全国性的会计师事务所都同意我的观点。”</p>\n  <p>如今，球队老板不仅可以减免他们为球员合同支付的费用，还可以减免一系列其他项目的费用，譬如电视和广播合同，甚至商誉，这是一个模糊的会计概念。</p>\n  <p><strong>总的来说，这意味着，当亿万富翁购买球队时，法律允许他们将所购买的几乎所有资产（包括不会贬值的资产）视为随着时间的推移而贬值。</strong></p>\n  <p><strong>事实上，在过去的几十年里，在大联盟中经营特许经营权的权利已经成为“印钞许可证”。</strong>在过去的二十年里，篮球、足球、棒球和冰球队的平均价值增长了500%以上。</p>\n  <h2><strong>3 亿万富翁热衷于买球队</strong></h2>\n  <p>除蔡崇信、鲍尔默等人热衷于买球队外，许多亿万富翁们也同样热爱买球队。</p>\n  <p>罗伯·沃尔顿身价846亿美元，是沃尔玛和山姆会员店创始人山姆·沃尔顿的三个孩子之一。2022年，他与女儿凯莉·沃尔顿·佩纳、她的丈夫兼沃尔玛董事长格雷格·佩纳以及ArielInvestments联席主席梅洛迪·霍布森共同，以46.5亿美元收购了丹佛野马足球队。</p>\n  <p>沃尔顿当时在一份声明中表示:“我们在科罗拉多州的生活和工作中，一直很钦佩野马队。凯莉、格雷格和我很荣幸有机会在一个充满机遇和热情的社区中管理这个伟大的充满活力的社区。”</p>\n  <p>这是当时北美职业体育队最昂贵的交易记录，后来华盛顿指挥队以61亿美元的价格卖给了亿万富翁乔什·哈里斯领导的私募股权集团，打破了这一记录。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_e7c87480e47d4f278e6c544b10f49bb2@000000_oswg200285oswg780oswg521_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">Dan Gilber</p>\n  <p>Rocket Mortgage（一家美国抵押贷款机构）联合创始人Dan Gilber资产达290亿美元，他拥有数家体育特许经营权，包括美国冰球联盟的克利夫兰怪兽队和NBAG联赛的克利夫兰冲锋队。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_d54f6bee02ea4753a4fe8417a6bac1dd@000000_oswg548708oswg783oswg527_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">米里亚姆·阿德尔森（Miriam Adelson）</p>\n  <p>赌场大亨米里亚姆·阿德尔森（Miriam Adelson）及其家族净资产320亿美元，2023年买下了达拉斯小牛队(NBA)。米丽亚姆·阿德尔森是拉斯维加斯金沙赌场前老板谢尔登·阿德尔森的遗孀，谢尔登于2021年去世。她和她的家人拥有这个赌博王国的一半以上资产。</p>\n  <p>全球对冲基金Appaloosa Management创始人David Tepper净资产达198亿美元。2018年，他以22.75亿美元收购了卡罗莱纳黑豹队，相当于当时NEL的纪录。他之前持有匹兹堡钢人球队约5%的股权。Tepper还拥有美国职业足球大联盟夏洛特足球俱乐部。</p>\n  <p>以下为全球最富有的体育老板排名（不完全统计）。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_e83d4ba4167e4c979fb42ba54c22bf74@000000_oswg924779oswg1080oswg1789_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2><strong>4 “吸金石”</strong></h2>\n  <p>私募股权公司Clayton以及Dubilier&amp;Rice联席总裁里克·施纳尔(Rick Schnall）是亚特兰大老鹰队的少数股东以及夏洛特黄蜂队的多数股东之一，他曾在2023年8月介绍夏洛特黄蜂队新东家的新闻发布会上，向众人透露了一个亿万富翁阶层的秘密：</p>\n  <p>如果你有足够的资源来购买一支大联盟的运动队，特别是NFL和NBA，那么你就不会失败。</p>\n  <p>以足球为例，自从丹尼尔·斯奈德（Daniel Marc Snyder）于1999年收购华盛顿指挥官队以来，该队的胜率与黄蜂队一样糟糕。除此之外，该队还有其他糟糕的问题。不得已，丹尼尔·斯奈德出售了这项“不良资产”，但却获得了体育史上最高的61亿美元。买家们非但没有认为被骗，反而欣喜若狂。</p>\n  <p>因为他们知道，自2007年以来，四大联赛（NBA、NFL、NHL和MLB）的平均估值已上涨了5-8倍，没有一支球队倒闭过。</p>\n  <p><strong>他们知道，即使估值飞涨，过去两年的每次出售都超过了乐观的估值。他们还知道，亿万富翁的数量在过去十年中几乎翻了一番，所以如果他们决定出售，不会缺少买家。</strong></p>\n  <p><strong>这些亿万富翁们需要的不是另一艘超级游艇，而是一艘真正“不会沉没”的豪华游艇，足以容纳18,000-80,000名付费客人，以及数百万在家观看比赛的客人，每个赛季有8次、41次甚至81次。</strong></p>\n  <p><strong>飙升的球队价值、投资安全性和极端稀缺性使体育特许经营权就像一块“磁石”，吸引着亿万富翁们。</strong>电视收入的激增，以及其他将投资货币化的方式——全球营销、互联网、流媒体服务、商品销售，让这些亿万富翁们认为投资球队一定不会失败。</p>\n  <p>自从杰里·琼斯（Jerry Jones）以1.4亿美元收购了资金拮据的达拉斯牛仔队（Dallas Cowboys）后，如今，该队已成为全球市值最高的球队，市值达90亿美元）。</p>\n  <p>2929 Entertainment联合创始人马克·库班（Mark Cuban）以35亿美元的价格将达拉斯小牛队的大部分股份出售给了亿万富翁米丽亚姆·阿德尔森和拉斯维加斯金沙集团的所有者杜蒙特家族，而当时他收购该球队股份时仅仅花了2.85亿美元。他现在仍拥有该球队27%股份。</p>\n  <p>1921年，实业家威廉·瑞格利 (William Wrigley Jr.)买下了芝加哥小熊队。60年后，这支球队就像是他家族财富驱动业务上的闪亮引擎盖装饰，以2050万美元的价格售出。</p>\n  <p><strong>不仅如此，还有的投资者靠买球队，逆风翻盘，联姻了皇室家族。</strong></p>\n  <p>马拉家族是纽约下东区一个苦苦挣扎的移民家庭，直到1925年他们以500美元买下纽约足球巨人队，这笔交易首先带来了经济保障，然后带来了巨额意外之财：2023年，这支球队的估值超过70亿美元。</p>\n  <p>其中一位马拉家族成员嫁给了NFL的另一个皇室家族，即匹兹堡钢人队的长期所有者鲁尼家族。这两大家族共同在好莱坞声名鹊起（演员凯特·玛拉和鲁妮·玛拉），并进入权力殿堂（已故驻爱尔兰特命全权大使丹·鲁尼）。</p>\n  <p><strong>多年来，一些有钱人加入体育队不是为了挣钱，而是为了打破社会壁垒。</strong></p>\n  <p>穆罕默德·法耶兹一心想获得英国公民身份并跻身英国上流社会，1997年，在他儿子多迪·法耶兹和戴安娜王妃死于车祸的几个月前，他以900万美元的价格收购了位于伦敦的富勒姆足球队。</p>\n  <p>法耶兹在比赛中招待了迈克尔·杰克逊这样的明星，并带领球队晋级英超联赛，但他既没有获得公民身份，也没有获得认可。尽管如此，富勒姆的价值还是飙升；据报道，当他在2013年出售富勒姆时，法耶兹的身价超过了2.25亿美元。</p>\n  <p>这些创纪录的销售额改变了人们对体育团队的看法，使其从财富“存放地”转变为快速增长财富的动力。</p>\n  <p><strong>NFL和NBA球队就像“稀有钻石”，超级富豪们为了得到一支球队，争相抢夺。</strong>过去11年，NFL球队已经被卖出四次，联盟的老板们平均会持有球队40年。这种“黄金门票”一生难得一见。亿万富翁们对“球队”的投入，似乎不存在极限。</p>\n  <p>在这几年里，全联盟的媒体交易也变得更加有利可图，因为体育赛事已成为电视和流媒体服务上最后必看的直播赛事。</p>\n  <p><strong>除此之外，富豪们还热衷于投资体育馆。</strong></p>\n  <p>蔡崇信拥有布鲁克林大型体育馆巴克莱中心（BarclaysCenter）的运营权。作为J Tsai Sports的董事长，他还投资了总部位于北美和亚洲的多家体育媒体和科技公司。2022年，他领投了专注于女子体育的美国媒体公司Just Women's Sports的一轮投资；</p>\n  <p>纽约尼克斯队老板詹姆斯·多兰 (James Dolan) 在拉斯维加斯建造了球形体育场；</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_1467cd8d0663417f87277e32267529ad@000000_oswg1341205oswg879oswg576_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_567ab971adde4092862147b8917aeec5@5091053_oswg83948oswg640oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">Intuit Dome球场</p>\n  <p>鲍尔默拥有位于加利福尼亚州英格尔伍德的Intuit Dome球场。球馆奢华无比，为了激发球迷的热情，鲍尔默将51排座位指定为铁杆球迷专用，而不是豪华包厢。这些座位经过电子验证，除通过快船市场外，不得转售。（这些座位上还禁止出售对方球队的装备。）这座体育场已被选为2026年NBA全明星赛的举办地。</p>\n  <p><strong>鲍尔默喜笑颜开，称他的建筑是体育场馆的“巅峰”。他大喊道：“我们有卫生间——很多卫生间！”，以此来调侃自己对卫生间的执着。</strong></p>\n  <p>尽管在2022年至2023年期间，快船队处于亏损状态，但随着新球馆的建成，球队的价值又上涨了19%。当新球馆开业时，预计增加的收入将进一步推高估值。</p>\n  <p>事实证明，至少对于那些身价12位数的人来说，把钱扔进马桶（指的是建造许多卫生间）都是值得的。Intuit Dome的卫生间数量是其他球馆的三倍。</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5MDU1OTIzMg==&amp;mid=2247499501&amp;idx=1&amp;sn=d718fee3d52a957854542c139ddaf338&amp;chksm=cefe18d11fd87bf2cc89f7b13bcc72576b0727d68df71e6c4edc7a37064db93e516a2e00f97a&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“家办新智点”（ID：foinsight）</a>，作者：foinsight，36氪经授权发布。</p>", "published": "2024-11-07 10:16:11", "id": "59898a9e-d263-44c3-b764-e65adf6c5a43", "source": "36氪", "section": "文章资讯"}, {"title": "电影市场“入冬”：观影人次急降，仅7家影视上市公司第三季度盈利", "link": "https://36kr.com/p/3026131353200132?f=rss", "description": "<p>随着2024年各大重要影视档期——春节档、五一档、暑期档直至国庆档的相继落幕，18家影视公司的年度表现基本尘埃落定，却都未能交出令人满意的成绩单。</p>\n  <p>深入剖析财报数据，今年第三季度，影视行业的盈利景象并不乐观，仅有7家公司得以维持正利润，而在这些盈利的公司中，能实现同比增长的更是寥寥无几，仅捷成股份（300182.SZ，股价5.8元，市值154.5亿元）、华策影视（300133.SZ，股价8.09元，市值153.8亿元）及中广天择（603721.SH，股价30.1元，市值39.13亿元）三家。</p>\n  <p>反观行业大势，归母净利润同比下滑成为了多数影视公司的常态。诸如万达电影（002739.SZ）、横店影视（603103.SH）、金逸影视（002905.SZ）及幸福蓝海（300528.SZ）等公司，其归母净利润同比下滑（亏损扩大）幅度分别达92.01%、157.75%、162.21%、219.3%，博纳影业则同比转亏。</p>\n  <p>万达电影在其公告中坦承，2024年第三季度，全国电影票房108.6亿元，较2023年同期下降43.8%，观影人次2.65亿，较2023年同期下降43.3%，主要由于暑期档头部爆款影片较2023年有所减少，电影行业整体表现相对平淡。</p>\n  <p>将时间轴拉长至整个前三季度，影视公司的业绩表现依旧普遍低迷。归母净利润超过1亿元的影视公司屈指可数，仅有6家，而营收不足1亿元的公司则有三家。</p>\n  <p>中国电影评论学会产业评论专委会副会长、聚影汇创始人朱玉卿对《每日经济新闻》记者指出，电影对观众的吸引力正逐渐减弱，非节假日时段，部分影院的场均观影人次甚至不足5人。他预测，与2023年相比，今年全年的票房数据或将大幅下滑，差额可能达到100亿元。</p>\n  <h2><strong>《第二十条》撑起光线传媒业绩</strong></h2>\n  <p>今年前三季度，18家影视公司中，只有8家影视公司盈利，10家影视陷入亏损。</p>\n  <p>2024年，“最赚钱”的影视公司是光线传媒。财报显示，光线传媒前三季度营业收入为14.42亿元，同比增长55.37%；净利润4.61亿元，同比增长25.08%。</p>\n  <p>把“最赚钱”打上引号，是因为9个月过去了，光线传媒的亮眼业绩还得追溯到春节期间上映的《第二十条》。单看第三季度的业绩，光线传媒亏损约0.12亿元。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_ead537aba6ab4224b949b65d7483c81c@5091053_oswg457329oswg1080oswg1800_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">《第二十条》宣传海报 图片 来源：豆瓣</p>\n  <p>光线传媒对此表示，前三季度公司参与投资、发行并计入票房的影片包括《大雨》《第二十条》《草木人间》《扫黑·决不放弃》以及第三季度上映的《从21世纪安全撤离》，2023年上映并有部分票房结转的影片包括《照明商店》。《怒潮》《你的婚礼》（复映），总票房约为29.27亿元。</p>\n  <p>然而，《每日经济新闻》记者统计发现，《大雨》《第二十条》《草木人间》《扫黑·决不放弃》和《从21世纪安全撤离》几部影片的票房成绩分别为0.17亿元、24.54亿元、1.21亿元、1.92亿元和1.12亿元。其中《第二十条》一部影片的票房成绩占了光线传媒这一年主要影片票房的84.7%，成为业绩支柱。</p>\n  <p>到了第四季度，国庆期间，光线传媒也没有主出品的影片上映。根据公告，由赵丽颖、辛芷蕾主演的电影《乔妍的心事》于10月26日上映，光线传媒参与投资、发行，但截至11月5日，该影片票房只有1.35亿元。</p>\n  <p>作为曾推出过《哪吒之魔童降世》《姜子牙》《大鱼海棠》等多部优秀动画电影的“国漫之光”，光线传媒在动画电影领域的表现一直备受瞩目。然而，今年五一前，动画电影《小倩》宣布撤档后，至今仍处于择机待映阶段；而备受期待的《哪吒之魔童闹海》虽然被视为2025年春节档的种子选手，但至今也未传来定档的消息。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_9c75a2d553764c6f9109ba41b1cc2b7b@5091053_oswg93360oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">《哪吒之魔童闹海》宣传海报 图片来源：豆瓣</p>\n  <p>此外，11月4日，光线传媒发布公告，控股股东光线控股有限公司（以下简称光线控股）将其所持有的部分公司股份办理了质押延期购回，光线控股此前于2023年11月2日质押公司5252万股用于偿还债务，原质押到期日为11月1日，现延期至2025年10月31日。截至公告披露日，光线控股累计质押公司股份3.53亿股，占公司股份总数的12.05%。</p>\n  <h2><strong>《蛟龙行动》《哪吒之魔童闹海》等大片等待上映时机</strong></h2>\n  <p>细看2024年第三季度，电影公司的业绩“黯然”是全方位的。18家A股影视公司中，只有7家公司盈利，其中捷成股份盈利1.12亿元，剩下6家影视公司净利润均未破1亿元。</p>\n  <p>在利润表现上更是乏善可陈，仅有5家公司实现了正增长。值得注意的是，博纳影业同比转亏，欢瑞世纪亏损幅度同比扩大3579.68%。</p>\n  <p>关于净利润大幅亏损，欢瑞世纪的解释为主要系按组合账龄计提信用减值影响以及本报告期内影视剧计提跌价所致。但是关于营业收入、营业成本的下降，欢瑞世纪在财报中点明了是因为影视剧售卖的减少。</p>\n  <p>在第三季度，净利润亏损最多的是博纳影业，亏损额为2.16亿元。事实上，拉长到2024年前三季度，博纳影业也是以3.98亿元的亏损额排在影视公司中的倒数第二名。</p>\n  <p>关于营收和净利润的双降，博纳影业表示主要系公司投资电影票房不及预期，且第三季度电影市场整体票房低于2023年同期，导致影院放映收入较2023年度同期有所下降所致。</p>\n  <p>《每日经济新闻》记者观察到，截至三季报发布日，博纳影业董事长于冬持有公司股份数量2.82亿股，其中1.37亿股股票为质押状态，质押率达到48.7%。</p>\n  <p>根据灯塔专业版，从全国票房数据来看，截至11月5日，今年总票房仅为388亿元，与2023年全年的549.53亿元相比，差距超过160亿元。尽管场次数量与去年相近，但观影人次的急剧减少成为票房下滑的主要原因。截至目前，全年总出票量仅为9.15亿张，远低于2023年的13亿张。</p>\n  <p>这一点，院线公司感受更深。今年第三季度，万达电影、横店影视、金逸影视和幸福蓝海几大院线公司的净利润分别为0.55亿元、-0.71亿元、-0.39亿元和0.4亿元，同比下滑92.01%、157.75%、162.21%和219.3%。</p>\n  <p>为了应对票房收入不足的挑战，万达电影开始尝试跨界合作，如开设首家“花花世界”爆米花专营店，并与头部游戏《原神》进行联动。</p>\n  <p>除了电影业务，博纳影业也在积极开拓电视剧市场。由黄轩、王雷主演的剧集《上甘岭》于2024年10月中旬开播。截至收官前，该剧观众规模突破2亿，酷云数据显示该剧暂列2024年剧集平均收视率年冠。</p>\n  <p>此外，博纳影业还凭借AI技术进入了微短剧行业。今年7月，由博纳影业出品制作的国内首部AIGC生成连续性叙事科幻短剧集《三星堆·未来启示录》在抖音上线。并非所有尝试都取得了成功，博纳影业出品的同样应用AI技术制作的电影《传说》票房并未达到预期。今年1月，在博纳影业发布的《关于新增募投项目的公告》中，曾披露过拟使用募集资金1.1亿元用于新增募投项目电影《传说》，但最终影片票房仅0.8亿元。</p>\n  <p>在日前举行的第二十六届全国影片推介会上，博纳影业宣布《蛟龙行动》将于2025年上映。不过，目前真正宣布定档于2025年春节档上映的影片仅有《封神第二部：战火西岐》和《熊出没·重启未来》。包括博纳影业出品的《蛟龙行动》、光线传媒出品的《哪吒之魔童闹海》、万达电影出品的《唐探1990》以及中国电影、横店影视出品的《射雕英雄传·侠之大者》在内的多部影片仍在等待合适的上映时机。</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/DYqwP68q78HTW1Ok6b8Wkw\" rel=\"noopener noreferrer\" target=\"_blank\">“每经影视”</a>，作者：毕媛媛，编辑：杨夏，36氪经授权发布。</p>", "published": "2024-11-07 10:15:49", "id": "63ba1ab5-9584-4387-88b2-f12cd8e0e8f3", "source": "36氪", "section": "文章资讯"}, {"title": "第一批增程车快要换电池了，4年衰减近25%，纯电车主笑了", "link": "https://36kr.com/p/3026135985563140?f=rss", "description": "<p>最近一段时间，「增程神教」风头无两，彻底压过纯电路线。</p>\n  <p>先是理想汽车，和摸着它过河的零跑汽车，拿下10月新势力销量冠亚军。</p>\n  <p>11月初，路透社又爆料，蔚来计划在海外推出增程车型；小鹏汽车更是不装了，官宣做增程车。</p>\n  <p>再加上被曝光的小米、极氪增程车型。放眼望去，新势力车企已经没几家专心做纯电的了。</p>\n  <p>但纯电车主也不要灰心，<strong>11月5日中汽试炼场的一份报告，扯下增程车「皇帝的新装」。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_efc962bde1474f2d8311288099681279@5091053_oswg96457oswg1080oswg618_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2><strong>01 4年衰减近25%，再过两年可能要换电池</strong></h2>\n  <p>在这份新能源汽车电池健康度评估测试报告中，<strong>2019款特斯拉Model 3，行驶11.6万公里后，电池健康度为89.3%。</strong></p>\n  <p>4年时间电池衰减10.7%，算是一个可以接受的数字，比iPhone表现要好多了。</p>\n  <p><strong>而2020款理想ONE，在行驶10.3万公里后，电池健康度仅有75.6%。</strong></p>\n  <p>4年时间电池衰减近25%，也比大多数iPhone的表现要好，但按照这个衰减速度下去，再过两年时间，或许就要换电池了。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_8112aa6034b14ed9b493e8d92650945c@5091053_oswg98478oswg1044oswg612_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>根据8月份发布，2025年3月1日实施的新能源车专属年检——《新能源汽车运行安全性能检验规程》。</p>\n  <p><strong>如果电池健康度低于60%，将被视为不合格，需要更换电池。</strong></p>\n  <p>诚然，很多车企都给自家新能源车，不少于8年的三电质保，有些甚至给到终身质保。</p>\n  <p>可这些质保都有诸多限制：必须是首任车主，必须是非营运车辆，维修保养时必须使用原厂提供的配件‌，在官方售后定期保养......</p>\n  <p><strong>要是电池年检不达标，车企是否会免费更换电池，还要打一个问号。</strong></p>\n  <p>如果是自费换电池，那价格可不便宜。</p>\n  <p>2023年，网上流传的一份特斯拉更换电池费用清单中，旗舰车型Model S/X，一块电池最贵24.6万元。Model 3/Y电池，则在12-15万元之间。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_20b309c966614e3ea72476f5554f42df@5091053_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>小鹏P7换电池的价格，则在8-10万元。</p>\n  <p>理想ONE这边没有官方数据，但40.5kWh的三元锂电池，便宜不到哪里去。</p>\n  <h2><strong>02 小电池循环次数多，衰减快很正常</strong></h2>\n  <p>需要注意的是，上述测试的样本太小，不能完全代表增程车电池的表现。</p>\n  <p>但增程车电池衰减比纯电车要快，却是一个不争的事实。</p>\n  <p><strong>原因很简单，很多人买了增程车回来，完全是当纯电车在用，只有偶尔跑长途才会用到汽油。</strong></p>\n  <p><strong>增程车电池小，循环次数更多，电池衰减自然会更快。</strong></p>\n  <p>比亚迪DM-i等插混车型，也是类似的道理。</p>\n  <p>汽车之家数据显示，2019款特斯拉Model 3，搭载52kWh三元锂电池，得益于风阻、车重和电机方面的优势，其NEDC续航有445公里。</p>\n  <p>2020款理想ONE，搭载40.5kWh三元锂电池，但因为是中大型SUV，风阻高、体重大、双电机，NEDC纯电续航只有180公里。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_54371a7bc13949cfb027e281768daabc@5091053_oswg35975oswg698oswg489_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>同样的通勤里程， 理想ONE车主，可能两三天就要充一次电；特斯拉Model 3车主，可以一两周充一次。</p>\n  <p><strong>而纯电状态下跑10万多公里，理想ONE电池循环次数，是特斯拉Model 3的两倍多。</strong></p>\n  <p>照这么看，上述测试中前者电池衰减近25%，是后者10.7%的两倍多，也就很合理了。</p>\n  <p>此外，增程车在混动模式下行驶，电池同样会有充放电。</p>\n  <p>官方资料显示，理想ONE急加速时，电池会与增程器一起给电机供电，匀速行驶时则接收增程器的多余电能。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_9e01d1164e0a4291a0360f02414d275c@5091053_oswg54457oswg721oswg221_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>有趣的是，此前理想官方发布了一份数据，表示在过去四年中，有78位车主的理想ONE行驶里程超过15万公里，电池健康度均在94%。</p>\n  <p>其中行驶里程最远的车主，驾驶理想ONE超过32万公里，电池健康度为92%。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_39d4ac80191546309a17740e833d1818@5091053_oswg152224oswg929oswg1200_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2><strong>03 固态电池是救星也是毒药</strong></h2>\n  <p>有什么办法，能控制增程车电池衰减速度吗？</p>\n  <p>有，比如固态电池。</p>\n  <p><strong>它相比目前在用的液态电池，具有高能量密度、快速充放电、低温性能优异以及高安全性、长寿命等优点。</strong></p>\n  <p>近日，华为公布了一项硫化物固态电解质新发明，名为《掺杂硫化物材料及其制备方法、锂离子电池》。</p>\n  <p>专利申请内容显示，本实现方式公开的掺杂硫化物材料，可以作为硫化物固态电解质应用在锂离子电池中，使得锂离子电池具有较长的使用寿命。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_ff8ddcea4b0740d391b4529b3f228d59@5091053_oswg177597oswg600oswg353_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>另据晚点Auto消息，<strong>宁德时代全固态电池，已进入20Ah样品试制阶段，预计2027年实现小批量生产。</strong></p>\n  <p>它能将三元锂电池的能量密度做到500Wh/kg，比现有电池提升40%以上。</p>\n  <p>但问题来了，增程车本就是为解决纯电车续航焦虑，才诞生的一个品类。</p>\n  <p>固态电池在解决电池衰减的同时，也顺带搞定了续航焦虑，那我们还会需要增程车吗？</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/klFRVmvvGkp_w9Ch6AWiKw\" rel=\"noopener noreferrer\" target=\"_blank\">“科技每日推送”</a>，作者：周伟鹏，编辑：汤安迪，36氪经授权发布。</p>", "published": "2024-11-07 10:15:30", "id": "3ce44afa-6535-48b9-8fb5-854a49e945cc", "source": "36氪", "section": "文章资讯"}, {"title": "CoWoS，是一门好生意", "link": "https://36kr.com/p/3026139385275907?f=rss", "description": "<p>台积电正在考虑涨价。</p>\n  <p>涨价的对象除了3nm先进工艺，还有CoWoS先进封装。明年3nm涨约5%，而<strong>CoWoS则高涨10%～20%。</strong></p>\n  <p>“不是AI芯片短缺，而是我们的CoWoS产能短缺。”这是台积电刘德音在接受采访时的回答。这项台积电默默培育十多年的技术，成为全球瞩目的焦点。</p>\n  <h2><strong>01 CoWoS的巨大需求</strong></h2>\n  <p>凭借着CoWoS台积电几乎要成为全球最大的封装厂了。</p>\n  <p>先进封装占台积电整体业绩的比重逐步增高，相关毛利率也逐步提升。有分析师预计，台积电今年先进封装营收可以超越70亿美元，挑战80亿美元。先进封装目前约占台积电营收的 7%～9%，预计未来五年该部门的增长将超过台积电的平均水平。</p>\n  <p>这与台积电CoWoS封装技术不无关系。不少AI芯片都需要采用CoWoS的封装技术。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_e4022173f92843e288b7b2b70bb17cee@000000_oswg222143oswg1080oswg644_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>我们可以看下CoWoS的市场需求。打头阵的是英伟达，英伟达占整体供应量比重超过50%。之前的A100和H100等用的都是CoWoS封装。之后的Blackwell Ultra 产品，也是使用的台积电CoWoS封装工艺。而到了明年，英伟达将会推广采用 CoWoS-L 技术的 B300 和 GB300 系列。</p>\n  <p>AMD的MI300用的是台积电SoIC（3D）和CoWoS（2.5D）两种封装技术。此外，博通、微软、亚马逊、谷歌对于CoWoS的也有一定的需求。据机构统计，AMD和博通对CoWoS产能需求，合计的占比超过27.7%。</p>\n  <p>目前，AI芯片虽然没有采用最先进的制造工艺，但高度依赖先进的封装技术。全球半导体公司能否从台积电获得更先进的封装产能，将决定其市场渗透率和控制力。</p>\n  <p>因此有消息称，<strong>英伟达为了获得更多CoWoS产能，甚至表示愿意涨价</strong>，从而拉开与竞争对手的距离。不过这一消息也不算空穴来风，因为黄仁勋真的在公开场合强调：“台积电不只是生产晶圆，还处理着众多供应链问题。”他也认同目前定价过低，支持台积电涨价的举措。</p>\n  <p>从目前的CoWoS需求来看，<strong>即使到了明年，英伟达50%占比仍然不会变，而AMD在台积电的CoWoS封装订单量将小幅增加。</strong>据预估，英伟达对CoWoS-L工艺的需求可能会从2024年的3.2万片晶圆大幅增加至2025年的38万片晶圆，同比增长1018%。</p>\n  <p>如此巨大的CoWoS需求，使得台积电频频提及扩产。</p>\n  <h2><strong>02 CoWoS怎么走到这一步？</strong></h2>\n  <p>CoWoS并非一飞冲天，而是默默前行。</p>\n  <p>先进封装不是一个新概念，追溯历史，2000年是先进封装的转折点。从这一年开始，封装从传统的引线接合、倒装芯片方式，转向“晶圆级封装”。</p>\n  <p>早在2008年，台积电便成立集成互连与封装技术整合部门（IIPD）入局先进封装。</p>\n  <p>当时的台积电在金融危机的影响下，陷入了经营亏损。内忧外患下，张忠谋重新出山执掌台积电，同时请回已经退休的蒋尚义掌舵研发，开发先进封装技术进行差异化竞争。据蒋尚义回忆，最初提出先进封装而被公司（台积电）内部视为“笑话”。</p>\n  <p>2011年，台积电开发出了第一代 CoWoS封装技术，这是最初的起源。当时，CoWoS 使用硅（Si）衬底作为中间衬底（中介层），将多个芯片集成在一个封装体内，实现了更高的互连密度和更好的性能。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_86cef15d732f453b8f8c995c2604c58c@000000_oswg37166oswg1080oswg312_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">来源：台积电CoWoS纪事表</p>\n  <p>此时，人们对于CoWoS还是缺乏兴趣。<strong>第一个愿意采用成本高昂CoWoS技术的公司还是华为。</strong>台积电CoWoS的记事表中显示，<strong>在2014年海思Hi1616芯片采用了CoWoS工艺。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_5f76edd578d34d96a50d0b1626382b4a@000000_oswg200135oswg1080oswg536_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>之后，CoWoS封装不断改进发展。现在CoWoS是一种2.5D的整合生产技术，由CoW和WoS组合而来：CoW就是将芯片堆叠在晶圆上（Chip-on-Wafer），而WoS就是基板上的晶圆（Wafer-on-Substrate），整合成CoWoS。</p>\n  <p>据不同的中介层，台积电将CoWoS封装技术分为了三类：第一类，CoWoS-S，使用Si衬底作为中介层；第二类CoWoS-R，使用重新布线层（RDL）作为中介层；第三类CoWoS-L，使用小芯片（Chiplet）和RDL作为中介层。</p>\n  <p>在最新的演讲中，台积电高效能封装整合处处长侯上勇表示，作为能满足所有条件的最佳解决方案，<strong>台积电的先进封装重点会从CoWoS-S 逐步转移至CoWoS-L，</strong>并称CoWoS-L 是未来蓝图关键技术。</p>\n  <p>侯上勇认为，由于顶部晶片（Top Die）成本非常高，CoWoS-L 是比CoWoS-R、CoWoS-S 更能满足所有条件的最佳解决方案，且因为具有灵活性，可在其中介层实现异质整合，会有其专精的尺寸与功能。CoWoS-L 可兼容于各式各样的高效能顶级芯片，例如先进逻辑、SoIC 和HBM。</p>\n  <h2><strong>03 都在眼馋CoWoS产能</strong></h2>\n  <p><strong>台积电“吃肉”</strong></p>\n  <p>台积电CoWoS产能全部在中国台湾，共有五座先进封测厂，分别位于龙潭、竹科、竹南、中科、南科。</p>\n  <p>南科嘉义园区第一座P1厂已于5月动工，不过在施工的过程中挖到了疑似遗址，现依据文资法进行相关处理。官方的回答是相关清理工作会在今年10月完成，台积电嘉科先进封装厂规划明年第3季装机不受影响。根据先前规划，台积电会在嘉义建设2座CoWoS先进封装厂，原计划2028年量产。</p>\n  <p>竹南先进封装厂（AP6）已经在2023年6月正式启用，经过了一年的运营，随着设备移至AP6C厂，已成为台积电最大的CoWoS基地，第三季CoWoS月产能翻倍，由1.7万片增至3.3万片。</p>\n  <p>除了竹南厂区AP6C外，原本仅承接OS后期制程的中科厂区也将逐步转为CoW制程，而嘉义厂区则正处于土地整备阶段，预计进度将比铜锣厂更快。</p>\n  <p>三季度，台积电还新增了CoWoS相关机台，并已要求设备厂商增派工程师，以充实龙潭AP3厂、中部科学园区AP5厂的产能。</p>\n  <p>在财报会议上，台积电已经明确表示了，其CoWoS产能会在2024年和2025年每年翻一番，但需求仍将超过供应。</p>\n  <p>现在，台积电先进封装产能在2022至2026年，年复合成长率达到50％以上。台积电营运、先进封装技术暨服务副总何军表示：<strong>“以往3至5年盖一个厂，现在已缩短到2年内就要盖好，以满足客户需求。”</strong></p>\n  <p>不过，台积电的CoWoS具体的产能在财报中并没有披露。</p>\n  <p>何军曾在秀出简报数据时，幽默提到：“现在简报都不敢放（先进封装产能）数字，因为客人都一直说（产能）不够，所以干脆不放具体数字了”。</p>\n  <p>目前台积电的CoWoS多是机构预测。具体来看，<strong>投行评估</strong>，到今年底，台积电CoWoS月产能可超过3.2万片，到2025年底月产能约在7万片上下。<strong>Digitiems预测</strong>，到2025年第四季度末，台积电的月产能预计将增至6.5万片以上12英寸晶圆当量。<strong>花旗证券预估</strong>，台积电今年底的CoWoS产能为每月3万～4万片，在买下群创南科四厂之后，到2025年底的CoWoS产能从6万～7万片上调到每月9万～10万片。</p>\n  <p>业内人士表示，台积电向设备制造商提供了2026年的机台需求并下了订单。明年的交货计划基本上已经排满了，目前台积电正在与设备供应商合作，敲定2026年的出货和安装计划。</p>\n  <p><strong>日月光“喝汤”</strong></p>\n  <p>作为真正的全球的第一大封测厂商，日月光接到了台积电溢出的CoWoS需求。</p>\n  <p>日月光也掌握了先进封装技术，成为台积电解决CoWoS封装产能紧张的最佳伙伴。其中，在 CoWoS-S 先进封装后段制程中，更是与台积电密切合作。</p>\n  <p>业内人士分析，到2025年，台积电在CoWoS-S后段的oS封装制程，可能外包其中40%至50%比重给日月光投控，可增加相关业绩规模约1.5亿美元至2亿美元。</p>\n  <p><strong>为了CoWoS的生意，日月光最近开出了大笔的支出。</strong></p>\n  <p>10月份，日月光斥资近200亿新台币（约为44.56 亿人民币）购买厂务与设备。今年下半年日月光累计投资超过了470亿新台币（约为104.72 亿人民币），全年资本支出相对预测增加30亿美元。这么来推算的话，明年日月光的资本支持有望接近40亿美元。<strong>对于自身的斥资，日月光表示：“好戏在后头。”</strong></p>\n  <p>日月光的豪掷巨资主要用来购买，<strong>CoW所需的成熟制程曝光机设备机台</strong>，加上旗下矽品彰化二林厂及中科厂等据点都开始扩增无尘室及进驻设备机台。</p>\n  <p>要知道，日月光旗下矽品前段时间宣布，投资新台币4.19亿元，取得中科彰化二林园区土地使用权，扩充CoWoS先进封装。同时，矽品也进一步投资37.02亿元，向明徽能源取得云林斗六厂房土地，也是扩大CoWoS先进封装产能。</p>\n  <p>不止如此，日月光在10月上旬宣布，高雄市大社区K28厂预计2026年完工，主要目的就是要扩充CoWoS先进封测产能。</p>\n  <p><strong>安靠“啃骨头”</strong></p>\n  <p>一个月前，安靠和台积电一起宣布，双方已签署谅解备忘录，将携手合作为亚利桑那州引入先进封装与测试能力，进一步拓展该地区的半导体生态系统。</p>\n  <p>按照协议，台积电在亚利桑那州皮奥里亚计划建的工厂，会和 Amkor 签一个一站式的先进封装和测试服务合同。台积电会靠这些服务好好地支持自家客户，特别是那些用 台积电在凤凰城先进晶圆制造设备的客户。其中，<strong>涉及到的封装技术包括台积电的集成扇出型技术（InFO）和基板上晶圆上芯片技术（CoWoS）。</strong></p>\n  <p>实际上，台积电在亚利桑那州规划3座厂的先进晶圆制程，结合安靠的先进封装产线，有助提升台积电当地厂区的附加价值，也可稳定接单。</p>\n  <h2><strong>04 结语</strong></h2>\n  <p>台积电吃肉、日月光喝汤、安靠啃骨头。</p>\n  <p>根据Yole最新发布的《2024年先进封装状况》报告，预计2023—2029年先进封装市场的复合年增长率将达到11%，市场规模将扩大至695亿美元。</p>\n  <p>DIGITIMES Research称，受云端AI加速器需求旺盛推动，2025年全球对CoWoS及类似封装产能的需求或将增长113%。</p>\n  <p>从当下的需求来看，明年的CoWoS封装，也还是一门好生意。</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247769104&amp;idx=1&amp;sn=2637744f616150817c8b1b8bd3da5666&amp;chksm=c0ec76229a801a55c69a52b5d7dfe0a29da353a2a0180ae66c66efa8f367270066a9468f2571&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“半导体产业纵横”（ID：ICViews）</a>，作者：九林，36氪经授权发布。</p>", "published": "2024-11-07 10:15:07", "id": "3e0124a0-a172-40dd-b1d9-f7bcd8ee63fe", "source": "36氪", "section": "文章资讯"}, {"title": "大模型来了，我还用搜索吗？", "link": "https://36kr.com/p/3026144048227589?f=rss", "description": "<blockquote>\n   <p>黄仁勋说，未来每个人都有一个AI助手。传统搜索，正在被分流。</p>\n  </blockquote>\n  <p>AI搜索市场上，正在涌入一大波大大小小的“新用户”。</p>\n  <p>“前不久国家发行国库券，我爸爸在发行前一天晚上，问了豆包国库券的种类和利息。”一位长期关注科技领域的人士告诉数智前线，它回答的特别清晰和工整。豆包这样的大模型产品，正在改变自己79岁父亲，一直无法学会手机搜索引擎的情况。</p>\n  <p>另一位人士也透露，自己刚满三岁，正在语言爆发期的女儿，现在经常会用豆包进行搜索。“比如女儿会问我某个英语单词，我可能也忘了怎么读，就会让她自己去问。”</p>\n  <p>而在另一面，AI搜索市场最近也十分火热。不管是<strong>kimi、ChatGPT、腾讯元宝等国内外大模型公司</strong>，都在推AI搜索功能；而<strong>传统搜索引擎，如百度、谷歌，也都有新动作</strong>，引入大模型技术变革搜索。</p>\n  <p>为什么大家都要抢去抢这块市场？</p>\n  <p>“<strong>AI搜索，对于大模型来说，是高潜力赛道，也是能出真正独角兽的赛道。</strong>ToC的赛道来说，AI搜索有望塑造出全新的搜索巨头。而对ToB市场来说，企业级AI搜索也越来越重要。企业的知识管理、知识使用，都会涉及到AI搜索。”IDC中国研究总监卢言霞告诉数智前线，这是需求所在，也是必然趋势。</p>\n  <p>而在大模型到来一年多后，一些改变也已经悄然发生。最近，我们和最早使用大模型的一波用户聊了聊，看看他们眼中，大模型到底给自己的搜索习惯带来了哪些改变？</p>\n  <h2><strong>01</strong></h2>\n  <h2><strong>吴悠，某大模型公司程序员</strong></h2>\n  <h2><strong>有了编程助手，我还搜索吗？</strong></h2>\n  <p>“以前我用Google比较多，但现在像一些工作中碰到的语法问题，基本都会首先用大模型进行搜索。”吴悠目前在一家大模型公司做前端开发，他告诉数智前线，作为距离大模型最近的人群之一，他周边的程序员朋友和同事，已经在日常的搜索中广泛用上大模型的能力，甚至有人专门为此购买了ChatGPT的会员，来帮助自己进行代码写作。</p>\n  <p>事实上，<strong>程序员也是目前使用大模型最多、效果最为明显的群体之一。</strong>此前，来自金融、互联网等行业的多家企业都曾在一些会议上公开表示，大模型在辅助代码方面的应用，是试验下来确定性和ROI曲线都比较好的场景。</p>\n  <p>“为什么它在写代码方面挺好的？”吴悠分析称，比如在进行语法搜索时，以前用Google，需要自己一条一条去分析筛选搜出的信息，而大模型相当于帮忙提前进行了一次筛选，虽然其中可能还有20%左右的错误率，但因为代码最终都要运行一遍，因此也能迅速检验它写得对不对。</p>\n  <p>“如果运行不了或者还有错误，我再去搜Google。”吴悠说，现在，他的<strong>工作中70%以上的语法问题，都可以通过大模型解决</strong>。</p>\n  <p>不过，语法问题其实仅占所有编程工作的百分之二三十。大模型虽然在编程其他环节也有应用，但大家对效果的评价、体验并不完全一致。</p>\n  <p>“比如一些编程辅助工具可以猜出你接下来大概要写什么，让你少写一些代码，但这只局限于在你写一些偏底层和算法类的代码时，帮你节约时间，但如果想用它写业务代码，由于业务是千变万化的，可能反而会拖慢你的进度。”</p>\n  <p>吴悠举例称，当他在前端工作中想要写一个表单时，表单里有一些字段的含义如果自己不写注释提醒大模型，它是不知道是什么含义的，<strong>如果想利用它节约时间，自己就得重新用注释写一遍产品文档，“还不如我自己写更快些。”</strong></p>\n  <p>“所以我觉得用AI有个原则，你要考虑一下这块的代码值不值得你亲自花时间去写，是不是用户访问较多、又经常出bug的地方。同时，你也不能指望它说的都是对的。”吴悠说。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_6deef7c7cc214c9fae817577fc988d21@000000_oswg68771oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>而除了节省时间，在吴悠看来，大模型对于搜索更重要的意义，在于它能够跟自己头脑风暴。</p>\n  <p>“认知上有一个东西叫你不知道自己不知道什么，但大模型可以告诉你，你不知道的东西是什么，还能推荐你去看一些资料。”吴悠告诉数智前线，比如他最近在学习一些数据概念时，就会去问大模型自己的理解是否正确，并让大模型提出进一步建议，自己可以去学习对应的哪些东西，而传统的搜索引擎很难做到这一点。</p>\n  <p>但与此同时，传统搜索引擎也有它的优势所在。“<strong>当我想看一些深入的文章，而不是一个简单的概述性的介绍时，我还是会自己手动去搜索。</strong>”吴悠说。</p>\n  <h2><strong>02</strong></h2>\n  <h2><strong>沐兰，日本某风投公司员工</strong></h2>\n  <h2><strong>有了ChatGPT，我还要搜索吗？</strong></h2>\n  <p>“我是ChatGPT最早的一批付费用户，但它对我来说，目前还是办公辅助、翻译等工具属性，大于搜索引擎的功能。”80后沐兰告诉数智前线，<strong>大模型目前还并不是自己想要获取信息时的最优先选择</strong>。</p>\n  <p>她在日本一家知名风投公司从事投资工作，日常需要搜集、分析、处理大量信息。这些工作原来主要通过谷歌、雅虎等渠道去完成，而现在，大约有不到20%的搜索量，正在转移到大模型。</p>\n  <p>“这20%，主要是一些特别精准的问题，我可能会去问ChatGPT。”沐兰举例称，比如微软成立于哪一年，又或是日本前五大运动品牌是哪些等，以前可能需要她去Google搜出一个链接，再跳转，现在直接找ChatGPT，一问一答即可得到答案，能够节约一定时间，而又大概率不会出错。</p>\n  <p>但对于更多要求时效性或者准确性的搜索需求，沐兰说，自己依然更习惯用雅虎和谷歌。“<strong>尤其是搜日本相关的特别local的内容，我一定是用雅虎，这一点ChatGPT很难取代。”</strong></p>\n  <p>比如，当她需要搜索日本近些年的旅游数据时，就一定会去用传统搜索引擎，找到对应的权威网站，而不是直接问大模型。“它给我的数字往往是非常笼统的，而且也没有出处，我就不知道该不该信。”沐兰告诉数智前线，相比之下，传统搜索引擎的天然优势是——我知道你的出处是哪里，我来决定你可信不可信。因此，在这种问题上，她宁愿花更多时间找到相应的数据后，再去喂给ChatGPT，让它帮忙整理。</p>\n  <p>又比如，在做投资工作时，她经常会碰到一种情况——当听到某个感兴趣公司的名字后，需要搜索了解，但同名的公司可能有很多个，这就需要通过谷歌或雅虎去提供大量链接，让她从中分辨哪一个是自己的目标公司。</p>\n  <p>“如果一个东西，我能够迅速提炼出关键词，或者需要更精准的数据，我就会去Google。但如果在我心里它是个开放性的问题，我就会用ChatGPT。”沐兰总结说。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_274cc3fb2855413ba8c28d6397028836@000000_oswg22868oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在她看来，<strong>大模型和传统搜索引擎的关系并不是二元对立的，而是大概率会共存。</strong>不同的工作属性、生活方式，不同的状态或心情，都可能决定用户可能在不同问题上使用不同的搜索方式。比如，自己从事IT工作的多位朋友就均表示，他们已经有接近一半的搜索，从传统搜索引擎切换到了大模型。</p>\n  <p>而在AI大模型之外，小红书、微信搜索等在过去一段时间其实也都一定程度上实现了对用户搜索习惯的转移。“比如我要搜索中文内容的旅游攻略时，就会使用小红书。”</p>\n  <h2><strong>03&nbsp;</strong></h2>\n  <h2><strong>孟飞，大模型应用落地企业员工</strong></h2>\n  <h2><strong>大模型，开始加速分流我的搜索需求</strong></h2>\n  <p>“AI确实有颠覆我日常搜索方式的趋势。”孟飞是国内一家从事大模型应用落地企业的员工，他告诉数智前线，在他的日常工作和生活中，已经有相当一部分搜索会很自然地用到大模型，而不再是去找搜索引擎。</p>\n  <p>事实上，早在去年三四月份，为了给公司出海业务做准备，孟飞就曾试图用ChatGPT做一些翻译和材料搜索的工作，但最后发现，时间上虽然比起百度、谷歌等节省不少，却也存在不少暗坑。“比如我们让它在中国的古籍里找一些具有优美含义的关键词出来，就有好多出处是瞎编的。”</p>\n  <p>不过，今年以来，随着模型逐渐成熟，各家大模型的搜索精准性都有进一步提高，AI搜索的效果更加优化，<strong>孟飞的搜索需求和搜索习惯，也在加速从传统搜索引擎，分流到大模型产品。</strong>最近，他还找到公司内部的工程团队，希望能给自己所在的市场部，建设一个知识助手。</p>\n  <p>“比如kimi，我现在可以直接限定它帮我找出，什么时间段哪个领域发生的大事件都有哪些，它会把新闻标题、链接，还有summary（摘要），都给我列出来，这样很快就出来结果了，省得我一个一个去搜、去点，这个我觉得还是蛮好用的。”孟飞说。</p>\n  <p>但在“涉及到工作中容易出事故”的更加严肃的搜索任务上，孟飞表示，依然会优先使用搜索引擎，而非大模型。“比如写客户案例时要搜索客户简介、过往荣誉，还是会去百度等搜官网查看，因为模型并不能让我100%放心。”</p>\n  <p>相比之下，日常生活中的搜索需求是更宽容的场景。孟飞告诉数智前线，AI搜索目前已经进入自己生活的方方面面，“比如我平时没事会看一些历史类的小说，里面提到某个朝代的某个地名，我不知道，就会随手用文心一言查一查。”&nbsp;</p>\n  <p><strong>但用得最好、最频繁的，还是辅导孩子学习上。</strong>“这让我节省了很多时间。”孟飞说，原来他每天教孩子学英语，都需要将生词一个一个贴进百度搜索框，再一个一个粘贴进教案，耗时又费力，但现在，只需将每天需要学习的教材内容，拍图上传到kimi，让kimi帮忙把每个生词的意思、用法、例句都梳理出来，很快就能完成备课。</p>\n  <p>而在使用多次后，这套流程也逐渐沉淀成一个模板，“现在我只要把图发给它，说‘请备课’，它就能咔咔开始输出，每次规定它备课需要配备的50套配套练习题，现在也不再会出现过多超纲的题。”</p>\n  <p>目前，在一些编程、作文、数学等方面的辅导任务上，孟飞告诉数智前线，自己也会用大模型去提供一个符合三年级水准的解法，再一步步引导孩子解题。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241107/v2_f9d214bcecfd424daf68a566a3d68700@000000_oswg82210oswg1024oswg789_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2><strong>04‍‍</strong></h2>\n  <h2><strong>结语</strong></h2>\n  <p>毋庸置疑，大模型的到来，正在改变一部分人的搜索习惯。它在一定程度上取代了原来的搜索引擎的部分功能，但目前仍然还有许多无法替代的部分：比如，对于一些时效性要求很高的需求，如今天发生的事情，AI搜索现在还无法那么快满足；又比如，一些更强调准确性的需求，大模型仍然存在幻觉问题……</p>\n  <p>“搜索的需求未来可能会越来越细分。比如工作场景下的搜索，也许就是岗位助手了。<strong>AI搜索有可能就成为全新的搜索工具，传统的搜索彻底退出历史舞台，但这需要时间，可能不是1-2年内能完成的。</strong>“卢言霞告诉数智前线。而目前，由于大模型的使用还有一定门槛，AI搜索的使用群体还比较受限。现在各家也都还在前期投入中，还没有形成明确清晰的商业模式。</p>\n  <p>AI与搜索还有很长的故事要讲。</p>\n  <p>（应采访对象要求，上述三位采访对象均为化名）</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MzkwNDMyOTA1NA==&amp;mid=2247491058&amp;idx=1&amp;sn=2715ca629a44d9dfce6bc40c4bc3df2c&amp;chksm=c1414813d0e34f3be33a2b819ae5487776178c3d45f0cd239c97762e866c057748f2f021841e&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“数智前线”（ID：szqx1991）</a>，作者：周享玥，编辑：赵艳秋‍，‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍36氪经授权发布。</p>", "published": "2024-11-07 10:14:41", "id": "a9327571-159e-4ec2-be54-e805a59a36bf", "source": "36氪", "section": "文章资讯"}, {"title": "中芯国际：第三季度净利润10.6亿元，同比增长56.4%", "link": "https://36kr.com/newsflashes/3026215207003654?f=rss", "description": "36氪获悉，中芯国际发布三季报，第三季度营收156.09亿元，同比增长32.5%；归属于上市公司股东净利润10.6亿元，同比增长56.4%。", "published": "2024-11-07 11:05:18", "id": "255f8578-3634-48df-b1e2-f7409efb7d50", "source": "36氪", "section": "最新快讯"}, {"title": "国科恒泰：股东拟减持股份比例合计不超7.01%", "link": "https://36kr.com/newsflashes/3026202142139906?f=rss", "description": "36氪获悉，国科恒泰公告，股东国丰鼎嘉、西藏国科鼎奕、国科嘉和金源计划在公告披露15个交易日后的3个月内，共减持公司股份不超过3274万股，合计减持比例不超过公司总股本的7.01%。其中，国丰鼎嘉计划减持不超过1017.21万股，占总股本的2.18%；国科鼎奕计划减持不超过383.68万股，占总股本的0.8216%；国科嘉和金源计划减持不超过1873.11万股，占总股本的4.01%。此次减持系股东正常资金需求，不会对公司治理结构及持续经营产生重大影响。", "published": "2024-11-07 11:17:50", "id": "9dc1c9e6-e863-4951-b254-0911cc627aad", "source": "36氪", "section": "最新快讯"}, {"title": "证监会10月期货公司名录新增摩根士丹利期货（中国）有限公司", "link": "https://36kr.com/newsflashes/3026174600422920?f=rss", "description": "36氪获悉，中国证监会公布“期货公司名录（2024年10月）”，期货公司数量由此前的150家变更为151家，新增机构为“摩根士丹利期货（中国）有限公司”。", "published": "2024-11-07 10:33:58", "id": "fafcfdb3-7653-4992-872e-784b2639ab74", "source": "36氪", "section": "最新快讯"}, {"title": "皖通高速：发行不超50亿元公司债券获得注册批复", "link": "https://36kr.com/newsflashes/3026199504561672?f=rss", "description": "36氪获悉，皖通高速公告，公司近日收到中国证监会出具的批复，同意公司向专业投资者公开发行面值总额不超过50亿元公司债券的注册申请。该批复24个月内有效，公司在注册有效期内可以分期发行。", "published": "2024-11-07 11:00:14", "id": "5575cfed-de53-431d-b614-611d4f7aa7b9", "source": "36氪", "section": "最新快讯"}, {"title": "欧元区9月零售销售环比增长0.5%", "link": "https://36kr.com/newsflashes/3026172655232265?f=rss", "description": "欧元区9月零售销售环比增长0.5%，同比增长2.9%。（界面）", "published": "2024-11-07 10:29:52", "id": "1589fa38-7220-4f33-bcaf-0064b18c47e4", "source": "36氪", "section": "最新快讯"}, {"title": "“战略性放手”外卖？抖音攻向即时零售", "link": "https://36kr.com/newsflashes/3026184167105792?f=rss", "description": "近日，抖音外卖业务再经调整。抖音生活服务学习中心发布公告称，原“团购配送”业务将于11月1日起逐步向“随心团”业务迁移，即同一件团购商品既支持用户到店核销，也支持配送到家。对此��接近抖音外卖业务的人士乔木（化名）表示，这次调整可以被视为抖音对外卖业务的“战略性放手”。“（外卖业绩）一直没有增长，始终没法进行履约。”对于此次调整的原因，截至发稿，抖音方面暂未回应。（每经）", "published": "2024-11-07 10:33:43", "id": "454d6e9a-4671-4cb5-9c2b-cedde50f43d1", "source": "36氪", "section": "最新快讯"}, {"title": "传网易游戏多名高管陷贪腐风波被带走调查，官方暂无回应", "link": "https://36kr.com/newsflashes/3026207977416201?f=rss", "description": "据媒体报道，近日网易游戏内部严查贪腐，涉及营销线多名高管，网易游戏市场部总经理向某等人已被带走调查。报道称，此次被带走高管多数出自市场部。在内部行业交流群里，有消息称，此次调查事件涉及金额上亿。就此向网易游戏求证，截至发稿官方暂未回应。（新浪科技）", "published": "2024-11-07 10:57:56", "id": "9a63c46e-9c5b-4775-8835-226be111f1ea", "source": "36氪", "section": "最新快讯"}, {"title": "三花智控：终止境外发行全球存托凭证并在瑞士证券交易所挂牌上市的计划", "link": "https://36kr.com/newsflashes/3026201390212610?f=rss", "description": "36氪获悉，三花智控公告，拟终止境外发行全球存托凭证（GDR）并在瑞士证券交易所（SIX Swiss Exchange）挂牌上市的计划。2024年11月4日，公司与保荐人中信证券向深交所提交了撤回申请文件。近日，公司收到深交所出具的决定，深交所决定终止对公司申请发行GDR境内新增基础股票的审核。", "published": "2024-11-07 11:11:08", "id": "b0c03657-601a-4178-a8f6-d4fd03346250", "source": "36氪", "section": "最新快讯"}, {"title": "中国软件：除2024年度向特定对象发行A股股票外，未筹划重大事项", "link": "https://36kr.com/newsflashes/3026181680735488?f=rss", "description": "36氪获悉，中国软件公告，公司股票交易连续3个交易日内日收盘价格涨幅偏离值累计达25.32%，已构成股票交易异常波动。公司日常经营情况及外部环境未发生重大变化，不存在应披露而未披露的重大事项。截至2024年11月7日，公司股票静态市盈率为-218.18倍、市净率23.38倍。截至2024年11月7日，除公司2024年度向特定对象中国电子、中电金投发行A股股票，募集资金用于子公司麒麟软件有限公司实施研发项目事项外，公司、控股股东及实际控制人未筹划涉及上市公司的重大资产重组、股份发行、重大交易类事项、业务重组、股份回购、股权激励、破产重整、重大业务合作、引进战略投资者等重大事项。", "published": "2024-11-07 10:43:09", "id": "b246028a-ab7c-4cec-9ef6-9c963a797ffa", "source": "36氪", "section": "最新快讯"}, {"title": "中国债券纳入彭博指数四周年，权重升至9.7%成第三大计价货币债券", "link": "https://36kr.com/newsflashes/3026190065821185?f=rss", "description": "彭博公布的最新数据显示，截至2024年11月初，彭博全球综合指数中包含325只中国债券，在该指数68万亿美元的市值中的权重达到9.7%，较四年前增长3.7个百分点。同时，人民币计价的中国债券成为全球综合指数中的第三大计价货币债券，仅次于美元（45.4%）和欧元（22.3%），略领先于日元（9.6%）。 （证券时报）", "published": "2024-11-07 10:39:43", "id": "dbc97e4c-0a86-492c-9f08-d2ee8d897c30", "source": "36氪", "section": "最新快讯"}, {"title": "祥明智能：股东拟合计减持不超7.7%的公司股份", "link": "https://36kr.com/newsflashes/3026177992959240?f=rss", "description": "36氪获悉，祥明智能公告称，股东杨剑芬、祥光投资、昆山超辉拟合计减持不超7.7%的公司股份。", "published": "2024-11-07 10:38:25", "id": "1a5df48e-15c1-4c2d-b78c-96ac9d262465", "source": "36氪", "section": "最新快讯"}, {"title": "圣农发展：10月销售收入15.83亿元 同比增长7.51%", "link": "https://36kr.com/newsflashes/3026198857721344?f=rss", "description": "36氪获悉，圣农发展公告，10月实现销售收入15.83亿元，较去年同期增长7.51%，较上月环比下降2.3%。销量方面，10月份家禽饲养加工板块鸡肉销量为12.62万吨，同比增长5.4%，环比增长0.35%；深加工肉制品板块产品销量为3.08万吨，同比增长17.05%，环比下降8.62%。10月，公司创下过去10个月的单月最佳盈利水平，同时较去年10月增长超400%，1—10月累计盈利同比降幅收窄。在降本增效的积极推动下，公司综合造肉成本稳步下降，产量和销量稳步增长。", "published": "2024-11-07 10:54:37", "id": "0a5a296a-5764-4fa1-9f8e-539685c747c4", "source": "36氪", "section": "最新快讯"}, {"title": "机构今日抛售同花顺等20股，买入中国软件8.34亿元", "link": "https://36kr.com/newsflashes/3026159814321668?f=rss", "description": "盘后数据显示，11月7日龙虎榜中，共44只个股出现了机构的身影，24只股票呈现机构净买入，20只股票呈现机构净卖出。当天机构净买入前三的股票分别是中国软件、金杯汽车、厦钨新能，净买入金额分别是8.34亿元、4.48亿元、1.81亿元。当天机构净卖出前三的股票分别是同花顺、中国长城、泸州老窖，净流出金额分别是6.41亿元、1.47亿元、1.15亿元。（第一财经）", "published": "2024-11-07 10:25:54", "id": "69dea280-b03a-4bda-a177-4f39de8fc64d", "source": "36氪", "section": "最新快讯"}, {"title": "6连板浩欧博：市盈率显著高于行业市盈率水平", "link": "https://36kr.com/newsflashes/3026200836842753?f=rss", "description": "36氪获悉，浩欧博发布股票交易异常波动暨严重异常波动公告，根据中证指数有限公司发布的公司最新市盈率为127.50倍，最新滚动市盈率为171.15倍，公司所处的医药制造业最近一个月平均滚动市盈率为27.03倍。公司市盈率显著高于行业市盈率水平。", "published": "2024-11-07 11:05:36", "id": "7bb44d83-29be-4091-ba33-0b2b29b450c8", "source": "36氪", "section": "最新快讯"}, {"title": "李迅雷：非常期待接下来的财政政策，中央财政仍有很大的加杠杆空间", "link": "https://36kr.com/newsflashes/3026175623521801?f=rss", "description": "在天弘基金20周年策略会上，中国首席经济学家论坛理事长李迅雷表示，非常期待接下来的财政政策。“方方面面的政策力度还会进一步加大，尤其是在昨天美国大选结果出来之后。”他认为，中国后续会进一步扩大内需、扩大消费，这是一个新的变量。（澎湃）", "published": "2024-11-07 10:25:02", "id": "5cb96211-05ae-4411-a4bc-ae5717f67b80", "source": "36氪", "section": "最新快讯"}, {"title": "挪威央行按兵不动，挪威克朗兑欧元升至10日高点", "link": "https://36kr.com/newsflashes/3026159695914499?f=rss", "description": "挪威央行如经济学家预期那样按兵不动后，挪威克朗兑欧元维持在10月28日以来的高点附近。欧元/挪威克朗跌0.5%至11.8198。挪威央行表示，经济前景没有发生重大变化。挪威克朗/瑞典克朗涨0.4%至0.9831；稍早一度升至0.9842，为8月16日以来最高水平。（新浪财经）", "published": "2024-11-07 10:19:47", "id": "0abfe367-d498-4b2b-95c6-066eedf6b47d", "source": "36氪", "section": "最新快讯"}, {"title": "9连板华夏幸福：鉴于公司股票价格短期涨幅较大，敬请注意二级市场交易风险", "link": "https://36kr.com/newsflashes/3026145309877512?f=rss", "description": "36氪获悉，华夏幸福发布股票交易异常波动暨严重异常波动公告，公司股票自2024年10月28日至11月7日，已连续九个交易日涨停，鉴于公司股票价格短期涨幅较大，公司敬请广大投资者注意二级市场交易风险，理性决策，审慎投资。", "published": "2024-11-07 10:14:29", "id": "bd36886d-f921-4676-af78-ea51f78241e6", "source": "36氪", "section": "最新快讯"}, {"title": "10连板华映科技：控股股东卖出0.61%公司股份", "link": "https://36kr.com/newsflashes/3026150030878213?f=rss", "description": "36氪获悉，华映科技发布股票交易异常波动公告，公司控股股东福建省电子信息集团于2024年11月6日-11月7日期间，通过集中竞价卖出16,750,000股华映科技股票，占华映科技总股本约0.61%。", "published": "2024-11-07 10:10:57", "id": "2ad2fda8-1179-4a31-ad4a-480761fde39e", "source": "36氪", "section": "最新快讯"}, {"title": "动力源：被美国财政部OFAC列入SDN清单", "link": "https://36kr.com/newsflashes/3026158216291848?f=rss", "description": "36氪获悉，动力源公告，公司于近日获悉，美国财政部OFAC将公司列入SDN清单。被列入清单的实体在与美国实体之间的交易、海外资产转移、外汇结算等方面将面临限制。公司自成立起便秉承自主研发的技术路线，致力于电力电子技术在数据通信、绿色出行和氢能源等领域电能转换与能源利用的研发和应用。公司与海外客户之间的贸易属于正常的业务往来，并严格遵守生产经营等活动涉及的相关法律法规及国际商业惯例。公司此次被列入“SDN清单”将可能对公司国际业务及部分商业银行合作等方面产生较大影响。", "published": "2024-11-07 10:07:19", "id": "f3413b8f-c7f8-462f-b617-4e8406970317", "source": "36氪", "section": "最新快讯"}, {"title": "巴西亚马孙地区毁林面积创9年来新低", "link": "https://36kr.com/newsflashes/3026147351078405?f=rss", "description": "巴西政府官员6日说，巴西境内亚马孙雨林区最近一个统计年度的森林砍伐面积同比下降30.6%，毁林规模为9年来最低纪录。巴西国家太空研究院的数据显示，2023年8月1日至2024年7月30日，巴西亚马孙地区森林砍伐面积为6288平方公里，比去年同期下降30.6%。研究院主管吉尔万·奥利韦拉说，这一森林损失量为“过去9年来最低”水平。（新华社）", "published": "2024-11-07 10:04:12", "id": "1cb2e8c0-e4de-4ec3-8247-6c508a0c8077", "source": "36氪", "section": "最新快讯"}, {"title": "Learning Force Distribution Estimation for the GelSight Mini Optical Tactile Sensor Based on Finite Element Analysis", "link": "https://arxiv.org/abs/2411.03315", "description": "arXiv:2411.03315v1 Announce Type: new \nAbstract: Contact-rich manipulation remains a major challenge in robotics. Optical tactile sensors like GelSight Mini offer a low-cost solution for contact sensing by capturing soft-body deformations of the silicone gel. However, accurately inferring shear and normal force distributions from these gel deformations has yet to be fully addressed. In this work, we propose a machine learning approach using a U-net architecture to predict force distributions directly from the sensor's raw images. Our model, trained on force distributions inferred from Finite Element Analysis (FEA), demonstrates promising accuracy in predicting normal and shear force distributions. It also shows potential for generalization across sensors of the same type and for enabling real-time application. The codebase, dataset and models are open-sourced and available at https://feats-ai.github.io .", "published": "2024-11-07 05:00:00", "id": "b41f3e80-fbac-4cac-add3-8d439e17c45d", "source": "arxiv", "section": "computerScience"}, {"title": "Will Trump Win in 2024? Predicting the US Presidential Election via Multi-step Reasoning with Large Language Models", "link": "https://arxiv.org/abs/2411.03321", "description": "arXiv:2411.03321v1 Announce Type: new \nAbstract: Can Large Language Models (LLMs) accurately predict election outcomes? While LLMs have demonstrated impressive performance in various domains, including healthcare, legal analysis, and creative tasks, their ability to forecast elections remains unknown. Election prediction poses unique challenges, such as limited voter-level data, rapidly changing political landscapes, and the need to model complex human behavior. To address these challenges, we introduce a multi-step reasoning framework designed for political analysis. Our approach is validated on real-world data from the American National Election Studies (ANES) 2016 and 2020, as well as synthetic personas generated by the leading machine learning framework, offering scalable datasets for voter behavior modeling. To capture temporal dynamics, we incorporate candidates' policy positions and biographical details, ensuring that the model adapts to evolving political contexts. Drawing on Chain of Thought prompting, our multi-step reasoning pipeline systematically integrates demographic, ideological, and time-dependent factors, enhancing the model's predictive power. Additionally, we apply our framework to predict the outcome of the 2024 U.S. presidential election in advance, demonstrating the adaptability of LLMs to unseen political data.", "published": "2024-11-07 05:00:00", "id": "2703842d-624d-4f7d-88c4-741d0bf87b53", "source": "arxiv", "section": "computerScience"}, {"title": "Fixing Security Vulnerabilities with AI in OSS-Fuzz", "link": "https://arxiv.org/abs/2411.03346", "description": "arXiv:2411.03346v1 Announce Type: new \nAbstract: Critical open source software systems undergo significant validation in the form of lengthy fuzz campaigns. The fuzz campaigns typically conduct a biased random search over the domain of program inputs, to find inputs which crash the software system. Such fuzzing is useful to enhance the security of software systems in general since even closed source software may use open source components. Hence testing open source software is of paramount importance. Currently OSS-Fuzz is the most significant and widely used infrastructure for continuous validation of open source systems. Unfortunately even though OSS-Fuzz has identified more than 10,000 vulnerabilities across 1000 or more software projects, the detected vulnerabilities may remain unpatched, as vulnerability fixing is often manual in practice. In this work, we rely on the recent progress in Large Language Model (LLM) agents for autonomous program improvement including bug fixing. We customise the well-known AutoCodeRover agent for fixing security vulnerabilities. This is because LLM agents like AutoCodeRover fix bugs from issue descriptions via code search. Instead for security patching, we rely on the test execution of the exploit input to extract code elements relevant to the fix. Our experience with OSS-Fuzz vulnerability data shows that LLM agent autonomy is useful for successful security patching, as opposed to approaches like Agentless where the control flow is fixed. More importantly our findings show that we cannot measure quality of patches by code similarity of the patch with reference codes (as in CodeBLEU scores used in VulMaster), since patches with high CodeBLEU scores still fail to pass given the given exploit input. Our findings indicate that security patch correctness needs to consider dynamic attributes like test executions as opposed to relying of standard text/code similarity metrics.", "published": "2024-11-07 05:00:00", "id": "423efbbf-c726-4567-9d7c-a858693341b6", "source": "arxiv", "section": "computerScience"}, {"title": "Satellite monitoring uncovers progress but large disparities in doubling crop yields", "link": "https://arxiv.org/abs/2411.03322", "description": "arXiv:2411.03322v1 Announce Type: new \nAbstract: High-resolution satellite-based crop yield mapping offers enormous promise for monitoring progress towards the SDGs. Across 15,000 villages in Rwanda we uncover areas that are on and off track to double productivity by 2030. This machine learning enabled analysis is used to design spatially explicit productivity targets that, if met, would simultaneously ensure national goals without leaving anyone behind.", "published": "2024-11-07 05:00:00", "id": "8ee7a4a1-66c1-4828-845f-81688915b0ee", "source": "arxiv", "section": "computerScience"}, {"title": "PipeLLM: Fast and Confidential Large Language Model Services with Speculative Pipelined Encryption", "link": "https://arxiv.org/abs/2411.03357", "description": "arXiv:2411.03357v1 Announce Type: new \nAbstract: Confidential computing on GPUs, like NVIDIA H100, mitigates the security risks of outsourced Large Language Models (LLMs) by implementing strong isolation and data encryption. Nonetheless, this encryption incurs a significant performance overhead, reaching up to 52.8 percent and 88.2 percent throughput drop when serving OPT-30B and OPT-66B, respectively. To address this challenge, we introduce PipeLLM, a user-transparent runtime system. PipeLLM removes the overhead by overlapping the encryption and GPU computation through pipelining - an idea inspired by the CPU instruction pipelining - thereby effectively concealing the latency increase caused by encryption. The primary technical challenge is that, unlike CPUs, the encryption module lacks prior knowledge of the specific data needing encryption until it is requested by the GPUs. To this end, we propose speculative pipelined encryption to predict the data requiring encryption by analyzing the serving patterns of LLMs. Further, we have developed an efficient, low-cost pipeline relinquishing approach for instances of incorrect predictions. Our experiments on NVIDIA H100 GPU show that compared with vanilla systems without confidential computing (e.g., vLLM, PEFT, and FlexGen), PipeLLM incurs modest overhead (less than 19.6 percent in throughput) across various LLM sizes, from 13B to 175B.", "published": "2024-11-07 05:00:00", "id": "487f4f4a-e420-4415-8cd7-3c89fcae2d10", "source": "arxiv", "section": "computerScience"}, {"title": "Kernel Approximation using Analog In-Memory Computing", "link": "https://arxiv.org/abs/2411.03375", "description": "arXiv:2411.03375v1 Announce Type: new \nAbstract: Kernel functions are vital ingredients of several machine learning algorithms, but often incur significant memory and computational costs. We introduce an approach to kernel approximation in machine learning algorithms suitable for mixed-signal Analog In-Memory Computing (AIMC) architectures. Analog In-Memory Kernel Approximation addresses the performance bottlenecks of conventional kernel-based methods by executing most operations in approximate kernel methods directly in memory. The IBM HERMES Project Chip, a state-of-the-art phase-change memory based AIMC chip, is utilized for the hardware demonstration of kernel approximation. Experimental results show that our method maintains high accuracy, with less than a 1% drop in kernel-based ridge classification benchmarks and within 1% accuracy on the Long Range Arena benchmark for kernelized attention in Transformer neural networks. Compared to traditional digital accelerators, our approach is estimated to deliver superior energy efficiency and lower power consumption. These findings highlight the potential of heterogeneous AIMC architectures to enhance the efficiency and scalability of machine learning applications.", "published": "2024-11-07 05:00:00", "id": "29419eb0-da95-40bd-b511-d30636ca64c7", "source": "arxiv", "section": "computerScience"}, {"title": "What Features in Prompts Jailbreak LLMs? Investigating the Mechanisms Behind Attacks", "link": "https://arxiv.org/abs/2411.03343", "description": "arXiv:2411.03343v1 Announce Type: new \nAbstract: While `jailbreaks' have been central to research on the safety and reliability of LLMs (large language models), the underlying mechanisms behind these attacks are not well understood. Some prior works have used linear methods to analyze jailbreak prompts or model refusal. Here, however, we compare linear and nonlinear methods to study the features in prompts that contribute to successful jailbreaks. We do this by probing for jailbreak success based only on the portions of the latent representations corresponding to prompt tokens. First, we introduce a dataset of 10,800 jailbreak attempts from 35 attack methods. We then show that different jailbreaking methods work via different nonlinear features in prompts. Specifically, we find that while probes can distinguish between successful and unsuccessful jailbreaking prompts with a high degree of accuracy, they often transfer poorly to held-out attack methods. We also show that nonlinear probes can be used to mechanistically jailbreak the LLM by guiding the design of adversarial latent perturbations. These mechanistic jailbreaks are able to jailbreak Gemma-7B-IT more reliably than 34 of the 35 techniques that it was trained on. Ultimately, our results suggest that jailbreaks cannot be thoroughly understood in terms of universal or linear prompt features alone.", "published": "2024-11-07 05:00:00", "id": "1df88c5f-1d45-4847-85f1-cd18710fd9b2", "source": "arxiv", "section": "computerScience"}, {"title": "Exploring Feature Importance and Explainability Towards Enhanced ML-Based DoS Detection in AI Systems", "link": "https://arxiv.org/abs/2411.03355", "description": "arXiv:2411.03355v1 Announce Type: new \nAbstract: Denial of Service (DoS) attacks pose a significant threat in the realm of AI systems security, causing substantial financial losses and downtime. However, AI systems' high computational demands, dynamic behavior, and data variability make monitoring and detecting DoS attacks challenging. Nowadays, statistical and machine learning (ML)-based DoS classification and detection approaches utilize a broad range of feature selection mechanisms to select a feature subset from networking traffic datasets. Feature selection is critical in enhancing the overall model performance and attack detection accuracy while reducing the training time. In this paper, we investigate the importance of feature selection in improving ML-based detection of DoS attacks. Specifically, we explore feature contribution to the overall components in DoS traffic datasets by utilizing statistical analysis and feature engineering approaches. Our experimental findings demonstrate the usefulness of the thorough statistical analysis of DoS traffic and feature engineering in understanding the behavior of the attack and identifying the best feature selection for ML-based DoS classification and detection.", "published": "2024-11-07 05:00:00", "id": "2e1799ec-3162-48ce-a4a9-06779368528a", "source": "arxiv", "section": "computerScience"}, {"title": "Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection", "link": "https://arxiv.org/abs/2411.03359", "description": "arXiv:2411.03359v1 Announce Type: new \nAbstract: Out-of-distribution (OOD) detection is crucial for deploying reliable machine learning models in open-world applications. Recent advances in CLIP-based OOD detection have shown promising results via regularizing prompt tuning with OOD features extracted from ID data. However, the irrelevant context mined from ID data can be spurious due to the inaccurate foreground-background decomposition, thus limiting the OOD detection performance. In this work, we propose a novel framework, namely, Self-Calibrated Tuning (SCT), to mitigate this problem for effective OOD detection with only the given few-shot ID data. Specifically, SCT introduces modulating factors respectively on the two components of the original learning objective. It adaptively directs the optimization process between the two tasks during training on data with different prediction uncertainty to calibrate the influence of OOD regularization, which is compatible with many prompt tuning based OOD detection methods. Extensive experiments and analyses have been conducted to characterize and demonstrate the effectiveness of the proposed SCT. The code is publicly available.", "published": "2024-11-07 05:00:00", "id": "295cd8c3-8d77-4b8c-a5d1-d56232e71910", "source": "arxiv", "section": "computerScience"}, {"title": "Analysis of Bipartite Networks in Anime Series: Textual Analysis, Topic Clustering, and Modeling", "link": "https://arxiv.org/abs/2411.03333", "description": "arXiv:2411.03333v1 Announce Type: new \nAbstract: This article analyzes a specific bipartite network that shows the relationships between users and anime, examining how the descriptions of anime influence the formation of user communities. In particular, we introduce a new variable that quantifies the frequency with which words from a description appear in specific word clusters. These clusters are generated from a bigram analysis derived from all descriptions in the database. This approach fully characterizes the dynamics of these communities and shows how textual content affect the cohesion and structure of the social network among anime enthusiasts. Our findings suggest that there may be significant implications for the design of recommendation systems and the enhancement of user experience on anime platforms.", "published": "2024-11-07 05:00:00", "id": "b61ef291-6dd7-46ec-ae85-18f7813d2b39", "source": "arxiv", "section": "computerScience"}, {"title": "Undermining Image and Text Classification Algorithms Using Adversarial Attacks", "link": "https://arxiv.org/abs/2411.03348", "description": "arXiv:2411.03348v1 Announce Type: new \nAbstract: Machine learning models are prone to adversarial attacks, where inputs can be manipulated in order to cause misclassifications. While previous research has focused on techniques like Generative Adversarial Networks (GANs), there's limited exploration of GANs and Synthetic Minority Oversampling Technique (SMOTE) in text and image classification models to perform adversarial attacks. Our study addresses this gap by training various machine learning models and using GANs and SMOTE to generate additional data points aimed at attacking text classification models. Furthermore, we extend our investigation to face recognition models, training a Convolutional Neural Network(CNN) and subjecting it to adversarial attacks with fast gradient sign perturbations on key features identified by GradCAM, a technique used to highlight key image characteristics CNNs use in classification. Our experiments reveal a significant vulnerability in classification models. Specifically, we observe a 20 % decrease in accuracy for the top-performing text classification models post-attack, along with a 30 % decrease in facial recognition accuracy. This highlights the susceptibility of these models to manipulation of input data. Adversarial attacks not only compromise the security but also undermine the reliability of machine learning systems. By showcasing the impact of adversarial attacks on both text classification and face recognition models, our study underscores the urgent need for develop robust defenses against such vulnerabilities.", "published": "2024-11-07 05:00:00", "id": "59b09f46-c310-4ff1-af6b-4e4f80badd94", "source": "arxiv", "section": "computerScience"}, {"title": "Maximal Extractable Value in Decentralized Finance: Taxonomy, Detection, and Mitigation", "link": "https://arxiv.org/abs/2411.03327", "description": "arXiv:2411.03327v1 Announce Type: new \nAbstract: Decentralized Finance (DeFi) leverages blockchain-enabled smart contracts to deliver automated and trustless financial services without the need for intermediaries. However, the public visibility of financial transactions on the blockchain can be exploited, as participants can reorder, insert, or remove transactions to extract value, often at the expense of others. This extracted value is known as the Maximal Extractable Value (MEV). MEV causes financial losses and consensus instability, disrupting the security, efficiency, and decentralization goals of the DeFi ecosystem. Therefore, it is crucial to analyze, detect, and mitigate MEV to safeguard DeFi. Our comprehensive survey offers a holistic view of the MEV landscape in the DeFi ecosystem. We present an in-depth understanding of MEV through a novel taxonomy of MEV transactions supported by real transaction examples. We perform a critical comparative analysis of various MEV detection approaches, evaluating their effectiveness in identifying different transaction types. Furthermore, we assess different categories of MEV mitigation strategies and discuss their limitations. We identify the challenges of current mitigation and detection approaches and discuss potential solutions. This survey provides valuable insights for researchers, developers, stakeholders, and policymakers, helping to curb and democratize MEV for a more secure and efficient DeFi ecosystem.", "published": "2024-11-07 05:00:00", "id": "0cd9b6b5-681d-492a-9773-3ce6b6c82603", "source": "arxiv", "section": "computerScience"}, {"title": "Algebraic metacomplexity and representation theory", "link": "https://arxiv.org/abs/2411.03444", "description": "arXiv:2411.03444v1 Announce Type: new \nAbstract: We prove that in the algebraic metacomplexity framework, the decomposition of metapolynomials into their isotypic components can be implemented efficiently, namely with only a quasipolynomial blowup in the circuit size. This means that many existing algebraic complexity lower bound proofs can be efficiently converted into isotypic lower bound proofs via highest weight metapolynomials, a notion studied in geometric complexity theory. In the context of algebraic natural proofs, our result means that without loss of generality algebraic natural proofs can be assumed to be isotypic. Our proof is built on the Poincar\\'e--Birkhoff--Witt theorem for Lie algebras and on Gelfand--Tsetlin theory, for which we give the necessary comprehensive background.", "published": "2024-11-07 05:00:00", "id": "214f7727-98c8-475c-bb12-e44e702bf4a1", "source": "arxiv", "section": "computerScience"}, {"title": "A Surrogate Model for Quay Crane Scheduling Problem", "link": "https://arxiv.org/abs/2411.03324", "description": "arXiv:2411.03324v1 Announce Type: new \nAbstract: In ports, a variety of tasks are carried out, and scheduling these tasks is crucial due to its significant impact on productivity, making the generation of precise plans essential. This study proposes a method to solve the Quay Crane Scheduling Problem (QCSP), a representative task scheduling problem in ports known to be NP-Hard, more quickly and accurately. First, the study suggests a method to create more accurate work plans for Quay Cranes (QCs) by learning from actual port data to accurately predict the working speed of QCs. Next, a Surrogate Model is proposed by combining a Machine Learning (ML) model with a Genetic Algorithm (GA), which is widely used to solve complex optimization problems, enabling faster and more precise exploration of solutions. Unlike methods that use fixed-dimensional chromosome encoding, the proposed methodology can provide solutions for encodings of various dimensions. To validate the performance of the newly proposed methodology, comparative experiments were conducted, demonstrating faster search speeds and improved fitness scores. The method proposed in this study can be applied not only to QCSP but also to various NP-Hard problems, and it opens up possibilities for the further development of advanced search algorithms by combining heuristic algorithms with ML models.", "published": "2024-11-07 05:00:00", "id": "e57e30c1-8fe3-4a3f-ad8a-af025f5cd47d", "source": "arxiv", "section": "computerScience"}, {"title": "An Open API Architecture to Discover the Trustworthy Explanation of Cloud AI Services", "link": "https://arxiv.org/abs/2411.03376", "description": "arXiv:2411.03376v1 Announce Type: new \nAbstract: This article presents the design of an open-API-based explainable AI (XAI) service to provide feature contribution explanations for cloud AI services. Cloud AI services are widely used to develop domain-specific applications with precise learning metrics. However, the underlying cloud AI services remain opaque on how the model produces the prediction. We argue that XAI operations are accessible as open APIs to enable the consolidation of the XAI operations into the cloud AI services assessment. We propose a design using a microservice architecture that offers feature contribution explanations for cloud AI services without unfolding the network structure of the cloud models. We can also utilize this architecture to evaluate the model performance and XAI consistency metrics showing cloud AI services trustworthiness. We collect provenance data from operational pipelines to enable reproducibility within the XAI service. Furthermore, we present the discovery scenarios for the experimental tests regarding model performance and XAI consistency metrics for the leading cloud vision AI services. The results confirm that the architecture, based on open APIs, is cloud-agnostic. Additionally, data augmentations result in measurable improvements in XAI consistency metrics for cloud AI services.", "published": "2024-11-07 05:00:00", "id": "e34f4a27-be83-46b3-970c-804755fb533e", "source": "arxiv", "section": "computerScience"}, {"title": "Pedestrian Volume Prediction Using a Diffusion Convolutional Gated Recurrent Unit Model", "link": "https://arxiv.org/abs/2411.03360", "description": "arXiv:2411.03360v1 Announce Type: new \nAbstract: Effective models for analysing and predicting pedestrian flow are important to ensure the safety of both pedestrians and other road users. These tools also play a key role in optimising infrastructure design and geometry and supporting the economic utility of interconnected communities. The implementation of city-wide automatic pedestrian counting systems provides researchers with invaluable data, enabling the development and training of deep learning applications that offer better insights into traffic and crowd flows. Benefiting from real-world data provided by the City of Melbourne pedestrian counting system, this study presents a pedestrian flow prediction model, as an extension of Diffusion Convolutional Grated Recurrent Unit (DCGRU) with dynamic time warping, named DCGRU-DTW. This model captures the spatial dependencies of pedestrian flow through the diffusion process and the temporal dependency captured by Gated Recurrent Unit (GRU). Through extensive numerical experiments, we demonstrate that the proposed model outperforms the classic vector autoregressive model and the original DCGRU across multiple model accuracy metrics.", "published": "2024-11-07 05:00:00", "id": "2440e394-9712-4322-8c17-f9fd14b72b86", "source": "arxiv", "section": "computerScience"}, {"title": "SPINEX_ Symbolic Regression: Similarity-based Symbolic Regression with Explainable Neighbors Exploration", "link": "https://arxiv.org/abs/2411.03358", "description": "arXiv:2411.03358v1 Announce Type: new \nAbstract: This article introduces a new symbolic regression algorithm based on the SPINEX (Similarity-based Predictions with Explainable Neighbors Exploration) family. This new algorithm (SPINEX_SymbolicRegression) adopts a similarity-based approach to identifying high-merit expressions that satisfy accuracy- and structural similarity metrics. We conducted extensive benchmarking tests comparing SPINEX_SymbolicRegression to over 180 mathematical benchmarking functions from international problem sets that span randomly generated expressions and those based on real physical phenomena. Then, we evaluated the performance of the proposed algorithm in terms of accuracy, expression similarity in terms of presence operators and variables (as compared to the actual expressions), population size, and number of generations at convergence. The results indicate that SPINEX_SymbolicRegression consistently performs well and can, in some instances, outperform leading algorithms. In addition, the algorithm's explainability capabilities are highlighted through in-depth experiments.", "published": "2024-11-07 05:00:00", "id": "9afd6d1a-e771-43db-8333-878ff369d767", "source": "arxiv", "section": "computerScience"}, {"title": "LLM-based Continuous Intrusion Detection Framework for Next-Gen Networks", "link": "https://arxiv.org/abs/2411.03354", "description": "arXiv:2411.03354v1 Announce Type: new \nAbstract: In this paper, we present an adaptive framework designed for the continuous detection, identification and classification of emerging attacks in network traffic. The framework employs a transformer encoder architecture, which captures hidden patterns in a bidirectional manner to differentiate between malicious and legitimate traffic. Initially, the framework focuses on the accurate detection of malicious activities, achieving a perfect recall of 100\\% in distinguishing between attack and benign traffic. Subsequently, the system incrementally identifies unknown attack types by leveraging a Gaussian Mixture Model (GMM) to cluster features derived from high-dimensional BERT embeddings. This approach allows the framework to dynamically adjust its identification capabilities as new attack clusters are discovered, maintaining high detection accuracy. Even after integrating additional unknown attack clusters, the framework continues to perform at a high level, achieving 95.6\\% in both classification accuracy and recall.The results demonstrate the effectiveness of the proposed framework in adapting to evolving threats while maintaining high accuracy in both detection and identification tasks. Our ultimate goal is to develop a scalable, real-time intrusion detection system that can continuously evolve with the ever-changing network threat landscape.", "published": "2024-11-07 05:00:00", "id": "15bebe85-abd5-4d3f-9177-578a0e034628", "source": "arxiv", "section": "computerScience"}, {"title": "STEER: Flexible Robotic Manipulation via Dense Language Grounding", "link": "https://arxiv.org/abs/2411.03409", "description": "arXiv:2411.03409v1 Announce Type: new \nAbstract: The complexity of the real world demands robotic systems that can intelligently adapt to unseen situations. We present STEER, a robot learning framework that bridges high-level, commonsense reasoning with precise, flexible low-level control. Our approach translates complex situational awareness into actionable low-level behavior through training language-grounded policies with dense annotation. By structuring policy training around fundamental, modular manipulation skills expressed in natural language, STEER exposes an expressive interface for humans or Vision-Language Models (VLMs) to intelligently orchestrate the robot's behavior by reasoning about the task and context. Our experiments demonstrate the skills learned via STEER can be combined to synthesize novel behaviors to adapt to new situations or perform completely new tasks without additional data collection or training.", "published": "2024-11-07 05:00:00", "id": "6530f547-b419-4889-9b6d-d1432d07fcd8", "source": "arxiv", "section": "computerScience"}, {"title": "RuAG: Learned-rule-augmented Generation for Large Language Models", "link": "https://arxiv.org/abs/2411.03349", "description": "arXiv:2411.03349v1 Announce Type: new \nAbstract: In-context learning (ICL) and Retrieval-Augmented Generation (RAG) have gained attention for their ability to enhance LLMs' reasoning by incorporating external knowledge but suffer from limited contextual window size, leading to insufficient information injection. To this end, we propose a novel framework, RuAG, to automatically distill large volumes of offline data into interpretable first-order logic rules, which are injected into LLMs to boost their reasoning capabilities. Our method begins by formulating the search process relying on LLMs' commonsense, where LLMs automatically define head and body predicates. Then, RuAG applies Monte Carlo Tree Search (MCTS) to address the combinational searching space and efficiently discover logic rules from data. The resulting logic rules are translated into natural language, allowing targeted knowledge injection and seamless integration into LLM prompts for LLM's downstream task reasoning. We evaluate our framework on public and private industrial tasks, including natural language processing, time-series, decision-making, and industrial tasks, demonstrating its effectiveness in enhancing LLM's capability over diverse tasks.", "published": "2024-11-07 05:00:00", "id": "bdbf5f7d-d6ea-46aa-b3fb-2c0817b59b94", "source": "arxiv", "section": "computerScience"}, {"title": "Tabular Data Synthesis with Differential Privacy: A Survey", "link": "https://arxiv.org/abs/2411.03351", "description": "arXiv:2411.03351v1 Announce Type: new \nAbstract: Data sharing is a prerequisite for collaborative innovation, enabling organizations to leverage diverse datasets for deeper insights. In real-world applications like FinTech and Smart Manufacturing, transactional data, often in tabular form, are generated and analyzed for insight generation. However, such datasets typically contain sensitive personal/business information, raising privacy concerns and regulatory risks. Data synthesis tackles this by generating artificial datasets that preserve the statistical characteristics of real data, removing direct links to individuals. However, attackers can still infer sensitive information using background knowledge. Differential privacy offers a solution by providing provable and quantifiable privacy protection. Consequently, differentially private data synthesis has emerged as a promising approach to privacy-aware data sharing. This paper provides a comprehensive overview of existing differentially private tabular data synthesis methods, highlighting the unique challenges of each generation model for generating tabular data under differential privacy constraints. We classify the methods into statistical and deep learning-based approaches based on their generation models, discussing them in both centralized and distributed environments. We evaluate and compare those methods within each category, highlighting their strengths and weaknesses in terms of utility, privacy, and computational complexity. Additionally, we present and discuss various evaluation methods for assessing the quality of the synthesized data, identify research gaps in the field and directions for future research.", "published": "2024-11-07 05:00:00", "id": "dc6c3e3c-1044-4bc1-b3bd-deb8b2493d73", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Maritime Situational Awareness through End-to-End Onboard Raw Data Analysis", "link": "https://arxiv.org/abs/2411.03403", "description": "arXiv:2411.03403v1 Announce Type: new \nAbstract: Satellite-based onboard data processing is crucial for time-sensitive applications requiring timely and efficient rapid response. Advances in edge artificial intelligence are shifting computational power from ground-based centers to on-orbit platforms, transforming the \"sensing-communication-decision-feedback\" cycle and reducing latency from acquisition to delivery. The current research presents a framework addressing the strict bandwidth, energy, and latency constraints of small satellites, focusing on maritime monitoring. The study contributes three main innovations. Firstly, it investigates the application of deep learning techniques for direct ship detection and classification from raw satellite imagery. By simplifying the onboard processing chain, our approach facilitates direct analyses without requiring computationally intensive steps such as calibration and ortho-rectification. Secondly, to address the scarcity of raw satellite data, we introduce two novel datasets, VDS2Raw and VDV2Raw, which are derived from raw data from Sentinel-2 and Vegetation and Environment Monitoring New Micro Satellite (VENuS) missions, respectively, and enriched with Automatic Identification System (AIS) records. Thirdly, we characterize the tasks' optimal single and multiple spectral band combinations through statistical and feature-based analyses validated on both datasets. In sum, we demonstrate the feasibility of the proposed method through a proof-of-concept on CubeSat-like hardware, confirming the models' potential for operational satellite-based maritime monitoring.", "published": "2024-11-07 05:00:00", "id": "e82bccb0-5916-4b50-b74a-b3850cb78748", "source": "arxiv", "section": "computerScience"}, {"title": "xApp-Level Conflict Mitigation in O-RAN, a Mobility Driven Energy Saving Case", "link": "https://arxiv.org/abs/2411.03326", "description": "arXiv:2411.03326v1 Announce Type: new \nAbstract: This paper investigates the emerging challenges of conflict detection and mitigation in Open Radio Access Network (O-RAN). Conflicts between xApps can arise that affect network performance and stability due to the disaggregated nature of O-RAN. This work provides a detailed theoretical framework of Extended Application (xApp)-level conflicts, i.e., direct, indirect, and implicit conflicts. Leveraging conflict graphs, we further highlight how conflicts impact Key Performance Indicators (KPIs) and explore strategies for conflict detection using Service Level Agreements (SLAs) and Quality of Service (QoS) thresholds. We evaluate the effectiveness of several mitigation strategies in a simulated environment with Mobility Robustness Optimization (MRO) and Energy Saving (ES) xApps and present experimental results showing comparisons among these strategies. The findings of this research provide significant insights for enhancing O-RAN deployments with flexible and efficient conflict management.", "published": "2024-11-07 05:00:00", "id": "45522db3-651f-4a68-a12a-578d489d44a0", "source": "arxiv", "section": "computerScience"}, {"title": "Asymmetric Weighted Cascade Model for Competitive Influence Maximization", "link": "https://arxiv.org/abs/2411.03335", "description": "arXiv:2411.03335v1 Announce Type: new \nAbstract: We introduce a modified Weighted Cascade model that integrates asymmetric budgets and product scores, providing new insights into the Generalized Asymmetric Influence Maximization problem, which we establish as NP-hard. Our simulations demonstrate that players with higher budgets possess a distinct advantage in networks characterized by larger diameters, whereas players with superior product scores exhibit a significant advantage in networks with smaller diameters. Moreover, we identify a robust linear relationship between graph size and the magnitude of influenced nodes. In densely connected networks we derive bounds for the probabilities of influence that are independent of network size. Our examination of Nash equilibria in this domain underscores the absence of a guaranteed pure Nash equilibrium, suggesting that the strategic enhancement of budgets or product scores may yield more substantial benefits than the pursuit of an optimal strategy in this context.", "published": "2024-11-07 05:00:00", "id": "e6fe76c3-5cd4-4b32-a773-8296c0bcd2fe", "source": "arxiv", "section": "computerScience"}, {"title": "Towards evaluations-based safety cases for AI scheming", "link": "https://arxiv.org/abs/2411.03336", "description": "arXiv:2411.03336v1 Announce Type: new \nAbstract: We sketch how developers of frontier AI systems could construct a structured rationale -- a 'safety case' -- that an AI system is unlikely to cause catastrophic outcomes through scheming. Scheming is a potential threat model where AI systems could pursue misaligned goals covertly, hiding their true capabilities and objectives. In this report, we propose three arguments that safety cases could use in relation to scheming. For each argument we sketch how evidence could be gathered from empirical evaluations, and what assumptions would need to be met to provide strong assurance. First, developers of frontier AI systems could argue that AI systems are not capable of scheming (Scheming Inability). Second, one could argue that AI systems are not capable of posing harm through scheming (Harm Inability). Third, one could argue that control measures around the AI systems would prevent unacceptable outcomes even if the AI systems intentionally attempted to subvert them (Harm Control). Additionally, we discuss how safety cases might be supported by evidence that an AI system is reasonably aligned with its developers (Alignment). Finally, we point out that many of the assumptions required to make these safety arguments have not been confidently satisfied to date and require making progress on multiple open research problems.", "published": "2024-11-07 05:00:00", "id": "6a5d352f-f7df-4d90-9d99-a5a5c5d2c284", "source": "arxiv", "section": "computerScience"}, {"title": "Six Candidates Suffice to Win a Voter Majority", "link": "https://arxiv.org/abs/2411.03390", "description": "arXiv:2411.03390v1 Announce Type: new \nAbstract: A cornerstone of social choice theory is Condorcet's paradox which says that in an election where $n$ voters rank $m$ candidates it is possible that, no matter which candidate is declared the winner, a majority of voters would have preferred an alternative candidate. Instead, can we always choose a small committee of winning candidates that is preferred to any alternative candidate by a majority of voters?\n  Elkind, Lang, and Saffidine raised this question and called such a committee a Condorcet winning set. They showed that winning sets of size $2$ may not exist, but sets of size logarithmic in the number of candidates always do. In this work, we show that Condorcet winning sets of size $6$ always exist, regardless of the number of candidates or the number of voters. More generally, we show that if $\\frac{\\alpha}{1 - \\ln \\alpha} \\geq \\frac{2}{k + 1}$, then there always exists a committee of size $k$ such that less than an $\\alpha$ fraction of the voters prefer an alternate candidate. These are the first nontrivial positive results that apply for all $k \\geq 2$.\n  Our proof uses the probabilistic method and the minimax theorem, inspired by recent work on approximately stable committee selection. We construct a distribution over committees that performs sufficiently well (when compared against any candidate on any small subset of the voters) so that this distribution must contain a committee with the desired property in its support.", "published": "2024-11-07 05:00:00", "id": "3e3fb0db-171d-4a33-a7b9-e1db9ae79606", "source": "arxiv", "section": "computerScience"}, {"title": "Enhanced Real-Time Threat Detection in 5G Networks: A Self-Attention RNN Autoencoder Approach for Spectral Intrusion Analysis", "link": "https://arxiv.org/abs/2411.03365", "description": "arXiv:2411.03365v1 Announce Type: new \nAbstract: In the rapidly evolving landscape of 5G technology, safeguarding Radio Frequency (RF) environments against sophisticated intrusions is paramount, especially in dynamic spectrum access and management. This paper presents an enhanced experimental model that integrates a self-attention mechanism with a Recurrent Neural Network (RNN)-based autoencoder for the detection of anomalous spectral activities in 5G networks at the waveform level. Our approach, grounded in time-series analysis, processes in-phase and quadrature (I/Q) samples to identify irregularities that could indicate potential jamming attacks. The model's architecture, augmented with a self-attention layer, extends the capabilities of RNN autoencoders, enabling a more nuanced understanding of temporal dependencies and contextual relationships within the RF spectrum. Utilizing a simulated 5G Radio Access Network (RAN) test-bed constructed with srsRAN 5G and Software Defined Radios (SDRs), we generated a comprehensive stream of data that reflects real-world RF spectrum conditions and attack scenarios. The model is trained to reconstruct standard signal behavior, establishing a normative baseline against which deviations, indicative of security threats, are identified. The proposed architecture is designed to balance between detection precision and computational efficiency, so the LSTM network, enriched with self-attention, continues to optimize for minimal execution latency and power consumption. Conducted on a real-world SDR-based testbed, our results demonstrate the model's improved performance and accuracy in threat detection.\n  Keywords: self-attention, real-time intrusion detection, RNN autoencoder, Transformer architecture, LSTM, time series anomaly detection, 5G Security, spectrum access security.", "published": "2024-11-07 05:00:00", "id": "6cc73543-46eb-4559-a862-324aa17bdb07", "source": "arxiv", "section": "computerScience"}, {"title": "EVA-S3PC: Efficient, Verifiable, Accurate Secure Matrix Multiplication Protocol Assembly and Its Application in Regression", "link": "https://arxiv.org/abs/2411.03404", "description": "arXiv:2411.03404v1 Announce Type: new \nAbstract: Efficient multi-party secure matrix multiplication is crucial for privacy-preserving machine learning, but existing mixed-protocol frameworks often face challenges in balancing security, efficiency, and accuracy. This paper presents an efficient, verifiable and accurate secure three-party computing (EVA-S3PC) framework that addresses these challenges with elementary 2-party and 3-party matrix operations based on data obfuscation techniques. We propose basic protocols for secure matrix multiplication, inversion, and hybrid multiplication, ensuring privacy and result verifiability. Experimental results demonstrate that EVA-S3PC achieves up to 14 significant decimal digits of precision in Float64 calculations, while reducing communication overhead by up to $54.8\\%$ compared to state of art methods. Furthermore, 3-party regression models trained using EVA-S3PC on vertically partitioned data achieve accuracy nearly identical to plaintext training, which illustrates its potential in scalable, efficient, and accurate solution for secure collaborative modeling across domains.", "published": "2024-11-07 05:00:00", "id": "fa8615a7-9c44-4cc3-bf2e-7d66bbea908b", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Table Representations with LLM-powered Synthetic Data Generation", "link": "https://arxiv.org/abs/2411.03356", "description": "arXiv:2411.03356v1 Announce Type: new \nAbstract: In the era of data-driven decision-making, accurate table-level representations and efficient table recommendation systems are becoming increasingly crucial for improving table management, discovery, and analysis. However, existing approaches to tabular data representation often face limitations, primarily due to their focus on cell-level tasks and the lack of high-quality training data. To address these challenges, we first formulate a clear definition of table similarity in the context of data transformation activities within data-driven enterprises. This definition serves as the foundation for synthetic data generation, which require a well-defined data generation process. Building on this, we propose a novel synthetic data generation pipeline that harnesses the code generation and data manipulation capabilities of Large Language Models (LLMs) to create a large-scale synthetic dataset tailored for table-level representation learning. Through manual validation and performance comparisons on the table recommendation task, we demonstrate that the synthetic data generated by our pipeline aligns with our proposed definition of table similarity and significantly enhances table representations, leading to improved recommendation performance.", "published": "2024-11-07 05:00:00", "id": "73027763-c0b2-4cd3-b5e0-9b25665e7da5", "source": "arxiv", "section": "computerScience"}, {"title": "Geographical and Disciplinary Coverage of Open Access Journals: OpenAlex, Scopus and WoS", "link": "https://arxiv.org/abs/2411.03325", "description": "arXiv:2411.03325v1 Announce Type: new \nAbstract: This study aims to compare the geographical and disciplinary coverage of OA journals in three databases: OpenAlex, Scopus and the WoS. We used the ROAD database, managed by the ISSN International Centre, as a reference database which indexes 62,701 OA active resources (as of May 2024). Among the 62,701 active resources indexed in the ROAD database, the Web of Science indexes 6,157 journals, while Scopus indexes 7,351, and OpenAlex indexes 34,217. A striking observation is the presence of 25,658 OA journals exclusively in OpenAlex, whereas only 182 journals are exclusively present in WoS and 373 in Scopus. The geographical analysis focusses on two levels: continents and countries. As for disciplinary comparison, we use the ten disciplinary levels of the ROAD database. Moreover, our findings reveal a striking similarity in OA journal coverage between WoS and Scopus. However, while OpenAlex offers better inclusivity and indexing, it is not without biases. WoS and Scopus predictably favor journals from Europe, North America and Oceania. Although OpenAlex presents a much more balanced indexing, certain regions and countries remain relatively underrepresented. Typically, Africa is proportionally as under-represented in OpenAlex as it is in WoS, and some emerging countries are proportionally less represented in OpenAlex than in WoS and Scopus. These results underscore a marked similarity in OA journal indexing between WoS and Scopus, while OpenAlex aligns more closely with the distribution observed in the ROAD database, although it also exhibits some representational biases.", "published": "2024-11-07 05:00:00", "id": "6bc1800e-ada4-437a-9ccc-49b46912231b", "source": "arxiv", "section": "computerScience"}, {"title": "Foundation Models for Rapid Autonomy Validation", "link": "https://arxiv.org/abs/2411.03328", "description": "arXiv:2411.03328v1 Announce Type: new \nAbstract: We are motivated by the problem of autonomous vehicle performance validation. A key challenge is that an autonomous vehicle requires testing in every kind of driving scenario it could encounter, including rare events, to provide a strong case for safety and show there is no edge-case pathological behavior. Autonomous vehicle companies rely on potentially millions of miles driven in realistic simulation to expose the driving stack to enough miles to estimate rates and severity of collisions. To address scalability and coverage, we propose the use of a behavior foundation model, specifically a masked autoencoder (MAE), trained to reconstruct driving scenarios. We leverage the foundation model in two complementary ways: we (i) use the learned embedding space to group qualitatively similar scenarios together and (ii) fine-tune the model to label scenario difficulty based on the likelihood of a collision upon re-simulation. We use the difficulty scoring as importance weighting for the groups of scenarios. The result is an approach which can more rapidly estimate the rates and severity of collisions by prioritizing hard scenarios while ensuring exposure to every kind of driving scenario.", "published": "2024-11-07 05:00:00", "id": "d5cc8f81-49c2-4010-aea7-7213fe4e9ff0", "source": "arxiv", "section": "computerScience"}, {"title": "Exploring Large Language Models for Specialist-level Oncology Care", "link": "https://arxiv.org/abs/2411.03395", "description": "arXiv:2411.03395v1 Announce Type: new \nAbstract: Large language models (LLMs) have shown remarkable progress in encoding clinical knowledge and responding to complex medical queries with appropriate clinical reasoning. However, their applicability in subspecialist or complex medical settings remains underexplored. In this work, we probe the performance of AMIE, a research conversational diagnostic AI system, in the subspecialist domain of breast oncology care without specific fine-tuning to this challenging domain. To perform this evaluation, we curated a set of 50 synthetic breast cancer vignettes representing a range of treatment-naive and treatment-refractory cases and mirroring the key information available to a multidisciplinary tumor board for decision-making (openly released with this work). We developed a detailed clinical rubric for evaluating management plans, including axes such as the quality of case summarization, safety of the proposed care plan, and recommendations for chemotherapy, radiotherapy, surgery and hormonal therapy. To improve performance, we enhanced AMIE with the inference-time ability to perform web search retrieval to gather relevant and up-to-date clinical knowledge and refine its responses with a multi-stage self-critique pipeline. We compare response quality of AMIE with internal medicine trainees, oncology fellows, and general oncology attendings under both automated and specialist clinician evaluations. In our evaluations, AMIE outperformed trainees and fellows demonstrating the potential of the system in this challenging and important domain. We further demonstrate through qualitative examples, how systems such as AMIE might facilitate conversational interactions to assist clinicians in their decision making. However, AMIE's performance was overall inferior to attending oncologists suggesting that further research is needed prior to consideration of prospective uses.", "published": "2024-11-07 05:00:00", "id": "2265bb07-6829-4576-b31d-32d7eefc3286", "source": "arxiv", "section": "computerScience"}, {"title": "TDDBench: A Benchmark for Training data detection", "link": "https://arxiv.org/abs/2411.03363", "description": "arXiv:2411.03363v1 Announce Type: new \nAbstract: Training Data Detection (TDD) is a task aimed at determining whether a specific data instance is used to train a machine learning model. In the computer security literature, TDD is also referred to as Membership Inference Attack (MIA). Given its potential to assess the risks of training data breaches, ensure copyright authentication, and verify model unlearning, TDD has garnered significant attention in recent years, leading to the development of numerous methods. Despite these advancements, there is no comprehensive benchmark to thoroughly evaluate the effectiveness of TDD methods. In this work, we introduce TDDBench, which consists of 13 datasets spanning three data modalities: image, tabular, and text. We benchmark 21 different TDD methods across four detection paradigms and evaluate their performance from five perspectives: average detection performance, best detection performance, memory consumption, and computational efficiency in both time and memory. With TDDBench, researchers can identify bottlenecks and areas for improvement in TDD algorithms, while practitioners can make informed trade-offs between effectiveness and efficiency when selecting TDD algorithms for specific use cases. Our large-scale benchmarking also reveals the generally unsatisfactory performance of TDD algorithms across different datasets. To enhance accessibility and reproducibility, we open-source TDDBench for the research community.", "published": "2024-11-07 05:00:00", "id": "df384ae0-0d7f-488a-b423-b0b98db9a2ff", "source": "arxiv", "section": "computerScience"}, {"title": "Hypergraphs as Weighted Directed Self-Looped Graphs: Spectral Properties, Clustering, Cheeger Inequality", "link": "https://arxiv.org/abs/2411.03331", "description": "arXiv:2411.03331v1 Announce Type: new \nAbstract: Hypergraphs naturally arise when studying group relations and have been widely used in the field of machine learning. There has not been a unified formulation of hypergraphs, yet the recently proposed edge-dependent vertex weights (EDVW) modeling is one of the most generalized modeling methods of hypergraphs, i.e., most existing hypergraphs can be formulated as EDVW hypergraphs without any information loss to the best of our knowledge. However, the relevant algorithmic developments on EDVW hypergraphs remain nascent: compared to spectral graph theories, the formulations are incomplete, the spectral clustering algorithms are not well-developed, and one result regarding hypergraph Cheeger Inequality is even incorrect. To this end, deriving a unified random walk-based formulation, we propose our definitions of hypergraph Rayleigh Quotient, NCut, boundary/cut, volume, and conductance, which are consistent with the corresponding definitions on graphs. Then, we prove that the normalized hypergraph Laplacian is associated with the NCut value, which inspires our HyperClus-G algorithm for spectral clustering on EDVW hypergraphs. Finally, we prove that HyperClus-G can always find an approximately linearly optimal partitioning in terms of Both NCut and conductance. Additionally, we provide extensive experiments to validate our theoretical findings from an empirical perspective.", "published": "2024-11-07 05:00:00", "id": "6607ee3a-ffdd-4253-b79a-d6ab7a0dc354", "source": "arxiv", "section": "computerScience"}, {"title": "DP-HLS: A High-Level Synthesis Framework for Accelerating Dynamic Programming Algorithms in Bioinformatics", "link": "https://arxiv.org/abs/2411.03398", "description": "arXiv:2411.03398v1 Announce Type: new \nAbstract: Dynamic programming (DP) based algorithms are essential yet compute-intensive parts of numerous bioinformatics pipelines, which typically involve populating a 2-D scoring matrix based on a recursive formula, optionally followed by a traceback step to get the optimal alignment path. DP algorithms are used in a wide spectrum of bioinformatics tasks, including read assembly, homology search, gene annotation, basecalling, and phylogenetic inference. So far, specialized hardware like ASICs and FPGAs have provided massive speedup for these algorithms. However, these solutions usually represent a single design point in the DP algorithmic space and typically require months of manual effort to implement using low-level hardware description languages (HDLs). This paper introduces DP-HLS, a novel framework based on High-Level Synthesis (HLS) that simplifies and accelerates the development of a broad set of bioinformatically relevant DP algorithms in hardware. DP-HLS features an easy-to-use template with integrated HLS directives, enabling efficient hardware solutions without requiring hardware design knowledge. In our experience, DP-HLS significantly reduced the development time of new kernels (months to days) and produced designs with comparable resource utilization to open-source hand-coded HDL-based implementations and performance within 7.7-16.8% margin. DP-HLS is compatible with AWS EC2 F1 FPGA instances. To demonstrate the versatility of the DP-HLS framework, we implemented 15 diverse DP kernels, achieving 1.3-32x improved throughput over state-of-the-art GPU and CPU baselines and providing the first open-source FPGA implementation for several of them. The DP-HLS codebase is available freely under the MIT license and its detailed wiki is available to assist new users.", "published": "2024-11-07 05:00:00", "id": "47d0891f-729e-497d-9971-4e1a5b931920", "source": "arxiv", "section": "computerScience"}, {"title": "DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural Networks", "link": "https://arxiv.org/abs/2411.03364", "description": "arXiv:2411.03364v1 Announce Type: new \nAbstract: Graph has become increasingly integral to the advancement of recommendation systems, particularly with the fast development of graph neural network(GNN). By exploring the virtue of rich node features and link information, GNN is designed to provide personalized and accurate suggestions. Meanwhile, the privacy leakage of GNN in such contexts has also captured special attention. Prior work has revealed that a malicious user can utilize auxiliary knowledge to extract sensitive link data of the target graph, integral to recommendation systems, via the decision made by the target GNN model. This poses a significant risk to the integrity and confidentiality of data used in recommendation system. Though important, previous works on GNN's privacy leakage are still challenged in three aspects, i.e., limited stealing attack scenarios, sub-optimal attack performance, and adaptation against defense. To address these issues, we propose a diffusion model based link stealing attack, named DM4Steal. It differs previous work from three critical aspects. (i) Generality: aiming at six attack scenarios with limited auxiliary knowledge, we propose a novel training strategy for diffusion models so that DM4Steal is transferable to diverse attack scenarios. (ii) Effectiveness: benefiting from the retention of semantic structure in the diffusion model during the training process, DM4Steal is capable to learn the precise topology of the target graph through the GNN decision process. (iii) Adaptation: when GNN is defensive (e.g., DP, Dropout), DM4Steal relies on the stability that comes from sampling the score model multiple times to keep performance degradation to a minimum, thus DM4Steal implements successful adaptive attack on defensive GNN.", "published": "2024-11-07 05:00:00", "id": "46e0cfa5-8964-408d-8193-eb14f31cbf41", "source": "arxiv", "section": "computerScience"}, {"title": "Usefulness of LLMs as an Author Checklist Assistant for Scientific Papers: NeurIPS'24 Experiment", "link": "https://arxiv.org/abs/2411.03417", "description": "arXiv:2411.03417v1 Announce Type: new \nAbstract: Large language models (LLMs) represent a promising, but controversial, tool in aiding scientific peer review. This study evaluates the usefulness of LLMs in a conference setting as a tool for vetting paper submissions against submission standards. We conduct an experiment at the 2024 Neural Information Processing Systems (NeurIPS) conference, where 234 papers were voluntarily submitted to an \"LLM-based Checklist Assistant.\" This assistant validates whether papers adhere to the author checklist used by NeurIPS, which includes questions to ensure compliance with research and manuscript preparation standards. Evaluation of the assistant by NeurIPS paper authors suggests that the LLM-based assistant was generally helpful in verifying checklist completion. In post-usage surveys, over 70% of authors found the assistant useful, and 70% indicate that they would revise their papers or checklist responses based on its feedback. While causal attribution to the assistant is not definitive, qualitative evidence suggests that the LLM contributed to improving some submissions. Survey responses and analysis of re-submissions indicate that authors made substantive revisions to their submissions in response to specific feedback from the LLM. The experiment also highlights common issues with LLMs: inaccuracy (20/52) and excessive strictness (14/52) were the most frequent issues flagged by authors. We also conduct experiments to understand potential gaming of the system, which reveal that the assistant could be manipulated to enhance scores through fabricated justifications, highlighting potential vulnerabilities of automated review tools.", "published": "2024-11-07 05:00:00", "id": "c5a54497-77ab-4430-8b6c-75e254b75068", "source": "arxiv", "section": "computerScience"}, {"title": "FUsion-based ConstitutivE model (FuCe): Towards model-data augmentation in constitutive modelling", "link": "https://arxiv.org/abs/2411.03318", "description": "arXiv:2411.03318v1 Announce Type: new \nAbstract: Constitutive modeling is crucial for engineering design and simulations to accurately describe material behavior. However, traditional phenomenological models often struggle to capture the complexities of real materials under varying stress conditions due to their fixed forms and limited parameters. While recent advances in deep learning have addressed some limitations of classical models, purely data-driven methods tend to require large datasets, lack interpretability, and struggle to generalize beyond their training data. To tackle these issues, we introduce \"Fusion-based Constitutive model (FuCe): Towards model-data augmentation in constitutive modelling\". This approach combines established phenomenological models with an ICNN architecture, designed to train on the limited and noisy force-displacement data typically available in practical applications. The hybrid model inherently adheres to necessary constitutive conditions. During inference, Monte Carlo dropout is employed to generate Bayesian predictions, providing mean values and confidence intervals that quantify uncertainty. We demonstrate the model's effectiveness by learning two isotropic constitutive models and one anisotropic model with a single fiber direction, across six different stress states. The framework's applicability is also showcased in finite element simulations across three geometries of varying complexities. Our results highlight the framework's superior extrapolation capabilities, even when trained on limited and noisy data, delivering accurate and physically meaningful predictions across all numerical examples.", "published": "2024-11-07 05:00:00", "id": "0c77283e-3933-4356-8697-7a413ba6b855", "source": "arxiv", "section": "computerScience"}, {"title": "Quantifying Aleatoric Uncertainty of the Treatment Effect: A Novel Orthogonal Learner", "link": "https://arxiv.org/abs/2411.03387", "description": "arXiv:2411.03387v1 Announce Type: new \nAbstract: Estimating causal quantities from observational data is crucial for understanding the safety and effectiveness of medical treatments. However, to make reliable inferences, medical practitioners require not only estimating averaged causal quantities, such as the conditional average treatment effect, but also understanding the randomness of the treatment effect as a random variable. This randomness is referred to as aleatoric uncertainty and is necessary for understanding the probability of benefit from treatment or quantiles of the treatment effect. Yet, the aleatoric uncertainty of the treatment effect has received surprisingly little attention in the causal machine learning community. To fill this gap, we aim to quantify the aleatoric uncertainty of the treatment effect at the covariate-conditional level, namely, the conditional distribution of the treatment effect (CDTE). Unlike average causal quantities, the CDTE is not point identifiable without strong additional assumptions. As a remedy, we employ partial identification to obtain sharp bounds on the CDTE and thereby quantify the aleatoric uncertainty of the treatment effect. We then develop a novel, orthogonal learner for the bounds on the CDTE, which we call AU-learner. We further show that our AU-learner has several strengths in that it satisfies Neyman-orthogonality and is doubly robust. Finally, we propose a fully-parametric deep learning instantiation of our AU-learner.", "published": "2024-11-07 05:00:00", "id": "928fc797-2af3-4376-b22d-471b3aac44e9", "source": "arxiv", "section": "computerScience"}, {"title": "Energy Price Modelling: A Comparative Evaluation of four Generations of Forecasting Methods", "link": "https://arxiv.org/abs/2411.03372", "description": "arXiv:2411.03372v1 Announce Type: new \nAbstract: Energy is a critical driver of modern economic systems. Accurate energy price forecasting plays an important role in supporting decision-making at various levels, from operational purchasing decisions at individual business organizations to policy-making. A significant body of literature has looked into energy price forecasting, investigating a wide range of methods to improve accuracy and inform these critical decisions. Given the evolving landscape of forecasting techniques, the literature lacks a thorough empirical comparison that systematically contrasts these methods.\n  This paper provides an in-depth review of the evolution of forecasting modeling frameworks, from well-established econometric models to machine learning methods, early sequence learners such LSTMs, and more recent advancements in deep learning with transformer networks, which represent the cutting edge in forecasting. We offer a detailed review of the related literature and categorize forecasting methodologies into four model families. We also explore emerging concepts like pre-training and transfer learning, which have transformed the analysis of unstructured data and hold significant promise for time series forecasting. We address a gap in the literature by performing a comprehensive empirical analysis on these four family models, using data from the EU energy markets, we conduct a large-scale empirical study, which contrasts the forecasting accuracy of different approaches, focusing especially on alternative propositions for time series transformers.", "published": "2024-11-07 05:00:00", "id": "6421914b-e6b4-4d55-88c4-607efdfa9eca", "source": "arxiv", "section": "computerScience"}, {"title": "Fine-Grained Spatial and Verbal Losses for 3D Visual Grounding", "link": "https://arxiv.org/abs/2411.03405", "description": "arXiv:2411.03405v1 Announce Type: new \nAbstract: 3D visual grounding consists of identifying the instance in a 3D scene which is referred by an accompanying language description. While several architectures have been proposed within the commonly employed grounding-by-selection framework, the utilized losses are comparatively under-explored. In particular, most methods rely on a basic supervised cross-entropy loss on the predicted distribution over candidate instances, which fails to model both spatial relations between instances and the internal fine-grained word-level structure of the verbal referral. Sparse attempts to additionally supervise verbal embeddings globally by learning the class of the referred instance from the description or employing verbo-visual contrast to better separate instance embeddings do not fundamentally lift the aforementioned limitations. Responding to these shortcomings, we introduce two novel losses for 3D visual grounding: a visual-level offset loss on regressed vector offsets from each instance to the ground-truth referred instance and a language-related span loss on predictions for the word-level span of the referred instance in the description. In addition, we equip the verbo-visual fusion module of our new 3D visual grounding architecture AsphaltNet with a top-down bidirectional attentive fusion block, which enables the supervisory signals from our two losses to propagate to the respective converse branches of the network and thus aid the latter to learn context-aware instance embeddings and grounding-aware verbal embeddings. AsphaltNet proposes novel auxiliary losses to aid 3D visual grounding with competitive results compared to the state-of-the-art on the ReferIt3D benchmark.", "published": "2024-11-07 05:00:00", "id": "303dd4b1-b87c-4d41-b8ef-30b7004d92c1", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Interoperability Testing of Smart Energy Systems -- An Overview and Discussion of Possibilities", "link": "https://arxiv.org/abs/2411.03369", "description": "arXiv:2411.03369v1 Announce Type: new \nAbstract: Interoperability is the key to implementing a wide range of energy systems applications. It involves the seamless cooperation of different methods and components. With smart energy systems, interoperability faces challenges due to integrating differ-ent approaches and technologies. This includes dealing with heterogeneous approaches with various communication proto-cols and data formats. However, it is essential for smart energy systems to carry out thorough interoperability tests. They are usually diverse, and challenging, thus requiring careful consideration of compatibility issues and complex integration scenari-os. Overcoming these challenges requires a systematic approach that includes thorough test planning, rigorous testing, and continuous test monitoring. Although numerous testing approaches exist, most are more developed at the component/device level than at the system level. Consequently, there are few approaches and related facilities to test the interoperability of smart energy approaches and solutions at the system level. This work analyses existing interoperability test concepts, identi-fies enablers and the potential for harmonisation of procedures, and proposes further developments of these approaches.", "published": "2024-11-07 05:00:00", "id": "e44cf5c1-51e2-4cac-8709-62a3e65c1048", "source": "arxiv", "section": "computerScience"}, {"title": "Balancing Profit and Traveller Acceptance in Ride-Pooling Personalised Fares", "link": "https://arxiv.org/abs/2411.03370", "description": "arXiv:2411.03370v1 Announce Type: new \nAbstract: In a ride-pooling system, travellers experience discomfort associated with a detour and a longer travel time, which is compensated with a sharing discount. Most studies assume travellers receive either a flat discount or, in rare cases, a proportional to the inconvenience. We show the system benefits from individually tailored fares. We argue that fares that optimise an expected profit of an operator also improve system-wide performance if they include travellers' acceptance.\n  Our pricing method is set in a heterogeneous population, where travellers have varying levels of value-of-time and willingness-to-share, unknown to the operator. A high fare discourages clients from the service, while a low fare reduces the profit margin. Notably, a shared ride is only realised if accepted by all co-travellers (decision is driven by the latent behavioural factors).\n  Our method reveals intriguing properties of the shareability topology. Not only identifies rides efficient for the system and supports them with reduced fares (to increase their realisation probability), but also identifies travellers unattractive for the system (e.g. due to incompatibility with other travellers) and effectively shifts them to private rides via high fares. Unlike in previous methods, such approach naturally balances the travellers satisfaction and the profit maximisation. With an experiment set in NYC, we show that this leads to significant improvements over the flat discount baseline: the mileage (proxy for environmental externalities) is reduced by 4.5% and the operator generates more profit per mile (over 20% improvement). We argue that ride pooling systems with fares that maximise profitability are more sustainable and efficient if they include travellers' satisfaction. Keywords: ride-pooling, personalised pricing, individual discounts", "published": "2024-11-07 05:00:00", "id": "189d07db-fd98-479b-b40c-30fe6a3e7c20", "source": "arxiv", "section": "computerScience"}, {"title": "Comparing Security and Efficiency of WebAssembly and Linux Containers in Kubernetes Cloud Computing", "link": "https://arxiv.org/abs/2411.03344", "description": "arXiv:2411.03344v1 Announce Type: new \nAbstract: This study investigates the potential of WebAssembly as a more secure and efficient alternative to Linux containers for executing untrusted code in cloud computing with Kubernetes. Specifically, it evaluates the security and performance implications of this shift. Security analyses demonstrate that both Linux containers and WebAssembly have attack surfaces when executing untrusted code, but WebAssembly presents a reduced attack surface due to an additional layer of isolation. The performance analysis further reveals that while WebAssembly introduces overhead, particularly in startup times, it could be negligible in long-running computations. However, WebAssembly enhances the core principle of containerization, offering better security through isolation and platform-agnostic portability compared to Linux containers. This research demonstrates that WebAssembly is not a silver bullet for all security concerns or performance requirements in a Kubernetes environment, but typical attacks are less likely to succeed and the performance loss is relatively small.", "published": "2024-11-07 05:00:00", "id": "dca72cbc-ea3c-4350-beff-fa433380d1c2", "source": "arxiv", "section": "computerScience"}, {"title": "SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction", "link": "https://arxiv.org/abs/2411.03397", "description": "arXiv:2411.03397v1 Announce Type: new \nAbstract: Many human interactions, such as political debates, are carried out in group settings, where there are arbitrarily many participants, each with different views and agendas. To explore such complex social settings, we present SAUCE: a customizable Python platform, allowing researchers to plug-and-play various LLMs participating in discussions on any topic chosen by the user. Our platform takes care of instantiating the models, scheduling their responses, managing the discussion history, and producing a comprehensive output log, all customizable through configuration files, requiring little to no coding skills. A novel feature of SAUCE is our asynchronous communication feature, where models decide when to speak in addition to what to say, thus modeling an important facet of human communication. We show SAUCE's attractiveness in two initial experiments, and invite the community to use it in simulating various group simulations.", "published": "2024-11-07 05:00:00", "id": "4dfe35dd-56b8-4485-9a17-49aa89e49f9a", "source": "arxiv", "section": "computerScience"}, {"title": "Learning Few-Shot Object Placement with Intra-Category Transfer", "link": "https://arxiv.org/abs/2411.03408", "description": "arXiv:2411.03408v1 Announce Type: new \nAbstract: Efficient learning from demonstration for long-horizon tasks remains an open challenge in robotics. While significant effort has been directed toward learning trajectories, a recent resurgence of object-centric approaches has demonstrated improved sample efficiency, enabling transferable robotic skills. Such approaches model tasks as a sequence of object poses over time. In this work, we propose a scheme for transferring observed object arrangements to novel object instances by learning these arrangements on canonical class frames. We then employ this scheme to enable a simple yet effective approach for training models from as few as five demonstrations to predict arrangements of a wide range of objects including tableware, cutlery, furniture, and desk spaces. We propose a method for optimizing the learned models to enables efficient learning of tasks such as setting a table or tidying up an office with intra-category transfer, even in the presence of distractors. We present extensive experimental results in simulation and on a real robotic system for table setting which, based on human evaluations, scored 73.3% compared to a human baseline. We make the code and trained models publicly available at http://oplict.cs.uni-freiburg.de.", "published": "2024-11-07 05:00:00", "id": "a55b2ba9-26bd-4fb5-814d-a6ba2a8409e4", "source": "arxiv", "section": "computerScience"}, {"title": "A robust first order meshfree method for time-dependent nonlinear conservation laws", "link": "https://arxiv.org/abs/2411.03411", "description": "arXiv:2411.03411v1 Announce Type: new \nAbstract: We introduce a robust first order accurate meshfree method to numerically solve time-dependent nonlinear conservation laws. The main contribution of this work is the meshfree construction of first order consistent summation by parts differentiations. We describe how to efficiently construct such operators on a point cloud. We then study the performance of such differentiations, and then combine these operators with a numerical flux-based formulation to approximate the solution of nonlinear conservation laws, with focus on the advection equation and the compressible Euler equations. We observe numerically that, while the resulting mesh-free differentiation operators are only $O(h^\\frac{1}{2})$ accurate in the $L^2$ norm, they achieve $O(h)$ rates of convergence when applied to the numerical solution of PDEs.", "published": "2024-11-07 05:00:00", "id": "4964acd4-1b9e-4cf3-a6fb-1ebd9d7a9a2d", "source": "arxiv", "section": "computerScience"}, {"title": "Chorded Cycle Facets of Clique Partitioning Polytopes", "link": "https://arxiv.org/abs/2411.03407", "description": "arXiv:2411.03407v1 Announce Type: new \nAbstract: The $q$-chorded $k$-cycle inequalities are a class of valid inequalities for the clique partitioning polytope. It is known that for $q = 2$ or $q = \\tfrac{k-1}{2}$, these inequalities induce facets of the clique partitioning polytope if and only if $k$ is odd. We solve the open problem of characterizing such facets for arbitrary $k$ and $q$. More specifically, we prove that the $q$-chorded $k$-cycle inequalities induce facets of the clique partitioning polytope if and only if two conditions are satisfied: $k = 1$ mod $q$, and if $k=3q+1$ then $q=3$ or $q$ is even. This establishes the existence of many facets induced by $q$-chorded $k$-cycle inequalities beyond those previously known.", "published": "2024-11-07 05:00:00", "id": "568ade37-728f-4e09-aca0-867ead353514", "source": "arxiv", "section": "computerScience"}, {"title": "A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness", "link": "https://arxiv.org/abs/2411.03350", "description": "arXiv:2411.03350v1 Announce Type: new \nAbstract: Large language models (LLM) have demonstrated emergent abilities in text generation, question answering, and reasoning, facilitating various tasks and domains. Despite their proficiency in various tasks, LLMs like LaPM 540B and Llama-3.1 405B face limitations due to large parameter sizes and computational demands, often requiring cloud API use which raises privacy concerns, limits real-time applications on edge devices, and increases fine-tuning costs. Additionally, LLMs often underperform in specialized domains such as healthcare and law due to insufficient domain-specific knowledge, necessitating specialized models. Therefore, Small Language Models (SLMs) are increasingly favored for their low inference latency, cost-effectiveness, efficient development, and easy customization and adaptability. These models are particularly well-suited for resource-limited environments and domain knowledge acquisition, addressing LLMs' challenges and proving ideal for applications that require localized data handling for privacy, minimal inference latency for efficiency, and domain knowledge acquisition through lightweight fine-tuning. The rising demand for SLMs has spurred extensive research and development. However, a comprehensive survey investigating issues related to the definition, acquisition, application, enhancement, and reliability of SLM remains lacking, prompting us to conduct a detailed survey on these topics. The definition of SLMs varies widely, thus to standardize, we propose defining SLMs by their capability to perform specialized tasks and suitability for resource-constrained settings, setting boundaries based on the minimal size for emergent abilities and the maximum size sustainable under resource constraints. For other aspects, we provide a taxonomy of relevant models/methods and develop general frameworks for each category to enhance and utilize SLMs effectively.", "published": "2024-11-07 05:00:00", "id": "76759f40-d15c-4647-9b9b-75fcffafd32c", "source": "arxiv", "section": "computerScience"}, {"title": "Blockchain-Based Multi-Path Mobile Access Point Selection for Secure 5G VANETs", "link": "https://arxiv.org/abs/2411.03371", "description": "arXiv:2411.03371v1 Announce Type: new \nAbstract: This letter presents a blockchain-based multi-path mobile access point (MAP) selection strategy for secure 5G vehicular ad-hoc networks (VANETs). The proposed method leverages blockchain technology for decentralized, transparent, and secure MAP selection, while the multi-path transmission strategy enhances network reliability and reduces communication delays. A trust-based attack detection mechanism is integrated to ensure network security. Simulation results demonstrate that the proposed algorithm reduces both handover frequency and average communication delay by over 80%, and successfully identifies and excludes more than 95% of Sybil nodes, ensuring reliable and secure communication in highly dynamic vehicular environments.", "published": "2024-11-07 05:00:00", "id": "bf86b524-7f8b-4c91-99e1-18857f4b884a", "source": "arxiv", "section": "computerScience"}, {"title": "Unlocking the Archives: Using Large Language Models to Transcribe Handwritten Historical Documents", "link": "https://arxiv.org/abs/2411.03340", "description": "arXiv:2411.03340v1 Announce Type: new \nAbstract: This study demonstrates that Large Language Models (LLMs) can transcribe historical handwritten documents with significantly higher accuracy than specialized Handwritten Text Recognition (HTR) software, while being faster and more cost-effective. We introduce an open-source software tool called Transcription Pearl that leverages these capabilities to automatically transcribe and correct batches of handwritten documents using commercially available multimodal LLMs from OpenAI, Anthropic, and Google. In tests on a diverse corpus of 18th/19th century English language handwritten documents, LLMs achieved Character Error Rates (CER) of 5.7 to 7% and Word Error Rates (WER) of 8.9 to 15.9%, improvements of 14% and 32% respectively over specialized state-of-the-art HTR software like Transkribus. Most significantly, when LLMs were then used to correct those transcriptions as well as texts generated by conventional HTR software, they achieved near-human levels of accuracy, that is CERs as low as 1.8% and WERs of 3.5%. The LLMs also completed these tasks 50 times faster and at approximately 1/50th the cost of proprietary HTR programs. These results demonstrate that when LLMs are incorporated into software tools like Transcription Pearl, they provide an accessible, fast, and highly accurate method for mass transcription of historical handwritten documents, significantly streamlining the digitization process.", "published": "2024-11-07 05:00:00", "id": "d04a08df-79bf-4e9c-ab59-9003a38d7b07", "source": "arxiv", "section": "computerScience"}, {"title": "Rapid Mixing at the Uniqueness Threshold", "link": "https://arxiv.org/abs/2411.03413", "description": "arXiv:2411.03413v1 Announce Type: new \nAbstract: Over the past decades, a fascinating computational phase transition has been identified in sampling from Gibbs distributions. Though, the computational complexity at the critical point remains poorly understood, as previous algorithmic and hardness results all required a constant slack from this threshold.\n  In this paper, we resolve this open question at the critical phase transition threshold, thus completing the picture of the computational phase transition. We show that for the hardcore model on graphs with maximum degree $\\Delta\\ge 3$ at the uniqueness threshold $\\lambda = \\lambda_c(\\Delta)$, the mixing time of Glauber dynamics is upper bounded by a polynomial in $n$, but is not nearly linear in the worst case.\n  For the Ising model (either antiferromagnetic or ferromagnetic), we establish similar results. For the Ising model on graphs with maximum degree $\\Delta\\ge 3$ at the critical temperature $\\beta$ where $|\\beta| = \\beta_c(\\Delta)$, with the tree-uniqueness threshold $\\beta_c(\\Delta)$, we show that the mixing time of Glauber dynamics is upper bounded by $\\tilde{O}\\left(n^{2 + O(1/\\Delta)}\\right)$ and lower bounded by $\\Omega\\left(n^{3/2}\\right)$ in the worst case. For the Ising model specified by a critical interaction matrix $J$ with $\\left \\lVert J \\right \\rVert_2=1$, we obtain an upper bound $\\tilde{O}(n^{3/2})$ for the mixing time, matching the lower bound $\\Omega\\left(n^{3/2}\\right)$ on the complete graph up to a logarithmic factor.\n  Our mixing time upper bounds are derived from a new interpretation and analysis of the localization scheme method introduced by Chen and Eldan (2022), applied to the field dynamics for the hardcore model and the proximal sampler for the Ising model. As key steps in both our upper and lower bounds, we establish sub-linear upper and lower bounds for spectral independence at the critical point for worst-case instances.", "published": "2024-11-07 05:00:00", "id": "df22ef8a-0616-4ae8-8b8e-1936beda8a71", "source": "arxiv", "section": "computerScience"}, {"title": "A networked small-gain theorem based on discrete-time diagonal stability", "link": "https://arxiv.org/abs/2411.03380", "description": "arXiv:2411.03380v1 Announce Type: new \nAbstract: We present a new sufficient condition for finite-gain $L_2$ input-to-output stability of a networked system. The condition requires a matrix, that combines information on the $L_2$ gains of the sub-systems and their interconnections, to be discrete-time diagonally stable (DTDS). We show that the new result generalizes the standard small gain theorem for the negative feedback connection of two sub-systems. An important advantage of the new result is that known sufficient conditions for DTDS can be applied to derive sufficient conditions for networked input-to-output stability. We demonstrate this using several examples. We also derive a new necessary and sufficient condition for a matrix that is a rank one perturbation of a Schur diagonal matrix to be DTDS.", "published": "2024-11-07 05:00:00", "id": "742682f4-0f9c-4b2a-9c78-e951f77d2182", "source": "arxiv", "section": "computerScience"}, {"title": "Accelerating Gaussian Variational Inference for Motion Planning Under Uncertainty", "link": "https://arxiv.org/abs/2411.03416", "description": "arXiv:2411.03416v1 Announce Type: new \nAbstract: This work addresses motion planning under uncertainty as a stochastic optimal control problem. The path distribution induced by the optimal controller corresponds to a posterior path distribution with a known form. To approximate this posterior, we frame an optimization problem in the space of Gaussian distributions, which aligns with the Gaussian Variational Inference Motion Planning (GVIMP) paradigm introduced in \\cite{yu2023gaussian}. In this framework, the computation bottleneck lies in evaluating the expectation of collision costs over a dense discretized trajectory and computing the marginal covariances. This work exploits the sparse motion planning factor graph, which allows for parallel computing collision costs and Gaussian Belief Propagation (GBP) marginal covariance computation, to introduce a computationally efficient approach to solving GVIMP. We term the novel paradigm as the Parallel Gaussian Variational Inference Motion Planning (P-GVIMP). We validate the proposed framework on various robotic systems, demonstrating significant speed acceleration achieved by leveraging Graphics Processing Units (GPUs) for parallel computation. An open-sourced implementation is presented at https://github.com/hzyu17/VIMP.", "published": "2024-11-07 05:00:00", "id": "4c7339c0-9cee-4acb-a52d-48e546d13d6f", "source": "arxiv", "section": "computerScience"}, {"title": "Personal Data Protection in AI-Native 6G Systems", "link": "https://arxiv.org/abs/2411.03368", "description": "arXiv:2411.03368v1 Announce Type: new \nAbstract: As 6G evolves into an AI-native technology, the integration of artificial intelligence (AI) and Generative AI into cellular communication systems presents unparalleled opportunities for enhancing connectivity, network optimization, and personalized services. However, these advancements also introduce significant data protection challenges, as AI models increasingly depend on vast amounts of personal data for training and decision-making. In this context, ensuring compliance with stringent data protection regulations, such as the General Data Protection Regulation (GDPR), becomes critical for the design and operational integrity of 6G networks. These regulations shape key system architecture aspects, including transparency, accountability, fairness, bias mitigation, and data security.\n  This paper identifies and examines the primary data protection risks associated with AI-driven 6G networks, focusing on the complex data flows and processing activities throughout the 6G lifecycle. By exploring these risks, we provide a comprehensive analysis of the potential privacy implications and propose effective mitigation strategies. Our findings stress the necessity of embedding privacy-by-design and privacy-by-default principles in the development of 6G standards to ensure both regulatory compliance and the protection of individual rights.", "published": "2024-11-07 05:00:00", "id": "64fee042-19e7-41fc-ab2b-8d1650186ff9", "source": "arxiv", "section": "computerScience"}, {"title": "Solving Trojan Detection Competitions with Linear Weight Classification", "link": "https://arxiv.org/abs/2411.03445", "description": "arXiv:2411.03445v1 Announce Type: new \nAbstract: Neural networks can conceal malicious Trojan backdoors that allow a trigger to covertly change the model behavior. Detecting signs of these backdoors, particularly without access to any triggered data, is the subject of ongoing research and open challenges. In one common formulation of the problem, we are given a set of clean and poisoned models and need to predict whether a given test model is clean or poisoned. In this paper, we introduce a detector that works remarkably well across many of the existing datasets and domains. It is obtained by training a binary classifier on a large number of models' weights after performing a few different pre-processing steps including feature selection and standardization, reference model weights subtraction, and model alignment prior to detection. We evaluate this algorithm on a diverse set of Trojan detection benchmarks and domains and examine the cases where the approach is most and least effective.", "published": "2024-11-07 05:00:00", "id": "a4e97d2b-c4e0-46c5-90ef-5ea1adc266e6", "source": "arxiv", "section": "computerScience"}, {"title": "AI Horizon Scanning -- White Paper p3395, IEEE-SA. Part III: Technology Watch: a selection of key developments, emerging technologies, and industry trends in Artificial Intelligence", "link": "https://arxiv.org/abs/2411.03449", "description": "arXiv:2411.03449v1 Announce Type: new \nAbstract: Generative Artificial Intelligence (AI) technologies are in a phase of unprecedented rapid development following the landmark release of Chat-GPT, which brought the phenomenon to wide public attention. As the deployment of AI products rises geometrically, considerable attention is being given to the threats and opportunities that AI technologies offer, and to the need for regulatory and standards initiatives to ensure that use of the technology aligns with societal needs and generates broad benefits while mitigating risks and threats. This manuscript is the third of a series of White Papers informing the development of IEEE-SA's p3995 {\\it `Standard for the Implementation of Safeguards, Controls, and Preventive Techniques for Artificial Intelligence Models'} \\cite{P3395}, Chair Marina Cort\\^{e}s. This part focuses on assessing calmly and objectively, as far as is possible, the current state of Artificial Intelligence (AI) technology development and identifying predominant trends, prospects, and ensuing risks. It necessarily forms a snapshot of the current instant of a rapidly-evolving landscape, with new products and innovations emerging continuously. While our main focus is on software and hardware developments and their corporate context, we also briefly review progress on robotics within the AI context and describe some implications of the substantial and growing AI energy demand.", "published": "2024-11-07 05:00:00", "id": "947c2b3f-a04c-49a9-978f-f18c9ef71861", "source": "arxiv", "section": "computerScience"}, {"title": "Fourier Analysis of Variational Quantum Circuits for Supervised Learning", "link": "https://arxiv.org/abs/2411.03450", "description": "arXiv:2411.03450v1 Announce Type: new \nAbstract: VQC can be understood through the lens of Fourier analysis. It is already well-known that the function space represented by any circuit architecture can be described through a truncated Fourier sum. We show that the spectrum available to that truncated Fourier sum is not entirely determined by the encoding gates of the circuit, since the variational part of the circuit can constrain certain coefficients to zero, effectively removing that frequency from the spectrum. To the best of our knowledge, we give the first description of the functional dependence of the Fourier coefficients on the variational parameters as trigonometric polynomials. This allows us to provide an algorithm which computes the exact spectrum of any given circuit and the corresponding Fourier coefficients. Finally, we demonstrate that by comparing the Fourier transform of the dataset to the available spectra, it is possible to predict which \\gls{VQC} out of a given list of choices will be able to best fit the data.", "published": "2024-11-07 05:00:00", "id": "7cd423f1-859b-4ae0-a986-af0a6bdbe846", "source": "arxiv", "section": "computerScience"}, {"title": "Redundancy Is All You Need", "link": "https://arxiv.org/abs/2411.03451", "description": "arXiv:2411.03451v1 Announce Type: new \nAbstract: The seminal work of Bencz\\'ur and Karger demonstrated cut sparsifiers of near-linear size, with several applications throughout theoretical computer science. Subsequent extensions have yielded sparsifiers for hypergraph cuts and more recently linear codes over Abelian groups. A decade ago, Kogan and Krauthgamer asked about the sparsifiability of arbitrary constraint satisfaction problems (CSPs). For this question, a trivial lower bound is the size of a non-redundant CSP instance, which admits, for each constraint, an assignment satisfying only that constraint (so that no constraint can be dropped by the sparsifier). For graph cuts, spanning trees are non-redundant instances.\n  Our main result is that redundant clauses are sufficient for sparsification: for any CSP predicate R, every unweighted instance of CSP(R) has a sparsifier of size at most its non-redundancy (up to polylog factors). For weighted instances, we similarly pin down the sparsifiability to the so-called chain length of the predicate. These results precisely determine the extent to which any CSP can be sparsified. A key technical ingredient in our work is a novel application of the entropy method from Gilmer's recent breakthrough on the union-closed sets conjecture.\n  As an immediate consequence of our main theorem, a number of results in the non-redundancy literature immediately extend to CSP sparsification. We also contribute new techniques for understanding the non-redundancy of CSP predicates. In particular, we give an explicit family of predicates whose non-redundancy roughly corresponds to the structure of matching vector families in coding theory. By adapting methods from the matching vector codes literature, we are able to construct an explicit predicate whose non-redundancy lies between $\\Omega(n^{1.5})$ and $\\widetilde{O}(n^{1.6})$, the first example with a provably non-integral exponent.", "published": "2024-11-07 05:00:00", "id": "526539fc-5a9f-4de2-9355-7bc4e17ff1aa", "source": "arxiv", "section": "computerScience"}, {"title": "Watson: A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents", "link": "https://arxiv.org/abs/2411.03455", "description": "arXiv:2411.03455v1 Announce Type: new \nAbstract: As foundation models (FMs) play an increasingly prominent role in complex software systems, such as FM-powered agentic software (i.e., Agentware), they introduce significant challenges for developers regarding observability. Unlike traditional software, agents operate autonomously, using extensive data and opaque implicit reasoning, making it difficult to observe and understand their behavior during runtime, especially when they take unexpected actions or encounter errors. In this paper, we highlight the limitations of traditional operational observability in the context of FM-powered software, and introduce cognitive observability as a new type of required observability that has emerged for such innovative systems. We then propose a novel framework that provides cognitive observability into the implicit reasoning processes of agents (a.k.a. reasoning observability), and demonstrate the effectiveness of our framework in boosting the debuggability of Agentware and, in turn, the abilities of an Agentware through a case study on AutoCodeRover, a cuttingedge Agentware for autonomous program improvement.", "published": "2024-11-07 05:00:00", "id": "982b3406-bb8b-4fb3-97c7-0a8494ca61a4", "source": "arxiv", "section": "computerScience"}, {"title": "Pathway-Guided Optimization of Deep Generative Molecular Design Models for Cancer Therapy", "link": "https://arxiv.org/abs/2411.03460", "description": "arXiv:2411.03460v1 Announce Type: new \nAbstract: The data-driven drug design problem can be formulated as an optimization task of a potentially expensive black-box objective function over a huge high-dimensional and structured molecular space. The junction tree variational autoencoder (JTVAE) has been shown to be an efficient generative model that can be used for suggesting legitimate novel drug-like small molecules with improved properties. While the performance of the generative molecular design (GMD) scheme strongly depends on the initial training data, one can improve its sampling efficiency for suggesting better molecules with enhanced properties by optimizing the latent space. In this work, we propose how mechanistic models - such as pathway models described by differential equations - can be used for effective latent space optimization(LSO) of JTVAEs and other similar models for GMD. To demonstrate the potential of our proposed approach, we show how a pharmacodynamic model, assessing the therapeutic efficacy of a drug-like small molecule by predicting how it modulates a cancer pathway, can be incorporated for effective LSO of data-driven models for GMD.", "published": "2024-11-07 05:00:00", "id": "e9035632-3ba4-4b36-b3e2-9b6fee188bef", "source": "arxiv", "section": "computerScience"}, {"title": "Digital Twin for Autonomous Surface Vessels: Enabler for Safe Maritime Navigation", "link": "https://arxiv.org/abs/2411.03465", "description": "arXiv:2411.03465v1 Announce Type: new \nAbstract: Autonomous surface vessels (ASVs) are becoming increasingly significant in enhancing the safety and sustainability of maritime operations. To ensure the reliability of modern control algorithms utilized in these vessels, digital twins (DTs) provide a robust framework for conducting safe and effective simulations within a virtual environment. Digital twins are generally classified on a scale from 0 to 5, with each level representing a progression in complexity and functionality: Level 0 (Standalone) employs offline modeling techniques; Level 1 (Descriptive) integrates sensors and online modeling to enhance situational awareness; Level 2 (Diagnostic) focuses on condition monitoring and cybersecurity; Level 3 (Predictive) incorporates predictive analytics; Level 4 (Prescriptive) embeds decision-support systems; and Level 5 (Autonomous) enables advanced functionalities such as collision avoidance and path following. These digital representations not only provide insights into the vessel's current state and operational efficiency but also predict future scenarios and assess life endurance. By continuously updating with real-time sensor data, the digital twin effectively corrects modeling errors and enhances decision-making processes. Since DTs are key enablers for complex autonomous systems, this paper introduces a comprehensive methodology for establishing a digital twin framework specifically tailored for ASVs. Through a detailed literature survey, we explore existing state-of-the-art enablers across the defined levels, offering valuable recommendations for future research and development in this rapidly evolving field.", "published": "2024-11-07 05:00:00", "id": "c83f78dd-21f6-45e4-bf07-f33377416caf", "source": "arxiv", "section": "computerScience"}, {"title": "MetRex: A Benchmark for Verilog Code Metric Reasoning Using LLMs", "link": "https://arxiv.org/abs/2411.03471", "description": "arXiv:2411.03471v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have been applied to various hardware design tasks, including Verilog code generation, EDA tool scripting, and RTL bug fixing. Despite this extensive exploration, LLMs are yet to be used for the task of post-synthesis metric reasoning and estimation of HDL designs. In this paper, we assess the ability of LLMs to reason about post-synthesis metrics of Verilog designs. We introduce MetRex, a large-scale dataset comprising 25,868 Verilog HDL designs and their corresponding post-synthesis metrics, namely area, delay, and static power. MetRex incorporates a Chain of Thought (CoT) template to enhance LLMs' reasoning about these metrics. Extensive experiments show that Supervised Fine-Tuning (SFT) boosts the LLM's reasoning capabilities on average by 37.0\\%, 25.3\\%, and 25.7\\% on the area, delay, and static power, respectively. While SFT improves performance on our benchmark, it remains far from achieving optimal results, especially on complex problems. Comparing to state-of-the-art regression models, our approach delivers accurate post-synthesis predictions for 17.4\\% more designs (within a 5\\% error margin), in addition to offering a 1.7x speedup by eliminating the need for pre-processing. This work lays the groundwork for advancing LLM-based Verilog code metric reasoning.", "published": "2024-11-07 05:00:00", "id": "347fc943-4ef0-40b4-8232-a529ddb7f668", "source": "arxiv", "section": "computerScience"}, {"title": "Computational Tools for Real-time Analysis of High-throughput High-resolution TEM (HRTEM) Images of Conjugated Polymers", "link": "https://arxiv.org/abs/2411.03474", "description": "arXiv:2411.03474v1 Announce Type: new \nAbstract: Automated analysis of high-resolution transmission electron microscopy (HRTEM) images is increasingly essential for advancing research in organic electronics, where precise characterization of nanoscale crystal structures is crucial for optimizing material properties. This paper introduces an open-source computational framework designed for real-time analysis of HRTEM data, with a focus on characterizing complex microstructures in conjugated polymers, and illustrated using Poly[N-9$'$-heptadecanyl-2,7-carbazole-alt-5,5-(4$'$,7$'$-di-2-thienyl-2$'$,1$'$,3$'$-benzothiadiazole)] (PCDTBT), a key material in organic photovoltaics. The framework employs fast, automated image processing algorithms, enabling rapid extraction of structural features like \\textit{d}-spacing, orientation, and shape metrics. Gaussian process optimization rapidly identifies the user-defined parameters in the approach, reducing the need for manual parameter tuning and thus enhancing reproducibility and usability. Additionally, the framework is compatible with high-performance computing (HPC) environments, allowing for efficient, large-scale data processing at near real-time speeds. A unique feature of the framework is a Wasserstein distance-based stopping criterion, which optimizes data collection by determining when further sampling no longer adds statistically significant information. This capability optimizes the amount of time the TEM facility is used while ensuring data adequacy for in-depth analysis. Open-source and tested on a substantial PCDTBT dataset, this tool offers a powerful, robust, and accessible solution for high-throughput material characterization in organic electronics.", "published": "2024-11-07 05:00:00", "id": "c346e696-f992-4551-a8c9-8b7d0b84648c", "source": "arxiv", "section": "computerScience"}, {"title": "Self Supervised Networks for Learning Latent Space Representations of Human Body Scans and Motions", "link": "https://arxiv.org/abs/2411.03475", "description": "arXiv:2411.03475v1 Announce Type: new \nAbstract: This paper introduces self-supervised neural network models to tackle several fundamental problems in the field of 3D human body analysis and processing. First, we propose VariShaPE (Varifold Shape Parameter Estimator), a novel architecture for the retrieval of latent space representations of body shapes and poses. This network offers a fast and robust method to estimate the embedding of arbitrary unregistered meshes into the latent space. Second, we complement the estimation of latent codes with MoGeN (Motion Geometry Network) a framework that learns the geometry on the latent space itself. This is achieved by lifting the body pose parameter space into a higher dimensional Euclidean space in which body motion mini-sequences from a training set of 4D data can be approximated by simple linear interpolation. Using the SMPL latent space representation we illustrate how the combination of these network models, once trained, can be used to perform a variety of tasks with very limited computational cost. This includes operations such as motion interpolation, extrapolation and transfer as well as random shape and pose generation.", "published": "2024-11-07 05:00:00", "id": "0bbd3ddd-d6c0-4866-b7aa-e993169440c5", "source": "arxiv", "section": "computerScience"}, {"title": "CrowdGenUI: Enhancing LLM-Based UI Widget Generation with a Crowdsourced Preference Library", "link": "https://arxiv.org/abs/2411.03477", "description": "arXiv:2411.03477v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable skills across various design domains, including UI generation. However, current LLMs for UI generation tend to offer generic solutions that lack a deep understanding of task context and user preferences in specific scenarios. We present \\textit{CrowdGenUI}, a framework that enhances LLM-driven UI generation with a crowdsourced user preference library. This approach addresses the limitations of existing methods by guiding LLM reasoning with user preferences, enabling the generation of UI widgets that align more closely with user needs and task-specific requirements. Using image editing as a test domain, we built this library from 50 users, capturing 720 user preferences, which include the predictability, efficiency, and explorability of multiple UI widgets. In a user study with 72 additional participants, our framework outperformed standard LLM-generated widgets in meeting user preferences and task requirements. We discuss these findings to inform future opportunities for designing user-centered and customizable UIs by comprehensively analyzing the extendability of the proposed framework and crowdsourced library.", "published": "2024-11-07 05:00:00", "id": "8b30e316-0e3c-4969-8671-17577e263362", "source": "arxiv", "section": "computerScience"}, {"title": "Rainfall regression from C-band Synthetic Aperture Radar using Multi-Task Generative Adversarial Networks", "link": "https://arxiv.org/abs/2411.03480", "description": "arXiv:2411.03480v1 Announce Type: new \nAbstract: This paper introduces a data-driven approach to estimate precipitation rates from Synthetic Aperture Radar (SAR) at a spatial resolution of 200 meters per pixel. It addresses previous challenges related to the collocation of SAR and weather radar data, specifically the misalignment in collocations and the scarcity of rainfall examples under strong wind. To tackle these challenges, the paper proposes a multi-objective formulation, introducing patch-level components and an adversarial component. It exploits the full NEXRAD archive to look for potential co-locations with Sentinel-1 data. With additional enhancements to the training procedure and the incorporation of additional inputs, the resulting model demonstrates improved accuracy in rainfall estimates and the ability to extend its performance to scenarios up to 15 m/s.", "published": "2024-11-07 05:00:00", "id": "b1d799b9-767a-49b1-91f9-3c7f7a4f7f57", "source": "arxiv", "section": "computerScience"}, {"title": "Chance-Constrained Convex MPC for Robust Quadruped Locomotion Under Parametric and Additive Uncertainties", "link": "https://arxiv.org/abs/2411.03481", "description": "arXiv:2411.03481v1 Announce Type: new \nAbstract: Recent advances in quadrupedal locomotion have focused on improving stability and performance across diverse environments. However, existing methods often lack adequate safety analysis and struggle to adapt to varying payloads and complex terrains, typically requiring extensive tuning. To overcome these challenges, we propose a Chance-Constrained Model Predictive Control (CCMPC) framework that explicitly models payload and terrain variability as distributions of parametric and additive disturbances within the single rigid body dynamics (SRBD) model. Our approach ensures safe and consistent performance under uncertain dynamics by expressing the model friction cone constraints, which define the feasible set of ground reaction forces, as chance constraints. Moreover, we solve the resulting stochastic control problem using a computationally efficient quadratic programming formulation. Extensive Monte Carlo simulations of quadrupedal locomotion across varying payloads and complex terrains demonstrate that CCMPC significantly outperforms two competitive benchmarks: Linear MPC (LMPC) and MPC with hand-tuned safety margins to maintain stability, reduce foot slippage, and track the center of mass. Hardware experiments on the Unitree Go1 robot show successful locomotion across various indoor and outdoor terrains with unknown loads exceeding 50% of the robot body weight, despite no additional parameter tuning. A video of the results and accompanying code can be found at: https://cc-mpc.github.io/.", "published": "2024-11-07 05:00:00", "id": "a55dfc2e-19dd-4c5c-9c62-2083dae21017", "source": "arxiv", "section": "computerScience"}, {"title": "Augmented-Reality Enabled Crop Monitoring with Robot Assistance", "link": "https://arxiv.org/abs/2411.03483", "description": "arXiv:2411.03483v1 Announce Type: new \nAbstract: The integration of augmented reality (AR), extended reality (XR), and virtual reality (VR) technologies in agriculture has shown significant promise in enhancing various agricultural practices. Mobile robots have also been adopted as assessment tools in precision agriculture, improving economic efficiency and productivity, and minimizing undesired effects such as weeds and pests. Despite considerable work on both fronts, the combination of a versatile User Interface (UI) provided by an AR headset with the integration and direct interaction and control of a mobile field robot has not yet been fully explored or standardized. This work aims to address this gap by providing real-time data input and control output of a mobile robot for precision agriculture through a virtual environment enabled by an AR headset interface. The system leverages open-source computational tools and off-the-shelf hardware for effective integration. Distinctive case studies are presented where growers or technicians can interact with a legged robot via an AR headset and a UI. Users can teleoperate the robot to gather information in an area of interest, request real-time graphed status of an area, or have the robot autonomously navigate to selected areas for measurement updates. The proposed system utilizes a custom local navigation method with a fixed holographic coordinate system in combination with QR codes. This step toward fusing AR and robotics in agriculture aims to provide practical solutions for real-time data management and control enabled by human-robot interaction. The implementation can be extended to various robot applications in agriculture and beyond, promoting a unified framework for on-demand and autonomous robot operation in the field.", "published": "2024-11-07 05:00:00", "id": "68ac9030-94c2-423a-9e7e-1623fd44ef41", "source": "arxiv", "section": "computerScience"}, {"title": "LLM Generated Distribution-Based Prediction of US Electoral Results, Part I", "link": "https://arxiv.org/abs/2411.03486", "description": "arXiv:2411.03486v1 Announce Type: new \nAbstract: This paper introduces distribution-based prediction, a novel approach to using Large Language Models (LLMs) as predictive tools by interpreting output token probabilities as distributions representing the models' learned representation of the world. This distribution-based nature offers an alternative perspective for analyzing algorithmic fidelity, complementing the approach used in silicon sampling. We demonstrate the use of distribution-based prediction in the context of recent United States presidential election, showing that this method can be used to determine task specific bias, prompt noise, and algorithmic fidelity. This approach has significant implications for assessing the reliability and increasing transparency of LLM-based predictions across various domains.", "published": "2024-11-07 05:00:00", "id": "f68b53e9-2231-4143-996e-8abc0c83b082", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Exploratory Capability of Visual Navigation Using Uncertainty of Implicit Scene Representation", "link": "https://arxiv.org/abs/2411.03487", "description": "arXiv:2411.03487v1 Announce Type: new \nAbstract: In the context of visual navigation in unknown scenes, both \"exploration\" and \"exploitation\" are equally crucial. Robots must first establish environmental cognition through exploration and then utilize the cognitive information to accomplish target searches. However, most existing methods for image-goal navigation prioritize target search over the generation of exploratory behavior. To address this, we propose the Navigation with Uncertainty-driven Exploration (NUE) pipeline, which uses an implicit and compact scene representation, NeRF, as a cognitive structure. We estimate the uncertainty of NeRF and augment the exploratory ability by the uncertainty to in turn facilitate the construction of implicit representation. Simultaneously, we extract memory information from NeRF to enhance the robot's reasoning ability for determining the location of the target. Ultimately, we seamlessly combine the two generated abilities to produce navigational actions. Our pipeline is end-to-end, with the environmental cognitive structure being constructed online. Extensive experimental results on image-goal navigation demonstrate the capability of our pipeline to enhance exploratory behaviors, while also enabling a natural transition from the exploration to exploitation phase. This enables our model to outperform existing memory-based cognitive navigation structures in terms of navigation performance.", "published": "2024-11-07 05:00:00", "id": "8e747958-1dae-41da-9fe4-d2b6cfe0d30b", "source": "arxiv", "section": "computerScience"}, {"title": "An Application-Agnostic Automatic Target Recognition System Using Vision Language Models", "link": "https://arxiv.org/abs/2411.03491", "description": "arXiv:2411.03491v1 Announce Type: new \nAbstract: We present a novel Automatic Target Recognition (ATR) system using open-vocabulary object detection and classification models. A primary advantage of this approach is that target classes can be defined just before runtime by a non-technical end user, using either a few natural language text descriptions of the target, or a few image exemplars, or both. Nuances in the desired targets can be expressed in natural language, which is useful for unique targets with little or no training data. We also implemented a novel combination of several techniques to improve performance, such as leveraging the additional information in the sequence of overlapping frames to perform tubelet identification (i.e., sequential bounding box matching), bounding box re-scoring, and tubelet linking. Additionally, we developed a technique to visualize the aggregate output of many overlapping frames as a mosaic of the area scanned during the aerial surveillance or reconnaissance, and a kernel density estimate (or heatmap) of the detected targets. We initially applied this ATR system to the use case of detecting and clearing unexploded ordinance on airfield runways and we are currently extending our research to other real-world applications.", "published": "2024-11-07 05:00:00", "id": "29a15b48-ffa3-4dee-b248-31c760079793", "source": "arxiv", "section": "computerScience"}, {"title": "LASER: Attention with Exponential Transformation", "link": "https://arxiv.org/abs/2411.03493", "description": "arXiv:2411.03493v1 Announce Type: new \nAbstract: Transformers have had tremendous impact for several sequence related tasks, largely due to their ability to retrieve from any part of the sequence via softmax based dot-product attention. This mechanism plays a crucial role in Transformer's performance. We analyze the gradients backpropagated through the softmax operation in the attention mechanism and observe that these gradients can often be small. This poor gradient signal backpropagation can lead to inefficient learning of parameters preceeding the attention operations. To this end, we introduce a new attention mechanism called LASER, which we analytically show to admit a larger gradient signal. We show that LASER Attention can be implemented by making small modifications to existing attention implementations. We conduct experiments on autoregressive large language models (LLMs) with upto 2.2 billion parameters where we show upto 3.38% and an average of ~1% improvement over standard attention on downstream evaluations. Using LASER gives the following relative improvements in generalization performance across a variety of tasks (vision, text and speech): 4.67% accuracy in Vision Transformer (ViT) on Imagenet, 2.25% error rate in Conformer on the Librispeech speech-to-text and 0.93% fraction of incorrect predictions in BERT with 2.2 billion parameters.", "published": "2024-11-07 05:00:00", "id": "4b9703dd-2ec4-4872-b469-9690c4bd1844", "source": "arxiv", "section": "computerScience"}, {"title": "An Open-source Sim2Real Approach for Sensor-independent Robot Navigation in a Grid", "link": "https://arxiv.org/abs/2411.03494", "description": "arXiv:2411.03494v1 Announce Type: new \nAbstract: This paper presents a Sim2Real (Simulation to Reality) approach to bridge the gap between a trained agent in a simulated environment and its real-world implementation in navigating a robot in a similar setting. Specifically, we focus on navigating a quadruped robot in a real-world grid-like environment inspired by the Gymnasium Frozen Lake -- a highly user-friendly and free Application Programming Interface (API) to develop and test Reinforcement Learning (RL) algorithms. We detail the development of a pipeline to transfer motion policies learned in the Frozen Lake simulation to a physical quadruped robot, thus enabling autonomous navigation and obstacle avoidance in a grid without relying on expensive localization and mapping sensors. The work involves training an RL agent in the Frozen Lake environment and utilizing the resulting Q-table to control a 12 Degrees-of-Freedom (DOF) quadruped robot. In addition to detailing the RL implementation, inverse kinematics-based quadruped gaits, and the transfer policy pipeline, we open-source the project on GitHub and include a demonstration video of our Sim2Real transfer approach. This work provides an accessible, straightforward, and low-cost framework for researchers, students, and hobbyists to explore and implement RL-based robot navigation in real-world grid environments.", "published": "2024-11-07 05:00:00", "id": "4ad6cd85-fc6d-45b8-b2e6-c51e418e7744", "source": "arxiv", "section": "computerScience"}, {"title": "Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology", "link": "https://arxiv.org/abs/2411.03495", "description": "arXiv:2411.03495v1 Announce Type: new \nAbstract: The automatic generation of hints by Large Language Models (LLMs) within Intelligent Tutoring Systems (ITSs) has shown potential to enhance student learning. However, generating pedagogically sound hints that address student misconceptions and adhere to specific educational objectives remains challenging. This work explores using LLMs (GPT-4o and Llama-3-8B-instruct) as teachers to generate effective hints for students simulated through LLMs (GPT-3.5-turbo, Llama-3-8B-Instruct, or Mistral-7B-instruct-v0.3) tackling math exercises designed for human high-school students, and designed using cognitive science principles. We present here the study of several dimensions: 1) identifying error patterns made by simulated students on secondary-level math exercises; 2) developing various prompts for GPT-4o as a teacher and evaluating their effectiveness in generating hints that enable simulated students to self-correct; and 3) testing the best-performing prompts, based on their ability to produce relevant hints and facilitate error correction, with Llama-3-8B-Instruct as the teacher, allowing for a performance comparison with GPT-4o. The results show that model errors increase with higher temperature settings. Notably, when hints are generated by GPT-4o, the most effective prompts include prompts tailored to specific errors as well as prompts providing general hints based on common mathematical errors. Interestingly, Llama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o. Also the problem-solving and response revision capabilities of the LLMs as students, particularly GPT-3.5-turbo, improved significantly after receiving hints, especially at lower temperature settings. However, models like Mistral-7B-Instruct demonstrated a decline in performance as the temperature increased.", "published": "2024-11-07 05:00:00", "id": "4df90743-4597-4479-a951-0b02b6c81b3a", "source": "arxiv", "section": "computerScience"}, {"title": "Uncertainty Quantification for Clinical Outcome Predictions with (Large) Language Models", "link": "https://arxiv.org/abs/2411.03497", "description": "arXiv:2411.03497v1 Announce Type: new \nAbstract: To facilitate healthcare delivery, language models (LMs) have significant potential for clinical prediction tasks using electronic health records (EHRs). However, in these high-stakes applications, unreliable decisions can result in high costs due to compromised patient safety and ethical concerns, thus increasing the need for good uncertainty modeling of automated clinical predictions. To address this, we consider the uncertainty quantification of LMs for EHR tasks in white- and black-box settings. We first quantify uncertainty in white-box models, where we can access model parameters and output logits. We show that an effective reduction of model uncertainty can be achieved by using the proposed multi-tasking and ensemble methods in EHRs. Continuing with this idea, we extend our approach to black-box settings, including popular proprietary LMs such as GPT-4. We validate our framework using longitudinal clinical data from more than 6,000 patients in ten clinical prediction tasks. Results show that ensembling methods and multi-task prediction prompts reduce uncertainty across different scenarios. These findings increase the transparency of the model in white-box and black-box settings, thus advancing reliable AI healthcare.", "published": "2024-11-07 05:00:00", "id": "6280d655-7961-45fd-ab67-6078a7b35d9c", "source": "arxiv", "section": "computerScience"}, {"title": "{\\lambda}-Tune: Harnessing Large Language Models for Automated Database System Tuning", "link": "https://arxiv.org/abs/2411.03500", "description": "arXiv:2411.03500v1 Announce Type: new \nAbstract: We introduce {\\lambda}-Tune, a framework that leverages Large Language Models (LLMs) for automated database system tuning. The design of {\\lambda}-Tune is motivated by the capabilities of the latest generation of LLMs. Different from prior work, leveraging LLMs to extract tuning hints for single parameters, {\\lambda}-Tune generates entire configuration scripts, based on a large input document, describing the tuning context. {\\lambda}-Tune generates alternative configurations, using a principled approach to identify the best configuration, out of a small set of candidates. In doing so, it minimizes reconfiguration overheads and ensures that evaluation costs are bounded as a function of the optimal run time. By treating prompt generation as a cost-based optimization problem, {\\lambda}-Tune conveys the most relevant context to the LLM while bounding the number of input tokens and, therefore, monetary fees for LLM invocations. We compare {\\lambda}-Tune to various baselines, using multiple benchmarks and PostgreSQL and MySQL as target systems for tuning, showing that {\\lambda}-Tune is significantly more robust than prior approaches.", "published": "2024-11-07 05:00:00", "id": "8c3990da-189d-46dd-9c98-697bc74213d5", "source": "arxiv", "section": "computerScience"}, {"title": "The Python LevelSet Toolbox (LevelSetPy)", "link": "https://arxiv.org/abs/2411.03501", "description": "arXiv:2411.03501v1 Announce Type: new \nAbstract: This paper describes open-source scientific contributions in python surrounding the numerical solutions to hyperbolic Hamilton-Jacobi (HJ) partial differential equations viz., their implicit representation on co-dimension one surfaces; dynamics evolution with levelsets; spatial derivatives; total variation diminishing Runge-Kutta integration schemes; and their applications to the theory of reachable sets. They are increasingly finding applications in multiple research domains such as reinforcement learning, robotics, control engineering and automation. We describe the library components, illustrate usage with an example, and provide comparisons with existing implementations. This GPU-accelerated package allows for easy portability to many modern libraries for the numerical analyses of the HJ equations. We also provide a CPU implementation in python that is significantly faster than existing alternatives.", "published": "2024-11-07 05:00:00", "id": "9f15cf21-333d-44ec-956a-5b0d4529195c", "source": "arxiv", "section": "computerScience"}, {"title": "TwiNet: Connecting Real World Networks to their Digital Twins Through a Live Bidirectional Link", "link": "https://arxiv.org/abs/2411.03503", "description": "arXiv:2411.03503v1 Announce Type: new \nAbstract: Only the chairs can edit The wireless spectrum's increasing complexity poses challenges and opportunities, highlighting the necessity for real-time solutions and robust data processing capabilities. Digital Twin (DT), virtual replicas of physical systems, integrate real-time data to mirror their real-world counterparts, enabling precise monitoring and optimization. Incorporating DTs into wireless communication enhances predictive maintenance, resource allocation, and troubleshooting, thus bolstering network reliability. Our paper introduces TwiNet, enabling bidirectional, near-realtime links between real-world wireless spectrum scenarios and DT replicas. Utilizing the protocol, MQTT, we can achieve data transfer times with an average latency of 14 ms, suitable for real-time communication. This is confirmed by monitoring real-world traffic and mirroring it in real-time within the DT's wireless environment. We evaluate TwiNet's performance in two use cases: (i) assessing risky traffic configurations of UEs in a Safe Adaptive Data Rate (SADR) system, improving network performance by approximately 15% compared to original network selections; and (ii) deploying new CNNs in response to jammed pilots, achieving up to 97% accuracy training on artificial data and deploying a new model in as low as 2 minutes to counter persistent adversaries. TwiNet enables swift deployment and adaptation of DTs, addressing crucial challenges in modern wireless communication systems.", "published": "2024-11-07 05:00:00", "id": "adb9d98f-7206-45b4-9e51-50ed9040b97d", "source": "arxiv", "section": "computerScience"}, {"title": "SynthSet: Generative Diffusion Model for Semantic Segmentation in Precision Agriculture", "link": "https://arxiv.org/abs/2411.03505", "description": "arXiv:2411.03505v1 Announce Type: new \nAbstract: This paper introduces a methodology for generating synthetic annotated data to address data scarcity in semantic segmentation tasks within the precision agriculture domain. Utilizing Denoising Diffusion Probabilistic Models (DDPMs) and Generative Adversarial Networks (GANs), we propose a dual diffusion model architecture for synthesizing realistic annotated agricultural data, without any human intervention. We employ super-resolution to enhance the phenotypic characteristics of the synthesized images and their coherence with the corresponding generated masks. We showcase the utility of the proposed method for wheat head segmentation. The high quality of synthesized data underscores the effectiveness of the proposed methodology in generating image-mask pairs. Furthermore, models trained on our generated data exhibit promising performance when tested on an external, diverse dataset of real wheat fields. The results show the efficacy of the proposed methodology for addressing data scarcity for semantic segmentation tasks. Moreover, the proposed approach can be readily adapted for various segmentation tasks in precision agriculture and beyond.", "published": "2024-11-07 05:00:00", "id": "2afbc5ba-9324-4355-8739-d052014dac2c", "source": "arxiv", "section": "computerScience"}, {"title": "Model-based Deep Learning for QoS-Aware Rate-Splitting Multiple Access Wireless Systems", "link": "https://arxiv.org/abs/2411.03507", "description": "arXiv:2411.03507v1 Announce Type: new \nAbstract: Next generation communications demand for better spectrum management, lower latency, and guaranteed quality-of-service (QoS). Recently, Artificial intelligence (AI) has been widely introduced to advance these aspects in next generation wireless systems. However, such AI applications suffer from limited training data, low robustness, and poor generalization capabilities. To address these issues, a model-driven deep unfolding (DU) algorithm is introduced in this paper to bridge the gap between traditional model-driven communication algorithms and data-driven deep learning. Focusing on the QoS-aware rate-splitting multiple access (RSMA) resource allocation problem in multi-user communications, a conventional fractional programming (FP) algorithm is first applied as a benchmark. The solution is then refined by the application of projection gradient descent (PGD). DU is employed to further speed up convergence procedure, hence improving the efficiency of PGD. Moreover, the feasibility of results is guaranteed by designing a low-complexity projection based on scale factors, plus adding violation control mechanisms into the loss function that minimizes error rates. Finally, we provide a detailed analysis of the computational complexity and analysis design of the proposed DU algorithm. Extensive simulations are conducted and the results demonstrate that the proposed DU algorithm can reach the optimal communication efficiency with a mere $0.024\\%$ violation rate for 4 layers DU. The DU algorithm also exhibits robustness in out-of-distribution tests and can be effectively trained with as few as 50 samples.", "published": "2024-11-07 05:00:00", "id": "a3230649-700d-49b2-9715-95fa670a74ad", "source": "arxiv", "section": "computerScience"}, {"title": "Beyond Complete Shapes: A quantitative Evaluation of 3D Shape Matching Algorithms", "link": "https://arxiv.org/abs/2411.03511", "description": "arXiv:2411.03511v1 Announce Type: new \nAbstract: Finding correspondences between 3D shapes is an important and long-standing problem in computer vision, graphics and beyond. While approaches based on machine learning dominate modern 3D shape matching, almost all existing (learning-based) methods require that at least one of the involved shapes is complete. In contrast, the most challenging and arguably most practically relevant setting of matching partially observed shapes, is currently underexplored. One important factor is that existing datasets contain only a small number of shapes (typically below 100), which are unable to serve data-hungry machine learning approaches, particularly in the unsupervised regime. In addition, the type of partiality present in existing datasets is often artificial and far from realistic. To address these limitations and to encourage research on these relevant settings, we provide a generic and flexible framework for the procedural generation of challenging partial shape matching scenarios. Our framework allows for a virtually infinite generation of partial shape matching instances from a finite set of shapes with complete geometry. Further, we manually create cross-dataset correspondences between seven existing (complete geometry) shape matching datasets, leading to a total of 2543 shapes. Based on this, we propose several challenging partial benchmark settings, for which we evaluate respective state-of-the-art methods as baselines.", "published": "2024-11-07 05:00:00", "id": "d7334347-7efb-40ce-a50e-cb3d7a4dc96b", "source": "arxiv", "section": "computerScience"}, {"title": "Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy", "link": "https://arxiv.org/abs/2411.03513", "description": "arXiv:2411.03513v1 Announce Type: new \nAbstract: This paper introduces a novel model compression approach through dynamic layer-specific pruning in Large Language Models (LLMs), enhancing the traditional methodology established by SliceGPT. By transitioning from constant to dynamic slicing, our method leverages the newly proposed Layer Redundancy (LR) score, which assesses how much change each layer changes its input by measuring the cosine similarity of the input to the output of the layer. We use this score to prune parts of individual layers based on redundancy in such a way that the average pruned percentage for all layers is a fixed value. We conducted extensive experiments using models like Llama3-8B and Mistral-7B on multiple datasets, evaluating different slicing bases and percentages to determine optimal configurations that balance efficiency and performance. Our findings show that our dynamic slicing approach not only maintains but, in many cases, enhances model performance compared to the baseline established by constant slicing methods. For instance, in several settings, we see performance improvements of up to 5% over the SliceGPT baseline. Additionally, a perplexity decrease by as much as 7% was observed across multiple benchmarks, validating the effectiveness of our method. The code, model weights, and datasets are open-sourced at https://github.com/RazvanDu/DynamicSlicing.", "published": "2024-11-07 05:00:00", "id": "c83823ad-41aa-4730-a4e1-3ad3471f6413", "source": "arxiv", "section": "computerScience"}, {"title": "Deriving Analytical Solutions Using Symbolic Matrix Structural Analysis: Part 1 -- Continuous Beams", "link": "https://arxiv.org/abs/2411.03514", "description": "arXiv:2411.03514v1 Announce Type: new \nAbstract: This study investigates the use of symbolic computation in Matrix Structural Analysis (MSA) for continuous beams, leveraging the MATLAB Symbolic Math Toolbox. By employing symbolic MSA, analytical expressions for displacements, support reactions, and internal forces are derived, offering deeper insights into structural behavior. This approach facilitates efficient and scalable sensitivity analysis, where partial derivatives of outputs concerning input parameters can be directly computed, enhancing design exploration. The development includes an open-source MATLAB program, hosted on GitHub, enabling symbolic analysis of continuous beams subjected to point and uniform loads. This approach is invaluable for both engineering practice and pedagogy, enriching the understanding of structural mechanics and aiding in education by illustrating clear parameter relationships. The program supports deriving influence lines and identifying maximum response values.", "published": "2024-11-07 05:00:00", "id": "37bd4f3c-e52a-447f-bd73-125a2a77f70f", "source": "arxiv", "section": "computerScience"}, {"title": "Understanding Contrastive Learning via Gaussian Mixture Models", "link": "https://arxiv.org/abs/2411.03517", "description": "arXiv:2411.03517v1 Announce Type: new \nAbstract: Contrastive learning attempts to learn representations from un-labeled data; it does so via a loss function that encourages the embedding of a point to be close to that of its augmentations, and far from the embeddings of random other points. This simple idea performs remarkably well, yet it is not precisely theoretically understood why this is the case. In this paper we analyze contrastive learning (specifically, the InfoNCE loss) in a natural context: dimensionality reduction in Gaussian Mixture Models. Crucially, we define an augmentation of a data point as being another independent draw from the same underlying mixture component. We show that vanilla InfoNCE is able to find the optimal lower-dimensional subspace even when the Gaussians are not isotropic -- something that vanilla spectral techniques cannot do. We further extend our analyses to multi-modal contrastive learning algorithms (e.g., CLIP). In this setting we show that contrastive learning learns the subset of fisher-optimal subspace, effectively filtering out all the noise from the learnt representations.", "published": "2024-11-07 05:00:00", "id": "9fa4690d-21cc-4221-ac8d-658092508123", "source": "arxiv", "section": "computerScience"}, {"title": "AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Execution", "link": "https://arxiv.org/abs/2411.03519", "description": "arXiv:2411.03519v1 Announce Type: new \nAbstract: With more advanced natural language understanding and reasoning capabilities, large language model (LLM)-powered agents are increasingly developed in simulated environments to perform complex tasks, interact with other agents, and exhibit emergent behaviors relevant to social science and gaming. However, current multi-agent simulations frequently suffer from inefficiencies due to the limited parallelism caused by false dependencies, resulting in performance bottlenecks. In this paper, we introduce AI Metropolis, a simulation engine that improves the efficiency of LLM agent simulations by incorporating out-of-order execution scheduling. By dynamically tracking real dependencies between agents, AI Metropolis minimizes false dependencies, enhancing parallelism and enabling efficient hardware utilization. Our evaluations demonstrate that AI Metropolis achieves speedups from 1.3x to 4.15x over standard parallel simulation with global synchronization, approaching optimal performance as the number of agents increases.", "published": "2024-11-07 05:00:00", "id": "ba34d661-0676-4991-8a75-ffcaeec09508", "source": "arxiv", "section": "computerScience"}, {"title": "Hamiltonian Monte Carlo methods for spectroscopy data analysis", "link": "https://arxiv.org/abs/2411.03523", "description": "arXiv:2411.03523v1 Announce Type: new \nAbstract: We present a scalable Bayesian framework for the analysis of confocal fluorescence spectroscopy data, addressing key limitations in traditional fluorescence correlation spectroscopy methods. Our framework captures molecular motion, microscope optics, and photon detection with high fidelity, enabling statistical inference of molecule trajectories from raw photon count data, introducing a superresolution parameter which further enhances trajectory estimation beyond the native time resolution of data acquisition. To handle the high dimensionality of the arising posterior distribution, we develop a family of Hamiltonian Monte Carlo (HMC) algorithms that leverages the unique characteristics inherent to spectroscopy data analysis. Here, due to the highly-coupled correlation structure of the target posterior distribution, HMC requires the numerical solution of a stiff ordinary differential equation containing a two-scale discrete Laplacian. By considering the spectral properties of this operator, we produce a CFL-type integrator stability condition for the standard St\\\"ormer-Verlet integrator used in HMC. To circumvent this instability we introduce a semi-implicit (IMEX) method which treats the stiff and non-stiff parts differently, while leveraging the sparse structure of the discrete Laplacian for computational efficiency. Detailed numerical experiments demonstrate that this method improves upon fully explicit approaches, allowing larger HMC step sizes and maintaining second-order accuracy in position and energy. Our framework provides a foundation for extensions to more complex models such as surface constrained molecular motion or motion with multiple diffusion modes.", "published": "2024-11-07 05:00:00", "id": "5e81e90f-c866-40d9-b743-25966f62523f", "source": "arxiv", "section": "computerScience"}, {"title": "Mitigating Metric Bias in Minimum Bayes Risk Decoding", "link": "https://arxiv.org/abs/2411.03524", "description": "arXiv:2411.03524v1 Announce Type: new \nAbstract: While Minimum Bayes Risk (MBR) decoding using metrics such as COMET or MetricX has outperformed traditional decoding methods such as greedy or beam search, it introduces a challenge we refer to as metric bias. As MBR decoding aims to produce translations that score highly according to a specific utility metric, this very process makes it impossible to use the same metric for both decoding and evaluation, as improvements might simply be due to reward hacking rather than reflecting real quality improvements. In this work we find that compared to human ratings, neural metrics not only overestimate the quality of MBR decoding when the same metric is used as the utility metric, but they also overestimate the quality of MBR/QE decoding with other neural utility metrics as well. We also show that the metric bias issue can be mitigated by using an ensemble of utility metrics during MBR decoding: human evaluations show that MBR decoding using an ensemble of utility metrics outperforms a single utility metric.", "published": "2024-11-07 05:00:00", "id": "8078d84b-70e6-4bae-a920-f40e3ba36c30", "source": "arxiv", "section": "computerScience"}, {"title": "PACE: Pacing Operator Learning to Accurate Optical Field Simulation for Complicated Photonic Devices", "link": "https://arxiv.org/abs/2411.03527", "description": "arXiv:2411.03527v1 Announce Type: new \nAbstract: Electromagnetic field simulation is central to designing, optimizing, and validating photonic devices and circuits. However, costly computation associated with numerical simulation poses a significant bottleneck, hindering scalability and turnaround time in the photonic circuit design process. Neural operators offer a promising alternative, but existing SOTA approaches, NeurOLight, struggle with predicting high-fidelity fields for real-world complicated photonic devices, with the best reported 0.38 normalized mean absolute error in NeurOLight. The inter-plays of highly complex light-matter interaction, e.g., scattering and resonance, sensitivity to local structure details, non-uniform learning complexity for full-domain simulation, and rich frequency information, contribute to the failure of existing neural PDE solvers. In this work, we boost the prediction fidelity to an unprecedented level for simulating complex photonic devices with a novel operator design driven by the above challenges. We propose a novel cross-axis factorized PACE operator with a strong long-distance modeling capacity to connect the full-domain complex field pattern with local device structures. Inspired by human learning, we further divide and conquer the simulation task for extremely hard cases into two progressively easy tasks, with a first-stage model learning an initial solution refined by a second model. On various complicated photonic device benchmarks, we demonstrate one sole PACE model is capable of achieving 73% lower error with 50% fewer parameters compared with various recent ML for PDE solvers. The two-stage setup further advances high-fidelity simulation for even more intricate cases. In terms of runtime, PACE demonstrates 154-577x and 11.8-12x simulation speedup over numerical solver using scipy or highly-optimized pardiso solver, respectively. We open sourced the code and dataset.", "published": "2024-11-07 05:00:00", "id": "5f30c9ff-43b4-48c4-9ae1-fe6f60729943", "source": "arxiv", "section": "computerScience"}, {"title": "Personalized Video Summarization by Multimodal Video Understanding", "link": "https://arxiv.org/abs/2411.03531", "description": "arXiv:2411.03531v1 Announce Type: new \nAbstract: Video summarization techniques have been proven to improve the overall user experience when it comes to accessing and comprehending video content. If the user's preference is known, video summarization can identify significant information or relevant content from an input video, aiding them in obtaining the necessary information or determining their interest in watching the original video. Adapting video summarization to various types of video and user preferences requires significant training data and expensive human labeling. To facilitate such research, we proposed a new benchmark for video summarization that captures various user preferences. Also, we present a pipeline called Video Summarization with Language (VSL) for user-preferred video summarization that is based on pre-trained visual language models (VLMs) to avoid the need to train a video summarization system on a large training dataset. The pipeline takes both video and closed captioning as input and performs semantic analysis at the scene level by converting video frames into text. Subsequently, the user's genre preference was used as the basis for selecting the pertinent textual scenes. The experimental results demonstrate that our proposed pipeline outperforms current state-of-the-art unsupervised video summarization models. We show that our method is more adaptable across different datasets compared to supervised query-based video summarization models. In the end, the runtime analysis demonstrates that our pipeline is more suitable for practical use when scaling up the number of user preferences and videos.", "published": "2024-11-07 05:00:00", "id": "19df5a2b-639f-43b6-90d8-b6fc42d7e7cd", "source": "arxiv", "section": "computerScience"}, {"title": "A Behavior Architecture for Fast Humanoid Robot Door Traversals", "link": "https://arxiv.org/abs/2411.03532", "description": "arXiv:2411.03532v1 Announce Type: new \nAbstract: Towards the role of humanoid robots as squad mates in urban operations and other domains, we identified doors as a major area lacking capability development. In this paper, we focus on the ability of humanoid robots to navigate and deal with doors. Human-sized doors are ubiquitous in many environment domains and the humanoid form factor is uniquely suited to operate and traverse them. We present an architecture which incorporates GPU accelerated perception and a tree based interactive behavior coordination system with a whole body motion and walking controller. Our system is capable of performing door traversals on a variety of door types. It supports rapid authoring of behaviors for unseen door types and techniques to achieve re-usability of those authored behaviors. The behaviors are modelled using trees and feature logical reactivity and action sequences that can be executed with layered concurrency to increase speed. Primitive actions are built on top of our existing whole body controller which supports manipulation while walking. We include a perception system using both neural networks and classical computer vision for door mechanism detection outside of the lab environment. We present operator-robot interdependence analysis charts to explore how human cognition is combined with artificial intelligence to produce complex robot behavior. Finally, we present and discuss real robot performances of fast door traversals on our Nadia humanoid robot. Videos online at https://www.youtube.com/playlist?list=PLXuyT8w3JVgMPaB5nWNRNHtqzRK8i68dy.", "published": "2024-11-07 05:00:00", "id": "c44e3243-e7e7-461a-8882-790077bd7130", "source": "arxiv", "section": "computerScience"}, {"title": "Shared Memory-Aware Latency-Sensitive Message Aggregation for Fine-Grained Communication", "link": "https://arxiv.org/abs/2411.03533", "description": "arXiv:2411.03533v1 Announce Type: new \nAbstract: Message aggregation is often used with a goal to reduce communication cost in HPC applications. The difference in the order of overhead of sending a message and cost of per byte transferred motivates the need for message aggregation, for several irregular fine-grained messaging applications like graph algorithms and parallel discrete event simulation (PDES). While message aggregation is frequently utilized in \"MPI-everywhere\" model, to coalesce messages between processes mapped to cores, such aggregation across threads in a process, say in MPI+X models or Charm++ SMP (Shared Memory Parallelism) mode, is often avoided. Within-process coalescing is likely to require synchronization across threads and lead to performance issues from contention. However, as a result, SMP-unaware aggregation mechanisms may not fully utilize aggregation opportunities available to applications in SMP mode. Additionally, while the benefit of message aggregation is often analyzed in terms of reducing the overhead, specifically the per message cost, we also analyze different schemes that can aid in reducing the message latency, ie. the time from when a message is sent to the time when it is received. Message latency can affect several applications like PDES with speculative execution where reducing message latency could result in fewer rollbacks. To address these challenges, in our work, we demonstrate the effectiveness of shared memory-aware message aggregation schemes for a range of proxy applications with respect to messaging overhead and latency.", "published": "2024-11-07 05:00:00", "id": "562ce32a-2de4-4092-bd7d-27974e95df74", "source": "arxiv", "section": "computerScience"}, {"title": "Spectral Transformation for the Dense Symmetric Semidefinite Generalized Eigenvalue Problem", "link": "https://arxiv.org/abs/2411.03534", "description": "arXiv:2411.03534v1 Announce Type: new \nAbstract: The spectral transformation Lanczos method for the sparse symmetric definite generalized eigenvalue problem for matrices $A$ and $B$ is an iterative method that addresses the case of semidefinite or ill conditioned $B$ using a shifted and inverted formulation of the problem. This paper proposes the same approach for dense problems and shows that with a shift chosen in accordance with certain constraints, the algorithm can conditionally ensure that every computed shifted and inverted eigenvalue is close to the exact shifted and inverted eigenvalue of a pair of matrices close to $A$ and $B$. Under the same assumptions on the shift, the analysis of the algorithm for the shifted and inverted problem leads to useful error bounds for the original problem, including a bound that shows how a single shift that is of moderate size in a scaled sense can be chosen so that every computed generalized eigenvalue corresponds to a generalized eigenvalue of a pair of matrices close to $A$ and $B$. The computed generalized eigenvectors give a relative residual that depends on the distance between the corresponding generalized eigenvalue and the shift. If the shift is of moderate size, then relative residuals are small for generalized eigenvalues that are not much larger than the shift. Larger shifts give small relative residuals for generalized eigenvalues that are not much larger or smaller than the shift.", "published": "2024-11-07 05:00:00", "id": "76553e8a-e9bc-47fa-8bb9-c62b3868e0e0", "source": "arxiv", "section": "computerScience"}, {"title": "Two-Stage Pretraining for Molecular Property Prediction in the Wild", "link": "https://arxiv.org/abs/2411.03537", "description": "arXiv:2411.03537v1 Announce Type: new \nAbstract: Accurate property prediction is crucial for accelerating the discovery of new molecules. Although deep learning models have achieved remarkable success, their performance often relies on large amounts of labeled data that are expensive and time-consuming to obtain. Thus, there is a growing need for models that can perform well with limited experimentally-validated data. In this work, we introduce MoleVers, a versatile pretrained model designed for various types of molecular property prediction in the wild, i.e., where experimentally-validated molecular property labels are scarce. MoleVers adopts a two-stage pretraining strategy. In the first stage, the model learns molecular representations from large unlabeled datasets via masked atom prediction and dynamic denoising, a novel task enabled by a new branching encoder architecture. In the second stage, MoleVers is further pretrained using auxiliary labels obtained with inexpensive computational methods, enabling supervised learning without the need for costly experimental data. This two-stage framework allows MoleVers to learn representations that generalize effectively across various downstream datasets. We evaluate MoleVers on a new benchmark comprising 22 molecular datasets with diverse types of properties, the majority of which contain 50 or fewer training labels reflecting real-world conditions. MoleVers achieves state-of-the-art results on 20 out of the 22 datasets, and ranks second among the remaining two, highlighting its ability to bridge the gap between data-hungry models and real-world conditions where practically-useful labels are scarce.", "published": "2024-11-07 05:00:00", "id": "2aa27d7b-4d9f-47f9-b358-48cba8f96737", "source": "arxiv", "section": "computerScience"}, {"title": "Long Context RAG Performance of Large Language Models", "link": "https://arxiv.org/abs/2411.03538", "description": "arXiv:2411.03538v1 Announce Type: new \nAbstract: Retrieval Augmented Generation (RAG) has emerged as a crucial technique for enhancing the accuracy of Large Language Models (LLMs) by incorporating external information. With the advent of LLMs that support increasingly longer context lengths, there is a growing interest in understanding how these models perform in RAG scenarios. Can these new long context models improve RAG performance? This paper presents a comprehensive study of the impact of increased context length on RAG performance across 20 popular open source and commercial LLMs. We ran RAG workflows while varying the total context length from 2,000 to 128,000 tokens (and 2 million tokens when possible) on three domain-specific datasets, and report key insights on the benefits and limitations of long context in RAG applications. Our findings reveal that while retrieving more documents can improve performance, only a handful of the most recent state of the art LLMs can maintain consistent accuracy at long context above 64k tokens. We also identify distinct failure modes in long context scenarios, suggesting areas for future research.", "published": "2024-11-07 05:00:00", "id": "b6a72423-a3a2-401c-9650-bd75034d4cbd", "source": "arxiv", "section": "computerScience"}, {"title": "VLA-3D: A Dataset for 3D Semantic Scene Understanding and Navigation", "link": "https://arxiv.org/abs/2411.03540", "description": "arXiv:2411.03540v1 Announce Type: new \nAbstract: With the recent rise of Large Language Models (LLMs), Vision-Language Models (VLMs), and other general foundation models, there is growing potential for multimodal, multi-task embodied agents that can operate in diverse environments given only natural language as input. One such application area is indoor navigation using natural language instructions. However, despite recent progress, this problem remains challenging due to the spatial reasoning and semantic understanding required, particularly in arbitrary scenes that may contain many objects belonging to fine-grained classes. To address this challenge, we curate the largest real-world dataset for Vision and Language-guided Action in 3D Scenes (VLA-3D), consisting of over 11.5K scanned 3D indoor rooms from existing datasets, 23.5M heuristically generated semantic relations between objects, and 9.7M synthetically generated referential statements. Our dataset consists of processed 3D point clouds, semantic object and room annotations, scene graphs, navigable free space annotations, and referential language statements that specifically focus on view-independent spatial relations for disambiguating objects. The goal of these features is to aid the downstream task of navigation, especially on real-world systems where some level of robustness must be guaranteed in an open world of changing scenes and imperfect language. We benchmark our dataset with current state-of-the-art models to obtain a performance baseline. All code to generate and visualize the dataset is publicly released, see https://github.com/HaochenZ11/VLA-3D. With the release of this dataset, we hope to provide a resource for progress in semantic 3D scene understanding that is robust to changes and one which will aid the development of interactive indoor navigation systems.", "published": "2024-11-07 05:00:00", "id": "4066b770-fffa-4534-bdf2-46805a17eb78", "source": "arxiv", "section": "computerScience"}, {"title": "Do Mice Grok? Glimpses of Hidden Progress During Overtraining in Sensory Cortex", "link": "https://arxiv.org/abs/2411.03541", "description": "arXiv:2411.03541v1 Announce Type: new \nAbstract: Does learning of task-relevant representations stop when behavior stops changing? Motivated by recent theoretical advances in machine learning and the intuitive observation that human experts continue to learn from practice even after mastery, we hypothesize that task-specific representation learning can continue, even when behavior plateaus. In a novel reanalysis of recently published neural data, we find evidence for such learning in posterior piriform cortex of mice following continued training on a task, long after behavior saturates at near-ceiling performance (\"overtraining\"). This learning is marked by an increase in decoding accuracy from piriform neural populations and improved performance on held-out generalization tests. We demonstrate that class representations in cortex continue to separate during overtraining, so that examples that were incorrectly classified at the beginning of overtraining can abruptly be correctly classified later on, despite no changes in behavior during that time. We hypothesize this hidden yet rich learning takes the form of approximate margin maximization; we validate this and other predictions in the neural data, as well as build and interpret a simple synthetic model that recapitulates these phenomena. We conclude by showing how this model of late-time feature learning implies an explanation for the empirical puzzle of overtraining reversal in animal learning, where task-specific representations are more robust to particular task changes because the learned features can be reused.", "published": "2024-11-07 05:00:00", "id": "183cadae-eca4-485a-82ab-82b967b81455", "source": "arxiv", "section": "computerScience"}, {"title": "Exploring the Benefits of Domain-Pretraining of Generative Large Language Models for Chemistry", "link": "https://arxiv.org/abs/2411.03542", "description": "arXiv:2411.03542v1 Announce Type: new \nAbstract: A proliferation of Large Language Models (the GPT series, BLOOM, LLaMA, and more) are driving forward novel development of multipurpose AI for a variety of tasks, particularly natural language processing (NLP) tasks. These models demonstrate strong performance on a range of tasks; however, there has been evidence of brittleness when applied to more niche or narrow domains where hallucinations or fluent but incorrect responses reduce performance. Given the complex nature of scientific domains, it is prudent to investigate the trade-offs of leveraging off-the-shelf versus more targeted foundation models for scientific domains. In this work, we examine the benefits of in-domain pre-training for a given scientific domain, chemistry, and compare these to open-source, off-the-shelf models with zero-shot and few-shot prompting. Our results show that not only do in-domain base models perform reasonably well on in-domain tasks in a zero-shot setting but that further adaptation using instruction fine-tuning yields impressive performance on chemistry-specific tasks such as named entity recognition and molecular formula generation.", "published": "2024-11-07 05:00:00", "id": "e0219eb3-95f0-48b8-9b06-3c968c7bdd4d", "source": "arxiv", "section": "computerScience"}, {"title": "Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays", "link": "https://arxiv.org/abs/2411.03550", "description": "arXiv:2411.03550v1 Announce Type: new \nAbstract: People tend to distribute information evenly in language production for better and clearer communication. In this study, we compared essays written by second language learners with various native language (L1) backgrounds to investigate how they distribute information in their non-native language (L2) production. Analyses of surprisal and constancy of entropy rate indicated that writers with higher L2 proficiency can reduce the expected uncertainty of language production while still conveying informative content. However, the uniformity of information distribution showed less variability among different groups of L2 speakers, suggesting that this feature may be universal in L2 essay writing and less affected by L2 writers' variability in L1 background and L2 proficiency.", "published": "2024-11-07 05:00:00", "id": "8fbacf61-80ad-4494-9340-4cb3b58c0f69", "source": "arxiv", "section": "computerScience"}, {"title": "Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset", "link": "https://arxiv.org/abs/2411.03554", "description": "arXiv:2411.03554v1 Announce Type: new \nAbstract: Machine unlearning has emerged as an effective strategy for forgetting specific information in the training data. However, with the increasing integration of visual data, privacy concerns in Vision Language Models (VLMs) remain underexplored. To address this, we introduce Facial Identity Unlearning Benchmark (FIUBench), a novel VLM unlearning benchmark designed to robustly evaluate the effectiveness of unlearning algorithms under the Right to be Forgotten setting. Specifically, we formulate the VLM unlearning task via constructing the Fictitious Facial Identity VQA dataset and apply a two-stage evaluation pipeline that is designed to precisely control the sources of information and their exposure levels. In terms of evaluation, since VLM supports various forms of ways to ask questions with the same semantic meaning, we also provide robust evaluation metrics including membership inference attacks and carefully designed adversarial privacy attacks to evaluate the performance of algorithms. Through the evaluation of four baseline VLM unlearning algorithms within FIUBench, we find that all methods remain limited in their unlearning performance, with significant trade-offs between model utility and forget quality. Furthermore, our findings also highlight the importance of privacy attacks for robust evaluations. We hope FIUBench will drive progress in developing more effective VLM unlearning algorithms.", "published": "2024-11-07 05:00:00", "id": "b5030380-ab6a-4946-b1cb-b2ba3db0fe56", "source": "arxiv", "section": "computerScience"}, {"title": "Object and Contact Point Tracking in Demonstrations Using 3D Gaussian Splatting", "link": "https://arxiv.org/abs/2411.03555", "description": "arXiv:2411.03555v1 Announce Type: new \nAbstract: This paper introduces a method to enhance Interactive Imitation Learning (IIL) by extracting touch interaction points and tracking object movement from video demonstrations. The approach extends current IIL systems by providing robots with detailed knowledge of both where and how to interact with objects, particularly complex articulated ones like doors and drawers. By leveraging cutting-edge techniques such as 3D Gaussian Splatting and FoundationPose for tracking, this method allows robots to better understand and manipulate objects in dynamic environments. The research lays the foundation for more effective task learning and execution in autonomous robotic systems.", "published": "2024-11-07 05:00:00", "id": "30ace228-2f56-422e-a943-c7f11ce99c09", "source": "arxiv", "section": "computerScience"}, {"title": "VQ-ACE: Efficient Policy Search for Dexterous Robotic Manipulation via Action Chunking Embedding", "link": "https://arxiv.org/abs/2411.03556", "description": "arXiv:2411.03556v1 Announce Type: new \nAbstract: Dexterous robotic manipulation remains a significant challenge due to the high dimensionality and complexity of hand movements required for tasks like in-hand manipulation and object grasping. This paper addresses this issue by introducing Vector Quantized Action Chunking Embedding (VQ-ACE), a novel framework that compresses human hand motion into a quantized latent space, significantly reducing the action space's dimensionality while preserving key motion characteristics. By integrating VQ-ACE with both Model Predictive Control (MPC) and Reinforcement Learning (RL), we enable more efficient exploration and policy learning in dexterous manipulation tasks using a biomimetic robotic hand. Our results show that latent space sampling with MPC produces more human-like behavior in tasks such as Ball Rolling and Object Picking, leading to higher task success rates and reduced control costs. For RL, action chunking accelerates learning and improves exploration, demonstrated through faster convergence in tasks like cube stacking and in-hand cube reorientation. These findings suggest that VQ-ACE offers a scalable and effective solution for robotic manipulation tasks involving complex, high-dimensional state spaces, contributing to more natural and adaptable robotic systems.", "published": "2024-11-07 05:00:00", "id": "fc5c14c4-c333-4b01-b694-571f24966bd5", "source": "arxiv", "section": "computerScience"}, {"title": "Shem: A Hardware-Aware Optimization Framework for Analog Computing Systems", "link": "https://arxiv.org/abs/2411.03557", "description": "arXiv:2411.03557v1 Announce Type: new \nAbstract: As the demand for efficient data processing escalates, reconfigurable analog hardware which implements novel analog compute paradigms, is promising for energy-efficient computing at the sensing and actuation boundaries. These analog computing platforms embed information in physical properties and then use the physics of materials, devices, and circuits to perform computation. These hardware platforms are more sensitive to nonidealities, such as noise and fabrication variations, than their digital counterparts and accrue high resource costs when programmable elements are introduced. Identifying resource-efficient analog system designs that mitigate these nonidealities is done manually today.\n  While design optimization frameworks have been enormously successful in other fields, such as photonics, they typically either target linear dynamical systems that have closed-form solutions or target a specific differential equation system and then derive the solution through hand analysis. In both cases, time-domain simulation is no longer needed to predict hardware behavior. In contrast, described analog hardware platforms have nonlinear time-evolving dynamics that vary substantially from design to design, lack closed-form solutions, and require the optimizer to consider time explicitly. We present Shem, an optimization framework for analog systems. Shem leverages differentiation methods recently popularized to train neural ODEs to enable the optimization of analog systems that exhibit nonlinear dynamics, noise and mismatch, and discrete behavior. We evaluate Shem on oscillator-based pattern recognizer, CNN edge detector, and transmission-line security primitive design case studies and demonstrate it can improve designs. To our knowledge, the latter two design problems have not been optimized with automated methods before.", "published": "2024-11-07 05:00:00", "id": "814292f9-d3d3-4ae2-a70d-ba28f574cdd0", "source": "arxiv", "section": "computerScience"}, {"title": "Estimating Ego-Body Pose from Doubly Sparse Egocentric Video Data", "link": "https://arxiv.org/abs/2411.03561", "description": "arXiv:2411.03561v1 Announce Type: new \nAbstract: We study the problem of estimating the body movements of a camera wearer from egocentric videos. Current methods for ego-body pose estimation rely on temporally dense sensor data, such as IMU measurements from spatially sparse body parts like the head and hands. However, we propose that even temporally sparse observations, such as hand poses captured intermittently from egocentric videos during natural or periodic hand movements, can effectively constrain overall body motion. Naively applying diffusion models to generate full-body pose from head pose and sparse hand pose leads to suboptimal results. To overcome this, we develop a two-stage approach that decomposes the problem into temporal completion and spatial completion. First, our method employs masked autoencoders to impute hand trajectories by leveraging the spatiotemporal correlations between the head pose sequence and intermittent hand poses, providing uncertainty estimates. Subsequently, we employ conditional diffusion models to generate plausible full-body motions based on these temporally dense trajectories of the head and hands, guided by the uncertainty estimates from the imputation. The effectiveness of our method was rigorously tested and validated through comprehensive experiments conducted on various HMD setup with AMASS and Ego-Exo4D datasets.", "published": "2024-11-07 05:00:00", "id": "e35516b8-e857-428d-97d0-131088e4627a", "source": "arxiv", "section": "computerScience"}, {"title": "Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level", "link": "https://arxiv.org/abs/2411.03562", "description": "arXiv:2411.03562v1 Announce Type: new \nAbstract: We introduce Agent K v1.0, an end-to-end autonomous data science agent designed to automate, optimise, and generalise across diverse data science tasks. Fully automated, Agent K v1.0 manages the entire data science life cycle by learning from experience. It leverages a highly flexible structured reasoning framework to enable it to dynamically process memory in a nested structure, effectively learning from accumulated experience stored to handle complex reasoning tasks. It optimises long- and short-term memory by selectively storing and retrieving key information, guiding future decisions based on environmental rewards. This iterative approach allows it to refine decisions without fine-tuning or backpropagation, achieving continuous improvement through experiential learning. We evaluate our agent's apabilities using Kaggle competitions as a case study. Following a fully automated protocol, Agent K v1.0 systematically addresses complex and multimodal data science tasks, employing Bayesian optimisation for hyperparameter tuning and feature engineering. Our new evaluation framework rigorously assesses Agent K v1.0's end-to-end capabilities to generate and send submissions starting from a Kaggle competition URL. Results demonstrate that Agent K v1.0 achieves a 92.5\\% success rate across tasks, spanning tabular, computer vision, NLP, and multimodal domains. When benchmarking against 5,856 human Kaggle competitors by calculating Elo-MMR scores for each, Agent K v1.0 ranks in the top 38\\%, demonstrating an overall skill level comparable to Expert-level users. Notably, its Elo-MMR score falls between the first and third quartiles of scores achieved by human Grandmasters. Furthermore, our results indicate that Agent K v1.0 has reached a performance level equivalent to Kaggle Grandmaster, with a record of 6 gold, 3 silver, and 7 bronze medals, as defined by Kaggle's progression system.", "published": "2024-11-07 05:00:00", "id": "61dc03e8-a12a-429c-b366-843c7df7b761", "source": "arxiv", "section": "computerScience"}, {"title": "The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge", "link": "https://arxiv.org/abs/2411.03568", "description": "arXiv:2411.03568v1 Announce Type: new \nAbstract: Language models for American Sign Language (ASL) could make language technologies substantially more accessible to those who sign. To train models on tasks such as isolated sign recognition (ISR) and ASL-to-English translation, datasets provide annotated video examples of ASL signs. To facilitate the generalizability and explainability of these models, we introduce the American Sign Language Knowledge Graph (ASLKG), compiled from twelve sources of expert linguistic knowledge. We use the ASLKG to train neuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of 91% on ISR, 14% for predicting the semantic features of unseen signs, and 36% for classifying the topic of Youtube-ASL videos.", "published": "2024-11-07 05:00:00", "id": "34cd5238-6411-40d2-bd78-633bf398d10e", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Personalized Federated Learning via Comprehensive Knowledge Distillation", "link": "https://arxiv.org/abs/2411.03569", "description": "arXiv:2411.03569v1 Announce Type: new \nAbstract: Federated learning is a distributed machine learning paradigm designed to protect data privacy. However, data heterogeneity across various clients results in catastrophic forgetting, where the model rapidly forgets previous knowledge while acquiring new knowledge. To address this challenge, personalized federated learning has emerged to customize a personalized model for each client. However, the inherent limitation of this mechanism is its excessive focus on personalization, potentially hindering the generalization of those models. In this paper, we present a novel personalized federated learning method that uses global and historical models as teachers and the local model as the student to facilitate comprehensive knowledge distillation. The historical model represents the local model from the last round of client training, containing historical personalized knowledge, while the global model represents the aggregated model from the last round of server aggregation, containing global generalized knowledge. By applying knowledge distillation, we effectively transfer global generalized knowledge and historical personalized knowledge to the local model, thus mitigating catastrophic forgetting and enhancing the general performance of personalized models. Extensive experimental results demonstrate the significant advantages of our method.", "published": "2024-11-07 05:00:00", "id": "802d7b2d-139f-4522-9e91-4f3b5d6df97d", "source": "arxiv", "section": "computerScience"}, {"title": "Learning Constant-Depth Circuits in Malicious Noise Models", "link": "https://arxiv.org/abs/2411.03570", "description": "arXiv:2411.03570v1 Announce Type: new \nAbstract: The seminal work of Linial, Mansour, and Nisan gave a quasipolynomial-time algorithm for learning constant-depth circuits ($\\mathsf{AC}^0$) with respect to the uniform distribution on the hypercube. Extending their algorithm to the setting of malicious noise, where both covariates and labels can be adversarially corrupted, has remained open. Here we achieve such a result, inspired by recent work on learning with distribution shift. Our running time essentially matches their algorithm, which is known to be optimal assuming various cryptographic primitives.\n  Our proof uses a simple outlier-removal method combined with Braverman's theorem for fooling constant-depth circuits. We attain the best possible dependence on the noise rate and succeed in the harshest possible noise model (i.e., contamination or so-called \"nasty noise\").", "published": "2024-11-07 05:00:00", "id": "0c66dd3c-f44b-454e-91b8-f3a7934e331f", "source": "arxiv", "section": "computerScience"}, {"title": "Advanced RAG Models with Graph Structures: Optimizing Complex Knowledge Reasoning and Text Generation", "link": "https://arxiv.org/abs/2411.03572", "description": "arXiv:2411.03572v1 Announce Type: new \nAbstract: This study aims to optimize the existing retrieval-augmented generation model (RAG) by introducing a graph structure to improve the performance of the model in dealing with complex knowledge reasoning tasks. The traditional RAG model has the problem of insufficient processing efficiency when facing complex graph structure information (such as knowledge graphs, hierarchical relationships, etc.), which affects the quality and consistency of the generated results. This study proposes a scheme to process graph structure data by combining graph neural network (GNN), so that the model can capture the complex relationship between entities, thereby improving the knowledge consistency and reasoning ability of the generated text. The experiment used the Natural Questions (NQ) dataset and compared it with multiple existing generation models. The results show that the graph-based RAG model proposed in this paper is superior to the traditional generation model in terms of quality, knowledge consistency, and reasoning ability, especially when dealing with tasks that require multi-dimensional reasoning. Through the combination of the enhancement of the retrieval module and the graph neural network, the model in this study can better handle complex knowledge background information and has broad potential value in multiple practical application scenarios.", "published": "2024-11-07 05:00:00", "id": "8286b3e3-4edf-4459-a75d-42a56e02850d", "source": "arxiv", "section": "computerScience"}, {"title": "Semantic Navigation for AI-assisted Ideation", "link": "https://arxiv.org/abs/2411.03575", "description": "arXiv:2411.03575v1 Announce Type: new \nAbstract: We present a novel AI-based ideation assistant and evaluate it in a user study with a group of innovators. The key contribution of our work is twofold: we propose a method of idea exploration in a constrained domain by means of LLM-supported semantic navigation of problem and solution spaces, and employ novel automated data input filtering to improve generations. We found that semantic exploration is preferred to the traditional prompt-output interactions, measured both in explicit survey rankings, and in terms of innovation assistant engagement, where 2.1x more generations were performed using semantic exploration. We also show that filtering input data with metrics such as relevancy, coherence and human alignment leads to improved generations in the same metrics as well as enhanced quality of experience among innovators.", "published": "2024-11-07 05:00:00", "id": "11d347c0-31fb-4970-b170-5743e99af081", "source": "arxiv", "section": "computerScience"}, {"title": "Hybrid Attention for Robust RGB-T Pedestrian Detection in Real-World Conditions", "link": "https://arxiv.org/abs/2411.03576", "description": "arXiv:2411.03576v1 Announce Type: new \nAbstract: Multispectral pedestrian detection has gained significant attention in recent years, particularly in autonomous driving applications. To address the challenges posed by adversarial illumination conditions, the combination of thermal and visible images has demonstrated its advantages. However, existing fusion methods rely on the critical assumption that the RGB-Thermal (RGB-T) image pairs are fully overlapping. These assumptions often do not hold in real-world applications, where only partial overlap between images can occur due to sensors configuration. Moreover, sensor failure can cause loss of information in one modality. In this paper, we propose a novel module called the Hybrid Attention (HA) mechanism as our main contribution to mitigate performance degradation caused by partial overlap and sensor failure, i.e. when at least part of the scene is acquired by only one sensor. We propose an improved RGB-T fusion algorithm, robust against partial overlap and sensor failure encountered during inference in real-world applications. We also leverage a mobile-friendly backbone to cope with resource constraints in embedded systems. We conducted experiments by simulating various partial overlap and sensor failure scenarios to evaluate the performance of our proposed method. The results demonstrate that our approach outperforms state-of-the-art methods, showcasing its superiority in handling real-world challenges.", "published": "2024-11-07 05:00:00", "id": "1e1b697b-c9c2-4ce0-a83a-dbcfcff53441", "source": "arxiv", "section": "computerScience"}, {"title": "Can Robotic Cues Manipulate Human Decisions? Exploring Consensus Building via Bias-Controlled Non-linear Opinion Dynamics and Robotic Eye Gaze Mediated Interaction in Human-Robot Teaming", "link": "https://arxiv.org/abs/2411.03581", "description": "arXiv:2411.03581v1 Announce Type: new \nAbstract: Although robots are becoming more advanced with human-like anthropomorphic features and decision-making abilities to improve collaboration, the active integration of humans into this process remains under-explored. This article presents the first experimental study exploring decision-making interactions between humans and robots with visual cues from robotic eyes, which can dynamically influence human opinion formation. The cues generated by robotic eyes gradually guide human decisions towards alignment with the robot's choices. Both human and robot decision-making processes are modeled as non-linear opinion dynamics with evolving biases. To examine these opinion dynamics under varying biases, we conduct numerical parametric and equilibrium continuation analyses using tuned parameters designed explicitly for the presented human-robot interaction experiment. Furthermore, to facilitate the transition from disagreement to agreement, we introduced a human opinion observation algorithm integrated with the formation of the robot's opinion, where the robot's behavior is controlled based on its formed opinion. The algorithms developed aim to enhance human involvement in consensus building, fostering effective collaboration between humans and robots. Experiments with 51 participants (N = 51) show that human-robot teamwork can be improved by guiding human decisions using robotic cues. Finally, we provide detailed insights on the effects of trust, cognitive load, and participant demographics on decision-making based on user feedback and post-experiment interviews.", "published": "2024-11-07 05:00:00", "id": "a1e89187-4182-443b-bb4f-ecad161a4258", "source": "arxiv", "section": "computerScience"}, {"title": "Privacy Preserving Mechanisms for Coordinating Airspace Usage in Advanced Air Mobility", "link": "https://arxiv.org/abs/2411.03582", "description": "arXiv:2411.03582v1 Announce Type: new \nAbstract: Advanced Air Mobility (AAM) operations are expected to transform air transportation while challenging current air traffic management practices. By introducing a novel market-based mechanism, we address the problem of on-demand allocation of capacity-constrained airspace to AAM vehicles with heterogeneous and private valuations. We model airspace and air infrastructure as a collection of contiguous regions with constraints on the number of vehicles that simultaneously enter, stay, or exit each region. Vehicles request access to the airspace with trajectories spanning multiple regions at different times. We use the graph structure of our airspace model to formulate the allocation problem as a path allocation problem on a time-extended graph. To ensure the cost information of AAM vehicles remains private, we introduce a novel mechanism that allocates each vehicle a budget of \"air-credits\" and anonymously charges prices for traversing the edges of the time-extended graph. We seek to compute a competitive equilibrium that ensures that: (i) capacity constraints are satisfied, (ii) a strictly positive resource price implies that the sector capacity is fully utilized, and (iii) the allocation is integral and optimal for each AAM vehicle given current prices, without requiring access to individual vehicle utilities. However, a competitive equilibrium with integral allocations may not always exist. We provide sufficient conditions for the existence and computation of a fractional-competitive equilibrium, where allocations can be fractional. Building on these theoretical insights, we propose a distributed, iterative, two-step algorithm that: 1) computes a fractional competitive equilibrium, and 2) derives an integral allocation from this equilibrium. We validate the effectiveness of our approach in allocating trajectories for two emerging urban air mobility services: drone delivery and air taxis.", "published": "2024-11-07 05:00:00", "id": "d55580e2-7b58-4e07-a349-5a0104d584d7", "source": "arxiv", "section": "computerScience"}, {"title": "Beyond Regularity: Simple versus Optimal Mechanisms, Revisited", "link": "https://arxiv.org/abs/2411.03583", "description": "arXiv:2411.03583v1 Announce Type: new \nAbstract: A large proportion of the Bayesian mechanism design literature is restricted to the family of regular distributions $\\mathbb{F}_{\\tt reg}$ [Mye81] or the family of monotone hazard rate (MHR) distributions $\\mathbb{F}_{\\tt MHR}$ [BMP63], which overshadows this beautiful and well-developed theory. We (re-)introduce two generalizations, the family of quasi-regular distributions $\\mathbb{F}_{\\tt Q-reg}$ and the family of quasi-MHR distributions $\\mathbb{F}_{\\tt Q-MHR}$. All four families together form the following hierarchy: $\\mathbb{F}_{\\tt MHR} \\subsetneq (\\mathbb{F}_{\\tt reg} \\cap \\mathbb{F}_{\\tt Q-MHR}) \\subsetneq \\mathbb{F}_{\\tt Q-reg}$ and $\\mathbb{F}_{\\tt Q-MHR} \\subsetneq (\\mathbb{F}_{\\tt reg} \\cup \\mathbb{F}_{\\tt Q-MHR}) \\subsetneq \\mathbb{F}_{\\tt Q-reg}$.\n  The significance of our new families is manifold. First, their defining conditions are immediate relaxations of the regularity/MHR conditions (i.e., monotonicity of the virtual value functions and/or the hazard rate functions), which reflect economic intuition. Second, they satisfy natural mathematical properties (about order statistics) that are violated by both original families $\\mathbb{F}_{\\tt reg}$ and $\\mathbb{F}_{\\tt MHR}$. Third but foremost, numerous results [BK96, HR09a, CD15, DRY15, HR14, AHN+19, JLTX20, JLQ+19b, FLR19, GHZ19b, JLX23, LM24] established before for regular/MHR distributions now can be generalized, with or even without quantitative losses.", "published": "2024-11-07 05:00:00", "id": "7ead7295-55dc-4fb2-8edf-29a92e4c6883", "source": "arxiv", "section": "computerScience"}, {"title": "Potential Use of IoT Distance Measurement Tool in Boule Sports", "link": "https://arxiv.org/abs/2411.03585", "description": "arXiv:2411.03585v1 Announce Type: new \nAbstract: In Petanque, each player aims to throw the boule closer to the jack. The closest boule to the jack among players will score the point. Currently, the distance of the boule to the jack is still measured using manual measurement tools such as measuring tape, string, and calipers. The manual measurement method is considered time-consuming and prone to inconsistent reading, which the ordinary referees and players conduct. A steady hand is required to hold the tape at two ends while squatting or kneeling. The technique of reading the measurement is also important to determine the accuracy of the length. This project aims to design and develop a prototype device that can measure the distance between jack and boule using a microcontroller and ultrasonic sensor technology. The device is expected to provide an instant measurement of the distance between the jack and the boule. The measurement data can be displayed on the mobile device to ease the user to view the result. This prototype device also counts the score points and determines the winner.", "published": "2024-11-07 05:00:00", "id": "5851b468-86c7-458c-9236-a732e237ffb9", "source": "arxiv", "section": "computerScience"}, {"title": "An Experimental Study on Decomposition-Based Deep Ensemble Learning for Traffic Flow Forecasting", "link": "https://arxiv.org/abs/2411.03588", "description": "arXiv:2411.03588v1 Announce Type: new \nAbstract: Traffic flow forecasting is a crucial task in intelligent transport systems. Deep learning offers an effective solution, capturing complex patterns in time-series traffic flow data to enable the accurate prediction. However, deep learning models are prone to overfitting the intricate details of flow data, leading to poor generalisation. Recent studies suggest that decomposition-based deep ensemble learning methods may address this issue by breaking down a time series into multiple simpler signals, upon which deep learning models are built and ensembled to generate the final prediction. However, few studies have compared the performance of decomposition-based ensemble methods with non-decomposition-based ones which directly utilise raw time-series data. This work compares several decomposition-based and non-decomposition-based deep ensemble learning methods. Experimental results on three traffic datasets demonstrate the superiority of decomposition-based ensemble methods, while also revealing their sensitivity to aggregation strategies and forecasting horizons.", "published": "2024-11-07 05:00:00", "id": "00caac2b-b875-4537-901a-9a7107e49408", "source": "arxiv", "section": "computerScience"}, {"title": "From Medprompt to o1: Exploration of Run-Time Strategies for Medical Challenge Problems and Beyond", "link": "https://arxiv.org/abs/2411.03590", "description": "arXiv:2411.03590v1 Announce Type: new \nAbstract: Run-time steering strategies like Medprompt are valuable for guiding large language models (LLMs) to top performance on challenging tasks. Medprompt demonstrates that a general LLM can be focused to deliver state-of-the-art performance on specialized domains like medicine by using a prompt to elicit a run-time strategy involving chain of thought reasoning and ensembling. OpenAI's o1-preview model represents a new paradigm, where a model is designed to do run-time reasoning before generating final responses. We seek to understand the behavior of o1-preview on a diverse set of medical challenge problem benchmarks. Following on the Medprompt study with GPT-4, we systematically evaluate the o1-preview model across various medical benchmarks. Notably, even without prompting techniques, o1-preview largely outperforms the GPT-4 series with Medprompt. We further systematically study the efficacy of classic prompt engineering strategies, as represented by Medprompt, within the new paradigm of reasoning models. We found that few-shot prompting hinders o1's performance, suggesting that in-context learning may no longer be an effective steering approach for reasoning-native models. While ensembling remains viable, it is resource-intensive and requires careful cost-performance optimization. Our cost and accuracy analysis across run-time strategies reveals a Pareto frontier, with GPT-4o representing a more affordable option and o1-preview achieving state-of-the-art performance at higher cost. Although o1-preview offers top performance, GPT-4o with steering strategies like Medprompt retains value in specific contexts. Moreover, we note that the o1-preview model has reached near-saturation on many existing medical benchmarks, underscoring the need for new, challenging benchmarks. We close with reflections on general directions for inference-time computation with LLMs.", "published": "2024-11-07 05:00:00", "id": "64d60c02-17a4-4532-8f72-d35fe305c546", "source": "arxiv", "section": "computerScience"}, {"title": "vMF-Contact: Uncertainty-aware Evidential Learning for Probabilistic Contact-grasp in Noisy Clutter", "link": "https://arxiv.org/abs/2411.03591", "description": "arXiv:2411.03591v1 Announce Type: new \nAbstract: Grasp learning in noisy environments, such as occlusions, sensor noise, and out-of-distribution (OOD) objects, poses significant challenges. Recent learning-based approaches focus primarily on capturing aleatoric uncertainty from inherent data noise. The epistemic uncertainty, which represents the OOD recognition, is often addressed by ensembles with multiple forward paths, limiting real-time application. In this paper, we propose an uncertainty-aware approach for 6-DoF grasp detection using evidential learning to comprehensively capture both uncertainties in real-world robotic grasping. As a key contribution, we introduce vMF-Contact, a novel architecture for learning hierarchical contact grasp representations with probabilistic modeling of directional uncertainty as von Mises-Fisher (vMF) distribution. To achieve this, we derive and analyze the theoretical formulation of the second-order objective on the posterior parametrization, providing formal guarantees for the model's ability to quantify uncertainty and improve grasp prediction performance. Moreover, we enhance feature expressiveness by applying partial point reconstructions as an auxiliary task, improving the comprehension of uncertainty quantification as well as the generalization to unseen objects. In the real-world experiments, our method demonstrates a significant improvement by 39% in the overall clearance rate compared to the baselines. Video is under https://www.youtube.com/watch?v=4aQsrDgdV8Y&amp;t=12s", "published": "2024-11-07 05:00:00", "id": "e5b88d26-8729-4466-9739-6592f4f46126", "source": "arxiv", "section": "computerScience"}, {"title": "Investigating Conceptual Blending of a Diffusion Model for Improving Nonword-to-Image Generation", "link": "https://arxiv.org/abs/2411.03595", "description": "arXiv:2411.03595v1 Announce Type: new \nAbstract: Text-to-image diffusion models sometimes depict blended concepts in the generated images. One promising use case of this effect would be the nonword-to-image generation task which attempts to generate images intuitively imaginable from a non-existing word (nonword). To realize nonword-to-image generation, an existing study focused on associating nonwords with similar-sounding words. Since each nonword can have multiple similar-sounding words, generating images containing their blended concepts would increase intuitiveness, facilitating creative activities and promoting computational psycholinguistics. Nevertheless, no existing study has quantitatively evaluated this effect in either diffusion models or the nonword-to-image generation paradigm. Therefore, this paper first analyzes the conceptual blending in a pretrained diffusion model, Stable Diffusion. The analysis reveals that a high percentage of generated images depict blended concepts when inputting an embedding interpolating between the text embeddings of two text prompts referring to different concepts. Next, this paper explores the best text embedding space conversion method of an existing nonword-to-image generation framework to ensure both the occurrence of conceptual blending and image generation quality. We compare the conventional direct prediction approach with the proposed method that combines $k$-nearest neighbor search and linear regression. Evaluation reveals that the enhanced accuracy of the embedding space conversion by the proposed method improves the image generation quality, while the emergence of conceptual blending could be attributed mainly to the specific dimensions of the high-dimensional text embedding space.", "published": "2024-11-07 05:00:00", "id": "f39550fc-f725-4b22-a80b-06815b6ce2cc", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing the Expressivity of Temporal Graph Networks through Source-Target Identification", "link": "https://arxiv.org/abs/2411.03596", "description": "arXiv:2411.03596v1 Announce Type: new \nAbstract: Despite the successful application of Temporal Graph Networks (TGNs) for tasks such as dynamic node classification and link prediction, they still perform poorly on the task of dynamic node affinity prediction -- where the goal is to predict `how much' two nodes will interact in the future. In fact, simple heuristic approaches such as persistent forecasts and moving averages over \\emph{ground-truth labels} significantly and consistently outperform TGNs. Building on this observation, we find that computing heuristics \\textit{over messages} is an equally competitive approach, outperforming TGN and all current temporal graph (TG) models on dynamic node affinity prediction. In this paper, we prove that no formulation of TGN can represent persistent forecasting or moving averages over messages, and propose to enhance the expressivity of TGNs by adding source-target identification to each interaction event message. We show that this modification is required to represent persistent forecasting, moving averages, and the broader class of autoregressive models over messages. Our proposed method, TGNv2, significantly outperforms TGN and all current TG models on all Temporal Graph Benchmark (TGB) dynamic node affinity prediction datasets.", "published": "2024-11-07 05:00:00", "id": "78b93d3b-584d-4206-9498-76a191934087", "source": "arxiv", "section": "computerScience"}, {"title": "Open-Source High-Speed Flight Surrogate Modeling Framework", "link": "https://arxiv.org/abs/2411.03598", "description": "arXiv:2411.03598v1 Announce Type: new \nAbstract: High-speed flight vehicles, which travel much faster than the speed of sound, are crucial for national defense and space exploration. However, accurately predicting their behavior under numerous, varied flight conditions is a challenge and often prohibitively expensive. The proposed approach involves creating smarter, more efficient machine learning models (also known as surrogate models or meta models) that can fuse data generated from a variety of fidelity levels -- to include engineering methods, simulation, wind tunnel, and flight test data -- to make more accurate predictions. These models are able to move the bulk of the computation from high performance computing (HPC) to single user machines (laptop, desktop, etc.). The project builds upon previous work but introduces code improvements and an informed perspective on the direction of the field. The new surrogate modeling framework is now modular and, by design, broadly applicable to many modeling problems. The new framework also has a more robust automatic hyperparameter tuning capability and abstracts away most of the pre- and post-processing tasks. The Gaussian process regression and deep neural network-based models included in the presented framework were able to model two datasets with high accuracy (R^2>0.99). The primary conclusion is that the framework is effective and has been delivered to the Air Force for integration into real-world projects. For future work, significant and immediate investment in continued research is crucial. The author recommends further testing and refining modeling methods that explicitly incorporate physical laws and are robust enough to handle simulation and test data from varying resolutions and sources, including coarse meshes, fine meshes, unstructured meshes, and limited experimental test points.", "published": "2024-11-07 05:00:00", "id": "9cc057ca-649c-438a-ac38-10ab125df1b7", "source": "arxiv", "section": "computerScience"}, {"title": "CPEG: Leveraging Consistency Policy with Consensus Guidance for Multi-agent Exploration", "link": "https://arxiv.org/abs/2411.03603", "description": "arXiv:2411.03603v1 Announce Type: new \nAbstract: Efficient exploration is crucial in cooperative multi-agent reinforcement learning (MARL), especially in sparse-reward settings. However, due to the reliance on the unimodal policy, existing methods are prone to falling into the local optima, hindering the effective exploration of better policies. Furthermore, tackling multi-agent tasks in complex environments requires cooperation during exploration, posing substantial challenges for MARL methods. To address these issues, we propose a Consistency Policy with consEnsus Guidance (CPEG), with two primary components: (a) introducing a multimodal policy to enhance exploration capabilities, and (b) sharing the consensus among agents to foster agent cooperation. For component (a), CPEG incorporates a Consistency model as the policy, leveraging its multimodal nature and stochastic characteristics to facilitate exploration. Regarding component (b), CPEG introduces a Consensus Learner to deduce the consensus on the global state from local observations. This consensus then serves as a guidance for the Consistency Policy, promoting cooperation among agents. The proposed method is evaluated in multi-agent particle environments (MPE) and multi-agent MuJoCo (MAMuJoCo), and empirical results indicate that CPEG not only achieves improvements in sparse-reward settings but also matches the performance of baselines in dense-reward environments.", "published": "2024-11-07 05:00:00", "id": "813d4090-9118-461a-a5e6-5e6d6eb5528a", "source": "arxiv", "section": "computerScience"}, {"title": "Temporal-Difference Learning Using Distributed Error Signals", "link": "https://arxiv.org/abs/2411.03604", "description": "arXiv:2411.03604v1 Announce Type: new \nAbstract: A computational problem in biological reward-based learning is how credit assignment is performed in the nucleus accumbens (NAc). Much research suggests that NAc dopamine encodes temporal-difference (TD) errors for learning value predictions. However, dopamine is synchronously distributed in regionally homogeneous concentrations, which does not support explicit credit assignment (like used by backpropagation). It is unclear whether distributed errors alone are sufficient for synapses to make coordinated updates to learn complex, nonlinear reward-based learning tasks. We design a new deep Q-learning algorithm, Artificial Dopamine, to computationally demonstrate that synchronously distributed, per-layer TD errors may be sufficient to learn surprisingly complex RL tasks. We empirically evaluate our algorithm on MinAtar, the DeepMind Control Suite, and classic control tasks, and show it often achieves comparable performance to deep RL algorithms that use backpropagation.", "published": "2024-11-07 05:00:00", "id": "c7754c8c-7e6c-4cfa-aed4-623f7ea39215", "source": "arxiv", "section": "computerScience"}, {"title": "Upper bound of high-order derivatives for Wachspress coordinates on polytopes", "link": "https://arxiv.org/abs/2411.03607", "description": "arXiv:2411.03607v1 Announce Type: new \nAbstract: The gradient bounds of generalized barycentric coordinates play an essential role in the $H^1$ norm approximation error estimate of generalized barycentric interpolations. Similarly, the $H^k$ norm, $k>1$, estimate needs upper bounds of high-order derivatives, which are not available in the literature. In this paper, we derive such upper bounds for the Wachspress generalized barycentric coordinates on simple convex $d$-dimensional polytopes, $d\\ge 1$. The result can be used to prove optimal convergence for Wachspress-based polytopal finite element approximation of, for example, fourth-order elliptic equations.\n  Another contribution of this paper is to compare various shape-regularity conditions for simple convex polytopes, and to clarify their relations using knowledge from convex geometry.", "published": "2024-11-07 05:00:00", "id": "dd5c0bf1-4886-43ca-aaf4-79d79880dfbe", "source": "arxiv", "section": "computerScience"}, {"title": "LCP-Fusion: A Neural Implicit SLAM with Enhanced Local Constraints and Computable Prior", "link": "https://arxiv.org/abs/2411.03610", "description": "arXiv:2411.03610v1 Announce Type: new \nAbstract: Recently the dense Simultaneous Localization and Mapping (SLAM) based on neural implicit representation has shown impressive progress in hole filling and high-fidelity mapping. Nevertheless, existing methods either heavily rely on known scene bounds or suffer inconsistent reconstruction due to drift in potential loop-closure regions, or both, which can be attributed to the inflexible representation and lack of local constraints. In this paper, we present LCP-Fusion, a neural implicit SLAM system with enhanced local constraints and computable prior, which takes the sparse voxel octree structure containing feature grids and SDF priors as hybrid scene representation, enabling the scalability and robustness during mapping and tracking. To enhance the local constraints, we propose a novel sliding window selection strategy based on visual overlap to address the loop-closure, and a practical warping loss to constrain relative poses. Moreover, we estimate SDF priors as coarse initialization for implicit features, which brings additional explicit constraints and robustness, especially when a light but efficient adaptive early ending is adopted. Experiments demonstrate that our method achieve better localization accuracy and reconstruction consistency than existing RGB-D implicit SLAM, especially in challenging real scenes (ScanNet) as well as self-captured scenes with unknown scene bounds. The code is available at https://github.com/laliwang/LCP-Fusion.", "published": "2024-11-07 05:00:00", "id": "03919b84-a2ee-4a75-bd88-9093fa876e06", "source": "arxiv", "section": "computerScience"}, {"title": "Robot Swarming over the internet", "link": "https://arxiv.org/abs/2411.03614", "description": "arXiv:2411.03614v1 Announce Type: new \nAbstract: This paper considers cooperative control of robots involving two different testbed systems in remote locations with communication on the internet. This provides us the capability to exchange robots status like positions, velocities and directions needed for the swarming algorithm. The results show that all robots properly follow some leader defined one of the testbeds. Measurement of data exchange rates show no loss of packets, and average transfer delays stay within tolerance limits for practical applications. In our knowledge, the novelty of this paper concerns this kind of control over a large network like internet.", "published": "2024-11-07 05:00:00", "id": "faf0c4d7-a557-4c9d-a37c-378a82f8b797", "source": "arxiv", "section": "computerScience"}, {"title": "Real-Time Safe Bipedal Robot Navigation using Linear Discrete Control Barrier Functions", "link": "https://arxiv.org/abs/2411.03619", "description": "arXiv:2411.03619v1 Announce Type: new \nAbstract: Safe navigation in real-time is an essential task for humanoid robots in real-world deployment. Since humanoid robots are inherently underactuated thanks to unilateral ground contacts, a path is considered safe if it is obstacle-free and respects the robot's physical limitations and underlying dynamics. Existing approaches often decouple path planning from gait control due to the significant computational challenge caused by the full-order robot dynamics. In this work, we develop a unified, safe path and gait planning framework that can be evaluated online in real-time, allowing the robot to navigate clustered environments while sustaining stable locomotion. Our approach uses the popular Linear Inverted Pendulum (LIP) model as a template model to represent walking dynamics. It incorporates heading angles in the model to evaluate kinematic constraints essential for physically feasible gaits properly. In addition, we leverage discrete control barrier functions (DCBF) for obstacle avoidance, ensuring that the subsequent foot placement provides a safe navigation path within clustered environments. To guarantee real-time computation, we use a novel approximation of the DCBF to produce linear DCBF (LDCBF) constraints. We validate the proposed approach in simulation using a Digit robot in randomly generated environments. The results demonstrate that our approach can generate safe gaits for a non-trivial humanoid robot to navigate environments with randomly generated obstacles in real-time.", "published": "2024-11-07 05:00:00", "id": "bc7cf2da-0f94-4f9f-8beb-30420d996a69", "source": "arxiv", "section": "computerScience"}, {"title": "Fully Hyperbolic Rotation for Knowledge Graph Embedding", "link": "https://arxiv.org/abs/2411.03622", "description": "arXiv:2411.03622v1 Announce Type: new \nAbstract: Hyperbolic rotation is commonly used to effectively model knowledge graphs and their inherent hierarchies. However, existing hyperbolic rotation models rely on logarithmic and exponential mappings for feature transformation. These models only project data features into hyperbolic space for rotation, limiting their ability to fully exploit the hyperbolic space. To address this problem, we propose a novel fully hyperbolic model designed for knowledge graph embedding. Instead of feature mappings, we define the model directly in hyperbolic space with the Lorentz model. Our model considers each relation in knowledge graphs as a Lorentz rotation from the head entity to the tail entity. We adopt the Lorentzian version distance as the scoring function for measuring the plausibility of triplets. Extensive results on standard knowledge graph completion benchmarks demonstrated that our model achieves competitive results with fewer parameters. In addition, our model get the state-of-the-art performance on datasets of CoDEx-s and CoDEx-m, which are more diverse and challenging than before. Our code is available at https://github.com/llqy123/FHRE.", "published": "2024-11-07 05:00:00", "id": "fab9a1bf-7f97-40d0-b11f-a378afbe1709", "source": "arxiv", "section": "computerScience"}, {"title": "SEGMN: A Structure-Enhanced Graph Matching Network for Graph Similarity Learning", "link": "https://arxiv.org/abs/2411.03624", "description": "arXiv:2411.03624v1 Announce Type: new \nAbstract: Graph similarity computation (GSC) aims to quantify the similarity score between two graphs. Although recent GSC methods based on graph neural networks (GNNs) take advantage of intra-graph structures in message passing, few of them fully utilize the structures presented by edges to boost the representation of their connected nodes. Moreover, previous cross-graph node embedding matching lacks the perception of the overall structure of the graph pair, due to the fact that the node representations from GNNs are confined to the intra-graph structure, causing the unreasonable similarity score. Intuitively, the cross-graph structure represented in the assignment graph is helpful to rectify the inappropriate matching. Therefore, we propose a structure-enhanced graph matching network (SEGMN). Equipped with a dual embedding learning module and a structure perception matching module, SEGMN achieves structure enhancement in both embedding learning and cross-graph matching. The dual embedding learning module incorporates adjacent edge representation into each node to achieve a structure-enhanced representation. The structure perception matching module achieves cross-graph structure enhancement through assignment graph convolution. The similarity score of each cross-graph node pair can be rectified by aggregating messages from structurally relevant node pairs. Experimental results on benchmark datasets demonstrate that SEGMN outperforms the state-of-the-art GSC methods in the GED regression task, and the structure perception matching module is plug-and-play, which can further improve the performance of the baselines by up to 25%.", "published": "2024-11-07 05:00:00", "id": "bf347df8-13eb-45e3-a4d8-7dad2a4c352f", "source": "arxiv", "section": "computerScience"}, {"title": "StreamingBench: Assessing the Gap for MLLMs to Achieve Streaming Video Understanding", "link": "https://arxiv.org/abs/2411.03628", "description": "arXiv:2411.03628v1 Announce Type: new \nAbstract: The rapid development of Multimodal Large Language Models (MLLMs) has expanded their capabilities from image comprehension to video understanding. However, most of these MLLMs focus primarily on offline video comprehension, necessitating extensive processing of all video frames before any queries can be made. This presents a significant gap compared to the human ability to watch, listen, think, and respond to streaming inputs in real time, highlighting the limitations of current MLLMs. In this paper, we introduce StreamingBench, the first comprehensive benchmark designed to evaluate the streaming video understanding capabilities of MLLMs. StreamingBench assesses three core aspects of streaming video understanding: (1) real-time visual understanding, (2) omni-source understanding, and (3) contextual understanding. The benchmark consists of 18 tasks, featuring 900 videos and 4,500 human-curated QA pairs. Each video features five questions presented at different time points to simulate a continuous streaming scenario. We conduct experiments on StreamingBench with 13 open-source and proprietary MLLMs and find that even the most advanced proprietary MLLMs like Gemini 1.5 Pro and GPT-4o perform significantly below human-level streaming video understanding capabilities. We hope our work can facilitate further advancements for MLLMs, empowering them to approach human-level video comprehension and interaction in more realistic scenarios.", "published": "2024-11-07 05:00:00", "id": "5fdbaeb7-2791-4aee-85cd-dbed1136bb2b", "source": "arxiv", "section": "computerScience"}, {"title": "RTify: Aligning Deep Neural Networks with Human Behavioral Decisions", "link": "https://arxiv.org/abs/2411.03630", "description": "arXiv:2411.03630v1 Announce Type: new \nAbstract: Current neural network models of primate vision focus on replicating overall levels of behavioral accuracy, often neglecting perceptual decisions' rich, dynamic nature. Here, we introduce a novel computational framework to model the dynamics of human behavioral choices by learning to align the temporal dynamics of a recurrent neural network (RNN) to human reaction times (RTs). We describe an approximation that allows us to constrain the number of time steps an RNN takes to solve a task with human RTs. The approach is extensively evaluated against various psychophysics experiments. We also show that the approximation can be used to optimize an \"ideal-observer\" RNN model to achieve an optimal tradeoff between speed and accuracy without human data. The resulting model is found to account well for human RT data. Finally, we use the approximation to train a deep learning implementation of the popular Wong-Wang decision-making model. The model is integrated with a convolutional neural network (CNN) model of visual processing and evaluated using both artificial and natural image stimuli. Overall, we present a novel framework that helps align current vision models with human behavior, bringing us closer to an integrated model of human vision.", "published": "2024-11-07 05:00:00", "id": "2f5d7b85-b666-4cf6-a95e-575327bc7259", "source": "arxiv", "section": "computerScience"}, {"title": "Privacy-Preserving Resilient Vector Consensus", "link": "https://arxiv.org/abs/2411.03633", "description": "arXiv:2411.03633v1 Announce Type: new \nAbstract: This paper studies privacy-preserving resilient vector consensus in multi-agent systems against faulty agents, where normal agents can achieve consensus within the convex hull of their initial states while protecting state vectors from being disclosed. Specifically, we consider a modification of an existing algorithm known as Approximate Distributed Robust Convergence Using Centerpoints (ADRC), i.e., Privacy-Preserving ADRC (PP-ADRC). Under PP-ADRC, each normal agent introduces multivariate Gaussian noise to its state during each iteration. We first provide sufficient conditions to ensure that all normal agents' states can achieve mean square convergence under PP-ADRC. Then, we analyze convergence accuracy from two perspectives, i.e., the Mahalanobis distance of the final value from its expectation and the Hausdorff distance based alteration of the convex hull caused by noise when only partial dimensions are added with noise. Then, we employ concentrated geo-privacy to characterize privacy preservation and conduct a thorough comparison with differential privacy. Finally, numerical simulations demonstrate the theoretical results.", "published": "2024-11-07 05:00:00", "id": "a2a4f9b2-d2c0-4e2a-ad8b-292382a89b6b", "source": "arxiv", "section": "computerScience"}, {"title": "Digital Twin-Assisted Robust and Adaptive Resource Slicing in LEO Satellite Networks", "link": "https://arxiv.org/abs/2411.03635", "description": "arXiv:2411.03635v1 Announce Type: new \nAbstract: Resource slicing in low Earth orbit satellite networks (LSN) is essential to support diversified services. In this paper, we investigate a resource slicing problem in LSN to reserve resources in satellites to achieve efficient resource provisioning. To address the challenges of non-stationary service demands, inaccurate prediction, and satellite mobility, we propose an adaptive digital twin (DT)-assisted resource slicing scheme for robust and adaptive resource management in LSN. Specifically, a slice DT, being able to capture the service demand prediction uncertainty through collected service demand data, is constructed to enhance the robustness of resource slicing decisions for dynamic service demands. In addition, the constructed DT can emulate resource slicing decisions for evaluating their performance, enabling adaptive slicing decision updates to efficiently reserve resources in LSN. Simulation results demonstrate that the proposed scheme outperforms benchmark methods, achieving low service demand violations with efficient resource consumption.", "published": "2024-11-07 05:00:00", "id": "ed741892-22f9-406f-b653-5f4c210513b1", "source": "arxiv", "section": "computerScience"}, {"title": "Structure Consistent Gaussian Splatting with Matching Prior for Few-shot Novel View Synthesis", "link": "https://arxiv.org/abs/2411.03637", "description": "arXiv:2411.03637v1 Announce Type: new \nAbstract: Despite the substantial progress of novel view synthesis, existing methods, either based on the Neural Radiance Fields (NeRF) or more recently 3D Gaussian Splatting (3DGS), suffer significant degradation when the input becomes sparse. Numerous efforts have been introduced to alleviate this problem, but they still struggle to synthesize satisfactory results efficiently, especially in the large scene. In this paper, we propose SCGaussian, a Structure Consistent Gaussian Splatting method using matching priors to learn 3D consistent scene structure. Considering the high interdependence of Gaussian attributes, we optimize the scene structure in two folds: rendering geometry and, more importantly, the position of Gaussian primitives, which is hard to be directly constrained in the vanilla 3DGS due to the non-structure property. To achieve this, we present a hybrid Gaussian representation. Besides the ordinary non-structure Gaussian primitives, our model also consists of ray-based Gaussian primitives that are bound to matching rays and whose optimization of their positions is restricted along the ray. Thus, we can utilize the matching correspondence to directly enforce the position of these Gaussian primitives to converge to the surface points where rays intersect. Extensive experiments on forward-facing, surrounding, and complex large scenes show the effectiveness of our approach with state-of-the-art performance and high efficiency. Code is available at https://github.com/prstrive/SCGaussian.", "published": "2024-11-07 05:00:00", "id": "f4072b3c-b615-4d2f-9c39-322eb5b9bd8f", "source": "arxiv", "section": "computerScience"}, {"title": "Adaptive Stereo Depth Estimation with Multi-Spectral Images Across All Lighting Conditions", "link": "https://arxiv.org/abs/2411.03638", "description": "arXiv:2411.03638v1 Announce Type: new \nAbstract: Depth estimation under adverse conditions remains a significant challenge. Recently, multi-spectral depth estimation, which integrates both visible light and thermal images, has shown promise in addressing this issue. However, existing algorithms struggle with precise pixel-level feature matching, limiting their ability to fully exploit geometric constraints across different spectra. To address this, we propose a novel framework incorporating stereo depth estimation to enforce accurate geometric constraints. In particular, we treat the visible light and thermal images as a stereo pair and utilize a Cross-modal Feature Matching (CFM) Module to construct a cost volume for pixel-level matching. To mitigate the effects of poor lighting on stereo matching, we introduce Degradation Masking, which leverages robust monocular thermal depth estimation in degraded regions. Our method achieves state-of-the-art (SOTA) performance on the Multi-Spectral Stereo (MS2) dataset, with qualitative evaluations demonstrating high-quality depth maps under varying lighting conditions.", "published": "2024-11-07 05:00:00", "id": "ad95f629-9433-4664-b0d2-acfcf0bbfe88", "source": "arxiv", "section": "computerScience"}, {"title": "Constrained Multi-objective Bayesian Optimization through Optimistic Constraints Estimation", "link": "https://arxiv.org/abs/2411.03641", "description": "arXiv:2411.03641v1 Announce Type: new \nAbstract: Multi-objective Bayesian optimization has been widely adopted in scientific experiment design, including drug discovery and hyperparameter optimization. In practice, regulatory or safety concerns often impose additional thresholds on certain attributes of the experimental outcomes. Previous work has primarily focused on constrained single-objective optimization tasks or active search under constraints. We propose CMOBO, a sample-efficient constrained multi-objective Bayesian optimization algorithm that balances learning of the feasible region (defined on multiple unknowns) with multi-objective optimization within the feasible region in a principled manner. We provide both theoretical justification and empirical evidence, demonstrating the efficacy of our approach on various synthetic benchmarks and real-world applications.", "published": "2024-11-07 05:00:00", "id": "18a2e1bc-cb9d-4cac-a425-c34975665734", "source": "arxiv", "section": "computerScience"}, {"title": "Deploying Multi-task Online Server with Large Language Model", "link": "https://arxiv.org/abs/2411.03644", "description": "arXiv:2411.03644v1 Announce Type: new \nAbstract: In the industry, numerous tasks are deployed online. Traditional approaches often tackle each task separately by its own network, which leads to excessive costs for developing and scaling models, especially in the context of large language models. Although multi-task methods can save costs through parameter sharing, they often struggle to outperform single-task methods in real-world applications. To tackle these challenges, we present a three-stage multi-task learning framework for large language models. It involves task filtering, followed by fine-tuning on high-resource tasks, and finally fine-tuning on all tasks. We conducted comprehensive experiments in single-task and multi-task settings. Our approach, exemplified on different benchmarks, demonstrates that it is able to achieve performance comparable to the single-task method while reducing up to 90.9\\% of its overhead.", "published": "2024-11-07 05:00:00", "id": "5a20f8c9-c57d-41fd-916c-e41fc87ab186", "source": "arxiv", "section": "computerScience"}, {"title": "Exploiting Stragglers in Distributed Computing Systems with Task Grouping", "link": "https://arxiv.org/abs/2411.03645", "description": "arXiv:2411.03645v1 Announce Type: new \nAbstract: We consider the problem of stragglers in distributed computing systems. Stragglers, which are compute nodes that unpredictably slow down, often increase the completion times of tasks. One common approach to mitigating stragglers is work replication, where only the first completion among replicated tasks is accepted, discarding the others. However, discarding work leads to resource wastage. In this paper, we propose a method for exploiting the work completed by stragglers rather than discarding it. The idea is to increase the granularity of the assigned work, and to increase the frequency of worker updates. We show that the proposed method reduces the completion time of tasks via experiments performed on a simulated cluster as well as on Amazon EC2 with Apache Hadoop.", "published": "2024-11-07 05:00:00", "id": "8cdacf26-73d8-4e08-90fc-371170d3ee74", "source": "arxiv", "section": "computerScience"}, {"title": "On the Error-correcting Capability of Twisted Centralizer Codes Obtained from a Fixed Rank-1 Matrix", "link": "https://arxiv.org/abs/2411.03647", "description": "arXiv:2411.03647v1 Announce Type: new \nAbstract: In this paper, we give a generalization on the error correcting capability of twisted centralizer codes obtained from a fixed rank 1 matrix. In particular, we fix the combinatorial matrix which is obtained by getting the linear combination of the matrix whose all entries are 1 and the identity matrix of order n. Results reveal that such codes have a dimension 1 for any fixed combinatorial matrix and constant a hence having a relatively low information rate due to the way its codewords are constructed, but are found to be maximum distance separable codes.", "published": "2024-11-07 05:00:00", "id": "847b132a-3537-44ec-a51d-e175844bcec7", "source": "arxiv", "section": "computerScience"}, {"title": "Policy Aggregation", "link": "https://arxiv.org/abs/2411.03651", "description": "arXiv:2411.03651v1 Announce Type: new \nAbstract: We consider the challenge of AI value alignment with multiple individuals that have different reward functions and optimal policies in an underlying Markov decision process. We formalize this problem as one of policy aggregation, where the goal is to identify a desirable collective policy. We argue that an approach informed by social choice theory is especially suitable. Our key insight is that social choice methods can be reinterpreted by identifying ordinal preferences with volumes of subsets of the state-action occupancy polytope. Building on this insight, we demonstrate that a variety of methods--including approval voting, Borda count, the proportional veto core, and quantile fairness--can be practically applied to policy aggregation.", "published": "2024-11-07 05:00:00", "id": "0401c48d-880c-42ad-a20b-e4def60008ce", "source": "arxiv", "section": "computerScience"}, {"title": "PyroGuardian: An IoT-Enabled System for Health and Location Monitoring in High-Risk Firefighting Environments", "link": "https://arxiv.org/abs/2411.03654", "description": "arXiv:2411.03654v1 Announce Type: new \nAbstract: First responders risk their lives to reduce property damage and prevent injuries during disasters. Among first responders, firefighters work with fires in residential properties, forests, or other locations where fire occurs. We built the PyroGuardian system that uses wearable modules to transmit unit information over Long Range (LoRa) to an Android tablet. The tablet runs our application, PyroPortal, to assign each firefighter's stats, such as body temperature, heart rate, and GPS location. PyroPortal displays this information on unit dashboards, and markers on Google Maps represent the firefighter's location and the direction they are facing. These dashboards can help the incident commander (IC) make more informed decisions on mission control operations and remove specific units whose health stats, such as oximeter and pulse, passed certain thresholds. PyroGuardian completes all these tasks at an affordable cost and in an impressive maximum range between the units and IC. In addition, PyroGuardian has various application scenarios, such as law enforcement and military operations, besides firefighting. We also conducted a sample mission inside a burning building while real firefighters watched. After the demonstration, they completed a survey on system usability and PyroGuardian's potential to meet their requirements.", "published": "2024-11-07 05:00:00", "id": "fc98bec9-b537-4c70-95bb-c324da897aa5", "source": "arxiv", "section": "computerScience"}, {"title": "Requirements Engineering for Older Adult Digital Health Software: A Systematic Literature Review", "link": "https://arxiv.org/abs/2411.03656", "description": "arXiv:2411.03656v1 Announce Type: new \nAbstract: Growth of the older adult population has led to an increasing interest in technology-supported aged care. However, the area has some challenges such as a lack of caregivers and limitations in understanding the emotional, social, physical, and mental well-being needs of seniors. Furthermore, there is a gap in the understanding between developers and ageing people of their requirements. Digital health can be important in supporting older adults wellbeing, emotional requirements, and social needs. Requirements Engineering (RE) is a major software engineering field, which can help to identify, elicit and prioritize the requirements of stakeholders and ensure that the systems meet standards for performance, reliability, and usability. We carried out a systematic review of the literature on RE for older adult digital health software. This was necessary to show the representatives of the current stage of understanding the needs of older adults in aged care digital health. Using established guidelines outlined by the Kitchenham method, the PRISMA and the PICO guideline, we developed a protocol, followed by the systematic exploration of eight databases. This resulted in 69 primary studies of high relevance, which were subsequently subjected to data extraction, synthesis, and reporting. We highlight key RE processes in digital health software for ageing people. It explored the utilization of technology for older user well-being and care, and the evaluations of such solutions. The review also identified key limitations found in existing primary studies that inspire future research opportunities. The results indicate that requirement gathering and understanding have a significant variation between different studies. The differences are in the quality, depth, and techniques adopted for requirement gathering and these differences are largely due to uneven adoption of RE methods.", "published": "2024-11-07 05:00:00", "id": "8c18f765-bc51-4fa3-989d-e32e79723045", "source": "arxiv", "section": "computerScience"}, {"title": "How do practitioners gain confidence in assurance cases?", "link": "https://arxiv.org/abs/2411.03657", "description": "arXiv:2411.03657v1 Announce Type: new \nAbstract: CONTEXT: Assurance Cases (ACs) are prepared to argue that the system's desired quality attributes (e.g., safety or security) are satisfied. While there is strong adoption of ACs, practitioners are often left asking an important question: are we confident that the claims made by the case are true? While many confidence assessment methods (CAMs) exist, little is known about the use of these methods in practice\n  OBJECTIVE: Develop an understanding of the current state of practice for AC confidence assessment: what methods are used in practice and what barriers exist for their use?\n  METHOD: Structured interviews were performed with practitioners with experience contributing to real-world ACs. Open-coding was performed on transcripts. A description of the current state of AC practice and future considerations for researchers was synthesized from the results.\n  RESULTS: A total of n = 19 practitioners were interviewed. The most common CAMs were (peer-)review of ACs, dialectic reasoning (\"defeaters\"), and comparing against checklists. Participants preferred qualitative methods and expressed concerns about quantitative CAMs. Barriers to using CAMs included additional work, inadequate guidance, subjectivity and interpretation of results, and trustworthiness of methods.\n  CONCLUSION: While many CAMs are described in the literature there is a gap between the proposed methods and needs of practitioners. Researchers working in this area should consider the need to: connect CAMs to established practices, use CAMs to communicate with interest holders, crystallize the details of CAM application, curate accessible guidance, and confirm that methods are trustworthy.", "published": "2024-11-07 05:00:00", "id": "4ae440d3-242b-440c-aef5-58cc3e876019", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Scalable Automated Grading: Leveraging Large Language Models for Conceptual Question Evaluation in Engineering", "link": "https://arxiv.org/abs/2411.03659", "description": "arXiv:2411.03659v1 Announce Type: new \nAbstract: This study explores the feasibility of using large language models (LLMs), specifically GPT-4o (ChatGPT), for automated grading of conceptual questions in an undergraduate Mechanical Engineering course. We compared the grading performance of GPT-4o with that of human teaching assistants (TAs) on ten quiz problems from the MEEN 361 course at Texas A&amp;M University, each answered by approximately 225 students. Both the LLM and TAs followed the same instructor-provided rubric to ensure grading consistency. We evaluated performance using Spearman's rank correlation coefficient and Root Mean Square Error (RMSE) to assess the alignment between rankings and the accuracy of scores assigned by GPT-4o and TAs under zero- and few-shot grading settings. In the zero-shot setting, GPT-4o demonstrated a strong correlation with TA grading, with Spearman's rank correlation coefficient exceeding 0.6 in seven out of ten datasets and reaching a high of 0.9387. Our analysis reveals that GPT-4o performs well when grading criteria are straightforward but struggles with nuanced answers, particularly those involving synonyms not present in the rubric. The model also tends to grade more stringently in ambiguous cases compared to human TAs. Overall, ChatGPT shows promise as a tool for grading conceptual questions, offering scalability and consistency.", "published": "2024-11-07 05:00:00", "id": "7671e4c4-84db-4858-8c98-879fd4ee4d34", "source": "arxiv", "section": "computerScience"}, {"title": "Development of a Practical Articulated Wheeled In-pipe Robot for Both 3-4 in Force Main Inspection of Sewer Pipes", "link": "https://arxiv.org/abs/2411.03660", "description": "arXiv:2411.03660v1 Announce Type: new \nAbstract: This paper reports a practical articulated wheeled in-pipe inspection robot \"AIRo-7.1\" which is waterproof and dustproof, and can adapt to 3 to 4 in inner diameters. The joint torque can be adjusted by a PWM open-loop control. The middle joint angle can be controlled by a position feedback control system while the other two joints are bent by torsional springs. Thanks to this simple and high-density design, not only downsizing of the robot but also wide range of the adaptive inner diameter were achieved. However, the relationship between the actual middle joint torque value and the PWM duty ratio should be pre-known because the reducer used in AIRo-7.1 was designed by ourselves. Therefore, preliminary experiments were conducted to clarify the relationship between them. To examine the adaptive movement, experiments in both 3 in and 4 in pipes with vertical, bend, and diameter change sections. Finally, field experiment was also conducted. From the results, high adaptability to different inner diameters of pipes and slippery environments were confirmed although waterproof and dustproof were not perfectly working.", "published": "2024-11-07 05:00:00", "id": "7fd483c4-bd7a-474f-b35d-de5f5e9707d1", "source": "arxiv", "section": "computerScience"}, {"title": "Can Graph Neural Networks Expose Training Data Properties? An Efficient Risk Assessment Approach", "link": "https://arxiv.org/abs/2411.03663", "description": "arXiv:2411.03663v1 Announce Type: new \nAbstract: Graph neural networks (GNNs) have attracted considerable attention due to their diverse applications. However, the scarcity and quality limitations of graph data present challenges to their training process in practical settings. To facilitate the development of effective GNNs, companies and researchers often seek external collaboration. Yet, directly sharing data raises privacy concerns, motivating data owners to train GNNs on their private graphs and share the trained models. Unfortunately, these models may still inadvertently disclose sensitive properties of their training graphs (e.g., average default rate in a transaction network), leading to severe consequences for data owners. In this work, we study graph property inference attack to identify the risk of sensitive property information leakage from shared models. Existing approaches typically train numerous shadow models for developing such attack, which is computationally intensive and impractical. To address this issue, we propose an efficient graph property inference attack by leveraging model approximation techniques. Our method only requires training a small set of models on graphs, while generating a sufficient number of approximated shadow models for attacks. To enhance diversity while reducing errors in the approximated models, we apply edit distance to quantify the diversity within a group of approximated models and introduce a theoretically guaranteed criterion to evaluate each model's error. Subsequently, we propose a novel selection mechanism to ensure that the retained approximated models achieve high diversity and low error. Extensive experiments across six real-world scenarios demonstrate our method's substantial improvement, with average increases of 2.7% in attack accuracy and 4.1% in ROC-AUC, while being 6.5$\\times$ faster compared to the best baseline.", "published": "2024-11-07 05:00:00", "id": "8cbdda61-e290-4d6c-9b68-898008d3e01b", "source": "arxiv", "section": "computerScience"}, {"title": "Evaluating Moral Beliefs across LLMs through a Pluralistic Framework", "link": "https://arxiv.org/abs/2411.03665", "description": "arXiv:2411.03665v1 Announce Type: new \nAbstract: Proper moral beliefs are fundamental for language models, yet assessing these beliefs poses a significant challenge. This study introduces a novel three-module framework to evaluate the moral beliefs of four prominent large language models. Initially, we constructed a dataset containing 472 moral choice scenarios in Chinese, derived from moral words. The decision-making process of the models in these scenarios reveals their moral principle preferences. By ranking these moral choices, we discern the varying moral beliefs held by different language models. Additionally, through moral debates, we investigate the firmness of these models to their moral choices. Our findings indicate that English language models, namely ChatGPT and Gemini, closely mirror moral decisions of the sample of Chinese university students, demonstrating strong adherence to their choices and a preference for individualistic moral beliefs. In contrast, Chinese models such as Ernie and ChatGLM lean towards collectivist moral beliefs, exhibiting ambiguity in their moral choices and debates. This study also uncovers gender bias embedded within the moral beliefs of all examined language models. Our methodology offers an innovative means to assess moral beliefs in both artificial and human intelligence, facilitating a comparison of moral values across different cultures.", "published": "2024-11-07 05:00:00", "id": "06882b37-3bb3-49cb-9350-2fb7114c19db", "source": "arxiv", "section": "computerScience"}, {"title": "Mobile Recording Device Recognition Based Cross-Scale and Multi-Level Representation Learning", "link": "https://arxiv.org/abs/2411.03668", "description": "arXiv:2411.03668v1 Announce Type: new \nAbstract: This paper introduces a modeling approach that employs multi-level global processing, encompassing both short-term frame-level and long-term sample-level feature scales. In the initial stage of shallow feature extraction, various scales are employed to extract multi-level features, including Mel-Frequency Cepstral Coefficients (MFCC) and pre-Fbank log energy spectrum. The construction of the identification network model involves considering the input two-dimensional temporal features from both frame and sample levels. Specifically, the model initially employs one-dimensional convolution-based Convolutional Long Short-Term Memory (ConvLSTM) to fuse spatiotemporal information and extract short-term frame-level features. Subsequently, bidirectional long Short-Term Memory (BiLSTM) is utilized to learn long-term sample-level sequential representations. The transformer encoder then performs cross-scale, multi-level processing on global frame-level and sample-level features, facilitating deep feature representation and fusion at both levels. Finally, recognition results are obtained through Softmax. Our method achieves an impressive 99.6% recognition accuracy on the CCNU_Mobile dataset, exhibiting a notable improvement of 2% to 12% compared to the baseline system. Additionally, we thoroughly investigate the transferability of our model, achieving an 87.9% accuracy in a classification task on a new dataset.", "published": "2024-11-07 05:00:00", "id": "1cb86516-2d66-449b-8737-835f42637d34", "source": "arxiv", "section": "computerScience"}, {"title": "Imagined Potential Games: A Framework for Simulating, Learning and Evaluating Interactive Behaviors", "link": "https://arxiv.org/abs/2411.03669", "description": "arXiv:2411.03669v1 Announce Type: new \nAbstract: Interacting with human agents in complex scenarios presents a significant challenge for robotic navigation, particularly in environments that necessitate both collision avoidance and collaborative interaction, such as indoor spaces. Unlike static or predictably moving obstacles, human behavior is inherently complex and unpredictable, stemming from dynamic interactions with other agents. Existing simulation tools frequently fail to adequately model such reactive and collaborative behaviors, impeding the development and evaluation of robust social navigation strategies. This paper introduces a novel framework utilizing distributed potential games to simulate human-like interactions in highly interactive scenarios. Within this framework, each agent imagines a virtual cooperative game with others based on its estimation. We demonstrate this formulation can facilitate the generation of diverse and realistic interaction patterns in a configurable manner across various scenarios. Additionally, we have developed a gym-like environment leveraging our interactive agent model to facilitate the learning and evaluation of interactive navigation algorithms.", "published": "2024-11-07 05:00:00", "id": "311d1162-4e66-4dcb-b29c-9a69d9da1e37", "source": "arxiv", "section": "computerScience"}, {"title": "Touchstone Benchmark: Are We on the Right Way for Evaluating AI Algorithms for Medical Segmentation?", "link": "https://arxiv.org/abs/2411.03670", "description": "arXiv:2411.03670v1 Announce Type: new \nAbstract: How can we test AI performance? This question seems trivial, but it isn't. Standard benchmarks often have problems such as in-distribution and small-size test sets, oversimplified metrics, unfair comparisons, and short-term outcome pressure. As a consequence, good performance on standard benchmarks does not guarantee success in real-world scenarios. To address these problems, we present Touchstone, a large-scale collaborative segmentation benchmark of 9 types of abdominal organs. This benchmark is based on 5,195 training CT scans from 76 hospitals around the world and 5,903 testing CT scans from 11 additional hospitals. This diverse test set enhances the statistical significance of benchmark results and rigorously evaluates AI algorithms across various out-of-distribution scenarios. We invited 14 inventors of 19 AI algorithms to train their algorithms, while our team, as a third party, independently evaluated these algorithms on three test sets. In addition, we also evaluated pre-existing AI frameworks--which, differing from algorithms, are more flexible and can support different algorithms--including MONAI from NVIDIA, nnU-Net from DKFZ, and numerous other open-source frameworks. We are committed to expanding this benchmark to encourage more innovation of AI algorithms for the medical domain.", "published": "2024-11-07 05:00:00", "id": "f57297a5-bbea-4416-90d8-a87e12b9caa4", "source": "arxiv", "section": "computerScience"}, {"title": "Energy-based physics-informed neural network for frictionless contact problems under large deformation", "link": "https://arxiv.org/abs/2411.03671", "description": "arXiv:2411.03671v1 Announce Type: new \nAbstract: Numerical methods for contact mechanics are of great importance in engineering applications, enabling the prediction and analysis of complex surface interactions under various conditions. In this work, we propose an energy-based physics-informed neural network (PINNs) framework for solving frictionless contact problems under large deformation. Inspired by microscopic Lennard-Jones potential, a surface contact energy is used to describe the contact phenomena. To ensure the robustness of the proposed PINN framework, relaxation, gradual loading and output scaling techniques are introduced. In the numerical examples, the well-known Hertz contact benchmark problem is conducted, demonstrating the effectiveness and robustness of the proposed PINNs framework. Moreover, challenging contact problems with the consideration of geometrical and material nonlinearities are tested. It has been shown that the proposed PINNs framework provides a reliable and powerful tool for nonlinear contact mechanics. More importantly, the proposed PINNs framework exhibits competitive computational efficiency to the commercial FEM software when dealing with those complex contact problems. The codes used in this manuscript are available at https://github.com/JinshuaiBai/energy_PINN_Contact.(The code will be available after acceptance)", "published": "2024-11-07 05:00:00", "id": "a105d885-bef5-4f4c-b730-d0be5e131293", "source": "arxiv", "section": "computerScience"}, {"title": "Towards 3D Semantic Scene Completion for Autonomous Driving: A Meta-Learning Framework Empowered by Deformable Large-Kernel Attention and Mamba Model", "link": "https://arxiv.org/abs/2411.03672", "description": "arXiv:2411.03672v1 Announce Type: new \nAbstract: Semantic scene completion (SSC) is essential for achieving comprehensive perception in autonomous driving systems. However, existing SSC methods often overlook the high deployment costs in real-world applications. Traditional architectures, such as 3D Convolutional Neural Networks (3D CNNs) and self-attention mechanisms, face challenges in efficiently capturing long-range dependencies within 3D voxel grids, limiting their effectiveness. To address these issues, we introduce MetaSSC, a novel meta-learning-based framework for SSC that leverages deformable convolution, large-kernel attention, and the Mamba (D-LKA-M) model. Our approach begins with a voxel-based semantic segmentation (SS) pretraining task, aimed at exploring the semantics and geometry of incomplete regions while acquiring transferable meta-knowledge. Using simulated cooperative perception datasets, we supervise the perception training of a single vehicle using aggregated sensor data from multiple nearby connected autonomous vehicles (CAVs), generating richer and more comprehensive labels. This meta-knowledge is then adapted to the target domain through a dual-phase training strategy that does not add extra model parameters, enabling efficient deployment. To further enhance the model's capability in capturing long-sequence relationships within 3D voxel grids, we integrate Mamba blocks with deformable convolution and large-kernel attention into the backbone network. Extensive experiments demonstrate that MetaSSC achieves state-of-the-art performance, significantly outperforming competing models while also reducing deployment costs.", "published": "2024-11-07 05:00:00", "id": "ca949de1-3c90-4e9c-bba3-40856dc52a8d", "source": "arxiv", "section": "computerScience"}, {"title": "QUILL: Quotation Generation Enhancement of Large Language Models", "link": "https://arxiv.org/abs/2411.03675", "description": "arXiv:2411.03675v1 Announce Type: new \nAbstract: While Large language models (LLMs) have become excellent writing assistants, they still struggle with quotation generation. This is because they either hallucinate when providing factual quotations or fail to provide quotes that exceed human expectations. To bridge the gap, we systematically study how to evaluate and improve LLMs' performance in quotation generation tasks. We first establish a holistic and automatic evaluation system for quotation generation task, which consists of five criteria each with corresponding automatic metric. To improve the LLMs' quotation generation abilities, we construct a bilingual knowledge base that is broad in scope and rich in dimensions, containing up to 32,022 quotes. Moreover, guided by our critiria, we further design a quotation-specific metric to rerank the retrieved quotations from the knowledge base. Extensive experiments show that our metrics strongly correlate with human preferences. Existing LLMs struggle to generate desired quotes, but our quotation knowledge base and reranking metric help narrow this gap. Our dataset and code are publicly available at https://github.com/GraceXiaoo/QUILL.", "published": "2024-11-07 05:00:00", "id": "6ac62108-efb2-4e9e-af6d-be0ef3e4e832", "source": "arxiv", "section": "computerScience"}, {"title": "Physical Layer Deception in OFDM Systems", "link": "https://arxiv.org/abs/2411.03677", "description": "arXiv:2411.03677v1 Announce Type: new \nAbstract: As a promising technology, physical layer security (PLS) enhances security by leveraging the physical characteristics of communication channels. However, the conventional PLS approach leads to a considerable disparity in the effort legitimate users need to secure data compared to eavesdroppers. To address this issue, we propose a physical layer deception (PLD) framework, which applies random deceptive ciphering and orthogonal frequency-division multiplexing (OFDM) to defend against eavesdropping proactively. While ensuring the same level of confidentiality as traditional PLS methods, the PLD approach additionally introduces a deception mechanism, even when the eavesdropper possesses the same knowledge about the transmitter end as the legitimate receiver. Through thorough theoretical analyses and numerical simulations, we prove the superiority of our method over the conventional PLS approach.", "published": "2024-11-07 05:00:00", "id": "e0b33eda-7a30-4c64-9249-27a6937f778a", "source": "arxiv", "section": "computerScience"}, {"title": "Multi-model Ensemble Conformal Prediction in Dynamic Environments", "link": "https://arxiv.org/abs/2411.03678", "description": "arXiv:2411.03678v1 Announce Type: new \nAbstract: Conformal prediction is an uncertainty quantification method that constructs a prediction set for a previously unseen datum, ensuring the true label is included with a predetermined coverage probability. Adaptive conformal prediction has been developed to address data distribution shifts in dynamic environments. However, the efficiency of prediction sets varies depending on the learning model used. Employing a single fixed model may not consistently offer the best performance in dynamic environments with unknown data distribution shifts. To address this issue, we introduce a novel adaptive conformal prediction framework, where the model used for creating prediction sets is selected on the fly from multiple candidate models. The proposed algorithm is proven to achieve strongly adaptive regret over all intervals while maintaining valid coverage. Experiments on real and synthetic datasets corroborate that the proposed approach consistently yields more efficient prediction sets while maintaining valid coverage, outperforming alternative methods.", "published": "2024-11-07 05:00:00", "id": "cd08feb7-9041-42cf-828d-1086473127f2", "source": "arxiv", "section": "computerScience"}, {"title": "LEGATO: Cross-Embodiment Imitation Using a Grasping Tool", "link": "https://arxiv.org/abs/2411.03682", "description": "arXiv:2411.03682v1 Announce Type: new \nAbstract: Cross-embodiment imitation learning enables policies trained on specific embodiments to transfer across different robots, unlocking the potential for large-scale imitation learning that is both cost-effective and highly reusable. This paper presents LEGATO, a cross-embodiment imitation learning framework for visuomotor skill transfer across varied kinematic morphologies. We introduce a handheld gripper that unifies action and observation spaces, allowing tasks to be defined consistently across robots. Using this gripper, we train visuomotor policies via imitation learning, applying a motion-invariant transformation to compute the training loss. Gripper motions are then retargeted into high-degree-of-freedom whole-body motions using inverse kinematics for deployment across diverse embodiments. Our evaluations in simulation and real-robot experiments highlight the framework's effectiveness in learning and transferring visuomotor skills across various robots. More information can be found at the project page: https://ut-hcrl.github.io/LEGATO.", "published": "2024-11-07 05:00:00", "id": "3e2a1655-38af-4ef4-9397-8b228e22d92f", "source": "arxiv", "section": "computerScience"}, {"title": "Learn to Slice, Slice to Learn: Unveiling Online Optimization and Reinforcement Learning for Slicing AI Services", "link": "https://arxiv.org/abs/2411.03686", "description": "arXiv:2411.03686v1 Announce Type: new \nAbstract: In the face of increasing demand for zero-touch networks to automate network management and operations, two pivotal concepts have emerged: \"Learn to Slice\" (L2S) and \"Slice to Learn\" (S2L). L2S involves leveraging Artificial intelligence (AI) techniques to optimize network slicing for general services, while S2L centers on tailoring network slices to meet the specific needs of various AI services. The complexity of optimizing and automating S2L surpasses that of L2S due to intricate AI services' requirements, such as handling uncontrollable parameters, learning in adversarial conditions, and achieving long-term performance goals. This paper aims to automate and optimize S2L by integrating the two concepts of L2S and S2L by using an intelligent slicing agent to solve S2L. Indeed, we choose two candidate slicing agents, namely the Exploration and Exploitation (EXP3) and Deep Q-Network (DQN) from the Online Convex Optimization (OCO) and Deep Reinforcement Learning (DRL) frameworks, and compare them. Our evaluation involves a series of carefully designed experiments that offer valuable insights into the strengths and limitations of EXP3 and DQN in slicing for AI services, thereby contributing to the advancement of zero-touch network capabilities.", "published": "2024-11-07 05:00:00", "id": "7a11be3a-de42-49fc-9ceb-7bd165ce0c1a", "source": "arxiv", "section": "computerScience"}, {"title": "Beyond Model Adaptation at Test Time: A Survey", "link": "https://arxiv.org/abs/2411.03687", "description": "arXiv:2411.03687v1 Announce Type: new \nAbstract: Machine learning algorithms have achieved remarkable success across various disciplines, use cases and applications, under the prevailing assumption that training and test samples are drawn from the same distribution. Consequently, these algorithms struggle and become brittle even when samples in the test distribution start to deviate from the ones observed during training. Domain adaptation and domain generalization have been studied extensively as approaches to address distribution shifts across test and train domains, but each has its limitations. Test-time adaptation, a recently emerging learning paradigm, combines the benefits of domain adaptation and domain generalization by training models only on source data and adapting them to target data during test-time inference. In this survey, we provide a comprehensive and systematic review on test-time adaptation, covering more than 400 recent papers. We structure our review by categorizing existing methods into five distinct categories based on what component of the method is adjusted for test-time adaptation: the model, the inference, the normalization, the sample, or the prompt, providing detailed analysis of each. We further discuss the various preparation and adaptation settings for methods within these categories, offering deeper insights into the effective deployment for the evaluation of distribution shifts and their real-world application in understanding images, video and 3D, as well as modalities beyond vision. We close the survey with an outlook on emerging research opportunities for test-time adaptation.", "published": "2024-11-07 05:00:00", "id": "5f40b9a3-c8b4-4c1e-8659-f8e32e77b725", "source": "arxiv", "section": "computerScience"}, {"title": "Where Do We Stand with Implicit Neural Representations? A Technical and Performance Survey", "link": "https://arxiv.org/abs/2411.03688", "description": "arXiv:2411.03688v1 Announce Type: new \nAbstract: Implicit Neural Representations (INRs) have emerged as a paradigm in knowledge representation, offering exceptional flexibility and performance across a diverse range of applications. INRs leverage multilayer perceptrons (MLPs) to model data as continuous implicit functions, providing critical advantages such as resolution independence, memory efficiency, and generalisation beyond discretised data structures. Their ability to solve complex inverse problems makes them particularly effective for tasks including audio reconstruction, image representation, 3D object reconstruction, and high-dimensional data synthesis. This survey provides a comprehensive review of state-of-the-art INR methods, introducing a clear taxonomy that categorises them into four key areas: activation functions, position encoding, combined strategies, and network structure optimisation. We rigorously analyse their critical properties, such as full differentiability, smoothness, compactness, and adaptability to varying resolutions while also examining their strengths and limitations in addressing locality biases and capturing fine details. Our experimental comparison offers new insights into the trade-offs between different approaches, showcasing the capabilities and challenges of the latest INR techniques across various tasks. In addition to identifying areas where current methods excel, we highlight key limitations and potential avenues for improvement, such as developing more expressive activation functions, enhancing positional encoding mechanisms, and improving scalability for complex, high-dimensional data. This survey serves as a roadmap for researchers, offering practical guidance for future exploration in the field of INRs. We aim to foster new methodologies by outlining promising research directions for INRs and applications.", "published": "2024-11-07 05:00:00", "id": "5afaefe2-e048-4d75-844a-d759059ff87d", "source": "arxiv", "section": "computerScience"}, {"title": "An efficient scheme for approximating long-time dynamics of a class of non-linear models", "link": "https://arxiv.org/abs/2411.03689", "description": "arXiv:2411.03689v1 Announce Type: new \nAbstract: We propose a novel, highly efficient, second-order accurate, long-time unconditionally stable numerical scheme for a class of finite-dimensional nonlinear models that are of importance in geophysical fluid dynamics. The scheme is highly efficient in the sense that only a (fixed) symmetric positive definite linear problem (with varying right hand sides) is involved at each time-step. The solutions to the scheme are uniformly bounded for all time. We show that the scheme is able to capture the long-time dynamics of the underlying geophysical model, with the global attractors as well as the invariant measures of the scheme converge to those of the original model as the step size approaches zero. In our numerical experiments, we take an indirect approach, using long-term statistics to approximate the invariant measures. Our results suggest that the convergence rate of the long-term statistics, as a function of terminal time, is approximately first order using the Jensen-Shannon metric and half-order using the L1 metric. This implies that very long time simulation is needed in order to capture a few significant digits of long time statistics (climate) correct. Nevertheless, the second order scheme's performance remains superior to that of the first order one, requiring significantly less time to reach a small neighborhood of statistical equilibrium for a given step size.", "published": "2024-11-07 05:00:00", "id": "1a14b5e9-9022-4949-9e32-15d97c5cd366", "source": "arxiv", "section": "computerScience"}, {"title": "AMNCutter: Affinity-Attention-Guided Multi-View Normalized Cutter for Unsupervised Surgical Instrument Segmentation", "link": "https://arxiv.org/abs/2411.03695", "description": "arXiv:2411.03695v1 Announce Type: new \nAbstract: Surgical instrument segmentation (SIS) is pivotal for robotic-assisted minimally invasive surgery, assisting surgeons by identifying surgical instruments in endoscopic video frames. Recent unsupervised surgical instrument segmentation (USIS) methods primarily rely on pseudo-labels derived from low-level features such as color and optical flow, but these methods show limited effectiveness and generalizability in complex and unseen endoscopic scenarios. In this work, we propose a label-free unsupervised model featuring a novel module named Multi-View Normalized Cutter (m-NCutter). Different from previous USIS works, our model is trained using a graph-cutting loss function that leverages patch affinities for supervision, eliminating the need for pseudo-labels. The framework adaptively determines which affinities from which levels should be prioritized. Therefore, the low- and high-level features and their affinities are effectively integrated to train a label-free unsupervised model, showing superior effectiveness and generalization ability. We conduct comprehensive experiments across multiple SIS datasets to validate our approach's state-of-the-art (SOTA) performance, robustness, and exceptional potential as a pre-trained model. Our code is released at https://github.com/MingyuShengSMY/AMNCutter.", "published": "2024-11-07 05:00:00", "id": "e3cc2e27-42ed-4401-9f87-803a007268c2", "source": "arxiv", "section": "computerScience"}, {"title": "OccLoff: Learning Optimized Feature Fusion for 3D Occupancy Prediction", "link": "https://arxiv.org/abs/2411.03696", "description": "arXiv:2411.03696v1 Announce Type: new \nAbstract: 3D semantic occupancy prediction is crucial for finely representing the surrounding environment, which is essential for ensuring the safety in autonomous driving. Existing fusion-based occupancy methods typically involve performing a 2D-to-3D view transformation on image features, followed by computationally intensive 3D operations to fuse these with LiDAR features, leading to high computational costs and reduced accuracy. Moreover, current research on occupancy prediction predominantly focuses on designing specific network architectures, often tailored to particular models, with limited attention given to the more fundamental aspect of semantic feature learning. This gap hinders the development of more transferable methods that could enhance the performance of various occupancy models. To address these challenges, we propose OccLoff, a framework that Learns to Optimize Feature Fusion for 3D occupancy prediction. Specifically, we introduce a sparse fusion encoder with entropy masks that directly fuses 3D and 2D features, improving model accuracy while reducing computational overhead. Additionally, we propose a transferable proxy-based loss function and an adaptive hard sample weighting algorithm, which enhance the performance of several state-of-the-art methods. Extensive evaluations on the nuScenes and SemanticKITTI benchmarks demonstrate the superiority of our framework, and ablation studies confirm the effectiveness of each proposed module.", "published": "2024-11-07 05:00:00", "id": "cd817042-b06b-49a9-aa69-75cb71f2f1e1", "source": "arxiv", "section": "computerScience"}, {"title": "TATAA: Programmable Mixed-Precision Transformer Acceleration with a Transformable Arithmetic Architecture", "link": "https://arxiv.org/abs/2411.03697", "description": "arXiv:2411.03697v1 Announce Type: new \nAbstract: Modern transformer-based deep neural networks present unique technical challenges for effective acceleration in real-world applications. Apart from the vast amount of linear operations needed due to their sizes, modern transformer models are increasingly reliance on precise non-linear computations that make traditional low-bitwidth quantization methods and fixed-dataflow matrix accelerators ineffective for end-to-end acceleration. To address this need to accelerate both linear and non-linear operations in a unified and programmable framework, this paper introduces TATAA. TATAA employs 8-bit integer (int8) arithmetic for quantized linear layer operations through post-training quantization, while it relies on bfloat16 floating-point arithmetic to approximate non-linear layers of a transformer model. TATAA hardware features a transformable arithmetic architecture that supports both formats during runtime with minimal overhead, enabling it to switch between a systolic array mode for int8 matrix multiplications and a SIMD mode for vectorized bfloat16 operations. An end-to-end compiler is presented to enable flexible mapping from emerging transformer models to the proposed hardware. Experimental results indicate that our mixed-precision design incurs only 0.14% to 1.16% accuracy drop when compared with the pre-trained single-precision transformer models across a range of vision, language, and generative text applications. Our prototype implementation on the Alveo U280 FPGA currently achieves 2935.2 GOPS throughput on linear layers and a maximum of 189.5 GFLOPS for non-linear operations, outperforming related works by up to 1.45x in end-to-end throughput and 2.29x in DSP efficiency, while achieving 2.19x higher power efficiency than modern NVIDIA RTX4090 GPU.", "published": "2024-11-07 05:00:00", "id": "2861ce43-7182-4060-86cb-2e02726d57c2", "source": "arxiv", "section": "computerScience"}, {"title": "The Root Shapes the Fruit: On the Persistence of Gender-Exclusive Harms in Aligned Language Models", "link": "https://arxiv.org/abs/2411.03700", "description": "arXiv:2411.03700v1 Announce Type: new \nAbstract: Natural-language assistants are designed to provide users with helpful responses while avoiding harmful outputs, largely achieved through alignment to human preferences. Yet there is limited understanding of whether alignment techniques may inadvertently perpetuate or even amplify harmful biases inherited from their pre-aligned base models. This issue is compounded by the choice of bias evaluation benchmarks in popular preference-finetuned models, which predominantly focus on dominant social categories, such as binary gender, thereby limiting insights into biases affecting underrepresented groups. Towards addressing this gap, we center transgender, nonbinary, and other gender-diverse identities to investigate how alignment procedures interact with pre-existing gender-diverse bias in LLMs. Our key contributions include: 1) a comprehensive survey of bias evaluation modalities across leading preference-finetuned LLMs, highlighting critical gaps in gender-diverse representation, 2) systematic evaluation of gender-diverse biases across 12 models spanning Direct Preference Optimization (DPO) stages, uncovering harms popular bias benchmarks fail to detect, and 3) a flexible framework for measuring harmful biases in implicit reward signals applicable to other social contexts. Our findings reveal that DPO-aligned models are particularly sensitive to supervised finetuning (SFT), and can amplify two forms of real-world gender-diverse harms from their base models: stigmatization and gender non-affirmative language. We conclude with recommendations tailored to DPO and broader alignment practices, advocating for the adoption of community-informed bias evaluation frameworks to more effectively identify and address underrepresented harms in LLMs.", "published": "2024-11-07 05:00:00", "id": "877b2435-bfa5-4686-b3c7-ba8e3cdfb8e0", "source": "arxiv", "section": "computerScience"}, {"title": "The Essence of the Essence from the Web:The Metasearch Engine", "link": "https://arxiv.org/abs/2411.03701", "description": "arXiv:2411.03701v1 Announce Type: new \nAbstract: The exponential growth of information source on the web and in turn continuing technological progress of searching the information by using tools like Search Engines gives rise to many problems for the user to know which tool is best for their query and which tool is not. At this time Metasearch Engine comes into play by reducing the user burden by dispatching queries to multiple search engines in parallel and refining the results of these search engines to give the best out of best by doing superior job on their side. These engines do not own a database of Web pages rather they send search terms to the databases maintained by the search engine companies, get back results from all the search engines queried and then compile the results to be presented to the user. In this paper, we describe the working of a typical metasearch engine and then present a comparative study of traditional search engines and metasearch engines on the basis of different parameters and show how metasearch engines are better than the other search engines.", "published": "2024-11-07 05:00:00", "id": "8293112b-eb02-4957-bb45-79fe61d1c27a", "source": "arxiv", "section": "computerScience"}, {"title": "Graph-Based Multi-Modal Sensor Fusion for Autonomous Driving", "link": "https://arxiv.org/abs/2411.03702", "description": "arXiv:2411.03702v1 Announce Type: new \nAbstract: The growing demand for robust scene understanding in mobile robotics and autonomous driving has highlighted the importance of integrating multiple sensing modalities. By combining data from diverse sensors like cameras and LIDARs, fusion techniques can overcome the limitations of individual sensors, enabling a more complete and accurate perception of the environment. We introduce a novel approach to multi-modal sensor fusion, focusing on developing a graph-based state representation that supports critical decision-making processes in autonomous driving. We present a Sensor-Agnostic Graph-Aware Kalman Filter [3], the first online state estimation technique designed to fuse multi-modal graphs derived from noisy multi-sensor data. The estimated graph-based state representations serve as a foundation for advanced applications like Multi-Object Tracking (MOT), offering a comprehensive framework for enhancing the situational awareness and safety of autonomous systems. We validate the effectiveness of our proposed framework through extensive experiments conducted on both synthetic and real-world driving datasets (nuScenes). Our results showcase an improvement in MOTA and a reduction in estimated position errors (MOTP) and identity switches (IDS) for tracked objects using the SAGA-KF. Furthermore, we highlight the capability of such a framework to develop methods that can leverage heterogeneous information (like semantic objects and geometric structures) from various sensing modalities, enabling a more holistic approach to scene understanding and enhancing the safety and effectiveness of autonomous systems.", "published": "2024-11-07 05:00:00", "id": "42086d0a-9bb2-462c-a201-066c5e6ff70e", "source": "arxiv", "section": "computerScience"}, {"title": "3DGS-CD: 3D Gaussian Splatting-based Change Detection for Physical Object Rearrangement", "link": "https://arxiv.org/abs/2411.03706", "description": "arXiv:2411.03706v1 Announce Type: new \nAbstract: We present 3DGS-CD, the first 3D Gaussian Splatting (3DGS)-based method for detecting physical object rearrangements in 3D scenes. Our approach estimates 3D object-level changes by comparing two sets of unaligned images taken at different times. Leveraging 3DGS's novel view rendering and EfficientSAM's zero-shot segmentation capabilities, we detect 2D object-level changes, which are then associated and fused across views to estimate 3D changes. Our method can detect changes in cluttered environments using sparse post-change images within as little as 18s, using as few as a single new image. It does not rely on depth input, user instructions, object classes, or object models -- An object is recognized simply if it has been re-arranged. Our approach is evaluated on both public and self-collected real-world datasets, achieving up to 14% higher accuracy and three orders of magnitude faster performance compared to the state-of-the-art radiance-field-based change detection method. This significant performance boost enables a broad range of downstream applications, where we highlight three key use cases: object reconstruction, robot workspace reset, and 3DGS model update. Our code and data will be made available at https://github.com/520xyxyzq/3DGS-CD.", "published": "2024-11-07 05:00:00", "id": "de251751-a5e5-4b30-afae-f82f2b9b423b", "source": "arxiv", "section": "computerScience"}, {"title": "Fine-Tuning Vision-Language Model for Automated Engineering Drawing Information Extraction", "link": "https://arxiv.org/abs/2411.03707", "description": "arXiv:2411.03707v1 Announce Type: new \nAbstract: Geometric Dimensioning and Tolerancing (GD&amp;T) plays a critical role in manufacturing by defining acceptable variations in part features to ensure component quality and functionality. However, extracting GD&amp;T information from 2D engineering drawings is a time-consuming and labor-intensive task, often relying on manual efforts or semi-automated tools. To address these challenges, this study proposes an automated and computationally efficient GD&amp;T extraction method by fine-tuning Florence-2, an open-source vision-language model (VLM). The model is trained on a dataset of 400 drawings with ground truth annotations provided by domain experts. For comparison, two state-of-the-art closed-source VLMs, GPT-4o and Claude-3.5-Sonnet, are evaluated on the same dataset. All models are assessed using precision, recall, F1-score, and hallucination metrics. Due to the computational cost and impracticality of fine-tuning large closed-source VLMs for domain-specific tasks, GPT-4o and Claude-3.5-Sonnet are evaluated in a zero-shot setting. In contrast, Florence-2, a smaller model with 0.23 billion parameters, is optimized through full-parameter fine-tuning across three distinct experiments, each utilizing datasets augmented to different levels. The results show that Florence-2 achieves a 29.95% increase in precision, a 37.75% increase in recall, a 52.40% improvement in F1-score, and a 43.15% reduction in hallucination rate compared to the best-performing closed-source model. These findings highlight the effectiveness of fine-tuning smaller, open-source VLMs like Florence-2, offering a practical and efficient solution for automated GD&amp;T extraction to support downstream manufacturing tasks.", "published": "2024-11-07 05:00:00", "id": "ba29d23a-8b3f-464c-916d-e057dac02d09", "source": "arxiv", "section": "computerScience"}, {"title": "Evaluating Eye Tracking Signal Quality with Real-time Gaze Interaction Simulation", "link": "https://arxiv.org/abs/2411.03708", "description": "arXiv:2411.03708v1 Announce Type: new \nAbstract: We present a real-time gaze-based interaction simulation methodology using an offline dataset to evaluate the eye-tracking signal quality. This study employs three fundamental eye-movement classification algorithms to identify physiological fixations from the eye-tracking data. We introduce the Rank-1 fixation selection approach to identify the most stable fixation period nearest to a target, referred to as the trigger-event. Our evaluation explores how varying constraints impact the definition of trigger-events and evaluates the eye-tracking signal quality of defined trigger-events. Results show that while the dispersion threshold-based algorithm identifies trigger-events more accurately, the Kalman filter-based classification algorithm performs better in eye-tracking signal quality, as demonstrated through a user-centric quality assessment using user- and error-percentile tiers. Despite median user-level performance showing minor differences across algorithms, significant variability in signal quality across participants highlights the importance of algorithm selection to ensure system reliability.", "published": "2024-11-07 05:00:00", "id": "e5d0534a-2090-40bb-a0a1-a4d20c7971a5", "source": "arxiv", "section": "computerScience"}, {"title": "AutoGameUI: Constructing High-Fidelity Game UIs via Multimodal Learning and Interactive Web-Based Tool", "link": "https://arxiv.org/abs/2411.03709", "description": "arXiv:2411.03709v1 Announce Type: new \nAbstract: We introduce an innovative system, AutoGameUI, for efficiently constructing cohesive user interfaces in game development. Our system is the first to address the coherence issue arising from integrating inconsistent UI and UX designs, typically leading to mismatches and inefficiencies. We propose a two-stage multimodal learning pipeline to obtain comprehensive representations of both UI and UX designs, and to establish their correspondences. Through the correspondences, a cohesive user interface is automatically constructed from pairwise designs. To achieve high-fidelity effects, we introduce a universal data protocol for precise design descriptions and cross-platform applications. We also develop an interactive web-based tool for game developers to facilitate the use of our system. We create a game UI dataset from actual game projects and combine it with a public dataset for training and evaluation. Our experimental results demonstrate the effectiveness of our system in maintaining coherence between the constructed interfaces and the original designs.", "published": "2024-11-07 05:00:00", "id": "24ba5bdd-38e5-4e98-8e50-77cd8834260e", "source": "arxiv", "section": "computerScience"}, {"title": "Generalized Trusted Multi-view Classification Framework with Hierarchical Opinion Aggregation", "link": "https://arxiv.org/abs/2411.03713", "description": "arXiv:2411.03713v1 Announce Type: new \nAbstract: Recently, multi-view learning has witnessed a considerable interest on the research of trusted decision-making. Previous methods are mainly inspired from an important paper published by Han et al. in 2021, which formulates a Trusted Multi-view Classification (TMC) framework that aggregates evidence from different views based on Dempster's combination rule. All these methods only consider inter-view aggregation, yet lacking exploitation of intra-view information. In this paper, we propose a generalized trusted multi-view classification framework with hierarchical opinion aggregation. This hierarchical framework includes a two-phase aggregation process: the intra-view and inter-view aggregation hierarchies. In the intra aggregation, we assume that each view is comprised of common information shared with other views, as well as its specific information. We then aggregate both the common and specific information. This aggregation phase is useful to eliminate the feature noise inherent to view itself, thereby improving the view quality. In the inter-view aggregation, we design an attention mechanism at the evidence level to facilitate opinion aggregation from different views. To the best of our knowledge, this is one of the pioneering efforts to formulate a hierarchical aggregation framework in the trusted multi-view learning domain. Extensive experiments show that our model outperforms some state-of-art trust-related baselines.", "published": "2024-11-07 05:00:00", "id": "1d79855c-b25c-4993-bbd9-9f39108d9a90", "source": "arxiv", "section": "computerScience"}, {"title": "Explaining Human Activity Recognition with SHAP: Validating Insights with Perturbation and Quantitative Measures", "link": "https://arxiv.org/abs/2411.03714", "description": "arXiv:2411.03714v1 Announce Type: new \nAbstract: In Human Activity Recognition (HAR), understanding the intricacy of body movements within high-risk applications is essential. This study uses SHapley Additive exPlanations (SHAP) to explain the decision-making process of Graph Convolution Networks (GCNs) when classifying activities with skeleton data. We employ SHAP to explain two real-world datasets: one for cerebral palsy (CP) classification and the widely used NTU RGB+D 60 action recognition dataset. To test the explanation, we introduce a novel perturbation approach that modifies the model's edge importance matrix, allowing us to evaluate the impact of specific body key points on prediction outcomes. To assess the fidelity of our explanations, we employ informed perturbation, targeting body key points identified as important by SHAP and comparing them against random perturbation as a control condition. This perturbation enables a judgment on whether the body key points are truly influential or non-influential based on the SHAP values. Results on both datasets show that body key points identified as important through SHAP have the largest influence on the accuracy, specificity, and sensitivity metrics. Our findings highlight that SHAP can provide granular insights into the input feature contribution to the prediction outcome of GCNs in HAR tasks. This demonstrates the potential for more interpretable and trustworthy models in high-stakes applications like healthcare or rehabilitation.", "published": "2024-11-07 05:00:00", "id": "e0f75e97-87cc-4bc7-bff9-6d8d0c12659f", "source": "arxiv", "section": "computerScience"}, {"title": "MOS-Bench: Benchmarking Generalization Abilities of Subjective Speech Quality Assessment Models", "link": "https://arxiv.org/abs/2411.03715", "description": "arXiv:2411.03715v1 Announce Type: new \nAbstract: Subjective speech quality assessment (SSQA) is critical for evaluating speech samples as perceived by human listeners. While model-based SSQA has enjoyed great success thanks to the development of deep neural networks (DNNs), generalization remains a key challenge, especially for unseen, out-of-domain data. To benchmark the generalization abilities of SSQA models, we present MOS-Bench, a diverse collection of datasets. In addition, we also introduce SHEET, an open-source toolkit containing complete recipes to conduct SSQA experiments. We provided benchmark results for MOS-Bench, and we also explored multi-dataset training to enhance generalization. Additionally, we proposed a new performance metric, best score difference/ratio, and used latent space visualizations to explain model behavior, offering valuable insights for future research.", "published": "2024-11-07 05:00:00", "id": "ac3bcca6-3bb8-4178-b7b0-fbb345eeea0a", "source": "arxiv", "section": "computerScience"}, {"title": "These Maps Are Made by Propagation: Adapting Deep Stereo Networks to Road Scenarios with Decisive Disparity Diffusion", "link": "https://arxiv.org/abs/2411.03717", "description": "arXiv:2411.03717v1 Announce Type: new \nAbstract: Stereo matching has emerged as a cost-effective solution for road surface 3D reconstruction, garnering significant attention towards improving both computational efficiency and accuracy. This article introduces decisive disparity diffusion (D3Stereo), marking the first exploration of dense deep feature matching that adapts pre-trained deep convolutional neural networks (DCNNs) to previously unseen road scenarios. A pyramid of cost volumes is initially created using various levels of learned representations. Subsequently, a novel recursive bilateral filtering algorithm is employed to aggregate these costs. A key innovation of D3Stereo lies in its alternating decisive disparity diffusion strategy, wherein intra-scale diffusion is employed to complete sparse disparity images, while inter-scale inheritance provides valuable prior information for higher resolutions. Extensive experiments conducted on our created UDTIRI-Stereo and Stereo-Road datasets underscore the effectiveness of D3Stereo strategy in adapting pre-trained DCNNs and its superior performance compared to all other explicit programming-based algorithms designed specifically for road surface 3D reconstruction. Additional experiments conducted on the Middlebury dataset with backbone DCNNs pre-trained on the ImageNet database further validate the versatility of D3Stereo strategy in tackling general stereo matching problems.", "published": "2024-11-07 05:00:00", "id": "97f6b0d9-9cf9-46fe-a5a6-4acc07b4ad2e", "source": "arxiv", "section": "computerScience"}, {"title": "Estimation of Psychosocial Work Environment Exposures Through Video Object Detection. Proof of Concept Using CCTV Footage", "link": "https://arxiv.org/abs/2411.03724", "description": "arXiv:2411.03724v1 Announce Type: new \nAbstract: This paper examines the use of computer vision algorithms to estimate aspects of the psychosocial work environment using CCTV footage. We present a proof of concept for a methodology that detects and tracks people in video footage and estimates interactions between customers and employees by estimating their poses and calculating the duration of their encounters. We propose a pipeline that combines existing object detection and tracking algorithms (YOLOv8 and DeepSORT) with pose estimation algorithms (BlazePose) to estimate the number of customers and employees in the footage as well as the duration of their encounters. We use a simple rule-based approach to classify the interactions as positive, neutral or negative based on three different criteria: distance, duration and pose. The proposed methodology is tested on a small dataset of CCTV footage. While the data is quite limited in particular with respect to the quality of the footage, we have chosen this case as it represents a typical setting where the method could be applied. The results show that the object detection and tracking part of the pipeline has a reasonable performance on the dataset with a high degree of recall and reasonable accuracy. At this stage, the pose estimation is still limited to fully detect the type of interactions due to difficulties in tracking employees in the footage. We conclude that the method is a promising alternative to self-reported measures of the psychosocial work environment and could be used in future studies to obtain external observations of the work environment.", "published": "2024-11-07 05:00:00", "id": "2538b351-1d94-4518-8d22-aaf94f04efd5", "source": "arxiv", "section": "computerScience"}, {"title": "PX2Tooth: Reconstructing the 3D Point Cloud Teeth from a Single Panoramic X-ray", "link": "https://arxiv.org/abs/2411.03725", "description": "arXiv:2411.03725v1 Announce Type: new \nAbstract: Reconstructing the 3D anatomical structures of the oral cavity, which originally reside in the cone-beam CT (CBCT), from a single 2D Panoramic X-ray(PX) remains a critical yet challenging task, as it can effectively reduce radiation risks and treatment costs during the diagnostic in digital dentistry. However, current methods are either error-prone or only trained/evaluated on small-scale datasets (less than 50 cases), resulting in compromised trustworthiness. In this paper, we propose PX2Tooth, a novel approach to reconstruct 3D teeth using a single PX image with a two-stage framework. First, we design the PXSegNet to segment the permanent teeth from the PX images, providing clear positional, morphological, and categorical information for each tooth. Subsequently, we design a novel tooth generation network (TGNet) that learns to transform random point clouds into 3D teeth. TGNet integrates the segmented patch information and introduces a Prior Fusion Module (PFM) to enhance the generation quality, especially in the root apex region. Moreover, we construct a dataset comprising 499 pairs of CBCT and Panoramic X-rays. Extensive experiments demonstrate that PX2Tooth can achieve an Intersection over Union (IoU) of 0.793, significantly surpassing previous methods, underscoring the great potential of artificial intelligence in digital dentistry.", "published": "2024-11-07 05:00:00", "id": "dcabf793-6580-4f01-b98c-9b515f6c204a", "source": "arxiv", "section": "computerScience"}, {"title": "PropNEAT -- Efficient GPU-Compatible Backpropagation over NeuroEvolutionary Augmenting Topology Networks", "link": "https://arxiv.org/abs/2411.03726", "description": "arXiv:2411.03726v1 Announce Type: new \nAbstract: We introduce PropNEAT, a fast backpropagation implementation of NEAT that uses a bidirectional mapping of the genome graph to a layer-based architecture that preserves the NEAT genomes whilst enabling efficient GPU backpropagation. We test PropNEAT on 58 binary classification datasets from the Penn Machine Learning Benchmarks database, comparing the performance against logistic regression, dense neural networks and random forests, as well as a densely retrained variant of the final PropNEAT model. PropNEAT had the second best overall performance, behind Random Forest, though the difference between the models was not statistically significant apart from between Random Forest in comparison with logistic regression and the PropNEAT retrain models. PropNEAT was substantially faster than a naive backpropagation method, and both were substantially faster and had better performance than the original NEAT implementation. We demonstrate that the per-epoch training time for PropNEAT scales linearly with network depth, and is efficient on GPU implementations for backpropagation. This implementation could be extended to support reinforcement learning or convolutional networks, and is able to find sparser and smaller networks with potential for applications in low-power contexts.", "published": "2024-11-07 05:00:00", "id": "150d0543-829c-4c1a-8a4e-52afbf2e7925", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient Fourier Filtering Network with Contrastive Learning for UAV-based Unaligned Bi-modal Salient Object Detection", "link": "https://arxiv.org/abs/2411.03728", "description": "arXiv:2411.03728v1 Announce Type: new \nAbstract: Unmanned aerial vehicle (UAV)-based bi-modal salient object detection (BSOD) aims to segment salient objects in a scene utilizing complementary cues in unaligned RGB and thermal image pairs. However, the high computational expense of existing UAV-based BSOD models limits their applicability to real-world UAV devices. To address this problem, we propose an efficient Fourier filter network with contrastive learning that achieves both real-time and accurate performance. Specifically, we first design a semantic contrastive alignment loss to align the two modalities at the semantic level, which facilitates mutual refinement in a parameter-free way. Second, inspired by the fast Fourier transform that obtains global relevance in linear complexity, we propose synchronized alignment fusion, which aligns and fuses bi-modal features in the channel and spatial dimensions by a hierarchical filtering mechanism. Our proposed model, AlignSal, reduces the number of parameters by 70.0%, decreases the floating point operations by 49.4%, and increases the inference speed by 152.5% compared to the cutting-edge BSOD model (i.e., MROS). Extensive experiments on the UAV RGB-T 2400 and three weakly aligned datasets demonstrate that AlignSal achieves both real-time inference speed and better performance and generalizability compared to sixteen state-of-the-art BSOD models across most evaluation metrics. In addition, our ablation studies further verify AlignSal's potential in boosting the performance of existing aligned BSOD models on UAV-based unaligned data. The code is available at: https://github.com/JoshuaLPF/AlignSal.", "published": "2024-11-07 05:00:00", "id": "2bca686d-87e2-463d-a7d6-32c9cb7f8f9b", "source": "arxiv", "section": "computerScience"}, {"title": "Relation Learning and Aggregate-attention for Multi-person Motion Prediction", "link": "https://arxiv.org/abs/2411.03729", "description": "arXiv:2411.03729v1 Announce Type: new \nAbstract: Multi-person motion prediction is an emerging and intricate task with broad real-world applications. Unlike single person motion prediction, it considers not just the skeleton structures or human trajectories but also the interactions between others. Previous methods use various networks to achieve impressive predictions but often overlook that the joints relations within an individual (intra-relation) and interactions among groups (inter-relation) are distinct types of representations. These methods often lack explicit representation of inter&amp;intra-relations, and inevitably introduce undesired dependencies. To address this issue, we introduce a new collaborative framework for multi-person motion prediction that explicitly modeling these relations:a GCN-based network for intra-relations and a novel reasoning network for inter-relations.Moreover, we propose a novel plug-and-play aggregation module called the Interaction Aggregation Module (IAM), which employs an aggregate-attention mechanism to seamlessly integrate these relations. Experiments indicate that the module can also be applied to other dual-path models. Extensive experiments on the 3DPW, 3DPW-RC, CMU-Mocap, MuPoTS-3D, as well as synthesized datasets Mix1 & Mix2 (9 to 15 persons), demonstrate that our method achieves state-of-the-art performance.", "published": "2024-11-07 05:00:00", "id": "ac8dd15c-54dc-4418-8b21-5e2bc4776f18", "source": "arxiv", "section": "computerScience"}, {"title": "NeurIPS 2023 Competition: Privacy Preserving Federated Learning Document VQA", "link": "https://arxiv.org/abs/2411.03730", "description": "arXiv:2411.03730v1 Announce Type: new \nAbstract: The Privacy Preserving Federated Learning Document VQA (PFL-DocVQA) competition challenged the community to develop provably private and communication-efficient solutions in a federated setting for a real-life use case: invoice processing. The competition introduced a dataset of real invoice documents, along with associated questions and answers requiring information extraction and reasoning over the document images. Thereby, it brings together researchers and expertise from the document analysis, privacy, and federated learning communities. Participants fine-tuned a pre-trained, state-of-the-art Document Visual Question Answering model provided by the organizers for this new domain, mimicking a typical federated invoice processing setup. The base model is a multi-modal generative language model, and sensitive information could be exposed through either the visual or textual input modality. Participants proposed elegant solutions to reduce communication costs while maintaining a minimum utility threshold in track 1 and to protect all information from each document provider using differential privacy in track 2. The competition served as a new testbed for developing and testing private federated learning methods, simultaneously raising awareness about privacy within the document image analysis and recognition community. Ultimately, the competition analysis provides best practices and recommendations for successfully running privacy-focused federated learning challenges in the future.", "published": "2024-11-07 05:00:00", "id": "078f0582-e5d4-4992-9d5d-a88739d1147d", "source": "arxiv", "section": "computerScience"}, {"title": "Reducing Hyperparameter Tuning Costs in ML, Vision and Language Model Training Pipelines via Memoization-Awareness", "link": "https://arxiv.org/abs/2411.03731", "description": "arXiv:2411.03731v1 Announce Type: new \nAbstract: The training or fine-tuning of machine learning, vision, and language models is often implemented as a pipeline: a sequence of stages encompassing data preparation, model training and evaluation. In this paper, we exploit pipeline structures to reduce the cost of hyperparameter tuning for model training/fine-tuning, which is particularly valuable for language models given their high costs in GPU-days. We propose a \"memoization-aware\" Bayesian Optimization (BO) algorithm, EEIPU, that works in tandem with a pipeline caching system, allowing it to evaluate significantly more hyperparameter candidates per GPU-day than other tuning algorithms. The result is better-quality hyperparameters in the same amount of search time, or equivalently, reduced search time to reach the same hyperparameter quality. In our benchmarks on machine learning (model ensembles), vision (convolutional architecture) and language (T5 architecture) pipelines, we compare EEIPU against recent BO algorithms: EEIPU produces an average of $103\\%$ more hyperparameter candidates (within the same budget), and increases the validation metric by an average of $108\\%$ more than other algorithms (where the increase is measured starting from the end of warm-up iterations).", "published": "2024-11-07 05:00:00", "id": "1d551a26-a488-4cde-bda3-c5ab1db0e833", "source": "arxiv", "section": "computerScience"}, {"title": "Static structural behaviour of wire bearings: comparison with conventional bearings and study of design and operational parameters", "link": "https://arxiv.org/abs/2411.03736", "description": "arXiv:2411.03736v1 Announce Type: new \nAbstract: In wire bearings the rolling process occurs on raceways machined on steel wires, and the rings are made of light materials such as aluminium. This particular architecture provides both weight and inertia savings, but also significantly different behaviour with respect to conventional bearings. For this reason, specific design and analysis tools must be developed; as a first step, this work uses Finite Element models to study the influence of different parameters on the static structural response of wire bearings. Thus, bearing stiffness, load capacity and contact status (contact force and angle, and ellipse truncation) have been evaluated for several combinations of conformity, friction coefficient and boundary conditions. The results have been compared with an equivalent conventional bearing, shedding light on the main structural features of wire bearings.", "published": "2024-11-07 05:00:00", "id": "73e0720a-e29b-4549-b0ba-0c756c843e99", "source": "arxiv", "section": "computerScience"}, {"title": "Wire twisting stiffness modelling with application in wire race ball bearings. Derivation of analytical formula and Finite Element validation", "link": "https://arxiv.org/abs/2411.03737", "description": "arXiv:2411.03737v1 Announce Type: new \nAbstract: Since Erich Franke produced the first wire race bearings in 1934, they have not been used profusely until these last years in applications such as computerized tomography, X-ray machines, wheels with direct drive... where low weight and inertia constraints are important. Accounting for the structural behaviour of the bearing, there exist a key phenomenon not present in other kind of more known bearings, which is the wire twisting under load; this wire twisting steers the force transmission among the bearing rings and the rolling elements. In this sense, for design and selection purposes, if a complete structural model of the bearing is to be done in an efficient way to assess bearing stiffness and load distribution over the rolling elements, the twisting stiffness of the wire has to be modelled properly. This work develops a simple analytical expression of that stiffness to be used in structural models, derived from an evidence-based deformation assumption at differential level for the section of the wire.", "published": "2024-11-07 05:00:00", "id": "42550eb0-22db-4f85-a952-61445aa7019c", "source": "arxiv", "section": "computerScience"}, {"title": "Human-in-the-Loop Feature Selection Using Interpretable Kolmogorov-Arnold Network-based Double Deep Q-Network", "link": "https://arxiv.org/abs/2411.03740", "description": "arXiv:2411.03740v1 Announce Type: new \nAbstract: Feature selection is critical for improving the performance and interpretability of machine learning models, particularly in high-dimensional spaces where complex feature interactions can reduce accuracy and increase computational demands. Existing approaches often rely on static feature subsets or manual intervention, limiting adaptability and scalability. However, dynamic, per-instance feature selection methods and model-specific interpretability in reinforcement learning remain underexplored. This study proposes a human-in-the-loop (HITL) feature selection framework integrated into a Double Deep Q-Network (DDQN) using a Kolmogorov-Arnold Network (KAN). Our novel approach leverages simulated human feedback and stochastic distribution-based sampling, specifically Beta, to iteratively refine feature subsets per data instance, improving flexibility in feature selection. The KAN-DDQN achieved notable test accuracies of 93% on MNIST and 83% on FashionMNIST, outperforming conventional MLP-DDQN models by up to 9%. The KAN-based model provided high interpretability via symbolic representation while using 4 times fewer neurons in the hidden layer than MLPs did. Comparatively, the models without feature selection achieved test accuracies of only 58% on MNIST and 64% on FashionMNIST, highlighting significant gains with our framework. Pruning and visualization further enhanced model transparency by elucidating decision pathways. These findings present a scalable, interpretable solution for feature selection that is suitable for applications requiring real-time, adaptive decision-making with minimal human oversight.", "published": "2024-11-07 05:00:00", "id": "14dd167a-fa78-41f6-869c-ff2dcba0f6e6", "source": "arxiv", "section": "computerScience"}, {"title": "Adaptive Consensus Gradients Aggregation for Scaled Distributed Training", "link": "https://arxiv.org/abs/2411.03742", "description": "arXiv:2411.03742v1 Announce Type: new \nAbstract: Distributed machine learning has recently become a critical paradigm for training large models on vast datasets. We examine the stochastic optimization problem for deep learning within synchronous parallel computing environments under communication constraints. While averaging distributed gradients is the most widely used method for gradient estimation, whether this is the optimal strategy remains an open question. In this work, we analyze the distributed gradient aggregation process through the lens of subspace optimization. By formulating the aggregation problem as an objective-aware subspace optimization problem, we derive an efficient weighting scheme for gradients, guided by subspace coefficients. We further introduce subspace momentum to accelerate convergence while maintaining statistical unbiasedness in the aggregation. Our method demonstrates improved performance over the ubiquitous gradient averaging on multiple MLPerf tasks while remaining extremely efficient in both communicational and computational complexity.", "published": "2024-11-07 05:00:00", "id": "25c8d32a-3e91-4efc-b576-6f7bd2a86d0e", "source": "arxiv", "section": "computerScience"}, {"title": "Automating Exploratory Proteomics Research via Language Models", "link": "https://arxiv.org/abs/2411.03743", "description": "arXiv:2411.03743v1 Announce Type: new \nAbstract: With the development of artificial intelligence, its contribution to science is evolving from simulating a complex problem to automating entire research processes and producing novel discoveries. Achieving this advancement requires both specialized general models grounded in real-world scientific data and iterative, exploratory frameworks that mirror human scientific methodologies. In this paper, we present PROTEUS, a fully automated system for scientific discovery from raw proteomics data. PROTEUS uses large language models (LLMs) to perform hierarchical planning, execute specialized bioinformatics tools, and iteratively refine analysis workflows to generate high-quality scientific hypotheses. The system takes proteomics datasets as input and produces a comprehensive set of research objectives, analysis results, and novel biological hypotheses without human intervention. We evaluated PROTEUS on 12 proteomics datasets collected from various biological samples (e.g. immune cells, tumors) and different sample types (single-cell and bulk), generating 191 scientific hypotheses. These were assessed using both automatic LLM-based scoring on 5 metrics and detailed reviews from human experts. Results demonstrate that PROTEUS consistently produces reliable, logically coherent results that align well with existing literature while also proposing novel, evaluable hypotheses. The system's flexible architecture facilitates seamless integration of diverse analysis tools and adaptation to different proteomics data types. By automating complex proteomics analysis workflows and hypothesis generation, PROTEUS has the potential to considerably accelerate the pace of scientific discovery in proteomics research, enabling researchers to efficiently explore large-scale datasets and uncover biological insights.", "published": "2024-11-07 05:00:00", "id": "d6c0be64-dbb7-40a4-a2ee-1c33da1b0d32", "source": "arxiv", "section": "computerScience"}, {"title": "Graph Neural Networks with Coarse- and Fine-Grained Division for Mitigating Label Sparsity and Noise", "link": "https://arxiv.org/abs/2411.03744", "description": "arXiv:2411.03744v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) have gained considerable prominence in semi-supervised learning tasks in processing graph-structured data, primarily owing to their message-passing mechanism, which largely relies on the availability of clean labels. However, in real-world scenarios, labels on nodes of graphs are inevitably noisy and sparsely labeled, significantly degrading the performance of GNNs. Exploring robust GNNs for semi-supervised node classification in the presence of noisy and sparse labels remains a critical challenge. Therefore, we propose a novel \\textbf{G}raph \\textbf{N}eural \\textbf{N}etwork with \\textbf{C}oarse- and \\textbf{F}ine-\\textbf{G}rained \\textbf{D}ivision for mitigating label sparsity and noise, namely GNN-CFGD. The key idea of GNN-CFGD is reducing the negative impact of noisy labels via coarse- and fine-grained division, along with graph reconstruction. Specifically, we first investigate the effectiveness of linking unlabeled nodes to cleanly labeled nodes, demonstrating that this approach is more effective in combating labeling noise than linking to potentially noisy labeled nodes. Based on this observation, we introduce a Gaussian Mixture Model (GMM) based on the memory effect to perform a coarse-grained division of the given labels into clean and noisy labels. Next, we propose a clean labels oriented link that connects unlabeled nodes to cleanly labeled nodes, aimed at mitigating label sparsity and promoting supervision propagation. Furthermore, to provide refined supervision for noisy labeled nodes and additional supervision for unlabeled nodes, we fine-grain the noisy labeled and unlabeled nodes into two candidate sets based on confidence, respectively. Extensive experiments on various datasets demonstrate the superior effectiveness and robustness of GNN-CFGD.", "published": "2024-11-07 05:00:00", "id": "fcc91d9b-c099-4412-a5b2-578e0447d562", "source": "arxiv", "section": "computerScience"}, {"title": "Homotopy Continuation Made Easy: Regression-based Online Simulation of Starting Problem-Solution Pairs", "link": "https://arxiv.org/abs/2411.03745", "description": "arXiv:2411.03745v1 Announce Type: new \nAbstract: While automatically generated polynomial elimination templates have sparked great progress in the field of 3D computer vision, there remain many problems for which the degree of the constraints or the number of unknowns leads to intractability. In recent years, homotopy continuation has been introduced as a plausible alternative. However, the method currently depends on expensive parallel tracking of all possible solutions in the complex domain, or a classification network for starting problem-solution pairs trained over a limited set of real-world examples. Our innovation consists of employing a regression network trained in simulation to directly predict a solution from input correspondences, followed by an online simulator that invents a consistent problem-solution pair. Subsequently, homotopy continuation is applied to track that single solution back to the original problem. We apply this elegant combination to generalized camera resectioning, and also introduce a new solution to the challenging generalized relative pose and scale problem. As demonstrated, the proposed method successfully compensates the raw error committed by the regressor alone, and leads to state-of-the-art efficiency and success rates while running on CPU resources, only.", "published": "2024-11-07 05:00:00", "id": "d2a21843-5dcb-4c8e-979d-d196c040707a", "source": "arxiv", "section": "computerScience"}, {"title": "Optimal Defenses Against Gradient Reconstruction Attacks", "link": "https://arxiv.org/abs/2411.03746", "description": "arXiv:2411.03746v1 Announce Type: new \nAbstract: Federated Learning (FL) is designed to prevent data leakage through collaborative model training without centralized data storage. However, it remains vulnerable to gradient reconstruction attacks that recover original training data from shared gradients. To optimize the trade-off between data leakage and utility loss, we first derive a theoretical lower bound of reconstruction error (among all attackers) for the two standard methods: adding noise, and gradient pruning. We then customize these two defenses to be parameter- and model-specific and achieve the optimal trade-off between our obtained reconstruction lower bound and model utility. Experimental results validate that our methods outperform Gradient Noise and Gradient Pruning by protecting the training data better while also achieving better utility.", "published": "2024-11-07 05:00:00", "id": "95795c07-a66f-49fc-bf66-dbdd4a15e2a9", "source": "arxiv", "section": "computerScience"}, {"title": "Observability-Aware Control for Cooperatively Localizing Quadrotor UAVs", "link": "https://arxiv.org/abs/2411.03747", "description": "arXiv:2411.03747v1 Announce Type: new \nAbstract: Cooperatively Localizing robots should seek optimal control strategies to maximize precision of position estimation and ensure safety in flight. Observability-Aware Trajectory Optimization has strong potential to address this issue, but no concrete link between observability and precision has been proven yet. In this paper, we prove that improvement in positioning precision inherently follows from optimizing observability. Based on this finding, we develop an Observability-Aware Control principle to generate observability-optimal control strategies. We implement this principle in a Model Predictive Control framework, and we verify it on a team of quadrotor Unmanned Aerial Vehicles comprising a follower vehicle localizing itself by tracking a leader vehicle in both simulations and real-world flight tests. Our results demonstrate that maximizing observability contributed to improving global positioning precision for the quadrotor team.", "published": "2024-11-07 05:00:00", "id": "7f2fa8fc-75a5-46eb-a984-a10aeebda1af", "source": "arxiv", "section": "computerScience"}, {"title": "Fundamental Limits of Routing Attack on Network Overload", "link": "https://arxiv.org/abs/2411.03749", "description": "arXiv:2411.03749v1 Announce Type: new \nAbstract: We quantify the threat of network adversaries to inducing \\emph{network overload} through \\emph{routing attacks}, where a subset of network nodes are hijacked by an adversary. We develop routing attacks on the hijacked nodes for two objectives related to overload: \\emph{no-loss throughput minimization} and \\emph{loss maximization}. The first objective attempts to identify a routing attack that minimizes the network's throughput that is guaranteed to survive. We develop a polynomial-time algorithm that can output the optimal routing attack in multi-hop networks with global information on the network's topology, and an algorithm with an approximation ratio of $2$ under partial information. The second objective attempts to maximize the throughput loss. We demonstrate that this problem is NP-hard, and develop two approximation algorithms with multiplicative and additive guarantees respectively in single-hop networks. We further investigate the adversary's optimal selection of nodes to hijack that can maximize network overload. We propose a heuristic polynomial-time algorithm to solve this NP-hard problem, and prove its optimality in special cases. We validate the near-optimal performance of the proposed algorithms over a wide range of network settings. Our results demonstrate that the proposed algorithms can accurately quantify the risk of overload given an arbitrary set of hijacked nodes and identify the critical nodes that should be protected against routing attacks.", "published": "2024-11-07 05:00:00", "id": "c34f0601-6edd-4d34-9231-48a691e1271e", "source": "arxiv", "section": "computerScience"}, {"title": "Deferred Poisoning: Making the Model More Vulnerable via Hessian Singularization", "link": "https://arxiv.org/abs/2411.03752", "description": "arXiv:2411.03752v1 Announce Type: new \nAbstract: Recent studies have shown that deep learning models are very vulnerable to poisoning attacks. Many defense methods have been proposed to address this issue. However, traditional poisoning attacks are not as threatening as commonly believed. This is because they often cause differences in how the model performs on the training set compared to the validation set. Such inconsistency can alert defenders that their data has been poisoned, allowing them to take the necessary defensive actions. In this paper, we introduce a more threatening type of poisoning attack called the Deferred Poisoning Attack. This new attack allows the model to function normally during the training and validation phases but makes it very sensitive to evasion attacks or even natural noise. We achieve this by ensuring the poisoned model's loss function has a similar value as a normally trained model at each input sample but with a large local curvature. A similar model loss ensures that there is no obvious inconsistency between the training and validation accuracy, demonstrating high stealthiness. On the other hand, the large curvature implies that a small perturbation may cause a significant increase in model loss, leading to substantial performance degradation, which reflects a worse robustness. We fulfill this purpose by making the model have singular Hessian information at the optimal point via our proposed Singularization Regularization term. We have conducted both theoretical and empirical analyses of the proposed method and validated its effectiveness through experiments on image classification tasks. Furthermore, we have confirmed the hazards of this form of poisoning attack under more general scenarios using natural noise, offering a new perspective for research in the field of security.", "published": "2024-11-07 05:00:00", "id": "97647bcd-f4f6-4344-9ba4-683a84875a3b", "source": "arxiv", "section": "computerScience"}, {"title": "Symbolic regression via MDLformer-guided search: from minimizing prediction error to minimizing description length", "link": "https://arxiv.org/abs/2411.03753", "description": "arXiv:2411.03753v1 Announce Type: new \nAbstract: Symbolic regression, a task discovering the formula best fitting the given data, is typically based on the heuristical search. These methods usually update candidate formulas to obtain new ones with lower prediction errors iteratively. However, since formulas with similar function shapes may have completely different symbolic forms, the prediction error does not decrease monotonously as the search approaches the target formula, causing the low recovery rate of existing methods. To solve this problem, we propose a novel search objective based on the minimum description length, which reflects the distance from the target and decreases monotonically as the search approaches the correct form of the target formula. To estimate the minimum description length of any input data, we design a neural network, MDLformer, which enables robust and scalable estimation through large-scale training. With the MDLformer's output as the search objective, we implement a symbolic regression method, SR4MDL, that can effectively recover the correct mathematical form of the formula. Extensive experiments illustrate its excellent performance in recovering formulas from data. Our method successfully recovers around 50 formulas across two benchmark datasets comprising 133 problems, outperforming state-of-the-art methods by 43.92%.", "published": "2024-11-07 05:00:00", "id": "2eab065e-6820-4077-8c8e-35b52a94b689", "source": "arxiv", "section": "computerScience"}, {"title": "Content-Style Learning from Unaligned Domains: Identifiability under Unknown Latent Dimensions", "link": "https://arxiv.org/abs/2411.03755", "description": "arXiv:2411.03755v1 Announce Type: new \nAbstract: Understanding identifiability of latent content and style variables from unaligned multi-domain data is essential for tasks such as domain translation and data generation. Existing works on content-style identification were often developed under somewhat stringent conditions, e.g., that all latent components are mutually independent and that the dimensions of the content and style variables are known. We introduce a new analytical framework via cross-domain \\textit{latent distribution matching} (LDM), which establishes content-style identifiability under substantially more relaxed conditions. Specifically, we show that restrictive assumptions such as component-wise independence of the latent variables can be removed. Most notably, we prove that prior knowledge of the content and style dimensions is not necessary for ensuring identifiability, if sparsity constraints are properly imposed onto the learned latent representations. Bypassing the knowledge of the exact latent dimension has been a longstanding aspiration in unsupervised representation learning -- our analysis is the first to underpin its theoretical and practical viability. On the implementation side, we recast the LDM formulation into a regularized multi-domain GAN loss with coupled latent variables. We show that the reformulation is equivalent to LDM under mild conditions -- yet requiring considerably less computational resource. Experiments corroborate with our theoretical claims.", "published": "2024-11-07 05:00:00", "id": "b400567f-10fd-43eb-b9bd-7266d29431ee", "source": "arxiv", "section": "computerScience"}, {"title": "Variational Inference on the Boolean Hypercube with the Quantum Entropy", "link": "https://arxiv.org/abs/2411.03759", "description": "arXiv:2411.03759v1 Announce Type: new \nAbstract: In this paper, we derive variational inference upper-bounds on the log-partition function of pairwise Markov random fields on the Boolean hypercube, based on quantum relaxations of the Kullback-Leibler divergence. We then propose an efficient algorithm to compute these bounds based on primal-dual optimization. An improvement of these bounds through the use of ''hierarchies,'' similar to sum-of-squares (SoS) hierarchies is proposed, and we present a greedy algorithm to select among these relaxations. We carry extensive numerical experiments and compare with state-of-the-art methods for this inference problem.", "published": "2024-11-07 05:00:00", "id": "45b02a7c-68cb-47a4-b2e7-fd5a2a6fd040", "source": "arxiv", "section": "computerScience"}, {"title": "Number Cookbook: Number Understanding of Language Models and How to Improve It", "link": "https://arxiv.org/abs/2411.03766", "description": "arXiv:2411.03766v1 Announce Type: new \nAbstract: Large language models (LLMs) can solve an increasing number of complex reasoning tasks while making surprising mistakes in basic numerical understanding and processing (such as 9.11 > 9.9). The latter ability is essential for tackling complex arithmetic and mathematical problems and serves as a foundation for most reasoning tasks, but previous work paid little attention to it or only discussed several restricted tasks (like integer addition). In this paper, we comprehensively investigate the numerical understanding and processing ability (NUPA) of LLMs. Firstly, we introduce a benchmark covering four common numerical representations and 17 distinct numerical tasks in four major categories, resulting in 41 meaningful combinations in total. These tasks are derived from primary and secondary education curricula, encompassing nearly all everyday numerical understanding and processing scenarios, and the rules of these tasks are very simple and clear. Through the benchmark, we find that current LLMs fail frequently in many of the tasks. To study the problem, we train small models with existing and potential techniques for enhancing NUPA (such as special tokenizers, PEs, and number formats), comprehensively evaluating their effectiveness using our testbed. We also finetune practical-scale LLMs on our proposed NUPA tasks and find that 1) naive finetuning can improve NUPA a lot on many but not all tasks, and 2) surprisingly, techniques designed to enhance NUPA prove ineffective for finetuning pretrained models. We further explore the impact of chain-of-thought techniques on NUPA. Our work takes a preliminary step towards understanding and improving NUPA of LLMs. Our benchmark and code are released at https://github.com/GraphPKU/number_cookbook.", "published": "2024-11-07 05:00:00", "id": "0c612804-fa43-4f89-b62d-0acde83f5f40", "source": "arxiv", "section": "computerScience"}, {"title": "A Bayesian Approach to Data Point Selection", "link": "https://arxiv.org/abs/2411.03768", "description": "arXiv:2411.03768v1 Announce Type: new \nAbstract: Data point selection (DPS) is becoming a critical topic in deep learning due to the ease of acquiring uncurated training data compared to the difficulty of obtaining curated or processed data. Existing approaches to DPS are predominantly based on a bi-level optimisation (BLO) formulation, which is demanding in terms of memory and computation, and exhibits some theoretical defects regarding minibatches. Thus, we propose a novel Bayesian approach to DPS. We view the DPS problem as posterior inference in a novel Bayesian model where the posterior distributions of the instance-wise weights and the main neural network parameters are inferred under a reasonable prior and likelihood model. We employ stochastic gradient Langevin MCMC sampling to learn the main network and instance-wise weights jointly, ensuring convergence even with minibatches. Our update equation is comparable to the widely used SGD and much more efficient than existing BLO-based methods. Through controlled experiments in both the vision and language domains, we present the proof-of-concept. Additionally, we demonstrate that our method scales effectively to large language models and facilitates automated per-task optimization for instruction fine-tuning datasets.", "published": "2024-11-07 05:00:00", "id": "a193c6cb-e512-4d94-8df6-fe6ab8ecfe5e", "source": "arxiv", "section": "computerScience"}, {"title": "No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages", "link": "https://arxiv.org/abs/2411.03769", "description": "arXiv:2411.03769v1 Announce Type: new \nAbstract: Research in vision and language has made considerable progress thanks to benchmarks such as COCO. COCO captions focused on unambiguous facts in English; ArtEmis introduced subjective emotions and ArtELingo introduced some multilinguality (Chinese and Arabic). However we believe there should be more multilinguality. Hence, we present ArtELingo-28, a vision-language benchmark that spans $\\textbf{28}$ languages and encompasses approximately $\\textbf{200,000}$ annotations ($\\textbf{140}$ annotations per image). Traditionally, vision research focused on unambiguous class labels, whereas ArtELingo-28 emphasizes diversity of opinions over languages and cultures. The challenge is to build machine learning systems that assign emotional captions to images. Baseline results will be presented for three novel conditions: Zero-Shot, Few-Shot and One-vs-All Zero-Shot. We find that cross-lingual transfer is more successful for culturally-related languages. Data and code are provided at www.artelingo.org.", "published": "2024-11-07 05:00:00", "id": "0c10b3bf-ac53-4e3c-b78c-bee1cf6981c5", "source": "arxiv", "section": "computerScience"}, {"title": "Analyzing Ultra-Low Inter-Core Crosstalk Fibers in Band and Space Division Multiplexing EONs", "link": "https://arxiv.org/abs/2411.03772", "description": "arXiv:2411.03772v1 Announce Type: new \nAbstract: In the ultra-low inter-core crosstalk working zone of terrestrial multi-band and multi-core fiber (MCF) elastic optical networks (EONs), the ICXT in all channels of all cores remains below the ICXT threshold of the highest modulation format level (64QAM) for long-haul distances (10000 km). This paper analyzes the performance of this type of MCF in multi-band EONs (MB-EONs). We investigate two band and space division multiplexing (BSDM) scenarios: MCF and a bundle of multi-fiber pairs (BuMFP). Furthermore, the UL-ICXT performance of two MCFs, one with the standard cladding diameter (CD = 125 micrometers) with 4 cores and another with a nonstandard larger CD with 7 cores, is evaluated in the US backbone network. Our findings show that, with careful design of the MCFs physical structure, even with a standard CD, it is possible to achieve UL-ICXT in C, L, and S-band long-haul BSDM EONs. Additionally, the simulation results show that network throughput for BSDM EONs with MCFs in the UL-ICXT regime is up to 12 percent higher than the BuMFP scenario, with capacity increasing linearly with the number of cores.", "published": "2024-11-07 05:00:00", "id": "d2822f44-c735-4e59-92df-6de930a87a7d", "source": "arxiv", "section": "computerScience"}, {"title": "Reconstruction of multiple strings of constant weight from prefix-suffix compositions", "link": "https://arxiv.org/abs/2411.03776", "description": "arXiv:2411.03776v1 Announce Type: new \nAbstract: Motivated by studies of data retrieval in polymer-based storage systems, we consider the problem of reconstructing a multiset of binary strings that have the same length and the same weight from the compositions of their prefixes and suffixes of every possible length. We provide necessary and sufficient conditions for which unique reconstruction up to reversal of the strings is possible. Additionally, we present two algorithms for reconstructing strings from the compositions of prefixes and suffixes of constant-length constant-weight strings.", "published": "2024-11-07 05:00:00", "id": "2042c1e8-e3a3-46b1-87c7-2c32c918a5fa", "source": "arxiv", "section": "computerScience"}, {"title": "An Ordinary Differential Equation Framework for Stability Analysis of Networks with Finite Buffers", "link": "https://arxiv.org/abs/2411.03780", "description": "arXiv:2411.03780v1 Announce Type: new \nAbstract: We consider the problem of network stability in finite-buffer systems. We observe that finite buffer may affect stability even in simplest network structure, and we propose an ordinary differential equation (ODE) model to capture the queuing dynamics and analyze the stability in buffered communication networks with general topology. For single-commodity systems, we propose a sufficient condition, which follows the fundamental idea of backpressure, for local transmission policies to stabilize the networks based on ODE stability theory. We further extend the condition to multi-commodity systems, with an additional restriction on the coupling level between different commodities, which can model networks with per-commodity buffers and shared buffers. The framework characterizes a set of policies that can stabilize buffered networks, and is useful for analyzing the effect of finite buffers on network stability.", "published": "2024-11-07 05:00:00", "id": "32ffedd2-55c6-49ac-851f-fd5a9683de8b", "source": "arxiv", "section": "computerScience"}, {"title": "Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications", "link": "https://arxiv.org/abs/2411.03782", "description": "arXiv:2411.03782v1 Announce Type: new \nAbstract: Recent technological advances in healthcare have led to unprecedented growth in patient data quantity and diversity. While artificial intelligence (AI) models have shown promising results in analyzing individual data modalities, there is increasing recognition that models integrating multiple complementary data sources, so-called multimodal AI, could enhance clinical decision-making. This scoping review examines the landscape of deep learning-based multimodal AI applications across the medical domain, analyzing 432 papers published between 2018 and 2024. We provide an extensive overview of multimodal AI development across different medical disciplines, examining various architectural approaches, fusion strategies, and common application areas. Our analysis reveals that multimodal AI models consistently outperform their unimodal counterparts, with an average improvement of 6.2 percentage points in AUC. However, several challenges persist, including cross-departmental coordination, heterogeneous data characteristics, and incomplete datasets. We critically assess the technical and practical challenges in developing multimodal AI systems and discuss potential strategies for their clinical implementation, including a brief overview of commercially available multimodal AI models for clinical decision-making. Additionally, we identify key factors driving multimodal AI development and propose recommendations to accelerate the field's maturation. This review provides researchers and clinicians with a thorough understanding of the current state, challenges, and future directions of multimodal AI in medicine.", "published": "2024-11-07 05:00:00", "id": "f29c71a4-f21f-4bdd-a7db-aca80de5af68", "source": "arxiv", "section": "computerScience"}, {"title": "Optimal prefix-suffix queries with applications", "link": "https://arxiv.org/abs/2411.03784", "description": "arXiv:2411.03784v1 Announce Type: new \nAbstract: We revisit the classic border tree data structure [Gu, Farach, Beigel, SODA 1994] that answers the following prefix-suffix queries on a string $T$ of length $n$ over an integer alphabet $\\Sigma=[0,\\sigma)$: for any $i,j \\in [0,n)$ return all occurrences of $T$ in $T[0\\mathinner{.\\,.} i]T[j\\mathinner{.\\,.} n-1]$. The border tree of $T$ can be constructed in $\\mathcal{O}(n)$ time and answers prefix-suffix queries in $\\mathcal{O}(\\log n + \\textsf{Occ})$ time, where $\\textsf{Occ}$ is the number of occurrences of $T$ in $T[0\\mathinner{.\\,.} i]T[j\\mathinner{.\\,.} n-1]$. Our contribution here is the following. We present a completely different and remarkably simple data structure that can be constructed in the optimal $\\mathcal{O}(n/\\log_\\sigma n)$ time and supports queries in the optimal $\\mathcal{O}(1)$ time. Our result is based on a new structural lemma that lets us encode the output of any query in constant time and space. We also show a new direct application of our result in pattern matching on node-labeled graphs.", "published": "2024-11-07 05:00:00", "id": "0de90cfd-870e-4471-b427-e1b3cc22fc3b", "source": "arxiv", "section": "computerScience"}, {"title": "The N-Grammys: Accelerating Autoregressive Inference with Learning-Free Batched Speculation", "link": "https://arxiv.org/abs/2411.03786", "description": "arXiv:2411.03786v1 Announce Type: new \nAbstract: Speculative decoding aims to speed up autoregressive generation of a language model by verifying in parallel the tokens generated by a smaller draft model.In this work, we explore the effectiveness of learning-free, negligible-cost draft strategies, namely $N$-grams obtained from the model weights and the context. While the predicted next token of the base model is rarely the top prediction of these simple strategies, we observe that it is often within their top-$k$ predictions for small $k$. Based on this, we show that combinations of simple strategies can achieve significant inference speedups over different tasks. The overall performance is comparable to more complex methods, yet does not require expensive preprocessing or modification of the base model, and allows for seamless `plug-and-play' integration into pipelines.", "published": "2024-11-07 05:00:00", "id": "f1934e45-c0e2-4cab-abe0-3a00dc8f88c8", "source": "arxiv", "section": "computerScience"}, {"title": "Quasi-Monte Carlo for partial differential equations with generalized Gaussian input uncertainty", "link": "https://arxiv.org/abs/2411.03793", "description": "arXiv:2411.03793v1 Announce Type: new \nAbstract: There has been a surge of interest in uncertainty quantification for parametric partial differential equations (PDEs) with Gevrey regular inputs. The Gevrey class contains functions that are infinitely smooth with a growth condition on the higher-order partial derivatives, but which are nonetheless not analytic in general. Recent studies by Chernov and Le (Comput. Math. Appl., 2024, and SIAM J. Numer. Anal., 2024) as well as Harbrecht, Schmidlin, and Schwab (Math. Models Methods Appl. Sci., 2024) analyze the setting wherein the input random field is assumed to be uniformly bounded with respect to the uncertain parameters. In this paper, we relax this assumption and allow for parameter-dependent bounds. The parametric inputs are modeled as generalized Gaussian random variables, and we analyze the application of quasi-Monte Carlo (QMC) integration to assess the PDE response statistics using randomly shifted rank-1 lattice rules. In addition to the QMC error analysis, we also consider the dimension truncation and finite element errors in this setting.", "published": "2024-11-07 05:00:00", "id": "ea96ff59-2f70-4bcb-b290-8dc96bc811df", "source": "arxiv", "section": "computerScience"}, {"title": "Harmformer: Harmonic Networks Meet Transformers for Continuous Roto-Translation Equivariance", "link": "https://arxiv.org/abs/2411.03794", "description": "arXiv:2411.03794v1 Announce Type: new \nAbstract: CNNs exhibit inherent equivariance to image translation, leading to efficient parameter and data usage, faster learning, and improved robustness. The concept of translation equivariant networks has been successfully extended to rotation transformation using group convolution for discrete rotation groups and harmonic functions for the continuous rotation group encompassing $360^\\circ$. We explore the compatibility of the SA mechanism with full rotation equivariance, in contrast to previous studies that focused on discrete rotation. We introduce the Harmformer, a harmonic transformer with a convolutional stem that achieves equivariance for both translation and continuous rotation. Accompanied by an end-to-end equivariance proof, the Harmformer not only outperforms previous equivariant transformers, but also demonstrates inherent stability under any continuous rotation, even without seeing rotated samples during training.", "published": "2024-11-07 05:00:00", "id": "328fea11-491c-489a-bba9-738aeda1c9c3", "source": "arxiv", "section": "computerScience"}, {"title": "VQA$^2$:Visual Question Answering for Video Quality Assessment", "link": "https://arxiv.org/abs/2411.03795", "description": "arXiv:2411.03795v1 Announce Type: new \nAbstract: The advent and proliferation of large multi-modal models (LMMs) have introduced a new paradigm to video-related computer vision fields, including training and inference methods based on visual question answering (VQA). These methods enable models to handle multiple downstream tasks robustly. Video Quality Assessment (VQA), a classic field in low-level visual quality evaluation, originally focused on quantitative video quality scoring. However, driven by advances in LMMs, it is now evolving towards more comprehensive visual quality understanding tasks. Visual question answering has significantly improved low-level visual evaluation within the image domain recently. However, related work is almost nonexistent in the video domain, leaving substantial room for improvement. To address this gap, we introduce the VQA2 Instruction Dataset the first visual question answering instruction dataset entirely focuses on video quality assessment, and based on it, we propose the VQA2 series models The VQA2 Instruction Dataset consists of three stages and covers various video types, containing 157,735 instruction question-answer pairs, including both manually annotated and synthetic data. We conduct extensive experiments on both video quality scoring and video quality understanding tasks. Results demonstrate that the VQA2 series models achieve state-of-the-art (SOTA) performance in quality scoring tasks, and their performance in visual quality question answering surpasses the renowned GPT-4o. Additionally, our final model, the VQA2-Assistant, performs well across both scoring and question-answering tasks, validating its versatility.", "published": "2024-11-07 05:00:00", "id": "1a4ed2ed-5ba8-48f8-8bda-b35d5c5b82e2", "source": "arxiv", "section": "computerScience"}, {"title": "Optimizing Metro Station Locations and Line Layouts in Selangor using Genetic Algorithm Approach: Technical Report", "link": "https://arxiv.org/abs/2411.03797", "description": "arXiv:2411.03797v1 Announce Type: new \nAbstract: This report presents an approach for optimizing metro station locations and line layouts in the area of Selangor, located in Malaysia. The project utilized the genetic algorithm in identifying the locations and lines layout. With population in Selangor projected to reach 7.3 million by 2024, the existing transport infrastructure is under increasing strain. This project addresses this challenge by optimizing the metro network to effectively cover the expanding population and minimize travel times. We employed a genetic algorithm to achieve these objectives, focusing on both the strategic placement of metro stations and the efficient layout of metro lines.", "published": "2024-11-07 05:00:00", "id": "7c0d4b03-8475-4ada-888d-49ac36715e33", "source": "arxiv", "section": "computerScience"}, {"title": "Overcoming label shift in targeted federated learning", "link": "https://arxiv.org/abs/2411.03799", "description": "arXiv:2411.03799v1 Announce Type: new \nAbstract: Federated learning enables multiple actors to collaboratively train models without sharing private data. This unlocks the potential for scaling machine learning to diverse applications. Existing algorithms for this task are well-justified when clients and the intended target domain share the same distribution of features and labels, but this assumption is often violated in real-world scenarios. One common violation is label shift, where the label distributions differ across clients or between clients and the target domain, which can significantly degrade model performance. To address this problem, we propose FedPALS, a novel model aggregation scheme that adapts to label shifts by leveraging knowledge of the target label distribution at the central server. Our approach ensures unbiased updates under stochastic gradient descent, ensuring robust generalization across clients with diverse, label-shifted data. Extensive experiments on image classification demonstrate that FedPALS consistently outperforms standard baselines by aligning model aggregation with the target domain. Our findings reveal that conventional federated learning methods suffer severely in cases of extreme client sparsity, highlighting the critical need for target-aware aggregation. FedPALS offers a principled and practical solution to mitigate label distribution mismatch, ensuring models trained in federated settings can generalize effectively to label-shifted target domains.", "published": "2024-11-07 05:00:00", "id": "55490107-b832-4fbf-934d-3dad59bc32b3", "source": "arxiv", "section": "computerScience"}, {"title": "On the Decomposition of Differential Game", "link": "https://arxiv.org/abs/2411.03802", "description": "arXiv:2411.03802v1 Announce Type: new \nAbstract: To understand the complexity of the dynamic of learning in differential games, we decompose the game into components where the dynamic is well understood. One of the possible tools is Helmholtz's theorem, which can decompose a vector field into a potential and a harmonic component. This has been shown to be effective in finite and normal-form games. However, applying Helmholtz's theorem by connecting it with the Hodge theorem on $\\mathbb{R}^n$ (which is the strategy space of differential game) is non-trivial due to the non-compactness of $\\mathbb{R}^n$. Bridging the dynamic-strategic disconnect through Hodge/Helmoltz's theorem in differential games is then left as an open problem \\cite{letcher2019differentiable}. In this work, we provide two decompositions of differential games to answer this question: the first as an exact scalar potential part, a near vector potential part, and a non-strategic part; the second as a near scalar potential part, an exact vector potential part, and a non-strategic part. We show that scalar potential games coincide with potential games proposed by \\cite{monderer1996potential}, where the gradient descent dynamic can successfully find the Nash equilibrium. For the vector potential game, we show that the individual gradient field is divergence-free, in which case the gradient descent dynamic may either be divergent or recurrent.", "published": "2024-11-07 05:00:00", "id": "7eaa562e-30c1-4fcc-addb-0e85b77c4eab", "source": "arxiv", "section": "computerScience"}, {"title": "A Comparative Study of Recent Large Language Models on Generating Hospital Discharge Summaries for Lung Cancer Patients", "link": "https://arxiv.org/abs/2411.03805", "description": "arXiv:2411.03805v1 Announce Type: new \nAbstract: Generating discharge summaries is a crucial yet time-consuming task in clinical practice, essential for conveying pertinent patient information and facilitating continuity of care. Recent advancements in large language models (LLMs) have significantly enhanced their capability in understanding and summarizing complex medical texts. This research aims to explore how LLMs can alleviate the burden of manual summarization, streamline workflow efficiencies, and support informed decision-making in healthcare settings. Clinical notes from a cohort of 1,099 lung cancer patients were utilized, with a subset of 50 patients for testing purposes, and 102 patients used for model fine-tuning. This study evaluates the performance of multiple LLMs, including GPT-3.5, GPT-4, GPT-4o, and LLaMA 3 8b, in generating discharge summaries. Evaluation metrics included token-level analysis (BLEU, ROUGE-1, ROUGE-2, ROUGE-L) and semantic similarity scores between model-generated summaries and physician-written gold standards. LLaMA 3 8b was further tested on clinical notes of varying lengths to examine the stability of its performance. The study found notable variations in summarization capabilities among LLMs. GPT-4o and fine-tuned LLaMA 3 demonstrated superior token-level evaluation metrics, while LLaMA 3 consistently produced concise summaries across different input lengths. Semantic similarity scores indicated GPT-4o and LLaMA 3 as leading models in capturing clinical relevance. This study contributes insights into the efficacy of LLMs for generating discharge summaries, highlighting LLaMA 3's robust performance in maintaining clarity and relevance across varying clinical contexts. These findings underscore the potential of automated summarization tools to enhance documentation precision and efficiency, ultimately improving patient care and operational capability in healthcare settings.", "published": "2024-11-07 05:00:00", "id": "9c2cb193-1904-483b-97c1-2acbaef7270d", "source": "arxiv", "section": "computerScience"}, {"title": "Understanding the Effects of Human-written Paraphrases in LLM-generated Text Detection", "link": "https://arxiv.org/abs/2411.03806", "description": "arXiv:2411.03806v1 Announce Type: new \nAbstract: Natural Language Generation has been rapidly developing with the advent of large language models (LLMs). While their usage has sparked significant attention from the general public, it is important for readers to be aware when a piece of text is LLM-generated. This has brought about the need for building models that enable automated LLM-generated text detection, with the aim of mitigating potential negative outcomes of such content. Existing LLM-generated detectors show competitive performances in telling apart LLM-generated and human-written text, but this performance is likely to deteriorate when paraphrased texts are considered. In this study, we devise a new data collection strategy to collect Human & LLM Paraphrase Collection (HLPC), a first-of-its-kind dataset that incorporates human-written texts and paraphrases, as well as LLM-generated texts and paraphrases. With the aim of understanding the effects of human-written paraphrases on the performance of state-of-the-art LLM-generated text detectors OpenAI RoBERTa and watermark detectors, we perform classification experiments that incorporate human-written paraphrases, watermarked and non-watermarked LLM-generated documents from GPT and OPT, and LLM-generated paraphrases from DIPPER and BART. The results show that the inclusion of human-written paraphrases has a significant impact of LLM-generated detector performance, promoting TPR@1%FPR with a possible trade-off of AUROC and accuracy.", "published": "2024-11-07 05:00:00", "id": "48de129b-9198-40ac-a754-e0e597b240b3", "source": "arxiv", "section": "computerScience"}, {"title": "GS2Pose: Tow-stage 6D Object Pose Estimation Guided by Gaussian Splatting", "link": "https://arxiv.org/abs/2411.03807", "description": "arXiv:2411.03807v1 Announce Type: new \nAbstract: This paper proposes a new method for accurate and robust 6D pose estimation of novel objects, named GS2Pose. By introducing 3D Gaussian splatting, GS2Pose can utilize the reconstruction results without requiring a high-quality CAD model, which means it only requires segmented RGBD images as input. Specifically, GS2Pose employs a two-stage structure consisting of coarse estimation followed by refined estimation. In the coarse stage, a lightweight U-Net network with a polarization attention mechanism, called Pose-Net, is designed. By using the 3DGS model for supervised training, Pose-Net can generate NOCS images to compute a coarse pose. In the refinement stage, GS2Pose formulates a pose regression algorithm following the idea of reprojection or Bundle Adjustment (BA), referred to as GS-Refiner. By leveraging Lie algebra to extend 3DGS, GS-Refiner obtains a pose-differentiable rendering pipeline that refines the coarse pose by comparing the input images with the rendered images. GS-Refiner also selectively updates parameters in the 3DGS model to achieve environmental adaptation, thereby enhancing the algorithm's robustness and flexibility to illuminative variation, occlusion, and other challenging disruptive factors. GS2Pose was evaluated through experiments conducted on the LineMod dataset, where it was compared with similar algorithms, yielding highly competitive results. The code for GS2Pose will soon be released on GitHub.", "published": "2024-11-07 05:00:00", "id": "e89048f3-049e-4d46-8ac5-270f2dd1c372", "source": "arxiv", "section": "computerScience"}, {"title": "Hybrid Transfer Reinforcement Learning: Provable Sample Efficiency from Shifted-Dynamics Data", "link": "https://arxiv.org/abs/2411.03810", "description": "arXiv:2411.03810v1 Announce Type: new \nAbstract: Online Reinforcement learning (RL) typically requires high-stakes online interaction data to learn a policy for a target task. This prompts interest in leveraging historical data to improve sample efficiency. The historical data may come from outdated or related source environments with different dynamics. It remains unclear how to effectively use such data in the target task to provably enhance learning and sample efficiency. To address this, we propose a hybrid transfer RL (HTRL) setting, where an agent learns in a target environment while accessing offline data from a source environment with shifted dynamics. We show that -- without information on the dynamics shift -- general shifted-dynamics data, even with subtle shifts, does not reduce sample complexity in the target environment. However, with prior information on the degree of the dynamics shift, we design HySRL, a transfer algorithm that achieves problem-dependent sample complexity and outperforms pure online RL. Finally, our experimental results demonstrate that HySRL surpasses state-of-the-art online RL baseline.", "published": "2024-11-07 05:00:00", "id": "e48138d4-4036-48c7-b638-bd3c5cb07d14", "source": "arxiv", "section": "computerScience"}, {"title": "The natural stability of autonomous morphology", "link": "https://arxiv.org/abs/2411.03811", "description": "arXiv:2411.03811v1 Announce Type: new \nAbstract: Autonomous morphology, such as inflection class systems and paradigmatic distribution patterns, is widespread and diachronically resilient in natural language. Why this should be so has remained unclear given that autonomous morphology imposes learning costs, offers no clear benefit relative to its absence and could easily be removed by the analogical forces which are constantly reshaping it. Here we propose an explanation for the resilience of autonomous morphology, in terms of a diachronic dynamic of attraction and repulsion between morphomic categories, which emerges spontaneously from a simple paradigm cell filling process. Employing computational evolutionary models, our key innovation is to bring to light the role of `dissociative evidence', i.e., evidence for inflectional distinctiveness which a rational reasoner will have access to during analogical inference. Dissociative evidence creates a repulsion dynamic which prevents morphomic classes from collapsing together entirely, i.e., undergoing complete levelling. As we probe alternative models, we reveal the limits of conditional entropy as a measure for predictability in systems that are undergoing change. Finally, we demonstrate that autonomous morphology, far from being `unnatural' (e.g. \\citealt{Aronoff1994}), is rather the natural (emergent) consequence of a natural (rational) process of inference applied to inflectional systems.", "published": "2024-11-07 05:00:00", "id": "7dc2225c-cd56-4d9b-bb9f-d5d947c8b97b", "source": "arxiv", "section": "computerScience"}, {"title": "MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue", "link": "https://arxiv.org/abs/2411.03814", "description": "arXiv:2411.03814v1 Announce Type: new \nAbstract: Large Language Models (LLMs) demonstrate outstanding performance in their reservoir of knowledge and understanding capabilities, but they have also been shown to be prone to illegal or unethical reactions when subjected to jailbreak attacks. To ensure their responsible deployment in critical applications, it is crucial to understand the safety capabilities and vulnerabilities of LLMs. Previous works mainly focus on jailbreak in single-round dialogue, overlooking the potential jailbreak risks in multi-round dialogues, which are a vital way humans interact with and extract information from LLMs. Some studies have increasingly concentrated on the risks associated with jailbreak in multi-round dialogues. These efforts typically involve the use of manually crafted templates or prompt engineering techniques. However, due to the inherent complexity of multi-round dialogues, their jailbreak performance is limited. To solve this problem, we propose a novel multi-round dialogue jailbreaking agent, emphasizing the importance of stealthiness in identifying and mitigating potential threats to human values posed by LLMs. We propose a risk decomposition strategy that distributes risks across multiple rounds of queries and utilizes psychological strategies to enhance attack strength. Extensive experiments show that our proposed method surpasses other attack methods and achieves state-of-the-art attack success rate. We will make the corresponding code and dataset available for future research. The code will be released soon.", "published": "2024-11-07 05:00:00", "id": "846ec9a9-4175-4fe4-aabf-b39272aa7411", "source": "arxiv", "section": "computerScience"}, {"title": "How to Drawjectory? -- Trajectory Planning using Programming by Demonstration", "link": "https://arxiv.org/abs/2411.03815", "description": "arXiv:2411.03815v1 Announce Type: new \nAbstract: A flight trajectory defines how exactly a quadrocopter moves in the three-dimensional space from one position to another. Automatic flight trajectory planning faces challenges such as high computational effort and a lack of precision. Hence, when low computational effort or precise control is required, programming the flight route trajectory manually might be preferable. However, this requires in-depth knowledge of how to accurately plan flight trajectories in three-dimensional space. We propose planning quadrocopter flight trajectories manually using the Programming by Demonstration (PbD) approach -- simply drawing the trajectory in the three-dimensional space by hand. This simplifies the planning process and reduces the level of in-depth knowledge required.\n  We implemented the approach in the context of the Quadcopter Lab at Ulm University. In order to evaluate our approach, we compare the precision and accuracy of the trajectories drawn by a user using our approach as well as the required time with those manually programmed using a domain specific language. The evaluation shows that the Drawjectory workflow is, on average, 78.7 seconds faster without a significant loss of precision, shown by an average deviation 6.67 cm.", "published": "2024-11-07 05:00:00", "id": "1dceaee0-e6e5-4ab9-b0bd-61e3a14d742c", "source": "arxiv", "section": "computerScience"}, {"title": "From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning", "link": "https://arxiv.org/abs/2411.03817", "description": "arXiv:2411.03817v1 Announce Type: new \nAbstract: The outstanding capabilities of large language models (LLMs) render them a crucial component in various autonomous agent systems. While traditional methods depend on the inherent knowledge of LLMs without fine-tuning, more recent approaches have shifted toward the reinforcement learning strategy to further enhance agents' ability to solve complex interactive tasks with environments and tools. However, previous approaches are constrained by the sparse reward issue, where existing datasets solely provide a final scalar reward for each multi-step reasoning chain, potentially leading to ineffectiveness and inefficiency in policy learning. In this paper, we introduce StepAgent, which utilizes step-wise reward to optimize the agent's reinforcement learning process. Inheriting the spirit of novice-to-expert theory, we first compare the actions of the expert and the agent to automatically generate intermediate rewards for fine-grained optimization. Additionally, we propose implicit-reward and inverse reinforcement learning techniques to facilitate agent reflection and policy adjustment. Further theoretical analysis demonstrates that the action distribution of the agent can converge toward the expert action distribution over multiple training cycles. Experimental results across various datasets indicate that StepAgent outperforms existing baseline methods.", "published": "2024-11-07 05:00:00", "id": "e5eef580-0ae3-4572-b964-00d0112657b3", "source": "arxiv", "section": "computerScience"}, {"title": "SA3DIP: Segment Any 3D Instance with Potential 3D Priors", "link": "https://arxiv.org/abs/2411.03819", "description": "arXiv:2411.03819v1 Announce Type: new \nAbstract: The proliferation of 2D foundation models has sparked research into adapting them for open-world 3D instance segmentation. Recent methods introduce a paradigm that leverages superpoints as geometric primitives and incorporates 2D multi-view masks from Segment Anything model (SAM) as merging guidance, achieving outstanding zero-shot instance segmentation results. However, the limited use of 3D priors restricts the segmentation performance. Previous methods calculate the 3D superpoints solely based on estimated normal from spatial coordinates, resulting in under-segmentation for instances with similar geometry. Besides, the heavy reliance on SAM and hand-crafted algorithms in 2D space suffers from over-segmentation due to SAM's inherent part-level segmentation tendency. To address these issues, we propose SA3DIP, a novel method for Segmenting Any 3D Instances via exploiting potential 3D Priors. Specifically, on one hand, we generate complementary 3D primitives based on both geometric and textural priors, which reduces the initial errors that accumulate in subsequent procedures. On the other hand, we introduce supplemental constraints from the 3D space by using a 3D detector to guide a further merging process. Furthermore, we notice a considerable portion of low-quality ground truth annotations in ScanNetV2 benchmark, which affect the fair evaluations. Thus, we present ScanNetV2-INS with complete ground truth labels and supplement additional instances for 3D class-agnostic instance segmentation. Experimental evaluations on various 2D-3D datasets demonstrate the effectiveness and robustness of our approach. Our code and proposed ScanNetV2-INS dataset are available HERE.", "published": "2024-11-07 05:00:00", "id": "e59368ff-0814-4f02-9ada-925f1b0ec6e0", "source": "arxiv", "section": "computerScience"}, {"title": "Beyond The Rainbow: High Performance Deep Reinforcement Learning On A Desktop PC", "link": "https://arxiv.org/abs/2411.03820", "description": "arXiv:2411.03820v1 Announce Type: new \nAbstract: Rainbow Deep Q-Network (DQN) demonstrated combining multiple independent enhancements could significantly boost a reinforcement learning (RL) agent's performance. In this paper, we present \"Beyond The Rainbow\" (BTR), a novel algorithm that integrates six improvements from across the RL literature to Rainbow DQN, establishing a new state-of-the-art for RL using a desktop PC, with a human-normalized interquartile mean (IQM) of 7.4 on atari-60. Beyond Atari, we demonstrate BTR's capability to handle complex 3D games, successfully training agents to play Super Mario Galaxy, Mario Kart, and Mortal Kombat with minimal algorithmic changes. Designing BTR with computational efficiency in mind, agents can be trained using a desktop PC on 200 million Atari frames within 12 hours. Additionally, we conduct detailed ablation studies of each component, analzying the performance and impact using numerous measures.", "published": "2024-11-07 05:00:00", "id": "707a0363-2e32-4580-ad90-367af94b362a", "source": "arxiv", "section": "computerScience"}, {"title": "Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination", "link": "https://arxiv.org/abs/2411.03823", "description": "arXiv:2411.03823v1 Announce Type: new \nAbstract: The rapid progression of multimodal large language models (MLLMs) has demonstrated superior performance on various multimodal benchmarks. However, the issue of data contamination during training creates challenges in performance evaluation and comparison. While numerous methods exist for detecting dataset contamination in large language models (LLMs), they are less effective for MLLMs due to their various modalities and multiple training phases. In this study, we introduce a multimodal data contamination detection framework, MM-Detect, designed for MLLMs. Our experimental results indicate that MM-Detect is sensitive to varying degrees of contamination and can highlight significant performance improvements due to leakage of the training set of multimodal benchmarks. Furthermore, We also explore the possibility of contamination originating from the pre-training phase of LLMs used by MLLMs and the fine-tuning phase of MLLMs, offering new insights into the stages at which contamination may be introduced.", "published": "2024-11-07 05:00:00", "id": "41249fbb-7822-4d03-959c-7bb1e2d5fe2a", "source": "arxiv", "section": "computerScience"}, {"title": "DesignMinds: Enhancing Video-Based Design Ideation with Vision-Language Model and Context-Injected Large Language Model", "link": "https://arxiv.org/abs/2411.03827", "description": "arXiv:2411.03827v1 Announce Type: new \nAbstract: Ideation is a critical component of video-based design (VBD), where videos serve as the primary medium for design exploration and inspiration. The emergence of generative AI offers considerable potential to enhance this process by streamlining video analysis and facilitating idea generation. In this paper, we present DesignMinds, a prototype that integrates a state-of-the-art Vision-Language Model (VLM) with a context-enhanced Large Language Model (LLM) to support ideation in VBD. To evaluate DesignMinds, we conducted a between-subject study with 35 design practitioners, comparing its performance to a baseline condition. Our results demonstrate that DesignMinds significantly enhances the flexibility and originality of ideation, while also increasing task engagement. Importantly, the introduction of this technology did not negatively impact user experience, technology acceptance, or usability.", "published": "2024-11-07 05:00:00", "id": "7a05e66c-d977-4744-9d6d-9324ce50fdbc", "source": "arxiv", "section": "computerScience"}, {"title": "Generalize or Detect? Towards Robust Semantic Segmentation Under Multiple Distribution Shifts", "link": "https://arxiv.org/abs/2411.03829", "description": "arXiv:2411.03829v1 Announce Type: new \nAbstract: In open-world scenarios, where both novel classes and domains may exist, an ideal segmentation model should detect anomaly classes for safety and generalize to new domains. However, existing methods often struggle to distinguish between domain-level and semantic-level distribution shifts, leading to poor out-of-distribution (OOD) detection or domain generalization performance. In this work, we aim to equip the model to generalize effectively to covariate-shift regions while precisely identifying semantic-shift regions. To achieve this, we design a novel generative augmentation method to produce coherent images that incorporate both anomaly (or novel) objects and various covariate shifts at both image and object levels. Furthermore, we introduce a training strategy that recalibrates uncertainty specifically for semantic shifts and enhances the feature extractor to align features associated with domain shifts. We validate the effectiveness of our method across benchmarks featuring both semantic and domain shifts. Our method achieves state-of-the-art performance across all benchmarks for both OOD detection and domain generalization. Code is available at https://github.com/gaozhitong/MultiShiftSeg.", "published": "2024-11-07 05:00:00", "id": "363236c9-0dd0-458f-abe6-22730eb89ca8", "source": "arxiv", "section": "computerScience"}, {"title": "An Enhancement of Haar Cascade Algorithm Applied to Face Recognition for Gate Pass Security", "link": "https://arxiv.org/abs/2411.03831", "description": "arXiv:2411.03831v1 Announce Type: new \nAbstract: This study is focused on enhancing the Haar Cascade Algorithm to decrease the false positive and false negative rate in face matching and face detection to increase the accuracy rate even under challenging conditions. The face recognition library was implemented with Haar Cascade Algorithm in which the 128-dimensional vectors representing the unique features of a face are encoded. A subprocess was applied where the grayscale image from Haar Cascade was converted to RGB to improve the face encoding. Logical process and face filtering are also used to decrease non-face detection. The Enhanced Haar Cascade Algorithm produced a 98.39% accuracy rate (21.39% increase), 63.59% precision rate, 98.30% recall rate, and 72.23% in F1 Score. In comparison, the Haar Cascade Algorithm achieved a 46.70% to 77.00% accuracy rate, 44.15% precision rate, 98.61% recall rate, and 47.01% in F1 Score. Both algorithms used the Confusion Matrix Test with 301,950 comparisons using the same dataset of 550 images. The 98.39% accuracy rate shows a significant decrease in false positive and false negative rates in facial recognition. Face matching and face detection are more accurate in images with complex backgrounds, lighting variations, and occlusions, or even those with similar attributes.", "published": "2024-11-07 05:00:00", "id": "ea8b0517-d40a-4ed8-abc3-fc894eba1b0f", "source": "arxiv", "section": "computerScience"}, {"title": "DART-PIM: DNA read mApping acceleRaTor Using Processing-In-Memory", "link": "https://arxiv.org/abs/2411.03832", "description": "arXiv:2411.03832v1 Announce Type: new \nAbstract: Genome analysis has revolutionized fields such as personalized medicine and forensics. Modern sequencing machines generate vast amounts of fragmented strings of genome data called reads. The alignment of these reads into a complete DNA sequence of an organism (the read mapping process) requires extensive data transfer between processing units and memory, leading to execution bottlenecks. Prior studies have primarily focused on accelerating specific stages of the read-mapping task. Conversely, this paper introduces a holistic framework called DART-PIM that accelerates the entire read-mapping process. DART-PIM facilitates digital processing-in-memory (PIM) for an end-to-end acceleration of the entire read-mapping process, from indexing using a unique data organization schema to filtering and read alignment with an optimized Wagner Fischer algorithm. A comprehensive performance evaluation with real genomic data shows that DART-PIM achieves a 5.7x and 257x improvement in throughput and a 92x and 27x energy efficiency enhancement compared to state-of-the-art GPU and PIM implementations, respectively.", "published": "2024-11-07 05:00:00", "id": "bf5c4fc6-f9ae-4240-922f-15c87e3e4238", "source": "arxiv", "section": "computerScience"}, {"title": "Reachability analysis for piecewise affine systems with neural network-based controllers", "link": "https://arxiv.org/abs/2411.03834", "description": "arXiv:2411.03834v1 Announce Type: new \nAbstract: Neural networks (NN) have been successfully applied to approximate various types of complex control laws, resulting in low-complexity NN-based controllers that are fast to evaluate. However, when approximating control laws using NN, performance and stability guarantees of the original controller may not be preserved. Recently, it has been shown that it is possible to provide such guarantees for linear systems with NN-based controllers by analyzing the approximation error with respect to a stabilizing base-line controller or by computing reachable sets of the closed-loop system. The latter has the advantage of not requiring a base-line controller. In this paper, we show that similar ideas can be used to analyze the closed-loop behavior of piecewise affine (PWA) systems with an NN-based controller. Our approach builds on computing over-approximations of reachable sets using mixed-integer linear programming, which allows to certify that the closed-loop system converges to a small set containing the origin while satisfying input and state constraints. We also show how to modify a given NN-based controller to ensure asymptotic stability for the controlled PWA system.", "published": "2024-11-07 05:00:00", "id": "f6c22a23-8f55-497d-bcf3-c9fc513ff84f", "source": "arxiv", "section": "computerScience"}, {"title": "An Edge Computing-Based Solution for Real-Time Leaf Disease Classification using Thermal Imaging", "link": "https://arxiv.org/abs/2411.03835", "description": "arXiv:2411.03835v1 Announce Type: new \nAbstract: Deep learning (DL) technologies can transform agriculture by improving crop health monitoring and management, thus improving food safety. In this paper, we explore the potential of edge computing for real-time classification of leaf diseases using thermal imaging. We present a thermal image dataset for plant disease classification and evaluate deep learning models, including InceptionV3, MobileNetV1, MobileNetV2, and VGG-16, on resource-constrained devices like the Raspberry Pi 4B. Using pruning and quantization-aware training, these models achieve inference times up to 1.48x faster on Edge TPU Max for VGG16, and up to 2.13x faster with precision reduction on Intel NCS2 for MobileNetV1, compared to high-end GPUs like the RTX 3090, while maintaining state-of-the-art accuracy.", "published": "2024-11-07 05:00:00", "id": "bc7fe6b9-9922-469c-b80b-d80ae0e0402d", "source": "arxiv", "section": "computerScience"}, {"title": "Fundamental Three-Dimensional Configuration of Wire-Wound Muscle-Tendon Complex Drive", "link": "https://arxiv.org/abs/2411.03838", "description": "arXiv:2411.03838v1 Announce Type: new \nAbstract: For robots to become more versatile and expand their areas of application, their bodies need to be suitable for contact with the environment. When the human body comes into contact with the environment, it is possible for it to continue to move even if the positional relationship between muscles or the shape of the muscles changes. We have already focused on the effect of geometric deformation of muscles and proposed a drive system called wire-wound Muscle-Tendon Complex (ww-MTC), an extension of the wire drive system. Our previous study using a robot with a two-dimensional configuration demonstrated several advantages: reduced wire loosening, interference, and wear; improved robustness during environmental contact; and a muscular appearance. However, this design had some problems, such as excessive muscle expansion that hindered inter-muscle movement, and confinement to planar motion. In this study, we develop the ww-MTC into a three-dimensional shape. We present a fundamental construction method for a muscle exterior that expands gently and can be contacted over its entire surface. We also apply the three-dimensional ww-MTC to a 2-axis 3-muscle robot, and confirm that the robot can continue to move while adapting to its environment.", "published": "2024-11-07 05:00:00", "id": "ee596003-51c2-4db6-8e8e-29939ebff912", "source": "arxiv", "section": "computerScience"}, {"title": "Noisy Linear Group Testing: Exact Thresholds and Efficient Algorithms", "link": "https://arxiv.org/abs/2411.03839", "description": "arXiv:2411.03839v1 Announce Type: new \nAbstract: In group testing, the task is to identify defective items by testing groups of them together using as few tests as possible. We consider the setting where each item is defective with a constant probability $\\alpha$, independent of all other items. In the (over-)idealized noiseless setting, tests are positive exactly if any of the tested items are defective. We study a more realistic model in which observed test results are subject to noise, i.e., tests can display false positive or false negative results with constant positive probabilities. We determine precise constants $c$ such that $cn\\log n$ tests are required to recover the infection status of every individual for both adaptive and non-adaptive group testing: in the former, the selection of groups to test can depend on previously observed test results, whereas it cannot in the latter. Additionally, for both settings, we provide efficient algorithms that identify all defective items with the optimal amount of tests with high probability. Thus, we completely solve the problem of binary noisy group testing in the studied setting.", "published": "2024-11-07 05:00:00", "id": "3413422d-7fc3-4ded-8e6d-898c83024cb2", "source": "arxiv", "section": "computerScience"}, {"title": "Flexible task abstractions emerge in linear networks with fast and bounded units", "link": "https://arxiv.org/abs/2411.03840", "description": "arXiv:2411.03840v1 Announce Type: new \nAbstract: Animals survive in dynamic environments changing at arbitrary timescales, but such data distribution shifts are a challenge to neural networks. To adapt to change, neural systems may change a large number of parameters, which is a slow process involving forgetting past information. In contrast, animals leverage distribution changes to segment their stream of experience into tasks and associate them with internal task abstracts. Animals can then respond flexibly by selecting the appropriate task abstraction. However, how such flexible task abstractions may arise in neural systems remains unknown. Here, we analyze a linear gated network where the weights and gates are jointly optimized via gradient descent, but with neuron-like constraints on the gates including a faster timescale, nonnegativity, and bounded activity. We observe that the weights self-organize into modules specialized for tasks or sub-tasks encountered, while the gates layer forms unique representations that switch the appropriate weight modules (task abstractions). We analytically reduce the learning dynamics to an effective eigenspace, revealing a virtuous cycle: fast adapting gates drive weight specialization by protecting previous knowledge, while weight specialization in turn increases the update rate of the gating layer. Task switching in the gating layer accelerates as a function of curriculum block size and task training, mirroring key findings in cognitive neuroscience. We show that the discovered task abstractions support generalization through both task and subtask composition, and we extend our findings to a non-linear network switching between two tasks. Overall, our work offers a theory of cognitive flexibility in animals as arising from joint gradient descent on synaptic and neural gating in a neural network architecture.", "published": "2024-11-07 05:00:00", "id": "5f327598-8876-4a22-a8e2-c21d5a9f1f06", "source": "arxiv", "section": "computerScience"}, {"title": "Attribute-Based Encryption With Payable Outsourced Decryption Using Blockchain and Responsive Zero Knowledge Proof", "link": "https://arxiv.org/abs/2411.03844", "description": "arXiv:2411.03844v1 Announce Type: new \nAbstract: Attribute-Based Encryption (ABE) is a promising solution for access control in cloud services. However, the heavy decryption overhead hinders its widespread adoption. A general approach to address this issue is to outsource decryption to decryption cloud service(DCS). Existing schemes have utilized various methods to enable users to verify outsourced results; however, they lack an effective mechanism to achieve exemptibility which enables the honest DCS to escape from wrong claims. And it is impractical to assume that the DCS will provide free services. In this paper, we propose a blockchain-based payable outsourced decryption ABE scheme that achieves both verifiability and exemptibility without adding redundant information to ABE ciphertext. We use zero-knowledge proof to verify outsourced results on blockchain and introduce an optional single-round challenge game under optimistic assumption to address the high cost of proof generation. Moreover, our system achieves fairness and decentralized outsourcing to protect the interests of all parties. Finally, we implement and evaluate our scheme on Ethereum to demonstrate its feasibility and efficiency, the gas usage in attribute numbers from 5 to 60 is 11$\\times$ to 140$\\times$ in the happy case and 4$\\times$ to 55$\\times$ in the challenge case lower than the scheme of Ge et al. (TDSC'23).", "published": "2024-11-07 05:00:00", "id": "147100d5-44b0-4d92-8ed3-a546a255f803", "source": "arxiv", "section": "computerScience"}, {"title": "Reconsidering the Performance of GAE in Link Prediction", "link": "https://arxiv.org/abs/2411.03845", "description": "arXiv:2411.03845v1 Announce Type: new \nAbstract: Various graph neural networks (GNNs) with advanced training techniques and model designs have been proposed for link prediction tasks. However, outdated baseline models may lead to an overestimation of the benefits provided by these novel approaches. To address this, we systematically investigate the potential of Graph Autoencoders (GAE) by meticulously tuning hyperparameters and utilizing the trick of orthogonal embedding and linear propagation. Our findings reveal that a well-optimized GAE can match the performance of more complex models while offering greater computational efficiency.", "published": "2024-11-07 05:00:00", "id": "4e117ea4-6486-4fde-8b95-321cc171e9a0", "source": "arxiv", "section": "computerScience"}, {"title": "A Novel Access Control and Privacy-Enhancing Approach for Models in Edge Computing", "link": "https://arxiv.org/abs/2411.03847", "description": "arXiv:2411.03847v1 Announce Type: new \nAbstract: With the widespread adoption of edge computing technologies and the increasing prevalence of deep learning models in these environments, the security risks and privacy threats to models and data have grown more acute. Attackers can exploit various techniques to illegally obtain models or misuse data, leading to serious issues such as intellectual property infringement and privacy breaches. Existing model access control technologies primarily rely on traditional encryption and authentication methods; however, these approaches exhibit significant limitations in terms of flexibility and adaptability in dynamic environments. Although there have been advancements in model watermarking techniques for marking model ownership, they remain limited in their ability to proactively protect intellectual property and prevent unauthorized access. To address these challenges, we propose a novel model access control method tailored for edge computing environments. This method leverages image style as a licensing mechanism, embedding style recognition into the model's operational framework to enable intrinsic access control. Consequently, models deployed on edge platforms are designed to correctly infer only on license data with specific style, rendering them ineffective on any other data. By restricting the input data to the edge model, this approach not only prevents attackers from gaining unauthorized access to the model but also enhances the privacy of data on terminal devices. We conducted extensive experiments on benchmark datasets, including MNIST, CIFAR-10, and FACESCRUB, and the results demonstrate that our method effectively prevents unauthorized access to the model while maintaining accuracy. Additionally, the model shows strong resistance against attacks such as forged licenses and fine-tuning. These results underscore the method's usability, security, and robustness.", "published": "2024-11-07 05:00:00", "id": "41252076-f141-4751-965d-ac9f9e2bfe47", "source": "arxiv", "section": "computerScience"}, {"title": "MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba", "link": "https://arxiv.org/abs/2411.03855", "description": "arXiv:2411.03855v1 Announce Type: new \nAbstract: An ecosystem of Transformer-based models has been established by building large models with extensive data. Parameter-efficient fine-tuning (PEFT) is a crucial technology for deploying these models to downstream tasks with minimal cost while achieving effective performance. Recently, Mamba, a State Space Model (SSM)-based model, has attracted attention as a potential alternative to Transformers. While many large-scale Mamba-based models have been proposed, efficiently adapting pre-trained Mamba-based models to downstream tasks remains unexplored. In this paper, we conduct an exploratory analysis of PEFT methods for Mamba. We investigate the effectiveness of existing PEFT methods for Transformers when applied to Mamba. We also modify these methods to better align with the Mamba architecture. Additionally, we propose new Mamba-specific PEFT methods that leverage the distinctive structure of Mamba. Our experiments indicate that PEFT performs more effectively for Mamba than Transformers. Lastly, we demonstrate how to effectively combine multiple PEFT methods and provide a framework that outperforms previous works. To ensure reproducibility, we will release the code after publication.", "published": "2024-11-07 05:00:00", "id": "3b6a053a-8636-42ef-a606-fdbe953be4a5", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient Message Passing Architecture for GCN Training on HBM-based FPGAs with Orthogonal Topology On-Chip Networks", "link": "https://arxiv.org/abs/2411.03857", "description": "arXiv:2411.03857v1 Announce Type: new \nAbstract: Graph Convolutional Networks (GCNs) are state-of-the-art deep learning models for representation learning on graphs. However, the efficient training of GCNs is hampered by constraints in memory capacity and bandwidth, compounded by the irregular data flow that results in communication bottlenecks. To address these challenges, we propose a message-passing architecture that leverages NUMA-based memory access properties and employs a parallel multicast routing algorithm based on a 4-D hypercube network within the accelerator for efficient message passing in graphs. Additionally, we have re-engineered the backpropagation algorithm specific to GCNs within our proposed accelerator. This redesign strategically mitigates the memory demands prevalent during the training phase and diminishes the computational overhead associated with the transposition of extensive matrices. Compared to the state-of-the-art HP-GNN architecture we achieved a performance improvement of $1.03\\times \\sim 1.81\\times$.", "published": "2024-11-07 05:00:00", "id": "39d7c15f-ce27-4da0-b563-3fd4131e2c7c", "source": "arxiv", "section": "computerScience"}, {"title": "UniTraj: Universal Human Trajectory Modeling from Billion-Scale Worldwide Traces", "link": "https://arxiv.org/abs/2411.03859", "description": "arXiv:2411.03859v1 Announce Type: new \nAbstract: Human trajectory modeling is essential for deciphering movement patterns and supporting advanced applications across various domains. However, existing methods are often tailored to specific tasks and regions, resulting in limitations related to task specificity, regional dependency, and data quality sensitivity. Addressing these challenges requires a universal human trajectory foundation model capable of generalizing and scaling across diverse tasks and geographic contexts. To this end, we propose UniTraj, a Universal human Trajectory foundation model that is task-adaptive, region-independent, and highly generalizable. To further enhance performance, we construct WorldTrace, the first large-scale, high-quality, globally distributed dataset sourced from open web platforms, encompassing 2.45 million trajectories with billions of points across 70 countries. Through multiple resampling and masking strategies designed for pre-training, UniTraj effectively overcomes geographic and task constraints, adapting to heterogeneous data quality. Extensive experiments across multiple trajectory analysis tasks and real-world datasets demonstrate that UniTraj consistently outperforms existing approaches in terms of scalability and adaptability. These results underscore the potential of UniTraj as a versatile, robust solution for a wide range of trajectory analysis applications, with WorldTrace serving as an ideal but non-exclusive foundation for training.", "published": "2024-11-07 05:00:00", "id": "99785765-abcd-419d-8ac3-d1df2e3717bd", "source": "arxiv", "section": "computerScience"}, {"title": "FedRISE: Rating Induced Sign Election of Gradients for Byzantine Tolerant Federated Aggregation", "link": "https://arxiv.org/abs/2411.03861", "description": "arXiv:2411.03861v1 Announce Type: new \nAbstract: One of the most common defense strategies against model poisoning in federated learning is to employ a robust aggregator mechanism that makes the training more resilient. Many of the existing Byzantine robust aggregators provide theoretical guarantees and are empirically effective against certain categories of attacks. However, we observe that certain high-strength attacks can subvert the aggregator and collapse the training. In addition, most aggregators require identifying tolerant settings to converge. Impact of attacks becomes more pronounced when the number of Byzantines is near-majority, and becomes harder to evade if the attacker is omniscient with access to data, honest updates and aggregation methods. Motivated by these observations, we develop a robust aggregator called FedRISE for cross-silo FL that is consistent and less susceptible to poisoning updates by an omniscient attacker. The proposed method explicitly determines the optimal direction of each gradient through a sign-voting strategy that uses variance-reduced sparse gradients. We argue that vote weighting based on the cosine similarity of raw gradients is misleading, and we introduce a sign-based gradient valuation function that ignores the gradient magnitude. We compare our method against 8 robust aggregators under 6 poisoning attacks on 3 datasets and architectures. Our results show that existing robust aggregators collapse for at least some attacks under severe settings, while FedRISE demonstrates better robustness because of a stringent gradient inclusion formulation.", "published": "2024-11-07 05:00:00", "id": "92706d57-d297-48de-9bde-4b71696e5572", "source": "arxiv", "section": "computerScience"}, {"title": "ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization", "link": "https://arxiv.org/abs/2411.03862", "description": "arXiv:2411.03862v1 Announce Type: new \nAbstract: Watermarking generative content serves as a vital tool for authentication, ownership protection, and mitigation of potential misuse. Existing watermarking methods face the challenge of balancing robustness and concealment. They empirically inject a watermark that is both invisible and robust and passively achieve concealment by limiting the strength of the watermark, thus reducing the robustness. In this paper, we propose to explicitly introduce a watermark hiding process to actively achieve concealment, thus allowing the embedding of stronger watermarks. To be specific, we implant a robust watermark in an intermediate diffusion state and then guide the model to hide the watermark in the final generated image. We employ an adversarial optimization algorithm to produce the optimal hiding prompt guiding signal for each watermark. The prompt embedding is optimized to minimize artifacts in the generated image, while the watermark is optimized to achieve maximum strength. The watermark can be verified by reversing the generation process. Experiments on various diffusion models demonstrate the watermark remains verifiable even under significant image tampering and shows superior invisibility compared to other state-of-the-art robust watermarking methods.", "published": "2024-11-07 05:00:00", "id": "d2afec89-b4cb-4c65-9288-98fa074940fd", "source": "arxiv", "section": "computerScience"}, {"title": "AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making", "link": "https://arxiv.org/abs/2411.03865", "description": "arXiv:2411.03865v1 Announce Type: new \nAbstract: Traditional interactive environments limit agents' intelligence growth with fixed tasks. Recently, single-agent environments address this by generating new tasks based on agent actions, enhancing task diversity. We consider the decision-making problem in multi-agent settings, where tasks are further influenced by social connections, affecting rewards and information access. However, existing multi-agent environments lack a combination of adaptive physical surroundings and social connections, hindering the learning of intelligent behaviors. To address this, we introduce AdaSociety, a customizable multi-agent environment featuring expanding state and action spaces, alongside explicit and alterable social structures. As agents progress, the environment adaptively generates new tasks with social structures for agents to undertake. In AdaSociety, we develop three mini-games showcasing distinct social structures and tasks. Initial results demonstrate that specific social structures can promote both individual and collective benefits, though current reinforcement learning and LLM-based algorithms show limited effectiveness in leveraging social structures to enhance performance. Overall, AdaSociety serves as a valuable research platform for exploring intelligence in diverse physical and social settings. The code is available at https://github.com/bigai-ai/AdaSociety.", "published": "2024-11-07 05:00:00", "id": "ca531fca-a637-4bbc-a435-cfcb98753e8f", "source": "arxiv", "section": "computerScience"}, {"title": "Performance evaluation of SLAM-ASR: The Good, the Bad, the Ugly, and the Way Forward", "link": "https://arxiv.org/abs/2411.03866", "description": "arXiv:2411.03866v1 Announce Type: new \nAbstract: Recent research has demonstrated that training a linear connector between speech foundation encoders and large language models (LLMs) enables this architecture to achieve strong ASR capabilities. Despite the impressive results, it remains unclear whether these simple approaches are robust enough across different scenarios and speech conditions, such as domain shifts and different speech perturbations. In this paper, we address these questions by conducting various ablation experiments using a recent and widely adopted approach called SLAM-ASR. We present novel empirical findings that offer insights on how to effectively utilize the SLAM-ASR architecture across a wide range of settings. Our main findings indicate that the SLAM-ASR exhibits poor performance in cross-domain evaluation settings. Additionally, speech perturbations within in-domain data, such as changes in speed or the presence of additive noise, can significantly impact performance. Our findings offer critical insights for fine-tuning and configuring robust LLM-based ASR models, tailored to different data characteristics and computational resources.", "published": "2024-11-07 05:00:00", "id": "2070a1d8-eb68-4eae-9a9e-18a3366db85e", "source": "arxiv", "section": "computerScience"}, {"title": "Safe Paths and Sequences for Scalable ILPs in RNA Transcript Assembly Problems", "link": "https://arxiv.org/abs/2411.03871", "description": "arXiv:2411.03871v1 Announce Type: new \nAbstract: A common step at the core of many RNA transcript assembly tools is to find a set of weighted paths that best explain the weights of a DAG. While such problems easily become NP-hard, scalable solvers exist only for a basic error-free version of this problem, namely minimally decomposing a network flow into weighted paths.\n  The main result of this paper is to show that we can achieve speedups of two orders of magnitude also for path-finding problems in the realistic setting (i.e., the weights do not induce a flow). We obtain these by employing the safety information that is encoded in the graph structure inside Integer Linear Programming (ILP) solvers for these problems. We first characterize the paths that appear in all path covers of the DAG, generalizing a graph reduction commonly used in the error-free setting (e.g. by Kloster et al. [ALENEX~2018]). Secondly, following the work of Ma, Zheng and Kingsford [RECOMB 2021], we characterize the \\emph{sequences} of arcs that appear in all path covers of the DAG.\n  We experiment with a path-finding ILP model (least squares) and with a more recent and accurate one. We use a variety of datasets originally created by Shao and Kingsford [TCBB, 2017], as well as graphs built from sequencing reads by the state-of-the-art tool for long-read transcript discovery, IsoQuant [Prjibelski et al., Nat.~Biotechnology~2023]. The ILPs armed with safe paths or sequences exhibit significant speed-ups over the original ones. On graphs with a large width, average speed-ups are in the range $50-160\\times$ in the latter ILP model and in the range $100-1000\\times$ in the least squares model.\n  Our scaling techniques apply to any ILP whose solution paths are a path cover of the arcs of the DAG. As such, they can become a scalable building block of practical RNA transcript assembly tools, avoiding heuristic trade-offs currently needed on complex graphs.", "published": "2024-11-07 05:00:00", "id": "d3996462-c6bc-4384-a694-6a852120eb22", "source": "arxiv", "section": "computerScience"}, {"title": "Biomechanics-Aware Trajectory Optimization for Navigation during Robotic Physiotherapy", "link": "https://arxiv.org/abs/2411.03873", "description": "arXiv:2411.03873v1 Announce Type: new \nAbstract: Robotic devices hold promise for aiding patients in orthopedic rehabilitation. However, current robotic-assisted physiotherapy methods struggle including biomechanical metrics in their control algorithms, crucial for safe and effective therapy. This paper introduces BATON, a Biomechanics-Aware Trajectory Optimization approach to robotic Navigation of human musculoskeletal loads. The method integrates a high-fidelity musculoskeletal model of the human shoulder into real-time control of robot-patient interaction during rotator cuff tendon rehabilitation. We extract skeletal dynamics and tendon loading information from an OpenSim shoulder model to solve an optimal control problem, generating strain-minimizing trajectories. Trajectories were realized on a healthy subject by an impedance-controlled robot while estimating the state of the subject's shoulder. Target poses were prescribed to design personalized rehabilitation across a wide range of shoulder motion avoiding high-strain areas. BATON was designed with real-time capabilities, enabling continuous trajectory replanning to address unforeseen variations in tendon strain, such as those from changing muscle activation of the subject.", "published": "2024-11-07 05:00:00", "id": "8f30a869-0457-4ee3-ac40-824046904c30", "source": "arxiv", "section": "computerScience"}, {"title": "Koopman-based control using sum-of-squares optimization: Improved stability guarantees and data efficiency", "link": "https://arxiv.org/abs/2411.03875", "description": "arXiv:2411.03875v1 Announce Type: new \nAbstract: In this paper, we propose a novel controller design approach for unknown nonlinear systems using the Koopman operator. In particular, we use the recently proposed stability- and certificate-oriented extended dynamic mode decomposition (SafEDMD) architecture to generate a data-driven bilinear surrogate model with certified error bounds. Then, by accounting for the obtained error bounds in a controller design based on the bilinear system, one can guarantee closed-loop stability for the true nonlinear system. While existing approaches over-approximate the bilinearity of the surrogate model, thus introducing conservatism and providing only local guarantees, we explicitly account for the bilinearity by using sum-of-squares (SOS) optimization in the controller design. More precisely, we parametrize a rational controller stabilizing the error-affected bilinear surrogate model and, consequently, the underlying nonlinear system. The resulting SOS optimization problem provides explicit data-driven controller design conditions for unknown nonlinear systems based on semidefinite programming. Our approach significantly reduces conservatism by establishing a larger region of attraction and improved data efficiency. The proposed method is evaluated using numerical examples, demonstrating its advantages over existing approaches.", "published": "2024-11-07 05:00:00", "id": "0baa3bd6-7c85-4bb7-b50e-20267a6eda17", "source": "arxiv", "section": "computerScience"}, {"title": "Large Generative Model-assisted Talking-face Semantic Communication System", "link": "https://arxiv.org/abs/2411.03876", "description": "arXiv:2411.03876v1 Announce Type: new \nAbstract: The rapid development of generative Artificial Intelligence (AI) continually unveils the potential of Semantic Communication (SemCom). However, current talking-face SemCom systems still encounter challenges such as low bandwidth utilization, semantic ambiguity, and diminished Quality of Experience (QoE). This study introduces a Large Generative Model-assisted Talking-face Semantic Communication (LGM-TSC) System tailored for the talking-face video communication. Firstly, we introduce a Generative Semantic Extractor (GSE) at the transmitter based on the FunASR model to convert semantically sparse talking-face videos into texts with high information density. Secondly, we establish a private Knowledge Base (KB) based on the Large Language Model (LLM) for semantic disambiguation and correction, complemented by a joint knowledge base-semantic-channel coding scheme. Finally, at the receiver, we propose a Generative Semantic Reconstructor (GSR) that utilizes BERT-VITS2 and SadTalker models to transform text back into a high-QoE talking-face video matching the user's timbre. Simulation results demonstrate the feasibility and effectiveness of the proposed LGM-TSC system.", "published": "2024-11-07 05:00:00", "id": "8a40ec3a-d111-4ad6-b217-336577e1f556", "source": "arxiv", "section": "computerScience"}, {"title": "EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning", "link": "https://arxiv.org/abs/2411.03877", "description": "arXiv:2411.03877v1 Announce Type: new \nAbstract: Answering reasoning-based complex questions over text and hybrid sources, including tables, is a challenging task. Recent advances in large language models (LLMs) have enabled in-context learning (ICL), allowing LLMs to acquire proficiency in a specific task using only a few demonstration samples (exemplars). A critical challenge in ICL is the selection of optimal exemplars, which can be either task-specific (static) or test-example-specific (dynamic). Static exemplars provide faster inference times and increased robustness across a distribution of test examples. In this paper, we propose an algorithm for static exemplar subset selection for complex reasoning tasks. We introduce EXPLORA, a novel exploration method designed to estimate the parameters of the scoring function, which evaluates exemplar subsets without incorporating confidence information. EXPLORA significantly reduces the number of LLM calls to ~11% of those required by state-of-the-art methods and achieves a substantial performance improvement of 12.24%. We open-source our code and data (https://github.com/kiranpurohit/EXPLORA).", "published": "2024-11-07 05:00:00", "id": "d2d711b3-16e7-4ed7-b908-c7b7cdec0ad9", "source": "arxiv", "section": "computerScience"}, {"title": "Data Fusion of Synthetic Query Variants With Generative Large Language Models", "link": "https://arxiv.org/abs/2411.03881", "description": "arXiv:2411.03881v1 Announce Type: new \nAbstract: Considering query variance in information retrieval (IR) experiments is beneficial for retrieval effectiveness. Especially ranking ensembles based on different topically related queries retrieve better results than rankings based on a single query alone. Recently, generative instruction-tuned Large Language Models (LLMs) improved on a variety of different tasks in capturing human language. To this end, this work explores the feasibility of using synthetic query variants generated by instruction-tuned LLMs in data fusion experiments. More specifically, we introduce a lightweight, unsupervised, and cost-efficient approach that exploits principled prompting and data fusion techniques. In our experiments, LLMs produce more effective queries when provided with additional context information on the topic. Furthermore, our analysis based on four TREC newswire benchmarks shows that data fusion based on synthetic query variants is significantly better than baselines with single queries and also outperforms pseudo-relevance feedback methods. We publicly share the code and query datasets with the community as resources for follow-up studies.", "published": "2024-11-07 05:00:00", "id": "e2110ac0-0c74-4ce4-8cb5-ed20bb71e50d", "source": "arxiv", "section": "computerScience"}, {"title": "MEG: Medical Knowledge-Augmented Large Language Models for Question Answering", "link": "https://arxiv.org/abs/2411.03883", "description": "arXiv:2411.03883v1 Announce Type: new \nAbstract: Question answering is a natural language understanding task that involves reasoning over both explicit context and unstated, relevant domain knowledge. Large language models (LLMs), which underpin most contemporary question answering systems, struggle to induce how concepts relate in specialized domains such as medicine. Existing medical LLMs are also costly to train. In this work, we present MEG, a parameter-efficient approach for medical knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate graph embeddings into the LLM, enabling it to leverage external knowledge in a cost-effective way. We evaluate our method on four popular medical multiple-choice datasets and show that LLMs greatly benefit from the factual grounding provided by knowledge graph embeddings. MEG attains an average of +10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized models like BioMistral. We also show results based on Llama-3. Finally, we show that MEG's performance remains robust to the choice of graph encoder.", "published": "2024-11-07 05:00:00", "id": "caf8ec2b-f3e2-4d69-aead-9a7c1e94444c", "source": "arxiv", "section": "computerScience"}, {"title": "Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models", "link": "https://arxiv.org/abs/2411.03884", "description": "arXiv:2411.03884v1 Announce Type: new \nAbstract: Transformers have found extensive applications across various domains due to the powerful fitting capabilities. This success can be partially attributed to their inherent nonlinearity. Thus, in addition to the ReLU function employed in the original transformer architecture, researchers have explored alternative modules such as GeLU and SwishGLU to enhance nonlinearity and thereby augment representational capacity. In this paper, we propose a novel category of polynomial composition activations (PolyCom), designed to optimize the dynamics of transformers. Theoretically, we provide a comprehensive mathematical analysis of PolyCom, highlighting its enhanced expressivity and efficacy relative to other activation functions. Notably, we demonstrate that networks incorporating PolyCom achieve the $\\textbf{optimal approximation rate}$, indicating that PolyCom networks require minimal parameters to approximate general smooth functions in Sobolev spaces. We conduct empirical experiments on the pre-training configurations of large language models (LLMs), including both dense and sparse architectures. By substituting conventional activation functions with PolyCom, we enable LLMs to capture higher-order interactions within the data, thus improving performance metrics in terms of accuracy and convergence rates. Extensive experimental results demonstrate the effectiveness of our method, showing substantial improvements over other activation functions. Code is available at https://github.com/BryceZhuo/PolyCom.", "published": "2024-11-07 05:00:00", "id": "fa9967ac-1dd4-4f19-8698-e200b7da6e33", "source": "arxiv", "section": "computerScience"}, {"title": "Disability data futures: Achievable imaginaries for AI and disability data justice", "link": "https://arxiv.org/abs/2411.03885", "description": "arXiv:2411.03885v1 Announce Type: new \nAbstract: Data are the medium through which individuals' identities and experiences are filtered in contemporary states and systems, and AI is increasingly the layer mediating between people, data, and decisions. The history of data and AI is often one of disability exclusion, oppression, and the reduction of disabled experience; left unchallenged, the current proliferation of AI and data systems thus risks further automating ableism behind the veneer of algorithmic neutrality. However, exclusionary histories do not preclude inclusive futures, and disability-led visions can chart new paths for collective action to achieve futures founded in disability justice. This chapter brings together four academics and disability advocates working at the nexus of disability, data, and AI, to describe achievable imaginaries for artificial intelligence and disability data justice. Reflecting diverse contexts, disciplinary perspectives, and personal experiences, we draw out the shape, actors, and goals of imagined future systems where data and AI support movement towards disability justice.", "published": "2024-11-07 05:00:00", "id": "bd1eb3ad-9ffc-40a3-9d2a-5fe9070b8233", "source": "arxiv", "section": "computerScience"}, {"title": "OML: Open, Monetizable, and Loyal AI", "link": "https://arxiv.org/abs/2411.03887", "description": "arXiv:2411.03887v1 Announce Type: new \nAbstract: Artificial Intelligence (AI) has steadily improved across a wide range of tasks. However, the development and deployment of AI are almost entirely controlled by a few powerful organizations that are racing to create Artificial General Intelligence (AGI). The centralized entities make decisions with little public oversight, shaping the future of humanity, often with unforeseen consequences. In this paper, we propose OML, which stands for Open, Monetizable, and Loyal AI, an approach designed to democratize AI development. OML is realized through an interdisciplinary framework spanning AI, blockchain, and cryptography. We present several ideas for constructing OML using technologies such as Trusted Execution Environments (TEE), traditional cryptographic primitives like fully homomorphic encryption and functional encryption, obfuscation, and AI-native solutions rooted in the sample complexity and intrinsic hardness of AI tasks. A key innovation of our work is introducing a new scientific field: AI-native cryptography. Unlike conventional cryptography, which focuses on discrete data and binary security guarantees, AI-native cryptography exploits the continuous nature of AI data representations and their low-dimensional manifolds, focusing on improving approximate performance. One core idea is to transform AI attack methods, such as data poisoning, into security tools. This novel approach serves as a foundation for OML 1.0 which uses model fingerprinting to protect the integrity and ownership of AI models. The spirit of OML is to establish a decentralized, open, and transparent platform for AI development, enabling the community to contribute, monetize, and take ownership of AI models. By decentralizing control and ensuring transparency through blockchain technology, OML prevents the concentration of power and provides accountability in AI development that has not been possible before.", "published": "2024-11-07 05:00:00", "id": "9f6ffe7d-5300-4aa9-bb0a-499ee96ad98b", "source": "arxiv", "section": "computerScience"}, {"title": "Multi3Hate: Multimodal, Multilingual, and Multicultural Hate Speech Detection with Vision-Language Models", "link": "https://arxiv.org/abs/2411.03888", "description": "arXiv:2411.03888v1 Announce Type: new \nAbstract: Warning: this paper contains content that may be offensive or upsetting\n  Hate speech moderation on global platforms poses unique challenges due to the multimodal and multilingual nature of content, along with the varying cultural perceptions. How well do current vision-language models (VLMs) navigate these nuances? To investigate this, we create the first multimodal and multilingual parallel hate speech dataset, annotated by a multicultural set of annotators, called Multi3Hate. It contains 300 parallel meme samples across 5 languages: English, German, Spanish, Hindi, and Mandarin. We demonstrate that cultural background significantly affects multimodal hate speech annotation in our dataset. The average pairwise agreement among countries is just 74%, significantly lower than that of randomly selected annotator groups. Our qualitative analysis indicates that the lowest pairwise label agreement-only 67% between the USA and India-can be attributed to cultural factors. We then conduct experiments with 5 large VLMs in a zero-shot setting, finding that these models align more closely with annotations from the US than with those from other cultures, even when the memes and prompts are presented in the dominant language of the other culture. Code and dataset are available at https://github.com/MinhDucBui/Multi3Hate.", "published": "2024-11-07 05:00:00", "id": "836935d7-1cd9-404e-9e39-1b3fba82c1e7", "source": "arxiv", "section": "computerScience"}, {"title": "Calibrating for the Future:Enhancing Calorimeter Longevity with Deep Learning", "link": "https://arxiv.org/abs/2411.03891", "description": "arXiv:2411.03891v1 Announce Type: new \nAbstract: In the realm of high-energy physics, the longevity of calorimeters is paramount. Our research introduces a deep learning strategy to refine the calibration process of calorimeters used in particle physics experiments. We develop a Wasserstein GAN inspired methodology that adeptly calibrates the misalignment in calorimeter data due to aging or other factors. Leveraging the Wasserstein distance for loss calculation, this innovative approach requires a significantly lower number of events and resources to achieve high precision, minimizing absolute errors effectively. Our work extends the operational lifespan of calorimeters, thereby ensuring the accuracy and reliability of data in the long term, and is particularly beneficial for experiments where data integrity is crucial for scientific discovery.", "published": "2024-11-07 05:00:00", "id": "9c776e1e-153b-465b-aafb-21704d5dd840", "source": "arxiv", "section": "computerScience"}, {"title": "Two Sides of the Same Coin: Large-scale Measurements of Builder and Rollup after EIP-4844", "link": "https://arxiv.org/abs/2411.03892", "description": "arXiv:2411.03892v1 Announce Type: new \nAbstract: Web3 is reshaping decentralized ecosystems through innovations like Ethereum. Recently, EIP-4844 is implemented in Ethereum to support its Layer-2 scaling solutions, which introduces a new 128 KB data structure called blob. This upgrade incorporates type-3 transactions with blobs to verify data availability and reduce gas costs for rollups, significantly affecting the strategies of both builders and rollups. In this paper, we present an in-depth study of emerging strategies in builder and rollup markets after EIP-4844, containing hundred million transactions. We find that the efficiency of builder and rollup strategies is interdependent, akin to two sides of the same coin -- both cannot be optimized simultaneously. That is, when builders operate efficiently, rollups tend to overpay in fees, conversely, when rollups optimize their costs, builders may incur losses in inefficient transaction selection. From the side of builders, our results show that 29.48% of these blocks have been constructed inefficiently, which does not produce sufficient profits for builders. Through our evaluation from the side of rollups, we find that over 72.53% of type-3 transactions pay unnecessary fees, leading to notable economic costs of rollups. Our work provides critical insights into optimizing block construction and transaction strategies, advancing the economic efficiency and data scalability of Web3 infrastructures, yet, much like balancing a seesaw, the efficiency of builders and rollups cannot be optimized concurrently.", "published": "2024-11-07 05:00:00", "id": "95e14c0f-8f6e-4256-adf6-525852fcb844", "source": "arxiv", "section": "computerScience"}, {"title": "Computational Analysis of Gender Depiction in the Comedias of Calder\\'on de la Barca", "link": "https://arxiv.org/abs/2411.03895", "description": "arXiv:2411.03895v1 Announce Type: new \nAbstract: In theatre, playwrights use the portrayal of characters to explore culturally based gender norms. In this paper, we develop quantitative methods to study gender depiction in the non-religious works (comedias) of Pedro Calder\\'on de la Barca, a prolific Spanish 17th century author. We gather insights from a corpus of more than 100 plays by using a gender classifier and applying model explainability (attribution) methods to determine which text features are most influential in the model's decision to classify speech as 'male' or 'female', indicating the most gendered elements of dialogue in Calder\\'on's comedias in a human accessible manner. We find that female and male characters are portrayed differently and can be identified by the gender prediction model at practically useful accuracies (up to f=0.83). Analysis reveals semantic aspects of gender portrayal, and demonstrates that the model is even useful in providing a relatively accurate scene-by-scene prediction of cross-dressing characters.", "published": "2024-11-07 05:00:00", "id": "59d9b977-312d-423c-b849-bdcaab578f98", "source": "arxiv", "section": "computerScience"}, {"title": "Retentive Neural Quantum States: Efficient Ans\\\"atze for Ab Initio Quantum Chemistry", "link": "https://arxiv.org/abs/2411.03900", "description": "arXiv:2411.03900v1 Announce Type: new \nAbstract: Neural-network quantum states (NQS) has emerged as a powerful application of quantum-inspired deep learning for variational Monte Carlo methods, offering a competitive alternative to existing techniques for identifying ground states of quantum problems. A significant advancement toward improving the practical scalability of NQS has been the incorporation of autoregressive models, most recently transformers, as variational ansatze. Transformers learn sequence information with greater expressiveness than recurrent models, but at the cost of increased time complexity with respect to sequence length. We explore the use of the retentive network (RetNet), a recurrent alternative to transformers, as an ansatz for solving electronic ground state problems in $\\textit{ab initio}$ quantum chemistry. Unlike transformers, RetNets overcome this time complexity bottleneck by processing data in parallel during training, and recurrently during inference. We give a simple computational cost estimate of the RetNet and directly compare it with similar estimates for transformers, establishing a clear threshold ratio of problem-to-model size past which the RetNet's time complexity outperforms that of the transformer. Though this efficiency can comes at the expense of decreased expressiveness relative to the transformer, we overcome this gap through training strategies that leverage the autoregressive structure of the model -- namely, variational neural annealing. Our findings support the RetNet as a means of improving the time complexity of NQS without sacrificing accuracy. We provide further evidence that the ablative improvements of neural annealing extend beyond the RetNet architecture, suggesting it would serve as an effective general training strategy for autoregressive NQS.", "published": "2024-11-07 05:00:00", "id": "d7d08d5e-07ff-47b8-83f2-66ba8fd2c69b", "source": "arxiv", "section": "computerScience"}, {"title": "Almost Time-Optimal Loosely-Stabilizing Leader Election on Arbitrary Graphs Without Identifiers in Population Protocols", "link": "https://arxiv.org/abs/2411.03902", "description": "arXiv:2411.03902v1 Announce Type: new \nAbstract: The population protocol model is a computational model for passive mobile agents. We address the leader election problem, which determines a unique leader on arbitrary communication graphs starting from any configuration. Unfortunately, self-stabilizing leader election is impossible to be solved without knowing the exact number of agents; thus, we consider loosely-stabilizing leader election, which converges to safe configurations in a relatively short time, and holds the specification (maintains a unique leader) for a relatively long time. When agents have unique identifiers, Sudo et al.(2019) proposed a protocol that, given an upper bound $N$ for the number of agents $n$, converges in $O(mN\\log n)$ expected steps, where $m$ is the number of edges. When unique identifiers are not required, they also proposed a protocol that, using random numbers and given $N$, converges in $O(mN^2\\log{N})$ expected steps. Both protocols have a holding time of $\\Omega(e^{2N})$ expected steps and use $O(\\log{N})$ bits of memory. They also showed that the lower bound of the convergence time is $\\Omega(mN)$ expected steps for protocols with a holding time of $\\Omega(e^N)$ expected steps given $N$.\n  In this paper, we propose protocols that do not require unique identifiers. These protocols achieve convergence times close to the lower bound with increasing memory usage. Specifically, given $N$ and an upper bound $\\Delta$ for the maximum degree, we propose two protocols whose convergence times are $O(mN\\log n)$ and $O(mN\\log N)$ both in expectation and with high probability. The former protocol uses random numbers, while the latter does not require them. Both protocols utilize $O(\\Delta \\log N)$ bits of memory and hold the specification for $\\Omega(e^{2N})$ expected steps.", "published": "2024-11-07 05:00:00", "id": "3f76882f-2d27-482b-8fe0-342a5ead5f07", "source": "arxiv", "section": "computerScience"}, {"title": "Lexicalization Is All You Need: Examining the Impact of Lexical Knowledge in a Compositional QALD System", "link": "https://arxiv.org/abs/2411.03906", "description": "arXiv:2411.03906v1 Announce Type: new \nAbstract: In this paper, we examine the impact of lexicalization on Question Answering over Linked Data (QALD). It is well known that one of the key challenges in interpreting natural language questions with respect to SPARQL lies in bridging the lexical gap, that is mapping the words in the query to the correct vocabulary elements. We argue in this paper that lexicalization, that is explicit knowledge about the potential interpretations of a word with respect to the given vocabulary, significantly eases the task and increases the performance of QA systems. Towards this goal, we present a compositional QA system that can leverage explicit lexical knowledge in a compositional manner to infer the meaning of a question in terms of a SPARQL query. We show that such a system, given lexical knowledge, has a performance well beyond current QA systems, achieving up to a $35.8\\%$ increase in the micro $F_1$ score compared to the best QA system on QALD-9. This shows the importance and potential of including explicit lexical knowledge. In contrast, we show that LLMs have limited abilities to exploit lexical knowledge, with only marginal improvements compared to a version without lexical knowledge. This shows that LLMs have no ability to compositionally interpret a question on the basis of the meaning of its parts, a key feature of compositional approaches. Taken together, our work shows new avenues for QALD research, emphasizing the importance of lexicalization and compositionality.", "published": "2024-11-07 05:00:00", "id": "3887b527-c6f0-482e-99cc-d30e52c5ce3d", "source": "arxiv", "section": "computerScience"}, {"title": "Direct Adaptive Control of Grid-Connected Power Converters via Output-Feedback Data-Enabled Policy Optimization", "link": "https://arxiv.org/abs/2411.03909", "description": "arXiv:2411.03909v1 Announce Type: new \nAbstract: Power electronic converters are gradually becoming the main components of modern power systems due to the increasing integration of renewable energy sources. However, power converters may become unstable when interacting with the complex and time-varying power grid. To deal with this problem, an adaptive control design scheme for power converters is preferable, which can capture the closed-loop dynamical interaction between the converter and the grid via online data. In this paper, we propose an adaptive data-driven control method, called data-enabled policy optimization (DeePO), to stabilize power converters by using only online input-output data. Our contributions are threefold. First, we propose a covariance parameterization of partially observed linear systems with input-output data. Second, we develop a DeePO algorithm, which updates the parameterized policy with data-based gradient descent to achieve computationally efficient adaptive control. Third, we use high-fidelity simulations to verify that DeePO can effectively stabilize grid-connected power converters and quickly adapt to the changes in the power grid.", "published": "2024-11-07 05:00:00", "id": "922b4f1b-bc8e-4695-bbe6-6e722dbbcac5", "source": "arxiv", "section": "computerScience"}, {"title": "WiP: Towards a Secure SECP256K1 for Crypto Wallets: Hardware Architecture and Implementation", "link": "https://arxiv.org/abs/2411.03910", "description": "arXiv:2411.03910v1 Announce Type: new \nAbstract: The SECP256K1 elliptic curve algorithm is fundamental in cryptocurrency wallets for generating secure public keys from private keys, thereby ensuring the protection and ownership of blockchain-based digital assets. However, the literature highlights several successful side-channel attacks on hardware wallets that exploit SECP256K1 to extract private keys. This work proposes a novel hardware architecture for SECP256K1, optimized for side-channel attack resistance and efficient resource utilization. The architecture incorporates complete addition formulas, temporary registers, and parallel processing techniques, making elliptic curve point addition and doubling operations indistinguishable. Implementation results demonstrate an average reduction of 45% in LUT usage compared to similar works, emphasizing the design's resource efficiency.", "published": "2024-11-07 05:00:00", "id": "25232218-2aa8-4813-b822-e37703f3e881", "source": "arxiv", "section": "computerScience"}, {"title": "Game-Theoretic Machine Unlearning: Mitigating Extra Privacy Leakage", "link": "https://arxiv.org/abs/2411.03914", "description": "arXiv:2411.03914v1 Announce Type: new \nAbstract: With the extensive use of machine learning technologies, data providers encounter increasing privacy risks. Recent legislation, such as GDPR, obligates organizations to remove requested data and its influence from a trained model. Machine unlearning is an emerging technique designed to enable machine learning models to erase users' private information. Although several efficient machine unlearning schemes have been proposed, these methods still have limitations. First, removing the contributions of partial data may lead to model performance degradation. Second, discrepancies between the original and generated unlearned models can be exploited by attackers to obtain target sample's information, resulting in additional privacy leakage risks. To address above challenges, we proposed a game-theoretic machine unlearning algorithm that simulates the competitive relationship between unlearning performance and privacy protection. This algorithm comprises unlearning and privacy modules. The unlearning module possesses a loss function composed of model distance and classification error, which is used to derive the optimal strategy. The privacy module aims to make it difficult for an attacker to infer membership information from the unlearned data, thereby reducing the privacy leakage risk during the unlearning process. Additionally, the experimental results on real-world datasets demonstrate that this game-theoretic unlearning algorithm's effectiveness and its ability to generate an unlearned model with a performance similar to that of the retrained one while mitigating extra privacy leakage risks.", "published": "2024-11-07 05:00:00", "id": "85fb8919-12db-4fe7-8175-344a8c83b3e9", "source": "arxiv", "section": "computerScience"}, {"title": "RAGulator: Lightweight Out-of-Context Detectors for Grounded Text Generation", "link": "https://arxiv.org/abs/2411.03920", "description": "arXiv:2411.03920v1 Announce Type: new \nAbstract: Real-time detection of out-of-context LLM outputs is crucial for enterprises looking to safely adopt RAG applications. In this work, we train lightweight models to discriminate LLM-generated text that is semantically out-of-context from retrieved text documents. We preprocess a combination of summarisation and semantic textual similarity datasets to construct training data using minimal resources. We find that DeBERTa is not only the best-performing model under this pipeline, but it is also fast and does not require additional text preprocessing or feature engineering. While emerging work demonstrates that generative LLMs can also be fine-tuned and used in complex data pipelines to achieve state-of-the-art performance, we note that speed and resource limits are important considerations for on-premise deployment.", "published": "2024-11-07 05:00:00", "id": "76e6f24d-1b5d-4306-a2da-070ae1aec5b9", "source": "arxiv", "section": "computerScience"}, {"title": "Inter-Frame Coding for Dynamic Meshes via Coarse-to-Fine Anchor Mesh Generation", "link": "https://arxiv.org/abs/2411.03921", "description": "arXiv:2411.03921v1 Announce Type: new \nAbstract: In the current Video-based Dynamic Mesh Coding (V-DMC) standard, inter-frame coding is restricted to mesh frames with constant topology. Consequently, temporal redundancy is not fully leveraged, resulting in suboptimal compression efficacy. To address this limitation, this paper introduces a novel coarse-to-fine scheme to generate anchor meshes for frames with time-varying topology. Initially, we generate a coarse anchor mesh using an octree-based nearest neighbor search. Motion estimation compensates for regions with significant motion changes during this process. However, the quality of the coarse mesh is low due to its suboptimal vertices. To enhance details, the fine anchor mesh is further optimized using the Quadric Error Metrics (QEM) algorithm to calculate more precise anchor points. The inter-frame anchor mesh generated herein retains the connectivity of the reference base mesh, while concurrently preserving superior quality. Experimental results show that our method achieves 7.2% ~ 10.3% BD-rate gain compared to the existing V-DMC test model version 7.", "published": "2024-11-07 05:00:00", "id": "af204e84-6b39-4ceb-af12-bccab990d67b", "source": "arxiv", "section": "computerScience"}, {"title": "Evaluation data contamination in LLMs: how do we measure it and (when) does it matter?", "link": "https://arxiv.org/abs/2411.03923", "description": "arXiv:2411.03923v1 Announce Type: new \nAbstract: Hampering the interpretation of benchmark scores, evaluation data contamination has become a growing concern in the evaluation of LLMs, and an active area of research studies its effects. While evaluation data contamination is easily understood intuitively, it is surprisingly difficult to define precisely which samples should be considered contaminated and, consequently, how it impacts benchmark scores. We propose that these questions should be addressed together and that contamination metrics can be assessed based on whether models benefit from the examples they mark contaminated. We propose a novel analysis method called ConTAM, and show with a large scale survey of existing and novel n-gram based contamination metrics across 13 benchmarks and 7 models from 2 different families that ConTAM can be used to better understand evaluation data contamination and its effects. We find that contamination may have a much larger effect than reported in recent LLM releases and benefits models differently at different scales. We also find that considering only the longest contaminated substring provides a better signal than considering a union of all contaminated substrings, and that doing model and benchmark specific threshold analysis greatly increases the specificity of the results. Lastly, we investigate the impact of hyperparameter choices, finding that, among other things, both using larger values of n and disregarding matches that are infrequent in the pre-training data lead to many false negatives. With ConTAM, we provide a method to empirically ground evaluation data contamination metrics in downstream effects. With our exploration, we shed light on how evaluation data contamination can impact LLMs and provide insight into the considerations important when doing contamination analysis. We end our paper by discussing these in more detail and providing concrete suggestions for future work.", "published": "2024-11-07 05:00:00", "id": "aafa91d7-7b54-4c1f-aa15-99f7345f6a1a", "source": "arxiv", "section": "computerScience"}, {"title": "Self-supervised Representation Learning for Cell Event Recognition through Time Arrow Prediction", "link": "https://arxiv.org/abs/2411.03924", "description": "arXiv:2411.03924v1 Announce Type: new \nAbstract: The spatio-temporal nature of live-cell microscopy data poses challenges in the analysis of cell states which is fundamental in bioimaging. Deep-learning based segmentation or tracking methods rely on large amount of high quality annotations to work effectively. In this work, we explore an alternative solution: using feature maps obtained from self-supervised representation learning (SSRL) on time arrow prediction (TAP) for the downstream supervised task of cell event recognition. We demonstrate through extensive experiments and analysis that this approach can achieve better performance with limited annotation compared to models trained from end to end using fully supervised approach. Our analysis also provides insight into applications of the SSRL using TAP in live-cell microscopy.", "published": "2024-11-07 05:00:00", "id": "02872a2e-55a0-4578-8261-b810d918d756", "source": "arxiv", "section": "computerScience"}, {"title": "Quantum Algorithm for Sparse Online Learning with Truncated Gradient Descent", "link": "https://arxiv.org/abs/2411.03925", "description": "arXiv:2411.03925v1 Announce Type: new \nAbstract: Logistic regression, the Support Vector Machine (SVM), and least squares are well-studied methods in the statistical and computer science community, with various practical applications. High-dimensional data arriving on a real-time basis makes the design of online learning algorithms that produce sparse solutions essential. The seminal work of \\hyperlink{cite.langford2009sparse}{Langford, Li, and Zhang (2009)} developed a method to obtain sparsity via truncated gradient descent, showing a near-optimal online regret bound. Based on this method, we develop a quantum sparse online learning algorithm for logistic regression, the SVM, and least squares. Given efficient quantum access to the inputs, we show that a quadratic speedup in the time complexity with respect to the dimension of the problem is achievable, while maintaining a regret of $O(1/\\sqrt{T})$, where $T$ is the number of iterations.", "published": "2024-11-07 05:00:00", "id": "e32fe6ca-da1c-4906-84eb-b3f2166e01ea", "source": "arxiv", "section": "computerScience"}, {"title": "Act in Collusion: A Persistent Distributed Multi-Target Backdoor in Federated Learning", "link": "https://arxiv.org/abs/2411.03926", "description": "arXiv:2411.03926v1 Announce Type: new \nAbstract: Federated learning, a novel paradigm designed to protect data privacy, is vulnerable to backdoor attacks due to its distributed nature. Current research often designs attacks based on a single attacker with a single backdoor, overlooking more realistic and complex threats in federated learning. We propose a more practical threat model for federated learning: the distributed multi-target backdoor. In this model, multiple attackers control different clients, embedding various triggers and targeting different classes, collaboratively implanting backdoors into the global model via central aggregation. Empirical validation shows that existing methods struggle to maintain the effectiveness of multiple backdoors in the global model. Our key insight is that similar backdoor triggers cause parameter conflicts and injecting new backdoors disrupts gradient directions, significantly weakening some backdoors performance. To solve this, we propose a Distributed Multi-Target Backdoor Attack (DMBA), ensuring efficiency and persistence of backdoors from different malicious clients. To avoid parameter conflicts, we design a multi-channel dispersed frequency trigger strategy to maximize trigger differences. To mitigate gradient interference, we introduce backdoor replay in local training to neutralize conflicting gradients. Extensive validation shows that 30 rounds after the attack, Attack Success Rates of three different backdoors from various clients remain above 93%. The code will be made publicly available after the review period.", "published": "2024-11-07 05:00:00", "id": "d9adcaa5-691b-456a-bdb6-58bb7838e239", "source": "arxiv", "section": "computerScience"}, {"title": "DEIO: Deep Event Inertial Odometry", "link": "https://arxiv.org/abs/2411.03928", "description": "arXiv:2411.03928v1 Announce Type: new \nAbstract: Event cameras are bio-inspired, motion-activated sensors that demonstrate impressive potential in handling challenging situations, such as motion blur and high-dynamic range. Despite their promise, existing event-based simultaneous localization and mapping (SLAM) approaches exhibit limited performance in real-world applications. On the other hand, state-of-the-art SLAM approaches that incorporate deep neural networks for better robustness and applicability. However, these is a lack of research in fusing learning-based event SLAM methods with IMU, which could be indispensable to push the event-based SLAM to large-scale, low-texture or complex scenarios. In this paper, we propose DEIO, the first monocular deep event-inertial odometry framework that combines learning-based method with traditional nonlinear graph-based optimization. Specifically, we tightly integrate a trainable event-based differentiable bundle adjustment (e-DBA) with the IMU pre-integration in a factor graph which employs keyframe-based sliding window optimization. Numerical Experiments in nine public challenge datasets show that our method can achieve superior performance compared with the image-based and event-based benchmarks. The source code is available at: https://github.com/arclab-hku/DEIO.", "published": "2024-11-07 05:00:00", "id": "6f11ebbf-b404-41dc-b333-02fd493d164e", "source": "arxiv", "section": "computerScience"}, {"title": "Inexact block LU preconditioners for incompressible fluids with flow rate conditions", "link": "https://arxiv.org/abs/2411.03929", "description": "arXiv:2411.03929v1 Announce Type: new \nAbstract: When studying the dynamics of incompressible fluids in bounded domains the only available data often provide average flow rate conditions on portions of the domain's boundary. In engineering applications a common practice to complete these conditions is to prescribe a Dirichlet condition by assuming a-priori a spatial profile for the velocity field. However, this strongly influence the accuracy of the numerical solution. A more mathematically sound approach is to prescribe the flow rate conditions using Lagrange multipliers, resulting in an augmented weak formulation of the Navier-Stokes problem.\n  In this paper we start from the SIMPLE preconditioner, introduced so far for the standard Navier-Stokes equations, and we derive two preconditioners for the monolithic solution of the augmented problem. This can be useful in complex applications where splitting the computation of the velocity/pressure and Lagrange multipliers numerical solutions can be very expensive. In particular, we investigate the numerical performance of the preconditioners in both idealized and real-life scenarios. Finally, we highlight the advantages of treating flow rate conditions with a Lagrange multipliers approach instead of prescribing a Dirichlet condition.", "published": "2024-11-07 05:00:00", "id": "c96fb898-a074-42ef-938f-4d170673ab11", "source": "arxiv", "section": "computerScience"}, {"title": "Interactions Across Blocks in Post-Training Quantization of Large Language Models", "link": "https://arxiv.org/abs/2411.03934", "description": "arXiv:2411.03934v1 Announce Type: new \nAbstract: Post-training quantization is widely employed to reduce the computational demands of neural networks. Typically, individual substructures, such as layers or blocks of layers, are quantized with the objective of minimizing quantization errors in their pre-activations by fine-tuning the corresponding weights. Deriving this local objective from the global objective of minimizing task loss involves two key simplifications: assuming substructures are mutually independent and ignoring the knowledge of subsequent substructures as well as the task loss. In this work, we assess the effects of these simplifications on weight-only quantization of large language models. We introduce two multi-block fine-tuning strategies and compare them against the baseline of fine-tuning single transformer blocks. The first captures correlations of weights across blocks by jointly optimizing multiple quantized blocks. The second incorporates knowledge of subsequent blocks by minimizing the error in downstream pre-activations rather than focusing solely on the quantized block. Our findings indicate that the effectiveness of these methods depends on the specific network model, with no impact on some models but demonstrating significant benefits for others.", "published": "2024-11-07 05:00:00", "id": "02994e28-5a31-4d60-ad5c-090ff7f9688e", "source": "arxiv", "section": "computerScience"}, {"title": "Error Controlled Cubic Spline Interpolation in CNC Technology", "link": "https://arxiv.org/abs/2411.03935", "description": "arXiv:2411.03935v1 Announce Type: new \nAbstract: Traditional CNC technology mostly uses the method of increasing the degree of interpolation polynomial when constructing $C^2$ continuous NURBS curves, but this often leads to the appearance of Runge phenomenon in interpolation curves. Alternatively,the method of adding boundary conditions at the endpoints can often make it difficult to control the error range of the interpolation curve. This article presents a $C^2$ continuous cubic B-spline curve interpolation method,which achieves $C^2$ continuity of the interpolation curve when the interpolation polynomial is cubic. At the same time, this article also studies the corresponding error control methods.", "published": "2024-11-07 05:00:00", "id": "c911c6b1-a15e-4940-8c13-cb936d51d67a", "source": "arxiv", "section": "computerScience"}, {"title": "GUIDE-VAE: Advancing Data Generation with User Information and Pattern Dictionaries", "link": "https://arxiv.org/abs/2411.03936", "description": "arXiv:2411.03936v1 Announce Type: new \nAbstract: Generative modelling of multi-user datasets has become prominent in science and engineering. Generating a data point for a given user requires employing user information, and conventional generative models, including variational autoencoders (VAEs), often ignore that. This paper introduces GUIDE-VAE, a novel conditional generative model that leverages user embeddings to generate user-guided data. By allowing the model to benefit from shared patterns across users, GUIDE-VAE enhances performance in multi-user settings, even under significant data imbalance. In addition to integrating user information, GUIDE-VAE incorporates a pattern dictionary-based covariance composition (PDCC) to improve the realism of generated samples by capturing complex feature dependencies. While user embeddings drive performance gains, PDCC addresses common issues such as noise and over-smoothing typically seen in VAEs.\n  The proposed GUIDE-VAE was evaluated on a multi-user smart meter dataset characterized by substantial data imbalance across users. Quantitative results show that GUIDE-VAE performs effectively in both synthetic data generation and missing record imputation tasks, while qualitative evaluations reveal that GUIDE-VAE produces more plausible and less noisy data. These results establish GUIDE-VAE as a promising tool for controlled, realistic data generation in multi-user datasets, with potential applications across various domains requiring user-informed modelling.", "published": "2024-11-07 05:00:00", "id": "2a41aa26-6b69-478a-835b-64867d03eae9", "source": "arxiv", "section": "computerScience"}, {"title": "Where postdoctoral journeys lead", "link": "https://arxiv.org/abs/2411.03938", "description": "arXiv:2411.03938v1 Announce Type: new \nAbstract: Postdoctoral training is a career stage often described as a demanding and anxiety-laden time when many promising PhDs see their academic dreams slip away due to circumstances beyond their control. We use a unique data set of academic publishing and careers to chart the more or less successful postdoctoral paths. We build a measure of academic success on the citation patterns two to five years into a faculty career. Then, we monitor how students' postdoc positions -- in terms of relocation, change of topic, and early well-cited papers -- relate to their early-career success. One key finding is that the postdoc period seems more important than the doctoral training to achieve this form of success. This is especially interesting in light of the many studies of academic faculty hiring that link Ph.D. granting institutions and hires, omitting the postdoc stage. Another group of findings can be summarized as a Goldilocks principle: it seems beneficial to change one's direction, but not too much.", "published": "2024-11-07 05:00:00", "id": "da06591d-ac11-40dc-ba50-9ba721031b1f", "source": "arxiv", "section": "computerScience"}, {"title": "Fine-tuning -- a Transfer Learning approach", "link": "https://arxiv.org/abs/2411.03941", "description": "arXiv:2411.03941v1 Announce Type: new \nAbstract: Secondary research use of Electronic Health Records (EHRs) is often hampered by the abundance of missing data in this valuable resource. Missingness in EHRs occurs naturally as a result of the data recording practices during routine clinical care, but handling it is crucial to the precision of medical analysis and the decision-making that follows. The literature contains a variety of imputation methodologies based on deep neural networks. Those aim to overcome the dynamic, heterogeneous and multivariate missingness patterns of EHRs, which cannot be handled by classical and statistical imputation methods. However, all existing deep imputation methods rely on end-to-end pipelines that incorporate both imputation and downstream analyses, e.g. classification. This coupling makes it difficult to assess the quality of imputation and takes away the flexibility of re-using the imputer for a different task. Furthermore, most end-to-end deep architectures tend to use complex networks to perform the downstream task, in addition to the already sophisticated deep imputation network. We, therefore ask if the high performance reported in the literature is due to the imputer or the classifier and further ask if an optimised state-of-the-art imputer is used, a simpler classifier can achieve comparable performance. This paper explores the development of a modular, deep learning-based imputation and classification pipeline, specifically built to leverage the capabilities of state-of-the-art imputation models for downstream classification tasks. Such a modular approach enables a) objective assessment of the quality of the imputer and classifier independently, and b) enables the exploration of the performance of simpler classification architectures using an optimised imputer.", "published": "2024-11-07 05:00:00", "id": "4d658439-0f68-41b5-a8df-22e7d6578802", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Achieving Energy Efficiency and Service Availability in O-RAN via Formal Verification", "link": "https://arxiv.org/abs/2411.03943", "description": "arXiv:2411.03943v1 Announce Type: new \nAbstract: As Open Radio Access Networks (O-RAN) continue to expand, AI-driven applications (xApps) are increasingly being deployed enhance network management. However, developing xApps without formal verification risks introducing logical inconsistencies, particularly in balancing energy efficiency and service availability. In this paper, we argue that prior to their development, the formal analysis of xApp models should be a critical early step in the O-RAN design process. Using the PRISM model checker, we demonstrate how our results provide realistic insights into the thresholds between energy efficiency and service availability. While our models are simplified, the findings highlight how AI-informed decisions can enable more effective cell-switching policies. We position formal verification as an essential practice for future xApp development, avoiding fallacies in real-world applications and ensuring networks operate efficiently.", "published": "2024-11-07 05:00:00", "id": "b154c19c-a5b1-456a-8089-0ac22380b132", "source": "arxiv", "section": "computerScience"}, {"title": "Can Custom Models Learn In-Context? An Exploration of Hybrid Architecture Performance on In-Context Learning Tasks", "link": "https://arxiv.org/abs/2411.03945", "description": "arXiv:2411.03945v1 Announce Type: new \nAbstract: In-Context Learning (ICL) is a phenomenon where task learning occurs through a prompt sequence without the necessity of parameter updates. ICL in Multi-Headed Attention (MHA) with absolute positional embedding has been the focus of more study than other sequence model varieties. We examine implications of architectural differences between GPT-2 and LLaMa as well as LlaMa and Mamba. We extend work done by Garg et al. (2022) and Park et al. (2024) to GPT-2/LLaMa hybrid and LLaMa/Mamba hybrid models - examining the interplay between sequence transformation blocks and regressive performance in-context. We note that certain architectural changes cause degraded training efficiency/ICL accuracy by converging to suboptimal predictors or converging slower. We also find certain hybrids showing optimistic performance improvements, informing potential future ICL-focused architecture modifications. Additionally, we propose the \"ICL regression score\", a scalar metric describing a model's whole performance on a specific task. Compute limitations impose restrictions on our architecture-space, training duration, number of training runs, function class complexity, and benchmark complexity. To foster reproducible and extensible research, we provide a typed, modular, and extensible Python package on which we run all experiments.", "published": "2024-11-07 05:00:00", "id": "b9d722bc-193b-4e9e-8e60-aaf015bf4df4", "source": "arxiv", "section": "computerScience"}, {"title": "Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of Study in Tabletop Role-Playing Games Soundtracks", "link": "https://arxiv.org/abs/2411.03948", "description": "arXiv:2411.03948v1 Announce Type: new \nAbstract: This paper investigates the capabilities of text-to-audio music generation models in producing long-form music with prompts that change over time, focusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs). We introduce Babel Bardo, a system that uses Large Language Models (LLMs) to transform speech transcriptions into music descriptions for controlling a text-to-music model. Four versions of Babel Bardo were compared in two TRPG campaigns: a baseline using direct speech transcriptions, and three LLM-based versions with varying approaches to music description generation. Evaluations considered audio quality, story alignment, and transition smoothness. Results indicate that detailed music descriptions improve audio quality while maintaining consistency across consecutive descriptions enhances story alignment and transition smoothness.", "published": "2024-11-07 05:00:00", "id": "54661c48-a1ec-4820-b614-f54c3cf9ffb0", "source": "arxiv", "section": "computerScience"}, {"title": "Continuous-Time State Estimation Methods in Robotics: A Survey", "link": "https://arxiv.org/abs/2411.03951", "description": "arXiv:2411.03951v1 Announce Type: new \nAbstract: Accurate, efficient, and robust state estimation is more important than ever in robotics as the variety of platforms and complexity of tasks continue to grow. Historically, discrete-time filters and smoothers have been the dominant approach, in which the estimated variables are states at discrete sample times. The paradigm of continuous-time state estimation proposes an alternative strategy by estimating variables that express the state as a continuous function of time, which can be evaluated at any query time. Not only can this benefit downstream tasks such as planning and control, but it also significantly increases estimator performance and flexibility, as well as reduces sensor preprocessing and interfacing complexity. Despite this, continuous-time methods remain underutilized, potentially because they are less well-known within robotics. To remedy this, this work presents a unifying formulation of these methods and the most exhaustive literature review to date, systematically categorizing prior work by methodology, application, state variables, historical context, and theoretical contribution to the field. By surveying splines and Gaussian processes together and contextualizing works from other research domains, this work identifies and analyzes open problems in continuous-time state estimation and suggests new research directions.", "published": "2024-11-07 05:00:00", "id": "ef1b695f-5213-47ef-94aa-4d8557f84206", "source": "arxiv", "section": "computerScience"}, {"title": "Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in Retrieval-Augmented Generation", "link": "https://arxiv.org/abs/2411.03957", "description": "arXiv:2411.03957v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) has proven to be an effective method for mitigating hallucination issues inherent in large language models (LLMs). Previous approaches typically train retrievers based on semantic similarity, lacking optimization for RAG. More recent works have proposed aligning retrievers with the preference signals of LLMs. However, these preference signals are often difficult for dense retrievers, which typically have weaker language capabilities, to understand and learn effectively. Drawing inspiration from pedagogical theories like Guided Discovery Learning, we propose a novel framework, FiGRet (Fine-grained Guidance for Retrievers), which leverages the language capabilities of LLMs to construct examples from a more granular, information-centric perspective to guide the learning of retrievers. Specifically, our method utilizes LLMs to construct easy-to-understand examples from samples where the retriever performs poorly, focusing on three learning objectives highly relevant to the RAG scenario: relevance, comprehensiveness, and purity. These examples serve as scaffolding to ultimately align the retriever with the LLM's preferences. Furthermore, we employ a dual curriculum learning strategy and leverage the reciprocal feedback between LLM and retriever to further enhance the performance of the RAG system. A series of experiments demonstrate that our proposed framework enhances the performance of RAG systems equipped with different retrievers and is applicable to various LLMs.", "published": "2024-11-07 05:00:00", "id": "7cdb240e-b4b1-4349-a5ee-9db0327cd34c", "source": "arxiv", "section": "computerScience"}, {"title": "Energy Score-based Pseudo-Label Filtering and Adaptive Loss for Imbalanced Semi-supervised SAR target recognition", "link": "https://arxiv.org/abs/2411.03959", "description": "arXiv:2411.03959v1 Announce Type: new \nAbstract: Automatic target recognition (ATR) is an important use case for synthetic aperture radar (SAR) image interpretation. Recent years have seen significant advancements in SAR ATR technology based on semi-supervised learning. However, existing semi-supervised SAR ATR algorithms show low recognition accuracy in the case of class imbalance. This work offers a non-balanced semi-supervised SAR target recognition approach using dynamic energy scores and adaptive loss. First, an energy score-based method is developed to dynamically select unlabeled samples near to the training distribution as pseudo-labels during training, assuring pseudo-label reliability in long-tailed distribution circumstances. Secondly, loss functions suitable for class imbalances are proposed, including adaptive margin perception loss and adaptive hard triplet loss, the former offsets inter-class confusion of classifiers, alleviating the imbalance issue inherent in pseudo-label generation. The latter effectively tackles the model's preference for the majority class by focusing on complex difficult samples during training. Experimental results on extremely imbalanced SAR datasets demonstrate that the proposed method performs well under the dual constraints of scarce labels and data imbalance, effectively overcoming the model bias caused by data imbalance and achieving high-precision target recognition.", "published": "2024-11-07 05:00:00", "id": "c13c8f5b-bbb0-457f-a6f3-07d580e61ddc", "source": "arxiv", "section": "computerScience"}, {"title": "Face Reconstruction from Face Embeddings using Adapter to a Face Foundation Model", "link": "https://arxiv.org/abs/2411.03960", "description": "arXiv:2411.03960v1 Announce Type: new \nAbstract: Face recognition systems extract embedding vectors from face images and use these embeddings to verify or identify individuals. Face reconstruction attack (also known as template inversion) refers to reconstructing face images from face embeddings and using the reconstructed face image to enter a face recognition system. In this paper, we propose to use a face foundation model to reconstruct face images from the embeddings of a blackbox face recognition model. The foundation model is trained with 42M images to generate face images from the facial embeddings of a fixed face recognition model. We propose to use an adapter to translate target embeddings into the embedding space of the foundation model. The generated images are evaluated on different face recognition models and different datasets, demonstrating the effectiveness of our method to translate embeddings of different face recognition models. We also evaluate the transferability of reconstructed face images when attacking different face recognition models. Our experimental results show that our reconstructed face images outperform previous reconstruction attacks against face recognition models.", "published": "2024-11-07 05:00:00", "id": "7ff103eb-18b2-4126-95d2-50d1a2b19ef3", "source": "arxiv", "section": "computerScience"}, {"title": "How Does A Text Preprocessing Pipeline Affect Ontology Syntactic Matching?", "link": "https://arxiv.org/abs/2411.03962", "description": "arXiv:2411.03962v1 Announce Type: new \nAbstract: The generic text preprocessing pipeline, comprising Tokenisation, Normalisation, Stop Words Removal, and Stemming/Lemmatisation, has been implemented in many ontology matching (OM) systems. However, the lack of standardisation in text preprocessing creates diversity in mapping results. In this paper, we investigate the effect of the text preprocessing pipeline on OM tasks at syntactic levels. Our experiments on 8 Ontology Alignment Evaluation Initiative (OAEI) track repositories with 49 distinct alignments indicate: (1) Tokenisation and Normalisation are currently more effective than Stop Words Removal and Stemming/Lemmatisation; and (2) The selection of Lemmatisation and Stemming is task-specific. We recommend standalone Lemmatisation or Stemming with post-hoc corrections. We find that (3) Porter Stemmer and Snowball Stemmer perform better than Lancaster Stemmer; and that (4) Part-of-Speech (POS) Tagging does not help Lemmatisation. To repair less effective Stop Words Removal and Stemming/Lemmatisation used in OM tasks, we propose a novel context-based pipeline repair approach that significantly improves matching correctness and overall matching performance. We also discuss the use of text preprocessing pipeline in the new era of large language models (LLMs).", "published": "2024-11-07 05:00:00", "id": "4cbc52f2-8034-4bf8-9155-b0cf64ce78b3", "source": "arxiv", "section": "computerScience"}, {"title": "What Really is Commonsense Knowledge?", "link": "https://arxiv.org/abs/2411.03964", "description": "arXiv:2411.03964v1 Announce Type: new \nAbstract: Commonsense datasets have been well developed in Natural Language Processing, mainly through crowdsource human annotation. However, there are debates on the genuineness of commonsense reasoning benchmarks. In specific, a significant portion of instances in some commonsense benchmarks do not concern commonsense knowledge. That problem would undermine the measurement of the true commonsense reasoning ability of evaluated models. It is also suggested that the problem originated from a blurry concept of commonsense knowledge, as distinguished from other types of knowledge. To demystify all of the above claims, in this study, we survey existing definitions of commonsense knowledge, ground into the three frameworks for defining concepts, and consolidate them into a multi-framework unified definition of commonsense knowledge (so-called consolidated definition). We then use the consolidated definition for annotations and experiments on the CommonsenseQA and CommonsenseQA 2.0 datasets to examine the above claims. Our study shows that there exists a large portion of non-commonsense-knowledge instances in the two datasets, and a large performance gap on these two subsets where Large Language Models (LLMs) perform worse on commonsense-knowledge instances.", "published": "2024-11-07 05:00:00", "id": "42fc65f6-e4bd-4e6f-8c15-838142ea82ed", "source": "arxiv", "section": "computerScience"}, {"title": "WorryWords: Norms of Anxiety Association for over 44k English Words", "link": "https://arxiv.org/abs/2411.03966", "description": "arXiv:2411.03966v1 Announce Type: new \nAbstract: Anxiety, the anticipatory unease about a potential negative outcome, is a common and beneficial human emotion. However, there is still much that is not known, such as how anxiety relates to our body and how it manifests in language. This is especially pertinent given the increasing impact of anxiety-related disorders. In this work, we introduce WorryWords, the first large-scale repository of manually derived word--anxiety associations for over 44,450 English words. We show that the anxiety associations are highly reliable. We use WorryWords to study the relationship between anxiety and other emotion constructs, as well as the rate at which children acquire anxiety words with age. Finally, we show that using WorryWords alone, one can accurately track the change of anxiety in streams of text. The lexicon enables a wide variety of anxiety-related research in psychology, NLP, public health, and social sciences. WorryWords (and its translations to over 100 languages) is freely available. http://saifmohammad.com/worrywords.html", "published": "2024-11-07 05:00:00", "id": "2022c630-bc47-4f4d-a115-55fbc749bd72", "source": "arxiv", "section": "computerScience"}, {"title": "Temporal Network Creation Games: The Impact of Non-Locality and Terminals", "link": "https://arxiv.org/abs/2411.03973", "description": "arXiv:2411.03973v1 Announce Type: new \nAbstract: We live in a world full of networks where our economy, our communication, and even our social life crucially depends on them. These networks typically emerge from the interaction of many entities, which is why researchers study agent-based models of network formation. While traditionally static networks with a fixed set of links were considered, a recent stream of works focuses on networks whose behavior may change over time. In particular, Bil\\`o et al. (IJCAI 2023) recently introduced a game-theoretic network formation model that embeds temporal aspects in networks. More precisely, a network is formed by selfish agents corresponding to nodes in a given host network with edges having labels denoting their availability over time. Each agent strategically selects local, i.e., incident, edges to ensure temporal reachability towards everyone at low cost.\n  In this work we set out to explore the impact of two novel conceptual features: agents are no longer restricted to creating incident edges, called the global setting, and agents might only want to ensure that they can reach a subset of the other nodes, called the terminal model. For both, we study the existence, structure, and quality of equilibrium networks. For the terminal model, we prove that many core properties crucially depend on the number of terminals. We also develop a novel tool that allows translating equilibrium constructions from the non-terminal model to the terminal model. For the global setting, we show the surprising result that equilibria in the global and the local model are incomparable and we establish a high lower bound on the Price of Anarchy of the global setting that matches the upper bound of the local model. This shows the counter-intuitive fact that allowing agents more flexibility in edge creation does not improve the quality of equilibrium networks.", "published": "2024-11-07 05:00:00", "id": "4fe8344c-f586-487d-aa8d-a88ccbabcd88", "source": "arxiv", "section": "computerScience"}, {"title": "HRDecoder: High-Resolution Decoder Network for Fundus Image Lesion Segmentation", "link": "https://arxiv.org/abs/2411.03976", "description": "arXiv:2411.03976v1 Announce Type: new \nAbstract: High resolution is crucial for precise segmentation in fundus images, yet handling high-resolution inputs incurs considerable GPU memory costs, with diminishing performance gains as overhead increases. To address this issue while tackling the challenge of segmenting tiny objects, recent studies have explored local-global fusion methods. These methods preserve fine details using local regions and capture long-range context information from downscaled global images. However, the necessity of multiple forward passes inevitably incurs significant computational overhead, adversely affecting inference speed. In this paper, we propose HRDecoder, a simple High-Resolution Decoder network for fundus lesion segmentation. It integrates a high-resolution representation learning module to capture fine-grained local features and a high-resolution fusion module to fuse multi-scale predictions. Our method effectively improves the overall segmentation accuracy of fundus lesions while consuming reasonable memory and computational overhead, and maintaining satisfying inference speed. Experimental results on the IDRID and DDR datasets demonstrate the effectiveness of our method. Code is available at https://github.com/CVIU-CSU/HRDecoder.", "published": "2024-11-07 05:00:00", "id": "0456b754-89f7-4187-962c-875079d1cae1", "source": "arxiv", "section": "computerScience"}, {"title": "Customized Multiple Clustering via Multi-Modal Subspace Proxy Learning", "link": "https://arxiv.org/abs/2411.03978", "description": "arXiv:2411.03978v1 Announce Type: new \nAbstract: Multiple clustering aims to discover various latent structures of data from different aspects. Deep multiple clustering methods have achieved remarkable performance by exploiting complex patterns and relationships in data. However, existing works struggle to flexibly adapt to diverse user-specific needs in data grouping, which may require manual understanding of each clustering. To address these limitations, we introduce Multi-Sub, a novel end-to-end multiple clustering approach that incorporates a multi-modal subspace proxy learning framework in this work. Utilizing the synergistic capabilities of CLIP and GPT-4, Multi-Sub aligns textual prompts expressing user preferences with their corresponding visual representations. This is achieved by automatically generating proxy words from large language models that act as subspace bases, thus allowing for the customized representation of data in terms specific to the user's interests. Our method consistently outperforms existing baselines across a broad set of datasets in visual multiple clustering tasks. Our code is available at https://github.com/Alexander-Yao/Multi-Sub.", "published": "2024-11-07 05:00:00", "id": "0d7548f7-2b1a-4743-9894-6760833e4519", "source": "arxiv", "section": "computerScience"}, {"title": "ReEdit: Multimodal Exemplar-Based Image Editing with Diffusion Models", "link": "https://arxiv.org/abs/2411.03982", "description": "arXiv:2411.03982v1 Announce Type: new \nAbstract: Modern Text-to-Image (T2I) Diffusion models have revolutionized image editing by enabling the generation of high-quality photorealistic images. While the de facto method for performing edits with T2I models is through text instructions, this approach non-trivial due to the complex many-to-many mapping between natural language and images. In this work, we address exemplar-based image editing -- the task of transferring an edit from an exemplar pair to a content image(s). We propose ReEdit, a modular and efficient end-to-end framework that captures edits in both text and image modalities while ensuring the fidelity of the edited image. We validate the effectiveness of ReEdit through extensive comparisons with state-of-the-art baselines and sensitivity analyses of key design choices. Our results demonstrate that ReEdit consistently outperforms contemporary approaches both qualitatively and quantitatively. Additionally, ReEdit boasts high practical applicability, as it does not require any task-specific optimization and is four times faster than the next best baseline.", "published": "2024-11-07 05:00:00", "id": "bf8174f1-33da-4f6f-babe-eb719fa3ad70", "source": "arxiv", "section": "computerScience"}, {"title": "ET-SEED: Efficient Trajectory-Level SE(3) Equivariant Diffusion Policy", "link": "https://arxiv.org/abs/2411.03990", "description": "arXiv:2411.03990v1 Announce Type: new \nAbstract: Imitation learning, e.g., diffusion policy, has been proven effective in various robotic manipulation tasks. However, extensive demonstrations are required for policy robustness and generalization. To reduce the demonstration reliance, we leverage spatial symmetry and propose ET-SEED, an efficient trajectory-level SE(3) equivariant diffusion model for generating action sequences in complex robot manipulation tasks. Further, previous equivariant diffusion models require the per-step equivariance in the Markov process, making it difficult to learn policy under such strong constraints. We theoretically extend equivariant Markov kernels and simplify the condition of equivariant diffusion process, thereby significantly improving training efficiency for trajectory-level SE(3) equivariant diffusion policy in an end-to-end manner. We evaluate ET-SEED on representative robotic manipulation tasks, involving rigid body, articulated and deformable object. Experiments demonstrate superior data efficiency and manipulation proficiency of our proposed method, as well as its ability to generalize to unseen configurations with only a few demonstrations. Website: https://et-seed.github.io/", "published": "2024-11-07 05:00:00", "id": "9fc7b688-ea0d-45e5-9796-2f0d519a280e", "source": "arxiv", "section": "computerScience"}, {"title": "Local vs distributed representations: What is the right basis for interpretability?", "link": "https://arxiv.org/abs/2411.03993", "description": "arXiv:2411.03993v1 Announce Type: new \nAbstract: Much of the research on the interpretability of deep neural networks has focused on studying the visual features that maximally activate individual neurons. However, recent work has cast doubts on the usefulness of such local representations for understanding the behavior of deep neural networks because individual neurons tend to respond to multiple unrelated visual patterns, a phenomenon referred to as \"superposition\". A promising alternative to disentangle these complex patterns is learning sparsely distributed vector representations from entire network layers, as the resulting basis vectors seemingly encode single identifiable visual patterns consistently. Thus, one would expect the resulting code to align better with human perceivable visual patterns, but supporting evidence remains, at best, anecdotal. To fill this gap, we conducted three large-scale psychophysics experiments collected from a pool of 560 participants. Our findings provide (i) strong evidence that features obtained from sparse distributed representations are easier to interpret by human observers and (ii) that this effect is more pronounced in the deepest layers of a neural network. Complementary analyses also reveal that (iii) features derived from sparse distributed representations contribute more to the model's decision. Overall, our results highlight that distributed representations constitute a superior basis for interpretability, underscoring a need for the field to move beyond the interpretation of local neural codes in favor of sparsely distributed ones.", "published": "2024-11-07 05:00:00", "id": "ce054ffc-fa77-4b3e-bcc7-915287374fc0", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Resource-Efficient Federated Learning in Industrial IoT for Multivariate Time Series Analysis", "link": "https://arxiv.org/abs/2411.03996", "description": "arXiv:2411.03996v1 Announce Type: new \nAbstract: Anomaly and missing data constitute a thorny problem in industrial applications. In recent years, deep learning enabled anomaly detection has emerged as a critical direction, however the improved detection accuracy is achieved with the utilization of large neural networks, increasing their storage and computational cost. Moreover, the data collected in edge devices contain user privacy, introducing challenges that can be successfully addressed by the privacy-preserving distributed paradigm, known as federated learning (FL). This framework allows edge devices to train and exchange models increasing also the communication cost. Thus, to deal with the increased communication, processing and storage challenges of the FL based deep anomaly detection NN pruning is expected to have significant benefits towards reducing the processing, storage and communication complexity. With this focus, a novel compression-based optimization problem is proposed at the server-side of a FL paradigm that fusses the received local models broadcast and performs pruning generating a more compressed model. Experiments in the context of anomaly detection and missing value imputation demonstrate that the proposed FL scenario along with the proposed compressed-based method are able to achieve high compression rates (more than $99.7\\%$) with negligible performance losses (less than $1.18\\%$ ) as compared to the centralized solutions.", "published": "2024-11-07 05:00:00", "id": "0cf346f4-d675-4e6f-b0bd-4acff7558367", "source": "arxiv", "section": "computerScience"}, {"title": "Dynamic Virtual Inertia and Damping Control for Zero-Inertia Grids", "link": "https://arxiv.org/abs/2411.03998", "description": "arXiv:2411.03998v1 Announce Type: new \nAbstract: In this paper virtual synchronous generation (VSG) approach is investigated in application to low- and zero-inertia grids operated by grid-forming (GFM) inverters. The key idea here is to introduce dynamic inertia and damping constants in order to keep power gird stable during different types of faults, islanding or large power balance oscillations. In order to achieve such robustness, we introduce frequency and phase angle shift functions to VSG along with dynamics virtual generator parameters. The stability of such approach is theoretically proven and theoretical results are supported by detailed case studies in RTDS (Real-Time Digital Simulator) NovaCor 1.0 with GFM inverters dynamics simulated with 1-3 microseconds timestep using two-level universal inverter model. Case studies include all aforementioned types of faults and demonstrate increased power grid robustness and survivability in comparison with traditional synchronous generation of comparable size.", "published": "2024-11-07 05:00:00", "id": "edf8cb79-67f6-4f26-8f0e-e3e6152fef42", "source": "arxiv", "section": "computerScience"}, {"title": "ParaGAN: A Scalable Distributed Training Framework for Generative Adversarial Networks", "link": "https://arxiv.org/abs/2411.03999", "description": "arXiv:2411.03999v1 Announce Type: new \nAbstract: Recent advances in Generative Artificial Intelligence have fueled numerous applications, particularly those involving Generative Adversarial Networks (GANs), which are essential for synthesizing realistic photos and videos. However, efficiently training GANs remains a critical challenge due to their computationally intensive and numerically unstable nature. Existing methods often require days or even weeks for training, posing significant resource and time constraints.\n  In this work, we introduce ParaGAN, a scalable distributed GAN training framework that leverages asynchronous training and an asymmetric optimization policy to accelerate GAN training. ParaGAN employs a congestion-aware data pipeline and hardware-aware layout transformation to enhance accelerator utilization, resulting in over 30% improvements in throughput. With ParaGAN, we reduce the training time of BigGAN from 15 days to 14 hours while achieving 91% scaling efficiency. Additionally, ParaGAN enables unprecedented high-resolution image generation using BigGAN.", "published": "2024-11-07 05:00:00", "id": "bd6fd562-b1b2-4b09-ad89-55656e2745ac", "source": "arxiv", "section": "computerScience"}, {"title": "Learning Aggregate Queries Defined by First-Order Logic with Counting", "link": "https://arxiv.org/abs/2411.04003", "description": "arXiv:2411.04003v1 Announce Type: new \nAbstract: In the logical framework introduced by Grohe and Tur\\'an (TOCS 2004) for Boolean classification problems, the instances to classify are tuples from a logical structure, and Boolean classifiers are described by parametric models based on logical formulas. This is a specific scenario for supervised passive learning, where classifiers should be learned based on labelled examples. Existing results in this scenario focus on Boolean classification. This paper presents learnability results beyond Boolean classification. We focus on multiclass classification problems where the task is to assign input tuples to arbitrary integers. To represent such integer-valued classifiers, we use aggregate queries specified by an extension of first-order logic with counting terms called FOC1.\n  Our main result shows the following: given a database of polylogarithmic degree, within quasi-linear time, we can build an index structure that makes it possible to learn FOC1-definable integer-valued classifiers in time polylogarithmic in the size of the database and polynomial in the number of training examples.", "published": "2024-11-07 05:00:00", "id": "727614dd-790b-4161-a3c5-08838964b19a", "source": "arxiv", "section": "computerScience"}, {"title": "Object-Centric Dexterous Manipulation from Human Motion Data", "link": "https://arxiv.org/abs/2411.04005", "description": "arXiv:2411.04005v1 Announce Type: new \nAbstract: Manipulating objects to achieve desired goal states is a basic but important skill for dexterous manipulation. Human hand motions demonstrate proficient manipulation capability, providing valuable data for training robots with multi-finger hands. Despite this potential, substantial challenges arise due to the embodiment gap between human and robot hands. In this work, we introduce a hierarchical policy learning framework that uses human hand motion data for training object-centric dexterous robot manipulation. At the core of our method is a high-level trajectory generative model, learned with a large-scale human hand motion capture dataset, to synthesize human-like wrist motions conditioned on the desired object goal states. Guided by the generated wrist motions, deep reinforcement learning is further used to train a low-level finger controller that is grounded in the robot's embodiment to physically interact with the object to achieve the goal. Through extensive evaluation across 10 household objects, our approach not only demonstrates superior performance but also showcases generalization capability to novel object geometries and goal states. Furthermore, we transfer the learned policies from simulation to a real-world bimanual dexterous robot system, further demonstrating its applicability in real-world scenarios. Project website: https://cypypccpy.github.io/obj-dex.github.io/.", "published": "2024-11-07 05:00:00", "id": "85d100e8-fe35-4f10-8b6a-107f4a440190", "source": "arxiv", "section": "computerScience"}, {"title": "Select2Plan: Training-Free ICL-Based Planning through VQA and Memory Retrieval", "link": "https://arxiv.org/abs/2411.04006", "description": "arXiv:2411.04006v1 Announce Type: new \nAbstract: This study explores the potential of off-the-shelf Vision-Language Models (VLMs) for high-level robot planning in the context of autonomous navigation. Indeed, while most of existing learning-based approaches for path planning require extensive task-specific training/fine-tuning, we demonstrate how such training can be avoided for most practical cases. To do this, we introduce Select2Plan (S2P), a novel training-free framework for high-level robot planning which completely eliminates the need for fine-tuning or specialised training. By leveraging structured Visual Question-Answering (VQA) and In-Context Learning (ICL), our approach drastically reduces the need for data collection, requiring a fraction of the task-specific data typically used by trained models, or even relying only on online data. Our method facilitates the effective use of a generally trained VLM in a flexible and cost-efficient way, and does not require additional sensing except for a simple monocular camera. We demonstrate its adaptability across various scene types, context sources, and sensing setups. We evaluate our approach in two distinct scenarios: traditional First-Person View (FPV) and infrastructure-driven Third-Person View (TPV) navigation, demonstrating the flexibility and simplicity of our method. Our technique significantly enhances the navigational capabilities of a baseline VLM of approximately 50% in TPV scenario, and is comparable to trained models in the FPV one, with as few as 20 demonstrations.", "published": "2024-11-07 05:00:00", "id": "23107b09-e2cf-48ea-a21a-84accca393bc", "source": "arxiv", "section": "computerScience"}, {"title": "Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability", "link": "https://arxiv.org/abs/2411.04008", "description": "arXiv:2411.04008v1 Announce Type: new \nAbstract: In mission-critical domains such as law enforcement and medical diagnosis, the ability to explain and interpret the outputs of deep learning models is crucial for ensuring user trust and supporting informed decision-making. Despite advancements in explainability, existing methods often fall short in providing explanations that mirror the depth and clarity of those given by human experts. Such expert-level explanations are essential for the dependable application of deep learning models in law enforcement and medical contexts. Additionally, we recognize that most explanations in real-world scenarios are communicated primarily through natural language. Addressing these needs, we propose a novel approach that utilizes characteristic descriptors to explain model decisions by identifying their presence in images, thereby generating expert-like explanations. Our method incorporates a concept bottleneck layer within the model architecture, which calculates the similarity between image and descriptor encodings to deliver inherent and faithful explanations. Through experiments in face recognition and chest X-ray diagnosis, we demonstrate that our approach offers a significant contrast over existing techniques, which are often limited to the use of saliency maps. We believe our approach represents a significant step toward making deep learning systems more accountable, transparent, and trustworthy in the critical domains of face recognition and medical diagnosis.", "published": "2024-11-07 05:00:00", "id": "01ed7041-8c08-417c-b0b5-411075cd6ab2", "source": "arxiv", "section": "computerScience"}, {"title": "Predicting and Publishing Accurate Imbalance Prices Using Monte Carlo Tree Search", "link": "https://arxiv.org/abs/2411.04011", "description": "arXiv:2411.04011v1 Announce Type: new \nAbstract: The growing reliance on renewable energy sources, particularly solar and wind, has introduced challenges due to their uncontrollable production. This complicates maintaining the electrical grid balance, prompting some transmission system operators in Western Europe to implement imbalance tariffs that penalize unsustainable power deviations. These tariffs create an implicit demand response framework to mitigate grid instability. Yet, several challenges limit active participation. In Belgium, for example, imbalance prices are only calculated at the end of each 15-minute settlement period, creating high risk due to price uncertainty. This risk is further amplified by the inherent volatility of imbalance prices, discouraging participation. Although transmission system operators provide minute-based price predictions, the system imbalance volatility makes accurate price predictions challenging to obtain and requires sophisticated techniques. Moreover, publishing price estimates can prompt participants to adjust their schedules, potentially affecting the system balance and the final price, adding further complexity. To address these challenges, we propose a Monte Carlo Tree Search method that publishes accurate imbalance prices while accounting for potential response actions. Our approach models the system dynamics using a neural network forecaster and a cluster of virtual batteries controlled by reinforcement learning agents. Compared to Belgium's current publication method, our technique improves price accuracy by 20.4% under ideal conditions and by 12.8% in more realistic scenarios. This research addresses an unexplored, yet crucial problem, positioning this paper as a pioneering work in analyzing the potential of more advanced imbalance price publishing techniques.", "published": "2024-11-07 05:00:00", "id": "59de5af2-5c39-4c47-8d5d-186c9fd2a207", "source": "arxiv", "section": "computerScience"}, {"title": "$k$NN Attention Demystified: A Theoretical Exploration for Scalable Transformers", "link": "https://arxiv.org/abs/2411.04013", "description": "arXiv:2411.04013v1 Announce Type: new \nAbstract: Despite their power, Transformers face challenges with long sequences due to the quadratic complexity of self-attention. To address this limitation, methods like $k$-Nearest-Neighbor ($k$NN) attention have been introduced [Roy, Saffar, Vaswani, Grangier, 2021] enabling each token to attend to only its $k$ closest tokens. While $k$NN attention has shown empirical success in making Transformers more efficient, its exact approximation guarantees have not been theoretically analyzed. In this work, we establish a theoretical framework for $k$NN attention, reformulating self-attention as expectations over softmax distributions and leveraging lazy Gumbel sampling [Mussmann, Levy, Ermon, 2017] with $k$NN indices for efficient approximation. Building on this framework, we also propose novel sub-quadratic algorithms that approximate self-attention gradients by leveraging efficient sampling techniques, such as Markov Chain-based estimation. Finally, we demonstrate the practical effectiveness of these algorithms through empirical experiments, showcasing their benefits in both training and inference.", "published": "2024-11-07 05:00:00", "id": "7579cf21-3e57-4ebc-bdd8-f1f25eae229f", "source": "arxiv", "section": "computerScience"}, {"title": "Multi-Scale and Multimodal Species Distribution Modeling", "link": "https://arxiv.org/abs/2411.04016", "description": "arXiv:2411.04016v1 Announce Type: new \nAbstract: Species distribution models (SDMs) aim to predict the distribution of species by relating occurrence data with environmental variables. Recent applications of deep learning to SDMs have enabled new avenues, specifically the inclusion of spatial data (environmental rasters, satellite images) as model predictors, allowing the model to consider the spatial context around each species' observations. However, the appropriate spatial extent of the images is not straightforward to determine and may affect the performance of the model, as scale is recognized as an important factor in SDMs. We develop a modular structure for SDMs that allows us to test the effect of scale in both single- and multi-scale settings. Furthermore, our model enables different scales to be considered for different modalities, using a late fusion approach. Results on the GeoLifeCLEF 2023 benchmark indicate that considering multimodal data and learning multi-scale representations leads to more accurate models.", "published": "2024-11-07 05:00:00", "id": "55a2fe93-39bf-47ad-940c-6efd6fe639ac", "source": "arxiv", "section": "computerScience"}, {"title": "Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages", "link": "https://arxiv.org/abs/2411.04025", "description": "arXiv:2411.04025v1 Announce Type: new \nAbstract: Language Identification (LI) is crucial for various natural language processing tasks, serving as a foundational step in applications such as sentiment analysis, machine translation, and information retrieval. In multilingual societies like India, particularly among the youth engaging on social media, text often exhibits code-mixing, blending local languages with English at different linguistic levels. This phenomenon presents formidable challenges for LI systems, especially when languages intermingle within single words. Dravidian languages, prevalent in southern India, possess rich morphological structures yet suffer from under-representation in digital platforms, leading to the adoption of Roman or hybrid scripts for communication. This paper introduces a prompt based method for a shared task aimed at addressing word-level LI challenges in Dravidian languages. In this work, we leveraged GPT-3.5 Turbo to understand whether the large language models is able to correctly classify words into correct categories. Our findings show that the Kannada model consistently outperformed the Tamil model across most metrics, indicating a higher accuracy and reliability in identifying and categorizing Kannada language instances. In contrast, the Tamil model showed moderate performance, particularly needing improvement in precision and recall.", "published": "2024-11-07 05:00:00", "id": "c283a1ef-6342-4422-890d-c9b90e700fb6", "source": "arxiv", "section": "computerScience"}, {"title": "Space-Time Spectral Element Tensor Network Approach for Time Dependent Convection Diffusion Reaction Equation with Variable Coefficients", "link": "https://arxiv.org/abs/2411.04026", "description": "arXiv:2411.04026v1 Announce Type: new \nAbstract: In this paper, we present a new space-time Petrov-Galerkin-like method. This method utilizes a mixed formulation of Tensor Train (TT) and Quantized Tensor Train (QTT), designed for the spectral element discretization (Q1-SEM) of the time-dependent convection-diffusion-reaction (CDR) equation. We reformulate the assembly process of the spectral element discretized CDR to enhance its compatibility with tensor operations and introduce a low-rank tensor structure for the spectral element operators. Recognizing the banded structure inherent in the spectral element framework's discrete operators, we further exploit the QTT format of the CDR to achieve greater speed and compression. Additionally, we present a comprehensive approach for integrating variable coefficients of CDR into the global discrete operators within the TT/QTT framework. The effectiveness of the proposed method, in terms of memory efficiency and computational complexity, is demonstrated through a series of numerical experiments, including a semi-linear example.", "published": "2024-11-07 05:00:00", "id": "0674eec4-0d14-4404-9f5c-8dbb72c2f234", "source": "arxiv", "section": "computerScience"}, {"title": "Prototyping O-RAN Enabled UAV Experimentation for the AERPAW Testbed", "link": "https://arxiv.org/abs/2411.04027", "description": "arXiv:2411.04027v1 Announce Type: new \nAbstract: The Open Radio Access Network (O-RAN) architecture is reshaping the telecommunications landscape by enhancing network flexibility, openness, and intelligence. This paper establishes the requirements, evaluates the design tradeoffs, and introduces a scalable architecture and prototype of an open-source O-RAN experimentation platform within the Aerial Experimentation and Research Platform for Advanced Wireless (AERPAW), an at scale testbed that integrates unmanned aerial vehicles (UAVs) with advanced wireless network technologies, offering experimentation in both outdoor testbed and emulation via a custom digital twin (DT). Through a series of aerial experiments, we evaluate FlexRIC, an open-source RAN Intelligent Controller, within the AERPAW hardware-software platform for network data monitoring, providing valuable insights into the proposed integration and revealing opportunities for leveraging O-RAN to create custom service based optimizations for cellular connected UAVs. We discuss the challenges and potential use cases of this integration and demonstrate the use of a generative artificial intelligence model for generating realistic data based on collected real-world data to support AERPAW's DT.", "published": "2024-11-07 05:00:00", "id": "2589dd4f-b468-461d-99c4-dfca62742cf7", "source": "arxiv", "section": "computerScience"}, {"title": "Quantum-Safe Hybrid Key Exchanges with KEM-Based Authentication", "link": "https://arxiv.org/abs/2411.04030", "description": "arXiv:2411.04030v1 Announce Type: new \nAbstract: Authenticated Key Exchange (AKE) between any two entities is one of the most important security protocols available for securing our digital networks and infrastructures. In PQCrypto 2023, Bruckner, Ramacher and Striecks proposed a novel hybrid AKE (HAKE) protocol, dubbed Muckle+, that is particularly useful in large quantum-safe networks consisting of a large number of nodes. Their protocol is hybrid in the sense that it allows key material from conventional and post-quantum primitives, as well as from quantum key distribution, to be incorporated into a single end-to-end shared key.\n  To achieve the desired authentication properties, Muckle+ utilizes post-quantum digital signatures. However, available instantiations of such signatures schemes are not yet efficient enough compared to their post-quantum key-encapsulation mechanism (KEM) counterparts, particularly in large networks with potentially several connections in a short period of time.\n  To mitigate this gap, we propose Muckle# that pushes the efficiency boundaries of currently known HAKE constructions. Muckle# uses post-quantum key-encapsulating mechanisms for implicit authentication inspired by recent works done in the area of Transport Layer Security (TLS) protocols, particularly, in KEMTLS (CCS'20).\n  We port those ideas to the HAKE framework and develop novel proof techniques on the way. Due to our novel KEM-based approach, the resulting protocol has a slightly different message flow compared to prior work that we carefully align with the HAKE framework and which makes our changes to the Muckle+ non-trivial.", "published": "2024-11-07 05:00:00", "id": "ccf96961-5a70-450d-aab2-078da15124fe", "source": "arxiv", "section": "computerScience"}, {"title": "Beemo: Benchmark of Expert-edited Machine-generated Outputs", "link": "https://arxiv.org/abs/2411.04032", "description": "arXiv:2411.04032v1 Announce Type: new \nAbstract: The rapid proliferation of large language models (LLMs) has increased the volume of machine-generated texts (MGTs) and blurred text authorship in various domains. However, most existing MGT benchmarks include single-author texts (human-written and machine-generated). This conventional design fails to capture more practical multi-author scenarios, where the user refines the LLM response for natural flow, coherence, and factual correctness. Our paper introduces the Benchmark of Expert-edited Machine-generated Outputs (Beemo), which includes 6.5k texts written by humans, generated by ten instruction-finetuned LLMs, and edited by experts for various use cases, ranging from creative writing to summarization. Beemo additionally comprises 13.1k machine-generated and LLM-edited texts, allowing for diverse MGT detection evaluation across various edit types. We document Beemo's creation protocol and present the results of benchmarking 33 configurations of MGT detectors in different experimental setups. We find that expert-based editing evades MGT detection, while LLM-edited texts are unlikely to be recognized as human-written. Beemo and all materials are publicly available.", "published": "2024-11-07 05:00:00", "id": "eae3d386-aebd-4c96-8ef9-303f5041f3e5", "source": "arxiv", "section": "computerScience"}, {"title": "Non-Stationary Learning of Neural Networks with Automatic Soft Parameter Reset", "link": "https://arxiv.org/abs/2411.04034", "description": "arXiv:2411.04034v1 Announce Type: new \nAbstract: Neural networks are traditionally trained under the assumption that data come from a stationary distribution. However, settings which violate this assumption are becoming more popular; examples include supervised learning under distributional shifts, reinforcement learning, continual learning and non-stationary contextual bandits. In this work we introduce a novel learning approach that automatically models and adapts to non-stationarity, via an Ornstein-Uhlenbeck process with an adaptive drift parameter. The adaptive drift tends to draw the parameters towards the initialisation distribution, so the approach can be understood as a form of soft parameter reset. We show empirically that our approach performs well in non-stationary supervised and off-policy reinforcement learning settings.", "published": "2024-11-07 05:00:00", "id": "4d644334-3a6b-4467-a25a-6a1a05ea0dc6", "source": "arxiv", "section": "computerScience"}, {"title": "Stepping Forward on the Last Mile", "link": "https://arxiv.org/abs/2411.04036", "description": "arXiv:2411.04036v1 Announce Type: new \nAbstract: Continuously adapting pre-trained models to local data on resource constrained edge devices is the $\\emph{last mile}$ for model deployment. However, as models increase in size and depth, backpropagation requires a large amount of memory, which becomes prohibitive for edge devices. In addition, most existing low power neural processing engines (e.g., NPUs, DSPs, MCUs, etc.) are designed as fixed-point inference accelerators, without training capabilities. Forward gradients, solely based on directional derivatives computed from two forward calls, have been recently used for model training, with substantial savings in computation and memory. However, the performance of quantized training with fixed-point forward gradients remains unclear. In this paper, we investigate the feasibility of on-device training using fixed-point forward gradients, by conducting comprehensive experiments across a variety of deep learning benchmark tasks in both vision and audio domains. We propose a series of algorithm enhancements that further reduce the memory footprint, and the accuracy gap compared to backpropagation. An empirical study on how training with forward gradients navigates in the loss landscape is further explored. Our results demonstrate that on the last mile of model customization on edge devices, training with fixed-point forward gradients is a feasible and practical approach.", "published": "2024-11-07 05:00:00", "id": "fcabc827-7cea-400b-acf2-2b3ef56f9716", "source": "arxiv", "section": "computerScience"}, {"title": "Taming Toxicity or Fueling It? The Great Ban Role in Shifting Toxic User Behavior and Engagement", "link": "https://arxiv.org/abs/2411.04037", "description": "arXiv:2411.04037v1 Announce Type: new \nAbstract: In today's online environments users experience harm and abuse on a daily basis. Therefore, content moderation is crucial to ensure their safety and well-being. However, the effectiveness of many moderation interventions is still uncertain. We evaluate the effectiveness of The Great Ban, one of the largest deplatforming interventions carried out by Reddit that affected almost 2,000 communities. We analyze 53M comments shared by nearly 34K users, providing in-depth results on both the intended and unintended consequences of this ban. We found that 15.6\\% of the moderated users abandoned the platform while the remaining ones decreased their overall toxicity by 4.1\\%. Nonetheless, a subset of those users increased their toxicity by 70\\% after the intervention. In any case, increases in toxicity did not lead to marked increases in activity or engagement, meaning that the most toxic users had overall a limited impact. Our findings bring to light new insights on the effectiveness of deplatforming. Furthermore, they also contribute to informing future content moderation strategies.", "published": "2024-11-07 05:00:00", "id": "c3060075-3b52-46d5-9564-774059da6742", "source": "arxiv", "section": "computerScience"}, {"title": "Instance-Optimal Acyclic Join Processing Without Regret: Engineering the Yannakakis Algorithm in Column Stores", "link": "https://arxiv.org/abs/2411.04042", "description": "arXiv:2411.04042v1 Announce Type: new \nAbstract: Acyclic join queries can be evaluated instance-optimally using Yannakakis' algorithm, which avoids needlessly large intermediate results through semi-join passes. Recent work proposes to address the significant hidden constant factors arising from a naive implementation of Yannakakis by decomposing the hash join operator into two suboperators, called Lookup and Expand. In this paper, we present a novel method for integrating Lookup and Expand plans in interpreted environments, like column stores, formalizing them using Nested Semijoin Algebra (NSA) and implementing them through a shredding approach. We characterize the class of NSA expressions that can be evaluated instance-optimally as those that are 2-phase: no `shrinking' operator is applied after an unnest (i.e., expand). We introduce Shredded Yannakakis (SYA), an evaluation algorithm for acyclic joins that, starting from a binary join plan, transforms it into a 2-phase NSA plan, and then evaluates it through the shredding technique. We show that SYA is provably robust (i.e., never produces large intermediate results) and without regret (i.e., is never worse than the binary join plan under a suitable cost model) on the class of well-behaved binary join plans. Our experiments on a suite of 1,849 queries show that SYA improves performance for 88.7% of the queries with speedups up to 188x, while remaining competitive on the other queries. We hope this approach offers a fresh perspective on Yannakakis' algorithm, helping system engineers better understand its practical benefits and facilitating its adoption into a broader spectrum of query engines.", "published": "2024-11-07 05:00:00", "id": "7f1b9aaa-fb76-4952-abaf-ec2518868ace", "source": "arxiv", "section": "computerScience"}, {"title": "Design and control of a robotic payload stabilization mechanism for rocket flights", "link": "https://arxiv.org/abs/2411.04046", "description": "arXiv:2411.04046v1 Announce Type: new \nAbstract: The use of parallel manipulators in aerospace engineering has gained significant attention due to their ability to provide improved stability and precision. This paper presents the design, control, and analysis of 'STEWIE', which is a three-degree-of-freedom (DoF) parallel manipulator robot developed by members of the thrustMIT rocketry team, as a payload stabilization mechanism for their sounding rocket, 'Altair'. The goal of the robot was to demonstrate the attitude control of the parallel plate against the continuous change in orientation experienced by the rocket during its flight, stabilizing the payloads. At the same time, the high gravitational forces (G-forces) and vibrations experienced by the sounding rocket are counteracted. A novel design of the mechanism, inspired by a standard Stewart platform, is proposed which was down-scaled to fit inside a 4U CubeSat within its space constraints. The robot uses three micro servo motors to actuate the links that control the alignment of the parallel plate. In addition to the actuation mechanism, a robust control system for its manipulation was developed for the robot. The robot represents a significant advancement in the field of space robotics in the aerospace industry by demonstrating the successful implementation of complex robotic mechanisms in small, confined spaces such as CubeSats, which are standard form factors for large payloads in the aerospace industry.", "published": "2024-11-07 05:00:00", "id": "660282ef-5cb7-436f-b899-b30e3d441438", "source": "arxiv", "section": "computerScience"}, {"title": "Memorized action chunking with Transformers: Imitation learning for vision-based tissue surface scanning", "link": "https://arxiv.org/abs/2411.04050", "description": "arXiv:2411.04050v1 Announce Type: new \nAbstract: Optical sensing technologies are emerging technologies used in cancer surgeries to ensure the complete removal of cancerous tissue. While point-wise assessment has many potential applications, incorporating automated large area scanning would enable holistic tissue sampling. However, such scanning tasks are challenging due to their long-horizon dependency and the requirement for fine-grained motion. To address these issues, we introduce Memorized Action Chunking with Transformers (MACT), an intuitive yet efficient imitation learning method for tissue surface scanning tasks. It utilizes a sequence of past images as historical information to predict near-future action sequences. In addition, hybrid temporal-spatial positional embeddings were employed to facilitate learning. In various simulation settings, MACT demonstrated significant improvements in contour scanning and area scanning over the baseline model. In real-world testing, with only 50 demonstration trajectories, MACT surpassed the baseline model by achieving a 60-80% success rate on all scanning tasks. Our findings suggest that MACT is a promising model for adaptive scanning in surgical settings.", "published": "2024-11-07 05:00:00", "id": "de31e9df-99ec-4833-800f-a9abdafd0f78", "source": "arxiv", "section": "computerScience"}, {"title": "Reproducible Hybrid Time-Travel Retrieval in Evolving Corpora", "link": "https://arxiv.org/abs/2411.04051", "description": "arXiv:2411.04051v1 Announce Type: new \nAbstract: There are settings in which reproducibility of ranked lists is desirable, such as when extracting a subset of an evolving document corpus for downstream research tasks or in domains such as patent retrieval or in medical systematic reviews, with high reproducibility expectations. However, as global term statistics change when documents change or are added to a corpus, queries using typical ranked retrieval models are not even reproducible for the parts of the document corpus that have not changed. Thus, Boolean retrieval frequently remains the mechanism of choice in such settings.\n  We present a hybrid retrieval system combining Lucene for fast retrieval with a column-store-based retrieval system maintaining a versioned and time-stamped index. The latter component allows re-execution of previously posed queries resulting in the same ranked list and further allows for time-travel queries over evolving collection, as web archives, while maintaining the original ranking. Thus, retrieval results in evolving document collections are fully reproducible even when document collections and thus term statistics change.", "published": "2024-11-07 05:00:00", "id": "e0115530-5307-4866-af43-02021e3554e2", "source": "arxiv", "section": "computerScience"}, {"title": "Multi-branch Spatio-Temporal Graph Neural Network For Efficient Ice Layer Thickness Prediction", "link": "https://arxiv.org/abs/2411.04055", "description": "arXiv:2411.04055v1 Announce Type: new \nAbstract: Understanding spatio-temporal patterns in polar ice layers is essential for tracking changes in ice sheet balance and assessing ice dynamics. While convolutional neural networks are widely used in learning ice layer patterns from raw echogram images captured by airborne snow radar sensors, noise in the echogram images prevents researchers from getting high-quality results. Instead, we focus on geometric deep learning using graph neural networks, aiming to build a spatio-temporal graph neural network that learns from thickness information of the top ice layers and predicts for deeper layers. In this paper, we developed a novel multi-branch spatio-temporal graph neural network that used the GraphSAGE framework for spatio features learning and a temporal convolution operation to capture temporal changes, enabling different branches of the network to be more specialized and focusing on a single learning task. We found that our proposed multi-branch network can consistently outperform the current fused spatio-temporal graph neural network in both accuracy and efficiency.", "published": "2024-11-07 05:00:00", "id": "17db4a26-a80e-45c3-b21d-069b78723b78", "source": "arxiv", "section": "computerScience"}, {"title": "Problem Space Transformations for Generalisation in Behavioural Cloning", "link": "https://arxiv.org/abs/2411.04056", "description": "arXiv:2411.04056v1 Announce Type: new \nAbstract: The combination of behavioural cloning and neural networks has driven significant progress in robotic manipulation. As these algorithms may require a large number of demonstrations for each task of interest, they remain fundamentally inefficient in complex scenarios. This issue is aggravated when the system is treated as a black-box, ignoring its physical properties. This work characterises widespread properties of robotic manipulation, such as pose equivariance and locality. We empirically demonstrate that transformations arising from each of these properties allow neural policies trained with behavioural cloning to better generalise to out-of-distribution problem instances.", "published": "2024-11-07 05:00:00", "id": "bf13c971-2a2e-4453-9f40-ce79881733f7", "source": "arxiv", "section": "computerScience"}, {"title": "Pseudo-labeling with Keyword Refining for Few-Supervised Video Captioning", "link": "https://arxiv.org/abs/2411.04059", "description": "arXiv:2411.04059v1 Announce Type: new \nAbstract: Video captioning generate a sentence that describes the video content. Existing methods always require a number of captions (\\eg, 10 or 20) per video to train the model, which is quite costly. In this work, we explore the possibility of using only one or very few ground-truth sentences, and introduce a new task named few-supervised video captioning. Specifically, we propose a few-supervised video captioning framework that consists of lexically constrained pseudo-labeling module and keyword-refined captioning module. Unlike the random sampling in natural language processing that may cause invalid modifications (\\ie, edit words), the former module guides the model to edit words using some actions (\\eg, copy, replace, insert, and delete) by a pretrained token-level classifier, and then fine-tunes candidate sentences by a pretrained language model. Meanwhile, the former employs the repetition penalized sampling to encourage the model to yield concise pseudo-labeled sentences with less repetition, and selects the most relevant sentences upon a pretrained video-text model. Moreover, to keep semantic consistency between pseudo-labeled sentences and video content, we develop the transformer-based keyword refiner with the video-keyword gated fusion strategy to emphasize more on relevant words. Extensive experiments on several benchmarks demonstrate the advantages of the proposed approach in both few-supervised and fully-supervised scenarios. The code implementation is available at https://github.com/mlvccn/PKG_VidCap", "published": "2024-11-07 05:00:00", "id": "0b925005-be05-4c3c-b611-0348d7c5e7af", "source": "arxiv", "section": "computerScience"}, {"title": "Soft Reverse Reconciliation for Discrete Modulations", "link": "https://arxiv.org/abs/2411.04063", "description": "arXiv:2411.04063v1 Announce Type: new \nAbstract: The performance of the information reconciliation phase is crucial for quantum key distribution (QKD). Reverse reconciliation (RR) is typically preferred over direct reconciliation (DR) because it yields higher secure key rates. However, a significant challenge in continuous-variable (CV) QKD with discrete modulations (such as QAM) is that Alice lacks soft information about the symbol decisions made by Bob. This limitation restricts error correction to hard-decoding methods, with low reconciliation efficiency. This work introduces a reverse reconciliation softening (RRS) procedure designed for CV-QKD scenarios employing discrete modulations. This procedure generates a soft metric that Bob can share with Alice over a public channel, enabling her to perform soft-decoding error correction without disclosing any information to a potential eavesdropper. After detailing the RRS procedure, we investigate how the mutual information between Alice's and Bob's variables changes when the additional metric is shared. We show numerically that RRS improves the mutual information with respect to RR with hard decoding, practically achieving the same mutual information as DR with soft decoding. Finally, we test the proposed RRS for PAM-4 signalling with a rate 1/2 binary LDPC code and bit-wise decoding through numerical simulations, obtaining more than 1dB SNR improvement compared to hard-decoding RR.", "published": "2024-11-07 05:00:00", "id": "d128944a-28d4-43b5-b552-6cff21a7ccf4", "source": "arxiv", "section": "computerScience"}, {"title": "Security Assessment of Mobile Banking Apps in West African Economic and Monetary Union", "link": "https://arxiv.org/abs/2411.04068", "description": "arXiv:2411.04068v1 Announce Type: new \nAbstract: The West African Economic and Monetary Union (WAEMU) states, characterized by widespread smartphone usage, have witnessed banks and financial institutions introducing mobile banking applications (MBAs). These apps empower users to perform transactions such as money transfers, bill payments, and account inquiries anytime, anywhere. However, this proliferation of MBAs also raises significant security concerns. Poorly implemented security measures during app development can expose users and financial institutions to substantial financial risks through increased vulnerability to cyberattacks. Our study evaluated fifty-nine WAEMU MBAs using static analysis techniques. These MBAs were collected from the 160 banks and financial institutions of the eight WAEMU countries listed on the Central Bank of West African States (BCEAO) website. We identified security-related code issues that could be exploited by malicious actors. We investigated the issues found in the older versions to track their evolution across updates. Additionally, we identified some banks from regions such as Europe, the United States, and other developing countries and analyzed their mobile apps for a security comparison with WAEMU MBAs. Key findings include: (1) WAEMU apps exhibit security issues introduced during development, posing significant risks of exploitation; (2) Despite frequent updates, underlying security issues often persist; (3) Compared to MBAs from developed and developing countries, WAEMU apps exhibit fewer critical security issues; and (4) Apps from banks that are branches of other non-WAEMU banks often inherit security concerns from their parent apps while also introducing additional issues unique to their context. Our research underscores the need for robust security practices in WAEMU MBAs development to enhance user safety and trust in financial services.", "published": "2024-11-07 05:00:00", "id": "bc8add26-f73c-4b20-a044-d0dd73ebc1f3", "source": "arxiv", "section": "computerScience"}, {"title": "Rescheduling after vehicle failures in the multi-depot rural postman problem with rechargeable and reusable vehicles", "link": "https://arxiv.org/abs/2411.04073", "description": "arXiv:2411.04073v1 Announce Type: new \nAbstract: We present a centralized auction algorithm to solve the Multi-Depot Rural Postman Problem with Rechargeable and Reusable Vehicles (MD-RPP-RRV), focusing on rescheduling arc routing after vehicle failures. The problem involves finding heuristically obtained best feasible routes for multiple rechargeable and reusable vehicles with capacity constraints capable of performing multiple trips from multiple depots, with the possibility of vehicle failures. Our algorithm auctions the failed trips to active (non-failed) vehicles through local auctioning, modifying initial routes to handle dynamic vehicle failures efficiently. When a failure occurs, the algorithm searches for the best active vehicle to perform the failed trip and inserts the trip into that vehicle's route, which avoids a complete rescheduling and reduces the computational effort. We compare the algorithm's solutions against offline optimal solutions obtained from solving a Mixed Integer Linear Programming (MILP) formulation using the Gurobi solver; this formulation assumes that perfect information about the vehicle failures and failure times is given. The results demonstrate that the centralized auction algorithm produces solutions that are, in some cases, near optimal; moreover, the execution time for the proposed approach is much more consistent and is, for some instances, orders of magnitude less than the execution time of the Gurobi solver. The theoretical analysis provides an upper bound for the competitive ratio and computational complexity of our algorithm, offering a formal performance guarantee in dynamic failure scenarios.", "published": "2024-11-07 05:00:00", "id": "8471bba1-5943-4abd-b1bd-cf240974e8da", "source": "arxiv", "section": "computerScience"}, {"title": "M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models", "link": "https://arxiv.org/abs/2411.04075", "description": "arXiv:2411.04075v1 Announce Type: new \nAbstract: Existing benchmarks for evaluating foundation models mainly focus on single-document, text-only tasks. However, they often fail to fully capture the complexity of research workflows, which typically involve interpreting non-textual data and gathering information across multiple documents. To address this gap, we introduce M3SciQA, a multi-modal, multi-document scientific question answering benchmark designed for a more comprehensive evaluation of foundation models. M3SciQA consists of 1,452 expert-annotated questions spanning 70 natural language processing paper clusters, where each cluster represents a primary paper along with all its cited documents, mirroring the workflow of comprehending a single paper by requiring multi-modal and multi-document data. With M3SciQA, we conduct a comprehensive evaluation of 18 foundation models. Our results indicate that current foundation models still significantly underperform compared to human experts in multi-modal information retrieval and in reasoning across multiple scientific documents. Additionally, we explore the implications of these findings for the future advancement of applying foundation models in multi-modal scientific literature analysis.", "published": "2024-11-07 05:00:00", "id": "cb3e1f18-1203-4ad2-bb8f-5093d241b1c6", "source": "arxiv", "section": "computerScience"}, {"title": "H-POPE: Hierarchical Polling-based Probing Evaluation of Hallucinations in Large Vision-Language Models", "link": "https://arxiv.org/abs/2411.04077", "description": "arXiv:2411.04077v1 Announce Type: new \nAbstract: By leveraging both texts and images, large vision language models (LVLMs) have shown significant progress in various multi-modal tasks. Nevertheless, these models often suffer from hallucinations, e.g., they exhibit inconsistencies between the visual input and the textual output. To address this, we propose H-POPE, a coarse-to-fine-grained benchmark that systematically assesses hallucination in object existence and attributes. Our evaluation shows that models are prone to hallucinations on object existence, and even more so on fine-grained attributes. We further investigate whether these models rely on visual input to formulate the output texts.", "published": "2024-11-07 05:00:00", "id": "933c12c7-e3c8-4f85-9a67-ff6fcacabe34", "source": "arxiv", "section": "computerScience"}, {"title": "Textual Decomposition Then Sub-motion-space Scattering for Open-Vocabulary Motion Generation", "link": "https://arxiv.org/abs/2411.04079", "description": "arXiv:2411.04079v1 Announce Type: new \nAbstract: Text-to-motion generation is a crucial task in computer vision, which generates the target 3D motion by the given text. The existing annotated datasets are limited in scale, resulting in most existing methods overfitting to the small datasets and unable to generalize to the motions of the open domain. Some methods attempt to solve the open-vocabulary motion generation problem by aligning to the CLIP space or using the Pretrain-then-Finetuning paradigm. However, the current annotated dataset's limited scale only allows them to achieve mapping from sub-text-space to sub-motion-space, instead of mapping between full-text-space and full-motion-space (full mapping), which is the key to attaining open-vocabulary motion generation. To this end, this paper proposes to leverage the atomic motion (simple body part motions over a short time period) as an intermediate representation, and leverage two orderly coupled steps, i.e., Textual Decomposition and Sub-motion-space Scattering, to address the full mapping problem. For Textual Decomposition, we design a fine-grained description conversion algorithm, and combine it with the generalization ability of a large language model to convert any given motion text into atomic texts. Sub-motion-space Scattering learns the compositional process from atomic motions to the target motions, to make the learned sub-motion-space scattered to form the full-motion-space. For a given motion of the open domain, it transforms the extrapolation into interpolation and thereby significantly improves generalization. Our network, $DSO$-Net, combines textual $d$ecomposition and sub-motion-space $s$cattering to solve the $o$pen-vocabulary motion generation. Extensive experiments demonstrate that our DSO-Net achieves significant improvements over the state-of-the-art methods on open-vocabulary motion generation. Code is available at https://vankouf.github.io/DSONet/.", "published": "2024-11-07 05:00:00", "id": "c05475b0-a9a8-4b34-a10e-1b93a42d763d", "source": "arxiv", "section": "computerScience"}, {"title": "Learned codes for broadcast channels with feedback", "link": "https://arxiv.org/abs/2411.04083", "description": "arXiv:2411.04083v1 Announce Type: new \nAbstract: We focus on designing error-correcting codes for the symmetric Gaussian broadcast channel with feedback. Feedback not only expands the capacity region of the broadcast channel but also enhances transmission reliability. In this work, we study the construction of learned finite blocklength codes for broadcast channels with feedback. Learned error-correcting codes, in which both the encoder and decoder are jointly trained, have shown impressive performance in point-to-point channels, particularly with noisy feedback. However, few learned schemes exist for multi-user channels. Here, we develop a lightweight code for the broadcast channel with feedback that outperforms existing schemes and operates effectively at short blocklengths.", "published": "2024-11-07 05:00:00", "id": "a911c21c-0692-4d29-9558-e71c01479a4c", "source": "arxiv", "section": "computerScience"}, {"title": "A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement", "link": "https://arxiv.org/abs/2411.04090", "description": "arXiv:2411.04090v1 Announce Type: new \nAbstract: Content moderation typically combines the efforts of human moderators and machine learning models.However, these systems often rely on data where significant disagreement occurs during moderation, reflecting the subjective nature of toxicity perception.Rather than dismissing this disagreement as noise, we interpret it as a valuable signal that highlights the inherent ambiguity of the content,an insight missed when only the majority label is considered.In this work, we introduce a novel content moderation framework that emphasizes the importance of capturing annotation disagreement. Our approach uses multitask learning, where toxicity classification serves as the primary task and annotation disagreement is addressed as an auxiliary task.Additionally, we leverage uncertainty estimation techniques, specifically Conformal Prediction, to account for both the ambiguity in comment annotations and the model's inherent uncertainty in predicting toxicity and disagreement.The framework also allows moderators to adjust thresholds for annotation disagreement, offering flexibility in determining when ambiguity should trigger a review.We demonstrate that our joint approach enhances model performance, calibration, and uncertainty estimation, while offering greater parameter efficiency and improving the review process in comparison to single-task methods.", "published": "2024-11-07 05:00:00", "id": "d5d8fe21-a2e7-4c36-83fc-fcc9ac99adf5", "source": "arxiv", "section": "computerScience"}, {"title": "Summarization of Opinionated Political Documents with Varied Perspectives", "link": "https://arxiv.org/abs/2411.04093", "description": "arXiv:2411.04093v1 Announce Type: new \nAbstract: Global partisan hostility and polarization has increased, and this polarization is heightened around presidential elections. Models capable of generating accurate summaries of diverse perspectives can help reduce such polarization by exposing users to alternative perspectives. In this work, we introduce a novel dataset and task for independently summarizing each political perspective in a set of passages from opinionated news articles. For this task, we propose a framework for evaluating different dimensions of perspective summary performance. We benchmark 10 models of varying sizes and architectures through both automatic and human evaluation. While recent models like GPT-4o perform well on this task, we find that all models struggle to generate summaries faithful to the intended perspective. Our analysis of summaries focuses on how extraction behavior depends on the features of the input documents.", "published": "2024-11-07 05:00:00", "id": "f69902e6-97c8-48ed-9f7d-4ef114dbc790", "source": "arxiv", "section": "computerScience"}, {"title": "RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models", "link": "https://arxiv.org/abs/2411.04097", "description": "arXiv:2411.04097v1 Announce Type: new \nAbstract: Fine-tuned vision-language models (VLMs) often capture spurious correlations between image features and textual attributes, resulting in degraded zero-shot performance at test time. Existing approaches for addressing spurious correlations (i) primarily operate at the global image-level rather than intervening directly on fine-grained image features and (ii) are predominantly designed for unimodal settings. In this work, we present RaVL, which takes a fine-grained perspective on VLM robustness by discovering and mitigating spurious correlations using local image features rather than operating at the global image level. Given a fine-tuned VLM, RaVL first discovers spurious correlations by leveraging a region-level clustering approach to identify precise image features contributing to zero-shot classification errors. Then, RaVL mitigates the identified spurious correlation with a novel region-aware loss function that enables the VLM to focus on relevant regions and ignore spurious relationships during fine-tuning. We evaluate RaVL on 654 VLMs with various model architectures, data domains, and learned spurious correlations. Our results show that RaVL accurately discovers (191% improvement over the closest baseline) and mitigates (8.2% improvement on worst-group image classification accuracy) spurious correlations. Qualitative evaluations on general-domain and medical-domain VLMs confirm our findings.", "published": "2024-11-07 05:00:00", "id": "378e1b5d-5755-4921-a468-e674e0353479", "source": "arxiv", "section": "computerScience"}, {"title": "Interpretable and Efficient Data-driven Discovery and Control of Distributed Systems", "link": "https://arxiv.org/abs/2411.04098", "description": "arXiv:2411.04098v1 Announce Type: new \nAbstract: Effectively controlling systems governed by Partial Differential Equations (PDEs) is crucial in several fields of Applied Sciences and Engineering. These systems usually yield significant challenges to conventional control schemes due to their nonlinear dynamics, partial observability, high-dimensionality once discretized, distributed nature, and the requirement for low-latency feedback control. Reinforcement Learning (RL), particularly Deep RL (DRL), has recently emerged as a promising control paradigm for such systems, demonstrating exceptional capabilities in managing high-dimensional, nonlinear dynamics. However, DRL faces challenges including sample inefficiency, robustness issues, and an overall lack of interpretability. To address these issues, we propose a data-efficient, interpretable, and scalable Dyna-style Model-Based RL framework for PDE control, combining the Sparse Identification of Nonlinear Dynamics with Control (SINDy-C) algorithm and an autoencoder (AE) framework for the sake of dimensionality reduction of PDE states and actions. This novel approach enables fast rollouts, reducing the need for extensive environment interactions, and provides an interpretable latent space representation of the PDE forward dynamics. We validate our method on two PDE problems describing fluid flows - namely, the 1D Burgers equation and 2D Navier-Stokes equations - comparing it against a model-free baseline, and carrying out an extensive analysis of the learned dynamics.", "published": "2024-11-07 05:00:00", "id": "bfd46102-1e44-4850-b101-7b745b89140b", "source": "arxiv", "section": "computerScience"}, {"title": "Optimizing Quantum Circuits, Fast and Slow", "link": "https://arxiv.org/abs/2411.04104", "description": "arXiv:2411.04104v1 Announce Type: new \nAbstract: Optimizing quantum circuits is critical: the number of quantum operations needs to be minimized for a successful evaluation of a circuit on a quantum processor. In this paper we unify two disparate ideas for optimizing quantum circuits, rewrite rules, which are fast standard optimizer passes, and unitary synthesis, which is slow, requiring a search through the space of circuits. We present a clean, unifying framework for thinking of rewriting and resynthesis as abstract circuit transformations. We then present a radically simple algorithm, GUOQ, for optimizing quantum circuits that exploits the synergies of rewriting and resynthesis. Our extensive evaluation demonstrates the ability of GUOQ to strongly outperform existing optimizers on a wide range of benchmarks.", "published": "2024-11-07 05:00:00", "id": "97e9bf4b-e3c1-45ce-a50d-5bb2d7f4b4e3", "source": "arxiv", "section": "computerScience"}, {"title": "How Transformers Solve Propositional Logic Problems: A Mechanistic Analysis", "link": "https://arxiv.org/abs/2411.04105", "description": "arXiv:2411.04105v1 Announce Type: new \nAbstract: Large language models (LLMs) have shown amazing performance on tasks that require planning and reasoning. Motivated by this, we investigate the internal mechanisms that underpin a network's ability to perform complex logical reasoning. We first construct a synthetic propositional logic problem that serves as a concrete test-bed for network training and evaluation. Crucially, this problem demands nontrivial planning to solve, but we can train a small transformer to achieve perfect accuracy. Building on our set-up, we then pursue an understanding of precisely how a three-layer transformer, trained from scratch, solves this problem. We are able to identify certain \"planning\" and \"reasoning\" circuits in the network that necessitate cooperation between the attention blocks to implement the desired logic. To expand our findings, we then study a larger model, Mistral 7B. Using activation patching, we characterize internal components that are critical in solving our logic problem. Overall, our work systemically uncovers novel aspects of small and large transformers, and continues the study of how they plan and reason.", "published": "2024-11-07 05:00:00", "id": "0c345080-e8be-48fd-9461-fb0510729d47", "source": "arxiv", "section": "computerScience"}, {"title": "A Comparative Study of Deep Reinforcement Learning for Crop Production Management", "link": "https://arxiv.org/abs/2411.04106", "description": "arXiv:2411.04106v1 Announce Type: new \nAbstract: Crop production management is essential for optimizing yield and minimizing a field's environmental impact to crop fields, yet it remains challenging due to the complex and stochastic processes involved. Recently, researchers have turned to machine learning to address these complexities. Specifically, reinforcement learning (RL), a cutting-edge approach designed to learn optimal decision-making strategies through trial and error in dynamic environments, has emerged as a promising tool for developing adaptive crop management policies. RL models aim to optimize long-term rewards by continuously interacting with the environment, making them well-suited for tackling the uncertainties and variability inherent in crop management. Studies have shown that RL can generate crop management policies that compete with, and even outperform, expert-designed policies within simulation-based crop models. In the gym-DSSAT crop model environment, one of the most widely used simulators for crop management, proximal policy optimization (PPO) and deep Q-networks (DQN) have shown promising results. However, these methods have not yet been systematically evaluated under identical conditions. In this study, we evaluated PPO and DQN against static baseline policies across three different RL tasks, fertilization, irrigation, and mixed management, provided by the gym-DSSAT environment. To ensure a fair comparison, we used consistent default parameters, identical reward functions, and the same environment settings. Our results indicate that PPO outperforms DQN in fertilization and irrigation tasks, while DQN excels in the mixed management task. This comparative analysis provides critical insights into the strengths and limitations of each approach, advancing the development of more effective RL-based crop management strategies.", "published": "2024-11-07 05:00:00", "id": "8c333f59-86fc-4ea4-bd4f-2da913eda973", "source": "arxiv", "section": "computerScience"}, {"title": "Weighted Sobolev Approximation Rates for Neural Networks on Unbounded Domains", "link": "https://arxiv.org/abs/2411.04108", "description": "arXiv:2411.04108v1 Announce Type: new \nAbstract: In this work, we consider the approximation capabilities of shallow neural networks in weighted Sobolev spaces for functions in the spectral Barron space. The existing literature already covers several cases, in which the spectral Barron space can be approximated well, i.e., without curse of dimensionality, by shallow networks and several different classes of activation function. The limitations of the existing results are mostly on the error measures that were considered, in which the results are restricted to Sobolev spaces over a bounded domain. We will here treat two cases that extend upon the existing results. Namely, we treat the case with bounded domain and Muckenhoupt weights and the case, where the domain is allowed to be unbounded and the weights are required to decay. We first present embedding results for the more general weighted Fourier-Lebesgue spaces in the weighted Sobolev spaces and then we establish asymptotic approximation rates for shallow neural networks that come without curse of dimensionality.", "published": "2024-11-07 05:00:00", "id": "b46766f0-a218-4385-9054-4112cf6d7a20", "source": "arxiv", "section": "computerScience"}, {"title": "Self-Consistency Preference Optimization", "link": "https://arxiv.org/abs/2411.04109", "description": "arXiv:2411.04109v1 Announce Type: new \nAbstract: Self-alignment, whereby models learn to improve themselves without human annotation, is a rapidly growing research area. However, existing techniques often fail to improve complex reasoning tasks due to the difficulty of assigning correct rewards. An orthogonal approach that is known to improve correctness is self-consistency, a method applied at inference time based on multiple sampling in order to find the most consistent answer. In this work, we extend the self-consistency concept to help train models. We thus introduce self-consistency preference optimization (ScPO), which iteratively trains consistent answers to be preferred over inconsistent ones on unsupervised new problems. We show ScPO leads to large improvements over conventional reward model training on reasoning tasks such as GSM8K and MATH, closing the gap with supervised training with gold answers or preferences, and that combining ScPO with standard supervised learning improves results even further. On ZebraLogic, ScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and Claude-3 Haiku.", "published": "2024-11-07 05:00:00", "id": "21b94ebe-9e00-4230-a290-4cf07a292467", "source": "arxiv", "section": "computerScience"}, {"title": "Fed-EC: Bandwidth-Efficient Clustering-Based Federated Learning For Autonomous Visual Robot Navigation", "link": "https://arxiv.org/abs/2411.04112", "description": "arXiv:2411.04112v1 Announce Type: new \nAbstract: Centralized learning requires data to be aggregated at a central server, which poses significant challenges in terms of data privacy and bandwidth consumption. Federated learning presents a compelling alternative, however, vanilla federated learning methods deployed in robotics aim to learn a single global model across robots that works ideally for all. But in practice one model may not be well suited for robots deployed in various environments. This paper proposes Federated-EmbedCluster (Fed-EC), a clustering-based federated learning framework that is deployed with vision based autonomous robot navigation in diverse outdoor environments. The framework addresses the key federated learning challenge of deteriorating model performance of a single global model due to the presence of non-IID data across real-world robots. Extensive real-world experiments validate that Fed-EC reduces the communication size by 23x for each robot while matching the performance of centralized learning for goal-oriented navigation and outperforms local learning. Fed-EC can transfer previously learnt models to new robots that join the cluster.", "published": "2024-11-07 05:00:00", "id": "db7c3eec-6309-4e8c-af7f-cb34069a6631", "source": "arxiv", "section": "computerScience"}, {"title": "Age of Gossip With Time-Varying Topologies", "link": "https://arxiv.org/abs/2411.04114", "description": "arXiv:2411.04114v1 Announce Type: new \nAbstract: We consider a gossiping network, where a source node sends updates to a network of $n$ gossiping nodes. Meanwhile, the connectivity topology of the gossiping network changes over time, among a finite number of connectivity ''states,'' such as the fully connected graph, the ring graph, the grid graph, etc. The transition of the connectivity graph among the possible options is governed by a finite state continuous time Markov chain (CTMC). When the CTMC is in a particular state, the associated graph topology of the gossiping network is in the way indicated by that state. We evaluate the impact of time-varying graph topologies on the freshness of information for nodes in the network. We use the version age of information metric to quantify the freshness of information at the nodes. Using a method similar to the first passage percolation method, we show that, if one of the states of the CTMC is the fully connected graph and the transition rates of the CTMC are constant, then the version age of a typical node in the network scales logarithmically with the number of nodes, as in the case if the network was always fully connected. That is, there is no loss in the age scaling, even if the network topology deviates from full connectivity, in this setting. We perform numerical simulations and analyze more generally how having different topologies and different CTMC rates (that might depend on the number of nodes) affect the average version age scaling of a node in the gossiping network.", "published": "2024-11-07 05:00:00", "id": "78b6b5ab-1b2b-405f-846a-6ae983da77ef", "source": "arxiv", "section": "computerScience"}, {"title": "Condensing Against Online Adversaries", "link": "https://arxiv.org/abs/2411.04115", "description": "arXiv:2411.04115v1 Announce Type: new \nAbstract: We investigate the task of deterministically condensing randomness from Online Non-Oblivious Symbol Fixing (oNOSF) sources, a natural model for which extraction is impossible [AORSV, EUROCRYPT'20]. A $(g,\\ell)$-oNOSF source is a sequence of $\\ell$ blocks where at least $g$ of the blocks are good (independent and have some min-entropy) and the remaining bad blocks are controlled by an online adversary where each bad block can be arbitrarily correlated with any block that appears before it.\n  The existence of condensers was studied in [CGR, FOCS'24]. They proved condensing impossibility results for various values of $g, \\ell$ and showed the existence of condensers matching the impossibility results in the case when $n$ is extremely large compared to $\\ell$.\n  In this work, we make significant progress on proving the existence of condensers with strong parameters in almost all parameter regimes, even when $n$ is a large enough constant and $\\ell$ is growing. This almost resolves the question of the existence of condensers for oNOSF sources, except when $n$ is a small constant.\n  We construct the first explicit condensers for oNOSF sources, achieve parameters that match the existential results of [CGR, FOCS'24], and obtain an improved construction for transforming low-entropy oNOSF sources into uniform ones.\n  We find applications of our results to collective coin flipping and sampling, well-studied problems in fault-tolerant distributed computing. We use our condensers to provide simple protocols for these problems.\n  To understand the case of small $n$, we focus on $n=1$ which corresponds to online non-oblivious bit-fixing (oNOBF) sources. We initiate a study of a new, natural notion of influence of Boolean functions which we call online influence. We establish tight bounds on the total online influence of Boolean functions, implying extraction lower bounds.", "published": "2024-11-07 05:00:00", "id": "fd7b9386-13e2-4f5f-808d-caa1eafff81e", "source": "arxiv", "section": "computerScience"}, {"title": "Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?", "link": "https://arxiv.org/abs/2411.04118", "description": "arXiv:2411.04118v1 Announce Type: new \nAbstract: Several recent works seek to develop foundation models specifically for medical applications, adapting general-purpose large language models (LLMs) and vision-language models (VLMs) via continued pretraining on publicly available biomedical corpora. These works typically claim that such domain-adaptive pretraining (DAPT) improves performance on downstream medical tasks, such as answering medical licensing exam questions. In this paper, we compare seven public \"medical\" LLMs and two VLMs against their corresponding base models, arriving at a different conclusion: all medical VLMs and nearly all medical LLMs fail to consistently improve over their base models in the zero-/few-shot prompting regime for medical question-answering (QA) tasks. For instance, across the tasks and model pairs we consider in the 3-shot setting, medical LLMs only outperform their base models in 12.1% of cases, reach a (statistical) tie in 49.8% of cases, and are significantly worse than their base models in the remaining 38.2% of cases. Our conclusions are based on (i) comparing each medical model head-to-head, directly against the corresponding base model; (ii) optimizing the prompts for each model separately; and (iii) accounting for statistical uncertainty in comparisons. While these basic practices are not consistently adopted in the literature, our ablations show that they substantially impact conclusions. Our findings suggest that state-of-the-art general-domain models may already exhibit strong medical knowledge and reasoning capabilities, and offer recommendations to strengthen the conclusions of future studies.", "published": "2024-11-07 05:00:00", "id": "0abb1bc7-11f0-430d-80a0-3486ad077ccb", "source": "arxiv", "section": "computerScience"}, {"title": "On the (Classical and Quantum) Fine-Grained Complexity of Log-Approximate CVP and Max-Cut", "link": "https://arxiv.org/abs/2411.04124", "description": "arXiv:2411.04124v1 Announce Type: new \nAbstract: We show a linear sized reduction from the Maximum Cut Problem (Max-Cut) with completeness $1 - \\varepsilon$ and soundness $1 - \\varepsilon^{1/2}$ to the $\\gamma$-Approximate Closest Vector Problem under any finite $\\ell_p$-norm including $p = 2$.\n  This reduction implies two headline results: (i) We show that any sub-exponential time (classical or quantum) algorithm for the $o(\\sqrt{\\log n}^{\\frac{1}{p}})$-Approximate Closest Vector Problem in any finite $\\ell_p$-norm implies a faster than the state-of-the-art (by Arora, Barak, and Steurer [\\textit{Journal of the ACM}, 2015]) sub-exponential time (classical or quantum) algorithm for Max-Cut. This fills the gap between the results by Bennett, Golovnev, and Stephens-Davidowitz [\\textit{FOCS} 2017] which had an almost optimal runtime lower bound but a very small approximation factor and the results by Dinur, Kindler, Raz, and Safra [\\textit{Combinatorica}, 2003] which had an almost optimal approximation factor but small runtime lower bound, albeit using a different underlying hard problem; (ii) in combination with the classical results of Aggarwal and Kumar [\\textit{FOCS} 2023] and our quantization of those results, there are no fine-grained reductions from $k$-SAT to Max-Cut with one-sided error, nor are there non-adaptive fine-grained (classical or quantum) reductions with two-sided error, unless the polynomial hierarchy collapses (or unless $\\mathrm{NP} \\subseteq \\mathrm{pr} \\text{-} \\mathrm{QSZK}$ in the quantum case). The second result poses a significant barrier against proving the fine-grained complexity of Max-Cut using the Strong Exponential Time Hypothesis (or the Quantum Strong Exponential Time Hypothesis).", "published": "2024-11-07 05:00:00", "id": "9cefb9f3-806f-4cea-a44f-023e19597b81", "source": "arxiv", "section": "computerScience"}, {"title": "Community Forensics: Using Thousands of Generators to Train Fake Image Detectors", "link": "https://arxiv.org/abs/2411.04125", "description": "arXiv:2411.04125v1 Announce Type: new \nAbstract: One of the key challenges of detecting AI-generated images is spotting images that have been created by previously unseen generative models. We argue that the limited diversity of the training data is a major obstacle to addressing this problem, and we propose a new dataset that is significantly larger and more diverse than prior work. As part of creating this dataset, we systematically download thousands of text-to-image latent diffusion models and sample images from them. We also collect images from dozens of popular open source and commercial models. The resulting dataset contains 2.7M images that have been sampled from 4803 different models. These images collectively capture a wide range of scene content, generator architectures, and image processing settings. Using this dataset, we study the generalization abilities of fake image detectors. Our experiments suggest that detection performance improves as the number of models in the training set increases, even when these models have similar architectures. We also find that detection performance improves as the diversity of the models increases, and that our trained detectors generalize better than those trained on other datasets.", "published": "2024-11-07 05:00:00", "id": "f3ea9792-2c29-4610-860e-0b40bde6ead6", "source": "arxiv", "section": "computerScience"}, {"title": "Masked Multi-Query Slot Attention for Unsupervised Object Discovery", "link": "https://arxiv.org/abs/2404.19654", "description": "arXiv:2404.19654v1 Announce Type: cross \nAbstract: Unsupervised object discovery is becoming an essential line of research for tackling recognition problems that require decomposing an image into entities, such as semantic segmentation and object detection. Recently, object-centric methods that leverage self-supervision have gained popularity, due to their simplicity and adaptability to different settings and conditions. However, those methods do not exploit effective techniques already employed in modern self-supervised approaches. In this work, we consider an object-centric approach in which DINO ViT features are reconstructed via a set of queried representations called slots. Based on that, we propose a masking scheme on input features that selectively disregards the background regions, inducing our model to focus more on salient objects during the reconstruction phase. Moreover, we extend the slot attention to a multi-query approach, allowing the model to learn multiple sets of slots, producing more stable masks. During training, these multiple sets of slots are learned independently while, at test time, these sets are merged through Hungarian matching to obtain the final slots. Our experimental results and ablations on the PASCAL-VOC 2012 dataset show the importance of each component and highlight how their combination consistently improves object localization. Our source code is available at: https://github.com/rishavpramanik/maskedmultiqueryslot", "published": "2024-11-07 05:00:00", "id": "419ee598-f878-45b8-b1fc-03848706f427", "source": "arxiv", "section": "computerScience"}, {"title": "Multilingual Large Language Models and Curse of Multilinguality", "link": "https://arxiv.org/abs/2406.10602", "description": "arXiv:2406.10602v1 Announce Type: cross \nAbstract: Multilingual Large Language Models (LLMs) have gained large popularity among Natural Language Processing (NLP) researchers and practitioners. These models, trained on huge datasets, show proficiency across various languages and demonstrate effectiveness in numerous downstream tasks. This paper navigates the landscape of multilingual LLMs, providing an introductory overview of their technical aspects. It explains underlying architectures, objective functions, pre-training data sources, and tokenization methods. This work explores the unique features of different model types: encoder-only (mBERT, XLM-R), decoder-only (XGLM, PALM, BLOOM, GPT-3), and encoder-decoder models (mT5, mBART). Additionally, it addresses one of the significant limitations of multilingual LLMs - the curse of multilinguality - and discusses current attempts to overcome it.", "published": "2024-11-07 05:00:00", "id": "cacd96fa-20cb-4df8-9f08-240bb2ca7d3b", "source": "arxiv", "section": "computerScience"}, {"title": "Designing Robust Cyber-Defense Agents with Evolving Behavior Trees", "link": "https://arxiv.org/abs/2410.16383", "description": "arXiv:2410.16383v1 Announce Type: cross \nAbstract: Modern network defense can benefit from the use of autonomous systems, offloading tedious and time-consuming work to agents with standard and learning-enabled components. These agents, operating on critical network infrastructure, need to be robust and trustworthy to ensure defense against adaptive cyber-attackers and, simultaneously, provide explanations for their actions and network activity. However, learning-enabled components typically use models, such as deep neural networks, that are not transparent in their high-level decision-making leading to assurance challenges. Additionally, cyber-defense agents must execute complex long-term defense tasks in a reactive manner that involve coordination of multiple interdependent subtasks. Behavior trees are known to be successful in modelling interpretable, reactive, and modular agent policies with learning-enabled components. In this paper, we develop an approach to design autonomous cyber defense agents using behavior trees with learning-enabled components, which we refer to as Evolving Behavior Trees (EBTs). We learn the structure of an EBT with a novel abstract cyber environment and optimize learning-enabled components for deployment. The learning-enabled components are optimized for adapting to various cyber-attacks and deploying security mechanisms. The learned EBT structure is evaluated in a simulated cyber environment, where it effectively mitigates threats and enhances network visibility. For deployment, we develop a software architecture for evaluating EBT-based agents in computer network defense scenarios. Our results demonstrate that the EBT-based agent is robust to adaptive cyber-attacks and provides high-level explanations for interpreting its decisions and actions.", "published": "2024-11-07 05:00:00", "id": "1cf6364f-99aa-4dfb-8baf-7cea0f4bfd11", "source": "arxiv", "section": "computerScience"}, {"title": "log-RRIM: Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling", "link": "https://arxiv.org/abs/2411.03320", "description": "arXiv:2411.03320v1 Announce Type: cross \nAbstract: Accurate prediction of chemical reaction yields is crucial for optimizing organic synthesis, potentially reducing time and resources spent on experimentation. With the rise of artificial intelligence (AI), there is growing interest in leveraging AI-based methods to accelerate yield predictions without conducting in vitro experiments. We present log-RRIM, an innovative graph transformer-based framework designed for predicting chemical reaction yields. Our approach implements a unique local-to-global reaction representation learning strategy. This approach initially captures detailed molecule-level information and then models and aggregates intermolecular interactions, ensuring that the impact of varying-sizes molecular fragments on yield is accurately accounted for. Another key feature of log-RRIM is its integration of a cross-attention mechanism that focuses on the interplay between reagents and reaction centers. This design reflects a fundamental principle in chemical reactions: the crucial role of reagents in influencing bond-breaking and formation processes, which ultimately affect reaction yields. log-RRIM outperforms existing methods in our experiments, especially for medium to high-yielding reactions, proving its reliability as a predictor. Its advanced modeling of reactant-reagent interactions and sensitivity to small molecular fragments make it a valuable tool for reaction planning and optimization in chemical synthesis. The data and codes of log-RRIM are accessible through https://github.com/ninglab/Yield_log_RRIM.", "published": "2024-11-07 05:00:00", "id": "490fb217-a8a2-4446-8f30-990c9456b6a8", "source": "arxiv", "section": "computerScience"}, {"title": "Neural Network Prediction of Strong Lensing Systems with Domain Adaptation and Uncertainty Quantification", "link": "https://arxiv.org/abs/2411.03334", "description": "arXiv:2411.03334v1 Announce Type: cross \nAbstract: Modeling strong gravitational lenses is computationally expensive for the complex data from modern and next-generation cosmic surveys. Deep learning has emerged as a promising approach for finding lenses and predicting lensing parameters, such as the Einstein radius. Mean-variance Estimators (MVEs) are a common approach for obtaining aleatoric (data) uncertainties from a neural network prediction. However, neural networks have not been demonstrated to perform well on out-of-domain target data successfully - e.g., when trained on simulated data and applied to real, observational data. In this work, we perform the first study of the efficacy of MVEs in combination with unsupervised domain adaptation (UDA) on strong lensing data. The source domain data is noiseless, and the target domain data has noise mimicking modern cosmology surveys. We find that adding UDA to MVE increases the accuracy on the target data by a factor of about two over an MVE model without UDA. Including UDA also permits much more well-calibrated aleatoric uncertainty predictions. Advancements in this approach may enable future applications of MVE models to real observational data.", "published": "2024-11-07 05:00:00", "id": "9d854325-548c-4afa-a86c-b541fa6953b6", "source": "arxiv", "section": "computerScience"}, {"title": "Interpretable Embeddings for Segmentation-Free Single-Cell Analysis in Multiplex Imaging", "link": "https://arxiv.org/abs/2411.03341", "description": "arXiv:2411.03341v1 Announce Type: cross \nAbstract: Multiplex Imaging (MI) enables the simultaneous visualization of multiple biological markers in separate imaging channels at subcellular resolution, providing valuable insights into cell-type heterogeneity and spatial organization. However, current computational pipelines rely on cell segmentation algorithms, which require laborious fine-tuning and can introduce downstream errors due to inaccurate single-cell representations. We propose a segmentation-free deep learning approach that leverages grouped convolutions to learn interpretable embedded features from each imaging channel, enabling robust cell-type identification without manual feature selection. Validated on an Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma patients, our method enables the accurate identification of known cell types, showcasing its scalability and suitability for high-dimensional MI data.", "published": "2024-11-07 05:00:00", "id": "4409b3e6-5ea2-4afa-8f57-72a44f2666bb", "source": "arxiv", "section": "computerScience"}, {"title": "Solving stochastic partial differential equations using neural networks in the Wiener chaos expansion", "link": "https://arxiv.org/abs/2411.03384", "description": "arXiv:2411.03384v1 Announce Type: cross \nAbstract: In this paper, we solve stochastic partial differential equations (SPDEs) numerically by using (possibly random) neural networks in the truncated Wiener chaos expansion of their corresponding solution. Moreover, we provide some approximation rates for learning the solution of SPDEs with additive and/or multiplicative noise. Finally, we apply our results in numerical examples to approximate the solution of three SPDEs: the stochastic heat equation, the Heath-Jarrow-Morton equation, and the Zakai equation.", "published": "2024-11-07 05:00:00", "id": "1440724c-2c96-4170-8a95-25ab8a672e65", "source": "arxiv", "section": "computerScience"}, {"title": "Neurons for Neutrons: A Transformer Model for Computation Load Estimation on Domain-Decomposed Neutron Transport Problems", "link": "https://arxiv.org/abs/2411.03389", "description": "arXiv:2411.03389v1 Announce Type: cross \nAbstract: Domain decomposition is a technique used to reduce memory overhead on large neutron transport problems. Currently, the optimal load-balanced processor allocation for these domains is typically determined through small-scale simulations of the problem, which can be time-consuming for researchers and must be repeated anytime a problem input is changed. We propose a Transformer model with a unique 3D input embedding, and input representations designed for domain-decomposed neutron transport problems, which can predict the subdomain computation loads generated by small-scale simulations. We demonstrate that such a model trained on domain-decomposed Small Modular Reactor (SMR) simulations achieves 98.2% accuracy while being able to skip the small-scale simulation step entirely. Tests of the model's robustness on variant fuel assemblies, other problem geometries, and changes in simulation parameters are also discussed.", "published": "2024-11-07 05:00:00", "id": "3c9bc009-a9e1-4a75-82e3-9e0bd782d5aa", "source": "arxiv", "section": "computerScience"}, {"title": "Climate AI for Corporate Decarbonization Metrics Extraction", "link": "https://arxiv.org/abs/2411.03402", "description": "arXiv:2411.03402v1 Announce Type: cross \nAbstract: Corporate Greenhouse Gas (GHG) emission targets are important metrics in sustainable investing [12, 16]. To provide a comprehensive view of company emission objectives, we propose an approach to source these metrics from company public disclosures. Without automation, curating these metrics manually is a labor-intensive process that requires combing through lengthy corporate sustainability disclosures that often do not follow a standard format. Furthermore, the resulting dataset needs to be validated thoroughly by Subject Matter Experts (SMEs), further lengthening the time-to-market. We introduce the Climate Artificial Intelligence for Corporate Decarbonization Metrics Extraction (CAI) model and pipeline, a novel approach utilizing Large Language Models (LLMs) to extract and validate linked metrics from corporate disclosures. We demonstrate that the process improves data collection efficiency and accuracy by automating data curation, validation, and metric scoring from public corporate disclosures. We further show that our results are agnostic to the choice of LLMs. This framework can be applied broadly to information extraction from textual data.", "published": "2024-11-07 05:00:00", "id": "364e5f47-a38b-40dc-aad1-57c1b738cb66", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Entropic Constraints on Quantum Speedups", "link": "https://arxiv.org/abs/2411.03439", "description": "arXiv:2411.03439v1 Announce Type: cross \nAbstract: Some quantum algorithms have \"quantum speedups\": improved time complexity as compared with the best-known classical algorithms for solving the same tasks. Can we understand what fuels these speedups from an entropic perspective? Information theory gives us a multitude of metrics we might choose from to measure how fundamentally 'quantum' is the behavior of a quantum computer running an algorithm. The entanglement entropies for subsystems of a quantum state can be analyzed for subsystems of qubits in a quantum computer throughout the running of an algorithm. Here, a framework for making this entropic analysis is constructed, and performed on a selection of quantum circuits implementing known fast quantum algorithms and subroutines: Grover search, the quantum Fourier transform, and phase estimation. Our results are largely unsatisfactory: known entropy inequalities do not suffice to identify the presence or absence of quantum speedups. Although we know our algorithms must have quantum \"magic\", the Ingleton inequality, which holds for all entropies of subsystems of stabilizer states, is not violated in any of our examples. In some cases, however, monogamy of mutual information, which is obeyed for product states but violated for highly entangled bipartite states such as the $GHZ$ states, fails at some point in the course of our quantum circuits.", "published": "2024-11-07 05:00:00", "id": "9f2084e0-9c38-4637-a5ac-9892ff1e5099", "source": "arxiv", "section": "computerScience"}, {"title": "BOston Neonatal Brain Injury Data for Hypoxic Ischemic Encephalopathy (BONBID-HIE): II. 2-year Neurocognitive Outcome and NICU Outcome", "link": "https://arxiv.org/abs/2411.03456", "description": "arXiv:2411.03456v1 Announce Type: cross \nAbstract: Hypoxic Ischemic Encephalopathy (HIE) affects approximately 1-5/1000 newborns globally and leads to adverse neurocognitive outcomes in 30% to 50% of cases by two years of age. Despite therapeutic advances with Therapeutic Hypothermia (TH), prognosis remains challenging, highlighting the need for improved biomarkers. This paper introduces the second release of the Boston Neonatal Brain Injury Dataset for Hypoxic-Ischemic Encephalopathy (BONBID-HIE), an open-source, comprehensive MRI and clinical dataset featuring 237 patients, including NICU outcomes and 2-year neurocognitive outcomes from Massachusetts General Hospital and Boston Children's Hospital.", "published": "2024-11-07 05:00:00", "id": "4154ebfc-5d99-4d4b-9c76-37e10ba48e4b", "source": "arxiv", "section": "computerScience"}, {"title": "TopoTxR: A topology-guided deep convolutional network for breast parenchyma learning on DCE-MRIs", "link": "https://arxiv.org/abs/2411.03464", "description": "arXiv:2411.03464v1 Announce Type: cross \nAbstract: Characterization of breast parenchyma in dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is a challenging task owing to the complexity of underlying tissue structures. Existing quantitative approaches, like radiomics and deep learning models, lack explicit quantification of intricate and subtle parenchymal structures, including fibroglandular tissue. To address this, we propose a novel topological approach that explicitly extracts multi-scale topological structures to better approximate breast parenchymal structures, and then incorporates these structures into a deep-learning-based prediction model via an attention mechanism. Our topology-informed deep learning model, \\emph{TopoTxR}, leverages topology to provide enhanced insights into tissues critical for disease pathophysiology and treatment response. We empirically validate \\emph{TopoTxR} using the VICTRE phantom breast dataset, showing that the topological structures extracted by our model effectively approximate the breast parenchymal structures. We further demonstrate \\emph{TopoTxR}'s efficacy in predicting response to neoadjuvant chemotherapy. Our qualitative and quantitative analyses suggest differential topological behavior of breast tissue in treatment-na\\\"ive imaging, in patients who respond favorably to therapy as achieving pathological complete response (pCR) versus those who do not. In a comparative analysis with several baselines on the publicly available I-SPY 1 dataset (N=161, including 47 patients with pCR and 114 without) and the Rutgers proprietary dataset (N=120, with 69 patients achieving pCR and 51 not), \\emph{TopoTxR} demonstrates a notable improvement, achieving a 2.6\\% increase in accuracy and a 4.6\\% enhancement in AUC compared to the state-of-the-art method.", "published": "2024-11-07 05:00:00", "id": "c5ca2a26-03a9-4c6d-a378-a990c8d07d4b", "source": "arxiv", "section": "computerScience"}, {"title": "Automated, LLM enabled extraction of synthesis details for reticular materials from scientific literature", "link": "https://arxiv.org/abs/2411.03484", "description": "arXiv:2411.03484v1 Announce Type: cross \nAbstract: Automated knowledge extraction from scientific literature can potentially accelerate materials discovery. We have investigated an approach for extracting synthesis protocols for reticular materials from scientific literature using large language models (LLMs). To that end, we introduce a Knowledge Extraction Pipeline (KEP) that automatizes LLM-assisted paragraph classification and information extraction. By applying prompt engineering with in-context learning (ICL) to a set of open-source LLMs, we demonstrate that LLMs can retrieve chemical information from PDF documents, without the need for fine-tuning or training and at a reduced risk of hallucination. By comparing the performance of five open-source families of LLMs in both paragraph classification and information extraction tasks, we observe excellent model performance even if only few example paragraphs are included in the ICL prompts. The results show the potential of the KEP approach for reducing human annotations and data curation efforts in automated scientific knowledge extraction.", "published": "2024-11-07 05:00:00", "id": "04546440-bdea-4798-9864-f2630ec53bd6", "source": "arxiv", "section": "computerScience"}, {"title": "Forecasting Outside the Box: Application-Driven Optimal Pointwise Forecasts for Stochastic Optimization", "link": "https://arxiv.org/abs/2411.03520", "description": "arXiv:2411.03520v1 Announce Type: cross \nAbstract: The exponential growth in data availability in recent years has led to new formulations of data-driven optimization problems. One such formulation is that of stochastic optimization problems with contextual information, where the goal is to optimize the expected value of a certain function given some contextual information (also called features) that accompany the main data of interest. The contextual information then allows for a better estimation of the quantity of interest via machine learning methods, thereby leading to better solutions. Oftentimes, however, machine learning methods yield just a pointwise estimate instead of an entire distribution. In this paper we show that, when the problem to be solved is a class of two-stage stochastic programs (namely, those with fixed recourse matrix and fixed costs), under mild assumptions the problem can be solved with just one scenario. While such a scenario - which does not have be unique - is usually unknown, we present an integrated learning and optimization procedure that yields the best approximation of that scenario within the modeler's pre-specified set of parameterized forecast functions. Numerical results conducted with inventory problems from the literature (with synthetic data) as well as a bike-sharing problem with real data demonstrate that the proposed approach performs well when compared to benchmark methods from the literature.", "published": "2024-11-07 05:00:00", "id": "775225c4-2c86-45e3-bd77-b8f10ed97d03", "source": "arxiv", "section": "computerScience"}, {"title": "Exploring the Potentials and Challenges of Using Large Language Models for the Analysis of Transcriptional Regulation of Long Non-coding RNAs", "link": "https://arxiv.org/abs/2411.03522", "description": "arXiv:2411.03522v1 Announce Type: cross \nAbstract: Research on long non-coding RNAs (lncRNAs) has garnered significant attention due to their critical roles in gene regulation and disease mechanisms. However, the complexity and diversity of lncRNA sequences, along with the limited knowledge of their functional mechanisms and the regulation of their expressions, pose significant challenges to lncRNA studies. Given the tremendous success of large language models (LLMs) in capturing complex dependencies in sequential data, this study aims to systematically explore the potential and limitations of LLMs in the sequence analysis related to the transcriptional regulation of lncRNA genes. Our extensive experiments demonstrated promising performance of fine-tuned genome foundation models on progressively complex tasks. Furthermore, we conducted an insightful analysis of the critical impact of task complexity, model selection, data quality, and biological interpretability for the studies of the regulation of lncRNA gene expression.", "published": "2024-11-07 05:00:00", "id": "0e9665a0-740c-4671-a6c0-40ba79bbecca", "source": "arxiv", "section": "computerScience"}, {"title": "Improving precision of A/B experiments using trigger intensity", "link": "https://arxiv.org/abs/2411.03530", "description": "arXiv:2411.03530v1 Announce Type: cross \nAbstract: In industry, online randomized controlled experiment (a.k.a A/B experiment) is a standard approach to measure the impact of a causal change. These experiments have small treatment effect to reduce the potential blast radius. As a result, these experiments often lack statistical significance due to low signal-to-noise ratio. To improve the precision (or reduce standard error), we introduce the idea of trigger observations where the output of the treatment and the control model are different. We show that the evaluation with full information about trigger observations (full knowledge) improves the precision in comparison to a baseline method. However, detecting all such trigger observations is a costly affair, hence we propose a sampling based evaluation method (partial knowledge) to reduce the cost. The randomness of sampling introduces bias in the estimated outcome. We theoretically analyze this bias and show that the bias is inversely proportional to the number of observations used for sampling. We also compare the proposed evaluation methods using simulation and empirical data. In simulation, evaluation with full knowledge reduces the standard error as much as 85%. In empirical setup, evaluation with partial knowledge reduces the standard error by 36.48%.", "published": "2024-11-07 05:00:00", "id": "1fbc59c6-fcba-4a3b-8bbc-70bcc5209324", "source": "arxiv", "section": "computerScience"}, {"title": "The Differentiable Feasibility Pump", "link": "https://arxiv.org/abs/2411.03535", "description": "arXiv:2411.03535v1 Announce Type: cross \nAbstract: Although nearly 20 years have passed since its conception, the feasibility pump algorithm remains a widely used heuristic to find feasible primal solutions to mixed-integer linear problems. Many extensions of the initial algorithm have been proposed. Yet, its core algorithm remains centered around two key steps: solving the linear relaxation of the original problem to obtain a solution that respects the constraints, and rounding it to obtain an integer solution. This paper shows that the traditional feasibility pump and many of its follow-ups can be seen as gradient-descent algorithms with specific parameters. A central aspect of this reinterpretation is observing that the traditional algorithm differentiates the solution of the linear relaxation with respect to its cost. This reinterpretation opens many opportunities for improving the performance of the original algorithm. We study how to modify the gradient-update step as well as extending its loss function. We perform extensive experiments on MIPLIB instances and show that these modifications can substantially reduce the number of iterations needed to find a solution.", "published": "2024-11-07 05:00:00", "id": "3f5ab43d-571b-45b0-b085-7e6a5ad2b469", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via Controllable Image Generation", "link": "https://arxiv.org/abs/2411.03551", "description": "arXiv:2411.03551v1 Announce Type: cross \nAbstract: Fibrotic Lung Disease (FLD) is a severe condition marked by lung stiffening and scarring, leading to respiratory decline. High-resolution computed tomography (HRCT) is critical for diagnosing and monitoring FLD; however, fibrosis appears as irregular, diffuse patterns with unclear boundaries, leading to high inter-observer variability and time-intensive manual annotation. To tackle this challenge, we propose DiffSeg, a novel weakly supervised semantic segmentation (WSSS) method that uses image-level annotations to generate pixel-level fibrosis segmentation, reducing the need for fine-grained manual labeling. Additionally, our DiffSeg incorporates a diffusion-based generative model to synthesize HRCT images with different levels of fibrosis from healthy slices, enabling the generation of the fibrosis-injected slices and their paired fibrosis location. Experiments indicate that our method significantly improves the accuracy of pseudo masks generated by existing WSSS methods, greatly reducing the complexity of manual labeling and enhancing the consistency of the generated masks.", "published": "2024-11-07 05:00:00", "id": "6c709931-554d-45ca-ac4b-372feb8c5257", "source": "arxiv", "section": "computerScience"}, {"title": "Structure-preserving quantum algorithms for linear and nonlinear Hamiltonian systems", "link": "https://arxiv.org/abs/2411.03599", "description": "arXiv:2411.03599v1 Announce Type: cross \nAbstract: Hamiltonian systems of ordinary and partial differential equations are fundamental across modern science and engineering, appearing in models that span virtually all physical scales. A critical property for the robustness and stability of computational methods in such systems is the symplectic structure, which preserves geometric properties like phase-space volume over time and energy conservation over an extended period. In this paper, we present quantum algorithms that incorporate symplectic integrators, ensuring the preservation of this key structure. We demonstrate how these algorithms maintain the symplectic properties for both linear and nonlinear Hamiltonian systems. Additionally, we provide a comprehensive theoretical analysis of the computational complexity, showing that our approach offers both accuracy and improved efficiency over classical algorithms. These results highlight the potential application of quantum algorithms for solving large-scale Hamiltonian systems while preserving essential physical properties.", "published": "2024-11-07 05:00:00", "id": "de1785e5-fe39-4636-a3f4-3dd0483fda56", "source": "arxiv", "section": "computerScience"}, {"title": "One-dimensional cellular automata with a unique active transition", "link": "https://arxiv.org/abs/2411.03601", "description": "arXiv:2411.03601v1 Announce Type: cross \nAbstract: A one-dimensional cellular automaton $\\tau : A^\\mathbb{Z} \\to A^\\mathbb{Z}$ is a transformation of the full shift defined via a finite neighborhood $S \\subset \\mathbb{Z}$ and a local function $\\mu : A^S \\to A$. We study the family of cellular automata whose finite neighborhood $S$ is an interval containing $0$, and there exists a pattern $p \\in A^S$ satisfying that $\\mu(z) = z(0)$ if and only if $z \\neq p$; this means that these cellular automata have a unique \\emph{active transition}. Despite its simplicity, this family presents interesting and subtle problems, as the behavior of the cellular automaton completely depends on the structure of $p$. We show that every cellular automaton $\\tau$ with a unique active transition $p \\in A^S$ is either idempotent or strictly almost equicontinuous, and we completely characterize each one of these situations in terms of $p$. In essence, the idempotence of $\\tau$ depends on the existence of a certain subpattern of $p$ with a translational symmetry.", "published": "2024-11-07 05:00:00", "id": "70afdd12-c733-4a5b-8590-419c86cbeb09", "source": "arxiv", "section": "computerScience"}, {"title": "Designing a Linearized Potential Function in Neural Network Optimization Using Csisz\\'{a}r Type of Tsallis Entropy", "link": "https://arxiv.org/abs/2411.03611", "description": "arXiv:2411.03611v1 Announce Type: cross \nAbstract: In recent years, learning for neural networks can be viewed as optimization in the space of probability measures. To obtain the exponential convergence to the optimizer, the regularizing term based on Shannon entropy plays an important role. Even though an entropy function heavily affects convergence results, there is almost no result on its generalization, because of the following two technical difficulties: one is the lack of sufficient condition for generalized logarithmic Sobolev inequality, and the other is the distributional dependence of the potential function within the gradient flow equation. In this paper, we establish a framework that utilizes a linearized potential function via Csisz\\'{a}r type of Tsallis entropy, which is one of the generalized entropies. We also show that our new framework enable us to derive an exponential convergence result.", "published": "2024-11-07 05:00:00", "id": "ce255510-5230-4b15-b2f7-067f70802cc5", "source": "arxiv", "section": "computerScience"}, {"title": "ADMIRE: a locally adaptive single-image, non-uniformity correction and denoising algorithm: application to uncooled IR camera", "link": "https://arxiv.org/abs/2411.03615", "description": "arXiv:2411.03615v1 Announce Type: cross \nAbstract: We propose a new way to correct for the non-uniformity (NU) and the noise in uncooled infrared-type images. This method works on static images, needs no registration, no camera motion and no model for the non uniformity. The proposed method uses an hybrid scheme including an automatic locally-adaptive contrast adjustment and a state-of-the-art image denoising method. It permits to correct for a fully non-linear NU and the noise efficiently using only one image. We compared it with total variation on real raw and simulated NU infrared images. The strength of this approach lies in its simplicity, low computational cost. It needs no test-pattern or calibration and produces no \"ghost-artefact\".", "published": "2024-11-07 05:00:00", "id": "ab655a19-d18f-47e7-893e-ebb219e3e01e", "source": "arxiv", "section": "computerScience"}, {"title": "Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification", "link": "https://arxiv.org/abs/2411.03618", "description": "arXiv:2411.03618v1 Announce Type: cross \nAbstract: Diabetic Retinopathy (DR) is a primary cause of blindness, necessitating early detection and diagnosis. This paper focuses on referable DR classification to enhance the applicability of the proposed method in clinical practice. We develop an advanced cross-learning DR classification method leveraging transfer learning and cross-attention mechanisms. The proposed method employs the Swin U-Net architecture to segment lesion maps from DR fundus images. The Swin U-Net segmentation model, enriched with DR lesion insights, is transferred to generate a lesion map. Both the fundus image and its segmented lesion map are used as complementary inputs for the classification model. A cross-attention mechanism is deployed to improve the model's ability to capture fine-grained details from the input pairs. Our experiments, utilizing two public datasets, FGADR and EyePACS, demonstrate a superior accuracy of 94.6%, surpassing current state-of-the-art methods by 4.4%. To this end, we aim for the proposed method to be seamlessly integrated into clinical workflows, enhancing accuracy and efficiency in identifying referable DR.", "published": "2024-11-07 05:00:00", "id": "f46fadb6-a960-436c-8431-7f8acb1ae377", "source": "arxiv", "section": "computerScience"}, {"title": "A Subsampling Based Neural Network for Spatial Data", "link": "https://arxiv.org/abs/2411.03620", "description": "arXiv:2411.03620v1 Announce Type: cross \nAbstract: The application of deep neural networks in geospatial data has become a trending research problem in the present day. A significant amount of statistical research has already been introduced, such as generalized least square optimization by incorporating spatial variance-covariance matrix, considering basis functions in the input nodes of the neural networks, and so on. However, for lattice data, there is no available literature about the utilization of asymptotic analysis of neural networks in regression for spatial data. This article proposes a consistent localized two-layer deep neural network-based regression for spatial data. We have proved the consistency of this deep neural network for bounded and unbounded spatial domains under a fixed sampling design of mixed-increasing spatial regions. We have proved that its asymptotic convergence rate is faster than that of \\cite{zhan2024neural}'s neural network and an improved generalization of \\cite{shen2023asymptotic}'s neural network structure. We empirically observe the rate of convergence of discrepancy measures between the empirical probability distribution of observed and predicted data, which will become faster for a less smooth spatial surface. We have applied our asymptotic analysis of deep neural networks to the estimation of the monthly average temperature of major cities in the USA from its satellite image. This application is an effective showcase of non-linear spatial regression. We demonstrate our methodology with simulated lattice data in various scenarios.", "published": "2024-11-07 05:00:00", "id": "5cedbe6c-3d87-4993-8802-fe6f9ebfe13b", "source": "arxiv", "section": "computerScience"}, {"title": "Quantum fault tolerance with constant-space and logarithmic-time overheads", "link": "https://arxiv.org/abs/2411.03632", "description": "arXiv:2411.03632v1 Announce Type: cross \nAbstract: In a model of fault-tolerant quantum computation with quick and noiseless polyloglog-time auxiliary classical computation, we construct a fault tolerance protocol with constant-space and $\\widetilde{O}(\\log N)$-time overhead, where $\\widetilde{O}(\\cdot)$ hides sub-polylog factors. Our construction utilizes constant-rate quantum locally testable codes (qLTC), new fault-tolerant gadgets on qLTCs and qLDPC codes, and a new analysis framework. In particular, 1) we develop a new simple and self-contained construction of magic state distillation for qubits using qudit quantum Reed-Solomon codes with $(\\log \\frac{1}{\\varepsilon})^{\\gamma}$ spacetime overhead, where $\\gamma \\rightarrow 0$. 2) We prove that the recent family of almost-good qLTCs of Dinur-Lin-Vidick admit parallel single-shot decoders against adversarial errors of weight scaling with the code distance. 3) We develop logical state preparation and logical gate procedures with $\\widetilde{O}(1)$-spacetime overhead on qLTCs. 4) To combine these ingredients, we introduce a new framework of fault tolerance analysis called the weight enumerator formalism. The framework permits easy formal composition of fault-tolerant gadgets, so we expect it to be of independent interest. Our work gives the lowest spacetime overhead to date, which, for the first time, matches that of classical fault tolerance up to sub-polylog factors. We conjecture this is optimal up to sub-polylog factors.", "published": "2024-11-07 05:00:00", "id": "920f8a00-07d6-41a1-81e8-f588f2bdf6b0", "source": "arxiv", "section": "computerScience"}, {"title": "Hierarchical Self-Organization in Fixed-Magnetization Particle Systems", "link": "https://arxiv.org/abs/2411.03643", "description": "arXiv:2411.03643v1 Announce Type: cross \nAbstract: Hierarchical sorting is a fundamental task for programmable matter, inspired by the spontaneous formation of interfaces and membranes in nature. The task entails particles of different types, present in fixed densities, sorting into corresponding regions of a space that are themselves organized. By analyzing the Gibbs distribution of a general fixed-magnetization model of equilibrium statistical mechanics, we prove that particles moving stochastically according to local affinities solve the hierarchical sorting task. The analysis of fixed-magnetization models is notoriously difficult, and approaches that have led to recent breakthroughs in sampling the low-temperature regime only work in the variable-magnetization setting by default. To overcome this barrier, we introduce a new approach for comparing the partition functions of fixed- and variable-magnetization models. The core technique identifies a special class of configurations that contribute comparably to the two partition functions, which then serves as a bridge between the fixed- and variable-magnetization settings. Our main result is an estimate of the Gibbs distribution that unifies existing and new results for models at fixed magnetization, including the Ising, Potts, and Blume--Capel models, and leads to stochastic distributed algorithms for hierarchical sorting and other self-organizing tasks, like compression and separation.", "published": "2024-11-07 05:00:00", "id": "a064cb1f-f3f1-4dc9-a3c9-7dc2e8478c72", "source": "arxiv", "section": "computerScience"}, {"title": "Quantum LDPC Codes of Almost Linear Distance via Homological Products", "link": "https://arxiv.org/abs/2411.03646", "description": "arXiv:2411.03646v1 Announce Type: cross \nAbstract: We present new constructions of quantum codes of linear or close-to-linear distance and dimension with low-weight stabilizers. Only a few constructions of such codes were previously known, and were primarily based on a specific operation from homological algebra, namely the balanced product. In contrast, our constructions are based on a more basic and widely used product, namely the homological product (i.e. the tensor product of chain complexes). Our results help address the natural question: When do homological products preserve good code distance?\n  Our first main result constructs asymptotically good $[[N,\\Theta(N),\\Theta(N)]]$ quantum codes with small polynomial stabilizer weight from homological products of codes with a property called product-expansion. This notion was recently introduced and used to bound the distance of balanced product quantum codes; we apply it instead to homological products.\n  For every $\\epsilon>0$, our second main result constructs close-to-linear distance $[[N,N^{1-\\epsilon},N^{1-\\epsilon}]]$ (subsystem) quantum LDPC codes with constant stabilizer weight from iterated homological products of a constant-sized quantum locally testable code. The key insight here is that by using subsystem codes (but still with constant-weight stabilizers), we can circumvent a particular obstruction that limited the distance of many prior product code constructions to at most $\\tilde{O}(\\sqrt{N})$.", "published": "2024-11-07 05:00:00", "id": "af8cbfd1-10e4-430e-a567-d89f7ee654f3", "source": "arxiv", "section": "computerScience"}, {"title": "Complexity Theory for Quantum Promise Problems", "link": "https://arxiv.org/abs/2411.03716", "description": "arXiv:2411.03716v1 Announce Type: cross \nAbstract: Quantum computing introduces many problems rooted in physics, asking to compute information from input quantum states. Determining the complexity of these problems has implications for both computer science and physics. However, as existing complexity theory primarily addresses problems with classical inputs and outputs, it lacks the framework to fully capture the complexity of quantum-input problems. This gap is relevant when studying the relationship between quantum cryptography and complexity theory, especially within Impagliazzo's five worlds framework, as characterizing the security of quantum cryptographic primitives requires complexity classes for problems involving quantum inputs. To bridge this gap, we examine the complexity theory of quantum promise problems, which determine if input quantum states have certain properties. We focus on complexity classes p/mBQP, p/mQ(C)MA, $\\mathrm{p/mQSZK_{hv}}$, p/mQIP, and p/mPSPACE, where \"p/mC\" denotes classes with pure (p) or mixed (m) states corresponding to any classical class C. We establish structural results, including complete problems, search-to-decision reductions, and relationships between classes. Notably, our findings reveal differences from classical counterparts, such as p/mQIP $\\neq$ p/mPSPACE and $\\mathrm{mcoQSZK_{hv}} \\neq \\mathrm{mQSZK_{hv}}$. As an application, we apply this framework to cryptography, showing that breaking one-way state generators, pseudorandom states, and EFI is bounded by mQCMA or $\\mathrm{mQSZK_{hv}}$. We also show that the average-case hardness of $\\mathrm{pQCZK_{hv}}$ implies the existence of EFI. These results provide new insights into Impagliazzo's worlds, establishing a connection between quantum cryptography and quantum promise complexity theory. We also extend our findings to quantum property testing and unitary synthesis, highlighting further applications of this new framework.", "published": "2024-11-07 05:00:00", "id": "59fc9936-12de-4b1d-9452-46a45b159570", "source": "arxiv", "section": "computerScience"}, {"title": "Zero-shot Dynamic MRI Reconstruction with Global-to-local Diffusion Model", "link": "https://arxiv.org/abs/2411.03723", "description": "arXiv:2411.03723v1 Announce Type: cross \nAbstract: Diffusion models have recently demonstrated considerable advancement in the generation and reconstruction of magnetic resonance imaging (MRI) data. These models exhibit great potential in handling unsampled data and reducing noise, highlighting their promise as generative models. However, their application in dynamic MRI remains relatively underexplored. This is primarily due to the substantial amount of fully-sampled data typically required for training, which is difficult to obtain in dynamic MRI due to its spatio-temporal complexity and high acquisition costs. To address this challenge, we propose a dynamic MRI reconstruction method based on a time-interleaved acquisition scheme, termed the Glob-al-to-local Diffusion Model. Specifically, fully encoded full-resolution reference data are constructed by merging under-sampled k-space data from adjacent time frames, generating two distinct bulk training datasets for global and local models. The global-to-local diffusion framework alternately optimizes global information and local image details, enabling zero-shot reconstruction. Extensive experiments demonstrate that the proposed method performs well in terms of noise reduction and detail preservation, achieving reconstruction quality comparable to that of supervised approaches.", "published": "2024-11-07 05:00:00", "id": "9cbd60ac-bf46-47f9-aa09-18a891370348", "source": "arxiv", "section": "computerScience"}, {"title": "Fatigue performance of prosthetic screws used in dental implant restorations: Rolled versus cut threads", "link": "https://arxiv.org/abs/2411.03733", "description": "arXiv:2411.03733v1 Announce Type: cross \nAbstract: Statement of problem. Cold rolling is widely used for screw thread manufacturing in industry but is less common in implant dentistry, where cutting is the preferred manufacturing method. Purpose. The purpose of this in vitro study was to compare the surface finish and mechanical performance of a specific model of prosthetic screw used for direct restorations manufactured by thread rolling and cutting. Material and methods. The thread profiles were measured in an optical measuring machine, the residual stresses in an X-ray diffractometer, the surface finish in a scanning electron microscope, and then fatigue and static load tests were carried out in a direct stress test bench according to the International Organization for Standardization (ISO) 14801. Finally, linear regression models and 95% interval confidence bands were calculated and compared through ANCOVA for fatigue tests while the t test was used for statistical comparisons (a=.05). Results. The surface finish was smoother, and compressive residual stresses were higher for the roll-threaded screws. Linear regression models showed a fatigue life 9 times higher for roll-threaded screws (P=1) without affecting static behavior, which showed statistically similar static strengths (P=.54). However, the thread profile in the roll-threaded screws was not accurately reproduced, but this should be easily corrected in future prototypes. Conclusions. Rolling was demonstrated to be a better thread-manufacturing process for prosthetic screws, producing improved surface quality and fatigue behavior.", "published": "2024-11-07 05:00:00", "id": "d6ef1ad7-4a4e-4630-aab8-e7b10be8623e", "source": "arxiv", "section": "computerScience"}, {"title": "Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction", "link": "https://arxiv.org/abs/2411.03758", "description": "arXiv:2411.03758v1 Announce Type: cross \nAbstract: Diffusion model-based approaches recently achieved re-markable success in MRI reconstruction, but integration into clinical routine remains challenging due to its time-consuming convergence. This phenomenon is partic-ularly notable when directly apply conventional diffusion process to k-space data without considering the inherent properties of k-space sampling, limiting k-space learning efficiency and image reconstruction quality. To tackle these challenges, we introduce subspace diffusion model with orthogonal decomposition, a method (referred to as Sub-DM) that restrict the diffusion process via projections onto subspace as the k-space data distribution evolves toward noise. Particularly, the subspace diffusion model circumvents the inference challenges posed by the com-plex and high-dimensional characteristics of k-space data, so the highly compact subspace ensures that diffusion process requires only a few simple iterations to produce accurate prior information. Furthermore, the orthogonal decomposition strategy based on wavelet transform hin-ders the information loss during the migration of the vanilla diffusion process to the subspace. Considering the strate-gy is approximately reversible, such that the entire pro-cess can be reversed. As a result, it allows the diffusion processes in different spaces to refine models through a mutual feedback mechanism, enabling the learning of ac-curate prior even when dealing with complex k-space data. Comprehensive experiments on different datasets clearly demonstrate that the superiority of Sub-DM against state of-the-art methods in terms of reconstruction speed and quality.", "published": "2024-11-07 05:00:00", "id": "613e7920-24be-4ab4-ad4b-4df300488a2a", "source": "arxiv", "section": "computerScience"}, {"title": "On the satisfiability of random $3$-SAT formulas with $k$-wise independent clauses", "link": "https://arxiv.org/abs/2411.03813", "description": "arXiv:2411.03813v1 Announce Type: cross \nAbstract: The problem of identifying the satisfiability threshold of random $3$-SAT formulas has received a lot of attention during the last decades and has inspired the study of other threshold phenomena in random combinatorial structures. The classical assumption in this line of research is that, for a given set of $n$ Boolean variables, each clause is drawn uniformly at random among all sets of three literals from these variables, independently from other clauses. Here, we keep the uniform distribution of each clause, but deviate significantly from the independence assumption and consider richer families of probability distributions. For integer parameters $n$, $m$, and $k$, we denote by $\\DistFamily_k(n,m)$ the family of probability distributions that produce formulas with $m$ clauses, each selected uniformly at random from all sets of three literals from the $n$ variables, so that the clauses are $k$-wise independent. Our aim is to make general statements about the satisfiability or unsatisfiability of formulas produced by distributions in $\\DistFamily_k(n,m)$ for different values of the parameters $n$, $m$, and $k$.", "published": "2024-11-07 05:00:00", "id": "dcb8b322-fc99-46f9-8d4e-deb38049b261", "source": "arxiv", "section": "computerScience"}, {"title": "Interacting Monoidal Structures with Applications in Computing", "link": "https://arxiv.org/abs/2411.03821", "description": "arXiv:2411.03821v1 Announce Type: cross \nAbstract: With a view on applications in computing, in particular concurrency theory and higher-dimensional rewriting, we develop notions of $n$-fold monoid and comonoid objects in $n$-fold monoidal categories and bicategories. We present a series of examples for these structures from various domains, including a categorical model for a communication protocol and a lax $n$-fold relational monoid, which has previously been used implicitly for higher-dimensional rewriting and which specialises in a natural way to strict $n$-categories. A special set of examples is built around modules and algebras of the boolean semiring, which allows us to deal with semilattices, additively idempotent semirings and quantales using tools from classical algebra.", "published": "2024-11-07 05:00:00", "id": "7a9c785f-7d76-421a-b8d8-f5e2f84a7eb4", "source": "arxiv", "section": "computerScience"}, {"title": "Steady State Blended Gas Flow on Networks: Existence and Uniqueness of Solutions", "link": "https://arxiv.org/abs/2411.03841", "description": "arXiv:2411.03841v1 Announce Type: cross \nAbstract: We prove an existence result for the steady state flow of gas mixtures on networks. The basis of the model are the physical principles of the isothermal Euler equation, coupling conditions for the flow and pressure, and the mixing of incoming flow at nodes. The state equation is based on a convex combination of the ideal gas equations of state for natural gas and hydrogen. We analyze mathematical properties of the model allowing us to prove the existence of solutions in particular for tree-shaped networks and networks with exactly one cycle. Numerical examples illustrate the results and explore the applicability of our approach to different network topologies.", "published": "2024-11-07 05:00:00", "id": "a6ab918e-dff8-4bcc-b17c-d2f66e4734bb", "source": "arxiv", "section": "computerScience"}, {"title": "On a probabilistic global optimizer derived from the Walker slice sampling", "link": "https://arxiv.org/abs/2411.03851", "description": "arXiv:2411.03851v1 Announce Type: cross \nAbstract: This article presents a zeroth order probabilistic global optimization algorithm -- SwiftNav -- for (not necessarily convex) functions over a compact domain. A discretization procedure is deployed on the compact domain, starting with a small step-size $h > 0$ and subsequently adaptively refining it in the course of a simulated annealing routine utilizing the Walker slice and the Gibbs sampler, in order to identify a set of global optimizers up to good precision. SwiftNav is parallelizable, which helps with scalability as the dimension of decision variables increases. Several numerical experiments are included here to demonstrate the effectiveness and accuracy of SwiftNav in high-dimensional benchmark optimization problems.", "published": "2024-11-07 05:00:00", "id": "81610cbd-01af-4a1b-86db-4af1f9c1fc2e", "source": "arxiv", "section": "computerScience"}, {"title": "A Causal Framework for Precision Rehabilitation", "link": "https://arxiv.org/abs/2411.03919", "description": "arXiv:2411.03919v1 Announce Type: cross \nAbstract: Precision rehabilitation offers the promise of an evidence-based approach for optimizing individual rehabilitation to improve long-term functional outcomes. Emerging techniques, including those driven by artificial intelligence, are rapidly expanding our ability to quantify the different domains of function during rehabilitation, other encounters with healthcare, and in the community. While this seems poised to usher rehabilitation into the era of big data and should be a powerful driver of precision rehabilitation, our field lacks a coherent framework to utilize these data and deliver on this promise. We propose a framework that builds upon multiple existing pillars to fill this gap. Our framework aims to identify the Optimal Dynamic Treatment Regimens (ODTR), or the decision-making strategy that takes in the range of available measurements and biomarkers to identify interventions likely to maximize long-term function. This is achieved by designing and fitting causal models, which extend the Computational Neurorehabilitation framework using tools from causal inference. These causal models can learn from heterogeneous data from different silos, which must include detailed documentation of interventions, such as using the Rehabilitation Treatment Specification System. The models then serve as digital twins of patient recovery trajectories, which can be used to learn the ODTR. Our causal modeling framework also emphasizes quantitatively linking changes across levels of the functioning to ensure that interventions can be precisely selected based on careful measurement of impairments while also being selected to maximize outcomes that are meaningful to patients and stakeholders. We believe this approach can provide a unifying framework to leverage growing big rehabilitation data and AI-powered measurements to produce precision rehabilitation treatments that can improve clinical outcomes.", "published": "2024-11-07 05:00:00", "id": "dd4e326f-dc20-4e47-8e7b-3a89825b422c", "source": "arxiv", "section": "computerScience"}, {"title": "Improved Regret of Linear Ensemble Sampling", "link": "https://arxiv.org/abs/2411.03932", "description": "arXiv:2411.03932v1 Announce Type: cross \nAbstract: In this work, we close the fundamental gap of theory and practice by providing an improved regret bound for linear ensemble sampling. We prove that with an ensemble size logarithmic in $T$, linear ensemble sampling can achieve a frequentist regret bound of $\\tilde{\\mathcal{O}}(d^{3/2}\\sqrt{T})$, matching state-of-the-art results for randomized linear bandit algorithms, where $d$ and $T$ are the dimension of the parameter and the time horizon respectively. Our approach introduces a general regret analysis framework for linear bandit algorithms. Additionally, we reveal a significant relationship between linear ensemble sampling and Linear Perturbed-History Exploration (LinPHE), showing that LinPHE is a special case of linear ensemble sampling when the ensemble size equals $T$. This insight allows us to derive a new regret bound of $\\tilde{\\mathcal{O}}(d^{3/2}\\sqrt{T})$ for LinPHE, independent of the number of arms. Our contributions advance the theoretical foundation of ensemble sampling, bringing its regret bounds in line with the best known bounds for other randomized exploration algorithms.", "published": "2024-11-07 05:00:00", "id": "7554db32-7d1f-4b9d-bdcf-15658772bf71", "source": "arxiv", "section": "computerScience"}, {"title": "Large Deviations Inequalities for Unequal Probability Sampling Without Replacement", "link": "https://arxiv.org/abs/2411.03955", "description": "arXiv:2411.03955v1 Announce Type: cross \nAbstract: We provide bounds on the tail probabilities for simple procedures that generate random samples _without replacement_, when the probabilities of being selected need not be equal.", "published": "2024-11-07 05:00:00", "id": "9c028810-80b7-436b-afce-58579b373b2c", "source": "arxiv", "section": "computerScience"}, {"title": "Bayesian algorithmic perfumery: A Hierarchical Relevance Vector Machine for the Estimation of Personalized Fragrance Preferences based on Three Sensory Layers and Jungian Personality Archetypes", "link": "https://arxiv.org/abs/2411.03965", "description": "arXiv:2411.03965v1 Announce Type: cross \nAbstract: This study explores a Bayesian algorithmic approach to personalized fragrance recommendation by integrating hierarchical Relevance Vector Machines (RVM) and Jungian personality archetypes. The paper proposes a structured model that links individual scent preferences for top, middle, and base notes to personality traits derived from Jungian archetypes, such as the Hero, Caregiver, and Explorer, among others. The algorithm utilizes Bayesian updating to dynamically refine predictions as users interact with each fragrance note. This iterative process allows for the personalization of fragrance experiences based on prior data and personality assessments, leading to adaptive and interpretable recommendations. By combining psychological theory with Bayesian machine learning, this approach addresses the complexity of modeling individual preferences while capturing user-specific and population-level trends. The study highlights the potential of hierarchical Bayesian frameworks in creating customized olfactory experiences, informed by psychological and demographic factors, contributing to advancements in personalized product design and machine learning applications in sensory-based industries.", "published": "2024-11-07 05:00:00", "id": "9ab1e005-cf3b-42f1-a05b-aadb677035f8", "source": "arxiv", "section": "computerScience"}, {"title": "Toward end-to-end quantum simulation for protein dynamics", "link": "https://arxiv.org/abs/2411.03972", "description": "arXiv:2411.03972v1 Announce Type: cross \nAbstract: Modeling and simulating the protein folding process overall remains a grand challenge in computational biology. We systematically investigate end-to-end quantum algorithms for simulating various protein dynamics with effects, such as mechanical forces or stochastic noises. We offer efficient quantum simulation algorithms to produce quantum encoding of the final states, history states, or density matrices of inhomogeneous or stochastic harmonic oscillator models. For the read-in setting, we design (i) efficient quantum algorithms for initial state preparation, utilizing counter-based random number generator and rejection sampling, and (ii) depth-efficient approaches for molecular structure loading. Both are particularly important in handling large protein molecules. For the read-out setting, our algorithms estimate various classical observables, such as energy, low vibration modes, density of states, correlation of displacement, and optimal control of molecular dynamics. We also show classical numerical experiments focused on estimating the density of states and applying the optimal control to facilitate conformation changes to verify our arguments on potential quantum speedups. Overall, our study demonstrates that the quantum simulation of protein dynamics can be a solid end-to-end application in the era of early or fully fault-tolerant quantum computing.", "published": "2024-11-07 05:00:00", "id": "67912823-2653-4734-a426-371100ce2ef9", "source": "arxiv", "section": "computerScience"}, {"title": "Tensor train solution to uncertain optimization problems with shared sparsity penalty", "link": "https://arxiv.org/abs/2411.03989", "description": "arXiv:2411.03989v1 Announce Type: cross \nAbstract: We develop both first and second order numerical optimization methods to solve non-smooth optimization problems featuring a shared sparsity penalty, constrained by differential equations with uncertainty. To alleviate the curse of dimensionality we use tensor product approximations. To handle the non-smoothness of the objective function we introduce a smoothed version of the shared sparsity objective. We consider both a benchmark elliptic PDE constraint, and a more realistic topology optimization problem. We demonstrate that the error converges linearly in iterations and the smoothing parameter, and faster than algebraically in the number of degrees of freedom, consisting of the number of quadrature points in one variable and tensor ranks. Moreover, in the topology optimization problem, the smoothed shared sparsity penalty actually reduces the tensor ranks compared to the unpenalised solution. This enables us to find a sparse high-resolution design under a high-dimensional uncertainty.", "published": "2024-11-07 05:00:00", "id": "18a56108-ed96-49b4-944a-8b4adb943c91", "source": "arxiv", "section": "computerScience"}, {"title": "Synomaly Noise and Multi-Stage Diffusion: A Novel Approach for Unsupervised Anomaly Detection in Ultrasound Imaging", "link": "https://arxiv.org/abs/2411.04004", "description": "arXiv:2411.04004v1 Announce Type: cross \nAbstract: Ultrasound (US) imaging is widely used in routine clinical practice due to its advantages of being radiation-free, cost-effective, and portable. However, the low reproducibility and quality of US images, combined with the scarcity of expert-level annotation, make the training of fully supervised segmentation models challenging. To address these issues, we propose a novel unsupervised anomaly detection framework based on a diffusion model that incorporates a synthetic anomaly (Synomaly) noise function and a multi-stage diffusion process. Synomaly noise introduces synthetic anomalies into healthy images during training, allowing the model to effectively learn anomaly removal. The multi-stage diffusion process is introduced to progressively denoise images, preserving fine details while improving the quality of anomaly-free reconstructions. The generated high-fidelity counterfactual healthy images can further enhance the interpretability of the segmentation models, as well as provide a reliable baseline for evaluating the extent of anomalies and supporting clinical decision-making. Notably, the unsupervised anomaly detection model is trained purely on healthy images, eliminating the need for anomalous training samples and pixel-level annotations. We validate the proposed approach on carotid US, brain MRI, and liver CT datasets. The experimental results demonstrate that the proposed framework outperforms existing state-of-the-art unsupervised anomaly detection methods, achieving performance comparable to fully supervised segmentation models in the US dataset. Additionally, ablation studies underline the importance of hyperparameter selection for Synomaly noise and the effectiveness of the multi-stage diffusion process in enhancing model performance.", "published": "2024-11-07 05:00:00", "id": "5530d1db-d8ee-47d8-ae7a-f2210aee68c5", "source": "arxiv", "section": "computerScience"}, {"title": "Laplace transform based quantum eigenvalue transformation via linear combination of Hamiltonian simulation", "link": "https://arxiv.org/abs/2411.04010", "description": "arXiv:2411.04010v1 Announce Type: cross \nAbstract: Eigenvalue transformations, which include solving time-dependent differential equations as a special case, have a wide range of applications in scientific and engineering computation. While quantum algorithms for singular value transformations are well studied, eigenvalue transformations are distinct, especially for non-normal matrices. We propose an efficient quantum algorithm for performing a class of eigenvalue transformations that can be expressed as a certain type of matrix Laplace transformation. This allows us to significantly extend the recently developed linear combination of Hamiltonian simulation (LCHS) method [An, Liu, Lin, Phys. Rev. Lett. 131, 150603, 2023; An, Childs, Lin, arXiv:2312.03916] to represent a wider class of eigenvalue transformations, such as powers of the matrix inverse, $A^{-k}$, and the exponential of the matrix inverse, $e^{-A^{-1}}$. The latter can be interpreted as the solution of a mass-matrix differential equation of the form $A u'(t)=-u(t)$. We demonstrate that our eigenvalue transformation approach can solve this problem without explicitly inverting $A$, reducing the computational complexity.", "published": "2024-11-07 05:00:00", "id": "a0fabca0-3224-45ed-a5b0-bfc3c265344b", "source": "arxiv", "section": "computerScience"}, {"title": "Generalized quantum asymptotic equipartition", "link": "https://arxiv.org/abs/2411.04035", "description": "arXiv:2411.04035v1 Announce Type: cross \nAbstract: We establish a generalized quantum asymptotic equipartition property (AEP) beyond the i.i.d. framework where the random samples are drawn from two sets of quantum states. In particular, under suitable assumptions on the sets, we prove that all operationally relevant divergences converge to the quantum relative entropy between the sets. More specifically, both the smoothed min- and max-relative entropy approach the regularized relative entropy between the sets. Notably, the asymptotic limit has explicit convergence guarantees and can be efficiently estimated through convex optimization programs, despite the regularization, provided that the sets have efficient descriptions.\n  We give four applications of this result: (i) The generalized AEP directly implies a new generalized quantum Stein's lemma for conducting quantum hypothesis testing between two sets of quantum states. (ii) We introduce a quantum version of adversarial hypothesis testing where the tester plays against an adversary who possesses internal quantum memory and controls the quantum device and show that the optimal error exponent is precisely characterized by a new notion of quantum channel divergence, named the minimum output channel divergence. (iii) We derive a relative entropy accumulation theorem stating that the smoothed min-relative entropy between two sequential processes of quantum channels can be lower bounded by the sum of the regularized minimum output channel divergences. (iv) We apply our generalized AEP to quantum resource theories and provide improved and efficient bounds for entanglement distillation, magic state distillation, and the entanglement cost of quantum states and channels.\n  At a technical level, we establish new additivity and chain rule properties for the measured relative entropy which we expect will have more applications.", "published": "2024-11-07 05:00:00", "id": "ead676ef-c2d4-448e-bbfa-8b386a96d95b", "source": "arxiv", "section": "computerScience"}, {"title": "Quantum Cryptography: an overview of Quantum Key Distribution", "link": "https://arxiv.org/abs/2411.04044", "description": "arXiv:2411.04044v1 Announce Type: cross \nAbstract: This chapter highlights the transformation of secure communications through the incorporation of quantum mechanics. Over the past four decades, this groundbreaking theory has quietly revolutionized private communication. The chapter provides a concise historical overview of this field's inception, tracking the development of its pioneering protocol, BB84. It delves deeply into the protocol's evolution, spotlighting its milestones and challenges. Furthermore, it offers a panoramic view of the entire quantum key distribution landscape, encompassing continuous variable protocols designed to harness existing telecom technologies and device-independent quantum key distribution protocols aimed at achieving secure key exchange with minimal reliance on the experimental setup.", "published": "2024-11-07 05:00:00", "id": "8ae76c8b-d990-4e07-8f8c-ddaa1268437f", "source": "arxiv", "section": "computerScience"}, {"title": "Koopman Operators for Global Analysis of Hybrid Limit-Cycling Systems: Construction and Spectral Properties", "link": "https://arxiv.org/abs/2411.04052", "description": "arXiv:2411.04052v1 Announce Type: cross \nAbstract: This paper reports a theory of Koopman operators for a class of hybrid dynamical systems with globally asymptotically stable periodic orbits, called hybrid limit-cycling systems. We leverage smooth structures intrinsic to the hybrid dynamical systems, thereby extending the existing theory of Koopman operators for smooth dynamical systems. Rigorous construction of an observable space is carried out to preserve the inherited smooth structures of the hybrid dynamical systems. Complete spectral characterization of the Koopman operators acting on the constructed space is then derived where the existence and uniqueness of their eigenfunctions are ensured. Our results facilitate global analysis of hybrid dynamical systems using the Koopman operator.", "published": "2024-11-07 05:00:00", "id": "892bdd5b-a97c-478f-955e-851a1ce9808d", "source": "arxiv", "section": "computerScience"}, {"title": "Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits", "link": "https://arxiv.org/abs/2411.04054", "description": "arXiv:2411.04054v1 Announce Type: cross \nAbstract: Causal knowledge about the relationships among decision variables and a reward variable in a bandit setting can accelerate the learning of an optimal decision. Current works often assume the causal graph is known, which may not always be available a priori. Motivated by this challenge, we focus on the causal bandit problem in scenarios where the underlying causal graph is unknown and may include latent confounders. While intervention on the parents of the reward node is optimal in the absence of latent confounders, this is not necessarily the case in general. Instead, one must consider a set of possibly optimal arms/interventions, each being a special subset of the ancestors of the reward node, making causal discovery beyond the parents of the reward node essential. For regret minimization, we identify that discovering the full causal structure is unnecessary; however, no existing work provides the necessary and sufficient components of the causal graph. We formally characterize the set of necessary and sufficient latent confounders one needs to detect or learn to ensure that all possibly optimal arms are identified correctly. We also propose a randomized algorithm for learning the causal graph with a limited number of samples, providing a sample complexity guarantee for any desired confidence level. In the causal bandit setup, we propose a two-stage approach. In the first stage, we learn the induced subgraph on ancestors of the reward, along with a necessary and sufficient subset of latent confounders, to construct the set of possibly optimal arms. The regret incurred during this phase scales polynomially with respect to the number of nodes in the causal graph. The second phase involves the application of a standard bandit algorithm, such as the UCB algorithm. We also establish a regret bound for our two-phase approach, which is sublinear in the number of rounds.", "published": "2024-11-07 05:00:00", "id": "913bef51-1e75-4b80-94b8-06e8905dd0fd", "source": "arxiv", "section": "computerScience"}, {"title": "A unified approach to quantum de Finetti theorems and SoS rounding via geometric quantization", "link": "https://arxiv.org/abs/2411.04057", "description": "arXiv:2411.04057v1 Announce Type: cross \nAbstract: The sum-of-squares hierarchy of semidefinite programs has become a common tool for algorithm design in theoretical computer science, including problems in quantum information. In this work we study a connection between a Hermitian version of the SoS hierarchy, related to the quantum de Finetti theorem, and geometric quantization of compact K\\\"ahler manifolds (such as complex projective space $\\mathbb{C}P^{d}$, the set of all pure states in a $(d + 1)$-dimensional Hilbert space). We show that previously known HSoS rounding algorithms can be recast as quantizing an objective function to obtain a finite-dimensional matrix, finding its top eigenvector, and then (possibly nonconstructively) rounding it by using a version of the Husimi quasiprobability distribution. Dually, we recover most known quantum de Finetti theorems by doing the same steps in the reverse order: a quantum state is first approximated by its Husimi distribution, and then quantized to obtain a separable state approximating the original one. In cases when there is a transitive group action on the manifold we give some new proofs of existing de Finetti theorems, as well as some applications including a new version of Renner's exponential de Finetti theorem proven using the Borel--Weil--Bott theorem, and hardness of approximation results and optimal degree-2 integrality gaps for the basic SDP relaxation of \\textsc{Quantum Max-$d$-Cut} (for arbitrary $d$). We also describe how versions of these results can be proven when there is no transitive group action. In these cases we can deduce some error bounds for the HSoS hierarchy on complex projective varieties which are smooth.", "published": "2024-11-07 05:00:00", "id": "80e15edc-906c-4b06-9507-b6156fccec01", "source": "arxiv", "section": "computerScience"}, {"title": "A Multi-level Monte Carlo simulation for invariant distribution of Markovian switching L\\'evy-driven SDEs with super-linearly growth coefficients", "link": "https://arxiv.org/abs/2411.04081", "description": "arXiv:2411.04081v1 Announce Type: cross \nAbstract: This paper concerns the numerical approximation for the invariant distribution of Markovian switching L\\'evy-driven stochastic differential equations. By combining the tamed-adaptive Euler-Maruyama scheme with the Multi-level Monte Carlo method, we propose an approximation scheme that can be applied to stochastic differential equations with super-linear growth drift and diffusion coefficients.", "published": "2024-11-07 05:00:00", "id": "67b23c38-257e-4989-a8f7-b243bc9e7806", "source": "arxiv", "section": "computerScience"}, {"title": "Revisiting BQP with Non-Collapsing Measurements", "link": "https://arxiv.org/abs/2411.04085", "description": "arXiv:2411.04085v1 Announce Type: cross \nAbstract: The study of non-collapsing measurements was initiated by Aaronson, Bouland, Fitzsimons, and Lee, who showed that BQP, when equipped with the ability to perform non-collapsing measurements (denoted as PDQP), contains both BQP and SZK, yet still requires $\\Omega (N^{1/4})$ queries to find an element in an unsorted list.\n  By formulating an alternative equivalent model of PDQP, we prove the positive weighted adversary method, obtaining a variety of new lower bounds and establishing a trade-off between queries and non-collapsing measurements. The method allows us to examine the well-studied majority and element distinctness problems, while also tightening the bound for the search problem to $\\Theta (N^{1/3})$. Additionally, we explore related settings, obtaining tight bounds in BQP with the ability to copy arbitrary states (called CBQP) and PDQP with non-adaptive queries.", "published": "2024-11-07 05:00:00", "id": "be342cda-a80b-4b52-9a85-64419412781e", "source": "arxiv", "section": "computerScience"}, {"title": "Marcinkiewicz-Zygmund inequalities in quasi-Banach function spaces", "link": "https://arxiv.org/abs/2411.04119", "description": "arXiv:2411.04119v1 Announce Type: cross \nAbstract: We obtain Marcinkiewicz--ygmund (MZ) inequalities in various Banach and quasi-Banach spaces under minimal assumptions on the structural properties of these spaces. Our main results show that the Bernstein inequality in a general quasi-Banach function lattice $X$ implies Marcinkiewicz-Zygmund type estimates in $X$. We present a general approach to obtain MZ inequalities not only for polynomials but for other function classes including entire functions of exponential type, splines, exponential sums, etc.", "published": "2024-11-07 05:00:00", "id": "5fff2659-4741-4d15-b938-d26069635e6d", "source": "arxiv", "section": "computerScience"}, {"title": "$hp$-Version space-time discontinuous Galerkin methods for parabolic problems on prismatic meshes", "link": "https://arxiv.org/abs/1605.01212", "description": "arXiv:1605.01212v3 Announce Type: replace \nAbstract: We present a new $hp$-version space-time discontinuous Galerkin (dG) finite element method for the numerical approximation of parabolic evolution equations on general spatial meshes consisting of polygonal/polyhedral (polytopic) elements, giving rise to prismatic space-time elements. A key feature of the proposed method is the use of space-time elemental polynomial bases of \\emph{total} degree, say $p$, defined in the physical coordinate system, as opposed to standard dG-time-stepping methods whereby spatial elemental bases are tensorized with temporal basis functions. This approach leads to a fully discrete $hp$-dG scheme using less degrees of freedom for each time step, compared to standard dG time-stepping schemes employing tensorized space-time, with acceptable deterioration of the approximation properties. A second key feature of the new space-time dG method is the incorporation of very general spatial meshes consisting of possibly polygonal/polyhedral elements with \\emph{arbitrary} number of faces. A priori error bounds are shown for the proposed method in various norms. An extensive comparison among the new space-time dG method, the (standard) tensorized space-time dG methods, the classical dG-time-stepping, and conforming finite element method in space, is presented in a series of numerical experiments.", "published": "2024-11-07 05:00:00", "id": "1cf2bbcd-303b-4382-8b8e-ebc1c3e17e97", "source": "arxiv", "section": "computerScience"}, {"title": "Bounds on the revenue gap of linear posted pricing for selling a divisible item", "link": "https://arxiv.org/abs/2007.08246", "description": "arXiv:2007.08246v2 Announce Type: replace \nAbstract: Selling a perfectly divisible item to potential buyers is a fundamental task with apparent applications to pricing communication bandwidth and cloud computing services. Surprisingly, despite the rich literature on single-item auctions, revenue maximization when selling a divisible item is a much less understood objective. We introduce a Bayesian setting, in which the potential buyers have concave valuation functions (defined for each possible item fraction) that are randomly chosen according to known probability distributions. Extending the sequential posted pricing paradigm, we focus on mechanisms that use linear pricing, charging a fixed price for the whole item and proportional prices for fractions of it. Our goal is to understand the power of such mechanisms by bounding the gap between the expected revenue that can be achieved by the best among these mechanisms and the maximum expected revenue that can be achieved by any mechanism assuming mild restrictions on the behavior of the buyers. Under regularity assumptions for the probability distributions, we show that this revenue gap depends only logarithmically on a natural parameter characterizing the valuation functions and the number of agents. Our results follow by bounding the objective value of a mathematical program that maximizes the ex-ante relaxation of optimal revenue under linear pricing revenue constraints.", "published": "2024-11-07 05:00:00", "id": "61a87c26-08c7-41f0-8e43-ec0220ff7be5", "source": "arxiv", "section": "computerScience"}, {"title": "Optimal Control-Based Baseline for Guided Exploration in Policy Gradient Methods", "link": "https://arxiv.org/abs/2011.02073", "description": "arXiv:2011.02073v5 Announce Type: replace \nAbstract: In this paper, a novel optimal control-based baseline function is presented for the policy gradient method in deep reinforcement learning (RL). The baseline is obtained by computing the value function of an optimal control problem, which is formed to be closely associated with the RL task. In contrast to the traditional baseline aimed at variance reduction of policy gradient estimates, our work utilizes the optimal control value function to introduce a novel aspect to the role of baseline -- providing guided exploration during policy learning. This aspect is less discussed in prior works. We validate our baseline on robot learning tasks, showing its effectiveness in guided exploration, particularly in sparse reward environments.", "published": "2024-11-07 05:00:00", "id": "e8cd39ce-8dba-4b2d-80cd-eaa0f4372d87", "source": "arxiv", "section": "computerScience"}, {"title": "Heteroscedastic Temporal Variational Autoencoder For Irregular Time Series", "link": "https://arxiv.org/abs/2107.11350", "description": "arXiv:2107.11350v2 Announce Type: replace \nAbstract: Irregularly sampled time series commonly occur in several domains where they present a significant challenge to standard deep learning models. In this paper, we propose a new deep learning framework for probabilistic interpolation of irregularly sampled time series that we call the Heteroscedastic Temporal Variational Autoencoder (HeTVAE). HeTVAE includes a novel input layer to encode information about input observation sparsity, a temporal VAE architecture to propagate uncertainty due to input sparsity, and a heteroscedastic output layer to enable variable uncertainty in output interpolations. Our results show that the proposed architecture is better able to reflect variable uncertainty through time due to sparse and irregular sampling than a range of baseline and traditional models, as well as recently proposed deep latent variable models that use homoscedastic output layers.", "published": "2024-11-07 05:00:00", "id": "ce8ce973-f207-47e7-9390-50bc69aeccbf", "source": "arxiv", "section": "computerScience"}, {"title": "Contraction Theory for Nonlinear Stability Analysis and Learning-based Control: A Tutorial Overview", "link": "https://arxiv.org/abs/2110.00675", "description": "arXiv:2110.00675v4 Announce Type: replace \nAbstract: Contraction theory is an analytical tool to study differential dynamics of a non-autonomous (i.e., time-varying) nonlinear system under a contraction metric defined with a uniformly positive definite matrix, the existence of which results in a necessary and sufficient characterization of incremental exponential stability of multiple solution trajectories with respect to each other. By using a squared differential length as a Lyapunov-like function, its nonlinear stability analysis boils down to finding a suitable contraction metric that satisfies a stability condition expressed as a linear matrix inequality, indicating that many parallels can be drawn between well-known linear systems theory and contraction theory for nonlinear systems. Furthermore, contraction theory takes advantage of a superior robustness property of exponential stability used in conjunction with the comparison lemma. This yields much-needed safety and stability guarantees for neural network-based control and estimation schemes, without resorting to a more involved method of using uniform asymptotic stability for input-to-state stability. Such distinctive features permit systematic construction of a contraction metric via convex optimization, thereby obtaining an explicit exponential bound on the distance between a time-varying target trajectory and solution trajectories perturbed externally due to disturbances and learning errors. The objective of this paper is therefore to present a tutorial overview of contraction theory and its advantages in nonlinear stability analysis of deterministic and stochastic systems, with an emphasis on deriving formal robustness and stability guarantees for various learning-based and data-driven automatic control methods. In particular, we provide a detailed review of techniques for finding contraction metrics and associated control and estimation laws using deep neural networks.", "published": "2024-11-07 05:00:00", "id": "f86ea800-d888-46d6-b0a0-b5bc079ab3ba", "source": "arxiv", "section": "computerScience"}, {"title": "Active Vapor-Based Robotic Wiper", "link": "https://arxiv.org/abs/2111.08248", "description": "arXiv:2111.08248v3 Announce Type: replace \nAbstract: This paper presents a method for estimating normals of mirrors and transparent objects challenging for cameras to recognize. We propose spraying water vapor onto mirror or transparent surfaces to create a diffuse reflective surface. Using an ultrasonic humidifier on a robotic arm, we apply water vapor to the target object's surface, forming a cross-shaped misted area. This creates partially diffuse reflective surfaces, enabling the camera to detect the target object's surface. Adjusting the gripper-mounted camera viewpoint maximizes the extracted misted area's appearance in the image, allowing normal estimation of the target surface. Experiments show the method's effectiveness, with RMSEs of azimuth estimation for mirrors and transparent glass at approximately 4.2 and 5.8 degrees, respectively. Our robot experiments demonstrated that our robotic wiper can perform contact-force-regulated wiping motions to clean a transparent window, akin to human performance.", "published": "2024-11-07 05:00:00", "id": "ce14d59a-5957-4267-a643-533c5b31828b", "source": "arxiv", "section": "computerScience"}, {"title": "Generalized Lagrange Coded Computing: A Flexible Computation-Communication Tradeoff for Resilient, Secure, and Private Computation", "link": "https://arxiv.org/abs/2204.11168", "description": "arXiv:2204.11168v3 Announce Type: replace \nAbstract: We consider the problem of evaluating arbitrary multivariate polynomials over a massive dataset containing multiple inputs, on a distributed computing system with a master node and multiple worker nodes. Generalized Lagrange Coded Computing (GLCC) codes are proposed to simultaneously provide resiliency against stragglers who do not return computation results in time, security against adversarial workers who deliberately modify results for their benefit, and information-theoretic privacy of the dataset amidst possible collusion of workers. GLCC codes are constructed by first partitioning the dataset into multiple groups, then encoding the dataset using carefully designed interpolating polynomials, and sharing multiple encoded data points to each worker, such that interference computation results across groups can be eliminated at the master. Particularly, GLCC codes include the state-of-the-art Lagrange Coded Computing (LCC) codes as a special case, and exhibit a more flexible tradeoff between communication and computation overheads in optimizing system efficiency. Furthermore, we apply GLCC to distributed training of machine learning models, and demonstrate that GLCC codes achieve a speedup of up to $2.5\\text{--}3.9\\times$ over LCC codes in training time, across experiments for training image classifiers on different datasets, model architectures, and straggler patterns.", "published": "2024-11-07 05:00:00", "id": "93051880-5578-43a9-a604-3ce4c26263ce", "source": "arxiv", "section": "computerScience"}, {"title": "Adaptive Complexity Model Predictive Control", "link": "https://arxiv.org/abs/2209.02849", "description": "arXiv:2209.02849v2 Announce Type: replace \nAbstract: This work introduces a formulation of model predictive control (MPC) which adaptively reasons about the complexity of the model based on the task while maintaining feasibility and stability guarantees. Existing MPC implementations often handle computational complexity by shortening prediction horizons or simplifying models, both of which can result in instability. Inspired by related approaches in behavioral economics, motion planning, and biomechanics, our method solves MPC problems with a simple model for dynamics and constraints over regions of the horizon where such a model is feasible and a complex model where it is not. The approach leverages an interleaving of planning and execution to iteratively identify these regions, which can be safely simplified if they satisfy an exact template/anchor relationship. We show that this method does not compromise the stability and feasibility properties of the system, and measure performance in simulation experiments on a quadrupedal robot executing agile behaviors over terrains of interest. We find that this adaptive method enables more agile motion and expands the range of executable tasks compared to fixed-complexity implementations.", "published": "2024-11-07 05:00:00", "id": "1b6a6a74-0c6c-40c9-b9bb-8cb20d6cb786", "source": "arxiv", "section": "computerScience"}, {"title": "CPnP: Consistent Pose Estimator for Perspective-n-Point Problem with Bias Elimination", "link": "https://arxiv.org/abs/2209.05824", "description": "arXiv:2209.05824v2 Announce Type: replace \nAbstract: The Perspective-n-Point (PnP) problem has been widely studied in both computer vision and photogrammetry societies. With the development of feature extraction techniques, a large number of feature points might be available in a single shot. It is promising to devise a consistent estimator, i.e., the estimate can converge to the true camera pose as the number of points increases. To this end, we propose a consistent PnP solver, named \\emph{CPnP}, with bias elimination. Specifically, linear equations are constructed from the original projection model via measurement model modification and variable elimination, based on which a closed-form least-squares solution is obtained. We then analyze and subtract the asymptotic bias of this solution, resulting in a consistent estimate. Additionally, Gauss-Newton (GN) iterations are executed to refine the consistent solution. Our proposed estimator is efficient in terms of computations -- it has $O(n)$ computational complexity. Experimental tests on both synthetic data and real images show that our proposed estimator is superior to some well-known ones for images with dense visual features, in terms of estimation precision and computing time.", "published": "2024-11-07 05:00:00", "id": "2fe1c032-75cc-46a4-a29a-7e0f9c22a8d9", "source": "arxiv", "section": "computerScience"}, {"title": "Benchmarking Numerical Algorithms for Harmonic Maps into the Sphere", "link": "https://arxiv.org/abs/2209.13665", "description": "arXiv:2209.13665v3 Announce Type: replace \nAbstract: We numerically benchmark methods for computing harmonic maps into the unit sphere, with particular focus on harmonic maps with singularities. For the discretization we compare two different approaches, both based on Lagrange finite elements. While the first method enforces the unit-length constraint only at the Lagrange nodes, the other one adds a pointwise projection to fulfill the constraint everywhere. For the solution of the resulting algebraic problems we compare a nonconforming gradient flow with a Riemannian trust-region method. Both are energy-decreasing and can be shown to converge globally to stationary points of the discretized Dirichlet energy. We observe that while the nonconforming and the conforming discretizations both show similar behavior for smooth problems, the nonconforming discretization handles singularities better. On the solver side, the second-order trust-region method converges after few steps, whereas the number of gradient-flow steps increases proportionally to the inverse grid element diameter.", "published": "2024-11-07 05:00:00", "id": "dfbe3c0c-d643-4792-93f5-e53100526cbd", "source": "arxiv", "section": "computerScience"}, {"title": "UMIRobot: An Open-{Software, Hardware} Low-Cost Robotic Manipulator for Education", "link": "https://arxiv.org/abs/2301.06668", "description": "arXiv:2301.06668v3 Announce Type: replace \nAbstract: Robot teleoperation has been studied for the past 70 years and is relevant in many contexts, such as in the handling of hazardous materials and telesurgery. The COVID19 pandemic has rekindled interest in this topic, but the existing robotic education kits fall short of being suitable for teleoperated robotic manipulator learning. In addition, the global restrictions of motion motivated large investments in online/hybrid education. In this work, a newly developed robotics education kit and its ecosystem are presented which is used as the backbone of an online/hybrid course in teleoperated robots. The students are divided into teams. Each team designs, fabricates (3D printing and assembling), and implements a control strategy for a master device and gripper. Coupling those with the UMIRobot, provided as a kit, the students compete in a teleoperation challenge. The kit is low cost (< 100USD), which allows higher-learning institutions to provide one kit per student and they can learn in a risk-free environment. As of now, 73 such kits have been assembled and sent to course participants in eight countries. As major success stories, we show an example of gripper and master designed for the proposed course. In addition, we show a teleoperated task between Japan and Bangladesh executed by course participants. Design files, videos, source code, and more information are available at https://mmmarinho.github.io/UMIRobot/", "published": "2024-11-07 05:00:00", "id": "523f3fac-a779-4778-947d-c359ad0d15b6", "source": "arxiv", "section": "computerScience"}, {"title": "Variational Inference on the Final-Layer Output of Neural Networks", "link": "https://arxiv.org/abs/2302.02420", "description": "arXiv:2302.02420v5 Announce Type: replace \nAbstract: Traditional neural networks are simple to train but they typically produce overconfident predictions. In contrast, Bayesian neural networks provide good uncertainty quantification but optimizing them is time consuming due to the large parameter space. This paper proposes to combine the advantages of both approaches by performing Variational Inference in the Final layer Output space (VIFO), because the output space is much smaller than the parameter space. We use neural networks to learn the mean and the variance of the probabilistic output. Using the Bayesian formulation we incorporate collapsed variational inference with VIFO which significantly improves the performance in practice. On the other hand, like standard, non-Bayesian models, VIFO enjoys simple training and one can use Rademacher complexity to provide risk bounds for the model. Experiments show that VIFO provides a good tradeoff in terms of run time and uncertainty quantification, especially for out of distribution data.", "published": "2024-11-07 05:00:00", "id": "bbc932be-7ef0-4500-9411-a39ccc525ab1", "source": "arxiv", "section": "computerScience"}, {"title": "Nearly Optimal Approximation of Matrix Functions by the Lanczos Method", "link": "https://arxiv.org/abs/2303.03358", "description": "arXiv:2303.03358v3 Announce Type: replace \nAbstract: Approximating the action of a matrix function $f(\\mathbf{A})$ on a vector $\\mathbf{b}$ is an increasingly important primitive in machine learning, data science, and statistics, with applications such as sampling high dimensional Gaussians, Gaussian process regression and Bayesian inference, principle component analysis, and approximating Hessian spectral densities. Over the past decade, a number of algorithms enjoying strong theoretical guarantees have been proposed for this task. Many of the most successful belong to a family of algorithms called Krylov subspace methods. Remarkably, a classic Krylov subspace method, called the Lanczos method for matrix functions (Lanczos-FA), frequently outperforms newer methods in practice. Our main result is a theoretical justification for this finding: we show that, for a natural class of rational functions, Lanczos-FA matches the error of the best possible Krylov subspace method up to a multiplicative approximation factor. The approximation factor depends on the degree of $f(x)$'s denominator and the condition number of $\\mathbf{A}$, but not on the number of iterations $k$. Our result provides a strong justification for the excellent performance of Lanczos-FA, especially on functions that are well approximated by rationals, such as the matrix square root.", "published": "2024-11-07 05:00:00", "id": "d5f65f99-da97-4a40-a520-78ca8ce308ce", "source": "arxiv", "section": "computerScience"}, {"title": "Understanding Mobile App Reviews to Guide Misuse Audits", "link": "https://arxiv.org/abs/2303.10795", "description": "arXiv:2303.10795v2 Announce Type: replace \nAbstract: Problem: We address the challenge in responsible computing where an exploitable mobile app is misused by one app user (an abuser) against another user or bystander (victim). We introduce the idea of a misuse audit of apps as a way of determining if they are exploitable without access to their implementation.\n  Method: We leverage app reviews to identify exploitable apps and their functionalities that enable misuse. First, we build a computational model to identify alarming reviews (which report misuse). Second, using the model, we identify exploitable apps and their functionalities. Third, we validate them through manual inspection of reviews.\n  Findings: Stories by abusers and victims mostly focus on past misuses, whereas stories by third parties mostly identify stories indicating the potential for misuse. Surprisingly, positive reviews by abusers, which exhibit language with high dominance, also reveal misuses. In total, we confirmed 156 exploitable apps facilitating the misuse. Based on our qualitative analysis, we found exploitable apps exhibiting four types of exploitable functionalities.\n  Implications: Our method can help identify exploitable apps and their functionalities, facilitating misuse audits of a large pool of apps.", "published": "2024-11-07 05:00:00", "id": "e684135b-25c4-4a7b-aa00-34424b9dc4c7", "source": "arxiv", "section": "computerScience"}, {"title": "Lattice-preserving $\\mathcal{ALC}$ ontology embeddings with saturation", "link": "https://arxiv.org/abs/2305.07163", "description": "arXiv:2305.07163v3 Announce Type: replace \nAbstract: Generating vector representations (embeddings) of OWL ontologies is a growing task due to its applications in predicting missing facts and knowledge-enhanced learning in fields such as bioinformatics. The underlying semantics of OWL ontologies are expressed using Description Logics (DLs). Initial approaches to generate embeddings relied on constructing a graph out of ontologies, neglecting the semantics of the logic therein. Recent semantic-preserving embedding methods often target lightweight DL languages like $\\mathcal{EL}^{++}$, ignoring more expressive information in ontologies. Although some approaches aim to embed more descriptive DLs like $\\mathcal{ALC}$, those methods require the existence of individuals, while many real-world ontologies are devoid of them. We propose an ontology embedding method for the $\\mathcal{ALC}$ DL language that considers the lattice structure of concept descriptions. We use connections between DL and Category Theory to materialize the lattice structure and embed it using an order-preserving embedding method. We show that our method outperforms state-of-the-art methods in several knowledge base completion tasks. Furthermore, we incoporate saturation procedures that increase the information within the constructed lattices. We make our code and data available at \\url{https://github.com/bio-ontology-research-group/catE}.", "published": "2024-11-07 05:00:00", "id": "483e4153-3ecd-4673-b5be-425c8cd140ce", "source": "arxiv", "section": "computerScience"}, {"title": "Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning", "link": "https://arxiv.org/abs/2305.15612", "description": "arXiv:2305.15612v3 Announce Type: replace \nAbstract: Bayesian optimization has attracted huge attention from diverse research areas in science and engineering, since it is capable of efficiently finding a global optimum of an expensive-to-evaluate black-box function. In general, a probabilistic regression model is widely used as a surrogate function to model an explicit distribution over function evaluations given an input to estimate and a training dataset. Beyond the probabilistic regression-based methods, density ratio estimation-based Bayesian optimization has been suggested in order to estimate a density ratio of the groups relatively close and relatively far to a global optimum. Developing this line of research further, supervised classifiers are employed to estimate a class probability for the two groups instead of a density ratio. However, the supervised classifiers used in this strategy are prone to be overconfident for known knowledge on global solution candidates. Supposing that we have access to unlabeled points, e.g., predefined fixed-size pools, we propose density ratio estimation-based Bayesian optimization with semi-supervised learning to solve this challenge. Finally, we show the empirical results of our methods and several baseline methods in two distinct scenarios with unlabeled point sampling and a fixed-size pool and analyze the validity of our proposed methods in diverse experiments.", "published": "2024-11-07 05:00:00", "id": "9c5d60be-6c74-479b-8dcf-fbb2caf2973a", "source": "arxiv", "section": "computerScience"}, {"title": "Codebook Configuration for RIS-aided Systems via Implicit Neural Representations", "link": "https://arxiv.org/abs/2306.00544", "description": "arXiv:2306.00544v3 Announce Type: replace \nAbstract: Reconfigurable Intelligent Surface (RIS) is envisioned to be an enabling technique in 6G wireless communications. By configuring the reflection beamforming codebook, RIS focuses signals on target receivers to enhance signal strength. In this paper, we investigate the codebook configuration for RIS-aided communication systems. We formulate an implicit relationship between user's coordinates information and the codebook from the perspective of signal radiation mechanisms, and introduce a novel learning-based method, implicit neural representations (INRs), to solve this implicit coordinates-to-codebook mapping problem. Our approach requires only user's coordinates, avoiding reliance on channel models. Additionally, given the significant practical applications of the 1-bit RIS, we formulate the 1-bit codebook configuration as a multi-label classification problem, and propose an encoding strategy for 1-bit RIS to reduce the codebook dimension, thereby improving learning efficiency. Experimental results from simulations and measured data demonstrate significant advantages of our method.", "published": "2024-11-07 05:00:00", "id": "01c3cbdb-b7d7-461b-8bfd-d904a24473c4", "source": "arxiv", "section": "computerScience"}, {"title": "On the rotational invariance and hyperbolicity of shallow water moment equations in two dimensions", "link": "https://arxiv.org/abs/2306.07202", "description": "arXiv:2306.07202v2 Announce Type: replace \nAbstract: In this paper, we investigate the two-dimensional extension of a recently introduced set of shallow water models based on a regularized moment expansion of the incompressible Navier-Stokes equations \\cite{kowalski2017moment,koellermeier2020analysis}. We show the rotational invariance of the proposed moment models with two different approaches. The first proof involves the split of the coefficient matrix into the conservative and non-conservative parts and proves the rotational invariance for each part, while the second one relies on the special block structure of the coefficient matrices. With the aid of rotational invariance, the analysis of the hyperbolicity for the moment model in 2D is reduced to the real diagonalizability of the coefficient matrix in 1D. Then we analyze the real diagonalizability by deriving the analytical form of the characteristic polynomial. We find that the moment model in 2D is hyperbolic in most cases and weakly hyperbolic in a degenerate edge case. With a simple modification to the coefficient matrices, we fix this weakly hyperbolicity and propose a new global hyperbolic model. Furthermore, we extend the model to include a more general class of closure relations than the original model and establish that this set of general closure relations retains both rotational invariance and hyperbolicity.", "published": "2024-11-07 05:00:00", "id": "76ee9afc-0517-45b9-90d4-e1cfecf6141a", "source": "arxiv", "section": "computerScience"}, {"title": "Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics", "link": "https://arxiv.org/abs/2306.10656", "description": "arXiv:2306.10656v3 Announce Type: replace \nAbstract: Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental well-being. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating healthcare, lifestyles, and personality attributes. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 2,000 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques and have deployed VHGM as a Web service, enabling various healthcare applications.", "published": "2024-11-07 05:00:00", "id": "79baeb9b-4677-4aea-a3e9-c01c1fa7a442", "source": "arxiv", "section": "computerScience"}, {"title": "Breaking the Metric Voting Distortion Barrier", "link": "https://arxiv.org/abs/2306.17838", "description": "arXiv:2306.17838v2 Announce Type: replace \nAbstract: We consider the following well-studied problem of metric distortion in social choice. Suppose we have an election with $n$ voters and $m$ candidates located in a shared metric space. We would like to design a voting rule that chooses a candidate whose average distance to the voters is small. However, instead of having direct access to the distances in the metric space, the voting rule obtains, from each voter, a ranked list of the candidates in order of distance. Can we design a rule that regardless of the election instance and underlying metric space, chooses a candidate whose cost differs from the true optimum by only a small factor (known as the distortion)?\n  A long line of work culminated in finding optimal deterministic voting rules with metric distortion $3$. However, for randomized voting rules, there is still a gap in our understanding: Even though the best lower bound is $2.112$, the best upper bound is still $3$, attained even by simple rules such as Random Dictatorship. Finding a randomized rule that guarantees distortion $3 - \\epsilon$ has been a major challenge in computational social choice, as prevalent approaches to designing voting rules are known to be insufficient. Such a voting rule must use information beyond aggregate comparisons between pairs of candidates, and cannot only assign positive probability to candidates that are voters' top choices.\n  In this work, we give a rule that guarantees distortion less than $2.753$. To do so we study a handful of voting rules that are new to the problem. One is Maximal Lotteries, a rule based on the Nash equilibrium of a natural zero-sum game which dates back to the 60's. The others are novel rules that can be thought of as hybrids of Random Dictatorship and the Copeland rule. Though none of these rules can beat distortion $3$ alone, a randomization between Maximal Lotteries and any of the novel rules can.", "published": "2024-11-07 05:00:00", "id": "3af97703-7015-4cff-8e7a-7b54eeb1ea31", "source": "arxiv", "section": "computerScience"}, {"title": "A class of Discontinuous Galerkin methods for nonlinear variational problems", "link": "https://arxiv.org/abs/2308.12891", "description": "arXiv:2308.12891v2 Announce Type: replace \nAbstract: In the context of Discontinuous Galerkin methods, we study approximations of nonlinear variational problems associated with convex energies. We propose element-wise nonconforming finite element methods to discretize the continuous minimisation problem. Using $\\Gamma$-convergence arguments we show that the discrete minimisers converge to the unique minimiser of the continuous problem as the mesh parameter tends to zero, under the additional contribution of appropriately defined penalty terms at the level of the discrete energies. We finally substantiate the feasibility of our methods by numerical examples.", "published": "2024-11-07 05:00:00", "id": "005ca36b-6b5a-4686-948e-d74f290b6881", "source": "arxiv", "section": "computerScience"}, {"title": "D3: Data Diversity Design for Systematic Generalization in Visual Question Answering", "link": "https://arxiv.org/abs/2309.08798", "description": "arXiv:2309.08798v2 Announce Type: replace \nAbstract: Systematic generalization is a crucial aspect of intelligence, which refers to the ability to generalize to novel tasks by combining known subtasks and concepts. One critical factor that has been shown to influence systematic generalization is the diversity of training data. However, diversity can be defined in various ways, as data have many factors of variation. A more granular understanding of how different aspects of data diversity affect systematic generalization is lacking. We present new evidence in the problem of Visual Question Answering (VQA) that reveals that the diversity of simple tasks (i.e. tasks formed by a few subtasks and concepts) plays a key role in achieving systematic generalization. This implies that it may not be essential to gather a large and varied number of complex tasks, which could be costly to obtain. We demonstrate that this result is independent of the similarity between the training and testing data and applies to well-known families of neural network architectures for VQA (i.e. monolithic architectures and neural module networks). Additionally, we observe that neural module networks leverage all forms of data diversity we evaluated, while monolithic architectures require more extensive amounts of data to do so. These findings provide a first step towards understanding the interactions between data diversity design, neural network architectures, and systematic generalization capabilities.", "published": "2024-11-07 05:00:00", "id": "c0eb1ee0-c8ac-4082-b5c3-d8fd7eda7645", "source": "arxiv", "section": "computerScience"}, {"title": "Robust Perception-Informed Navigation using PAC-NMPC with a Learned Value Function", "link": "https://arxiv.org/abs/2309.13171", "description": "arXiv:2309.13171v2 Announce Type: replace \nAbstract: Nonlinear model predictive control (NMPC) is typically restricted to short, finite horizons to limit the computational burden of online optimization. As a result, global planning frameworks are frequently necessary to avoid local minima when using NMPC for navigation in complex environments. By contrast, reinforcement learning (RL) can generate policies that minimize the expected cost over an infinite-horizon and can often avoid local minima, even when operating only on current sensor measurements. However, these learned policies are usually unable to provide performance guarantees (e.g., on collision avoidance), especially when outside of the training distribution. In this paper, we augment Probably Approximately Correct NMPC (PAC-NMPC), a sampling-based stochastic NMPC algorithm capable of providing statistical guarantees of performance and safety, with an approximate perception-dependent value function trained via RL. We demonstrate in simulation that our algorithm can improve the long-term behavior of PAC-NMPC while outperforming other approaches with regards to safety for both planar car dynamics and more complex, high-dimensional fixed-wing aerial vehicle dynamics. We also demonstrate that, even when our value function is trained in simulation, our algorithm can successfully achieve statistically safe navigation on hardware using a 1/10th scale rally car in cluttered real-world environments using only current sensor information.", "published": "2024-11-07 05:00:00", "id": "a8738678-5e42-43eb-a77f-2e341e135317", "source": "arxiv", "section": "computerScience"}, {"title": "EViT: An Eagle Vision Transformer with Bi-Fovea Self-Attention", "link": "https://arxiv.org/abs/2310.06629", "description": "arXiv:2310.06629v4 Announce Type: replace \nAbstract: Owing to advancements in deep learning technology, Vision Transformers (ViTs) have demonstrated impressive performance in various computer vision tasks. Nonetheless, ViTs still face some challenges, such as high computational complexity and the absence of desirable inductive biases. To alleviate these issues, {the potential advantages of combining eagle vision with ViTs are explored. We summarize a Bi-Fovea Visual Interaction (BFVI) structure inspired by the unique physiological and visual characteristics of eagle eyes. A novel Bi-Fovea Self-Attention (BFSA) mechanism and Bi-Fovea Feedforward Network (BFFN) are proposed based on this structural design approach, which can be used to mimic the hierarchical and parallel information processing scheme of the biological visual cortex, enabling networks to learn feature representations of targets in a coarse-to-fine manner. Furthermore, a Bionic Eagle Vision (BEV) block is designed as the basic building unit based on the BFSA mechanism and BFFN. By stacking BEV blocks, a unified and efficient family of pyramid backbone networks called Eagle Vision Transformers (EViTs) is developed. Experimental results show that EViTs exhibit highly competitive performance in various computer vision tasks, such as image classification, object detection and semantic segmentation. Compared with other approaches, EViTs have significant advantages, especially in terms of performance and computational efficiency. Code is available at https://github.com/nkusyl/EViT", "published": "2024-11-07 05:00:00", "id": "be1d7a5c-46c9-42d3-b79f-5a5685b2ddcb", "source": "arxiv", "section": "computerScience"}, {"title": "Topology-guided Hypergraph Transformer Network: Unveiling Structural Insights for Improved Representation", "link": "https://arxiv.org/abs/2310.09657", "description": "arXiv:2310.09657v4 Announce Type: replace \nAbstract: Hypergraphs, with their capacity to depict high-order relationships, have emerged as a significant extension of traditional graphs. Although Graph Neural Networks (GNNs) have remarkable performance in graph representation learning, their extension to hypergraphs encounters challenges due to their intricate structures. Furthermore, current hypergraph transformers, a special variant of GNN, utilize semantic feature-based self-attention, ignoring topological attributes of nodes and hyperedges. To address these challenges, we propose a Topology-guided Hypergraph Transformer Network (THTN). In this model, we first formulate a hypergraph from a graph while retaining its structural essence to learn higher-order relations within the graph. Then, we design a simple yet effective structural and spatial encoding module to incorporate the topological and spatial information of the nodes into their representation. Further, we present a structure-aware self-attention mechanism that discovers the important nodes and hyperedges from both semantic and structural viewpoints. By leveraging these two modules, THTN crafts an improved node representation, capturing both local and global topological expressions. Extensive experiments conducted on node classification tasks demonstrate that the performance of the proposed model consistently exceeds that of the existing approaches.", "published": "2024-11-07 05:00:00", "id": "7203c798-7a17-4953-9fc7-46ee62c778fd", "source": "arxiv", "section": "computerScience"}, {"title": "Non-Pyrotechnic Radial Deployment Mechanism for Payloads in Sounding Rockets", "link": "https://arxiv.org/abs/2310.19673", "description": "arXiv:2310.19673v5 Announce Type: replace \nAbstract: A novel, non-pyrotechnic payload deployment mechanism tailored for sounding rockets is introduced in this research paper. The mechanism addresses the challenge of efficiently and compactly deploying payloads radially during a single launch, featuring a cylindrical carrier structure actuated by a rack-pinion mechanism. Powered by a servo motor, the carrier structure translates to enable radial ejection of payloads. The paper presents the mechanism's design and conducts a comprehensive performance analysis, including structural stability, system dynamics and power requirements. A simulation model is developed to assess payload deployment behavior under various conditions, demonstrating the mechanism's viability and efficiency for deploying multiple payloads within a single sounding rocket launch. The mechanism's adaptability to accommodate diverse payload types, sizes and weights enhances its versatility, while its radial deployment capability allows payloads to be released at different altitudes, offering greater flexibility for scientific experiments. The paper concludes that this innovative payload radial deployment mechanism represents a significant advancement in sounding rocket technology and holds promise for a wide array of applications in both scientific and commercial missions.", "published": "2024-11-07 05:00:00", "id": "3561d024-8b52-43c9-94c4-6f064d2338ec", "source": "arxiv", "section": "computerScience"}, {"title": "A Data Perspective on Enhanced Identity Preservation for Diffusion Personalization", "link": "https://arxiv.org/abs/2311.04315", "description": "arXiv:2311.04315v4 Announce Type: replace \nAbstract: Large text-to-image models have revolutionized the ability to generate imagery using natural language. However, particularly unique or personal visual concepts, such as pets and furniture, will not be captured by the original model. This has led to interest in how to personalize a text-to-image model. Despite significant progress, this task remains a formidable challenge, particularly in preserving the subject's identity. Most researchers attempt to address this issue by modifying model architectures. These methods are capable of keeping the subject structure and color but fail to preserve identity details. Towards this issue, our approach takes a data-centric perspective. We introduce a novel regularization dataset generation strategy on both the text and image level. This strategy enables the model to preserve fine details of the desired subjects, such as text and logos. Our method is architecture-agnostic and can be flexibly applied on various text-to-image models. We show on established benchmarks that our data-centric approach forms the new state of the art in terms of identity preservation and text alignment.", "published": "2024-11-07 05:00:00", "id": "2eb5c951-4965-4450-a0bb-46359c74cffb", "source": "arxiv", "section": "computerScience"}, {"title": "Continuous Management of Machine Learning-Based Application Behavior", "link": "https://arxiv.org/abs/2311.12686", "description": "arXiv:2311.12686v5 Announce Type: replace \nAbstract: Modern applications are increasingly driven by Machine Learning (ML) models whose non-deterministic behavior is affecting the entire application life cycle from design to operation. The pervasive adoption of ML is urgently calling for approaches that guarantee a stable non-functional behavior of ML-based applications over time and across model changes. To this aim, non-functional properties of ML models, such as privacy, confidentiality, fairness, and explainability, must be monitored, verified, and maintained. Existing approaches mostly focus on i) implementing solutions for classifier selection according to the functional behavior of ML models, ii) finding new algorithmic solutions, such as continuous re-training. In this paper, we propose a multi-model approach that aims to guarantee a stable non-functional behavior of ML-based applications. An architectural and methodological approach is provided to compare multiple ML models showing similar non-functional properties and select the model supporting stable non-functional behavior over time according to (dynamic and unpredictable) contextual changes. Our approach goes beyond the state of the art by providing a solution that continuously guarantees a stable non-functional behavior of ML-based applications, is ML algorithm-agnostic, and is driven by non-functional properties assessed on the ML models themselves. It consists of a two-step process working during application operation, where model assessment verifies non-functional properties of ML models trained and selected at development time, and model substitution guarantees continuous and stable support of non-functional properties. We experimentally evaluate our solution in a real-world scenario focusing on non-functional property fairness.", "published": "2024-11-07 05:00:00", "id": "cf5a38a5-8965-4dfa-8d49-8ea593a3eb7a", "source": "arxiv", "section": "computerScience"}, {"title": "Principal-Agent Problem with Third Party: Information Design from Social Planner's Perspective", "link": "https://arxiv.org/abs/2311.16959", "description": "arXiv:2311.16959v2 Announce Type: replace \nAbstract: We study the principal-agent problem with a third party that we call social planner, whose responsibility is to reconcile the conflicts of interest between the two players and induce socially optimal outcome in terms of some given social utility function. The social planner owns no contractual power but manages to control the information flow between the principal and the agent. We design a simple workflow with two stages for the social planner. In the first stage, the problem is reformulated as an optimization problem whose solution is the optimal utility profile. In the second stage, we investigate information design and show that binary-signal information structure suffices to induce the socially optimal outcome determined in the first stage. The simplicity and modularity of our method make it easy to implement in various scenarios within the principal-agent problem.", "published": "2024-11-07 05:00:00", "id": "ab26a986-a5dc-4e15-9610-b63d356efc8e", "source": "arxiv", "section": "computerScience"}, {"title": "Queueing Delay Minimization in Overloaded Networks", "link": "https://arxiv.org/abs/2312.04054", "description": "arXiv:2312.04054v2 Announce Type: replace \nAbstract: We develop link rate control policies to minimize the queueing delay of packets in overloaded networks. We show that increasing link rates does not guarantee delay reduction during overload. We consider a fluid queueing model that facilitates explicit characterization of the queueing delay of packets, and establish explicit conditions on link rates that can minimize the average and maximum queueing delay in both single-hop and multi-stage (switching) networks. These min-delay conditions require maintaining an identical ratio between the ingress and egress rates of different nodes at the same layer of the network. We term the policies that follow these conditions rate-proportional policies. We further generalize the rate-proportional policies to queue-proportional policies, which minimize the queueing delay asymptotically based on the time-varying queue length while remaining agnostic of packet arrival rates. We validate that the proposed policies lead to minimum queueing delay under various network topologies and settings, compared with benchmarks including the backpressure policy that maximizes network throughput and the max-link-rate policy that fully utilizes bandwidth. We further remark that the explicit min-delay policy design in multi-stage networks facilitates co-optimization with other metrics, such as minimizing total bandwidth, balancing link utilization and node buffer usage. This demonstrates the wider utility of our main results in data center network optimization in practice.", "published": "2024-11-07 05:00:00", "id": "deea1e97-ae29-4f6b-b717-2a8ec88a227c", "source": "arxiv", "section": "computerScience"}, {"title": "LifelongMemory: Leveraging LLMs for Answering Queries in Long-form Egocentric Videos", "link": "https://arxiv.org/abs/2312.05269", "description": "arXiv:2312.05269v3 Announce Type: replace \nAbstract: In this paper we introduce LifelongMemory, a new framework for accessing long-form egocentric videographic memory through natural language question answering and retrieval. LifelongMemory generates concise video activity descriptions of the camera wearer and leverages the zero-shot capabilities of pretrained large language models to perform reasoning over long-form video context. Furthermore, LifelongMemory uses a confidence and explanation module to produce confident, high-quality, and interpretable answers. Our approach achieves state-of-the-art performance on the EgoSchema benchmark for question answering and is highly competitive on the natural language query (NLQ) challenge of Ego4D. Code is available at https://github.com/agentic-learning-ai-lab/lifelong-memory.", "published": "2024-11-07 05:00:00", "id": "43f0e62e-de6e-4331-b718-8f1a2db83570", "source": "arxiv", "section": "computerScience"}, {"title": "Noise Distribution Decomposition based Multi-Agent Distributional Reinforcement Learning", "link": "https://arxiv.org/abs/2312.07025", "description": "arXiv:2312.07025v2 Announce Type: replace \nAbstract: Generally, Reinforcement Learning (RL) agent updates its policy by repetitively interacting with the environment, contingent on the received rewards to observed states and undertaken actions. However, the environmental disturbance, commonly leading to noisy observations (e.g., rewards and states), could significantly shape the performance of agent. Furthermore, the learning performance of Multi-Agent Reinforcement Learning (MARL) is more susceptible to noise due to the interference among intelligent agents. Therefore, it becomes imperative to revolutionize the design of MARL, so as to capably ameliorate the annoying impact of noisy rewards. In this paper, we propose a novel decomposition-based multi-agent distributional RL method by approximating the globally shared noisy reward by a Gaussian mixture model (GMM) and decomposing it into the combination of individual distributional local rewards, with which each agent can be updated locally through distributional RL. Moreover, a diffusion model (DM) is leveraged for reward generation in order to mitigate the issue of costly interaction expenditure for learning distributions. Furthermore, the optimality of the distribution decomposition is theoretically validated, while the design of loss function is carefully calibrated to avoid the decomposition ambiguity. We also verify the effectiveness of the proposed method through extensive simulation experiments with noisy rewards. Besides, different risk-sensitive policies are evaluated in order to demonstrate the superiority of distributional RL in different MARL tasks.", "published": "2024-11-07 05:00:00", "id": "e7dd66cd-4cec-4be7-9cc3-8f1fa6181867", "source": "arxiv", "section": "computerScience"}, {"title": "A dynamical clipping approach with task feedback for Proximal Policy Optimization", "link": "https://arxiv.org/abs/2312.07624", "description": "arXiv:2312.07624v3 Announce Type: replace \nAbstract: Proximal Policy Optimization (PPO) has been broadly applied to robotics learning, showcasing stable training performance. However, the fixed clipping bound setting may limit the performance of PPO. Specifically, there is no theoretical proof that the optimal clipping bound remains consistent throughout the entire training process. Meanwhile, previous researches suggest that a fixed clipping bound restricts the policy's ability to explore. Therefore, many past studies have aimed to dynamically adjust the PPO clipping bound to enhance PPO's performance. However, the objective of these approaches are not directly aligned with the objective of reinforcement learning (RL) tasks, which is to maximize the cumulative Return. Unlike previous clipping approaches, we propose a bi-level proximal policy optimization objective that can dynamically adjust the clipping bound to better reflect the preference (maximizing Return) of these RL tasks. Based on this bi-level proximal policy optimization paradigm, we introduce a new algorithm named Preference based Proximal Policy Optimization (Pb-PPO). Pb-PPO utilizes a multi-armed bandit approach to refelect RL preference, recommending the clipping bound for PPO that can maximizes the current Return. Therefore, Pb-PPO results in greater stability and improved performance compared to PPO with a fixed clipping bound. We test Pb-PPO on locomotion benchmarks across multiple environments, including Gym-Mujoco and legged-gym. Additionally, we validate Pb-PPO on customized navigation tasks. Meanwhile, we conducted comparisons with PPO using various fixed clipping bounds and various of clipping approaches. The experimental results indicate that Pb-PPO demonstrates superior training performance compared to PPO and its variants. Our codebase has been released at : https://github.com/stevezhangzA/pb_ppo", "published": "2024-11-07 05:00:00", "id": "875d0777-e163-44aa-b866-7460e77e7a8c", "source": "arxiv", "section": "computerScience"}, {"title": "Scalable Approximate Optimal Diagonal Preconditioning", "link": "https://arxiv.org/abs/2312.15594", "description": "arXiv:2312.15594v2 Announce Type: replace \nAbstract: We consider the problem of finding the optimal diagonal preconditioner for a positive definite matrix. Although this problem has been shown to be solvable and various methods have been proposed, none of the existing approaches are scalable to matrices of large dimension, or when access is limited to black-box matrix-vector products, thereby significantly limiting their practical application. In view of these challenges, we propose practical algorithms applicable to finding approximate optimal diagonal preconditioners of large sparse systems. Our approach is based on the idea of dimension reduction, and combines techniques from semi-definite programming (SDP), random projection, semi-infinite programming (SIP), and column generation. Numerical experiments demonstrate that our method scales to sparse matrices of size greater than $10^7$. Notably, our approach is efficient and implementable using only black-box matrix-vector product operations, making it highly practical for a wide variety of applications.", "published": "2024-11-07 05:00:00", "id": "470790d6-32e9-4596-86e3-7cb8483907d6", "source": "arxiv", "section": "computerScience"}, {"title": "Projected Langevin Monte Carlo algorithms in non-convex and super-linear setting", "link": "https://arxiv.org/abs/2312.17077", "description": "arXiv:2312.17077v3 Announce Type: replace \nAbstract: It is of significant interest in many applications to sample from a high-dimensional target distribution $\\pi$ with the density $\\pi(\\text{d} x) \\propto e^{-U(x)} (\\text{d} x) $, based on the temporal discretization of the Langevin stochastic differential equations (SDEs). In this paper, we propose an explicit projected Langevin Monte Carlo (PLMC) algorithm with non-convex potential $U$ and super-linear gradient of $U$ and investigate the non-asymptotic analysis of its sampling error in total variation distance. Equipped with time-independent regularity estimates for the associated Kolmogorov equation, we derive the non-asymptotic bounds on the total variation distance between the target distribution of the Langevin SDEs and the law induced by the PLMC scheme with order $\\mathcal{O}(d^{\\max\\{3\\gamma/2 , 2\\gamma-1 \\}} h |\\ln h|)$, where $d$ is the dimension of the target distribution and $\\gamma \\geq 1$ characterizes the growth of the gradient of $U$. In addition, if the gradient of $U$ is globally Lipschitz continuous, an improved convergence order of $\\mathcal{O}(d^{3/2} h)$ for the classical Langevin Monte Carlo (LMC) scheme is derived with a refinement of the proof based on Malliavin calculus techniques. To achieve a given precision $\\epsilon$, the smallest number of iterations of the PLMC algorithm is proved to be of order ${\\mathcal{O}}\\big(\\tfrac{d^{\\max\\{3\\gamma/2 , 2\\gamma-1 \\}}}{\\epsilon} \\ \\cdot \\ln (\\tfrac{d}{\\epsilon}) \\cdot \\ln (\\tfrac{1}{\\epsilon}) \\big)$. In particular, the classical Langevin Monte Carlo (LMC) scheme with the non-convex potential $U$ and the globally Lipschitz gradient of $U$ can be guaranteed by order ${\\mathcal{O}}\\big(\\tfrac{d^{3/2}}{\\epsilon} \\cdot \\ln (\\tfrac{1}{\\epsilon}) \\big)$. Numerical experiments are provided to confirm the theoretical findings.", "published": "2024-11-07 05:00:00", "id": "35ada491-259e-46eb-9749-d7868490aac5", "source": "arxiv", "section": "computerScience"}, {"title": "ConfusionPrompt: Practical Private Inference for Online Large Language Models", "link": "https://arxiv.org/abs/2401.00870", "description": "arXiv:2401.00870v4 Announce Type: replace \nAbstract: State-of-the-art large language models (LLMs) are typically deployed as online services, requiring users to transmit detailed prompts to cloud servers. This raises significant privacy concerns. In response, we introduce ConfusionPrompt, a novel framework for private LLM inference that protects user privacy by: (i) decomposing the original prompt into smaller sub-prompts, and (ii) generating pseudo-prompts alongside the genuine sub-prompts, which are then sent to the LLM. The server responses are later recomposed by the user to reconstruct the final output. This approach offers key advantages over previous LLM privacy protection methods: (i) it integrates seamlessly with existing black-box LLMs, and (ii) it delivers a significantly improved privacy-utility trade-off compared to existing text perturbation methods. We also develop a $(\\lambda, \\mu, \\rho)$-privacy model to formulate the requirements for a privacy-preserving group of prompts and provide a complexity analysis to justify the role of prompt decomposition. Our empirical evaluation shows that ConfusionPrompt achieves significantly higher utility than local inference methods using open-source models and perturbation-based techniques, while also reducing memory consumption compared to open-source LLMs.", "published": "2024-11-07 05:00:00", "id": "44498af0-5e9a-497b-9e9b-d6a25440ca49", "source": "arxiv", "section": "computerScience"}, {"title": "Three classes of propagation rules for generalized Reed-Solomon codes and their applications to EAQECCs", "link": "https://arxiv.org/abs/2401.08195", "description": "arXiv:2401.08195v2 Announce Type: replace \nAbstract: In this paper, we study the Hermitian hulls of generalized Reed-Solomon (GRS) codes over finite fields. For a given class of GRS codes, by extending the length, increasing the dimension, and extending the length and increasing the dimension at the same time, we obtain three classes of GRS codes with Hermitian hulls of arbitrary dimensions. Furthermore, based on some known $q^2$-ary Hermitian self-orthogonal GRS codes with dimension $q-1$, we obtain several classes of $q^2$-ary maximum distance separable (MDS) codes with Hermitian hulls of arbitrary dimensions. It is worth noting that the dimension of these MDS codes can be taken from $q$ to $\\frac{n}{2}$, and the parameters of these MDS codes can be more flexible by propagation rules. As an application, we derive three new propagation rules for MDS entanglement-assisted quantum error correction codes (EAQECCs) constructed from GRS codes. Then, from the presently known GRS codes with Hermitian hulls, we can directly obtain many MDS EAQECCs with more flexible parameters. Finally, we present several new classes of (MDS) EAQECCs with flexible parameters, and the distance of these codes can be taken from $q+1$ to $\\frac{n+2}{2}$.", "published": "2024-11-07 05:00:00", "id": "1fca527c-72cd-4d89-a7dd-f042610a56fa", "source": "arxiv", "section": "computerScience"}, {"title": "GD doesn't make the cut: Three ways that non-differentiability affects neural network training", "link": "https://arxiv.org/abs/2401.08426", "description": "arXiv:2401.08426v4 Announce Type: replace \nAbstract: This paper investigates the distinctions between gradient methods applied to non-differentiable functions (NGDMs) and classical gradient descents (GDs) designed for differentiable functions. First, we demonstrate significant differences in the convergence properties of NGDMs compared to GDs, challenging the applicability of the extensive neural network convergence literature based on $L-smoothness$ to non-smooth neural networks. Next, we demonstrate the paradoxical nature of NGDM solutions for $L_{1}$-regularized problems, showing that increasing the regularization penalty leads to an increase in the $L_{1}$ norm of optimal solutions in NGDMs. Consequently, we show that widely adopted $L_{1}$ penalization-based techniques for network pruning do not yield expected results. Additionally, we dispel the common belief that optimization algorithms like Adam and RMSProp perform similarly in non-differentiable contexts. Finally, we explore the Edge of Stability phenomenon, indicating its inapplicability even to Lipschitz continuous convex differentiable functions, leaving its relevance to non-convex non-differentiable neural networks inconclusive. Our analysis exposes misguided interpretations of NGDMs in widely referenced papers and texts due to an overreliance on strong smoothness assumptions, emphasizing the necessity for a nuanced understanding of foundational assumptions in the analysis of these systems.", "published": "2024-11-07 05:00:00", "id": "57e1a04e-f6dd-44d9-bac1-d1e4f7362def", "source": "arxiv", "section": "computerScience"}, {"title": "Learning with Geometry: Including Riemannian Geometric Features in Coefficient of Pressure Prediction on Aircraft Wings", "link": "https://arxiv.org/abs/2401.09452", "description": "arXiv:2401.09452v2 Announce Type: replace \nAbstract: We propose to incorporate Riemannian geometric features from the geometry of aircraft wing surfaces in the prediction of coefficient of pressure (CP) on the aircraft wing. Contrary to existing approaches that treat the wing surface as a flat object, we represent the wing as a piecewise smooth manifold and calculate a set of Riemannian geometric features (Riemannian metric, connection, and curvature) over points of the wing. Combining these features in neighborhoods of points on the wing with coordinates and flight conditions gives inputs to a deep learning model that predicts CP distributions. Experimental results show that the method with incorporation of Riemannian geometric features, compared to state-of-the-art Deep Attention Network (DAN), reduces the predicted mean square error (MSE) of CP by an average of 15.00% for the DLR-F11 aircraft test set.", "published": "2024-11-07 05:00:00", "id": "2b2fc2f9-3452-490e-900f-163dc39e842f", "source": "arxiv", "section": "computerScience"}, {"title": "Cross-Task Affinity Learning for Multitask Dense Scene Predictions", "link": "https://arxiv.org/abs/2401.11124", "description": "arXiv:2401.11124v2 Announce Type: replace \nAbstract: Multitask learning (MTL) has become prominent for its ability to predict multiple tasks jointly, achieving better per-task performance with fewer parameters than single-task learning. Recently, decoder-focused architectures have significantly improved multitask performance by refining task predictions using features from related tasks. However, most refinement methods struggle to efficiently capture both local and long-range dependencies between task-specific representations and cross-task patterns. In this paper, we introduce the Cross-Task Affinity Learning (CTAL) module, a lightweight framework that enhances task refinement in multitask networks. CTAL effectively captures local and long-range cross-task interactions by optimizing task affinity matrices for parameter-efficient grouped convolutions without concern for information loss. Our results demonstrate state-of-the-art MTL performance for both CNN and transformer backbones, using significantly fewer parameters than single-task learning. Our code is publicly available at https://github.com/Armanfard-Lab/EMA-Net.", "published": "2024-11-07 05:00:00", "id": "f64133a4-80f1-4313-aed7-53092b70d866", "source": "arxiv", "section": "computerScience"}, {"title": "CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray Report Labeling", "link": "https://arxiv.org/abs/2401.11505", "description": "arXiv:2401.11505v2 Announce Type: replace \nAbstract: Free-text radiology reports present a rich data source for various medical tasks, but effectively labeling these texts remains challenging. Traditional rule-based labeling methods fall short of capturing the nuances of diverse free-text patterns. Moreover, models using expert-annotated data are limited by data scarcity and pre-defined classes, impacting their performance, flexibility and scalability. To address these issues, our study offers three main contributions: 1) We demonstrate the potential of GPT as an adept labeler using carefully designed prompts. 2) Utilizing only the data labeled by GPT, we trained a BERT-based labeler, CheX-GPT, which operates faster and more efficiently than its GPT counterpart. 3) To benchmark labeler performance, we introduced a publicly available expert-annotated test set, MIMIC-500, comprising 500 cases from the MIMIC validation set. Our findings demonstrate that CheX-GPT not only excels in labeling accuracy over existing models, but also showcases superior efficiency, flexibility, and scalability, supported by our introduction of the MIMIC-500 dataset for robust benchmarking. Code and models are available at https://github.com/Soombit-ai/CheXGPT.", "published": "2024-11-07 05:00:00", "id": "a8e45171-ec30-46da-a671-d989b19a5113", "source": "arxiv", "section": "computerScience"}, {"title": "Indirect Lossy Source Coding with Observed Source Reconstruction: Nonasymptotic Bounds and Second-Order Asymptotics", "link": "https://arxiv.org/abs/2401.14962", "description": "arXiv:2401.14962v5 Announce Type: replace \nAbstract: This paper considers the joint compression of a pair of correlated sources, where the encoder is allowed to access only one of the sources. The objective is to recover both sources under separate distortion constraints for each source while minimizing the rate. This problem generalizes the indirect lossy source coding problem by also requiring the recovery of the observed source. In this paper, we aim to study the nonasymptotic and second-order asymptotic properties of this problem. Specifically, we begin by deriving nonasymptotic achievability and converse bounds valid for general sources and distortion measures. The source dispersion (Gaussian approximation) is then determined through asymptotic analysis of the nonasymptotic bounds. We further examine the case of erased fair coin flips (EFCF) and provide its specific nonasymptotic achievability and converse bounds. Numerical results under the EFCF case demonstrate that our second-order asymptotic approximation closely approximates the optimum rate at appropriately large blocklengths.", "published": "2024-11-07 05:00:00", "id": "a24f958e-d6ac-4ffd-a1f0-7a4502db4a2e", "source": "arxiv", "section": "computerScience"}, {"title": "Scalable Network Emulation on Analog Neuromorphic Hardware", "link": "https://arxiv.org/abs/2401.16840", "description": "arXiv:2401.16840v2 Announce Type: replace \nAbstract: We present a novel software feature for the BrainScaleS-2 accelerated neuromorphic platform that facilitates the partitioned emulation of large-scale spiking neural networks. This approach is well suited for deep spiking neural networks and allows for sequential model emulation on undersized neuromorphic resources if the largest recurrent subnetwork and the required neuron fan-in fit on the substrate. The ability to emulate and train networks larger than the substrate provides a pathway for accurate performance evaluation in planned or scaled systems, ultimately advancing the development and understanding of large-scale models and neuromorphic computing architectures. We demonstrate the training of two deep spiking neural network models -- using the MNIST and EuroSAT datasets -- that exceed the physical size constraints of a single-chip BrainScaleS-2 system.", "published": "2024-11-07 05:00:00", "id": "d3b07346-b319-4f94-bc15-4a5bae4e08db", "source": "arxiv", "section": "computerScience"}, {"title": "Deep Learning Based Amharic Chatbot for FAQs in Universities", "link": "https://arxiv.org/abs/2402.01720", "description": "arXiv:2402.01720v2 Announce Type: replace \nAbstract: University students often spend a considerable amount of time seeking answers to common questions from administrators or teachers. This can become tedious for both parties, leading to a need for a solution. In response, this paper proposes a chatbot model that utilizes natural language processing and deep learning techniques to answer frequently asked questions (FAQs) in the Amharic language. Chatbots are computer programs that simulate human conversation through the use of artificial intelligence (AI), acting as a virtual assistant to handle questions and other tasks. The proposed chatbot program employs tokenization, normalization, stop word removal, and stemming to analyze and categorize Amharic input sentences. Three machine learning model algorithms were used to classify tokens and retrieve appropriate responses: Support Vector Machine (SVM), Multinomial Na\\\"ive Bayes, and deep neural networks implemented through TensorFlow, Keras, and NLTK. The deep learning model achieved the best results with 91.55% accuracy and a validation loss of 0.3548 using an Adam optimizer and SoftMax activation function. The chatbot model was integrated with Facebook Messenger and deployed on a Heroku server for 24-hour accessibility. The experimental results demonstrate that the chatbot framework achieved its objectives and effectively addressed challenges such as Amharic Fidel variation, morphological variation, and lexical gaps. Future research could explore the integration of Amharic WordNet to narrow the lexical gap and support more complex questions.", "published": "2024-11-07 05:00:00", "id": "6078b41a-ab1e-4997-a73d-3849b7932d40", "source": "arxiv", "section": "computerScience"}, {"title": "DexDiffuser: Generating Dexterous Grasps with Diffusion Models", "link": "https://arxiv.org/abs/2402.02989", "description": "arXiv:2402.02989v3 Announce Type: replace \nAbstract: We introduce DexDiffuser, a novel dexterous grasping method that generates, evaluates, and refines grasps on partial object point clouds. DexDiffuser includes the conditional diffusion-based grasp sampler DexSampler and the dexterous grasp evaluator DexEvaluator. DexSampler generates high-quality grasps conditioned on object point clouds by iterative denoising of randomly sampled grasps. We also introduce two grasp refinement strategies: Evaluator-Guided Diffusion (EGD) and Evaluator-based Sampling Refinement (ESR). The experiment results demonstrate that DexDiffuser consistently outperforms the state-of-the-art multi-finger grasp generation method FFHNet with an, on average, 9.12% and 19.44% higher grasp success rate in simulation and real robot experiments, respectively. Supplementary materials are available at https://yulihn.github.io/DexDiffuser_page/", "published": "2024-11-07 05:00:00", "id": "0ce010db-9396-4e66-b7b7-ed66da582fe9", "source": "arxiv", "section": "computerScience"}, {"title": "Whispers in the Machine: Confidentiality in LLM-integrated Systems", "link": "https://arxiv.org/abs/2402.06922", "description": "arXiv:2402.06922v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) are increasingly augmented with external tools and commercial services into LLM-integrated systems. While these interfaces can significantly enhance the capabilities of the models, they also introduce a new attack surface. Manipulated integrations, for example, can exploit the model and compromise sensitive data accessed through other interfaces. While previous work primarily focused on attacks targeting a model's alignment or the leakage of training data, the security of data that is only available during inference has escaped scrutiny so far. In this work, we demonstrate the vulnerabilities associated with external components and introduce a systematic approach to evaluate confidentiality risks in LLM-integrated systems. We identify two specific attack scenarios unique to these systems and formalize these into a tool-robustness framework designed to measure a model's ability to protect sensitive information. Our findings show that all examined models are highly vulnerable to confidentiality attacks, with the risk increasing significantly when models are used together with external tools.", "published": "2024-11-07 05:00:00", "id": "a0235025-f4c5-4a9d-9a46-c4eb498999a9", "source": "arxiv", "section": "computerScience"}, {"title": "LDTrack: Dynamic People Tracking by Service Robots using Diffusion Models", "link": "https://arxiv.org/abs/2402.08774", "description": "arXiv:2402.08774v3 Announce Type: replace \nAbstract: Tracking of dynamic people in cluttered and crowded human-centered environments is a challenging robotics problem due to the presence of intraclass variations including occlusions, pose deformations, and lighting variations. This paper introduces a novel deep learning architecture, using conditional latent diffusion models, the Latent Diffusion Track (LDTrack), for tracking multiple dynamic people under intraclass variations. By uniquely utilizing conditional latent diffusion models to capture temporal person embeddings, our architecture can adapt to appearance changes of people over time. We incorporated a latent feature encoder network which enables the diffusion process to operate within a high-dimensional latent space to allow for the extraction and spatial-temporal refinement of such rich features as person appearance, motion, location, identity, and contextual information. Extensive experiments demonstrate the effectiveness of LDTrack over other state-of-the-art tracking methods in cluttered and crowded human-centered environments under intraclass variations. Namely, the results show our method outperforms existing deep learning robotic people tracking methods in both tracking accuracy and tracking precision with statistical significance. Additionally, a comprehensive multi-object tracking comparison study was performed against the state-of-the-art methods in urban environments, demonstrating the generalizability of LDTrack. An ablation study was performed to validate the design choices of LDTrack.", "published": "2024-11-07 05:00:00", "id": "88bd3f0c-7f3f-46d9-9579-0b68ac35f21c", "source": "arxiv", "section": "computerScience"}, {"title": "Opening the Black-Box: A Systematic Review on Explainable AI in Remote Sensing", "link": "https://arxiv.org/abs/2402.13791", "description": "arXiv:2402.13791v2 Announce Type: replace \nAbstract: In recent years, black-box machine learning approaches have become a dominant modeling paradigm for knowledge extraction in remote sensing. Despite the potential benefits of uncovering the inner workings of these models with explainable AI, a comprehensive overview summarizing the explainable AI methods used and their objectives, findings, and challenges in remote sensing applications is still missing. In this paper, we address this gap by performing a systematic review to identify the key trends in the field and shed light on novel explainable AI approaches and emerging directions that tackle specific remote sensing challenges. We also reveal the common patterns of explanation interpretation, discuss the extracted scientific insights, and reflect on the approaches used for the evaluation of explainable AI methods. As such, our review provides a complete summary of the state-of-the-art of explainable AI in remote sensing. Further, we give a detailed outlook on the challenges and promising research directions, representing a basis for novel methodological development and a useful starting point for new researchers in the field.", "published": "2024-11-07 05:00:00", "id": "7fa870d6-2ee5-4beb-a781-08af9da6fbb2", "source": "arxiv", "section": "computerScience"}, {"title": "DropBP: Accelerating Fine-Tuning of Large Language Models by Dropping Backward Propagation", "link": "https://arxiv.org/abs/2402.17812", "description": "arXiv:2402.17812v2 Announce Type: replace \nAbstract: Large language models (LLMs) have achieved significant success across various domains. However, training these LLMs typically involves substantial memory and computational costs during both forward and backward propagation. While parameter-efficient fine-tuning (PEFT) considerably reduces the training memory associated with parameters, it does not address the significant computational costs and activation memory. In this paper, we propose Dropping Backward Propagation (DropBP), a novel approach designed to reduce computational costs and activation memory while maintaining accuracy. DropBP randomly drops layers during backward propagation, which is essentially equivalent to training shallow submodules generated by undropped layers and residual connections. Additionally, DropBP calculates the sensitivity of each layer to assign an appropriate drop rate, thereby stabilizing the training process. DropBP is not only applicable to full fine-tuning but can also be orthogonally integrated with all types of PEFT by dropping layers during backward propagation. Specifically, DropBP can reduce training time by 44% with comparable accuracy to the baseline, accelerate convergence to the same perplexity by 1.5x, and enable training with a sequence length 6.2x larger on a single NVIDIA-A100 GPU. Furthermore, our DropBP enabled a throughput increase of 79% on a NVIDIA A100 GPU and 117% on an Intel Gaudi2 HPU. The code is available at https://github.com/WooSunghyeon/dropbp.", "published": "2024-11-07 05:00:00", "id": "899dcb87-b969-4158-aade-22c6323e80c8", "source": "arxiv", "section": "computerScience"}, {"title": "EncodingNet: A Novel Encoding-based MAC Design for Efficient Neural Network Acceleration", "link": "https://arxiv.org/abs/2402.18595", "description": "arXiv:2402.18595v2 Announce Type: replace \nAbstract: Deep neural networks (DNNs) have achieved great breakthroughs in many fields such as image classification and natural language processing. However, the execution of DNNs needs to conduct massive numbers of multiply-accumulate (MAC) operations on hardware and thus incurs a large power consumption. To address this challenge, we propose a novel digital MAC design based on encoding. In this new design, the multipliers are replaced by simple logic gates to represent the results with a wide bit representation. The outputs of the new multipliers are added by bit-wise weighted accumulation and the accumulation results are compatible with existing computing platforms accelerating neural networks. Since the multiplication function is replaced by a simple logic representation, the critical paths in the resulting circuits become much shorter. Correspondingly, pipelining stages and intermediate registers used to store partial sums in the MAC array can be reduced, leading to a significantly smaller area as well as better power efficiency. The proposed design has been synthesized and verified by ResNet18- Cifar10, ResNet20-Cifar100, ResNet50-ImageNet, MobileNetV2-Cifar10, MobileNetV2-Cifar100, and EfficientNetB0-ImageNet. The experimental results confirmed the reduction of circuit area by up to 48.79% and the reduction of power consumption of executing DNNs by up to 64.41%, while the accuracy of the neural networks can still be well maintained. The open source code of this work can be found on GitHub with link https://github.com/Bo-Liu-TUM/EncodingNet/.", "published": "2024-11-07 05:00:00", "id": "cb4fa99e-375b-4e19-94f6-c852e4e69a03", "source": "arxiv", "section": "computerScience"}, {"title": "Tree-Averaging Algorithms for Ensemble-Based Unsupervised Discontinuous Constituency Parsing", "link": "https://arxiv.org/abs/2403.00143", "description": "arXiv:2403.00143v2 Announce Type: replace \nAbstract: We address unsupervised discontinuous constituency parsing, where we observe a high variance in the performance of the only previous model in the literature. We propose to build an ensemble of different runs of the existing discontinuous parser by averaging the predicted trees, to stabilize and boost performance. To begin with, we provide comprehensive computational complexity analysis (in terms of P and NP-complete) for tree averaging under different setups of binarity and continuity. We then develop an efficient exact algorithm to tackle the task, which runs in a reasonable time for all samples in our experiments. Results on three datasets show our method outperforms all baselines in all metrics; we also provide in-depth analyses of our approach.", "published": "2024-11-07 05:00:00", "id": "b78ac1e7-5a1c-4ab1-87b5-2425fdfe6d98", "source": "arxiv", "section": "computerScience"}, {"title": "SynCode: LLM Generation with Grammar Augmentation", "link": "https://arxiv.org/abs/2403.01632", "description": "arXiv:2403.01632v4 Announce Type: replace \nAbstract: LLMs are widely used in complex AI applications. These applications underscore the need for LLM outputs to adhere to a specific format, for their integration with other components in the systems. Typically the format rules e.g., for data serialization formats such as JSON, YAML, or Code in Programming Language are expressed as context-free grammar (CFG). Due to the hallucinations and unreliability of LLMs, instructing LLMs to adhere to specified syntax becomes an increasingly important challenge.\n  We present SynCode, a novel framework for efficient and general syntactical decoding with LLMs, to address this challenge. SynCode ensures soundness and completeness with respect to the CFG of a formal language, effectively retaining valid tokens while filtering out invalid ones. SynCode uses an offline-constructed, efficient lookup table, the DFA mask store, derived from the DFA of the language's grammar for efficient generation. SynCode seamlessly integrates with any language defined by CFG, as evidenced by experiments focusing on generating JSON, Python, and Go outputs. Our experiments evaluating the effectiveness of SynCode for JSON generation demonstrate that SynCode eliminates all syntax errors and significantly outperforms state-of-the-art baselines. Furthermore, our results underscore how SynCode significantly reduces 96.07% of syntax errors in generated Python and Go code, showcasing its substantial impact on enhancing syntactical precision in LLM generation. Our code is available at https://github.com/uiuc-focal-lab/syncode", "published": "2024-11-07 05:00:00", "id": "355a4572-84ad-411e-bd07-b809cec4fe29", "source": "arxiv", "section": "computerScience"}, {"title": "Policy Mirror Descent with Lookahead", "link": "https://arxiv.org/abs/2403.14156", "description": "arXiv:2403.14156v3 Announce Type: replace \nAbstract: Policy Mirror Descent (PMD) stands as a versatile algorithmic framework encompassing several seminal policy gradient algorithms such as natural policy gradient, with connections with state-of-the-art reinforcement learning (RL) algorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration algorithm implementing regularized 1-step greedy policy improvement. However, 1-step greedy policies might not be the best choice and recent remarkable empirical successes in RL such as AlphaGo and AlphaZero have demonstrated that greedy approaches with respect to multiple steps outperform their 1-step counterpart. In this work, we propose a new class of PMD algorithms called $h$-PMD which incorporates multi-step greedy policy improvement with lookahead depth $h$ to the PMD update rule. To solve discounted infinite horizon Markov Decision Processes with discount factor $\\gamma$, we show that $h$-PMD which generalizes the standard PMD enjoys a faster dimension-free $\\gamma^h$-linear convergence rate, contingent on the computation of multi-step greedy policies. We propose an inexact version of $h$-PMD where lookahead action values are estimated. Under a generative model, we establish a sample complexity for $h$-PMD which improves over prior work. Finally, we extend our result to linear function approximation to scale to large state spaces. Under suitable assumptions, our sample complexity only involves dependence on the dimension of the feature map space instead of the state space size.", "published": "2024-11-07 05:00:00", "id": "fc0d337c-50d1-4c37-9672-3a0b0163b455", "source": "arxiv", "section": "computerScience"}, {"title": "Initialisation and Network Effects in Decentralised Federated Learning", "link": "https://arxiv.org/abs/2403.15855", "description": "arXiv:2403.15855v3 Announce Type: replace \nAbstract: Fully decentralised federated learning enables collaborative training of individual machine learning models on a distributed network of communicating devices while keeping the training data localised on each node. This approach avoids central coordination, enhances data privacy and eliminates the risk of a single point of failure. Our research highlights that the effectiveness of decentralised federated learning is significantly influenced by the network topology of connected devices and the learning models' initial conditions. We propose a strategy for uncoordinated initialisation of the artificial neural networks based on the distribution of eigenvector centralities of the underlying communication network, leading to a radically improved training efficiency. Additionally, our study explores the scaling behaviour and the choice of environmental parameters under our proposed initialisation strategy. This work paves the way for more efficient and scalable artificial neural network training in a distributed and uncoordinated environment, offering a deeper understanding of the intertwining roles of network structure and learning dynamics.", "published": "2024-11-07 05:00:00", "id": "31a5c1a1-51a2-4c98-bff5-ade39a461218", "source": "arxiv", "section": "computerScience"}, {"title": "A Semi-Lagrangian Approach for Time and Energy Path Planning Optimization in Static Flow Fields", "link": "https://arxiv.org/abs/2403.16859", "description": "arXiv:2403.16859v3 Announce Type: replace \nAbstract: Efficient path planning for autonomous mobile robots is a critical problem across numerous domains, where optimizing both time and energy consumption is paramount. This paper introduces a novel methodology that considers the dynamic influence of an environmental flow field and considers geometric constraints, including obstacles and forbidden zones, enriching the complexity of the planning problem. We formulate it as a multi-objective optimal control problem, propose a novel transformation called Harmonic Transformation, and apply a semi-Lagrangian scheme to solve it. The set of Pareto efficient solutions is obtained considering two distinct approaches: a deterministic method and an evolutionary-based one, both of which are designed to make use of the proposed Harmonic Transformation. Through an extensive analysis of these approaches, we demonstrate their efficacy in finding optimized paths.", "published": "2024-11-07 05:00:00", "id": "78897b3e-9375-48b8-a50f-5718128239ab", "source": "arxiv", "section": "computerScience"}, {"title": "First-order (coarse) correlated equilibria in non-concave games", "link": "https://arxiv.org/abs/2403.18174", "description": "arXiv:2403.18174v2 Announce Type: replace \nAbstract: We investigate first-order notions of correlated equilibria; distributions of actions for smooth, potentially non-concave games such that players do not incur any regret against small modifications to their strategies along a set of continuous vector fields. We define two such notions, based on local deviations and on stationarity of the distribution, and identify the notion of coarseness as the setting where the associated vector fields are in fact gradient fields. For coarse equilibria, we prove that online (projected) gradient decent has a universal approximation property for both variants of equilibrium. In the non-coarse setting, we instead reduce the problem of finding an equilibrium to fixed-point computation via the usual framework of $\\Phi$-regret minimisation, and identify tractable instances. Finally, we study the primal-dual framework to our notion of first-order equilibria. For coarse equilibria defined by a family of functions, we find that a dual bound on the worst-case expectation of a performance metric takes the form of a generalised Lyapunov function for the dynamics of the game. Specifically, usual primal-dual price of anarchy analysis for coarse correlated equilibria as well as the smoothness framework of Roughgarden are both equivalent to a problem of general Lyapunov function estimation. For non-coarse equilibria, we instead observe a vector field fit problem for the gradient dynamics of the game. These follow from containment results in normal form games; the usual notion of a (coarse) correlated equilibria is equivalent to our first-order local notions of (coarse) correlated equilibria with respect to an appropriately chosen set of vector fields.", "published": "2024-11-07 05:00:00", "id": "1581ed9f-b5a1-4999-8d7e-7820a27a6364", "source": "arxiv", "section": "computerScience"}, {"title": "DeNetDM: Debiasing by Network Depth Modulation", "link": "https://arxiv.org/abs/2403.19863", "description": "arXiv:2403.19863v4 Announce Type: replace \nAbstract: Neural networks trained on biased datasets tend to inadvertently learn spurious correlations, hindering generalization. We formally prove that (1) samples that exhibit spurious correlations lie on a lower rank manifold relative to the ones that do not; and (2) the depth of a network acts as an implicit regularizer on the rank of the attribute subspace that is encoded in its representations. Leveraging these insights, we present DeNetDM, a novel debiasing method that uses network depth modulation as a way of developing robustness to spurious correlations. Using a training paradigm derived from Product of Experts, we create both biased and debiased branches with deep and shallow architectures and then distill knowledge to produce the target debiased model. Our method requires no bias annotations or explicit data augmentation while performing on par with approaches that require either or both. We demonstrate that DeNetDM outperforms existing debiasing techniques on both synthetic and real-world datasets by 5\\%. The project page is available at https://vssilpa.github.io/denetdm/.", "published": "2024-11-07 05:00:00", "id": "80de8c26-1169-4462-975d-11f4f6230bbe", "source": "arxiv", "section": "computerScience"}, {"title": "VHM: Versatile and Honest Vision Language Model for Remote Sensing Image Analysis", "link": "https://arxiv.org/abs/2403.20213", "description": "arXiv:2403.20213v3 Announce Type: replace \nAbstract: This paper develops a Versatile and Honest vision language Model (VHM) for remote sensing image analysis. VHM is built on a large-scale remote sensing image-text dataset with rich-content captions (VersaD), and an honest instruction dataset comprising both factual and deceptive questions (HnstD). Unlike prevailing remote sensing image-text datasets, in which image captions focus on a few prominent objects and their relationships, VersaD captions provide detailed information about image properties, object attributes, and the overall scene. This comprehensive captioning enables VHM to thoroughly understand remote sensing images and perform diverse remote sensing tasks. Moreover, different from existing remote sensing instruction datasets that only include factual questions, HnstD contains additional deceptive questions stemming from the non-existence of objects. This feature prevents VHM from producing affirmative answers to nonsense queries, thereby ensuring its honesty. In our experiments, VHM significantly outperforms various vision language models on common tasks of scene classification, visual question answering, and visual grounding. Additionally, VHM achieves competent performance on several unexplored tasks, such as building vectorizing, multi-label classification and honest question answering. We will release the code, data and model weights at https://github.com/opendatalab/VHM .", "published": "2024-11-07 05:00:00", "id": "2ed0cfb7-bf59-4799-937d-0f72f2d2ade5", "source": "arxiv", "section": "computerScience"}, {"title": "The Fine Line: Navigating Large Language Model Pretraining with Down-streaming Capability Analysis", "link": "https://arxiv.org/abs/2404.01204", "description": "arXiv:2404.01204v3 Announce Type: replace \nAbstract: Uncovering early-stage metrics that reflect final model performance is one core principle for large-scale pretraining. The existing scaling law demonstrates the power-law correlation between pretraining loss and training flops, which serves as an important indicator of the current training state for large language models. However, this principle only focuses on the model's compression properties on the training data, resulting in an inconsistency with the ability improvements on the downstream tasks. Some follow-up works attempted to extend the scaling-law to more complex metrics (such as hyperparameters), but still lacked a comprehensive analysis of the dynamic differences among various capabilities during pretraining. To address the aforementioned limitations, this paper undertakes a comprehensive comparison of model capabilities at various pretraining intermediate checkpoints. Through this analysis, we confirm that specific downstream metrics exhibit similar training dynamics across models of different sizes, up to 67 billion parameters. In addition to our core findings, we've reproduced Amber and OpenLLaMA, releasing their intermediate checkpoints. This initiative offers valuable resources to the research community and facilitates the verification and exploration of LLM pretraining by open-source researchers. Besides, we provide empirical summaries, including performance comparisons of different models and capabilities, and tuition of key metrics for different training phases. Based on these findings, we provide a more user-friendly strategy for evaluating the optimization state, offering guidance for establishing a stable pretraining process.", "published": "2024-11-07 05:00:00", "id": "4cb3c45a-85ec-4805-bea2-6c8ca6cf7ecc", "source": "arxiv", "section": "computerScience"}, {"title": "From Similarity to Superiority: Channel Clustering for Time Series Forecasting", "link": "https://arxiv.org/abs/2404.01340", "description": "arXiv:2404.01340v2 Announce Type: replace \nAbstract: Time series forecasting has attracted significant attention in recent decades. Previous studies have demonstrated that the Channel-Independent (CI) strategy improves forecasting performance by treating different channels individually, while it leads to poor generalization on unseen instances and ignores potentially necessary interactions between channels. Conversely, the Channel-Dependent (CD) strategy mixes all channels with even irrelevant and indiscriminate information, which, however, results in oversmoothing issues and limits forecasting accuracy. There is a lack of channel strategy that effectively balances individual channel treatment for improved forecasting performance without overlooking essential interactions between channels. Motivated by our observation of a correlation between the time series model's performance boost against channel mixing and the intrinsic similarity on a pair of channels, we developed a novel and adaptable Channel Clustering Module (CCM). CCM dynamically groups channels characterized by intrinsic similarities and leverages cluster information instead of individual channel identities, combining the best of CD and CI worlds. Extensive experiments on real-world datasets demonstrate that CCM can (1) boost the performance of CI and CD models by an average margin of 2.4% and 7.2% on long-term and short-term forecasting, respectively; (2) enable zero-shot forecasting with mainstream time series forecasting models; (3) uncover intrinsic time series patterns among channels and improve interpretability of complex time series models.", "published": "2024-11-07 05:00:00", "id": "087ee005-2219-48e0-ac05-92b3f06428d5", "source": "arxiv", "section": "computerScience"}, {"title": "Transformers as Transducers", "link": "https://arxiv.org/abs/2404.02040", "description": "arXiv:2404.02040v3 Announce Type: replace \nAbstract: We study the sequence-to-sequence mapping capacity of transformers by relating them to finite transducers, and find that they can express surprisingly large classes of transductions. We do so using variants of RASP, a programming language designed to help people \"think like transformers,\" as an intermediate representation. We extend the existing Boolean variant B-RASP to sequence-to-sequence functions and show that it computes exactly the first-order rational functions (such as string rotation). Then, we introduce two new extensions. B-RASP[pos] enables calculations on positions (such as copying the first half of a string) and contains all first-order regular functions. S-RASP adds prefix sum, which enables additional arithmetic operations (such as squaring a string) and contains all first-order polyregular functions. Finally, we show that masked average-hard attention transformers can simulate S-RASP.", "published": "2024-11-07 05:00:00", "id": "d3cd48de-d2e6-4f70-b795-574d77bb0cf3", "source": "arxiv", "section": "computerScience"}, {"title": "OmniGS: Fast Radiance Field Reconstruction using Omnidirectional Gaussian Splatting", "link": "https://arxiv.org/abs/2404.03202", "description": "arXiv:2404.03202v5 Announce Type: replace \nAbstract: Photorealistic reconstruction relying on 3D Gaussian Splatting has shown promising potential in various domains. However, the current 3D Gaussian Splatting system only supports radiance field reconstruction using undistorted perspective images. In this paper, we present OmniGS, a novel omnidirectional Gaussian splatting system, to take advantage of omnidirectional images for fast radiance field reconstruction. Specifically, we conduct a theoretical analysis of spherical camera model derivatives in 3D Gaussian Splatting. According to the derivatives, we then implement a new GPU-accelerated omnidirectional rasterizer that directly splats 3D Gaussians onto the equirectangular screen space for omnidirectional image rendering. We realize differentiable optimization of the omnidirectional radiance field without the requirement of cube-map rectification or tangent-plane approximation. Extensive experiments conducted in egocentric and roaming scenarios demonstrate that our method achieves state-of-the-art reconstruction quality and high rendering speed using omnidirectional images. The code will be publicly available.", "published": "2024-11-07 05:00:00", "id": "15858413-b47a-44db-9e53-e95c1f3918c7", "source": "arxiv", "section": "computerScience"}, {"title": "A mean correction for improved phase-averaging accuracy in oscillatory, multiscale, differential equations", "link": "https://arxiv.org/abs/2404.03964", "description": "arXiv:2404.03964v2 Announce Type: replace \nAbstract: This paper introduces a new algorithm to improve the accuracy of numerical phase-averaging in oscillatory, multiscale, differential equations. Phase-averaging is a timestepping method which averages a mapped variable to remove highly oscillatory linear terms from the differential equation. This retains the main contribution of fast waves on the low frequencies without explicitly resolving the rapid oscillations. However, this comes at the cost of introducing an averaging error. To offset this, we propose a modified mapping that includes a mean correction term encoding an average measure of the nonlinear interactions. This mapping was introduced in Tao (2019) for weak nonlinearity and relied on classical time-averaging, which leaves only the zero frequencies. Our algorithm instead considers mean corrected phase-averaging when 1) the nonlinearity is not weak but the linear oscillations are fast and 2) finite averaging windows are applied via a smooth kernel, which has the advantage of retaining low frequencies whilst still eliminating the fastest oscillations. In particular, we introduce a local mean correction that combines the concepts of a mean correction and finite averaging; this retains low-frequency components in the mean correction that are removed with classical time-averaging. We show that the new timestepping algorithm reduces phase errors in the mapped variable for the swinging spring ODE in various dynamical configurations. We also show accuracy improvements with a local mean correction compared to standard phase-averaging in the one-dimensional rotating shallow water equations, a useful test case for weather and climate applications.", "published": "2024-11-07 05:00:00", "id": "ab56e73a-af94-42ba-bb16-926ff6fe502e", "source": "arxiv", "section": "computerScience"}, {"title": "Concept-Attention Whitening for Interpretable Skin Lesion Diagnosis", "link": "https://arxiv.org/abs/2404.05997", "description": "arXiv:2404.05997v2 Announce Type: replace \nAbstract: The black-box nature of deep learning models has raised concerns about their interpretability for successful deployment in real-world clinical applications. To address the concerns, eXplainable Artificial Intelligence (XAI) aims to provide clear and understandable explanations of the decision-making process. In the medical domain, concepts such as attributes of lesions or abnormalities serve as key evidence for deriving diagnostic results. Existing concept-based models mainly depend on concepts that appear independently and require fine-grained concept annotations such as bounding boxes. However, a medical image usually contains multiple concepts, and the fine-grained concept annotations are difficult to acquire. In this paper, we aim to interpret representations in deep neural networks by aligning the axes of the latent space with known concepts of interest. We propose a novel Concept-Attention Whitening (CAW) framework for interpretable skin lesion diagnosis. CAW is comprised of a disease diagnosis branch and a concept alignment branch. In the former branch, we train a convolutional neural network (CNN) with an inserted CAW layer to perform skin lesion diagnosis. The CAW layer decorrelates features and aligns image features to conceptual meanings via an orthogonal matrix. In the latter branch, the orthogonal matrix is calculated under the guidance of the concept attention mask. We particularly introduce a weakly-supervised concept mask generator that only leverages coarse concept labels for filtering local regions that are relevant to certain concepts, improving the optimization of the orthogonal matrix. Extensive experiments on two public skin lesion diagnosis datasets demonstrated that CAW not only enhanced interpretability but also maintained a state-of-the-art diagnostic performance.", "published": "2024-11-07 05:00:00", "id": "4ede8afb-18d4-412d-a266-ef6fc78f3eeb", "source": "arxiv", "section": "computerScience"}, {"title": "Guidelines for Using Mixed Methods Research in Software Engineering", "link": "https://arxiv.org/abs/2404.06011", "description": "arXiv:2404.06011v2 Announce Type: replace \nAbstract: Mixed methods research is often used in software engineering, but researchers outside of the social or human sciences often lack experience when using these designs. This paper provides guidelines and advice on how to design mixed method research, and to encourage the intentional, rigorous, and innovative use of mixed methods in software engineering. It also presents key characteristics of core mixed method research designs. Through a number of fictitious but recognizable software engineering research scenarios, we showcase how to choose suitable designs and consider the inevitable trade-offs any design choice leads to. We describe several antipatterns that illustrate what to avoid in mixed method research, and when mixed method research should be considered over other approaches.", "published": "2024-11-07 05:00:00", "id": "73287a4a-1d5f-4674-931a-b8d7b2298d00", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient Algorithms and New Characterizations for CSP Sparsification", "link": "https://arxiv.org/abs/2404.06327", "description": "arXiv:2404.06327v2 Announce Type: replace \nAbstract: CSP sparsification, introduced by Kogan and Krauthgamer (ITCS 2015), considers the following question: how much can an instance of a constraint satisfaction problem be sparsified (by retaining a reweighted subset of the constraints) while still roughly capturing the weight of constraints satisfied by {\\em every} assignment. CSP sparsification captures as a special case several well-studied problems including graph cut-sparsification, hypergraph cut-sparsification, hypergraph XOR-sparsification, and corresponds to a general class of hypergraph sparsification problems where an arbitrary $0/1$-valued {\\em splitting function} is used to define the notion of cutting a hyperedge (see, for instance, Veldt-Benson-Kleinberg SIAM Review 2022). The main question here is to understand, for a given constraint predicate $P:\\Sigma^r \\to \\{0,1\\}$ (where variables are assigned values in $\\Sigma$), the smallest constant $c$ such that $\\widetilde{O}(n^c)$ sized sparsifiers exist for every instance of a constraint satisfaction problem over $P$. A recent work of Khanna, Putterman and Sudan (SODA 2024) [KPS24] showed {\\em existence} of near-linear size sparsifiers for new classes of CSPs. In this work (1) we significantly extend the class of CSPs for which nearly linear-size sparsifications can be shown to exist while also extending the scope to settings with non-linear-sized sparsifications; (2) we give a polynomial-time algorithm to extract such sparsifications for all the problems we study including the first efficient sparsification algorithms for the problems studied in [KPS24].", "published": "2024-11-07 05:00:00", "id": "297bbea7-f09f-4b36-856e-9714bb7094a0", "source": "arxiv", "section": "computerScience"}, {"title": "Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models", "link": "https://arxiv.org/abs/2404.07724", "description": "arXiv:2404.07724v2 Announce Type: replace \nAbstract: Guidance is a crucial technique for extracting the best performance out of image-generating diffusion models. Traditionally, a constant guidance weight has been applied throughout the sampling chain of an image. We show that guidance is clearly harmful toward the beginning of the chain (high noise levels), largely unnecessary toward the end (low noise levels), and only beneficial in the middle. We thus restrict it to a specific range of noise levels, improving both the inference speed and result quality. This limited guidance interval improves the record FID in ImageNet-512 significantly, from 1.81 to 1.40. We show that it is quantitatively and qualitatively beneficial across different sampler parameters, network architectures, and datasets, including the large-scale setting of Stable Diffusion XL. We thus suggest exposing the guidance interval as a hyperparameter in all diffusion models that use guidance.", "published": "2024-11-07 05:00:00", "id": "e4008a34-765b-4343-9cca-01aff6c6bfd4", "source": "arxiv", "section": "computerScience"}, {"title": "Fourier Analysis of Iterative Algorithms", "link": "https://arxiv.org/abs/2404.07881", "description": "arXiv:2404.07881v2 Announce Type: replace \nAbstract: We study a general class of nonlinear iterative algorithms which includes power iteration, belief propagation and approximate message passing, and many forms of gradient descent. When the input is a random matrix with i.i.d. entries, we use Boolean Fourier analysis to analyze these algorithms as low-degree polynomials in the entries of the input matrix. Each symmetrized Fourier character represents all monomials with a certain shape as specified by a small graph, which we call a Fourier diagram.\n  We prove fundamental asymptotic properties of the Fourier diagrams: over the randomness of the input, all diagrams with cycles are negligible; the tree-shaped diagrams form a basis of asymptotically independent Gaussian vectors; and, when restricted to the trees, iterative algorithms exactly follow an idealized Gaussian dynamic. We use this to prove a state evolution formula, giving a \"complete\" asymptotic description of the algorithm's trajectory.\n  The restriction to tree-shaped monomials mirrors the assumption of the cavity method, a 40-year-old non-rigorous technique in statistical physics which has served as one of the most important techniques in the field. We demonstrate how to implement cavity method derivations by 1) restricting the iteration to its tree approximation, and 2) observing that heuristic cavity method-type arguments hold rigorously on the simplified iteration. Our proofs use combinatorial arguments similar to the trace method from random matrix theory.\n  Finally, we push the diagram analysis to a number of iterations that scales with the dimension $n$ of the input matrix, proving that the tree approximation still holds for a simple variant of power iteration all the way up to $n^{\\Omega(1)}$ iterations.", "published": "2024-11-07 05:00:00", "id": "86bea314-e56e-40f6-8b6b-cdf62f51653c", "source": "arxiv", "section": "computerScience"}, {"title": "Balanced Mixed-Type Tabular Data Synthesis with Diffusion Models", "link": "https://arxiv.org/abs/2404.08254", "description": "arXiv:2404.08254v2 Announce Type: replace \nAbstract: Diffusion models have emerged as a robust framework for various generative tasks, including tabular data synthesis. However, current tabular diffusion models tend to inherit bias in the training dataset and generate biased synthetic data, which may influence discriminatory actions. In this research, we introduce a novel tabular diffusion model that incorporates sensitive guidance to generate fair synthetic data with balanced joint distributions of the target label and sensitive attributes, such as sex and race. The empirical results demonstrate that our method effectively mitigates bias in training data while maintaining the quality of the generated samples. Furthermore, we provide evidence that our approach outperforms existing methods for synthesizing tabular data on fairness metrics such as demographic parity ratio and equalized odds ratio, achieving improvements of over $10\\%$. Our implementation is available at https://github.com/comp-well-org/fair-tab-diffusion.", "published": "2024-11-07 05:00:00", "id": "7fef1dd9-8ffc-464f-a42d-790a1b80f30f", "source": "arxiv", "section": "computerScience"}, {"title": "Pretraining and Updates of Domain-Specific LLM: A Case Study in the Japanese Business Domain", "link": "https://arxiv.org/abs/2404.08262", "description": "arXiv:2404.08262v3 Announce Type: replace \nAbstract: The development of Large Language Models (LLMs) in various languages has been advancing, but the combination of non-English languages with domain-specific contexts remains underexplored. This paper presents our findings from training and evaluating a Japanese business domain-specific LLM designed to better understand business-related documents, such as the news on current affairs, technical reports, and patents. Additionally, LLMs in this domain require regular updates to incorporate the most recent knowledge. Therefore, we also report our findings from the first experiments and evaluations involving updates to this LLM using the latest article data, which is an important problem setting that has not been addressed in previous research. From our experiments on a newly created benchmark dataset for question answering in the target domain, we found that (1) our pretrained model improves QA accuracy without losing general knowledge, and (2) a proper mixture of the latest and older texts in the training data for the update is necessary. Our pretrained model and business domain benchmark are publicly available to support further studies.", "published": "2024-11-07 05:00:00", "id": "c5abd195-020c-4df8-b17b-cc388ddd73d4", "source": "arxiv", "section": "computerScience"}, {"title": "Safe Reinforcement Learning on the Constraint Manifold: Theory and Applications", "link": "https://arxiv.org/abs/2404.09080", "description": "arXiv:2404.09080v2 Announce Type: replace \nAbstract: Integrating learning-based techniques, especially reinforcement learning, into robotics is promising for solving complex problems in unstructured environments. However, most existing approaches are trained in well-tuned simulators and subsequently deployed on real robots without online fine-tuning. In this setting, extensive engineering is required to mitigate the sim-to-real gap, which can be challenging for complex systems. Instead, learning with real-world interaction data offers a promising alternative: it not only eliminates the need for a fine-tuned simulator but also applies to a broader range of tasks where accurate modeling is unfeasible. One major problem for on-robot reinforcement learning is ensuring safety, as uncontrolled exploration can cause catastrophic damage to the robot or the environment. Indeed, safety specifications, often represented as constraints, can be complex and non-linear, making safety challenging to guarantee in learning systems. In this paper, we show how we can impose complex safety constraints on learning-based robotics systems in a principled manner, both from theoretical and practical points of view. Our approach is based on the concept of the Constraint Manifold, representing the set of safe robot configurations. Exploiting differential geometry techniques, i.e., the tangent space, we can construct a safe action space, allowing learning agents to sample arbitrary actions while ensuring safety. We demonstrate the method's effectiveness in a real-world Robot Air Hockey task, showing that our method can handle high-dimensional tasks with complex constraints. Videos of the real robot experiments are available on the project website (https://puzeliu.github.io/TRO-ATACOM).", "published": "2024-11-07 05:00:00", "id": "ecba2169-49f1-4d05-b022-e0e78ecc9ad9", "source": "arxiv", "section": "computerScience"}, {"title": "In-Context Translation: Towards Unifying Image Recognition, Processing, and Generation", "link": "https://arxiv.org/abs/2404.09633", "description": "arXiv:2404.09633v2 Announce Type: replace \nAbstract: We propose In-Context Translation (ICT), a general learning framework to unify visual recognition (e.g., semantic segmentation), low-level image processing (e.g., denoising), and conditional image generation (e.g., edge-to-image synthesis). Thanks to unification, ICT significantly reduces the inherent inductive bias that comes with designing models for specific tasks, and it maximizes mutual enhancement across similar tasks. However, the unification across a large number of tasks is non-trivial due to various data formats and training pipelines. To this end, ICT introduces two designs. Firstly, it standardizes input-output data of different tasks into RGB image pairs, e.g., semantic segmentation data pairs an RGB image with its segmentation mask in the same RGB format. This turns different tasks into a general translation task between two RGB images. Secondly, it standardizes the training of different tasks into a general in-context learning, where \"in-context\" means the input comprises an example input-output pair of the target task and a query image. The learning objective is to generate the \"missing\" data paired with the query. The implicit translation process is thus between the query and the generated image. In experiments, ICT unifies ten vision tasks and showcases impressive performance on their respective benchmarks. Notably, ICT performs well across three major categories of computer vision tasks, while its two competitors (Painter and PromptDiffusion) are only effective in at most two of these task categories. In addition, compared to its competitors, ICT trained on only 4 RTX 3090 GPUs is shown to be more efficient and less costly in training.", "published": "2024-11-07 05:00:00", "id": "22144bf4-74af-4273-b179-6a691377213e", "source": "arxiv", "section": "computerScience"}, {"title": "A variational discretization method for mean curvature flows by the Onsager principle", "link": "https://arxiv.org/abs/2404.11935", "description": "arXiv:2404.11935v2 Announce Type: replace \nAbstract: The mean curvature flow describes the evolution of a surface (a curve) with normal velocity proportional to the local mean curvature. It has many applications in mathematics, science and engineering. In this paper, we develop a numerical method for mean curvature flows by using the Onsager principle as an approximation tool. We first show that the mean curvature flow can be derived naturally from the Onsager variational principle. Then we consider a piecewise linear approximation of the curve and derive a discrete geometric flow. The discrete flow is described by a system of ordinary differential equations for the nodes of the discrete curve. We prove that the discrete system preserve the energy dissipation structure in the framework of the Onsager principle and this implies the energy decreasing property. The ODE system can be solved by the improved Euler scheme and this leads to an efficient fully discrete scheme. We first consider the method for a simple mean curvature flow and then extend it to the volume preserving mean curvature flow and also a wetting problem on substrates. Numerical examples show that the method has optimal convergence rate and works well for all the three problems.", "published": "2024-11-07 05:00:00", "id": "7ae0ed02-78ac-4728-a8e5-5b1f15e26dc4", "source": "arxiv", "section": "computerScience"}, {"title": "Automated Commit Message Generation with Large Language Models: An Empirical Study and Beyond", "link": "https://arxiv.org/abs/2404.14824", "description": "arXiv:2404.14824v2 Announce Type: replace \nAbstract: Commit Message Generation (CMG) approaches aim to automatically generate commit messages based on given code diffs, which facilitate collaboration among developers and play a critical role in Open-Source Software (OSS). Very recently, Large Language Models (LLMs) have demonstrated extensive applicability in diverse code-related task. But few studies systematically explored their effectiveness using LLMs. This paper conducts the first comprehensive experiment to investigate how far we have been in applying LLM to generate high-quality commit messages. Motivated by a pilot analysis, we first clean the most widely-used CMG dataset following practitioners' criteria. Afterward, we re-evaluate diverse state-of-the-art CMG approaches and make comparisons with LLMs, demonstrating the superior performance of LLMs against state-of-the-art CMG approaches. Then, we further propose four manual metrics following the practice of OSS, including Accuracy, Integrity, Applicability, and Readability, and assess various LLMs accordingly. Results reveal that GPT-3.5 performs best overall, but different LLMs carry different advantages. To further boost LLMs' performance in the CMG task, we propose an Efficient Retrieval-based In-Context Learning (ICL) framework, namely ERICommiter, which leverages a two-step filtering to accelerate the retrieval efficiency and introduces semantic/lexical-based retrieval algorithm to construct the ICL examples. Extensive experiments demonstrate the substantial performance improvement of ERICommiter on various LLMs for code diffs of different programming languages. Meanwhile, ERICommiter also significantly reduces the retrieval time while keeping almost the same performance. Our research contributes to the understanding of LLMs' capabilities in the CMG field and provides valuable insights for practitioners seeking to leverage these tools in their workflows.", "published": "2024-11-07 05:00:00", "id": "f9596521-7c77-4c7e-bb7e-41badbcff238", "source": "arxiv", "section": "computerScience"}, {"title": "The Power of Question Translation Training in Multilingual Reasoning: Broadened Scope and Deepened Insights", "link": "https://arxiv.org/abs/2405.01345", "description": "arXiv:2405.01345v3 Announce Type: replace \nAbstract: Bridging the significant gap between large language model's English and non-English performance presents a great challenge. While some previous studies attempt to mitigate this gap with translated training data, the recently proposed question alignment framework leverages the model's English expertise to improve multilingual performance with minimum usage of expensive, error-prone translation. In this paper, we explore how broadly this method can be applied by examining its effects in reasoning with and without chain-of-thought, as well as with program-of-thought. We also explore applying this framework to extremely large language models in an efficient manner, such as through proxy-tuning. Experiment results on multilingual reasoning benchmarks mGSM, mSVAMP, xCSQA and xNLI demonstrate that we can extend question alignment framework to boost multilingual performance across diverse reasoning scenarios, model families, and sizes. For instance, when applied to the LLaMA2 models, it brings an average accuracy improvements of 12.2% on mGSM even with the 70B model. To understand the mechanism of its success, we analyze representation space, generated response and data scales, and reveal how question translation training strengthens language alignment within LLMs and shapes their working patterns.", "published": "2024-11-07 05:00:00", "id": "1af7faa7-c5c9-4181-815c-d3e85d59433c", "source": "arxiv", "section": "computerScience"}, {"title": "Model-based Deep Learning for Wireless Resource Allocation in RSMA Communications Systems", "link": "https://arxiv.org/abs/2405.01515", "description": "arXiv:2405.01515v2 Announce Type: replace \nAbstract: Rate-splitting multiple access (RSMA) has been proven as an effective communication scheme for 5G and beyond. However, current approaches to RSMA resource management require complicated iterative algorithms, which cannot meet the stringent latency requirement by users with limited resources. Recently, data-driven methods are explored to alleviate this issue. However, they suffer from poor generalizability and scarce training data to achieve satisfactory performance. In this paper, we propose a fractional programming (FP) based deep unfolding (DU) approach to address resource allocation problem for a weighted sum rate optimization in RSMA. By carefully designing the penalty function, we couple the variable update with projected gradient descent algorithm (PGD). Following the structure of PGD, we embed a few learnable parameters in each layer of the DU network. Through extensive simulation, we have shown that the proposed model-based neural networks can yield similar results compared to the traditional optimization algorithm for RSMA resource management but with much lower computational complexity, less training data, and higher resilience to out-of-distribution (OOD) data.", "published": "2024-11-07 05:00:00", "id": "1bf516a8-d8e3-4038-87fa-a3aa1d28e9ac", "source": "arxiv", "section": "computerScience"}, {"title": "Reconfigurable Massive MIMO: Precoding Design and Channel Estimation in the Electromagnetic Domain", "link": "https://arxiv.org/abs/2405.02823", "description": "arXiv:2405.02823v3 Announce Type: replace \nAbstract: Reconfigurable massive multiple-input multiple-output (RmMIMO), as an electronically-controlled fluid antenna system, offers increased flexibility for future communication systems by exploiting previously untapped degrees of freedom in the electromagnetic (EM) domain. The representation of the traditional spatial domain channel state information (sCSI) limits the insights into the potential of EM domain channel properties, constraining the base station's (BS) utmost capability for precoding design. This paper leverages the EM domain channel state information (eCSI) for antenna radiation pattern design at the BS. We develop an orthogonal decomposition method based on spherical harmonic functions to decompose the radiation pattern into a linear combination of orthogonal bases. By formulating the radiation pattern design as an optimization problem for the projection coefficients over these bases, we develop a manifold optimization-based method for iterative radiation pattern and digital precoder design. To address the eCSI estimation problem, we capitalize on the inherent structure of the channel. Specifically, we propose a subspace-based scheme to reduce the pilot overhead for wideband sCSI estimation. Given the estimated full-band sCSI, we further employ parameterized methods for angle of arrival estimation. Subsequently, the complete eCSI can be reconstructed after estimating the equivalent channel gain via the least squares method. Simulation results demonstrate that, in comparison to traditional mMIMO systems with fixed antenna radiation patterns, the proposed RmMIMO architecture offers significant throughput gains for multi-user transmission at a low channel estimation overhead.", "published": "2024-11-07 05:00:00", "id": "11e54820-4a14-4927-bbe9-b7e35ba964e4", "source": "arxiv", "section": "computerScience"}, {"title": "Model Reconstruction Using Counterfactual Explanations: A Perspective From Polytope Theory", "link": "https://arxiv.org/abs/2405.05369", "description": "arXiv:2405.05369v2 Announce Type: replace \nAbstract: Counterfactual explanations provide ways of achieving a favorable model outcome with minimum input perturbation. However, counterfactual explanations can also be leveraged to reconstruct the model by strategically training a surrogate model to give similar predictions as the original (target) model. In this work, we analyze how model reconstruction using counterfactuals can be improved by further leveraging the fact that the counterfactuals also lie quite close to the decision boundary. Our main contribution is to derive novel theoretical relationships between the error in model reconstruction and the number of counterfactual queries required using polytope theory. Our theoretical analysis leads us to propose a strategy for model reconstruction that we call Counterfactual Clamping Attack (CCA) which trains a surrogate model using a unique loss function that treats counterfactuals differently than ordinary instances. Our approach also alleviates the related problem of decision boundary shift that arises in existing model reconstruction approaches when counterfactuals are treated as ordinary instances. Experimental results demonstrate that our strategy improves fidelity between the target and surrogate model predictions on several datasets.", "published": "2024-11-07 05:00:00", "id": "f5aa9189-f3fe-4cac-a513-c028e1b7dd87", "source": "arxiv", "section": "computerScience"}, {"title": "ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering", "link": "https://arxiv.org/abs/2405.07001", "description": "arXiv:2405.07001v4 Announce Type: replace \nAbstract: Chart question answering (ChartQA) tasks play a critical role in interpreting and extracting insights from visualization charts. While recent advancements in multimodal large language models (MLLMs) like GPT-4o have shown promise in high-level ChartQA tasks, such as chart captioning, their effectiveness in low-level ChartQA tasks (e.g., identifying correlations) remains underexplored. In this paper, we address this gap by evaluating MLLMs on low-level ChartQA using a newly curated dataset, ChartInsights, which consists of 22,347 (chart, task, query, answer) covering 10 data analysis tasks across 7 chart types. We systematically evaluate 19 advanced MLLMs, including 12 open-source and 7 closed-source models. The average accuracy rate across these models is 39.8%, with GPT-4o achieving the highest accuracy at 69.17%. To further explore the limitations of MLLMs in low-level ChartQA, we conduct experiments that alter visual elements of charts (e.g., changing color schemes, adding image noise) to assess their impact on the task effectiveness. Furthermore, we propose a new textual prompt strategy, Chain-of-Charts, tailored for low-level ChartQA tasks, which boosts performance by 14.41%, achieving an accuracy of 83.58%. Finally, incorporating a visual prompt strategy that directs attention to relevant visual elements further improves accuracy to 84.32%.", "published": "2024-11-07 05:00:00", "id": "4eba8638-8132-40bb-8751-c2a79027c76b", "source": "arxiv", "section": "computerScience"}, {"title": "Rounding Large Independent Sets on Expanders", "link": "https://arxiv.org/abs/2405.10238", "description": "arXiv:2405.10238v2 Announce Type: replace \nAbstract: We develop a new approach for approximating large independent sets when the input graph is a one-sided spectral expander - that is, the uniform random walk matrix of the graph has its second eigenvalue bounded away from 1. Consequently, we obtain a polynomial time algorithm to find linear-sized independent sets in one-sided expanders that are almost $3$-colorable or are promised to contain an independent set of size $(1/2-\\epsilon)n$. Our second result above can be refined to require only a weaker vertex expansion property with an efficient certificate. In a surprising contrast to our algorithmic result, we observe that the analogous task of finding a linear-sized independent set in almost $4$-colorable one-sided expanders (even when the second eigenvalue is $o_n(1)$) is NP-hard, assuming the Unique Games Conjecture.\n  All prior algorithms that beat the worst-case guarantees for this problem rely on bottom eigenspace enumeration techniques (following the classical spectral methods of Alon and Kahale) and require two-sided expansion, meaning a bounded number of negative eigenvalues of magnitude $\\Omega(1)$. Such techniques naturally extend to almost $k$-colorable graphs for any constant $k$, in contrast to analogous guarantees on one-sided expanders, which are Unique Games-hard to achieve for $k \\geq 4$.\n  Our rounding builds on the method of simulating multiple samples from a pseudo-distribution introduced by Bafna et. al. for rounding Unique Games instances. The key to our analysis is a new clustering property of large independent sets in expanding graphs - every large independent set has a larger-than-expected intersection with some member of a small list - and its formalization in the low-degree sum-of-squares proof system.", "published": "2024-11-07 05:00:00", "id": "a4fc0e95-e2c3-4b37-a940-5c420ce9179e", "source": "arxiv", "section": "computerScience"}, {"title": "Agent Design Pattern Catalogue: A Collection of Architectural Patterns for Foundation Model based Agents", "link": "https://arxiv.org/abs/2405.10467", "description": "arXiv:2405.10467v4 Announce Type: replace \nAbstract: Foundation model-enabled generative artificial intelligence facilitates the development and implementation of agents, which can leverage distinguished reasoning and language processing capabilities to takes a proactive, autonomous role to pursue users' goals. Nevertheless, there is a lack of systematic knowledge to guide practitioners in designing the agents considering challenges of goal-seeking (including generating instrumental goals and plans), such as hallucinations inherent in foundation models, explainability of reasoning process, complex accountability, etc. To address this issue, we have performed a systematic literature review to understand the state-of-the-art foundation model-based agents and the broader ecosystem. In this paper, we present a pattern catalogue consisting of 18 architectural patterns with analyses of the context, forces, and trade-offs as the outcomes from the previous literature review. We propose a decision model for selecting the patterns. The proposed catalogue can provide holistic guidance for the effective use of patterns, and support the architecture design of foundation model-based agents by facilitating goal-seeking and plan generation.", "published": "2024-11-07 05:00:00", "id": "b208950e-82e9-4a93-812e-a011956b48c8", "source": "arxiv", "section": "computerScience"}, {"title": "R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments", "link": "https://arxiv.org/abs/2405.11541", "description": "arXiv:2405.11541v2 Announce Type: replace \nAbstract: Recently, ray tracing has gained renewed interest with the advent of Reflective Intelligent Surfaces (RIS) technology, a key enabler of 6G wireless communications due to its capability of intelligent manipulation of electromagnetic waves. However, accurately modeling RIS-enabled wireless environments poses significant challenges due to the complex variations caused by various environmental factors and the mobility of RISs. In this paper, we propose a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in such environments. Our method utilizes NeRF-based ray tracing to intuitively capture and visualize the complex dynamics of signal propagation, effectively modeling the complete signal pathways from the transmitter to the RIS, and from the RIS to the receiver. This two-stage process accurately characterizes multiple complex transmission paths, enhancing our understanding of signal behavior in real-world scenarios. Our approach predicts the signal field for any specified RIS placement and receiver location, facilitating efficient RIS deployment. Experimental evaluations using both simulated and real-world data validate the significant benefits of our methodology.", "published": "2024-11-07 05:00:00", "id": "d0c1d9a7-1d61-4a66-a06d-292a6486bc22", "source": "arxiv", "section": "computerScience"}, {"title": "Blockchain-based AI Methods for Managing Industrial IoT: Recent Developments, Integration Challenges and Opportunities", "link": "https://arxiv.org/abs/2405.12550", "description": "arXiv:2405.12550v3 Announce Type: replace \nAbstract: Currently, Blockchain (BC), Artificial Intelligence (AI), and smart Industrial Internet of Things (IIoT) are not only leading promising technologies in the world, but also these technologies facilitate the current society to develop the standard of living and make it easier for users. However, these technologies have been applied in various domains for different purposes. Then, these are successfully assisted in developing the desired system, such as-smart cities, homes, manufacturers, education, and industries. Moreover, these technologies need to consider various issues-security, privacy, confidentiality, scalability, and application challenges in diverse fields. In this context, with the increasing demand for these issues solutions, the authors present a comprehensive survey on the AI approaches with BC in the smart IIoT. Firstly, we focus on state-of-the-art overviews regarding AI, BC, and smart IoT applications. Then, we provide the benefits of integrating these technologies and discuss the established methods, tools, and strategies efficiently. Most importantly, we highlight the various issues--security, stability, scalability, and confidentiality and guide the way of addressing strategy and methods. Furthermore, the individual and collaborative benefits of applications have been discussed. Lastly, we are extensively concerned about the open research challenges and potential future guidelines based on BC-based AI approaches in the intelligent IIoT system.", "published": "2024-11-07 05:00:00", "id": "81488f6f-5956-4ac0-b2eb-63d20209e6e6", "source": "arxiv", "section": "computerScience"}, {"title": "ODGEN: Domain-specific Object Detection Data Generation with Diffusion Models", "link": "https://arxiv.org/abs/2405.15199", "description": "arXiv:2405.15199v2 Announce Type: replace \nAbstract: Modern diffusion-based image generative models have made significant progress and become promising to enrich training data for the object detection task. However, the generation quality and the controllability for complex scenes containing multi-class objects and dense objects with occlusions remain limited. This paper presents ODGEN, a novel method to generate high-quality images conditioned on bounding boxes, thereby facilitating data synthesis for object detection. Given a domain-specific object detection dataset, we first fine-tune a pre-trained diffusion model on both cropped foreground objects and entire images to fit target distributions. Then we propose to control the diffusion model using synthesized visual prompts with spatial constraints and object-wise textual descriptions. ODGEN exhibits robustness in handling complex scenes and specific domains. Further, we design a dataset synthesis pipeline to evaluate ODGEN on 7 domain-specific benchmarks to demonstrate its effectiveness. Adding training data generated by ODGEN improves up to 25.3% mAP@.50:.95 with object detectors like YOLOv5 and YOLOv7, outperforming prior controllable generative methods. In addition, we design an evaluation protocol based on COCO-2014 to validate ODGEN in general domains and observe an advantage up to 5.6% in mAP@.50:.95 against existing methods.", "published": "2024-11-07 05:00:00", "id": "71f53459-1ed5-4c7a-950d-c46ca266c0a9", "source": "arxiv", "section": "computerScience"}, {"title": "DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ", "link": "https://arxiv.org/abs/2405.15306", "description": "arXiv:2405.15306v3 Announce Type: replace \nAbstract: Creating high-quality scientific figures can be time-consuming and challenging, even though sketching ideas on paper is relatively easy. Furthermore, recreating existing figures that are not stored in formats preserving semantic information is equally complex. To tackle this problem, we introduce DeTikZify, a novel multimodal language model that automatically synthesizes scientific figures as semantics-preserving TikZ graphics programs based on sketches and existing figures. To achieve this, we create three new datasets: DaTikZv2, the largest TikZ dataset to date, containing over 360k human-created TikZ graphics; SketchFig, a dataset that pairs hand-drawn sketches with their corresponding scientific figures; and MetaFig, a collection of diverse scientific figures and associated metadata. We train DeTikZify on MetaFig and DaTikZv2, along with synthetically generated sketches learned from SketchFig. We also introduce an MCTS-based inference algorithm that enables DeTikZify to iteratively refine its outputs without the need for additional training. Through both automatic and human evaluation, we demonstrate that DeTikZify outperforms commercial Claude 3 and GPT-4V in synthesizing TikZ programs, with the MCTS algorithm effectively boosting its performance. We make our code, models, and datasets publicly available.", "published": "2024-11-07 05:00:00", "id": "a06bf25e-7c13-41de-a376-10b98f9dd40e", "source": "arxiv", "section": "computerScience"}, {"title": "DMPlug: A Plug-in Method for Solving Inverse Problems with Diffusion Models", "link": "https://arxiv.org/abs/2405.16749", "description": "arXiv:2405.16749v2 Announce Type: replace \nAbstract: Pretrained diffusion models (DMs) have recently been popularly used in solving inverse problems (IPs). The existing methods mostly interleave iterative steps in the reverse diffusion process and iterative steps to bring the iterates closer to satisfying the measurement constraint. However, such interleaving methods struggle to produce final results that look like natural objects of interest (i.e., manifold feasibility) and fit the measurement (i.e., measurement feasibility), especially for nonlinear IPs. Moreover, their capabilities to deal with noisy IPs with unknown types and levels of measurement noise are unknown. In this paper, we advocate viewing the reverse process in DMs as a function and propose a novel plug-in method for solving IPs using pretrained DMs, dubbed DMPlug. DMPlug addresses the issues of manifold feasibility and measurement feasibility in a principled manner, and also shows great potential for being robust to unknown types and levels of noise. Through extensive experiments across various IP tasks, including two linear and three nonlinear IPs, we demonstrate that DMPlug consistently outperforms state-of-the-art methods, often by large margins especially for nonlinear IPs. The code is available at https://github.com/sun-umn/DMPlug.", "published": "2024-11-07 05:00:00", "id": "8f56cf86-b5fc-4c04-8b4d-82346bc421c8", "source": "arxiv", "section": "computerScience"}, {"title": "CLIBD: Bridging Vision and Genomics for Biodiversity Monitoring at Scale", "link": "https://arxiv.org/abs/2405.17537", "description": "arXiv:2405.17537v3 Announce Type: replace \nAbstract: Measuring biodiversity is crucial for understanding ecosystem health. While prior works have developed machine learning models for taxonomic classification of photographic images and DNA separately, in this work, we introduce a multimodal approach combining both, using CLIP-style contrastive learning to align images, barcode DNA, and text-based representations of taxonomic labels in a unified embedding space. This allows for accurate classification of both known and unknown insect species without task-specific fine-tuning, leveraging contrastive learning for the first time to fuse DNA and image data. Our method surpasses previous single-modality approaches in accuracy by over 8% on zero-shot learning tasks, showcasing its effectiveness in biodiversity studies.", "published": "2024-11-07 05:00:00", "id": "c54a183a-986c-4c06-bc4f-29e9669e359e", "source": "arxiv", "section": "computerScience"}, {"title": "Optimizing Layout of Recursive Datatypes with Marmoset", "link": "https://arxiv.org/abs/2405.17590", "description": "arXiv:2405.17590v3 Announce Type: replace \nAbstract: While programmers know that the low-level memory representation of data structures can have significant effects on performance, compiler support to optimize the layout of those structures is an under-explored field. Prior work has optimized the layout of individual, non-recursive structures without considering how collections of those objects in linked or recursive data structures are laid out. This work introduces Marmoset, a compiler that optimizes the layouts of algebraic datatypes, with a special focus on producing highly optimized, packed data layouts where recursive structures can be traversed with minimal pointer chasing. Marmoset performs an analysis of how a recursive ADT is used across functions to choose a global layout that promotes simple, strided access for that ADT in memory. It does so by building and solving a constraint system to minimize an abstract cost model, yielding a predicted efficient layout for the ADT. Marmoset then builds on top of Gibbon, a prior compiler for packed, mostly-serial representations, to synthesize optimized ADTs. We show experimentally that Marmoset is able to choose optimal layouts across a series of microbenchmarks and case studies, outperforming both Gibbons baseline approach, as well as MLton, a Standard ML compiler that uses traditional pointer-heavy representations.", "published": "2024-11-07 05:00:00", "id": "4bb8821c-de1c-4aa9-adaf-3dded8aa905b", "source": "arxiv", "section": "computerScience"}, {"title": "DC-Gaussian: Improving 3D Gaussian Splatting for Reflective Dash Cam Videos", "link": "https://arxiv.org/abs/2405.17705", "description": "arXiv:2405.17705v3 Announce Type: replace \nAbstract: We present DC-Gaussian, a new method for generating novel views from in-vehicle dash cam videos. While neural rendering techniques have made significant strides in driving scenarios, existing methods are primarily designed for videos collected by autonomous vehicles. However, these videos are limited in both quantity and diversity compared to dash cam videos, which are more widely used across various types of vehicles and capture a broader range of scenarios. Dash cam videos often suffer from severe obstructions such as reflections and occlusions on the windshields, which significantly impede the application of neural rendering techniques. To address this challenge, we develop DC-Gaussian based on the recent real-time neural rendering technique 3D Gaussian Splatting (3DGS). Our approach includes an adaptive image decomposition module to model reflections and occlusions in a unified manner. Additionally, we introduce illumination-aware obstruction modeling to manage reflections and occlusions under varying lighting conditions. Lastly, we employ a geometry-guided Gaussian enhancement strategy to improve rendering details by incorporating additional geometry priors. Experiments on self-captured and public dash cam videos show that our method not only achieves state-of-the-art performance in novel view synthesis, but also accurately reconstructing captured scenes getting rid of obstructions. See the project page for code, data: https://linhanwang.github.io/dcgaussian/.", "published": "2024-11-07 05:00:00", "id": "ee0a343f-db8c-4e6a-aa5c-0d31c9398e39", "source": "arxiv", "section": "computerScience"}, {"title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey", "link": "https://arxiv.org/abs/2405.19202", "description": "arXiv:2405.19202v4 Announce Type: replace \nAbstract: Traffic incidents involving vulnerable road users (VRUs) constitute a significant proportion of global road accidents. Advances in traffic communication ecosystems, coupled with sophisticated signal processing and machine learning techniques, have facilitated the utilization of data from diverse sensors. Despite these advancements and the availability of extensive datasets, substantial progress is required to mitigate traffic casualties. This paper provides a comprehensive survey of state-of-the-art technologies and methodologies to enhance the safety of VRUs. The study delves into the communication networks between vehicles and VRUs, emphasizing the integration of advanced sensors and the availability of relevant datasets. It explores preprocessing techniques and data fusion methods to enhance sensor data quality. Furthermore, our study assesses critical simulation environments essential for developing and testing VRU safety systems. Our research also highlights recent advances in VRU detection and classification algorithms, addressing challenges such as variable environmental conditions. Additionally, we cover cutting-edge research in predicting VRU intentions and behaviors, which is crucial for proactive collision avoidance strategies. Through this survey, we aim to provide a comprehensive understanding of the current landscape of VRU safety technologies, identifying areas of progress and areas needing further research and development.", "published": "2024-11-07 05:00:00", "id": "69ba1768-630e-462f-a3cd-1dfc97234b6d", "source": "arxiv", "section": "computerScience"}, {"title": "LightDE: A Lightweight Method for Eliminating Dangling Pointers", "link": "https://arxiv.org/abs/2405.20697", "description": "arXiv:2405.20697v4 Announce Type: replace \nAbstract: The widespread presence of Use-After-Free (UAF) vulnerabilities poses a serious threat to software security, with dangling pointers being considered the primary cause of these vulnerabilities. However, existing methods for defending against UAF vulnerabilities by eliminating dangling pointers need to interrupt the program's execution when encountering pointer assignment operations in order to store the memory addresses of the pointers in a specific data structure. This makes these methods not lightweight. To overcome this drawback, we propose a novel approach called LightDE. This method does not require storing the memory addresses of pointers during program execution. LightDE uses our proposed structure-sensitive pointer analysis method to determine which objects pointers point to and stores the pointing relationships in the program's data segment during program compilation. Since LightDE only needs to verify if pointers identified by the pointer analysis point to released objects when eliminating dangling pointers, it is very lightweight. Our experimental results show that LightDE can effectively defend against UAF vulnerabilities and the performance overhead it introduces is very low.", "published": "2024-11-07 05:00:00", "id": "9aa6a2d0-5101-4242-9005-5b27590d707f", "source": "arxiv", "section": "computerScience"}, {"title": "Reward Machines for Deep RL in Noisy and Uncertain Environments", "link": "https://arxiv.org/abs/2406.00120", "description": "arXiv:2406.00120v3 Announce Type: replace \nAbstract: Reward Machines provide an automaton-inspired structure for specifying instructions, safety constraints, and other temporally extended reward-worthy behaviour. By exposing the underlying structure of a reward function, they enable the decomposition of an RL task, leading to impressive gains in sample efficiency. Although Reward Machines and similar formal specifications have a rich history of application towards sequential decision-making problems, they critically rely on a ground-truth interpretation of the domain-specific vocabulary that forms the building blocks of the reward function--such ground-truth interpretations are elusive in the real world due in part to partial observability and noisy sensing. In this work, we explore the use of Reward Machines for Deep RL in noisy and uncertain environments. We characterize this problem as a POMDP and propose a suite of RL algorithms that exploit task structure under uncertain interpretation of the domain-specific vocabulary. Through theory and experiments, we expose pitfalls in naive approaches to this problem while simultaneously demonstrating how task structure can be successfully leveraged under noisy interpretations of the vocabulary.", "published": "2024-11-07 05:00:00", "id": "61473ff1-ebc5-4b09-84b7-e08c86267d12", "source": "arxiv", "section": "computerScience"}, {"title": "Open Problem: Active Representation Learning", "link": "https://arxiv.org/abs/2406.03845", "description": "arXiv:2406.03845v2 Announce Type: replace \nAbstract: In this work, we introduce the concept of Active Representation Learning, a novel class of problems that intertwines exploration and representation learning within partially observable environments. We extend ideas from Active Simultaneous Localization and Mapping (active SLAM), and translate them to scientific discovery problems, exemplified by adaptive microscopy. We explore the need for a framework that derives exploration skills from representations that are in some sense actionable, aiming to enhance the efficiency and effectiveness of data collection and model building in the natural sciences.", "published": "2024-11-07 05:00:00", "id": "32988868-e637-42f0-b3d8-1344359d6d51", "source": "arxiv", "section": "computerScience"}, {"title": "Interpretable Lightweight Transformer via Unrolling of Learned Graph Smoothness Priors", "link": "https://arxiv.org/abs/2406.04090", "description": "arXiv:2406.04090v2 Announce Type: replace \nAbstract: We build interpretable and lightweight transformer-like neural networks by unrolling iterative optimization algorithms that minimize graph smoothness priors -- the quadratic graph Laplacian regularizer (GLR) and the $\\ell_1$-norm graph total variation (GTV) -- subject to an interpolation constraint. The crucial insight is that a normalized signal-dependent graph learning module amounts to a variant of the basic self-attention mechanism in conventional transformers. Unlike \"black-box\" transformers that require learning of large key, query and value matrices to compute scaled dot products as affinities and subsequent output embeddings, resulting in huge parameter sets, our unrolled networks employ shallow CNNs to learn low-dimensional features per node to establish pairwise Mahalanobis distances and construct sparse similarity graphs. At each layer, given a learned graph, the target interpolated signal is simply a low-pass filtered output derived from the minimization of an assumed graph smoothness prior, leading to a dramatic reduction in parameter count. Experiments for two image interpolation applications verify the restoration performance, parameter efficiency and robustness to covariate shift of our graph-based unrolled networks compared to conventional transformers.", "published": "2024-11-07 05:00:00", "id": "477f7236-6824-4dd2-b120-fa02859a0a82", "source": "arxiv", "section": "computerScience"}, {"title": "Skill-aware Mutual Information Optimisation for Generalisation in Reinforcement Learning", "link": "https://arxiv.org/abs/2406.04815", "description": "arXiv:2406.04815v3 Announce Type: replace \nAbstract: Meta-Reinforcement Learning (Meta-RL) agents can struggle to operate across tasks with varying environmental features that require different optimal skills (i.e., different modes of behaviour). Using context encoders based on contrastive learning to enhance the generalisability of Meta-RL agents is now widely studied but faces challenges such as the requirement for a large sample size, also referred to as the $\\log$-$K$ curse. To improve RL generalisation to different tasks, we first introduce Skill-aware Mutual Information (SaMI), an optimisation objective that aids in distinguishing context embeddings according to skills, thereby equipping RL agents with the ability to identify and execute different skills across tasks. We then propose Skill-aware Noise Contrastive Estimation (SaNCE), a $K$-sample estimator used to optimise the SaMI objective. We provide a framework for equipping an RL agent with SaNCE in practice and conduct experimental validation on modified MuJoCo and Panda-gym benchmarks. We empirically find that RL agents that learn by maximising SaMI achieve substantially improved zero-shot generalisation to unseen tasks. Additionally, the context encoder trained with SaNCE demonstrates greater robustness to a reduction in the number of available samples, thus possessing the potential to overcome the $\\log$-$K$ curse.", "published": "2024-11-07 05:00:00", "id": "ef2c7b0b-9a46-4039-b66a-8368294efd6f", "source": "arxiv", "section": "computerScience"}, {"title": "Testably Learning Polynomial Threshold Functions", "link": "https://arxiv.org/abs/2406.06106", "description": "arXiv:2406.06106v2 Announce Type: replace \nAbstract: Rubinfeld & Vasilyan recently introduced the framework of testable learning as an extension of the classical agnostic model. It relaxes distributional assumptions which are difficult to verify by conditions that can be checked efficiently by a tester. The tester has to accept whenever the data truly satisfies the original assumptions, and the learner has to succeed whenever the tester accepts. We focus on the setting where the tester has to accept standard Gaussian data. There, it is known that basic concept classes such as halfspaces can be learned testably with the same time complexity as in the (distribution-specific) agnostic model. In this work, we ask whether there is a price to pay for testably learning more complex concept classes. In particular, we consider polynomial threshold functions (PTFs), which naturally generalize halfspaces. We show that PTFs of arbitrary constant degree can be testably learned up to excess error $\\varepsilon > 0$ in time $n^{\\mathrm{poly}(1/\\varepsilon)}$. This qualitatively matches the best known guarantees in the agnostic model. Our results build on a connection between testable learning and fooling. In particular, we show that distributions that approximately match at least $\\mathrm{poly}(1/\\varepsilon)$ moments of the standard Gaussian fool constant-degree PTFs (up to error $\\varepsilon$). As a secondary result, we prove that a direct approach to show testable learning (without fooling), which was successfully used for halfspaces, cannot work for PTFs.", "published": "2024-11-07 05:00:00", "id": "91dfedfd-82b1-4bbe-9d99-fa9312771004", "source": "arxiv", "section": "computerScience"}, {"title": "Mastering truss structure optimization with tree search", "link": "https://arxiv.org/abs/2406.06145", "description": "arXiv:2406.06145v4 Announce Type: replace \nAbstract: This study investigates the combined use of generative grammar rules and Monte Carlo Tree Search (MCTS) for optimizing truss structures. Our approach accommodates intermediate construction stages characteristic of progressive construction settings. We demonstrate the significant robustness and computational efficiency of our approach compared to alternative reinforcement learning frameworks from previous research activities, such as Q-learning or deep Q-learning. These advantages stem from the ability of MCTS to strategically navigate large state spaces, leveraging the upper confidence bound for trees formula to effectively balance exploitation-exploration trade-offs. We also emphasize the importance of early decision nodes in the search tree, reflecting design choices crucial for highly performative solutions. Additionally, we show how MCTS dynamically adapts to complex and extensive state spaces without significantly affecting solution quality. While the focus of this paper is on truss optimization, our findings suggest MCTS as a powerful tool for addressing other increasingly complex engineering applications.", "published": "2024-11-07 05:00:00", "id": "88f475ea-46fd-48c3-add3-5e4787b8369a", "source": "arxiv", "section": "computerScience"}, {"title": "An Improved Empirical Fisher Approximation for Natural Gradient Descent", "link": "https://arxiv.org/abs/2406.06420", "description": "arXiv:2406.06420v2 Announce Type: replace \nAbstract: Approximate Natural Gradient Descent (NGD) methods are an important family of optimisers for deep learning models, which use approximate Fisher information matrices to pre-condition gradients during training. The empirical Fisher (EF) method approximates the Fisher information matrix empirically by reusing the per-sample gradients collected during back-propagation. Despite its ease of implementation, the EF approximation has its theoretical and practical limitations. This paper investigates the inversely-scaled projection issue of EF, which is shown to be a major cause of its poor empirical approximation quality. An improved empirical Fisher (iEF) method is proposed to address this issue, which is motivated as a generalised NGD method from a loss reduction perspective, meanwhile retaining the practical convenience of EF. The exact iEF and EF methods are experimentally evaluated using practical deep learning setups. Optimisation experiments show that applying exact iEF directly as an optimiser provides strong convergence and generalisation. Additionally, under a novel empirical evaluation framework, the proposed iEF method shows consistently better approximation quality to exact Natural Gradient updates than both the EF and the more expensive sampled Fisher methods, meanwhile demonstrating the superior property of being robust to the choice of damping across tasks and training stages. Improving existing approximate NGD optimisers with iEF is expected to lead to better convergence and robustness. Furthermore, the iEF method also serves as a better approximation method to the Fisher information matrix itself, which enables the improvement of a variety of Fisher-based methods, not limited to the scope of optimisation.", "published": "2024-11-07 05:00:00", "id": "e0494eea-3be5-475d-be63-4c1ec6a76c40", "source": "arxiv", "section": "computerScience"}, {"title": "Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs", "link": "https://arxiv.org/abs/2406.09324", "description": "arXiv:2406.09324v3 Announce Type: replace \nAbstract: Although Large Language Models (LLMs) have demonstrated significant capabilities in executing complex tasks in a zero-shot manner, they are susceptible to jailbreak attacks and can be manipulated to produce harmful outputs. Recently, a growing body of research has categorized jailbreak attacks into token-level and prompt-level attacks. However, previous work primarily overlooks the diverse key factors of jailbreak attacks, with most studies concentrating on LLM vulnerabilities and lacking exploration of defense-enhanced LLMs. To address these issues, we introduced $\\textbf{JailTrickBench}$ to evaluate the impact of various attack settings on LLM performance and provide a baseline for jailbreak attacks, encouraging the adoption of a standardized evaluation framework. Specifically, we evaluate the eight key factors of implementing jailbreak attacks on LLMs from both target-level and attack-level perspectives. We further conduct seven representative jailbreak attacks on six defense methods across two widely used datasets, encompassing approximately 354 experiments with about 55,000 GPU hours on A800-80G. Our experimental results highlight the need for standardized benchmarking to evaluate these attacks on defense-enhanced LLMs. Our code is available at https://github.com/usail-hkust/JailTrickBench.", "published": "2024-11-07 05:00:00", "id": "f46553cd-0850-4126-98e7-742399b41a4b", "source": "arxiv", "section": "computerScience"}, {"title": "First Multi-Dimensional Evaluation of Flowchart Comprehension for Multimodal Large Language Models", "link": "https://arxiv.org/abs/2406.10057", "description": "arXiv:2406.10057v3 Announce Type: replace \nAbstract: With the development of Multimodal Large Language Models (MLLMs) technology, its general capabilities are increasingly powerful. To evaluate the various abilities of MLLMs, numerous evaluation systems have emerged. But now there is still a lack of a comprehensive method to evaluate MLLMs in the tasks related to flowcharts, which are very important in daily life and work. We propose the first comprehensive method, FlowCE, to assess MLLMs across various dimensions for tasks related to flowcharts. It encompasses evaluating MLLMs' abilities in Reasoning, Localization Recognition, Information Extraction, Logical Verification, and Summarization on flowcharts. However, we find that even the GPT4o model achieves only a score of 56.63. Among open-source models, Phi-3-Vision obtained the highest score of 49.97. We hope that FlowCE can contribute to future research on MLLMs for tasks based on flowcharts. \\url{https://github.com/360AILABNLP/FlowCE}", "published": "2024-11-07 05:00:00", "id": "6672de7d-b371-419e-8df8-ad75dd7dcb88", "source": "arxiv", "section": "computerScience"}, {"title": "BABILong: Testing the Limits of LLMs with Long Context Reasoning-in-a-Haystack", "link": "https://arxiv.org/abs/2406.10149", "description": "arXiv:2406.10149v2 Announce Type: replace \nAbstract: In recent years, the input context sizes of large language models (LLMs) have increased dramatically. However, existing evaluation methods have not kept pace, failing to comprehensively assess the efficiency of models in handling long contexts. To bridge this gap, we introduce the BABILong benchmark, designed to test language models' ability to reason across facts distributed in extremely long documents. BABILong includes a diverse set of 20 reasoning tasks, including fact chaining, simple induction, deduction, counting, and handling lists/sets. These tasks are challenging on their own, and even more demanding when the required facts are scattered across long natural text. Our evaluations show that popular LLMs effectively utilize only 10-20\\% of the context and their performance declines sharply with increased reasoning complexity. Among alternatives to in-context reasoning, Retrieval-Augmented Generation methods achieve a modest 60\\% accuracy on single-fact question answering, independent of context length. Among context extension methods, the highest performance is demonstrated by recurrent memory transformers after fine-tuning, enabling the processing of lengths up to 50 million tokens. The BABILong benchmark is extendable to any length to support the evaluation of new upcoming models with increased capabilities, and we provide splits up to 10 million token lengths.", "published": "2024-11-07 05:00:00", "id": "4fc2c38c-6903-4ce8-a917-e2f75da54c8f", "source": "arxiv", "section": "computerScience"}, {"title": "LiveMind: Low-latency Large Language Models with Simultaneous Inference", "link": "https://arxiv.org/abs/2406.14319", "description": "arXiv:2406.14319v2 Announce Type: replace \nAbstract: In this paper, we introduce LiveMind, a novel low-latency inference framework for large language model (LLM) inference which enables LLMs to perform inferences with incomplete user input. By reallocating computational processes to the input phase, a substantial reduction in latency is achieved, thereby significantly enhancing the interactive experience for users of LLMs. The framework adeptly manages the visibility of the streaming input to the model, allowing it to infer from incomplete user input or await additional content. Compared with traditional inference methods on complete user input, our approach demonstrates an average reduction in response latency of 84.0% on the MMLU dataset and 71.6% on the MMLU-Pro dataset, while maintaining comparable accuracy. Additionally, our framework facilitates collaborative inference and output across different models. By employing an large LLM for inference and a small LLM for output, we achieve an average 37% reduction in response latency, alongside a 4.30% improvement in accuracy on the MMLU-Pro dataset compared with the baseline. The proposed LiveMind framework advances the field of human-AI interaction by enabling more responsive and efficient communication between users and AI systems.", "published": "2024-11-07 05:00:00", "id": "39c3092e-174a-47a6-929c-6060177b5dd2", "source": "arxiv", "section": "computerScience"}, {"title": "Identifying and Solving Conditional Image Leakage in Image-to-Video Diffusion Model", "link": "https://arxiv.org/abs/2406.15735", "description": "arXiv:2406.15735v3 Announce Type: replace \nAbstract: Diffusion models have obtained substantial progress in image-to-video generation. However, in this paper, we find that these models tend to generate videos with less motion than expected. We attribute this to the issue called conditional image leakage, where the image-to-video diffusion models (I2V-DMs) tend to over-rely on the conditional image at large time steps. We further address this challenge from both inference and training aspects. First, we propose to start the generation process from an earlier time step to avoid the unreliable large-time steps of I2V-DMs, as well as an initial noise distribution with optimal analytic expressions (Analytic-Init) by minimizing the KL divergence between it and the actual marginal distribution to bridge the training-inference gap. Second, we design a time-dependent noise distribution (TimeNoise) for the conditional image during training, applying higher noise levels at larger time steps to disrupt it and reduce the model's dependency on it. We validate these general strategies on various I2V-DMs on our collected open-domain image benchmark and the UCF101 dataset. Extensive results show that our methods outperform baselines by producing higher motion scores with lower errors while maintaining image alignment and temporal consistency, thereby yielding superior overall performance and enabling more accurate motion control. The project page: \\url{https://cond-image-leak.github.io/}.", "published": "2024-11-07 05:00:00", "id": "ad91d186-3c9f-4671-9fca-89d72cbfc6ec", "source": "arxiv", "section": "computerScience"}, {"title": "AudioBench: A Universal Benchmark for Audio Large Language Models", "link": "https://arxiv.org/abs/2406.16020", "description": "arXiv:2406.16020v4 Announce Type: replace \nAbstract: We introduce AudioBench, a universal benchmark designed to evaluate Audio Large Language Models (AudioLLMs). It encompasses 8 distinct tasks and 26 datasets, among which, 7 are newly proposed datasets. The evaluation targets three main aspects: speech understanding, audio scene understanding, and voice understanding (paralinguistic). Despite recent advancements, there lacks a comprehensive benchmark for AudioLLMs on instruction following capabilities conditioned on audio signals. AudioBench addresses this gap by setting up datasets as well as desired evaluation metrics. Besides, we also evaluated the capabilities of five popular models and found that no single model excels consistently across all tasks. We outline the research outlook for AudioLLMs and anticipate that our open-sourced evaluation toolkit, data, and leaderboard will offer a robust testbed for future model developments.", "published": "2024-11-07 05:00:00", "id": "d5836031-962d-44bd-add3-c0d57703a2a1", "source": "arxiv", "section": "computerScience"}, {"title": "Building on Efficient Foundations: Effectively Training LLMs with Structured Feedforward Layers", "link": "https://arxiv.org/abs/2406.16450", "description": "arXiv:2406.16450v2 Announce Type: replace \nAbstract: State-of-the-art results in large language models (LLMs) often rely on scale, which becomes computationally expensive. This has sparked a research agenda to reduce these models' parameter counts and computational costs without significantly impacting their performance. Our study focuses on transformer-based LLMs, specifically targeting the computationally intensive feedforward networks (FFNs), which are less studied than attention blocks. We consider three structured linear parameterizations of the FFN using efficient low-rank and block-diagonal matrices. In contrast to many previous works that examined these approximations, our study i) explores these structures from a training-from-scratch perspective, ii) scales up to 1.3B parameters, and iii) is conducted within recent Transformer-based LLMs rather than convolutional architectures. We demonstrate that these structures can lead to actual computational gains in various scenarios, including online decoding when using a pre-merge technique. Additionally, we propose a novel training regime, called \\textit{self-guided training}, aimed at improving the poor training dynamics that these approximations exhibit when used from initialization. Interestingly, the scaling performance of structured matrices is explored, revealing steeper curves in scaling training FLOPs, along with a favorable scaling trend in the overtraining regime. Specifically, we show that wide and structured networks can utilize training FLOPs more efficiently, with fewer parameters and lower loss than dense models at their optimal trade-off. Our code is available at \\url{https://github.com/CLAIRE-Labo/StructuredFFN/tree/main}.", "published": "2024-11-07 05:00:00", "id": "35e0659e-23d3-4b5f-83b4-b04c9fb7fc01", "source": "arxiv", "section": "computerScience"}, {"title": "D2SP: Dynamic Dual-Stage Purification Framework for Dual Noise Mitigation in Vision-based Affective Recognition", "link": "https://arxiv.org/abs/2406.16473", "description": "arXiv:2406.16473v2 Announce Type: replace \nAbstract: The contemporary state-of-the-art of Dynamic Facial Expression Recognition (DFER) technology facilitates remarkable progress by deriving emotional mappings of facial expressions from video content, underpinned by training on voluminous datasets. Yet, the DFER datasets encompass a substantial volume of noise data. Noise arises from low-quality captures that defy logical labeling, and instances that suffer from mislabeling due to annotation bias, engendering two principal types of uncertainty: the uncertainty regarding data usability and the uncertainty concerning label reliability. Addressing the two types of uncertainty, we have meticulously crafted a two-stage framework aiming at \\textbf{S}eeking \\textbf{C}ertain data \\textbf{I}n extensive \\textbf{U}ncertain data (SCIU). This initiative aims to purge the DFER datasets of these uncertainties, thereby ensuring that only clean, verified data is employed in training processes. To mitigate the issue of low-quality samples, we introduce the Coarse-Grained Pruning (CGP) stage, which assesses sample weights and prunes those deemed unusable due to their low weight. For samples with incorrect annotations, the Fine-Grained Correction (FGC) stage evaluates prediction stability to rectify mislabeled data. Moreover, SCIU is conceived as a universally compatible, plug-and-play framework, tailored to integrate seamlessly with prevailing DFER methodologies. Rigorous experiments across prevalent DFER datasets and against numerous benchmark methods substantiates SCIU's capacity to markedly elevate performance metrics.", "published": "2024-11-07 05:00:00", "id": "408a01f3-3b12-4961-9c93-127a0eec1d78", "source": "arxiv", "section": "computerScience"}, {"title": "Generalized Dynamic Brain Functional Connectivity Based on Random Convolutions", "link": "https://arxiv.org/abs/2406.16619", "description": "arXiv:2406.16619v3 Announce Type: replace \nAbstract: Dynamic functional connectivity (DFC) analysis has been widely applied to functional magnetic resonance imaging (fMRI) data to reveal time-varying dynamic changes of brain states. The sliding window method is by far the most popular DFC analysis method due to its simplicity. However, the sliding window method comes with some assumptions, namely the typically approach uses a single window which captures dynamics only within a specific frequency range. In this study, we propose a generalized approach to dynamics via a multi-dimensional random convolution (RandCon) DFC method that is able to effectively capture time-varying DFC at arbitrary time scales by extracting different local features from fMRI time series using a number of multi-dimensional random convolution kernels without the need for learning kernel weights. Compared to a standard sliding window method, multiplication of temporal derivatives (MTD) and phase synchrony methods, RandCon with the smallest kernel size (3 time points) showed notable improvements in performance on simulated data, particularly in terms of DFC temporal and spatial estimation in very short window/kernel size under different noise levels. Results from real fMRI data indicated that RandCon was more sensitive to gender differences than competing methods. Furthermore, we show that the sliding window method can be considered a special case of the proposed multi-dimensional convolution framework. The proposed method is simple and efficient significantly broadens the scope of dynamic functional connectivity research and offer theoretical and practical potential.", "published": "2024-11-07 05:00:00", "id": "6c0c68b7-254b-4637-9d49-c6c2f9af547e", "source": "arxiv", "section": "computerScience"}, {"title": "MT2ST: Adaptive Multi-Task to Single-Task Learning", "link": "https://arxiv.org/abs/2406.18038", "description": "arXiv:2406.18038v2 Announce Type: replace \nAbstract: The conventional training approaches often face challenges in balancing the breadth of multi-task learning (MTL) with the depth of single-task learning (STL). To address this issue, we introduce the Multi-Task to Single-Task (MT2ST) framework, a groundbreaking approach that can combine the generalizability of MTL with the precision of STL. Our work include two strategies: 'Diminish' and 'Switch'. 'Diminish' Strategy will gradually reduce the influence of auxiliary tasks, while the 'Switch' strategy involves a shift from multi-tasking to single-tasking at a specific timepoint at the training process.\n  In this paper, we propose the Multi-Task to Single-Task (MT2ST) framework, a novel approach that significantly enhances the efficiency and accuracy of word embedding training while concurrently addressing prevalent issues such as overfitting. Our empirical studies demonstrate that MT2ST can reduce training time by 67% when contrasted with single-task learning approaches, and by 13% compared to traditional multi-task learning methods. These findings underscore MT2ST's potential to be a powerful tools for word embedding training acceleration. The code implementation is can be found at: https://github.com/NoakLiu/MT2ST-Word-Embeddings-Acceleration.", "published": "2024-11-07 05:00:00", "id": "478f93f1-0749-4303-ba76-ef15829030a5", "source": "arxiv", "section": "computerScience"}, {"title": "MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization", "link": "https://arxiv.org/abs/2406.18379", "description": "arXiv:2406.18379v2 Announce Type: replace \nAbstract: Binary malware summarization aims to automatically generate human-readable descriptions of malware behaviors from executable files, facilitating tasks like malware cracking and detection. Previous methods based on Large Language Models (LLMs) have shown great promise. However, they still face significant issues, including poor usability, inaccurate explanations,and incomplete summaries, primarily due to the obscure pseudocode structure and the lack of malware training summaries. Further, calling relationships between functions, which involve the rich interactions within a binary malware, remain largely underexplored. To this end, we propose MALSIGHT, a novel code summarization framework that can iteratively generate descriptions of binary malware by exploring malicious source code and benign pseudocode. Specifically, we construct the first malware summary dataset, MalS and MalP, using an LLM and manually refine this dataset with human effort. At the training stage, we tune our proposed MalT5, a novel LLM-based code model, on the MalS and benign pseudocode datasets. Then, at the test stage, we iteratively feed the pseudocode functions into MalT5 to obtain the summary. Such a procedure facilitates the understanding of pseudocode structure and captures the intricate interactions between functions, thereby benefiting summaries' usability, accuracy, and completeness. Additionally, we propose a novel evaluation benchmark, BLEURT-sum, to measure the quality of summaries. Experiments on three datasets show the effectiveness of the proposed MALSIGHT. Notably, our proposed MalT5, with only 0.77B parameters, delivers comparable performance to much larger Code-Llama.", "published": "2024-11-07 05:00:00", "id": "1ff54935-529f-4a9c-9122-3f045351fd0b", "source": "arxiv", "section": "computerScience"}, {"title": "Semantic orchestration and exploitation of material data: A dataspace solution demonstrated on steel and copper applications", "link": "https://arxiv.org/abs/2406.19509", "description": "arXiv:2406.19509v3 Announce Type: replace \nAbstract: In materials science and manufacturing, vast amounts of heterogeneous data (e.g., measurement and simulation logs, process data, publications) serve as the bedrock of valuable knowledge for various engineering applications. However, efficiently storing and managing this diverse data poses challenges due to limited standardization and integration across different organizational units. Addressing these challenges is essential to fully unlock the potential of data-driven approaches. This paper introduces novel, comprehensive semantic methodology tailored to materials engineering and realized as a technology stack named Dataspace Management System (DSMS), which powers dataspace solutions that leverage the knowledge encoded in heterogeneous data sources to support data-driven insights and to derive new knowledge. At its core, DSMS offers a distinctive knowledge management approach tuned to meet the specific requirements of the materials science and manufacturing domain, all while adhering to the FAIR principles. DSMS provides functionalities for data integration, linkage, exploration, visualization, processing, data sharing, and services (e.g., consulting) to support engineers in decision-making, design and optimization. We present an architectural overview of DSMS, outlining its core concepts and their technological implementation, as well as demonstrate its applicability to common data-processing tasks through use cases from the StahlDigital and KupferDigital research projects within Germany's MaterialDigital initiative.", "published": "2024-11-07 05:00:00", "id": "fd160cea-9e4e-43df-9f5d-9461395ce9a6", "source": "arxiv", "section": "computerScience"}, {"title": "Hierarchical Temporal Context Learning for Camera-based Semantic Scene Completion", "link": "https://arxiv.org/abs/2407.02077", "description": "arXiv:2407.02077v4 Announce Type: replace \nAbstract: Camera-based 3D semantic scene completion (SSC) is pivotal for predicting complicated 3D layouts with limited 2D image observations. The existing mainstream solutions generally leverage temporal information by roughly stacking history frames to supplement the current frame, such straightforward temporal modeling inevitably diminishes valid clues and increases learning difficulty. To address this problem, we present HTCL, a novel Hierarchical Temporal Context Learning paradigm for improving camera-based semantic scene completion. The primary innovation of this work involves decomposing temporal context learning into two hierarchical steps: (a) cross-frame affinity measurement and (b) affinity-based dynamic refinement. Firstly, to separate critical relevant context from redundant information, we introduce the pattern affinity with scale-aware isolation and multiple independent learners for fine-grained contextual correspondence modeling. Subsequently, to dynamically compensate for incomplete observations, we adaptively refine the feature sampling locations based on initially identified locations with high affinity and their neighboring relevant regions. Our method ranks $1^{st}$ on the SemanticKITTI benchmark and even surpasses LiDAR-based methods in terms of mIoU on the OpenOccupancy benchmark. Our code is available on https://github.com/Arlo0o/HTCL.", "published": "2024-11-07 05:00:00", "id": "817d2880-6216-42e8-abb8-5458f52a87a4", "source": "arxiv", "section": "computerScience"}, {"title": "Towards a Scalable Reference-Free Evaluation of Generative Models", "link": "https://arxiv.org/abs/2407.02961", "description": "arXiv:2407.02961v2 Announce Type: replace \nAbstract: While standard evaluation scores for generative models are mostly reference-based, a reference-dependent assessment of generative models could be generally difficult due to the unavailability of applicable reference datasets. Recently, the reference-free entropy scores, VENDI and RKE, have been proposed to evaluate the diversity of generated data. However, estimating these scores from data leads to significant computational costs for large-scale generative models. In this work, we leverage the random Fourier features framework to reduce the computational price and propose the Fourier-based Kernel Entropy Approximation (FKEA) method. We utilize FKEA's approximated eigenspectrum of the kernel matrix to efficiently estimate the mentioned entropy scores. Furthermore, we show the application of FKEA's proxy eigenvectors to reveal the method's identified modes in evaluating the diversity of produced samples. We provide a stochastic implementation of the FKEA assessment algorithm with a complexity $O(n)$ linearly growing with sample size $n$. We extensively evaluate FKEA's numerical performance in application to standard image, text, and video datasets. Our empirical results indicate the method's scalability and interpretability applied to large-scale generative models. The codebase is available at https://github.com/aziksh-ospanov/FKEA.", "published": "2024-11-07 05:00:00", "id": "5c5456a3-ba1d-4958-98a2-0ebd76ff5d47", "source": "arxiv", "section": "computerScience"}, {"title": "The Selective G-Bispectrum and its Inversion: Applications to G-Invariant Networks", "link": "https://arxiv.org/abs/2407.07655", "description": "arXiv:2407.07655v2 Announce Type: replace \nAbstract: An important problem in signal processing and deep learning is to achieve \\textit{invariance} to nuisance factors not relevant for the task. Since many of these factors are describable as the action of a group $G$ (e.g. rotations, translations, scalings), we want methods to be $G$-invariant. The $G$-Bispectrum extracts every characteristic of a given signal up to group action: for example, the shape of an object in an image, but not its orientation. Consequently, the $G$-Bispectrum has been incorporated into deep neural network architectures as a computational primitive for $G$-invariance\\textemdash akin to a pooling mechanism, but with greater selectivity and robustness. However, the computational cost of the $G$-Bispectrum ($\\mathcal{O}(|G|^2)$, with $|G|$ the size of the group) has limited its widespread adoption. Here, we show that the $G$-Bispectrum computation contains redundancies that can be reduced into a \\textit{selective $G$-Bispectrum} with $\\mathcal{O}(|G|)$ complexity. We prove desirable mathematical properties of the selective $G$-Bispectrum and demonstrate how its integration in neural networks enhances accuracy and robustness compared to traditional approaches, while enjoying considerable speeds-up compared to the full $G$-Bispectrum.", "published": "2024-11-07 05:00:00", "id": "9f16f67e-7bda-4c07-a0c4-241e2c0b74b2", "source": "arxiv", "section": "computerScience"}, {"title": "Self-supervised 3D Point Cloud Completion via Multi-view Adversarial Learning", "link": "https://arxiv.org/abs/2407.09786", "description": "arXiv:2407.09786v2 Announce Type: replace \nAbstract: In real-world scenarios, scanned point clouds are often incomplete due to occlusion issues. The task of self-supervised point cloud completion involves reconstructing missing regions of these incomplete objects without the supervision of complete ground truth. Current self-supervised methods either rely on multiple views of partial observations for supervision or overlook the intrinsic geometric similarity that can be identified and utilized from the given partial point clouds. In this paper, we propose MAL-SPC, a framework that effectively leverages both object-level and category-specific geometric similarities to complete missing structures. Our MAL-SPC does not require any 3D complete supervision and only necessitates a single partial point cloud for each object. Specifically, we first introduce a Pattern Retrieval Network to retrieve similar position and curvature patterns between the partial input and the predicted shape, then leverage these similarities to densify and refine the reconstructed results. Additionally, we render the reconstructed complete shape into multi-view depth maps and design an adversarial learning module to learn the geometry of the target shape from category-specific single-view depth images. To achieve anisotropic rendering, we design a density-aware radius estimation algorithm to improve the quality of the rendered images. Our MAL-SPC yields the best results compared to current state-of-the-art methods.We will make the source code publicly available at \\url{https://github.com/ltwu6/malspc", "published": "2024-11-07 05:00:00", "id": "d7e4ddb7-a5bf-4270-a804-055aa10c475a", "source": "arxiv", "section": "computerScience"}, {"title": "CIBench: Evaluating Your LLMs with a Code Interpreter Plugin", "link": "https://arxiv.org/abs/2407.10499", "description": "arXiv:2407.10499v3 Announce Type: replace \nAbstract: While LLM-Based agents, which use external tools to solve complex problems, have made significant progress, benchmarking their ability is challenging, thereby hindering a clear understanding of their limitations. In this paper, we propose an interactive evaluation framework, named CIBench, to comprehensively assess LLMs' ability to utilize code interpreters for data science tasks. Our evaluation framework includes an evaluation dataset and two evaluation modes. The evaluation dataset is constructed using an LLM-human cooperative approach and simulates an authentic workflow by leveraging consecutive and interactive IPython sessions. The two evaluation modes assess LLMs' ability with and without human assistance. We conduct extensive experiments to analyze the ability of 24 LLMs on CIBench and provide valuable insights for future LLMs in code interpreter utilization.", "published": "2024-11-07 05:00:00", "id": "b7c1febf-cc86-40bc-a855-ec43c013128d", "source": "arxiv", "section": "computerScience"}, {"title": "No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen Representations", "link": "https://arxiv.org/abs/2407.10964", "description": "arXiv:2407.10964v2 Announce Type: replace \nAbstract: This paper introduces FUNGI, Features from UNsupervised GradIents, a method to enhance the features of transformer encoders by leveraging self-supervised gradients. Our method is simple: given any pretrained model, we first compute gradients from various self-supervised objectives for each input. These gradients are projected to a lower dimension and then concatenated with the model's output embedding. The resulting features are evaluated on k-nearest neighbor classification over 11 datasets from vision, 5 from natural language processing, and 2 from audio. Across backbones spanning various sizes and pretraining strategies, FUNGI features provide consistent performance improvements over the embeddings. We also show that using FUNGI features can benefit linear classification, clustering and image retrieval, and that they significantly improve the retrieval-based in-context scene understanding abilities of pretrained models, for example improving upon DINO by +17% for semantic segmentation - without any training.", "published": "2024-11-07 05:00:00", "id": "2114a2b0-b6c9-4ecb-9e39-d2df2d1d8c15", "source": "arxiv", "section": "computerScience"}, {"title": "A Safe and Data-efficient Model-based Reinforcement Learning System for HVAC Control", "link": "https://arxiv.org/abs/2407.12195", "description": "arXiv:2407.12195v2 Announce Type: replace \nAbstract: Model-Based Reinforcement Learning (MBRL) has been widely studied for Heating, Ventilation, and Air Conditioning (HVAC) control in buildings. One of the critical challenges is the large amount of data required to effectively train neural networks for modeling building dynamics. This paper presents CLUE, an MBRL system for HVAC control in buildings. CLUE optimizes HVAC operations by integrating a Gaussian Process (GP) model to model building dynamics with uncertainty awareness. CLUE utilizes GP to predict state transitions as Gaussian distributions, effectively capturing prediction uncertainty and enhancing decision-making under sparse data conditions. Our approach employs a meta-kernel learning technique to efficiently set GP kernel hyperparameters using domain knowledge from diverse buildings. This drastically reduces the data requirements typically associated with GP models in HVAC applications. Additionally, CLUE incorporates these uncertainty estimates into a Model Predictive Path Integral (MPPI) algorithm, enabling the selection of safe, energy-efficient control actions. This uncertainty-aware control strategy evaluates and selects action trajectories based on their predicted impact on energy consumption and human comfort, optimizing operations even under uncertain conditions. Extensive simulations in a five-zone office building demonstrate that CLUE reduces the required training data from hundreds of days to just seven while maintaining robust control performance. It reduces comfort violations by an average of 12.07% compared to existing MBRL methods, without compromising on energy efficiency.", "published": "2024-11-07 05:00:00", "id": "347f0dc7-6615-4bc5-bcec-289e81e30bb8", "source": "arxiv", "section": "computerScience"}, {"title": "NutriBench: A Dataset for Evaluating Large Language Models in Carbohydrate Estimation from Meal Descriptions", "link": "https://arxiv.org/abs/2407.12843", "description": "arXiv:2407.12843v3 Announce Type: replace \nAbstract: Accurate nutrition estimation helps people make informed dietary choices and is essential in the prevention of serious health complications. We present NutriBench, the first publicly available natural language meal description nutrition benchmark. NutriBench consists of 11,857 meal descriptions generated from real-world global dietary intake data. The data is human-verified and annotated with macro-nutrient labels, including carbohydrates, proteins, fats, and calories. We conduct an extensive evaluation of NutriBench on the task of carbohydrate estimation, testing twelve leading Large Language Models (LLMs), including GPT-4o, Llama3.1, Qwen2, Gemma2, and OpenBioLLM models, using standard, Chain-of-Thought and Retrieval-Augmented Generation strategies. Additionally, we present a study involving professional nutritionists, finding that LLMs can provide more accurate and faster estimates. Finally, we perform a real-world risk assessment by simulating the effect of carbohydrate predictions on the blood glucose levels of individuals with diabetes. Our work highlights the opportunities and challenges of using LLMs for nutrition estimation, demonstrating their potential to aid professionals and laypersons and improve health outcomes. Our benchmark is publicly available at: https://mehak126.github.io/nutribench.html", "published": "2024-11-07 05:00:00", "id": "3296d79b-d68d-440e-a180-f5cd01244bc3", "source": "arxiv", "section": "computerScience"}, {"title": "Routing Experts: Learning to Route Dynamic Experts in Multi-modal Large Language Models", "link": "https://arxiv.org/abs/2407.14093", "description": "arXiv:2407.14093v2 Announce Type: replace \nAbstract: Recently, mixture of experts (MoE) has become a popular paradigm for achieving the trade-off between modal capacity and efficiency of multi-modal large language models (MLLMs). Different from previous efforts, we are dedicated to exploring the dynamic expert path in an already exist MLLM and show that a standard MLLM can be also a mixture of experts. To approach this target, we propose a novel dynamic expert scheme for MLLMs, termed Routing Experts (RoE), which can achieve example-dependent optimal path routing without obvious structure tweaks. Meanwhile, a new regularization of structure sparsity is also introduced to enforce MLLMs to learn more short-cut inference, ensuring the efficiency. In addition, we also realize the first attempt of aligning the training and inference schemes of MLLMs in terms of network routing. To validate RoE, we apply it to a set of latest MLLMs, including LLaVA-1.5, LLaVA-HR and VILA, and conduct extensive experiments on a bunch of VL benchmarks. The experiment results not only show the great advantages of our RoE in improving MLLMs' efficiency, but also yield obvious advantages than MoE-LLaVA in both performance and speed, e.g., an average performance gain of 3.3% on 5 benchmarks while being faster.", "published": "2024-11-07 05:00:00", "id": "f248de52-15b5-48ce-873d-cd4bab1e3eb7", "source": "arxiv", "section": "computerScience"}, {"title": "Improving Context-Aware Preference Modeling for Language Models", "link": "https://arxiv.org/abs/2407.14916", "description": "arXiv:2407.14916v2 Announce Type: replace \nAbstract: While finetuning language models from pairwise preferences has proven remarkably effective, the underspecified nature of natural language presents critical challenges. Direct preference feedback is uninterpretable, difficult to provide where multidimensional criteria may apply, and often inconsistent, either because it is based on incomplete instructions or provided by diverse principals. To address these challenges, we consider the two-step preference modeling procedure that first resolves the under-specification by selecting a context, and then evaluates preference with respect to the chosen context. We decompose reward modeling error according to these two steps, which suggests that supervising context in addition to context-specific preference may be a viable approach to aligning models with diverse human preferences. For this to work, the ability of models to evaluate context-specific preference is critical. To this end, we contribute context-conditioned preference datasets and accompanying experiments that investigate the ability of language models to evaluate context-specific preference. We use our datasets to (1) show that existing preference models benefit from, but fail to fully consider, added context, (2) finetune a context-aware reward model with context-specific performance exceeding that of GPT-4 and Llama 3 70B on tested datasets, and (3) investigate the value of context-aware preference modeling.", "published": "2024-11-07 05:00:00", "id": "c3b5aae2-2310-4bcd-8e1e-bc1355f64fe6", "source": "arxiv", "section": "computerScience"}, {"title": "SLVideo: A Sign Language Video Moment Retrieval Framework", "link": "https://arxiv.org/abs/2407.15668", "description": "arXiv:2407.15668v2 Announce Type: replace \nAbstract: SLVideo is a video moment retrieval system for Sign Language videos that incorporates facial expressions, addressing this gap in existing technology. The system extracts embedding representations for the hand and face signs from video frames to capture the signs in their entirety, enabling users to search for a specific sign language video segment with text queries. A collection of eight hours of annotated Portuguese Sign Language videos is used as the dataset, and a CLIP model is used to generate the embeddings. The initial results are promising in a zero-shot setting. In addition, SLVideo incorporates a thesaurus that enables users to search for similar signs to those retrieved, using the video segment embeddings, and also supports the edition and creation of video sign language annotations. Project web page: https://novasearch.github.io/SLVideo/", "published": "2024-11-07 05:00:00", "id": "4f8f8ef5-a123-4c53-9b7f-f6059fa9508d", "source": "arxiv", "section": "computerScience"}, {"title": "Multi-label Cluster Discrimination for Visual Representation Learning", "link": "https://arxiv.org/abs/2407.17331", "description": "arXiv:2407.17331v2 Announce Type: replace \nAbstract: Contrastive Language Image Pre-training (CLIP) has recently demonstrated success across various tasks due to superior feature representation empowered by image-text contrastive learning. However, the instance discrimination method used by CLIP can hardly encode the semantic structure of training data. To handle this limitation, cluster discrimination has been proposed through iterative cluster assignment and classification. Nevertheless, most cluster discrimination approaches only define a single pseudo-label for each image, neglecting multi-label signals in the image. In this paper, we propose a novel Multi-Label Cluster Discrimination method named MLCD to enhance representation learning. In the clustering step, we first cluster the large-scale LAION-400M dataset into one million centers based on off-the-shelf embedding features. Considering that natural images frequently contain multiple visual objects or attributes, we select the multiple closest centers as auxiliary class labels. In the discrimination step, we design a novel multi-label classification loss, which elegantly separates losses from positive classes and negative classes, and alleviates ambiguity on decision boundary. We validate the proposed multi-label cluster discrimination method with experiments on different scales of models and pre-training datasets. Experimental results show that our method achieves state-of-the-art performance on multiple downstream tasks including linear probe, zero-shot classification, and image-text retrieval. Code and models have been released at https://github.com/deepglint/unicom .", "published": "2024-11-07 05:00:00", "id": "b79a6d61-6adc-4916-8455-7cf9b7fc74ae", "source": "arxiv", "section": "computerScience"}, {"title": "BetterDepth: Plug-and-Play Diffusion Refiner for Zero-Shot Monocular Depth Estimation", "link": "https://arxiv.org/abs/2407.17952", "description": "arXiv:2407.17952v2 Announce Type: replace \nAbstract: By training over large-scale datasets, zero-shot monocular depth estimation (MDE) methods show robust performance in the wild but often suffer from insufficient detail. Although recent diffusion-based MDE approaches exhibit a superior ability to extract details, they struggle in geometrically complex scenes that challenge their geometry prior, trained on less diverse 3D data. To leverage the complementary merits of both worlds, we propose BetterDepth to achieve geometrically correct affine-invariant MDE while capturing fine details. Specifically, BetterDepth is a conditional diffusion-based refiner that takes the prediction from pre-trained MDE models as depth conditioning, in which the global depth layout is well-captured, and iteratively refines details based on the input image. For the training of such a refiner, we propose global pre-alignment and local patch masking methods to ensure BetterDepth remains faithful to the depth conditioning while learning to add fine-grained scene details. With efficient training on small-scale synthetic datasets, BetterDepth achieves state-of-the-art zero-shot MDE performance on diverse public datasets and on in-the-wild scenes. Moreover, BetterDepth can improve the performance of other MDE models in a plug-and-play manner without further re-training.", "published": "2024-11-07 05:00:00", "id": "4c7d7b7f-909e-4a60-be03-3e7d3e67cb49", "source": "arxiv", "section": "computerScience"}, {"title": "Efficiently and Effectively: A Two-stage Approach to Balance Plaintext and Encrypted Text for Traffic Classification", "link": "https://arxiv.org/abs/2407.19687", "description": "arXiv:2407.19687v3 Announce Type: replace \nAbstract: Encrypted traffic classification is the task of identifying the application or service associated with encrypted network traffic. One effective approach for this task is to use deep learning methods to encode the raw traffic bytes directly and automatically extract features for classification (byte-based models). However, current byte-based models input raw traffic bytes, whether plaintext or encrypted text, for automated feature extraction, neglecting the distinct impacts of plaintext and encrypted text on downstream tasks. Additionally, these models primarily focus on improving classification accuracy, with little emphasis on the efficiency of models. In this paper, for the first time, we analyze the impact of plaintext and encrypted text on the model's effectiveness and efficiency. Based on our observations and findings, we propose a two-phase approach to balance the trade-off between plaintext and encrypted text in traffic classification. Specifically, Stage one is to Determine whether the Plain text is enough to be accurately Classified (DPC) using the proposed DPC Selector. This stage quickly identifies samples that can be classified using plaintext, leveraging explicit byte features in plaintext to enhance model's efficiency. Stage two aims to adaptively make a classification with the result from stage one. This stage incorporates encrypted text information for samples that cannot be classified using plaintext alone, ensuring the model's effectiveness on traffic classification tasks. Experiments on two datasets demonstrate that our proposed model achieves state-of-the-art results in both effectiveness and efficiency.", "published": "2024-11-07 05:00:00", "id": "f7a619ae-9724-469d-876b-73fcf74521f6", "source": "arxiv", "section": "computerScience"}, {"title": "colorspace: A Python Toolbox for Manipulating and Assessing Colors and Palettes", "link": "https://arxiv.org/abs/2407.19921", "description": "arXiv:2407.19921v2 Announce Type: replace \nAbstract: The Python colorspace package provides a toolbox for mapping between different color spaces which can then be used to generate a wide range of perceptually-based color palettes for qualitative or quantitative (sequential or diverging) information. These palettes (as well as any other sets of colors) can be visualized, assessed, and manipulated in various ways, e.g., by color swatches, emulating the effects of color vision deficiencies, or depicting the perceptual properties. Finally, the color palettes generated by the package can be easily integrated into standard visualization workflows in Python, e.g., using matplotlib, seaborn, or plotly.", "published": "2024-11-07 05:00:00", "id": "d248ec0c-4cb7-4f8f-8004-6428a60ac23b", "source": "arxiv", "section": "computerScience"}, {"title": "Tree-Cotree-Based Tearing and Interconnecting for 3D Magnetostatics: A Dual-Primal Approach", "link": "https://arxiv.org/abs/2407.21707", "description": "arXiv:2407.21707v2 Announce Type: replace \nAbstract: The simulation of electromagnetic devices with complex geometries and large-scale discrete systems benefits from advanced computational methods like IsoGeometric Analysis and Domain Decomposition. In this paper, we employ both concepts in an Isogeometric Tearing and Interconnecting method to enable the use of parallel computations for magnetostatic problems. We address the underlying non-uniqueness by using a graph-theoretic approach, the tree-cotree decomposition. The classical tree-cotree gauging is adapted to be feasible for parallelization, which requires that all local subsystems are uniquely solvable. Our contribution consists of an explicit algorithm for constructing compatible trees and combining it with a dual-primal approach to enable parallelization. The correctness of the proposed approach is proved and verified by numerical experiments, showing its accuracy, scalability and optimal convergence.", "published": "2024-11-07 05:00:00", "id": "4824121a-3514-41ac-993c-05d793cabda1", "source": "arxiv", "section": "computerScience"}, {"title": "Virchow2: Scaling Self-Supervised Mixed Magnification Models in Pathology", "link": "https://arxiv.org/abs/2408.00738", "description": "arXiv:2408.00738v3 Announce Type: replace \nAbstract: Foundation models are rapidly being developed for computational pathology applications. However, it remains an open question which factors are most important for downstream performance with data scale and diversity, model size, and training algorithm all playing a role. In this work, we propose algorithmic modifications, tailored for pathology, and we present the result of scaling both data and model size, surpassing previous studies in both dimensions. We introduce three new models: Virchow2, a 632 million parameter vision transformer, Virchow2G, a 1.9 billion parameter vision transformer, and Virchow2G Mini, a 22 million parameter distillation of Virchow2G, each trained with 3.1 million histopathology whole slide images, with diverse tissues, originating institutions, and stains. We achieve state of the art performance on 12 tile-level tasks, as compared to the top performing competing models. Our results suggest that data diversity and domain-specific methods can outperform models that only scale in the number of parameters, but, on average, performance benefits from the combination of domain-specific methods, data scale, and model scale.", "published": "2024-11-07 05:00:00", "id": "f384e49e-a785-43e2-adb1-ab2cd78c27b6", "source": "arxiv", "section": "computerScience"}, {"title": "A Real-Time Adaptive Multi-Stream GPU System for Online Approximate Nearest Neighborhood Search", "link": "https://arxiv.org/abs/2408.02937", "description": "arXiv:2408.02937v2 Announce Type: replace \nAbstract: In recent years, Approximate Nearest Neighbor Search (ANNS) has played a pivotal role in modern search and recommendation systems, especially in emerging LLM applications like Retrieval-Augmented Generation. There is a growing exploration into harnessing the parallel computing capabilities of GPUs to meet the substantial demands of ANNS. However, existing systems primarily focus on offline scenarios, overlooking the distinct requirements of online applications that necessitate real-time insertion of new vectors. This limitation renders such systems inefficient for real-world scenarios. Moreover, previous architectures struggled to effectively support real-time insertion due to their reliance on serial execution streams. In this paper, we introduce a novel Real-Time Adaptive Multi-Stream GPU ANNS System (RTAMS-GANNS). Our architecture achieves its objectives through three key advancements: 1) We initially examined the real-time insertion mechanisms in existing GPU ANNS systems and discovered their reliance on repetitive copying and memory allocation, which significantly hinders real-time effectiveness on GPUs. As a solution, we introduce a dynamic vector insertion algorithm based on memory blocks, which includes in-place rearrangement. 2) To enable real-time vector insertion in parallel, we introduce a multi-stream parallel execution mode, which differs from existing systems that operate serially within a single stream. Our system utilizes a dynamic resource pool, allowing multiple streams to execute concurrently without additional execution blocking. 3) Through extensive experiments and comparisons, our approach effectively handles varying QPS levels across different datasets, reducing latency by up to 40%-80%. The proposed system has also been deployed in real-world industrial search and recommendation systems, serving hundreds of millions of users daily, and has achieved good results.", "published": "2024-11-07 05:00:00", "id": "6cb74b40-aaa8-4426-8d70-c634cdc5fa2e", "source": "arxiv", "section": "computerScience"}, {"title": "Reducing Matroid Optimization to Basis Search", "link": "https://arxiv.org/abs/2408.04118", "description": "arXiv:2408.04118v2 Announce Type: replace \nAbstract: Matroids provide one of the most elegant structures for algorithm design. This is best identified by the Edmonds-Rado theorem relating the success of the simple greedy algorithm to the anatomy of the optimal basis of a matroid [Edm71; Rad57]. As a response, much energy has been devoted to understanding a matroid's computational properties. Yet, less is understood where parallel algorithms are concerned. In response, we initiate the study of parallel matroid optimization in the adaptive complexity model [BS18]. First, we reexamine Bor\\r{u}vka's classical minimum weight spanning tree algorithm [Bor26b; Bor26a] in the abstract language of matroid theory, and identify a new certificate of optimality for the basis of any matroid as a result. In particular, a basis is optimal if and only if it contains the points of minimum weight in every circuit of the dual matroid. Hence, we can witnesses whether any specific point belongs to the optimal basis via a test for local optimality in a circuit of the dual matroid, thereby revealing a general design paradigm towards parallel matroid optimization. To instantiate this paradigm, we use the special structure of a binary matroid to identify an optimization scheme with low adaptivity. Here, our key technical step is reducing optimization to the simpler task of basis search in the binary matroid, using only logarithmic overhead of adaptive rounds of queries to independence oracles. Consequentially, we compose our reduction with the parallel basis search method of [KUW88] to obtain an algorithm for finding the optimal basis of a binary matroid terminating in sublinearly many adaptive rounds of queries to an independence oracle. To the authors' knowledge, this is the first algorithm for matroid optimization to outperform the greedy algorithm in terms of adaptive complexity in the independence query model without assuming the matroid is encoded by a graph.", "published": "2024-11-07 05:00:00", "id": "4d2042ff-f914-445c-88c5-d3411b62dbdc", "source": "arxiv", "section": "computerScience"}, {"title": "Hotfixing Large Language Models for Code", "link": "https://arxiv.org/abs/2408.05727", "description": "arXiv:2408.05727v4 Announce Type: replace \nAbstract: Large Language Models for Code (LLM4Code) have become an integral part of developers' workflows, assisting with tasks such as code completion and generation. However, these models are found to exhibit undesired behaviors after their release, like generating buggy code, due to their extensive training on vast amounts of source code that contain such buggy code. The training data (usually coming from open-source software) keeps evolving, e.g., developers fix the buggy code. However, adapting such evolution to mitigate LLM4Code's undesired behaviors is non-trivial, as retraining models on the updated dataset usually takes much time and resources. This motivates us to propose the concept of hotfixing LLM4Code, mitigating LLM4Code's undesired behaviors effectively and efficiently with minimal negative effects. This paper mainly focuses on hotfixing LLM4Code to make them generate less buggy code and more fixed code. We begin by demonstrating that models from the popular CodeGen family frequently generate buggy code. Then, we define three learning objectives in hotfixing and design multiple loss functions for each objective: (1) learn the desired behaviors, (2) unlearn the undesired behaviors, and (3) retain knowledge of other code. We evaluate four different fine-tuning techniques for hotfixing the models and gain the following insights. Optimizing these three learning goals together, using LoRA (low-rank adaptation), effectively influences the model's behavior. Specifically, it increases the generation of fixed code by up to 108.42% and decreases the generation of buggy code by up to 50.47%. Statistical tests confirm that hotfixing does not significantly affect the models' functional correctness on the HumanEval benchmark. Additionally, to evaluate the generalizability of hotfixing by reducing the exposure of email addresses by 99.30%.", "published": "2024-11-07 05:00:00", "id": "937bc1e0-7320-4c82-83a7-e77036ec2ede", "source": "arxiv", "section": "computerScience"}, {"title": "LADDER: Language Driven Slice Discovery and Error Rectification", "link": "https://arxiv.org/abs/2408.07832", "description": "arXiv:2408.07832v5 Announce Type: replace \nAbstract: Error slice discovery associates structured patterns with model errors. Existing methods discover error slices by clustering the error-prone samples with similar patterns or assigning discrete attributes to each sample for post-hoc analysis. While these methods aim for interpretability and easier mitigation through reweighting or rebalancing, they may not capture the full complexity of error patterns due to incomplete or missing attributes. Contrary to the existing approach, this paper utilizes the reasoning capabilities of the Large Language Model (LLM) to analyze complex error patterns and generate testable hypotheses. This paper proposes LADDER: Language Driven slice Discovery and Error Rectification. It first projects the model's representation into a language-aligned feature space (eg CLIP) to preserve semantics in the original model feature space. This ensures the accurate retrieval of sentences that highlight the model's errors. Next, the LLM utilizes the sentences and generates hypotheses to discover error slices. Finally, we mitigate the error by fine-tuning the classification head by creating a group-balanced dataset using the hypotheses. Our entire method does not require any attribute annotation, either explicitly or through external tagging models. We validate our method with \\textbf{five} image classification datasets.", "published": "2024-11-07 05:00:00", "id": "d40e517d-c304-4959-94d5-1f36699e0134", "source": "arxiv", "section": "computerScience"}, {"title": "ELASTIC: Efficient Linear Attention for Sequential Interest Compression", "link": "https://arxiv.org/abs/2408.09380", "description": "arXiv:2408.09380v3 Announce Type: replace \nAbstract: State-of-the-art sequential recommendation models heavily rely on transformer's attention mechanism. However, the quadratic computational and memory complexities of self attention have limited its scalability for modeling users' long range behaviour sequences. To address this problem, we propose ELASTIC, an Efficient Linear Attention for SequenTial Interest Compression, requiring only linear time complexity and decoupling model capacity from computational cost. Specifically, ELASTIC introduces a fixed length interest experts with linear dispatcher attention mechanism which compresses the long-term behaviour sequences to a significantly more compact representation which reduces up to 90% GPU memory usage with x2.7 inference speed up. The proposed linear dispatcher attention mechanism significantly reduces the quadratic complexity and makes the model feasible for adequately modeling extremely long sequences. Moreover, in order to retain the capacity for modeling various user interests, ELASTIC initializes a vast learnable interest memory bank and sparsely retrieves compressed user's interests from the memory with a negligible computational overhead. The proposed interest memory retrieval technique significantly expands the cardinality of available interest space while keeping the same computational cost, thereby striking a trade-off between recommendation accuracy and efficiency. To validate the effectiveness of our proposed ELASTIC, we conduct extensive experiments on various public datasets and compare it with several strong sequential recommenders. Experimental results demonstrate that ELASTIC consistently outperforms baselines by a significant margin and also highlight the computational efficiency of ELASTIC when modeling long sequences. We will make our implementation code publicly available.", "published": "2024-11-07 05:00:00", "id": "2f726239-ef0b-49f0-9810-8de617db5b1f", "source": "arxiv", "section": "computerScience"}, {"title": "CIPHER: Cybersecurity Intelligent Penetration-testing Helper for Ethical Researcher", "link": "https://arxiv.org/abs/2408.11650", "description": "arXiv:2408.11650v2 Announce Type: replace \nAbstract: Penetration testing, a critical component of cybersecurity, typically requires extensive time and effort to find vulnerabilities. Beginners in this field often benefit from collaborative approaches with the community or experts. To address this, we develop CIPHER (Cybersecurity Intelligent Penetration-testing Helper for Ethical Researchers), a large language model specifically trained to assist in penetration testing tasks. We trained CIPHER using over 300 high-quality write-ups of vulnerable machines, hacking techniques, and documentation of open-source penetration testing tools. Additionally, we introduced the Findings, Action, Reasoning, and Results (FARR) Flow augmentation, a novel method to augment penetration testing write-ups to establish a fully automated pentesting simulation benchmark tailored for large language models. This approach fills a significant gap in traditional cybersecurity Q\\&amp;A benchmarks and provides a realistic and rigorous standard for evaluating AI's technical knowledge, reasoning capabilities, and practical utility in dynamic penetration testing scenarios. In our assessments, CIPHER achieved the best overall performance in providing accurate suggestion responses compared to other open-source penetration testing models of similar size and even larger state-of-the-art models like Llama 3 70B and Qwen1.5 72B Chat, particularly on insane difficulty machine setups. This demonstrates that the current capabilities of general LLMs are insufficient for effectively guiding users through the penetration testing process. We also discuss the potential for improvement through scaling and the development of better benchmarks using FARR Flow augmentation results. Our benchmark will be released publicly at https://github.com/ibndias/CIPHER.", "published": "2024-11-07 05:00:00", "id": "e3fc8eff-4322-46fa-9fcb-3d2053fd3509", "source": "arxiv", "section": "computerScience"}, {"title": "OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs", "link": "https://arxiv.org/abs/2408.11832", "description": "arXiv:2408.11832v2 Announce Type: replace \nAbstract: The increased use of large language models (LLMs) across a variety of real-world applications calls for automatic tools to check the factual accuracy of their outputs, as LLMs often hallucinate. This is difficult as it requires assessing the factuality of free-form open-domain responses. While there has been a lot of research on this topic, different papers use different evaluation benchmarks and measures, which makes them hard to compare and hampers future progress. To mitigate these issues, we developed OpenFactCheck, a unified framework, with three modules: (i) RESPONSEEVAL, which allows users to easily customize an automatic fact-checking system and to assess the factuality of all claims in an input document using that system, (ii) LLMEVAL, which assesses the overall factuality of an LLM, and (iii) CHECKEREVAL, a module to evaluate automatic fact-checking systems. OpenFactCheck is open-sourced (https://github.com/mbzuai-nlp/openfactcheck) and publicly released as a Python library (https://pypi.org/project/openfactcheck/) and also as a web service (http://app.openfactcheck.com). A video describing the system is available at https://youtu.be/-i9VKL0HleI.", "published": "2024-11-07 05:00:00", "id": "bde88291-5404-44f6-8b5b-3fc273ad9afe", "source": "arxiv", "section": "computerScience"}, {"title": "Domain Adaptation for Offline Reinforcement Learning with Limited Samples", "link": "https://arxiv.org/abs/2408.12136", "description": "arXiv:2408.12136v2 Announce Type: replace \nAbstract: Offline reinforcement learning (RL) learns effective policies from a static target dataset. Despite state-of-the-art (SOTA) offline RL algorithms being promising, they highly rely on the quality of the target dataset. The performance of SOTA algorithms can degrade in scenarios with limited samples in the target dataset, which is often the case in real-world applications. To address this issue, domain adaptation that leverages auxiliary samples from related source datasets (such as simulators) can be beneficial. In this context, determining the optimal way to trade off the source and target datasets remains a critical challenge in offline RL. To the best of our knowledge, this paper proposes the first framework that theoretically and experimentally explores how the weight assigned to each dataset affects the performance of offline RL. We establish the performance bounds and convergence neighborhood of our framework, both of which depend on the selection of the weight. Furthermore, we identify the existence of an optimal weight for balancing the two datasets. All theoretical guarantees and optimal weight depend on the quality of the source dataset and the size of the target dataset. Our empirical results on the well-known Procgen Benchmark substantiate our theoretical contributions.", "published": "2024-11-07 05:00:00", "id": "4d26cf96-791b-428b-b4c0-4978732812c0", "source": "arxiv", "section": "computerScience"}, {"title": "Lecture Notes on Linear Neural Networks: A Tale of Optimization and Generalization in Deep Learning", "link": "https://arxiv.org/abs/2408.13767", "description": "arXiv:2408.13767v2 Announce Type: replace \nAbstract: These notes are based on a lecture delivered by NC on March 2021, as part of an advanced course in Princeton University on the mathematical understanding of deep learning. They present a theory (developed by NC, NR and collaborators) of linear neural networks -- a fundamental model in the study of optimization and generalization in deep learning. Practical applications born from the presented theory are also discussed. The theory is based on mathematical tools that are dynamical in nature. It showcases the potential of such tools to push the envelope of our understanding of optimization and generalization in deep learning. The text assumes familiarity with the basics of statistical learning theory. Exercises (without solutions) are included.", "published": "2024-11-07 05:00:00", "id": "28bec155-6b73-43d7-a7a0-9c92d9845fe3", "source": "arxiv", "section": "computerScience"}, {"title": "Revisiting Surgical Instrument Segmentation Without Human Intervention: A Graph Partitioning View", "link": "https://arxiv.org/abs/2408.14789", "description": "arXiv:2408.14789v2 Announce Type: replace \nAbstract: Surgical instrument segmentation (SIS) on endoscopic images stands as a long-standing and essential task in the context of computer-assisted interventions for boosting minimally invasive surgery. Given the recent surge of deep learning methodologies and their data-hungry nature, training a neural predictive model based on massive expert-curated annotations has been dominating and served as an off-the-shelf approach in the field, which could, however, impose prohibitive burden to clinicians for preparing fine-grained pixel-wise labels corresponding to the collected surgical video frames. In this work, we propose an unsupervised method by reframing the video frame segmentation as a graph partitioning problem and regarding image pixels as graph nodes, which is significantly different from the previous efforts. A self-supervised pre-trained model is firstly leveraged as a feature extractor to capture high-level semantic features. Then, Laplacian matrixs are computed from the features and are eigendecomposed for graph partitioning. On the \"deep\" eigenvectors, a surgical video frame is meaningfully segmented into different modules such as tools and tissues, providing distinguishable semantic information like locations, classes, and relations. The segmentation problem can then be naturally tackled by applying clustering or threshold on the eigenvectors. Extensive experiments are conducted on various datasets (e.g., EndoVis2017, EndoVis2018, UCL, etc.) for different clinical endpoints. Across all the challenging scenarios, our method demonstrates outstanding performance and robustness higher than unsupervised state-of-the-art (SOTA) methods. The code is released at https://github.com/MingyuShengSMY/GraphClusteringSIS.git.", "published": "2024-11-07 05:00:00", "id": "473b0592-2fc8-4a09-bbf2-d6ea1ed50cb6", "source": "arxiv", "section": "computerScience"}, {"title": "Asymptotic Preserving Linearly Implicit Additive IMEX-RK Finite Volume Schemes for Low Mach Number Isentropic Euler Equations", "link": "https://arxiv.org/abs/2409.05854", "description": "arXiv:2409.05854v2 Announce Type: replace \nAbstract: We consider the compressible Euler equations of gas dynamics with isentropic equation of state. Standard numerical schemes for the Euler equations suffer from stability and accuracy issues in the low Mach regime. These failures are attributed to the transitional behaviour of the governing equations from compressible to incompressible solution in the limit of vanishing Mach number. In this paper we introduce an extra flux term to the momentum flux. This extra term is recognised by looking at the constraints of the incompressible limit system. As a consequence the flux terms enable us to get a suitable splitting, so that an additive IMEX-RK scheme could be applied. Using an elliptic reformulation the scheme boils down to just solving a linear elliptic problem for the density and then explicit updates for the momentum. The IMEX schemes developed are shown to be formally asymptotically consistent with the low Mach number limit of the Euler equations and are shown to be linearly $L^2$ stable. A second order space time fully discrete scheme is obtained in the finite volume framework using a combination of Rusanov flux for the explicit part and simple central differences for the implicit part. Results of numerical case studies are reported which elucidate the theoretical assertions regarding the scheme and its robustness.", "published": "2024-11-07 05:00:00", "id": "b007eb90-1d11-428e-9f6a-14729765b878", "source": "arxiv", "section": "computerScience"}, {"title": "Compute-Update Federated Learning: A Lattice Coding Approach Over-the-Air", "link": "https://arxiv.org/abs/2409.06343", "description": "arXiv:2409.06343v2 Announce Type: replace \nAbstract: This paper introduces a federated learning framework that enables over-the-air computation via digital communications, using a new joint source-channel coding scheme. Without relying on channel state information at devices, this scheme employs lattice codes to both quantize model parameters and exploit interference from the devices. We propose a novel receiver structure at the server, designed to reliably decode an integer combination of the quantized model parameters as a lattice point for the purpose of aggregation. We present a mathematical approach to derive a convergence bound for the proposed scheme and offer design remarks. In this context, we suggest an aggregation metric and a corresponding algorithm to determine effective integer coefficients for the aggregation in each communication round. Our results illustrate that, regardless of channel dynamics and data heterogeneity, our scheme consistently delivers superior learning accuracy across various parameters and markedly surpasses other over-the-air methodologies.", "published": "2024-11-07 05:00:00", "id": "ff9b3d07-f6fa-4859-a059-6805c77f3231", "source": "arxiv", "section": "computerScience"}, {"title": "The Converse of the Real Orthogonal Holant Theorem", "link": "https://arxiv.org/abs/2409.06911", "description": "arXiv:2409.06911v2 Announce Type: replace \nAbstract: The Holant theorem is a powerful tool for studying the computational complexity of counting problems in the Holant framework. Due to the great expressiveness of the Holant framework, a converse to the Holant theorem would itself be a very powerful counting indistinguishability theorem. The most general converse does not hold, but we prove the following, still highly general, version: if any two sets of real-valued signatures are Holant-indistinguishable, then they are equivalent up to an orthogonal transformation. This resolves a partially open conjecture of Xia (2010). Consequences of this theorem include the well-known result that homomorphism counts from all graphs determine a graph up to isomorphism, the classical sufficient condition for simultaneous orthogonal similarity of sets of real matrices, and a combinatorial characterization of simultaneosly orthogonally decomposable (odeco) sets of symmetric tensors.", "published": "2024-11-07 05:00:00", "id": "e1707b1a-924e-4ac7-ac0c-39d18609cc55", "source": "arxiv", "section": "computerScience"}, {"title": "IFAdapter: Instance Feature Control for Grounded Text-to-Image Generation", "link": "https://arxiv.org/abs/2409.08240", "description": "arXiv:2409.08240v3 Announce Type: replace \nAbstract: While Text-to-Image (T2I) diffusion models excel at generating visually appealing images of individual instances, they struggle to accurately position and control the features generation of multiple instances. The Layout-to-Image (L2I) task was introduced to address the positioning challenges by incorporating bounding boxes as spatial control signals, but it still falls short in generating precise instance features. In response, we propose the Instance Feature Generation (IFG) task, which aims to ensure both positional accuracy and feature fidelity in generated instances. To address the IFG task, we introduce the Instance Feature Adapter (IFAdapter). The IFAdapter enhances feature depiction by incorporating additional appearance tokens and utilizing an Instance Semantic Map to align instance-level features with spatial locations. The IFAdapter guides the diffusion process as a plug-and-play module, making it adaptable to various community models. For evaluation, we contribute an IFG benchmark and develop a verification pipeline to objectively compare models' abilities to generate instances with accurate positioning and features. Experimental results demonstrate that IFAdapter outperforms other models in both quantitative and qualitative evaluations.", "published": "2024-11-07 05:00:00", "id": "d2b78675-6398-4873-820b-f0030bd5dd7b", "source": "arxiv", "section": "computerScience"}, {"title": "Distributed Binary Optimization with In-Memory Computing: An Application for the SAT Problem", "link": "https://arxiv.org/abs/2409.09152", "description": "arXiv:2409.09152v2 Announce Type: replace \nAbstract: In-memory computing (IMC) has been shown to be a promising approach for solving binary optimization problems while significantly reducing energy and latency. Building on the advantages of parallel computation, we propose an IMC-compatible parallelism framework inspired by parallel tempering (PT), enabling cross-replica communication to improve the performance of IMC solvers. This framework enables an IMC solver not only to improve performance beyond what can be achieved through parallelization, but also affords greater flexibility for the search process with low hardware overhead. We justify that the framework can be applied to almost any IMC solver. We demonstrate the effectiveness of the framework for the Boolean satisfiability (SAT) problem, using the WalkSAT heuristic as a proxy for existing IMC solvers. The resulting PT-inspired cooperative WalkSAT (PTIC-WalkSAT) algorithm outperforms the traditional WalkSAT heuristic in terms of the iterations-to-solution in 76.3% of the tested problem instances and its na\\\"ive parallel variant (PA-WalkSAT) does so in 68.4% of the instances. An estimate of the energy overhead of the PTIC framework for two hardware accelerator architectures indicates that in both cases the overhead of running the PTIC framework would be less than 1% of the total energy required to run each accelerator.", "published": "2024-11-07 05:00:00", "id": "23b0952e-ee03-4ae6-8336-b2926af83164", "source": "arxiv", "section": "computerScience"}, {"title": "Generalizing Alignment Paradigm of Text-to-Image Generation with Preferences through $f$-divergence Minimization", "link": "https://arxiv.org/abs/2409.09774", "description": "arXiv:2409.09774v3 Announce Type: replace \nAbstract: Direct Preference Optimization (DPO) has recently expanded its successful application from aligning large language models (LLMs) to aligning text-to-image models with human preferences, which has generated considerable interest within the community. However, we have observed that these approaches rely solely on minimizing the reverse Kullback-Leibler divergence during alignment process between the fine-tuned model and the reference model, neglecting the incorporation of other divergence constraints. In this study, we focus on extending reverse Kullback-Leibler divergence in the alignment paradigm of text-to-image models to $f$-divergence, which aims to garner better alignment performance as well as good generation diversity. We provide the generalized formula of the alignment paradigm under the $f$-divergence condition and thoroughly analyze the impact of different divergence constraints on alignment process from the perspective of gradient fields. We conduct comprehensive evaluation on image-text alignment performance, human value alignment performance and generation diversity performance under different divergence constraints, and the results indicate that alignment based on Jensen-Shannon divergence achieves the best trade-off among them. The option of divergence employed for aligning text-to-image models significantly impacts the trade-off between alignment performance (especially human value alignment) and generation diversity, which highlights the necessity of selecting an appropriate divergence for practical applications.", "published": "2024-11-07 05:00:00", "id": "b7fe8d9f-126e-456e-829e-74d509fabd2b", "source": "arxiv", "section": "computerScience"}, {"title": "Maritime Cybersecurity: A Comprehensive Review", "link": "https://arxiv.org/abs/2409.11417", "description": "arXiv:2409.11417v3 Announce Type: replace \nAbstract: The maritime industry stands at a critical juncture, where the imperative for technological advancement intersects with the pressing need for robust cybersecurity measures. Maritime cybersecurity refers to the protection of computer systems and digital assests within the maritime industry, as well as the broader network of interconnected components that make up the maritime ecosystem. In this survey, we aim to identify the significant domains of maritime cybersecurity and measure their effectiveness. We have provided an in-depth analysis of threats in key maritime systems, including AIS, GNSS, ECDIS, VDR, RADAR, VSAT, and GMDSS, while exploring real-world cyber incidents that have impacted the sector. A multi-dimensional taxonomy of maritime cyber attacks is presented, offering insights into threat actors, motivations, and impacts. We have also evaluated various security solutions, from integrated solutions to component specific solutions. Finally, we have shared open challenges and future solutions. In the supplementary section, we have presented definitions and vulnerabilities of vessel components that have discussed in this survey. By addressing all these critical issues with key interconnected aspects, this review aims to foster a more resilient maritime ecosystem.", "published": "2024-11-07 05:00:00", "id": "0bdf8c18-f196-41b9-8b4a-b5eddf9d44f0", "source": "arxiv", "section": "computerScience"}, {"title": "TalkMosaic: Interactive PhotoMosaic with Multi-modal LLM Q&A Interactions", "link": "https://arxiv.org/abs/2409.13941", "description": "arXiv:2409.13941v2 Announce Type: replace \nAbstract: We use images of cars of a wide range of varieties to compose an image of an animal such as a bird or a lion for the theme of environmental protection to maximize the information about cars in a single composed image and to raise the awareness about environmental challenges. We present a novel way of image interaction with an artistically-composed photomosaic image, in which a simple operation of \"click and display\" is used to demonstrate the interactive switch between a tile image in a photomosaic image and the corresponding original car image, which will be automatically saved on the Desktop. We build a multimodal custom GPT named TalkMosaic by incorporating car images information and the related knowledge to ChatGPT. By uploading the original car image to TalkMosaic, we can ask questions about the given car image and get the corresponding answers efficiently and effectively such as where to buy the tire in the car image that satisfies high environmental standards. We give an in-depth analysis on how to speed up the inference of multimodal LLM using sparse attention and quantization techniques with presented probabilistic FlashAttention (PrFlashAttention) and Staircase Adaptive Quantization (SAQ) methods. The implemented prototype demonstrates the feasibility and effectiveness of the presented approach.", "published": "2024-11-07 05:00:00", "id": "ec3ce012-df51-4aa5-b5b1-3c9f0e0ead14", "source": "arxiv", "section": "computerScience"}, {"title": "The Roles of Generative Artificial Intelligence in Internet of Electric Vehicles", "link": "https://arxiv.org/abs/2409.15750", "description": "arXiv:2409.15750v2 Announce Type: replace \nAbstract: With the advancements of generative artificial intelligence (GenAI) models, their capabilities are expanding significantly beyond content generation and the models are increasingly being used across diverse applications. Particularly, GenAI shows great potential in addressing challenges in the electric vehicle (EV) ecosystem ranging from charging management to cyber-attack prevention. In this paper, we specifically consider Internet of electric vehicles (IoEV) and we categorize GenAI for IoEV into four different layers namely, EV's battery layer, individual EV layer, smart grid layer, and security layer. We introduce various GenAI techniques used in each layer of IoEV applications. Subsequently, public datasets available for training the GenAI models are summarized. Finally, we provide recommendations for future directions. This survey not only categorizes the applications of GenAI in IoEV across different layers but also serves as a valuable resource for researchers and practitioners by highlighting the design and implementation challenges within each layer. Furthermore, it provides a roadmap for future research directions, enabling the development of more robust and efficient IoEV systems through the integration of advanced GenAI techniques.", "published": "2024-11-07 05:00:00", "id": "45e1cf69-0d64-41d7-8b21-19f9d1838e50", "source": "arxiv", "section": "computerScience"}, {"title": "TabEBM: A Tabular Data Augmentation Method with Distinct Class-Specific Energy-Based Models", "link": "https://arxiv.org/abs/2409.16118", "description": "arXiv:2409.16118v3 Announce Type: replace \nAbstract: Data collection is often difficult in critical fields such as medicine, physics, and chemistry. As a result, classification methods usually perform poorly with these small datasets, leading to weak predictive performance. Increasing the training set with additional synthetic data, similar to data augmentation in images, is commonly believed to improve downstream classification performance. However, current tabular generative methods that learn either the joint distribution $ p(\\mathbf{x}, y) $ or the class-conditional distribution $ p(\\mathbf{x} \\mid y) $ often overfit on small datasets, resulting in poor-quality synthetic data, usually worsening classification performance compared to using real data alone. To solve these challenges, we introduce TabEBM, a novel class-conditional generative method using Energy-Based Models (EBMs). Unlike existing methods that use a shared model to approximate all class-conditional densities, our key innovation is to create distinct EBM generative models for each class, each modelling its class-specific data distribution individually. This approach creates robust energy landscapes, even in ambiguous class distributions. Our experiments show that TabEBM generates synthetic data with higher quality and better statistical fidelity than existing methods. When used for data augmentation, our synthetic data consistently improves the classification performance across diverse datasets of various sizes, especially small ones. Code is available at https://github.com/andreimargeloiu/TabEBM.", "published": "2024-11-07 05:00:00", "id": "ae3a4400-ae04-4643-aee9-09819c151c06", "source": "arxiv", "section": "computerScience"}, {"title": "Gaussian Deja-vu: Creating Controllable 3D Gaussian Head-Avatars with Enhanced Generalization and Personalization Abilities", "link": "https://arxiv.org/abs/2409.16147", "description": "arXiv:2409.16147v3 Announce Type: replace \nAbstract: Recent advancements in 3D Gaussian Splatting (3DGS) have unlocked significant potential for modeling 3D head avatars, providing greater flexibility than mesh-based methods and more efficient rendering compared to NeRF-based approaches. Despite these advancements, the creation of controllable 3DGS-based head avatars remains time-intensive, often requiring tens of minutes to hours. To expedite this process, we here introduce the \"Gaussian Deja-vu\" framework, which first obtains a generalized model of the head avatar and then personalizes the result. The generalized model is trained on large 2D (synthetic and real) image datasets. This model provides a well-initialized 3D Gaussian head that is further refined using a monocular video to achieve the personalized head avatar. For personalizing, we propose learnable expression-aware rectification blendmaps to correct the initial 3D Gaussians, ensuring rapid convergence without the reliance on neural networks. Experiments demonstrate that the proposed method meets its objectives. It outperforms state-of-the-art 3D Gaussian head avatars in terms of photorealistic quality as well as reduces training time consumption to at least a quarter of the existing methods, producing the avatar in minutes.", "published": "2024-11-07 05:00:00", "id": "ae4807c4-7c3c-4fa2-8a0b-3882a699bf4e", "source": "arxiv", "section": "computerScience"}, {"title": "Counterfactual Token Generation in Large Language Models", "link": "https://arxiv.org/abs/2409.17027", "description": "arXiv:2409.17027v2 Announce Type: replace \nAbstract: \"Sure, I am happy to generate a story for you: Captain Lyra stood at the helm of her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...] Lyra's eyes welled up with tears as she realized the bitter truth - she had sacrificed everything for fleeting riches, and lost the love of her crew, her family, and herself.\" Although this story, generated by a large language model, is captivating, one may wonder -- how would the story have unfolded if the model had chosen \"Captain Maeve\" as the protagonist instead? We cannot know. State-of-the-art large language models are stateless -- they maintain no internal memory or state. Given a prompt, they generate a sequence of tokens as an output using an autoregressive process. As a consequence, they cannot reason about counterfactual alternatives to tokens they have generated in the past. In this work, our goal is to enhance them with this functionality. To this end, we develop a causal model of token generation that builds upon the Gumbel-Max structural causal model. Our model allows any large language model to perform counterfactual token generation at almost no cost in comparison with vanilla token generation, it is embarrassingly simple to implement, and it does not require any fine-tuning nor prompt engineering. We implement our model on Llama 3 8B-Instruct and Ministral-8B-Instruct and conduct a qualitative and a quantitative analysis of counterfactually generated text. We conclude with a demonstrative application of counterfactual token generation for bias detection, unveiling interesting insights about the model of the world constructed by large language models.", "published": "2024-11-07 05:00:00", "id": "b3ea4f63-4628-41e0-89e8-a4f268242acd", "source": "arxiv", "section": "computerScience"}, {"title": "TFS-NeRF: Template-Free NeRF for Semantic 3D Reconstruction of Dynamic Scene", "link": "https://arxiv.org/abs/2409.17459", "description": "arXiv:2409.17459v2 Announce Type: replace \nAbstract: Despite advancements in Neural Implicit models for 3D surface reconstruction, handling dynamic environments with arbitrary rigid, non-rigid, or deformable entities remains challenging. Many template-based methods are entity-specific, focusing on humans, while generic reconstruction methods adaptable to such dynamic scenes often require additional inputs like depth or optical flow or rely on pre-trained image features for reasonable outcomes. These methods typically use latent codes to capture frame-by-frame deformations. In contrast, some template-free methods bypass these requirements and adopt traditional LBS (Linear Blend Skinning) weights for a detailed representation of deformable object motions, although they involve complex optimizations leading to lengthy training times. To this end, as a remedy, this paper introduces TFS-NeRF, a template-free 3D semantic NeRF for dynamic scenes captured from sparse or single-view RGB videos, featuring interactions among various entities and more time-efficient than other LBS-based approaches. Our framework uses an Invertible Neural Network (INN) for LBS prediction, simplifying the training process. By disentangling the motions of multiple entities and optimizing per-entity skinning weights, our method efficiently generates accurate, semantically separable geometries. Extensive experiments demonstrate that our approach produces high-quality reconstructions of both deformable and non-deformable objects in complex interactions, with improved training efficiency compared to existing methods.", "published": "2024-11-07 05:00:00", "id": "4f68b05f-4aa9-40ad-9753-1379d34476f9", "source": "arxiv", "section": "computerScience"}, {"title": "Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models", "link": "https://arxiv.org/abs/2409.18680", "description": "arXiv:2409.18680v3 Announce Type: replace \nAbstract: Various audio-LLMs (ALLMs) have been explored recently for tackling different audio tasks simultaneously using a single, unified model. While existing evaluations of ALLMs primarily focus on single-audio tasks, real-world applications often involve processing multiple audio streams simultaneously. To bridge this gap, we propose the first multi-audio evaluation (MAE) benchmark that consists of 20 datasets from 11 multi-audio tasks encompassing both speech and sound scenarios. Comprehensive experiments on MAE demonstrate that the existing ALLMs, while being powerful in comprehending primary audio elements in individual audio inputs, struggling to handle multi-audio scenarios. To this end, we propose a novel multi-audio-LLM (MALLM) to capture audio context among multiple similar audios using discriminative learning on our proposed synthetic data. The results demonstrate that the proposed MALLM outperforms all baselines and achieves high data efficiency using synthetic data without requiring human annotations. The proposed MALLM opens the door for ALLMs towards multi-audio processing era and brings us closer to replicating human auditory capabilities in machines.", "published": "2024-11-07 05:00:00", "id": "83d92bea-f3d3-4d25-82c8-9adf55134088", "source": "arxiv", "section": "computerScience"}, {"title": "Perception Compressor:A training-free prompt compression method in long context scenarios", "link": "https://arxiv.org/abs/2409.19272", "description": "arXiv:2409.19272v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) demonstrate exceptional capabilities in various scenarios. However, they suffer from much redundant information and are sensitive to the position of key information (relevant to the input question) in long context scenarios, leading to inferior performance. To address these challenges, we present Perception Compressor, a training-free prompt compression method. It includes a perception retriever that leverages guiding questions and instruction to retrieve the most relevant demonstrations, a dual-slope ratio allocator to dynamically allocate compression ratios and open-book ratios, and a semi-guided iterative compression that retains key information at the token level while removing tokens that distract the LLM. We conduct extensive experiments on long context benchmarks, i.e., NaturalQuestions, LongBench, and MuSiQue. Experiment results show that Perception Compressor outperforms existing methods by a large margin, achieving state-of-the-art performance.", "published": "2024-11-07 05:00:00", "id": "e7cd8009-d87d-4ce6-b8ad-c1fc106a67b9", "source": "arxiv", "section": "computerScience"}, {"title": "The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems", "link": "https://arxiv.org/abs/2409.20002", "description": "arXiv:2409.20002v2 Announce Type: replace \nAbstract: The wide deployment of Large Language Models (LLMs) has given rise to strong demands for optimizing their inference performance. Today's techniques serving this purpose primarily focus on reducing latency and improving throughput through algorithmic and hardware enhancements, while largely overlooking their privacy side effects, particularly in a multi-user environment. In our research, for the first time, we discovered a set of new timing side channels in LLM systems, arising from shared caches and GPU memory allocations, which can be exploited to infer both confidential system prompts and those issued by other users. These vulnerabilities echo security challenges observed in traditional computing systems, highlighting an urgent need to address potential information leakage in LLM serving infrastructures. In this paper, we report novel attack strategies designed to exploit such timing side channels inherent in LLM deployments, specifically targeting the Key-Value (KV) cache and semantic cache widely used to enhance LLM inference performance. Our approach leverages timing measurements and classification models to detect cache hits, allowing an adversary to infer private prompts with high accuracy. We also propose a token-by-token search algorithm to efficiently recover shared prompt prefixes in the caches, showing the feasibility of stealing system prompts and those produced by peer users. Our experimental studies on black-box testing of popular online LLM services demonstrate that such privacy risks are completely realistic, with significant consequences. Our findings underscore the need for robust mitigation to protect LLM systems against such emerging threats.", "published": "2024-11-07 05:00:00", "id": "76435b30-b855-4dbe-9b80-bc56ce4c3a6c", "source": "arxiv", "section": "computerScience"}, {"title": "Explain Like I'm Five: Using LLMs to Improve PDE Surrogate Models with Text", "link": "https://arxiv.org/abs/2410.01137", "description": "arXiv:2410.01137v4 Announce Type: replace \nAbstract: Solving Partial Differential Equations (PDEs) is ubiquitous in science and engineering. Computational complexity and difficulty in writing numerical solvers has motivated the development of machine learning techniques to generate solutions quickly. Many existing methods are purely data driven, relying solely on numerical solution fields, rather than known system information such as boundary conditions and governing equations. However, the recent rise in popularity of Large Language Models (LLMs) has enabled easy integration of text in multimodal machine learning models. In this work, we use pretrained LLMs to integrate various amounts known system information into PDE learning. Our multimodal approach significantly outperforms our baseline model, FactFormer, in both next-step prediction and autoregressive rollout performance on the 2D Heat, Burgers, Navier-Stokes, and Shallow Water equations. Further analysis shows that pretrained LLMs provide highly structured latent space that is consistent with the amount of system information provided through text.", "published": "2024-11-07 05:00:00", "id": "94032ae9-4392-4650-8cfd-25ccc1202002", "source": "arxiv", "section": "computerScience"}, {"title": "A Probabilistic Perspective on Unlearning and Alignment for Large Language Models", "link": "https://arxiv.org/abs/2410.03523", "description": "arXiv:2410.03523v3 Announce Type: replace \nAbstract: Comprehensive evaluation of Large Language Models (LLMs) is an open research problem. Existing evaluations rely on deterministic point estimates generated via greedy decoding. However, we find that deterministic evaluations fail to capture the whole output distribution of a model, yielding inaccurate estimations of model capabilities. This is particularly problematic in critical contexts such as unlearning and alignment, where precise model evaluations are crucial. To remedy this, we introduce the first formal probabilistic evaluation framework in LLMs. Namely, we derive novel metrics with high-probability guarantees concerning the output distribution of a model. Our metrics are application-independent and allow practitioners to make more reliable estimates about model capabilities before deployment. Through a case study focused on unlearning, we reveal that deterministic evaluations falsely indicate successful unlearning, whereas our probabilistic evaluations demonstrate that most if not all of the supposedly unlearned information remains accessible in these models. Additionally, we propose a novel unlearning loss based on entropy optimization and adaptive temperature scaling, which significantly improves unlearning in probabilistic settings on recent benchmarks. Our proposed shift from point estimates to probabilistic evaluations of output distributions represents an important step toward comprehensive evaluations of LLMs. Code available at https://github.com/yascho/probabilistic-unlearning.", "published": "2024-11-07 05:00:00", "id": "38e9df12-2ba1-48cf-85f7-98220dfa5c32", "source": "arxiv", "section": "computerScience"}, {"title": "Timer-XL: Long-Context Transformers for Unified Time Series Forecasting", "link": "https://arxiv.org/abs/2410.04803", "description": "arXiv:2410.04803v2 Announce Type: replace \nAbstract: We present Timer-XL, a generative Transformer for unified time series forecasting. To uniformly predict 1D and 2D time series, we generalize next token prediction, predominantly adopted for causal generation of 1D sequences, to multivariate next token prediction. The proposed paradigm uniformly formulates various forecasting scenarios as a long-context generation problem. We opt for the generative Transformer, which can capture global-range and causal dependencies while providing contextual flexibility, to implement unified forecasting on univariate series characterized by non-stationarity, multivariate time series with complicated dynamics and correlations, and covariate-informed contexts that include both endogenous and exogenous variables. Technically, we propose a universal TimeAttention to facilitate generative Transformers on time series, which can effectively capture fine-grained intra- and inter-series dependencies of flattened time series tokens (patches) and is further strengthened by position embeddings in both temporal and variable dimensions. Timer-XL achieves state-of-the-art performance across challenging forecasting benchmarks through a unified approach. As a large time series model, it demonstrates notable model transferability by large-scale pre-training, as well as contextual flexibility in token lengths, positioning it as a one-for-all forecaster.", "published": "2024-11-07 05:00:00", "id": "20456a1b-3d38-41a8-95e6-b39078c1af0d", "source": "arxiv", "section": "computerScience"}, {"title": "Deep neural network-based detection of counterfeit products from smartphone images", "link": "https://arxiv.org/abs/2410.05969", "description": "arXiv:2410.05969v2 Announce Type: replace \nAbstract: Counterfeit products such as drugs and vaccines as well as luxury items such as high-fashion handbags, watches, jewelry, garments, and cosmetics, represent significant direct losses of revenue to legitimate manufacturers and vendors, as well as indirect costs to societies at large. We present the world's first purely computer-vision-based system to combat such counterfeiting-one that does not require special security tags or other alterations to the products or modifications to supply chain tracking. Our deep neural network system shows high accuracy on branded garments from our first manufacturer tested (99.71% after 3.06% rejections) using images captured under natural, weakly controlled conditions, such as in retail stores, customs checkpoints, warehouses, and outdoors. Our system, suitably transfer trained on a small number of fake and genuine articles, should find application in additional product categories as well, for example fashion accessories, perfume boxes, medicines, and more.", "published": "2024-11-07 05:00:00", "id": "bd1add3e-e7b8-40e2-a009-5e2e268cd1be", "source": "arxiv", "section": "computerScience"}, {"title": "Hibikino-Musashi@Home 2024 Team Description Paper", "link": "https://arxiv.org/abs/2410.06192", "description": "arXiv:2410.06192v2 Announce Type: replace \nAbstract: This paper provides an overview of the techniques employed by Hibikino-Musashi@Home, which intends to participate in the domestic standard platform league. The team has developed a dataset generator for training a robot vision system and an open-source development environment running on a Human Support Robot simulator.\n  The large language model powered task planner selects appropriate primitive skills to perform the task requested by users. The team aims to design a home service robot that can assist humans in their homes and continuously attends competitions to evaluate and improve the developed system.", "published": "2024-11-07 05:00:00", "id": "89b82ecb-1ec4-4463-84e5-dda074fc0707", "source": "arxiv", "section": "computerScience"}, {"title": "News Reporter: A Multi-lingual LLM Framework for Broadcast T.V News", "link": "https://arxiv.org/abs/2410.07520", "description": "arXiv:2410.07520v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have fast become an essential tools to many conversational chatbots due to their ability to provide coherent answers for varied queries. Datasets used to train these LLMs are often a mix of generic and synthetic samples, thus lacking the verification needed to provide correct and verifiable answers for T.V. News.\n  We collect and share a large collection of QA pairs extracted from transcripts of news recordings from various news-channels across the United States. Resultant QA pairs are then used to fine-tune an off-the-shelf LLM model. Our model surpasses base models of similar size on several open LLM benchmarks. We further integrate and propose a RAG method to improve contextualization of our answers and also point it to a verifiable news recording.", "published": "2024-11-07 05:00:00", "id": "2d613f6c-d904-4e50-91bd-7bf1f5771190", "source": "arxiv", "section": "computerScience"}, {"title": "The Function-Representation Model of Computation", "link": "https://arxiv.org/abs/2410.07928", "description": "arXiv:2410.07928v3 Announce Type: replace \nAbstract: Cognitive Architectures are the forefront of the research into developing an artificial cognition. However, they approach the problem from a separated memory and program model of computation. This model of computation poses a fundamental problem: the knowledge retrieval heuristic. In this paper we propose to solve this problem by using a novel model of computation, one where memory and program are merged: the Function-Representation. This model of computation involves defining a generic Function-Representation and instantiating multiple instances of it. In this paper we explore the potential of this novel model of computation through mathematical definitions and proofs. We also explore the kind of functions a Function-Representation can implement, and present different ways to organise multiple instances of a Function-Representation.", "published": "2024-11-07 05:00:00", "id": "53f489f5-256d-48d6-96bd-80987da23411", "source": "arxiv", "section": "computerScience"}, {"title": "Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning", "link": "https://arxiv.org/abs/2410.08081", "description": "arXiv:2410.08081v3 Announce Type: replace \nAbstract: Packing, initially utilized in the pre-training phase, is an optimization technique designed to maximize hardware resource efficiency by combining different training sequences to fit the model's maximum input length. Although it has demonstrated effectiveness during pre-training, there remains a lack of comprehensive analysis for the supervised fine-tuning (SFT) stage on the following points: (1) whether packing can effectively enhance training efficiency while maintaining performance, (2) the suitable size of the model and dataset for fine-tuning with the packing method, and (3) whether packing unrelated or related training samples might cause the model to either excessively disregard or over-rely on the context.\n  In this paper, we perform extensive comparisons between SFT methods using padding and packing, covering SFT datasets ranging from 69K to 1.2M and models from 8B to 70B. This provides the first comprehensive analysis of the advantages and limitations of packing versus padding, as well as practical considerations for implementing packing in various training scenarios. Our analysis covers various benchmarks, including knowledge, reasoning, and coding, as well as GPT-based evaluations, time efficiency, and other fine-tuning parameters. We also open-source our code for fine-tuning and evaluation and provide checkpoints fine-tuned on datasets of different sizes, aiming to advance future research on packing methods. Code is available at: https://github.com/ShuheWang1998/Packing-Analysis?tab=readme-ov-file.", "published": "2024-11-07 05:00:00", "id": "a42fc177-76e2-4bd9-ab6f-38f524a9733a", "source": "arxiv", "section": "computerScience"}, {"title": "Obelia: Scaling DAG-Based Blockchains to Hundreds of Validators", "link": "https://arxiv.org/abs/2410.08701", "description": "arXiv:2410.08701v2 Announce Type: replace \nAbstract: Obelia improves upon structured DAG-based consensus protocols used in proof-of-stake systems, allowing them to effectively scale to accommodate hundreds of validators. Obelia implements a two-tier validator system. A core group of high-stake validators that propose blocks as in current protocols and a larger group of lower-stake auxiliary validators that occasionally author blocks. Obelia incentivizes auxiliary validators to assist recovering core validators and integrates seamlessly with existing protocols. We show that Obelia does not introduce visible overhead compared to the original protocol, even when scaling to hundreds of validators, or when a large number of auxiliary validators are unreliable.", "published": "2024-11-07 05:00:00", "id": "35acf71f-9dc7-4a06-ab74-500a382d1303", "source": "arxiv", "section": "computerScience"}, {"title": "SHyPar: A Spectral Coarsening Approach to Hypergraph Partitioning", "link": "https://arxiv.org/abs/2410.10875", "description": "arXiv:2410.10875v2 Announce Type: replace \nAbstract: State-of-the-art hypergraph partitioners utilize a multilevel paradigm to construct progressively coarser hypergraphs across multiple layers, guiding cut refinements at each level of the hierarchy. Traditionally, these partitioners employ heuristic methods for coarsening and do not consider the structural features of hypergraphs. In this work, we introduce a multilevel spectral framework, SHyPar, for partitioning large-scale hypergraphs by leveraging hyperedge effective resistances and flow-based community detection techniques. Inspired by the latest theoretical spectral clustering frameworks, such as HyperEF and HyperSF, SHyPar aims to decompose large hypergraphs into multiple subgraphs with few inter-partition hyperedges (cut size). A key component of SHyPar is a flow-based local clustering scheme for hypergraph coarsening, which incorporates a max-flow-based algorithm to produce clusters with substantially improved conductance. Additionally, SHyPar utilizes an effective resistance-based rating function for merging nodes that are strongly connected (coupled). Compared with existing state-of-the-art hypergraph partitioning methods, our extensive experimental results on real-world VLSI designs demonstrate that SHyPar can more effectively partition hypergraphs, achieving state-of-the-art solution quality.", "published": "2024-11-07 05:00:00", "id": "2c701b4d-5cd5-4ef4-96cf-673d7d7c75ba", "source": "arxiv", "section": "computerScience"}, {"title": "Why Go Full? Elevating Federated Learning Through Partial Network Updates", "link": "https://arxiv.org/abs/2410.11559", "description": "arXiv:2410.11559v3 Announce Type: replace \nAbstract: Federated learning is a distributed machine learning paradigm designed to protect user data privacy, which has been successfully implemented across various scenarios. In traditional federated learning, the entire parameter set of local models is updated and averaged in each training round. Although this full network update method maximizes knowledge acquisition and sharing for each model layer, it prevents the layers of the global model from cooperating effectively to complete the tasks of each client, a challenge we refer to as layer mismatch. This mismatch problem recurs after every parameter averaging, consequently slowing down model convergence and degrading overall performance. To address the layer mismatch issue, we introduce the FedPart method, which restricts model updates to either a single layer or a few layers during each communication round. Furthermore, to maintain the efficiency of knowledge acquisition and sharing, we develop several strategies to select trainable layers in each round, including sequential updating and multi-round cycle training. Through both theoretical analysis and experiments, our findings demonstrate that the FedPart method significantly surpasses conventional full network update strategies in terms of convergence speed and accuracy, while also reducing communication and computational overheads.", "published": "2024-11-07 05:00:00", "id": "fb99e773-7fe8-4e26-bf70-907a7581760a", "source": "arxiv", "section": "computerScience"}, {"title": "Degradation Oriented and Regularized Network for Blind Depth Super-Resolution", "link": "https://arxiv.org/abs/2410.11666", "description": "arXiv:2410.11666v3 Announce Type: replace \nAbstract: Recent RGB-guided depth super-resolution methods have achieved impressive performance under the assumption of fixed and known degradation (e.g., bicubic downsampling). However, in real-world scenarios, captured depth data often suffer from unconventional and unknown degradation due to sensor limitations and complex imaging environments (e.g., low reflective surfaces, varying illumination). Consequently, the performance of these methods significantly declines when real-world degradation deviate from their assumptions. In this paper, we propose the Degradation Oriented and Regularized Network (DORNet), a novel framework designed to adaptively address unknown degradation in real-world scenes through implicit degradation representations. Our approach begins with the development of a self-supervised degradation learning strategy, which models the degradation representations of low-resolution depth data using routing selection-based degradation regularization. To facilitate effective RGB-D fusion, we further introduce a degradation-oriented feature transformation module that selectively propagates RGB content into the depth data based on the learned degradation priors. Extensive experimental results on both real and synthetic datasets demonstrate the superiority of our DORNet in handling unknown degradation, outperforming existing methods. The code is available at https://github.com/yanzq95/DORNet.", "published": "2024-11-07 05:00:00", "id": "6e4c7041-d664-4f0a-9e6a-f24cb800e210", "source": "arxiv", "section": "computerScience"}, {"title": "Evaluating Morphological Compositional Generalization in Large Language Models", "link": "https://arxiv.org/abs/2410.12656", "description": "arXiv:2410.12656v2 Announce Type: replace \nAbstract: Large language models (LLMs) have demonstrated significant progress in various natural language generation and understanding tasks. However, their linguistic generalization capabilities remain questionable, raising doubts about whether these models learn language similarly to humans. While humans exhibit compositional generalization and linguistic creativity in language use, the extent to which LLMs replicate these abilities, particularly in morphology, is under-explored. In this work, we systematically investigate the morphological generalization abilities of LLMs through the lens of compositionality. We define morphemes as compositional primitives and design a novel suite of generative and discriminative tasks to assess morphological productivity and systematicity. Focusing on agglutinative languages such as Turkish and Finnish, we evaluate several state-of-the-art instruction-finetuned multilingual models, including GPT-4 and Gemini. Our analysis shows that LLMs struggle with morphological compositional generalization particularly when applied to novel word roots, with performance declining sharply as morphological complexity increases. While models can identify individual morphological combinations better than chance, their performance lacks systematicity, leading to significant accuracy gaps compared to humans.", "published": "2024-11-07 05:00:00", "id": "5ad47eaa-658d-4ed4-88c0-30ae42db7e88", "source": "arxiv", "section": "computerScience"}, {"title": "Utilizing Large Language Models in an iterative paradigm with Domain feedback for Zero-shot Molecule optimization", "link": "https://arxiv.org/abs/2410.13147", "description": "arXiv:2410.13147v5 Announce Type: replace \nAbstract: Molecule optimization is a critical task in drug discovery to optimize desired properties of a given molecule through chemical modification. Despite Large Language Models (LLMs) holding the potential to efficiently simulate this task by using natural language to direct the optimization, straightforwardly utilizing shows limited performance. In this work, we facilitate utilizing LLMs in an iterative paradigm by proposing a simple yet highly effective domain feedback provider, namely $\\text{Re}^3$DF. In detail, $\\text{Re}^3$DF harnesses an external toolkit, RDKit, to handle the molecule hallucination, if the modified molecule is chemically invalid. Otherwise, its desired properties are computed and compared to the original one, establishing reliable domain feedback with correct direction and distance towards the objective, followed by a retrieved example, to explicitly guide the LLM to refine the modified molecule. We conduct experiments across both single- and multi-property objectives with 2 thresholds, where $\\text{Re}^3$DF shows significant improvements. Particularly, for 20 single-property objectives, $\\text{Re}^3$DF enhances Hit ratio by 16.95% and 20.76% under loose and strict thresholds, respectively. For 32 multi-property objectives, $\\text{Re}^3$DF enhances Hit ratio by 6.04% and 5.25%.", "published": "2024-11-07 05:00:00", "id": "0025d669-466c-420c-a57c-00e38585beaf", "source": "arxiv", "section": "computerScience"}, {"title": "Harnessing Webpage UIs for Text-Rich Visual Understanding", "link": "https://arxiv.org/abs/2410.13824", "description": "arXiv:2410.13824v3 Announce Type: replace \nAbstract: Text-rich visual understanding-the ability to process environments where dense textual content is integrated with visuals-is crucial for multimodal large language models (MLLMs) to interact effectively with structured environments. To enhance this capability, we propose synthesizing general multimodal instructions from webpage UIs using text-based large language models (LLMs). Despite lacking direct visual input, text-based LLMs are able to process structured text representations from webpage accessibility trees. These instructions are then paired with UI screenshots to train multimodal models. We introduce MultiUI, a dataset containing 7.3 million samples from 1 million websites, covering diverse multimodal tasks and UI layouts. Models trained on MultiUI not only excel in web UI tasks-achieving up to a 48% improvement on VisualWebBench and a 19.1% boost in element accuracy on a web agent dataset Mind2Web-but also generalize surprisingly well to non-web UI tasks and even to non-UI domains, such as document understanding, OCR, and chart interpretation. These results highlight the broad applicability of web UI data for advancing text-rich visual understanding across various scenarios.", "published": "2024-11-07 05:00:00", "id": "c451ad28-f10f-4580-9c0d-63b4de347f38", "source": "arxiv", "section": "computerScience"}, {"title": "Diverging Preferences: When do Annotators Disagree and do Models Know?", "link": "https://arxiv.org/abs/2410.14632", "description": "arXiv:2410.14632v2 Announce Type: replace \nAbstract: We examine diverging preferences in human-labeled preference datasets. We develop a taxonomy of disagreement sources spanning 10 categories across four high-level classes -- task underspecification, response style, refusals, and annotation errors. We find that the majority of disagreements are in opposition with standard reward modeling approaches, which are designed with the assumption that annotator disagreement is noise. We then explore how these findings impact two areas of LLM development: reward modeling and evaluation. In our experiments, we demonstrate how standard reward modeling methods, like the Bradley-Terry model, fail to differentiate whether a given preference judgment is the result of unanimous agreement among annotators or the majority opinion among diverging user preferences. We also find that these tendencies are also echoed by popular LLM-as-Judge evaluation methods, which consistently identify a winning response in cases of diverging preferences. These findings highlight remaining challenges in LLM evaluations, which are greatly influenced by divisive features like response style, and in developing pluralistically aligned LLMs. To address these issues, we develop methods for identifying diverging preferences to mitigate their influence on evaluation and training.", "published": "2024-11-07 05:00:00", "id": "1e3b68c9-aa2a-4514-bd2f-71fb86afdde2", "source": "arxiv", "section": "computerScience"}, {"title": "LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics", "link": "https://arxiv.org/abs/2410.16103", "description": "arXiv:2410.16103v2 Announce Type: replace \nAbstract: We introduce LDAdam, a memory-efficient optimizer for training large models, that performs adaptive optimization steps within lower dimensional subspaces, while consistently exploring the full parameter space during training. This strategy keeps the optimizer's memory footprint to a fraction of the model size. LDAdam relies on a new projection-aware update rule for the optimizer states that allows for transitioning between subspaces, i.e., estimation of the statistics of the projected gradients. To mitigate the errors due to low-rank projection, LDAdam integrates a new generalized error feedback mechanism, which explicitly accounts for both gradient and optimizer state compression. We prove the convergence of LDAdam under standard assumptions, and show that LDAdam allows for accurate and efficient fine-tuning and pre-training of language models.", "published": "2024-11-07 05:00:00", "id": "6eb0682f-2109-4eac-91a9-e4b92de83b7c", "source": "arxiv", "section": "computerScience"}, {"title": "Why So Serious? Exploring Humor in AAC Through AI-Powered Interfaces", "link": "https://arxiv.org/abs/2410.16634", "description": "arXiv:2410.16634v2 Announce Type: replace \nAbstract: People with speech disabilities may use speech generating devices to facilitate their speech, aka Augmentative and Alternative Communication (AAC) technology. This technology enables practical conversation; however it remains challenging to deliver expressive and timely comments. In this paper, we study how AAC technology can facilitate such speech, through AI powered interfaces. We focus on the least predictable and most high-paced type: humorous comments. We conducted seven qualitative interviews with people with speech disabilities, and performed thematic analysis to gain in-depth insights in usage and challenges of AAC technology, and the role humor plays for them. We designed four simple AI powered interfaces to create humorous comments. In a user study with five participants with speech disabilities, these interfaces allowed us to study how to best support making well-timed humorous comments. We conclude with a discussion of recommendations for interface design based on both studies.", "published": "2024-11-07 05:00:00", "id": "b3760125-5afc-4363-9d5b-679393117681", "source": "arxiv", "section": "computerScience"}, {"title": "Improving Causal Reasoning in Large Language Models: A Survey", "link": "https://arxiv.org/abs/2410.16676", "description": "arXiv:2410.16676v3 Announce Type: replace \nAbstract: Causal reasoning (CR) is a crucial aspect of intelligence, essential for problem-solving, decision-making, and understanding the world. While large language models (LLMs) can generate rationales for their outputs, their ability to reliably perform causal reasoning remains uncertain, often falling short in tasks requiring a deep understanding of causality. In this survey, we provide a comprehensive review of research aimed at enhancing LLMs for causal reasoning. We categorize existing methods based on the role of LLMs: either as reasoning engines or as helpers providing knowledge or data to traditional CR methods, followed by a detailed discussion of the methodologies in each category. We then evaluate the performance of LLMs on various causal reasoning tasks, providing key findings and in-depth analysis. Finally, we provide insights from current studies and highlight promising directions for future research. We aim for this work to serve as a comprehensive resource, fostering further advancements in causal reasoning with LLMs. Resources are available at https://github.com/chendl02/Awesome-LLM-causal-reasoning.", "published": "2024-11-07 05:00:00", "id": "e40cf11a-b051-4846-a9ea-9dcbe2a3596b", "source": "arxiv", "section": "computerScience"}, {"title": "Evaluation of Systems Programming Exercises through Tailored Static Analysis", "link": "https://arxiv.org/abs/2410.17260", "description": "arXiv:2410.17260v3 Announce Type: replace \nAbstract: In large programming classes, it takes a significant effort from teachers to evaluate exercises and provide detailed feedback. In systems programming, test cases are not sufficient to assess exercises, since concurrency and resource management bugs are difficult to reproduce. This paper presents an experience report on static analysis for the automatic evaluation of systems programming exercises. We design systems programming assignments with static analysis rules that are tailored for each assignment, to provide detailed and accurate feedback. Our evaluation shows that static analysis can identify a significant number of erroneous submissions missed by test cases.", "published": "2024-11-07 05:00:00", "id": "5a664ded-abcf-41cb-af98-cdbc073d3e88", "source": "arxiv", "section": "computerScience"}, {"title": "Spatioformer: A Geo-encoded Transformer for Large-Scale Plant Species Richness Prediction", "link": "https://arxiv.org/abs/2410.19256", "description": "arXiv:2410.19256v2 Announce Type: replace \nAbstract: Earth observation data have shown promise in predicting species richness of vascular plants ($\\alpha$-diversity), but extending this approach to large spatial scales is challenging because geographically distant regions may exhibit different compositions of plant species ($\\beta$-diversity), resulting in a location-dependent relationship between richness and spectral measurements. In order to handle such geolocation dependency, we propose Spatioformer, where a novel geolocation encoder is coupled with the transformer model to encode geolocation context into remote sensing imagery. The Spatioformer model compares favourably to state-of-the-art models in richness predictions on a large-scale ground-truth richness dataset (HAVPlot) that consists of 68,170 in-situ richness samples covering diverse landscapes across Australia. The results demonstrate that geolocational information is advantageous in predicting species richness from satellite observations over large spatial scales. With Spatioformer, plant species richness maps over Australia are compiled from Landsat archive for the years from 2015 to 2023. The richness maps produced in this study reveal the spatiotemporal dynamics of plant species richness in Australia, providing supporting evidence to inform effective planning and policy development for plant diversity conservation. Regions of high richness prediction uncertainties are identified, highlighting the need for future in-situ surveys to be conducted in these areas to enhance the prediction accuracy.", "published": "2024-11-07 05:00:00", "id": "517706fd-63b0-4bac-a6b0-0e5bfcfbb349", "source": "arxiv", "section": "computerScience"}, {"title": "Engineering Trustworthy AI: A Developer Guide for Empirical Risk Minimization", "link": "https://arxiv.org/abs/2410.19361", "description": "arXiv:2410.19361v2 Announce Type: replace \nAbstract: AI systems increasingly shape critical decisions across personal and societal domains. While empirical risk minimization (ERM) drives much of the AI success, it typically prioritizes accuracy over trustworthiness, often resulting in biases, opacity, and other adverse effects. This paper discusses how key requirements for trustworthy AI can be translated into design choices for the components of ERM. We hope to provide actionable guidance for building AI systems that meet emerging standards for trustworthiness of AI.", "published": "2024-11-07 05:00:00", "id": "e5af6654-c0f0-498e-84aa-73a45c969fbf", "source": "arxiv", "section": "computerScience"}, {"title": "ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework", "link": "https://arxiv.org/abs/2410.19453", "description": "arXiv:2410.19453v2 Announce Type: replace \nAbstract: Although fine-tuning Large Language Models (LLMs) with multilingual data can rapidly enhance the multilingual capabilities of LLMs, they still exhibit a performance gap between the dominant language (e.g., English) and non-dominant ones due to the imbalance of training data across languages. To further enhance the performance of non-dominant languages, we propose ShifCon, a Shift-based Contrastive framework that aligns the internal forward process of other languages toward that of the dominant one. Specifically, it shifts the representations of non-dominant languages into the dominant language subspace, allowing them to access relatively rich information encoded in the model parameters. The enriched representations are then shifted back into their original language subspace before generation. Moreover, we introduce a subspace distance metric to pinpoint the optimal layer area for shifting representations and employ multilingual contrastive learning to further enhance the alignment of representations within this area. Experiments demonstrate that our ShifCon framework significantly enhances the performance of non-dominant languages, particularly for low-resource ones. Further analysis offers extra insights to verify the effectiveness of ShifCon and propel future research", "published": "2024-11-07 05:00:00", "id": "ba542901-4969-442b-bcd2-8078948762e2", "source": "arxiv", "section": "computerScience"}, {"title": "On Multi-Stage Loss Dynamics in Neural Networks: Mechanisms of Plateau and Descent Stages", "link": "https://arxiv.org/abs/2410.20119", "description": "arXiv:2410.20119v2 Announce Type: replace \nAbstract: The multi-stage phenomenon in the training loss curves of neural networks has been widely observed, reflecting the non-linearity and complexity inherent in the training process. In this work, we investigate the training dynamics of neural networks (NNs), with particular emphasis on the small initialization regime, identifying three distinct stages observed in the loss curve during training: the initial plateau stage, the initial descent stage, and the secondary plateau stage. Through rigorous analysis, we reveal the underlying challenges contributing to slow training during the plateau stages. While the proof and estimate for the emergence of the initial plateau were established in our previous work, the behaviors of the initial descent and secondary plateau stages had not been explored before. Here, we provide a more detailed proof for the initial plateau, followed by a comprehensive analysis of the initial descent stage dynamics. Furthermore, we examine the factors facilitating the network's ability to overcome the prolonged secondary plateau, supported by both experimental evidence and heuristic reasoning. Finally, to clarify the link between global training trends and local parameter adjustments, we use the Wasserstein distance to track the fine-scale evolution of weight amplitude distribution.", "published": "2024-11-07 05:00:00", "id": "9f04ab69-9ea9-4557-904b-072d3b3d40e6", "source": "arxiv", "section": "computerScience"}, {"title": "Copyright-Aware Incentive Scheme for Generative Art Models Using Hierarchical Reinforcement Learning", "link": "https://arxiv.org/abs/2410.20180", "description": "arXiv:2410.20180v2 Announce Type: replace \nAbstract: Generative art using Diffusion models has achieved remarkable performance in image generation and text-to-image tasks. However, the increasing demand for training data in generative art raises significant concerns about copyright infringement, as models can produce images highly similar to copyrighted works. Existing solutions attempt to mitigate this by perturbing Diffusion models to reduce the likelihood of generating such images, but this often compromises model performance. Another approach focuses on economically compensating data holders for their contributions, yet it fails to address copyright loss adequately. Our approach begin with the introduction of a novel copyright metric grounded in copyright law and court precedents on infringement. We then employ the TRAK method to estimate the contribution of data holders. To accommodate the continuous data collection process, we divide the training into multiple rounds. Finally, We designed a hierarchical budget allocation method based on reinforcement learning to determine the budget for each round and the remuneration of the data holder based on the data holder's contribution and copyright loss in each round. Extensive experiments across three datasets show that our method outperforms all eight benchmarks, demonstrating its effectiveness in optimizing budget distribution in a copyright-aware manner. To the best of our knowledge, this is the first technical work that introduces to incentive contributors and protect their copyrights by compensating them.", "published": "2024-11-07 05:00:00", "id": "5298a93b-13e3-4e09-831f-6cb953bfccab", "source": "arxiv", "section": "computerScience"}, {"title": "FoldMark: Protecting Protein Generative Models with Watermarking", "link": "https://arxiv.org/abs/2410.20354", "description": "arXiv:2410.20354v3 Announce Type: replace \nAbstract: Protein structure is key to understanding protein function and is essential for progress in bioengineering, drug discovery, and molecular biology. Recently, with the incorporation of generative AI, the power and accuracy of computational protein structure prediction/design have been improved significantly. However, ethical concerns such as copyright protection and harmful content generation (biosecurity) pose challenges to the wide implementation of protein generative models. Here, we investigate whether it is possible to embed watermarks into protein generative models and their outputs for copyright authentication and the tracking of generated structures. As a proof of concept, we propose a two-stage method FoldMark as a generalized watermarking strategy for protein generative models. FoldMark first pretrain watermark encoder and decoder, which can minorly adjust protein structures to embed user-specific information and faithfully recover the information from the encoded structure. In the second step, protein generative models are fine-tuned with watermark Low-Rank Adaptation (LoRA) modules to preserve generation quality while learning to generate watermarked structures with high recovery rates. Extensive experiments are conducted on open-source protein structure prediction models (e.g., ESMFold and MultiFlow) and de novo structure design models (e.g., FrameDiff and FoldFlow) and we demonstrate that our method is effective across all these generative models. Meanwhile, our watermarking framework only exerts a negligible impact on the original protein structure quality and is robust under potential post-processing and adaptive attacks.", "published": "2024-11-07 05:00:00", "id": "78b8ae85-5819-4b9b-a6ae-0e919a564ef0", "source": "arxiv", "section": "computerScience"}, {"title": "AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions", "link": "https://arxiv.org/abs/2410.20424", "description": "arXiv:2410.20424v3 Announce Type: replace \nAbstract: Data science tasks involving tabular data present complex challenges that require sophisticated problem-solving approaches. We propose AutoKaggle, a powerful and user-centric framework that assists data scientists in completing daily data pipelines through a collaborative multi-agent system. AutoKaggle implements an iterative development process that combines code execution, debugging, and comprehensive unit testing to ensure code correctness and logic consistency. The framework offers highly customizable workflows, allowing users to intervene at each phase, thus integrating automated intelligence with human expertise. Our universal data science toolkit, comprising validated functions for data cleaning, feature engineering, and modeling, forms the foundation of this solution, enhancing productivity by streamlining common tasks. We selected 8 Kaggle competitions to simulate data processing workflows in real-world application scenarios. Evaluation results demonstrate that AutoKaggle achieves a validation submission rate of 0.85 and a comprehensive score of 0.82 in typical data science pipelines, fully proving its effectiveness and practicality in handling complex data science tasks.", "published": "2024-11-07 05:00:00", "id": "7a0ff688-9723-4067-8cf1-67731c912777", "source": "arxiv", "section": "computerScience"}, {"title": "ElectionSim: Massive Population Election Simulation Powered by Large Language Model Driven Agents", "link": "https://arxiv.org/abs/2410.20746", "description": "arXiv:2410.20746v3 Announce Type: replace \nAbstract: The massive population election simulation aims to model the preferences of specific groups in particular election scenarios. It has garnered significant attention for its potential to forecast real-world social trends. Traditional agent-based modeling (ABM) methods are constrained by their ability to incorporate complex individual background information and provide interactive prediction results. In this paper, we introduce ElectionSim, an innovative election simulation framework based on large language models, designed to support accurate voter simulations and customized distributions, together with an interactive platform to dialogue with simulated voters. We present a million-level voter pool sampled from social media platforms to support accurate individual simulation. We also introduce PPE, a poll-based presidential election benchmark to assess the performance of our framework under the U.S. presidential election scenario. Through extensive experiments and analyses, we demonstrate the effectiveness and robustness of our framework in U.S. presidential election simulations.", "published": "2024-11-07 05:00:00", "id": "993dfaf2-437e-4f11-827b-5a32c01ba388", "source": "arxiv", "section": "computerScience"}, {"title": "Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts", "link": "https://arxiv.org/abs/2410.20763", "description": "arXiv:2410.20763v2 Announce Type: replace \nAbstract: One useful application of NLP models is to support people in reading complex text from unfamiliar domains (e.g., scientific articles). Simplifying the entire text makes it understandable but sometimes removes important details. On the contrary, helping adult readers understand difficult concepts in context can enhance their vocabulary and knowledge. In a preliminary human study, we first identify that lack of context and unfamiliarity with difficult concepts is a major reason for adult readers' difficulty with domain-specific text. We then introduce \"targeted concept simplification,\" a simplification task for rewriting text to help readers comprehend text containing unfamiliar concepts. We also introduce WikiDomains, a new dataset of 22k definitions from 13 academic domains paired with a difficult concept within each definition. We benchmark the performance of open-source and commercial LLMs and a simple dictionary baseline on this task across human judgments of ease of understanding and meaning preservation. Interestingly, our human judges preferred explanations about the difficult concept more than simplification of the concept phrase. Further, no single model achieved superior performance across all quality dimensions, and automated metrics also show low correlations with human evaluations of concept simplification ($\\sim0.2$), opening up rich avenues for research on personalized human reading comprehension support.", "published": "2024-11-07 05:00:00", "id": "04efc7e0-dec3-467a-8d51-2140c8e3e53b", "source": "arxiv", "section": "computerScience"}, {"title": "Optimal planning for heterogeneous autonomous teams with precedence and compatibility constraints and its application on power grid inspection with Unmanned Aerial Vehicles", "link": "https://arxiv.org/abs/2410.20849", "description": "arXiv:2410.20849v2 Announce Type: replace \nAbstract: In this paper we address the optimal planning of autonomous teams for general purpose tasks including a wide spectrum of situations: from project management of human teams to the coordination of an automated assembly lines, focusing in the automated inspection of power grids. There exist many methods for task planning. However, the vast majority of such methods are conceived for very specific problems or situations and are often based in certain assumptions and simplifications. Consider for example all the different algorithms developed to solve the Vehicle Routing Problem (VRP) for all the different vehicles and environment characteristics. This means that no robust general planning method exists and that a possible extension of any of them to a more general situation is often not a trivial task. To address this, we propose a new truly general method ultimately based on a generalization of the Traveling Salesman Problem (TSP). We call this new model the Heterogeneous Multi-worker Task Planning Problem (HMWTPP). It provides a natural framework to model many situations typical in task planning of all kinds. Task-Worker compatibility, precedence/order and time-windows constraints are already encoded into the HMWTPP while it can be easily extended to include weight capacity or battery per node constraints in an intuitive manner. Several classical TSP problems included in the TSPLIB library are solved for validation and performance analysis of HMWTPP showing a comparable numerical performance to that of existing models. In addition, a synthetic example modeling an automated assembly line is analyzed to prove the potential capabilities of the HMWTPP in real-life scenarios. Ultimately, we focus in the computation of the optimal plan of Unmanned Aerial Vehicles (UAVs) specifically in the context of automated inspection of electrical power grids.", "published": "2024-11-07 05:00:00", "id": "f5939fca-4142-41ef-9198-31f7d2f49c62", "source": "arxiv", "section": "computerScience"}, {"title": "Getting By Goal Misgeneralization With a Little Help From a Mentor", "link": "https://arxiv.org/abs/2410.21052", "description": "arXiv:2410.21052v2 Announce Type: replace \nAbstract: While reinforcement learning (RL) agents often perform well during training, they can struggle with distribution shift in real-world deployments. One particularly severe risk of distribution shift is goal misgeneralization, where the agent learns a proxy goal that coincides with the true goal during training but not during deployment. In this paper, we explore whether allowing an agent to ask for help from a supervisor in unfamiliar situations can mitigate this issue. We focus on agents trained with PPO in the CoinRun environment, a setting known to exhibit goal misgeneralization. We evaluate multiple methods for determining when the agent should request help and find that asking for help consistently improves performance. However, we also find that methods based on the agent's internal state fail to proactively request help, instead waiting until mistakes have already occurred. Further investigation suggests that the agent's internal state does not represent the coin at all, highlighting the importance of learning nuanced representations, the risks of ignoring everything not immediately relevant to reward, and the necessity of developing ask-for-help strategies tailored to the agent's training algorithm.", "published": "2024-11-07 05:00:00", "id": "b6b10d30-6227-4212-8e8e-6405171182f6", "source": "arxiv", "section": "computerScience"}, {"title": "Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction", "link": "https://arxiv.org/abs/2410.21169", "description": "arXiv:2410.21169v3 Announce Type: replace \nAbstract: Document parsing is essential for converting unstructured and semi-structured documents-such as contracts, academic papers, and invoices-into structured, machine-readable data. Document parsing extract reliable structured data from unstructured inputs, providing huge convenience for numerous applications. Especially with recent achievements in Large Language Models, document parsing plays an indispensable role in both knowledge base construction and training data generation. This survey presents a comprehensive review of the current state of document parsing, covering key methodologies, from modular pipeline systems to end-to-end models driven by large vision-language models. Core components such as layout detection, content extraction (including text, tables, and mathematical expressions), and multi-modal data integration are examined in detail. Additionally, this paper discusses the challenges faced by modular document parsing systems and vision-language models in handling complex layouts, integrating multiple modules, and recognizing high-density text. It emphasizes the importance of developing larger and more diverse datasets and outlines future research directions.", "published": "2024-11-07 05:00:00", "id": "e4530a2f-92f3-4074-bf7a-737a4edc7974", "source": "arxiv", "section": "computerScience"}, {"title": "Information diffusion assumptions can distort our understanding of social network dynamics", "link": "https://arxiv.org/abs/2410.21554", "description": "arXiv:2410.21554v3 Announce Type: replace \nAbstract: To analyze the flow of information online, experts often rely on platform-provided data from social media companies, which typically attribute all resharing actions to an original poster. This obscures the true dynamics of how information spreads online, as users can be exposed to content in various ways. While most researchers analyze data as it is provided by the platform and overlook this issue, some attempt to infer the structure of these information cascades. However, the absence of ground truth about actual diffusion cascades makes verifying the efficacy of these efforts impossible. This study investigates the implications of the common practice of ignoring reconstruction all together. Two case studies involving data from Twitter and Bluesky reveal that reconstructing cascades significantly alters the identification of influential users, therefore affecting downstream analyses in general. We also propose a novel reconstruction approach that allows us to evaluate the effects of different assumptions made during the cascade inference procedure. Analysis of the diffusion of over 40,000 true and false news stories on Twitter reveals that the assumptions made during the reconstruction procedure drastically distort both microscopic and macroscopic properties of cascade networks. This work highlights the challenges of studying information spreading processes on complex networks and has significant implications for the broader study of digital platforms.", "published": "2024-11-07 05:00:00", "id": "3d4a1c82-f4a0-44d4-963c-46d41a6ae1f8", "source": "arxiv", "section": "computerScience"}, {"title": "Partial Orders in Rate-Matched Polar Codes", "link": "https://arxiv.org/abs/2410.21661", "description": "arXiv:2410.21661v2 Announce Type: replace \nAbstract: In this paper, we establish the partial order (POs) for both the binary erasure channel (BEC) and the binary memoryless symmetric channel (BMSC) under any block rate-matched polar codes. Firstly, we define the POs in the sense of rate-matched polar codes as a sequential block version. Furthermore, we demonstrate the persistence of POs after block rate matching in the BEC. Finally, leveraging the existing POs in the BEC, we obtain more POs in the BMSC under block rate matching. Simulations show that the PW sequence constructed from \\beta-expansion can be improved by the tool of POs. Actually, any fixed reliable sequence in the mother polar codes can be improved by POs for rate matching.", "published": "2024-11-07 05:00:00", "id": "b16920ad-8c73-4bae-ada8-30672a59f735", "source": "arxiv", "section": "computerScience"}, {"title": "Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning", "link": "https://arxiv.org/abs/2410.21845", "description": "arXiv:2410.21845v2 Announce Type: replace \nAbstract: Reinforcement learning (RL) holds great promise for enabling autonomous acquisition of complex robotic manipulation skills, but realizing this potential in real-world settings has been challenging. We present a human-in-the-loop vision-based RL system that demonstrates impressive performance on a diverse set of dexterous manipulation tasks, including dynamic manipulation, precision assembly, and dual-arm coordination. Our approach integrates demonstrations and human corrections, efficient RL algorithms, and other system-level design choices to learn policies that achieve near-perfect success rates and fast cycle times within just 1 to 2.5 hours of training. We show that our method significantly outperforms imitation learning baselines and prior RL approaches, with an average 2x improvement in success rate and 1.8x faster execution. Through extensive experiments and analysis, we provide insights into the effectiveness of our approach, demonstrating how it learns robust, adaptive policies for both reactive and predictive control strategies. Our results suggest that RL can indeed learn a wide range of complex vision-based manipulation policies directly in the real world within practical training times. We hope this work will inspire a new generation of learned robotic manipulation techniques, benefiting both industrial applications and research advancements. Videos and code are available at our project website https://hil-serl.github.io/.", "published": "2024-11-07 05:00:00", "id": "de0fe8e5-6e29-4b57-96fc-96d336d6fbb4", "source": "arxiv", "section": "computerScience"}, {"title": "Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning", "link": "https://arxiv.org/abs/2410.21872", "description": "arXiv:2410.21872v2 Announce Type: replace \nAbstract: Early and accurate diagnosis of brain tumors is crucial for improving patient survival rates. However, the detection and classification of brain tumors are challenging due to their diverse types and complex morphological characteristics. This study investigates the application of pre-trained models for brain tumor classification, with a particular focus on deploying the Mamba model. We fine-tuned several mainstream transfer learning models and applied them to the multi-class classification of brain tumors. By comparing these models to those trained from scratch, we demonstrated the significant advantages of transfer learning, especially in the medical imaging field, where annotated data is often limited. Notably, we introduced the Vision Mamba (Vim), a novel network architecture, and applied it for the first time in brain tumor classification, achieving exceptional classification accuracy. Experimental results indicate that the Vim model achieved 100% classification accuracy on an independent test set, emphasizing its potential for tumor classification tasks. These findings underscore the effectiveness of transfer learning in brain tumor classification and reveal that, compared to existing state-of-the-art models, the Vim model is lightweight, efficient, and highly accurate, offering a new perspective for clinical applications. Furthermore, the framework proposed in this study for brain tumor classification, based on transfer learning and the Vision Mamba model, is broadly applicable to other medical imaging classification problems.", "published": "2024-11-07 05:00:00", "id": "950abbea-7bce-4a72-aba7-ac683a2cc50e", "source": "arxiv", "section": "computerScience"}, {"title": "Even the \"Devil\" has Rights!", "link": "https://arxiv.org/abs/2410.22963", "description": "arXiv:2410.22963v2 Announce Type: replace \nAbstract: There have been works discussing the adoption of a human rights framework for responsible AI, emphasizing various rights such as the right to contribute to scientific advancements. Yet, to the best of our knowledge, this is the first attempt to take this framework with special focus on computer vision and documenting human rights violations in its community. This work summarizes such incidents accompanied with evidence from the lens of a female African Muslim Hijabi researcher. While previous works resorted to qualitative surveys that gather opinions from various researchers in the field, this work argues that a single documented violation is sufficient to warrant attention regardless of the stature of this researcher. Incidents documented in this work include silence on Genocides that are occurring while promoting the governments contributing to it, a broken reviewing system and corruption in the faculty support systems. This work discusses that demonizing individuals for discrimination based on gender, ethnicity, creed or reprisal has been a successful tool for exclusion with documented evidence from a single case. We argue that human rights are guaranteed for every single individual even the ones that might be labelled as devils in the community for whichever reasons to dismantle such a tool from its roots.", "published": "2024-11-07 05:00:00", "id": "58d87fb3-4e90-4918-96c1-132e674fe1b6", "source": "arxiv", "section": "computerScience"}, {"title": "A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics", "link": "https://arxiv.org/abs/2410.22997", "description": "arXiv:2410.22997v2 Announce Type: replace \nAbstract: Recent advances in LLM have been instrumental in autonomous robot control and human-robot interaction by leveraging their vast general knowledge and capabilities to understand and reason across a wide range of tasks and scenarios. Previous works have investigated various prompt engineering techniques for improving the performance of LLM to accomplish tasks, while others have proposed methods that utilize LLMs to plan and execute tasks based on the available functionalities of a given robot platform. In this work, we consider both lines of research by comparing prompt engineering techniques and combinations thereof within the application of high-level task planning and execution in service robotics. We define a diverse set of tasks and a simple set of functionalities in simulation, and measure task completion accuracy and execution time for several state-of-the-art models.", "published": "2024-11-07 05:00:00", "id": "5ba13ec9-f0c0-41d1-afb0-34e73b6103e0", "source": "arxiv", "section": "computerScience"}, {"title": "A Transformer Framework for Simultaneous Segmentation, Classification, and Caller Identification of Marmoset Vocalization", "link": "https://arxiv.org/abs/2410.23279", "description": "arXiv:2410.23279v2 Announce Type: replace \nAbstract: Marmoset, a highly vocalized primate, has become a popular animal model for studying social-communicative behavior and its underlying mechanism comparing with human infant linguistic developments. In the study of vocal communication, it is vital to know the caller identities, call contents, and vocal exchanges. Previous work of a CNN has achieved a joint model for call segmentation, classification, and caller identification for marmoset vocalizations. However, the CNN has limitations in modeling long-range acoustic patterns; the Transformer architecture that has been shown to outperform CNNs, utilizes the self-attention mechanism that efficiently segregates information parallelly over long distances and captures the global structure of marmoset vocalization. We propose using the Transformer to jointly segment and classify the marmoset calls and identify the callers for each vocalization.", "published": "2024-11-07 05:00:00", "id": "2d402a2e-bf5c-4dca-ad2b-ea521fd4d50e", "source": "arxiv", "section": "computerScience"}, {"title": "SceneComplete: Open-World 3D Scene Completion in Complex Real World Environments for Robot Manipulation", "link": "https://arxiv.org/abs/2410.23643", "description": "arXiv:2410.23643v2 Announce Type: replace \nAbstract: Careful robot manipulation in every-day cluttered environments requires an accurate understanding of the 3D scene, in order to grasp and place objects stably and reliably and to avoid mistakenly colliding with other objects. In general, we must construct such a 3D interpretation of a complex scene based on limited input, such as a single RGB-D image. We describe SceneComplete, a system for constructing a complete, segmented, 3D model of a scene from a single view. It provides a novel pipeline for composing general-purpose pretrained perception modules (vision-language, segmentation, image-inpainting, image-to-3D, and pose-estimation) to obtain high-accuracy results. We demonstrate its accuracy and effectiveness with respect to ground-truth models in a large benchmark dataset and show that its accurate whole-object reconstruction enables robust grasp proposal generation, including for a dexterous hand. Project website - https://scenecomplete.github.io/", "published": "2024-11-07 05:00:00", "id": "8a4b5f01-1207-472c-89a8-d9042aaa6e0c", "source": "arxiv", "section": "computerScience"}, {"title": "DiffBatt: A Diffusion Model for Battery Degradation Prediction and Synthesis", "link": "https://arxiv.org/abs/2410.23893", "description": "arXiv:2410.23893v2 Announce Type: replace \nAbstract: Battery degradation remains a critical challenge in the pursuit of green technologies and sustainable energy solutions. Despite significant research efforts, predicting battery capacity loss accurately remains a formidable task due to its complex nature, influenced by both aging and cycling behaviors. To address this challenge, we introduce a novel general-purpose model for battery degradation prediction and synthesis, DiffBatt. Leveraging an innovative combination of conditional and unconditional diffusion models with classifier-free guidance and transformer architecture, DiffBatt achieves high expressivity and scalability. DiffBatt operates as a probabilistic model to capture uncertainty in aging behaviors and a generative model to simulate battery degradation. The performance of the model excels in prediction tasks while also enabling the generation of synthetic degradation curves, facilitating enhanced model training by data augmentation. In the remaining useful life prediction task, DiffBatt provides accurate results with a mean RMSE of 196 cycles across all datasets, outperforming all other models and demonstrating superior generalizability. This work represents an important step towards developing foundational models for battery degradation.", "published": "2024-11-07 05:00:00", "id": "4c014458-db76-428e-b2bd-bd4945f2eff5", "source": "arxiv", "section": "computerScience"}, {"title": "Multilingual Pretraining Using a Large Corpus Machine-Translated from a Single Source Language", "link": "https://arxiv.org/abs/2410.23956", "description": "arXiv:2410.23956v2 Announce Type: replace \nAbstract: English, as a very high-resource language, enables the pretraining of high-quality large language models (LLMs). The same cannot be said for most other languages, as leading LLMs still underperform for non-English languages, likely due to a gap in the quality and diversity of the available multilingual pretraining corpora. In this work, we find that machine-translated text from a single high-quality source language can contribute significantly to the pretraining of multilingual LLMs. We translate FineWeb-Edu, a high-quality English web dataset, into French, German, and Spanish, resulting in a final 300B-token dataset, which we call TransWeb-Edu, and pretrain a 1.3B-parameter model, CuatroLLM, from scratch on this dataset. Across five non-English reasoning tasks, we show that CuatroLLM matches or outperforms state-of-the-art multilingual models trained using closed data, such as Llama3.2 and Gemma2, despite using an order of magnitude less data, such as about 6% of the tokens used for Llama3.2's training. We further demonstrate that with additional domain-specific pretraining, amounting to less than 1% of TransWeb-Edu, CuatroLLM surpasses the state of the art in multilingual reasoning. To promote reproducibility, we release our corpus, models, and training pipeline under open licenses at hf.co/britllm/CuatroLLM.", "published": "2024-11-07 05:00:00", "id": "458f3911-cfa9-49fc-9ca7-9868fb006e8f", "source": "arxiv", "section": "computerScience"}, {"title": "An Efficient Dynamic Resource Allocation Framework for Evolutionary Bilevel Optimization", "link": "https://arxiv.org/abs/2410.24081", "description": "arXiv:2410.24081v2 Announce Type: replace \nAbstract: Bilevel optimization problems are characterized by an interactive hierarchical structure, where the upper level seeks to optimize its strategy while simultaneously considering the response of the lower level. Evolutionary algorithms are commonly used to solve complex bilevel problems in practical scenarios, but they face significant resource consumption challenges due to the nested structure imposed by the implicit lower-level optimality condition. This challenge becomes even more pronounced as problem dimensions increase. Although recent methods have enhanced bilevel convergence through task-level knowledge sharing, further efficiency improvements are still hindered by redundant lower-level iterations that consume excessive resources while generating unpromising solutions. To overcome this challenge, this paper proposes an efficient dynamic resource allocation framework for evolutionary bilevel optimization, named DRC-BLEA. Compared to existing approaches, DRC-BLEA introduces a novel competitive quasi-parallel paradigm, in which multiple lower-level optimization tasks, derived from different upper-level individuals, compete for resources. A continuously updated selection probability is used to prioritize execution opportunities to promising tasks. Additionally, a cooperation mechanism is integrated within the competitive framework to further enhance efficiency and prevent premature convergence. Experimental results compared with chosen state-of-the-art algorithms demonstrate the effectiveness of the proposed method. Specifically, DRC-BLEA achieves competitive accuracy across diverse problem sets and real-world scenarios, while significantly reducing the number of function evaluations and overall running time.", "published": "2024-11-07 05:00:00", "id": "a5469ef1-41b1-4f8b-ae43-a67e79be4a66", "source": "arxiv", "section": "computerScience"}, {"title": "SimpleFSDP: Simpler Fully Sharded Data Parallel with torch.compile", "link": "https://arxiv.org/abs/2411.00284", "description": "arXiv:2411.00284v2 Announce Type: replace \nAbstract: Distributed training of large models consumes enormous computation resources and requires substantial engineering efforts to compose various training techniques. This paper presents SimpleFSDP, a PyTorch-native compiler-based Fully Sharded Data Parallel (FSDP) framework, which has a simple implementation for maintenance and composability, allows full computation-communication graph tracing, and brings performance enhancement via compiler backend optimizations.\n  SimpleFSDP's novelty lies in its unique $torch.compile$-friendly implementation of collective communications using existing PyTorch primitives, namely parametrizations, selective activation checkpointing, and DTensor. It also features the first-of-its-kind intermediate representation (IR) nodes bucketing and reordering in the TorchInductor backend for effective computation-communication overlapping. As a result, users can employ the aforementioned optimizations to automatically or manually wrap model components for minimal communication exposure. Extensive evaluations of SimpleFSDP on Llama 3 models (including the ultra-large 405B) using TorchTitan demonstrate up to 28.54% memory reduction and 68.67% throughput improvement compared to the most widely adopted FSDP2 eager framework, when composed with other distributed training techniques.", "published": "2024-11-07 05:00:00", "id": "4a265366-83c8-43d1-929e-4d6ba6babdf3", "source": "arxiv", "section": "computerScience"}, {"title": "Advantages of Neural Population Coding for Deep Learning", "link": "https://arxiv.org/abs/2411.00393", "description": "arXiv:2411.00393v3 Announce Type: replace \nAbstract: Scalar variables, e.g., the orientation of a shape in an image, are commonly predicted using a single output neuron in a neural network. In contrast, the mammalian cortex represents variables with a population of neurons. In this population code, each neuron is most active at its preferred value and shows partial activity for other values. Here, we investigate the benefit of using a population code for the output layer of a neural network. We compare population codes against single-neuron outputs and one-hot vectors. First, we show theoretically and in experiments with synthetic data that population codes improve robustness to input noise in networks of stacked linear layers. Second, we demonstrate the benefit of using population codes to encode ambiguous outputs, such as the pose of symmetric objects. Using the T-LESS dataset of feature-less real-world objects, we show that population codes improve the accuracy of predicting 3D object orientation from image input.", "published": "2024-11-07 05:00:00", "id": "f1a4af51-32d3-4fa9-986a-6bfe239c11b8", "source": "arxiv", "section": "computerScience"}, {"title": "Adapting Language Models via Token Translation", "link": "https://arxiv.org/abs/2411.00593", "description": "arXiv:2411.00593v2 Announce Type: replace \nAbstract: Modern large language models use a fixed tokenizer to effectively compress text drawn from a source domain. However, applying the same tokenizer to a new target domain often leads to inferior compression, more costly inference, and reduced semantic alignment. To address this deficiency, we introduce Sparse Sinkhorn Token Translation (S2T2). S2T2 trains a tailored tokenizer for the target domain and learns to translate between target and source tokens, enabling more effective reuse of the pre-trained next-source-token predictor. In our experiments with finetuned English language models, S2T2 improves both the perplexity and the compression of out-of-domain protein sequences, outperforming direct finetuning with either the source or target tokenizer. In addition, we find that token translations learned for smaller, less expensive models can be directly transferred to larger, more powerful models to reap the benefits of S2T2 at lower cost.", "published": "2024-11-07 05:00:00", "id": "171143f3-f941-41b9-93a5-5abbc9876ff1", "source": "arxiv", "section": "computerScience"}, {"title": "Swan and ArabicMTEB: Dialect-Aware, Arabic-Centric, Cross-Lingual, and Cross-Cultural Embedding Models and Benchmarks", "link": "https://arxiv.org/abs/2411.01192", "description": "arXiv:2411.01192v2 Announce Type: replace \nAbstract: We introduce {\\bf Swan}, a family of embedding models centred around the Arabic language, addressing both small-scale and large-scale use cases. Swan includes two variants: Swan-Small, based on ARBERTv2, and Swan-Large, built on ArMistral, a pretrained Arabic large language model. To evaluate these models, we propose ArabicMTEB, a comprehensive benchmark suite that assesses cross-lingual, multi-dialectal, multi-domain, and multi-cultural Arabic text embedding performance, covering eight diverse tasks and spanning 94 datasets. Swan-Large achieves state-of-the-art results, outperforming Multilingual-E5-large in most Arabic tasks, while the Swan-Small consistently surpasses Multilingual-E5-base. Our extensive evaluations demonstrate that Swan models are both dialectally and culturally aware, excelling across various Arabic domains while offering significant monetary efficiency. This work significantly advances the field of Arabic language modelling and provides valuable resources for future research and applications in Arabic natural language processing. Our models and benchmark will be made publicly accessible for research.", "published": "2024-11-07 05:00:00", "id": "b5dbbc36-8253-469b-b102-70f8be109183", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Neural Network Interpretability with Feature-Aligned Sparse Autoencoders", "link": "https://arxiv.org/abs/2411.01220", "description": "arXiv:2411.01220v2 Announce Type: replace \nAbstract: Sparse Autoencoders (SAEs) have shown promise in improving the interpretability of neural network activations, but can learn features that are not features of the input, limiting their effectiveness. We propose \\textsc{Mutual Feature Regularization} \\textbf{(MFR)}, a regularization technique for improving feature learning by encouraging SAEs trained in parallel to learn similar features. We motivate \\textsc{MFR} by showing that features learned by multiple SAEs are more likely to correlate with features of the input. By training on synthetic data with known features of the input, we show that \\textsc{MFR} can help SAEs learn those features, as we can directly compare the features learned by the SAE with the input features for the synthetic data. We then scale \\textsc{MFR} to SAEs that are trained to denoise electroencephalography (EEG) data and SAEs that are trained to reconstruct GPT-2 Small activations. We show that \\textsc{MFR} can improve the reconstruction loss of SAEs by up to 21.21\\% on GPT-2 Small, and 6.67\\% on EEG data. Our results suggest that the similarity between features learned by different SAEs can be leveraged to improve SAE training, thereby enhancing performance and the usefulness of SAEs for model interpretability.", "published": "2024-11-07 05:00:00", "id": "2cff20ae-1682-4232-8ad0-9ead298c9335", "source": "arxiv", "section": "computerScience"}, {"title": "$B^4$: A Black-Box Scrubbing Attack on LLM Watermarks", "link": "https://arxiv.org/abs/2411.01222", "description": "arXiv:2411.01222v2 Announce Type: replace \nAbstract: Watermarking has emerged as a prominent technique for LLM-generated content detection by embedding imperceptible patterns. Despite supreme performance, its robustness against adversarial attacks remains underexplored. Previous work typically considers a grey-box attack setting, where the specific type of watermark is already known. Some even necessitates knowledge about hyperparameters of the watermarking method. Such prerequisites are unattainable in real-world scenarios. Targeting at a more realistic black-box threat model with fewer assumptions, we here propose $\\mathcal{B}^4$, a black-box scrubbing attack on watermarks. Specifically, we formulate the watermark scrubbing attack as a constrained optimization problem by capturing its objectives with two distributions, a Watermark Distribution and a Fidelity Distribution. This optimization problem can be approximately solved using two proxy distributions. Experimental results across 12 different settings demonstrate the superior performance of $\\mathcal{B}^4$ compared with other baselines.", "published": "2024-11-07 05:00:00", "id": "9f2aa9f9-eaaa-41e0-a572-f7c0a8226e4a", "source": "arxiv", "section": "computerScience"}, {"title": "From Federated Learning to Quantum Federated Learning for Space-Air-Ground Integrated Networks", "link": "https://arxiv.org/abs/2411.01312", "description": "arXiv:2411.01312v2 Announce Type: replace \nAbstract: 6G wireless networks are expected to provide seamless and data-based connections that cover space-air-ground and underwater networks. As a core partition of future 6G networks, Space-Air-Ground Integrated Networks (SAGIN) have been envisioned to provide countless real-time intelligent applications. To realize this, promoting AI techniques into SAGIN is an inevitable trend. Due to the distributed and heterogeneous architecture of SAGIN, federated learning (FL) and then quantum FL are emerging AI model training techniques for enabling future privacy-enhanced and computation-efficient SAGINs. In this work, we explore the vision of using FL/QFL in SAGINs. We present a few representative applications enabled by the integration of FL and QFL in SAGINs. A case study of QFL over UAV networks is also given, showing the merit of quantum-enabled training approach over the conventional FL benchmark. Research challenges along with standardization for QFL adoption in future SAGINs are also highlighted.", "published": "2024-11-07 05:00:00", "id": "ee4c7b4a-7a23-42c0-b6ea-e03f08f24ed7", "source": "arxiv", "section": "computerScience"}, {"title": "False Data Injection Attack Detection in Edge-based Smart Metering Networks with Federated Learning", "link": "https://arxiv.org/abs/2411.01313", "description": "arXiv:2411.01313v2 Announce Type: replace \nAbstract: Smart metering networks are increasingly susceptible to cyber threats, where false data injection (FDI) appears as a critical attack. Data-driven-based machine learning (ML) methods have shown immense benefits in detecting FDI attacks via data learning and prediction abilities. Literature works have mostly focused on centralized learning and deploying FDI attack detection models at the control center, which requires data collection from local utilities like meters and transformers. However, this data sharing may raise privacy concerns due to the potential disclosure of household information like energy usage patterns. This paper proposes a new privacy-preserved FDI attack detection by developing an efficient federated learning (FL) framework in the smart meter network with edge computing. Distributed edge servers located at the network edge run an ML-based FDI attack detection model and share the trained model with the grid operator, aiming to build a strong FDI attack detection model without data sharing. Simulation results demonstrate the efficiency of our proposed FL method over the conventional method without collaboration.", "published": "2024-11-07 05:00:00", "id": "cf13203a-2e2c-4911-b55a-5c62141617bd", "source": "arxiv", "section": "computerScience"}, {"title": "Centrality in Collaboration: A Novel Algorithm for Social Partitioning Gradients in Community Detection for Multiple Oncology Clinical Trial Enrollments", "link": "https://arxiv.org/abs/2411.01394", "description": "arXiv:2411.01394v2 Announce Type: replace \nAbstract: Patients at a comprehensive cancer center who do not achieve cure or remission following standard treatments often become candidates for clinical trials. Patients who participate in a clinical trial may be suitable for other studies. A key factor influencing patient enrollment in subsequent clinical trials is the structured collaboration between oncologists and most responsible physicians. Possible identification of these collaboration networks can be achieved through the analysis of patient movements between clinical trial intervention types with social network analysis and community detection algorithms. In the detection of oncologist working groups, the present study evaluates three community detection algorithms: Girvan-Newman, Louvain and an algorithm developed by the author. Girvan-Newman identifies each intervention as their own community, while Louvain groups interventions in a manner that is difficult to interpret. In contrast, the author's algorithm groups interventions in a way that is both intuitive and informative, with a gradient evident in social partitioning that is particularly useful for epidemiological research. This lays the groundwork for future subgroup analysis of clustered interventions.", "published": "2024-11-07 05:00:00", "id": "7ca2d21c-3d74-4a20-846b-fa027a805896", "source": "arxiv", "section": "computerScience"}, {"title": "HOBBIT: A Mixed Precision Expert Offloading System for Fast MoE Inference", "link": "https://arxiv.org/abs/2411.01433", "description": "arXiv:2411.01433v2 Announce Type: replace \nAbstract: The Mixture-of-Experts (MoE) architecture has demonstrated significant advantages in the era of Large Language Models (LLMs), offering enhanced capabilities with reduced inference costs. However, deploying MoE-based LLMs on memoryconstrained edge devices remains challenging due to their substantial memory requirements. While existing expertoffloading methods alleviate the memory requirements, they often incur significant expert-loading costs or compromise model accuracy. We present HOBBIT, a mixed precision expert offloading system to enable flexible and efficient MoE inference. Our key insight is that dynamically replacing less critical cache-miss experts with low precision versions can substantially reduce expert-loading latency while preserving model accuracy. HOBBIT introduces three innovative techniques that map the natural hierarchy of MoE computation: (1) a token-level dynamic expert loading mechanism, (2) a layer-level adaptive expert prefetching technique, and (3) a sequence-level multidimensional expert caching policy. These innovations fully leverage the benefits of mixedprecision expert inference. By implementing HOBBIT on top of the renowned LLM inference framework Llama.cpp, we evaluate its performance across different edge devices with representative MoE models. The results demonstrate that HOBBIT achieves up to a 9.93x speedup in decoding compared to state-of-the-art MoE offloading systems.", "published": "2024-11-07 05:00:00", "id": "e83125b7-bde9-4ad6-ace7-b2ab04c4fcd0", "source": "arxiv", "section": "computerScience"}, {"title": "The Fairness of Maximum Nash Social Welfare Under Matroid Constraints and Beyond", "link": "https://arxiv.org/abs/2411.01462", "description": "arXiv:2411.01462v2 Announce Type: replace \nAbstract: We study the problem of fair allocation of a set of indivisible items among agents with additive valuations, under matroid constraints and two generalizations: $p$-extendible system and independence system constraints. The objective is to find fair and efficient allocations in which the subset of items assigned to every agent satisfies the given constraint. We focus on a common fairness notion of envy-freeness up to one item (EF1) and a well-known efficient (and fair) notion of the maximum Nash social welfare (Max-NSW). By using properties of matroids, we demonstrate that the Max-NSW allocation, implying Pareto optimality (PO), achieves a tight $1/2$-EF1 under matroid constraints. This result resolves an open question proposed in prior literature [26]. In particular, if agents have 2-valued ($\\{1, a\\}$) valuations, we prove that the Max-NSW allocation admits $\\max\\{1/a^2, 1/2\\}$-EF1 and PO. Under strongly $p$-extendible system constraints, we show that the Max-NSW allocation guarantees $\\max\\{1/p, 1/4\\}$-EF1 and PO for identical binary valuations. Indeed, the approximation of $1/4$ is the ratio for independence system constraints and additive valuations. Additionally, for lexicographic preferences, we study possibly feasible allocations other than Max-NSW admitting exactly EF1 and PO under the above constraints.", "published": "2024-11-07 05:00:00", "id": "259f56b6-e1df-44b3-a978-a8660ed7c94f", "source": "arxiv", "section": "computerScience"}, {"title": "Teaching Models to Improve on Tape", "link": "https://arxiv.org/abs/2411.01483", "description": "arXiv:2411.01483v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) often struggle when prompted to generate content under specific constraints. However, in such cases it is often easy to check whether these constraints are satisfied or violated. Recent works have shown that LLMs can benefit from such \"corrective feedback\". Here we claim that this skill of LLMs can be significantly enhanced via training. We introduce an RL framework for teaching models to use such rewards, by simulating interaction sessions, and rewarding the model according to its ability to satisfy the constraints. We refer to our method as CORGI (Controlled Generation with RL for Guided Interaction), and evaluate it on a variety of controlled generation tasks using unlabeled training data. We find that CORGI consistently outperforms the baseline reinforcement learning method that does not incorporate conversational feedback. Furthermore, CORGI's interactive framework enables meta-learning, allowing the LLM to generalize better to guided interaction in new tasks. Our results clearly show that conversational optimization, when combined with reinforcement learning, significantly improves the effectiveness of LLMs in controlled generation contexts.", "published": "2024-11-07 05:00:00", "id": "c4fa5aa8-e97b-4ac2-8446-a1194fa1bdd5", "source": "arxiv", "section": "computerScience"}, {"title": "Diversity Progress for Goal Selection in Discriminability-Motivated RL", "link": "https://arxiv.org/abs/2411.01521", "description": "arXiv:2411.01521v2 Announce Type: replace \nAbstract: Non-uniform goal selection has the potential to improve the reinforcement learning (RL) of skills over uniform-random selection. In this paper, we introduce a method for learning a goal-selection policy in intrinsically-motivated goal-conditioned RL: \"Diversity Progress\" (DP). The learner forms a curriculum based on observed improvement in discriminability over its set of goals. Our proposed method is applicable to the class of discriminability-motivated agents, where the intrinsic reward is computed as a function of the agent's certainty of following the true goal being pursued. This reward can motivate the agent to learn a set of diverse skills without extrinsic rewards. We demonstrate empirically that a DP-motivated agent can learn a set of distinguishable skills faster than previous approaches, and do so without suffering from a collapse of the goal distribution -- a known issue with some prior approaches. We end with plans to take this proof-of-concept forward.", "published": "2024-11-07 05:00:00", "id": "bcd0afe3-47a3-4c05-bb28-192bdf320f78", "source": "arxiv", "section": "computerScience"}, {"title": "Enriching Tabular Data with Contextual LLM Embeddings: A Comprehensive Ablation Study for Ensemble Classifiers", "link": "https://arxiv.org/abs/2411.01645", "description": "arXiv:2411.01645v2 Announce Type: replace \nAbstract: Feature engineering is crucial for optimizing machine learning model performance, particularly in tabular data classification tasks. Leveraging advancements in natural language processing, this study presents a systematic approach to enrich tabular datasets with features derived from large language model embeddings. Through a comprehensive ablation study on diverse datasets, we assess the impact of RoBERTa and GPT-2 embeddings on ensemble classifiers, including Random Forest, XGBoost, and CatBoost. Results indicate that integrating embeddings with traditional numerical and categorical features often enhances predictive performance, especially on datasets with class imbalance or limited features and samples, such as UCI Adult, Heart Disease, Titanic, and Pima Indian Diabetes, with improvements particularly notable in XGBoost and CatBoost classifiers. Additionally, feature importance analysis reveals that LLM-derived features frequently rank among the most impactful for the predictions. This study provides a structured approach to embedding-based feature enrichment and illustrates its benefits in ensemble learning for tabular data.", "published": "2024-11-07 05:00:00", "id": "2c431b0b-4fbe-47d8-9030-da12ef22691c", "source": "arxiv", "section": "computerScience"}, {"title": "Revisiting Game-Theoretic Control in Socio-Technical Networks: Emerging Design Frameworks and Contemporary Applications", "link": "https://arxiv.org/abs/2411.01794", "description": "arXiv:2411.01794v2 Announce Type: replace \nAbstract: Socio-technical networks represent emerging cyber-physical infrastructures that are tightly interwoven with human networks. The coupling between human and technical networks presents significant challenges in managing, controlling, and securing these complex, interdependent systems. This paper investigates game-theoretic frameworks for the design and control of socio-technical networks, with a focus on critical applications such as misinformation management, infrastructure optimization, and resilience in socio-cyber-physical systems (SCPS). Core methodologies, including Stackelberg games, mechanism design, and dynamic game theory, are examined as powerful tools for modeling interactions in hierarchical, multi-agent environments. Key challenges addressed include mitigating human-driven vulnerabilities, managing large-scale system dynamics, and countering adversarial threats. By bridging individual agent behaviors with overarching system goals, this work illustrates how the integration of game theory and control theory can lead to robust, resilient, and adaptive socio-technical networks. This paper highlights the potential of these frameworks to dynamically align decentralized agent actions with system-wide objectives of stability, security, and efficiency.", "published": "2024-11-07 05:00:00", "id": "079bbb45-a56d-4359-b946-9729a69e9bf4", "source": "arxiv", "section": "computerScience"}, {"title": "AIWR: Aerial Image Water Resource Dataset for Segmentation Analysis", "link": "https://arxiv.org/abs/2411.01797", "description": "arXiv:2411.01797v2 Announce Type: replace \nAbstract: Effective water resource management is crucial in agricultural regions like northeastern Thailand, where limited water retention in sandy soils poses significant challenges. In response to this issue, the Aerial Image Water Resource (AIWR) dataset was developed, comprising 800 aerial images focused on natural and artificial water bodies in this region. The dataset was created using Bing Maps and follows the standards of the Fundamental Geographic Data Set (FGDS). It includes ground truth annotations validated by experts in remote sensing, making it an invaluable resource for researchers in geoinformatics, computer vision, and artificial intelligence. The AIWR dataset presents considerable challenges, such as segmentation due to variations in the size, color, shape, and similarity of water bodies, which often resemble other land use categories. The objective of the proposed dataset is to explore advanced AI-driven methods for water body segmentation, addressing the unique challenges posed by the dataset complexity and limited size. This dataset and related research contribute to the development of novel algorithms for water management, supporting sustainable agricultural practices in regions facing similar challenges.", "published": "2024-11-07 05:00:00", "id": "f6ae807e-27f5-4193-bd50-376d750bb201", "source": "arxiv", "section": "computerScience"}, {"title": "GVKF: Gaussian Voxel Kernel Functions for Highly Efficient Surface Reconstruction in Open Scenes", "link": "https://arxiv.org/abs/2411.01853", "description": "arXiv:2411.01853v2 Announce Type: replace \nAbstract: In this paper we present a novel method for efficient and effective 3D surface reconstruction in open scenes. Existing Neural Radiance Fields (NeRF) based works typically require extensive training and rendering time due to the adopted implicit representations. In contrast, 3D Gaussian splatting (3DGS) uses an explicit and discrete representation, hence the reconstructed surface is built by the huge number of Gaussian primitives, which leads to excessive memory consumption and rough surface details in sparse Gaussian areas. To address these issues, we propose Gaussian Voxel Kernel Functions (GVKF), which establish a continuous scene representation based on discrete 3DGS through kernel regression. The GVKF integrates fast 3DGS rasterization and highly effective scene implicit representations, achieving high-fidelity open scene surface reconstruction. Experiments on challenging scene datasets demonstrate the efficiency and effectiveness of our proposed GVKF, featuring with high reconstruction quality, real-time rendering speed, significant savings in storage and training memory consumption.", "published": "2024-11-07 05:00:00", "id": "96ae37e1-e864-4d22-9dc2-ace879ff94c3", "source": "arxiv", "section": "computerScience"}, {"title": "Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis", "link": "https://arxiv.org/abs/2411.01929", "description": "arXiv:2411.01929v2 Announce Type: replace \nAbstract: Artificial Intelligence (AI) research often aims to develop models that can generalize reliably across complex datasets, yet this remains challenging in fields where data is scarce, intricate, or inaccessible. This paper introduces a novel approach that leverages three generative models of varying complexity to synthesize one of the most demanding structured datasets: Malicious Network Traffic. Our approach uniquely transforms numerical data into text, re-framing data generation as a language modeling task, which not only enhances data regularization but also significantly improves generalization and the quality of the synthetic data. Extensive statistical analyses demonstrate that our method surpasses state-of-the-art generative models in producing high-fidelity synthetic data. Additionally, we conduct a comprehensive study on synthetic data applications, effectiveness, and evaluation strategies, offering valuable insights into its role across various domains. Our code and pre-trained models are openly accessible at Github, enabling further exploration and application of our methodology. Index Terms: Data synthesis, machine learning, traffic generation, privacy preserving data, generative models.", "published": "2024-11-07 05:00:00", "id": "310560d5-2f32-4185-a281-7633feb1e6dc", "source": "arxiv", "section": "computerScience"}, {"title": "TableGPT2: A Large Multimodal Model with Tabular Data Integration", "link": "https://arxiv.org/abs/2411.02059", "description": "arXiv:2411.02059v2 Announce Type: replace \nAbstract: The emergence of models like GPTs, Claude, LLaMA, and Qwen has reshaped AI applications, presenting vast new opportunities across industries. Yet, the integration of tabular data remains notably underdeveloped, despite its foundational role in numerous real-world domains.\n  This gap is critical for three main reasons. First, database or data warehouse data integration is essential for advanced applications; second, the vast and largely untapped resource of tabular data offers immense potential for analysis; and third, the business intelligence domain specifically demands adaptable, precise solutions that many current LLMs may struggle to provide.\n  In response, we introduce TableGPT2, a model rigorously pre-trained and fine-tuned with over 593.8K tables and 2.36M high-quality query-table-output tuples, a scale of table-related data unprecedented in prior research. This extensive training enables TableGPT2 to excel in table-centric tasks while maintaining strong general language and coding abilities.\n  One of TableGPT2's key innovations is its novel table encoder, specifically designed to capture schema-level and cell-level information. This encoder strengthens the model's ability to handle ambiguous queries, missing column names, and irregular tables commonly encountered in real-world applications. Similar to visual language models, this pioneering approach integrates with the decoder to form a robust large multimodal model.\n  We believe the results are compelling: over 23 benchmarking metrics, TableGPT2 achieves an average performance improvement of 35.20% in the 7B model and 49.32% in the 72B model over prior benchmark-neutral LLMs, with robust general-purpose capabilities intact.", "published": "2024-11-07 05:00:00", "id": "dc169bb9-fd84-411f-973c-e5e6688a3cea", "source": "arxiv", "section": "computerScience"}, {"title": "Optimizing AoI at Query in Multiuser Wireless Uplink Networks: A Whittle Index Approach", "link": "https://arxiv.org/abs/2411.02108", "description": "arXiv:2411.02108v3 Announce Type: replace \nAbstract: In this paper, we explore how to schedule multiple users to optimize information freshness in a pull-based wireless network, where the status updates from users are requested by randomly arriving queries at the destination. We use the age of information at query (QAoI) to characterize the performance of information freshness. Such a decision-making problem is naturally modeled as a Markov decision process (MDP), which, however, is prohibitively high to be solved optimally by the standard method due to the curse of dimensionality. To address this issue, we employ Whittle index approach, which allows us to decouple the original MDP into multiple sub-MDPs by relaxing the scheduling constraints. However, the binary Markovian query arrival process results in a bi-dimensional state and complex state transitions within each sub-MDP, making it challenging to verify Whittle indexability using conventional methods. After a thorough analysis of the sub-MDP's structure, we show that it is unichain and its optimal policy follows a threshold-type structure. This facilitates the verification of Whittle indexability of the sub-MDP by employing an easy-to-verify condition. Subsequently, the steady-state probability distributions of the sub-MDP under different threshold-type policies are analyzed, constituting the analytical expressions of different Whittle indices in terms of the expected average QAoI and scheduling time of the sub-MDP. Building on these, we devise an efficient algorithm to calculate Whittle indices for the formulated sub-MDPs. The simulation results validate our analyses and show the proposed Whittle index policy outperforms baseline policies and achieves near-optimal performance.", "published": "2024-11-07 05:00:00", "id": "83dbd72a-0418-465f-b807-085c460c2f77", "source": "arxiv", "section": "computerScience"}, {"title": "Digi2Real: Bridging the Realism Gap in Synthetic Data Face Recognition via Foundation Models", "link": "https://arxiv.org/abs/2411.02188", "description": "arXiv:2411.02188v3 Announce Type: replace \nAbstract: The accuracy of face recognition systems has improved significantly in the past few years, thanks to the large amount of data collected and the advancement in neural network architectures. However, these large-scale datasets are often collected without explicit consent, raising ethical and privacy concerns. To address this, there have been proposals to use synthetic datasets for training face recognition models. Yet, such models still rely on real data to train the generative models and generally exhibit inferior performance compared to those trained on real datasets. One of these datasets, DigiFace, uses a graphics pipeline to generate different identities and different intra-class variations without using real data in training the models. However, the performance of this approach is poor on face recognition benchmarks, possibly due to the lack of realism in the images generated from the graphics pipeline. In this work, we introduce a novel framework for realism transfer aimed at enhancing the realism of synthetically generated face images. Our method leverages the large-scale face foundation model, and we adapt the pipeline for realism enhancement. By integrating the controllable aspects of the graphics pipeline with our realism enhancement technique, we generate a large amount of realistic variations-combining the advantages of both approaches. Our empirical evaluations demonstrate that models trained using our enhanced dataset significantly improve the performance of face recognition systems over the baseline. The source code and datasets will be made available publicly: https://www.idiap.ch/paper/digi2real", "published": "2024-11-07 05:00:00", "id": "58c1c14c-25e3-4b0d-9d8d-c685cfc584a3", "source": "arxiv", "section": "computerScience"}, {"title": "Provably Transformers Harness Multi-Concept Word Semantics for Efficient In-Context Learning", "link": "https://arxiv.org/abs/2411.02199", "description": "arXiv:2411.02199v2 Announce Type: replace \nAbstract: Transformer-based large language models (LLMs) have displayed remarkable creative prowess and emergence capabilities. Existing empirical studies have revealed a strong connection between these LLMs' impressive emergence abilities and their in-context learning (ICL) capacity, allowing them to solve new tasks using only task-specific prompts without further fine-tuning. On the other hand, existing empirical and theoretical studies also show that there is a linear regularity of the multi-concept encoded semantic representation behind transformer-based LLMs. However, existing theoretical work fail to build up an understanding of the connection between this regularity and the innovative power of ICL. Additionally, prior work often focuses on simplified, unrealistic scenarios involving linear transformers or unrealistic loss functions, and they achieve only linear or sub-linear convergence rates. In contrast, this work provides a fine-grained mathematical analysis to show how transformers leverage the multi-concept semantics of words to enable powerful ICL and excellent out-of-distribution ICL abilities, offering insights into how transformers innovate solutions for certain unseen tasks encoded with multiple cross-concept semantics. Inspired by empirical studies on the linear latent geometry of LLMs, the analysis is based on a concept-based low-noise sparse coding prompt model. Leveraging advanced techniques, this work showcases the exponential 0-1 loss convergence over the highly non-convex training dynamics, which pioneeringly incorporates the challenges of softmax self-attention, ReLU-activated MLPs, and cross-entropy loss. Empirical simulations corroborate the theoretical findings.", "published": "2024-11-07 05:00:00", "id": "9c852075-fefa-4229-9103-0589cd999451", "source": "arxiv", "section": "computerScience"}, {"title": "FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training", "link": "https://arxiv.org/abs/2411.02229", "description": "arXiv:2411.02229v2 Announce Type: replace \nAbstract: The field of novel view synthesis from images has seen rapid advancements with the introduction of Neural Radiance Fields (NeRF) and more recently with 3D Gaussian Splatting. Gaussian Splatting became widely adopted due to its efficiency and ability to render novel views accurately. While Gaussian Splatting performs well when a sufficient amount of training images are available, its unstructured explicit representation tends to overfit in scenarios with sparse input images, resulting in poor rendering performance. To address this, we present a 3D Gaussian-based novel view synthesis method using sparse input images that can accurately render the scene from the viewpoints not covered by the training images. We propose a multi-stage training scheme with matching-based consistency constraints imposed on the novel views without relying on pre-trained depth estimation or diffusion models. This is achieved by using the matches of the available training images to supervise the generation of the novel views sampled between the training frames with color, geometry, and semantic losses. In addition, we introduce a locality preserving regularization for 3D Gaussians which removes rendering artifacts by preserving the local color structure of the scene. Evaluation on synthetic and real-world datasets demonstrates competitive or superior performance of our method in few-shot novel view synthesis compared to existing state-of-the-art methods.", "published": "2024-11-07 05:00:00", "id": "2b0e9e4e-ae6c-42ba-8aea-bba946a47b5f", "source": "arxiv", "section": "computerScience"}, {"title": "Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent", "link": "https://arxiv.org/abs/2411.02265", "description": "arXiv:2411.02265v3 Announce Type: replace \nAbstract: In this paper, we introduce Hunyuan-Large, which is currently the largest open-source Transformer-based mixture of experts model, with a total of 389 billion parameters and 52 billion activation parameters, capable of handling up to 256K tokens. We conduct a thorough evaluation of Hunyuan-Large's superior performance across various benchmarks including language understanding and generation, logical reasoning, mathematical problem-solving, coding, long-context, and aggregated tasks, where it outperforms LLama3.1-70B and exhibits comparable performance when compared to the significantly larger LLama3.1-405B model. Key practice of Hunyuan-Large include large-scale synthetic data that is orders larger than in previous literature, a mixed expert routing strategy, a key-value cache compression technique, and an expert-specific learning rate strategy. Additionally, we also investigate the scaling laws and learning rate schedule of mixture of experts models, providing valuable insights and guidances for future model development and optimization. The code and checkpoints of Hunyuan-Large are released to facilitate future innovations and applications.\n  Codes: https://github.com/Tencent/Hunyuan-Large\n  Models: https://huggingface.co/tencent/Tencent-Hunyuan-Large", "published": "2024-11-07 05:00:00", "id": "db2c6090-55e5-4ac9-ae95-7fadda6382e2", "source": "arxiv", "section": "computerScience"}, {"title": "Memory-Efficient Community Detection on Large Graphs Using Weighted Sketches", "link": "https://arxiv.org/abs/2411.02268", "description": "arXiv:2411.02268v2 Announce Type: replace \nAbstract: Community detection in graphs identifies groups of nodes with denser connections within the groups than between them, and while existing studies often focus on optimizing detection performance, memory constraints become critical when processing large graphs on shared-memory systems. We recently proposed efficient implementations of the Louvain, Leiden, and Label Propagation Algorithms (LPA) for community detection. However, these incur significant memory overhead from the use of collision-free per-thread hashtables. To address this, we introduce memory-efficient alternatives using weighted Misra-Gries (MG) sketches, which replace the per-thread hashtables, and reduce memory demands in Louvain, Leiden, and LPA implementations - while incurring only a minor quality drop (up to 1%) and moderate runtime penalties. We believe that these approaches, though slightly slower, are well-suited for parallel processing and could outperform current memory-intensive techniques on systems with many threads.", "published": "2024-11-07 05:00:00", "id": "5e8ccc8d-c6d9-47b1-b612-d05033a7d211", "source": "arxiv", "section": "computerScience"}, {"title": "A Persuasion-Based Prompt Learning Approach to Improve Smishing Detection through Data Augmentation", "link": "https://arxiv.org/abs/2411.02403", "description": "arXiv:2411.02403v2 Announce Type: replace \nAbstract: Smishing, which aims to illicitly obtain personal information from unsuspecting victims, holds significance due to its negative impacts on our society. In prior studies, as a tool to counteract smishing, machine learning (ML) has been widely adopted, which filters and blocks smishing messages before they reach potential victims. However, a number of challenges remain in ML-based smishing detection, with the scarcity of annotated datasets being one major hurdle. Specifically, given the sensitive nature of smishing-related data, there is a lack of publicly accessible data that can be used for training and evaluating ML models. Additionally, the nuanced similarities between smishing messages and other types of social engineering attacks such as spam messages exacerbate the challenge of smishing classification with limited resources. To tackle this challenge, we introduce a novel data augmentation method utilizing a few-shot prompt learning approach. What sets our approach apart from extant methods is the use of the principles of persuasion, a psychology theory which explains the underlying mechanisms of smishing. By designing prompts grounded in the persuasion principles, our augmented dataset could effectively capture various, important aspects of smishing messages, enabling ML models to be effectively trained. Our evaluation within a real-world context demonstrates that our augmentation approach produces more diverse and higher-quality smishing data instances compared to other cutting-edging approaches, leading to substantial improvements in the ability of ML models to detect the subtle characteristics of smishing messages. Moreover, our additional analyses reveal that the performance improvement provided by our approach is more pronounced when used with ML models that have a larger number of parameters, demonstrating its effectiveness in training large-scale ML models.", "published": "2024-11-07 05:00:00", "id": "cd504597-5ebe-4b20-b160-041719dc4b62", "source": "arxiv", "section": "computerScience"}, {"title": "FactTest: Factuality Testing in Large Language Models with Finite-Sample and Distribution-Free Guarantees", "link": "https://arxiv.org/abs/2411.02603", "description": "arXiv:2411.02603v2 Announce Type: replace \nAbstract: The propensity of Large Language Models (LLMs) to generate hallucinations and non-factual content undermines their reliability in high-stakes domains, where rigorous control over Type I errors (the conditional probability of incorrectly classifying hallucinations as truthful content) is essential. Despite its importance, formal verification of LLM factuality with such guarantees remains largely unexplored. In this paper, we introduce FactTest, a novel framework that statistically assesses whether an LLM can confidently provide correct answers to given questions with high-probability correctness guarantees. We formulate factuality testing as hypothesis testing problem to enforce an upper bound of Type I errors at user-specified significance levels. Notably, we prove that our framework also ensures strong Type II error control under mild conditions and can be extended to maintain its effectiveness when covariate shifts exist. %These analyses are amenable to the principled NP framework. Our approach is distribution-free and works for any number of human-annotated samples. It is model-agnostic and applies to any black-box or white-box LM. Extensive experiments on question-answering (QA) and multiple-choice benchmarks demonstrate that \\approach effectively detects hallucinations and improves the model's ability to abstain from answering unknown questions, leading to an over 40% accuracy improvement.", "published": "2024-11-07 05:00:00", "id": "9e95f18d-3240-4c22-96e3-594d6b4a96b1", "source": "arxiv", "section": "computerScience"}, {"title": "Wave Network: An Ultra-Small Language Model", "link": "https://arxiv.org/abs/2411.02674", "description": "arXiv:2411.02674v2 Announce Type: replace \nAbstract: We propose an innovative token representation and update method in a new ultra-small language model: the Wave network. Specifically, we use a complex vector to represent each token, encoding both global and local semantics of the input text. A complex vector consists of two components: a magnitude vector representing the global semantics of the input text, and a phase vector capturing the relationships between individual tokens and global semantics. Experiments on the AG News text classification task demonstrate that, when generating complex vectors from randomly initialized token embeddings, our single-layer Wave Network achieves 90.91% accuracy with wave interference and 91.66% with wave modulation - outperforming a single Transformer layer using BERT pre-trained embeddings by 19.23% and 19.98%, respectively, and approaching the accuracy of the pre-trained and fine-tuned BERT base model (94.64%). Additionally, compared to BERT base, the Wave Network reduces video memory usage and training time by 77.34% and 85.62% during wave modulation. In summary, we used a 2.4-million-parameter small language model to achieve accuracy comparable to a 100-million-parameter BERT model in text classification.", "published": "2024-11-07 05:00:00", "id": "703f410d-752c-4483-b435-6f0a2ceab8ec", "source": "arxiv", "section": "computerScience"}, {"title": "Sensitivity Lower Bounds for Approximaiton Algorithms", "link": "https://arxiv.org/abs/2411.02744", "description": "arXiv:2411.02744v2 Announce Type: replace \nAbstract: Sensitivity measures how much the output of an algorithm changes, in terms of Hamming distance, when part of the input is modified. While approximation algorithms with low sensitivity have been developed for many problems, no sensitivity lower bounds were previously known for approximation algorithms. In this work, we establish the first polynomial lower bound on the sensitivity of (randomized) approximation algorithms for constraint satisfaction problems (CSPs) by adapting the probabilistically checkable proof (PCP) framework to preserve sensitivity lower bounds. From this, we derive polynomial sensitivity lower bounds for approximation algorithms for a variety of problems, including maximum clique, minimum vertex cover, and maximum cut.\n  Given the connection between sensitivity and distributed algorithms, our sensitivity lower bounds also allow us to recover various round complexity lower bounds for distributed algorithms in the LOCAL model. Additionally, we present new lower bounds for distributed CSPs.", "published": "2024-11-07 05:00:00", "id": "96f79149-a893-4ab5-be40-1df916615e0f", "source": "arxiv", "section": "computerScience"}, {"title": "PersianRAG: A Retrieval-Augmented Generation System for Persian Language", "link": "https://arxiv.org/abs/2411.02832", "description": "arXiv:2411.02832v2 Announce Type: replace \nAbstract: Retrieval augmented generation (RAG) models, which integrate large-scale pre-trained generative models with external retrieval mechanisms, have shown significant success in various natural language processing (NLP) tasks. However, applying RAG models in Persian language as a low-resource language, poses distinct challenges. These challenges primarily involve the preprocessing, embedding, retrieval, prompt construction, language modeling, and response evaluation of the system. In this paper, we address the challenges towards implementing a real-world RAG system for Persian language called PersianRAG. We propose novel solutions to overcome these obstacles and evaluate our approach using several Persian benchmark datasets. Our experimental results demonstrate the capability of the PersianRAG framework to enhance question answering task in Persian.", "published": "2024-11-07 05:00:00", "id": "64ac4508-d33a-4016-b032-72e9601e74af", "source": "arxiv", "section": "computerScience"}, {"title": "Dissecting the Failure of Invariant Learning on Graphs", "link": "https://arxiv.org/abs/2411.02847", "description": "arXiv:2411.02847v2 Announce Type: replace \nAbstract: Enhancing node-level Out-Of-Distribution (OOD) generalization on graphs remains a crucial area of research. In this paper, we develop a Structural Causal Model (SCM) to theoretically dissect the performance of two prominent invariant learning methods -- Invariant Risk Minimization (IRM) and Variance-Risk Extrapolation (VREx) -- in node-level OOD settings. Our analysis reveals a critical limitation: due to the lack of class-conditional invariance constraints, these methods may struggle to accurately identify the structure of the predictive invariant ego-graph and consequently rely on spurious features. To address this, we propose Cross-environment Intra-class Alignment (CIA), which explicitly eliminates spurious features by aligning cross-environment representations conditioned on the same class, bypassing the need for explicit knowledge of the causal pattern structure. To adapt CIA to node-level OOD scenarios where environment labels are hard to obtain, we further propose CIA-LRA (Localized Reweighting Alignment) that leverages the distribution of neighboring labels to selectively align node representations, effectively distinguishing and preserving invariant features while removing spurious ones, all without relying on environment labels. We theoretically prove CIA-LRA's effectiveness by deriving an OOD generalization error bound based on PAC-Bayesian analysis. Experiments on graph OOD benchmarks validate the superiority of CIA and CIA-LRA, marking a significant advancement in node-level OOD generalization. The codes are available at https://github.com/NOVAglow646/NeurIPS24-Invariant-Learning-on-Graphs.", "published": "2024-11-07 05:00:00", "id": "957d018c-d0c3-4b59-b1d2-61f1af9ed42b", "source": "arxiv", "section": "computerScience"}, {"title": "Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent", "link": "https://arxiv.org/abs/2411.02937", "description": "arXiv:2411.02937v2 Announce Type: replace \nAbstract: Multimodal Retrieval Augmented Generation (mRAG) plays an important role in mitigating the \"hallucination\" issue inherent in multimodal large language models (MLLMs). Although promising, existing heuristic mRAGs typically predefined fixed retrieval processes, which causes two issues: (1) Non-adaptive Retrieval Queries. (2) Overloaded Retrieval Queries. However, these flaws cannot be adequately reflected by current knowledge-seeking visual question answering (VQA) datasets, since the most required knowledge can be readily obtained with a standard two-step retrieval. To bridge the dataset gap, we first construct Dyn-VQA dataset, consisting of three types of \"dynamic\" questions, which require complex knowledge retrieval strategies variable in query, tool, and time: (1) Questions with rapidly changing answers. (2) Questions requiring multi-modal knowledge. (3) Multi-hop questions. Experiments on Dyn-VQA reveal that existing heuristic mRAGs struggle to provide sufficient and precisely relevant knowledge for dynamic questions due to their rigid retrieval processes. Hence, we further propose the first self-adaptive planning agent for multimodal retrieval, OmniSearch. The underlying idea is to emulate the human behavior in question solution which dynamically decomposes complex multimodal questions into sub-question chains with retrieval action. Extensive experiments prove the effectiveness of our OmniSearch, also provide direction for advancing mRAG. The code and dataset will be open-sourced at https://github.com/Alibaba-NLP/OmniSearch.", "published": "2024-11-07 05:00:00", "id": "4433b9c0-e8f4-4e43-91b2-401b2ff3e9a2", "source": "arxiv", "section": "computerScience"}, {"title": "Speaker Emotion Recognition: Leveraging Self-Supervised Models for Feature Extraction Using Wav2Vec2 and HuBERT", "link": "https://arxiv.org/abs/2411.02964", "description": "arXiv:2411.02964v2 Announce Type: replace \nAbstract: Speech is the most natural way of expressing ourselves as humans. Identifying emotion from speech is a nontrivial task due to the ambiguous definition of emotion itself. Speaker Emotion Recognition (SER) is essential for understanding human emotional behavior. The SER task is challenging due to the variety of speakers, background noise, complexity of emotions, and speaking styles. It has many applications in education, healthcare, customer service, and Human-Computer Interaction (HCI). Previously, conventional machine learning methods such as SVM, HMM, and KNN have been used for the SER task. In recent years, deep learning methods have become popular, with convolutional neural networks and recurrent neural networks being used for SER tasks. The input of these methods is mostly spectrograms and hand-crafted features. In this work, we study the use of self-supervised transformer-based models, Wav2Vec2 and HuBERT, to determine the emotion of speakers from their voice. The models automatically extract features from raw audio signals, which are then used for the classification task. The proposed solution is evaluated on reputable datasets, including RAVDESS, SHEMO, SAVEE, AESDD, and Emo-DB. The results show the effectiveness of the proposed method on different datasets. Moreover, the model has been used for real-world applications like call center conversations, and the results demonstrate that the model accurately predicts emotions.", "published": "2024-11-07 05:00:00", "id": "b26cf64f-3525-4bb9-8d1d-b6157c6f3f48", "source": "arxiv", "section": "computerScience"}, {"title": "Confidence Calibration of Classifiers with Many Classes", "link": "https://arxiv.org/abs/2411.02988", "description": "arXiv:2411.02988v2 Announce Type: replace \nAbstract: For classification models based on neural networks, the maximum predicted class probability is often used as a confidence score. This score rarely predicts well the probability of making a correct prediction and requires a post-processing calibration step. However, many confidence calibration methods fail for problems with many classes. To address this issue, we transform the problem of calibrating a multiclass classifier into calibrating a single surrogate binary classifier. This approach allows for more efficient use of standard calibration methods. We evaluate our approach on numerous neural networks used for image or text classification and show that it significantly enhances existing calibration methods.", "published": "2024-11-07 05:00:00", "id": "6f89062e-2d62-4e1a-9ed7-32f66ca1d32d", "source": "arxiv", "section": "computerScience"}, {"title": "Self-Compositional Data Augmentation for Scientific Keyphrase Generation", "link": "https://arxiv.org/abs/2411.03039", "description": "arXiv:2411.03039v2 Announce Type: replace \nAbstract: State-of-the-art models for keyphrase generation require large amounts of training data to achieve good performance. However, obtaining keyphrase-labeled documents can be challenging and costly. To address this issue, we present a self-compositional data augmentation method. More specifically, we measure the relatedness of training documents based on their shared keyphrases, and combine similar documents to generate synthetic samples. The advantage of our method lies in its ability to create additional training samples that keep domain coherence, without relying on external data or resources. Our results on multiple datasets spanning three different domains, demonstrate that our method consistently improves keyphrase generation. A qualitative analysis of the generated keyphrases for the Computer Science domain confirms this improvement towards their representativity property.", "published": "2024-11-07 05:00:00", "id": "8279486f-8c0b-40c8-8c83-97c5b0a0ec0b", "source": "arxiv", "section": "computerScience"}, {"title": "ATM: Improving Model Merging by Alternating Tuning and Merging", "link": "https://arxiv.org/abs/2411.03055", "description": "arXiv:2411.03055v2 Announce Type: replace \nAbstract: Model merging has recently emerged as a cost-efficient paradigm for multi-task learning. Among current approaches, task arithmetic stands out for its simplicity and effectiveness. In this paper, we motivate the effectiveness of task vectors by linking them to multi-task gradients. We show that in a single-epoch scenario, task vectors are mathematically equivalent to the gradients obtained via gradient descent in a multi-task setting, and still approximate these gradients in subsequent epochs. Furthermore, we show that task vectors perform optimally when equality is maintained, and their effectiveness is largely driven by the first epoch's gradient. Building on this insight, we propose viewing model merging as a single step in an iterative process that Alternates between Tuning and Merging (ATM). This method acts as a bridge between model merging and multi-task gradient descent, achieving state-of-the-art results with the same data and computational requirements. We extensively evaluate ATM across diverse settings, achieving up to 20% higher accuracy in computer vision and NLP tasks, compared to the best baselines. Finally, we provide both empirical and theoretical support for its effectiveness, demonstrating increased orthogonality between task vectors and proving that ATM minimizes an upper bound on the loss obtained by jointly finetuning all tasks.", "published": "2024-11-07 05:00:00", "id": "8d3a4c43-3f86-4eed-9a73-c4eac78dac44", "source": "arxiv", "section": "computerScience"}, {"title": "Navigating Extremes: Dynamic Sparsity in Large Output Space", "link": "https://arxiv.org/abs/2411.03171", "description": "arXiv:2411.03171v2 Announce Type: replace \nAbstract: In recent years, Dynamic Sparse Training (DST) has emerged as an alternative to post-training pruning for generating efficient models. In principle, DST allows for a more memory efficient training process, as it maintains sparsity throughout the entire training run. However, current DST implementations fail to capitalize on this in practice. Because sparse matrix multiplication is much less efficient than dense matrix multiplication on GPUs, most implementations simulate sparsity by masking weights. In this paper, we leverage recent advances in semi-structured sparse training to apply DST in the domain of classification with large output spaces, where memory-efficiency is paramount. With a label space of possibly millions of candidates, the classification layer alone will consume several gigabytes of memory. Switching from a dense to a fixed fan-in sparse layer updated with sparse evolutionary training (SET); however, severely hampers training convergence, especially at the largest label spaces. We find that poor gradient flow from the sparse classifier to the dense text encoder make it difficult to learn good input representations. By employing an intermediate layer or adding an auxiliary training objective, we recover most of the generalisation performance of the dense model. Overall, we demonstrate the applicability and practical benefits of DST in a challenging domain -- characterized by a highly skewed label distribution that differs substantially from typical DST benchmark datasets -- which enables end-to-end training with millions of labels on commodity hardware.", "published": "2024-11-07 05:00:00", "id": "ef0a444c-9d90-463b-aa41-7173a58d86b7", "source": "arxiv", "section": "computerScience"}, {"title": "GIS Copilot: Towards an Autonomous GIS Agent for Spatial Analysis", "link": "https://arxiv.org/abs/2411.03205", "description": "arXiv:2411.03205v2 Announce Type: replace \nAbstract: Recent advancements in Generative AI offer promising capabilities for spatial analysis. Despite their potential, the integration of generative AI with established GIS platforms remains underexplored. In this study, we propose a framework for integrating LLMs directly into existing GIS platforms, using QGIS as an example. Our approach leverages the reasoning and programming capabilities of LLMs to autonomously generate spatial analysis workflows and code through an informed agent that has comprehensive documentation of key GIS tools and parameters. The implementation of this framework resulted in the development of a \"GIS Copilot\" that allows GIS users to interact with QGIS using natural language commands for spatial analysis. The GIS Copilot was evaluated based on three complexity levels: basic tasks that require one GIS tool and typically involve one data layer to perform simple operations; intermediate tasks involving multi-step processes with multiple tools, guided by user instructions; and advanced tasks which involve multi-step processes that require multiple tools but not guided by user instructions, necessitating the agent to independently decide on and executes the necessary steps. The evaluation reveals that the GIS Copilot demonstrates strong potential in automating foundational GIS operations, with a high success rate in tool selection and code generation for basic and intermediate tasks, while challenges remain in achieving full autonomy for more complex tasks. This study contributes to the emerging vision of Autonomous GIS, providing a pathway for non-experts to engage with geospatial analysis with minimal prior expertise. While full autonomy is yet to be achieved, the GIS Copilot demonstrates significant potential for simplifying GIS workflows and enhancing decision-making processes.", "published": "2024-11-07 05:00:00", "id": "bd6fb811-db56-4ea3-986d-df9fb2039666", "source": "arxiv", "section": "computerScience"}, {"title": "Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation", "link": "https://arxiv.org/abs/2411.03223", "description": "arXiv:2411.03223v2 Announce Type: replace \nAbstract: Earth Observation (EO) data analysis has been significantly revolutionized by deep learning (DL), with applications typically limited to grid-like data structures. Graph Neural Networks (GNNs) emerge as an important innovation, propelling DL into the non-Euclidean domain. Naturally, GNNs can effectively tackle the challenges posed by diverse modalities, multiple sensors, and the heterogeneous nature of EO data. To introduce GNNs in the related domains, our review begins by offering fundamental knowledge on GNNs. Then, we summarize the generic problems in EO, to which GNNs can offer potential solutions. Following this, we explore a broad spectrum of GNNs' applications to scientific problems in Earth systems, covering areas such as weather and climate analysis, disaster management, air quality monitoring, agriculture, land cover classification, hydrological process modeling, and urban modeling. The rationale behind adopting GNNs in these fields is explained, alongside methodologies for organizing graphs and designing favorable architectures for various tasks. Furthermore, we highlight methodological challenges of implementing GNNs in these domains and possible solutions that could guide future research. While acknowledging that GNNs are not a universal solution, we conclude the paper by comparing them with other popular architectures like transformers and analyzing their potential synergies.", "published": "2024-11-07 05:00:00", "id": "1e6c93d6-3152-48c9-851c-450a89c1aa54", "source": "arxiv", "section": "computerScience"}, {"title": "Formal Logic-guided Robust Federated Learning against Poisoning Attacks", "link": "https://arxiv.org/abs/2411.03231", "description": "arXiv:2411.03231v2 Announce Type: replace \nAbstract: Federated Learning (FL) offers a promising solution to the privacy concerns associated with centralized Machine Learning (ML) by enabling decentralized, collaborative learning. However, FL is vulnerable to various security threats, including poisoning attacks, where adversarial clients manipulate the training data or model updates to degrade overall model performance. Recognizing this threat, researchers have focused on developing defense mechanisms to counteract poisoning attacks in FL systems. However, existing robust FL methods predominantly focus on computer vision tasks, leaving a gap in addressing the unique challenges of FL with time series data. In this paper, we present FLORAL, a defense mechanism designed to mitigate poisoning attacks in federated learning for time-series tasks, even in scenarios with heterogeneous client data and a large number of adversarial participants. Unlike traditional model-centric defenses, FLORAL leverages logical reasoning to evaluate client trustworthiness by aligning their predictions with global time-series patterns, rather than relying solely on the similarity of client updates. Our approach extracts logical reasoning properties from clients, then hierarchically infers global properties, and uses these to verify client updates. Through formal logic verification, we assess the robustness of each client contribution, identifying deviations indicative of adversarial behavior. Experimental results on two datasets demonstrate the superior performance of our approach compared to existing baseline methods, highlighting its potential to enhance the robustness of FL to time series applications. Notably, FLORAL reduced the prediction error by 93.27% in the best-case scenario compared to the second-best baseline. Our code is available at https://anonymous.4open.science/r/FLORAL-Robust-FTS.", "published": "2024-11-07 05:00:00", "id": "2a09475b-889e-40be-bad1-ffe70ed8ebf4", "source": "arxiv", "section": "computerScience"}, {"title": "Out-of-Distribution Recovery with Object-Centric Keypoint Inverse Policy For Visuomotor Imitation Learning", "link": "https://arxiv.org/abs/2411.03294", "description": "arXiv:2411.03294v2 Announce Type: replace \nAbstract: We propose an object-centric recovery policy framework to address the challenges of out-of-distribution (OOD) scenarios in visuomotor policy learning. Previous behavior cloning (BC) methods rely heavily on a large amount of labeled data coverage, failing in unfamiliar spatial states. Without relying on extra data collection, our approach learns a recovery policy constructed by an inverse policy inferred from object keypoint manifold gradient in the original training data. The recovery policy serves as a simple add-on to any base visuomotor BC policy, agnostic to a specific method, guiding the system back towards the training distribution to ensure task success even in OOD situations. We demonstrate the effectiveness of our object-centric framework in both simulation and real robot experiments, achieving an improvement of 77.7% over the base policy in OOD. Project Website: https://sites.google.com/view/ocr-penn", "published": "2024-11-07 05:00:00", "id": "de7d5294-7207-4d1b-9cd9-bb31d44e9736", "source": "arxiv", "section": "computerScience"}, {"title": "Classification Done Right for Vision-Language Pre-Training", "link": "https://arxiv.org/abs/2411.03313", "description": "arXiv:2411.03313v2 Announce Type: replace \nAbstract: We introduce SuperClass, a super simple classification method for vision-language pre-training on image-text data. Unlike its contrastive counterpart CLIP who contrast with a text encoder, SuperClass directly utilizes tokenized raw text as supervised classification labels, without the need for additional text filtering or selection. Due to the absence of the text encoding as contrastive target, SuperClass does not require a text encoder and does not need to maintain a large batch size as CLIP does. SuperClass demonstrated superior performance on various downstream tasks, including classic computer vision benchmarks and vision language downstream tasks. We further explored the scaling behavior of SuperClass on model size, training length, or data size, and reported encouraging results and comparisons to CLIP. https://github.com/x-cls/superclass", "published": "2024-11-07 05:00:00", "id": "e99a5b22-f3d8-4aa8-a81f-5a13c928415f", "source": "arxiv", "section": "computerScience"}, {"title": "Fault-tolerant Coding for Quantum Communication", "link": "https://arxiv.org/abs/2009.07161", "description": "arXiv:2009.07161v3 Announce Type: replace-cross \nAbstract: Designing encoding and decoding circuits to reliably send messages over many uses of a noisy channel is a central problem in communication theory. When studying the optimal transmission rates achievable with asymptotically vanishing error it is usually assumed that these circuits can be implemented using noise-free gates. While this assumption is satisfied for classical machines in many scenarios, it is not expected to be satisfied in the near term future for quantum machines where decoherence leads to faults in the quantum gates. As a result, fundamental questions regarding the practical relevance of quantum channel coding remain open. By combining techniques from fault-tolerant quantum computation with techniques from quantum communication, we initiate the study of these questions. We introduce fault-tolerant versions of quantum capacities quantifying the optimal communication rates achievable with asymptotically vanishing total error when the encoding and decoding circuits are affected by gate errors with small probability. Our main results are threshold theorems for the classical and quantum capacity: For every quantum channel $T$ and every $\\epsilon>0$ there exists a threshold $p(\\epsilon,T)$ for the gate error probability below which rates larger than $C-\\epsilon$ are fault-tolerantly achievable with vanishing overall communication error, where $C$ denotes the usual capacity. Our results are not only relevant in communication over large distances, but also on-chip, where distant parts of a quantum computer might need to communicate under higher levels of noise than affecting the local gates.", "published": "2024-11-07 05:00:00", "id": "9a596d10-c272-4710-bc0a-f22efce1d6ea", "source": "arxiv", "section": "computerScience"}, {"title": "Robustifying automatic speech recognition by extracting slowly varying features", "link": "https://arxiv.org/abs/2112.07400", "description": "arXiv:2112.07400v3 Announce Type: replace-cross \nAbstract: In the past few years, it has been shown that deep learning systems are highly vulnerable under attacks with adversarial examples. Neural-network-based automatic speech recognition (ASR) systems are no exception. Targeted and untargeted attacks can modify an audio input signal in such a way that humans still recognise the same words, while ASR systems are steered to predict a different transcription. In this paper, we propose a defense mechanism against targeted adversarial attacks consisting in removing fast-changing features from the audio signals, either by applying slow feature analysis, a low-pass filter, or both, before feeding the input to the ASR system. We perform an empirical analysis of hybrid ASR models trained on data pre-processed in such a way. While the resulting models perform quite well on benign data, they are significantly more robust against targeted adversarial attacks: Our final, proposed model shows a performance on clean data similar to the baseline model, while being more than four times more robust.", "published": "2024-11-07 05:00:00", "id": "d36639eb-dcff-4e05-acf4-50a8bedd8242", "source": "arxiv", "section": "computerScience"}, {"title": "$\\mathcal{S}$-adic characterization of minimal dendric shifts", "link": "https://arxiv.org/abs/2206.00333", "description": "arXiv:2206.00333v3 Announce Type: replace-cross \nAbstract: Dendric shifts are defined by combinatorial restrictions of the extensions of the words in their languages. This family generalizes well-known families of shifts such as Sturmian shifts, Arnoux-Rauzy shifts and codings of interval exchange transformations. It is known that any minimal dendric shift has a primitive $\\mathcal{S}$-adic representation where the morphisms in $\\mathcal{S}$ are positive tame automorphisms of the free group generated by the alphabet. In this paper we give an $\\mathcal{S}$-adic characterization of this family by means of two finite graphs. As an application, we are able to decide whether a shift space generated by a uniformly recurrent morphic word is (eventually) dendric.", "published": "2024-11-07 05:00:00", "id": "73d61051-e36c-4ee9-8bb5-77dd8a6139aa", "source": "arxiv", "section": "computerScience"}, {"title": "Exponential convergence rates for momentum stochastic gradient descent in the overparametrized setting", "link": "https://arxiv.org/abs/2302.03550", "description": "arXiv:2302.03550v2 Announce Type: replace-cross \nAbstract: We prove explicit bounds on the exponential rate of convergence for the momentum stochastic gradient descent scheme (MSGD) for arbitrary, fixed hyperparameters (learning rate, friction parameter) and its continuous-in-time counterpart in the context of non-convex optimization. In the small step-size regime and in the case of flat minima or large noise intensities, these bounds prove faster convergence of MSGD compared to plain stochastic gradient descent (SGD). The results are shown for objective functions satisfying a local Polyak-Lojasiewicz inequality and under assumptions on the variance of MSGD that are satisfied in overparametrized settings. Moreover, we analyze the optimal choice of the friction parameter and show that the MSGD process almost surely converges to a local minimum.", "published": "2024-11-07 05:00:00", "id": "37d89a39-3720-4b19-a9b7-0392e3516837", "source": "arxiv", "section": "computerScience"}, {"title": "Pre-trained Mixed Integer Optimization through Multi-variable Cardinality Branching", "link": "https://arxiv.org/abs/2305.12352", "description": "arXiv:2305.12352v2 Announce Type: replace-cross \nAbstract: In this paper, we propose a Pre-trained Mixed Integer Optimization framework (PreMIO) that accelerates online mixed integer program (MIP) solving with offline datasets and machine learning models. Our method is based on a data-driven multi-variable cardinality branching procedure that splits the MIP feasible region using hyperplanes chosen by the concentration inequalities. Unlike most previous ML+MIP approaches that either require complicated implementation or suffer from a lack of theoretical justification, our method is simple, flexible, provable, and explainable. Numerical experiments on both classical OR benchmark datasets and real-life instances validate the efficiency of our proposed method.", "published": "2024-11-07 05:00:00", "id": "c302d002-1f6c-477c-93a8-cd9634d240f1", "source": "arxiv", "section": "computerScience"}, {"title": "Mind the spikes: Benign overfitting of kernels and neural networks in fixed dimension", "link": "https://arxiv.org/abs/2305.14077", "description": "arXiv:2305.14077v3 Announce Type: replace-cross \nAbstract: The success of over-parameterized neural networks trained to near-zero training error has caused great interest in the phenomenon of benign overfitting, where estimators are statistically consistent even though they interpolate noisy training data. While benign overfitting in fixed dimension has been established for some learning methods, current literature suggests that for regression with typical kernel methods and wide neural networks, benign overfitting requires a high-dimensional setting where the dimension grows with the sample size. In this paper, we show that the smoothness of the estimators, and not the dimension, is the key: benign overfitting is possible if and only if the estimator's derivatives are large enough. We generalize existing inconsistency results to non-interpolating models and more kernels to show that benign overfitting with moderate derivatives is impossible in fixed dimension. Conversely, we show that rate-optimal benign overfitting is possible for regression with a sequence of spiky-smooth kernels with large derivatives. Using neural tangent kernels, we translate our results to wide neural networks. We prove that while infinite-width networks do not overfit benignly with the ReLU activation, this can be fixed by adding small high-frequency fluctuations to the activation function. Our experiments verify that such neural networks, while overfitting, can indeed generalize well even on low-dimensional data sets.", "published": "2024-11-07 05:00:00", "id": "b9d38987-a958-42c0-b7c5-49080bfdef47", "source": "arxiv", "section": "computerScience"}, {"title": "Nonlinear Distributionally Robust Optimization", "link": "https://arxiv.org/abs/2306.03202", "description": "arXiv:2306.03202v3 Announce Type: replace-cross \nAbstract: This article focuses on a class of distributionally robust optimization (DRO) problems where, unlike the growing body of the literature, the objective function is potentially nonlinear in the distribution. Existing methods to optimize nonlinear functions in probability space use the Frechet derivatives, which present theoretical and computational challenges. Motivated by this, we propose an alternative notion for the derivative and corresponding smoothness based on Gateaux (G)-derivative for generic risk measures. These concepts are explained via three running risk measure examples of variance, entropic risk, and risk on finite support sets. We then propose a G-derivative-based Frank-Wolfe (FW) algorithm for generic nonlinear optimization problems in probability spaces and establish its convergence under the proposed notion of smoothness in a completely norm-independent manner. We use the set-up of the FW algorithm to devise a methodology to compute a saddle point of the nonlinear DRO problem. Finally, we validate our theoretical results on two cases of the $entropic$ and $variance$ risk measures in the context of portfolio selection problems. In particular, we analyze their regularity conditions and \"sufficient statistic\", compute the respective FW-oracle in various settings, and confirm the theoretical outcomes through numerical validation.", "published": "2024-11-07 05:00:00", "id": "2e46f051-ed02-4de5-b3ee-4b3157f3f916", "source": "arxiv", "section": "computerScience"}, {"title": "Learning to Compute Gr\\\"obner Bases", "link": "https://arxiv.org/abs/2311.12904", "description": "arXiv:2311.12904v3 Announce Type: replace-cross \nAbstract: Solving a polynomial system, or computing an associated Gr\\\"obner basis, has been a fundamental task in computational algebra. However, it is also known for its notorious doubly exponential time complexity in the number of variables in the worst case. This paper is the first to address the learning of Gr\\\"obner basis computation with Transformers. The training requires many pairs of a polynomial system and the associated Gr\\\"obner basis, raising two novel algebraic problems: random generation of Gr\\\"obner bases and transforming them into non-Gr\\\"obner ones, termed as backward Gr\\\"obner problem. We resolve these problems with 0-dimensional radical ideals, the ideals appearing in various applications. Further, we propose a hybrid input embedding to handle coefficient tokens with continuity bias and avoid the growth of the vocabulary set. The experiments show that our dataset generation method is a few orders of magnitude faster than a naive approach, overcoming a crucial challenge in learning to compute Gr\\\"obner bases, and Gr\\\"obner computation is learnable in a particular class.", "published": "2024-11-07 05:00:00", "id": "241e04d7-918c-4e52-bf88-2ba714d5207f", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Content Moderation with Culturally-Aware Models", "link": "https://arxiv.org/abs/2312.02401", "description": "arXiv:2312.02401v2 Announce Type: replace-cross \nAbstract: Content moderation on a global scale must navigate a complex array of local cultural distinctions, which can hinder effective enforcement. While global policies aim for consistency and broad applicability, they often miss the subtleties of regional language interpretation, cultural beliefs, and local legislation. This work introduces a flexible framework that enhances foundation language models with cultural knowledge. Our approach involves fine-tuning encoder-decoder models on media-diet data to capture cultural nuances, and applies a continued training regime to effectively integrate these models into a content moderation pipeline. We evaluate this framework in a case study of an online podcast platform with content spanning various regions. The results show that our culturally adapted models improve the accuracy of local violation detection and offer explanations that align more closely with regional cultural norms. Our findings reinforce the need for an adaptable content moderation approach that remains flexible in response to the diverse cultural landscapes it operates in and represents a step towards a more equitable and culturally sensitive framework for content moderation, demonstrating what is achievable in this domain.", "published": "2024-11-07 05:00:00", "id": "b43cef33-f909-44af-a112-14fa0d302906", "source": "arxiv", "section": "computerScience"}, {"title": "Skills or Degree? The Rise of Skill-Based Hiring for AI and Green Jobs", "link": "https://arxiv.org/abs/2312.11942", "description": "arXiv:2312.11942v2 Announce Type: replace-cross \nAbstract: Emerging professions in fields like Artificial Intelligence (AI) and sustainability (green jobs) are experiencing labour shortages as industry demand outpaces labour supply. In this context, our study aims to understand whether employers have begun focusing more on individual skills rather than formal qualifications in their recruitment processes. We analysed a large time-series dataset of approximately eleven million online job vacancies in the UK from 2018 to mid-2024, drawing on diverse literature on technological change and labour market signalling. Our findings provide evidence that employers have initiated \"skill-based hiring\" for AI roles, adopting more flexible hiring practices to expand the available talent pool. From 2018-2023, demand for AI roles grew by 21% as a proportion of all postings (and accelerated into 2024). Simultaneously, mentions of university education requirements for AI roles declined by 15%. Our regression analysis shows that university degrees have a significantly lower wage premium for both AI and green roles. In contrast, AI skills command a wage premium of 23%, exceeding the value of degrees up until the PhD-level (33%). In occupations with high demand for AI skills, the premium for skills is high, and the reward for degrees is relatively low. We recommend leveraging alternative skill-building formats such as apprenticeships, on-the-job training, MOOCs, vocational education and training, micro-certificates, and online bootcamps to fully utilise human capital and address talent shortages.", "published": "2024-11-07 05:00:00", "id": "dfc80eff-c8ea-46ea-aea4-1e38da07065d", "source": "arxiv", "section": "computerScience"}, {"title": "Data needs and challenges for quantum dot devices automation", "link": "https://arxiv.org/abs/2312.14322", "description": "arXiv:2312.14322v3 Announce Type: replace-cross \nAbstract: Gate-defined quantum dots are a promising candidate system for realizing scalable, coupled qubit systems and serving as a fundamental building block for quantum computers. However, present-day quantum dot devices suffer from imperfections that must be accounted for, which hinders the characterization, tuning, and operation process. Moreover, with an increasing number of quantum dot qubits, the relevant parameter space grows sufficiently to make heuristic control infeasible. Thus, it is imperative that reliable and scalable autonomous tuning approaches are developed. This meeting report outlines current challenges in automating quantum dot device tuning and operation with a particular focus on datasets, benchmarking, and standardization. We also present insights and ideas put forward by the quantum dot community on how to overcome them. We aim to provide guidance and inspiration to researchers invested in automation efforts.", "published": "2024-11-07 05:00:00", "id": "e71e7821-64c6-4af9-a61f-6878e126fbf8", "source": "arxiv", "section": "computerScience"}, {"title": "Nonparametric Evaluation of Noisy ICA Solutions", "link": "https://arxiv.org/abs/2401.08468", "description": "arXiv:2401.08468v3 Announce Type: replace-cross \nAbstract: Independent Component Analysis (ICA) was introduced in the 1980's as a model for Blind Source Separation (BSS), which refers to the process of recovering the sources underlying a mixture of signals, with little knowledge about the source signals or the mixing process. While there are many sophisticated algorithms for estimation, different methods have different shortcomings. In this paper, we develop a nonparametric score to adaptively pick the right algorithm for ICA with arbitrary Gaussian noise. The novelty of this score stems from the fact that it just assumes a finite second moment of the data and uses the characteristic function to evaluate the quality of the estimated mixing matrix without any knowledge of the parameters of the noise distribution. In addition, we propose some new contrast functions and algorithms that enjoy the same fast computability as existing algorithms like FASTICA and JADE but work in domains where the former may fail. While these also may have weaknesses, our proposed diagnostic, as shown by our simulations, can remedy them. Finally, we propose a theoretical framework to analyze the local and global convergence properties of our algorithms.", "published": "2024-11-07 05:00:00", "id": "77c5ae62-1b4c-4626-8e6f-e0282b22a56f", "source": "arxiv", "section": "computerScience"}, {"title": "Stochastic Weakly Convex Optimization Beyond Lipschitz Continuity", "link": "https://arxiv.org/abs/2401.13971", "description": "arXiv:2401.13971v2 Announce Type: replace-cross \nAbstract: This paper considers stochastic weakly convex optimization without the standard Lipschitz continuity assumption. Based on new adaptive regularization (stepsize) strategies, we show that a wide class of stochastic algorithms, including the stochastic subgradient method, preserve the $\\mathcal{O} ( 1 / \\sqrt{K})$ convergence rate with constant failure rate. Our analyses rest on rather weak assumptions: the Lipschitz parameter can be either bounded by a general growth function of $\\|x\\|$ or locally estimated through independent random samples.", "published": "2024-11-07 05:00:00", "id": "22c6ce0c-7a1e-47a8-b3c8-c78e9964bfd4", "source": "arxiv", "section": "computerScience"}, {"title": "Ensemble-Based Annealed Importance Sampling", "link": "https://arxiv.org/abs/2401.15645", "description": "arXiv:2401.15645v2 Announce Type: replace-cross \nAbstract: Sampling from a multimodal distribution is a fundamental and challenging problem in computational science and statistics. Among various approaches proposed for this task, one popular method is Annealed Importance Sampling (AIS). In this paper, we propose an ensemble-based version of AIS by combining it with population-based Monte Carlo methods to improve its efficiency. By keeping track of an ensemble instead of a single particle along some continuation path between the starting distribution and the target distribution, we take advantage of the interaction within the ensemble to encourage the exploration of undiscovered modes. Specifically, our main idea is to utilize either the snooker algorithm or the genetic algorithm used in Evolutionary Monte Carlo. We discuss how the proposed algorithm can be implemented and derive a partial differential equation governing the evolution of the ensemble under the continuous time and mean-field limit. We also test the efficiency of the proposed algorithm on various continuous and discrete distributions.", "published": "2024-11-07 05:00:00", "id": "cf18fbb8-726b-4858-9df4-9f94bbb10976", "source": "arxiv", "section": "computerScience"}, {"title": "Parameter uncertainties for imperfect surrogate models in the low-noise regime", "link": "https://arxiv.org/abs/2402.01810", "description": "arXiv:2402.01810v5 Announce Type: replace-cross \nAbstract: Bayesian regression determines model parameters by minimizing the expected loss, an upper bound to the true generalization error. However, the loss ignores misspecification, where models are imperfect. Parameter uncertainties from Bayesian regression are thus significantly underestimated and vanish in the large data limit. This is particularly problematic when building models of low-noise, or near-deterministic, calculations, as the main source of uncertainty is neglected. We analyze the generalization error of misspecified, near-deterministic surrogate models, a regime of broad relevance in science and engineering. We show posterior distributions must cover every training point to avoid a divergent generalization error and design an ansatz that respects this constraint, which for linear models incurs minimal overhead. This is demonstrated on model problems before application to thousand dimensional datasets in atomistic machine learning. Our efficient misspecification-aware scheme gives accurate prediction and bounding of test errors where existing schemes fail, allowing this important source of uncertainty to be incorporated in computational workflows.", "published": "2024-11-07 05:00:00", "id": "4a2a8c4f-e006-4c25-9e09-a411706d078a", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient Numerical Wave Propagation Enhanced By An End-to-End Deep Learning Model", "link": "https://arxiv.org/abs/2402.02304", "description": "arXiv:2402.02304v5 Announce Type: replace-cross \nAbstract: In a variety of scientific and engineering domains, the need for high-fidelity and efficient solutions for high-frequency wave propagation holds great significance. Recent advances in wave modeling use sufficiently accurate fine solver outputs to train a neural network that enhances the accuracy of a fast but inaccurate coarse solver. In this paper we build upon the work of Nguyen and Tsai (2023) and present a novel unified system that integrates a numerical solver with a deep learning component into an end-to-end framework. In the proposed setting, we investigate refinements to the network architecture and data generation algorithm. A stable and fast solver further allows the use of Parareal, a parallel-in-time algorithm to correct high-frequency wave components. Our results show that the cohesive structure improves performance without sacrificing speed, and demonstrate the importance of temporal dynamics, as well as Parareal, for accurate wave propagation.", "published": "2024-11-07 05:00:00", "id": "f940a78f-faab-4bac-a3b0-e78bb605f16c", "source": "arxiv", "section": "computerScience"}, {"title": "Oja's Algorithm for Streaming Sparse PCA", "link": "https://arxiv.org/abs/2402.07240", "description": "arXiv:2402.07240v4 Announce Type: replace-cross \nAbstract: Oja's algorithm for Streaming Principal Component Analysis (PCA) for $n$ data-points in a $d$ dimensional space achieves the same sin-squared error $O(r_{\\mathsf{eff}}/n)$ as the offline algorithm in $O(d)$ space and $O(nd)$ time and a single pass through the datapoints. Here $r_{\\mathsf{eff}}$ is the effective rank (ratio of the trace and the principal eigenvalue of the population covariance matrix $\\Sigma$). Under this computational budget, we consider the problem of sparse PCA, where the principal eigenvector of $\\Sigma$ is $s$-sparse, and $r_{\\mathsf{eff}}$ can be large. In this setting, to our knowledge, \\textit{there are no known single-pass algorithms} that achieve the minimax error bound in $O(d)$ space and $O(nd)$ time without either requiring strong initialization conditions or assuming further structure (e.g., spiked) of the covariance matrix. We show that a simple single-pass procedure that thresholds the output of Oja's algorithm (the Oja vector) can achieve the minimax error bound under some regularity conditions in $O(d)$ space and $O(nd)$ time. We present a nontrivial and novel analysis of the entries of the unnormalized Oja vector, which involves the projection of a product of independent random matrices on a random initial vector. This is completely different from previous analyses of Oja's algorithm and matrix products, which have been done when the $r_{\\mathsf{eff}}$ is bounded.", "published": "2024-11-07 05:00:00", "id": "ef1c4f92-b71f-4b83-b788-d6fbccfa6c4b", "source": "arxiv", "section": "computerScience"}, {"title": "A Learnable Prior Improves Inverse Tumor Growth Modeling", "link": "https://arxiv.org/abs/2403.04500", "description": "arXiv:2403.04500v2 Announce Type: replace-cross \nAbstract: Biophysical modeling, particularly involving partial differential equations (PDEs), offers significant potential for tailoring disease treatment protocols to individual patients. However, the inverse problem-solving aspect of these models presents a substantial challenge, either due to the high computational requirements of model-based approaches or the limited robustness of deep learning (DL) methods. We propose a novel framework that leverages the unique strengths of both approaches in a synergistic manner. Our method incorporates a DL ensemble for initial parameter estimation, facilitating efficient downstream evolutionary sampling initialized with this DL-based prior. We showcase the effectiveness of integrating a rapid deep-learning algorithm with a high-precision evolution strategy in estimating brain tumor cell concentrations from magnetic resonance images. The DL-Prior plays a pivotal role, significantly constraining the effective sampling-parameter space. This reduction results in a fivefold convergence acceleration and a Dice-score of 95%.", "published": "2024-11-07 05:00:00", "id": "925811a8-c536-4705-97fd-0c330b49d002", "source": "arxiv", "section": "computerScience"}, {"title": "Ab-initio variational wave functions for the time-dependent many-electron Schr\\\"odinger equation", "link": "https://arxiv.org/abs/2403.07447", "description": "arXiv:2403.07447v3 Announce Type: replace-cross \nAbstract: Understanding the real-time evolution of many-electron quantum systems is essential for studying dynamical properties in condensed matter, quantum chemistry, and complex materials, yet it poses a significant theoretical and computational challenge. Our work introduces a variational approach for fermionic time-dependent wave functions, surpassing mean-field approximations by accurately capturing many-body correlations. Therefore, we employ time-dependent Jastrow factors and backflow transformations, which are enhanced through neural networks parameterizations. To compute the optimal time-dependent parameters, we utilize the time-dependent variational Monte Carlo technique and a new method based on Taylor-root expansions of the propagator, enhancing the accuracy of our simulations. The approach is demonstrated in three distinct systems. In all cases, we show clear signatures of many-body correlations in the dynamics. The results showcase the ability of our variational approach to accurately capture the time evolution, providing insight into the quantum dynamics of interacting electronic systems, beyond the capabilities of mean-field.", "published": "2024-11-07 05:00:00", "id": "eb67ca47-9bc0-4c87-a4fa-43b36e8da7b2", "source": "arxiv", "section": "computerScience"}, {"title": "A First-Order Gradient Approach for the Connectivity Analysis of Markov Chains", "link": "https://arxiv.org/abs/2403.11744", "description": "arXiv:2403.11744v2 Announce Type: replace-cross \nAbstract: Weighted graphs are commonly used to model various complex systems, including social networks, power grids, transportation networks, and biological systems. In many applications, the connectivity of these networks can be expressed through the Mean First Passage Times (MFPTs) of a Markov chain modeling a random walker on the graph. In this paper, we generalize the network metrics based on Markov chains' MFPTs and extend them to networks affected by uncertainty, in which edges may fail and hence not be present according to a pre-determined stochastic model. To find optimally connected Markov chains, we present a parameterization-free method for optimizing the MFPTs of the Markov chain. More specifically, we present an efficient Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm in the context of Markov chain optimization. The proposed algorithm is suitable for both fixed and random networks. Using various numerical experiments, we demonstrate scalability compared to established benchmarks. Importantly, our algorithm finds an optimal solution without requiring prior knowledge of edge failure probabilities, allowing for an online optimization approach.", "published": "2024-11-07 05:00:00", "id": "dd995db4-c70e-4816-9941-b3fe6fc00a2a", "source": "arxiv", "section": "computerScience"}, {"title": "Detecting critical treatment effect bias in small subgroups", "link": "https://arxiv.org/abs/2404.18905", "description": "arXiv:2404.18905v2 Announce Type: replace-cross \nAbstract: Randomized trials are considered the gold standard for making informed decisions in medicine, yet they often lack generalizability to the patient populations in clinical practice. Observational studies, on the other hand, cover a broader patient population but are prone to various biases. Thus, before using an observational study for decision-making, it is crucial to benchmark its treatment effect estimates against those derived from a randomized trial. We propose a novel strategy to benchmark observational studies beyond the average treatment effect. First, we design a statistical test for the null hypothesis that the treatment effects estimated from the two studies, conditioned on a set of relevant features, differ up to some tolerance. We then estimate an asymptotically valid lower bound on the maximum bias strength for any subgroup in the observational study. Finally, we validate our benchmarking strategy in a real-world setting and show that it leads to conclusions that align with established medical knowledge.", "published": "2024-11-07 05:00:00", "id": "3c702ef0-e51e-4d32-bf8a-e0ad5827e514", "source": "arxiv", "section": "computerScience"}, {"title": "Discrete Aware Matrix Completion via Convexized $\\ell_0$-Norm Approximation", "link": "https://arxiv.org/abs/2405.02101", "description": "arXiv:2405.02101v2 Announce Type: replace-cross \nAbstract: We consider a novel algorithm, for the completion of partially observed low-rank matrices in a structured setting where each entry can be chosen from a finite discrete alphabet set, such as in common recommender systems. The proposed low-rank matrix completion (MC) method is an improved variation of state-of-the-art (SotA) discrete aware matrix completion method which we previously proposed, in which discreteness is enforced by an $\\ell_0$-norm regularizer, not by replaced with the $\\ell_1$-norm, but instead approximated by a continuous and differentiable function normalized via fractional programming (FP) under a proximal gradient (PG) framework. Simulation results demonstrate the superior performance of the new method compared to the SotA techniques as well as the earlier $\\ell_1$-norm-based discrete-aware matrix completion approach.", "published": "2024-11-07 05:00:00", "id": "1557e475-9a3c-46da-bbf9-65aa01cd48fd", "source": "arxiv", "section": "computerScience"}, {"title": "Multimodal Super-Resolution: Discovering hidden physics and its application to fusion plasmas", "link": "https://arxiv.org/abs/2405.05908", "description": "arXiv:2405.05908v4 Announce Type: replace-cross \nAbstract: A non-linear system governed by multi-spatial and multi-temporal physics scales cannot be fully understood with a single diagnostic, as each provides only a partial view, leading to information loss. Combining multiple diagnostics may also result in incomplete projections of the system's physics. By identifying hidden inter-correlations between diagnostics, we can leverage mutual support to fill in these gaps, but uncovering such correlations analytically is too complex. We introduce a machine learning methodology to address this issue. Unlike traditional methods, our multimodal approach does not rely on the target diagnostic's direct measurements to generate its super-resolution version. Instead, it uses other diagnostics to produce super-resolution data, capturing detailed structural evolution and responses to perturbations previously unobservable. This not only enhances the resolution of a diagnostic for deeper insights but also reconstructs the target diagnostic, providing a valuable tool to mitigate diagnostic failure. This methodology addresses a key challenge in fusion plasmas: the Edge Localized Mode (ELM), a plasma instability that can cause significant erosion of plasma-facing materials. A method to stabilize ELM is using resonant magnetic perturbation (RMP) to trigger magnetic islands. However, limited spatial and temporal resolution restricts analysis of these islands due to their small size, rapid dynamics, and complex plasma interactions. With super-resolution diagnostics, we can experimentally verify theoretical models of magnetic islands for the first time, providing insights into their role in ELM stabilization. This advancement supports the development of effective ELM suppression strategies for future fusion reactors like ITER and has broader applications, potentially revolutionizing diagnostics in fields such as astronomy, astrophysics, and medical imaging.", "published": "2024-11-07 05:00:00", "id": "35218c27-558d-48e2-9f05-cfbf553a8672", "source": "arxiv", "section": "computerScience"}, {"title": "Root Cause Analysis of Outliers with Missing Structural Knowledge", "link": "https://arxiv.org/abs/2406.05014", "description": "arXiv:2406.05014v2 Announce Type: replace-cross \nAbstract: Recent work conceptualized root cause analysis (RCA) of anomalies via quantitative contribution analysis using causal counterfactuals in structural causal models (SCMs).The framework comes with three practical challenges: (1) it requires the causal directed acyclic graph (DAG), together with an SCM, (2) it is statistically ill-posed since it probes regression models in regions of low probability density, (3) it relies on Shapley values which are computationally expensive to find.\n  In this paper, we propose simplified, efficient methods of root cause analysis when the task is to identify a unique root cause instead of quantitative contribution analysis. Our proposed methods run in linear order of SCM nodes and they require only the causal DAG without counterfactuals. Furthermore, for those use cases where the causal DAG is unknown, we justify the heuristic of identifying root causes as the variables with the highest anomaly score. To this end, we prove that anomalies with small scores are unlikely to cause those with large scores and show upper bounds for the likelihood of causal pathways with non-monotonic anomaly scores.", "published": "2024-11-07 05:00:00", "id": "abed93c2-55fe-44ae-bfe9-07e32473a76e", "source": "arxiv", "section": "computerScience"}, {"title": "Computing congruences of finite inverse semigroups", "link": "https://arxiv.org/abs/2406.09281", "description": "arXiv:2406.09281v2 Announce Type: replace-cross \nAbstract: In this paper we present a novel algorithm for computing a congruence on an inverse semigroup from a collection of generating pairs. This algorithm uses a myriad of techniques from computational group theory, automata, and the theory of inverse semigroups. An initial implementation of this algorithm outperforms existing implementations by several orders of magnitude.", "published": "2024-11-07 05:00:00", "id": "2921370a-4102-4c9c-9c19-4026b7b7e10e", "source": "arxiv", "section": "computerScience"}, {"title": "Communication-Efficient Adaptive Batch Size Strategies for Distributed Local Gradient Methods", "link": "https://arxiv.org/abs/2406.13936", "description": "arXiv:2406.13936v2 Announce Type: replace-cross \nAbstract: Modern deep neural networks often require distributed training with many workers due to their large size. As the number of workers increases, communication overheads become the main bottleneck in data-parallel minibatch stochastic gradient methods with per-iteration gradient synchronization. Local gradient methods like Local SGD reduce communication by only synchronizing model parameters and/or gradients after several local steps. Despite an understanding of their convergence and the importance of batch sizes for training efficiency and generalization, optimal batch sizes for local gradient methods are difficult to determine. We introduce adaptive batch size strategies for local gradient methods that increase batch sizes adaptively to reduce minibatch gradient variance. We provide convergence guarantees under homogeneous data conditions and support our claims with image classification and language modeling experiments, demonstrating the effectiveness of our strategies for both training efficiency and generalization.", "published": "2024-11-07 05:00:00", "id": "b4b8f37d-686f-4ca5-a687-e6fbb439e25c", "source": "arxiv", "section": "computerScience"}, {"title": "Universal Sound Separation with Self-Supervised Audio Masked Autoencoder", "link": "https://arxiv.org/abs/2407.11745", "description": "arXiv:2407.11745v2 Announce Type: replace-cross \nAbstract: Universal sound separation (USS) is a task of separating mixtures of arbitrary sound sources. Typically, universal separation models are trained from scratch in a supervised manner, using labeled data. Self-supervised learning (SSL) is an emerging deep learning approach that leverages unlabeled data to obtain task-agnostic representations, which can benefit many downstream tasks. In this paper, we propose integrating a self-supervised pre-trained model, namely the audio masked autoencoder (A-MAE), into a universal sound separation system to enhance its separation performance. We employ two strategies to utilize SSL embeddings: freezing or updating the parameters of A-MAE during fine-tuning. The SSL embeddings are concatenated with the short-time Fourier transform (STFT) to serve as input features for the separation model. We evaluate our methods on the AudioSet dataset, and the experimental results indicate that the proposed methods successfully enhance the separation performance of a state-of-the-art ResUNet-based USS model.", "published": "2024-11-07 05:00:00", "id": "d07b8a22-31f4-46f8-b447-7f3a61feeba1", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Verifying Exact Conditions for Implementations of Density Functional Approximations", "link": "https://arxiv.org/abs/2408.05316", "description": "arXiv:2408.05316v4 Announce Type: replace-cross \nAbstract: Density Functional Theory (DFT) is used extensively in the computation of electronic properties of matter, with various applications. Approximating the exchange-correlation (XC) functional is the key to the Kohn-Sham DFT approach, the basis of most DFT calculations. The choice of this density functional approximation (DFA) depends crucially on the particular system under study, which has resulted in the development of hundreds of DFAs. Though the exact density functional is not known, researchers have discovered analytical properties of this exact functional. Furthermore, these exact conditions are used when designing DFAs. We present XCVerifier, the first approach for verifying whether a DFA implementation satisfies the DFT exact conditions. XCVerifier was evaluated on five DFAs from the popular Libxc library and seven exact conditions from recent work. XCVerifier was able to verify or find violations for a majority of the DFA/condition pairs, demonstrating the feasibility of using formal methods to verify DFA implementations.", "published": "2024-11-07 05:00:00", "id": "67c397f8-9a71-4dd4-b803-7d2c30f5927b", "source": "arxiv", "section": "computerScience"}, {"title": "Anatomical Foundation Models for Brain MRIs", "link": "https://arxiv.org/abs/2408.07079", "description": "arXiv:2408.07079v2 Announce Type: replace-cross \nAbstract: Deep Learning (DL) in neuroimaging has become increasingly relevant for detecting neurological conditions and neurodegenerative disorders. One of the most predominant biomarkers in neuroimaging is represented by brain age, which has been shown to be a good indicator for different conditions, such as Alzheimer's Disease. Using brain age for pretraining DL models in transfer learning settings has also recently shown promising results, especially when dealing with data scarcity of different conditions. On the other hand, anatomical information of brain MRIs (e.g. cortical thickness) can provide important information for learning good representations that can be transferred to many downstream tasks. In this work, we propose AnatCL, an anatomical foundation model for brain MRIs that i.) leverages anatomical information with a weakly contrastive learning approach and ii.) achieves state-of-the-art performances in many different downstream tasks. To validate our approach we consider 12 different downstream tasks for diagnosis classification, and prediction of 10 different clinical assessment scores. Pretrained models can be found at https://github.com/EIDOSLAB/AnatCL.", "published": "2024-11-07 05:00:00", "id": "0a13149f-4ea0-4069-9b73-6dc98db3fcb0", "source": "arxiv", "section": "computerScience"}, {"title": "BCDNet: A Fast Residual Neural Network For Invasive Ductal Carcinoma Detection", "link": "https://arxiv.org/abs/2408.13800", "description": "arXiv:2408.13800v3 Announce Type: replace-cross \nAbstract: It is of great significance to diagnose Invasive Ductal Carcinoma (IDC) in early stage, which is the most common subtype of breast cancer. Although the powerful models in the Computer-Aided Diagnosis (CAD) systems provide promising results, it is still difficult to integrate them into other medical devices or use them without sufficient computation resource. In this paper, we propose BCDNet, which firstly upsamples the input image by the residual block and use smaller convolutional block and a special MLP to learn features. BCDNet is proofed to effectively detect IDC in histopathological RGB images with an average accuracy of 91.6% and reduce training consumption effectively compared to ResNet 50 and ViT-B-16.", "published": "2024-11-07 05:00:00", "id": "e357a321-45eb-409b-8acb-67a9c901034f", "source": "arxiv", "section": "computerScience"}, {"title": "Using Deep Learning to Design High Aspect Ratio Fusion Devices", "link": "https://arxiv.org/abs/2409.00564", "description": "arXiv:2409.00564v2 Announce Type: replace-cross \nAbstract: The design of fusion devices is typically based on computationally expensive simulations. This can be alleviated using high aspect ratio models that employ a reduced number of free parameters, especially in the case of stellarator optimization where non-axisymmetric magnetic fields with a large parameter space are optimized to satisfy certain performance criteria. However, optimization is still required to find configurations with properties such as low elongation, high rotational transform, finite plasma beta, and good fast particle confinement. In this work, we train a machine learning model to construct configurations with favorable confinement properties by finding a solution to the inverse design problem, that is, obtaining a set of model input parameters for given desired properties. Since the solution of the inverse problem is non-unique, a probabilistic approach, based on mixture density networks, is used. It is shown that optimized configurations can be generated reliably using this method.", "published": "2024-11-07 05:00:00", "id": "7bf0926f-d377-421f-9c8a-ed69ee9ac956", "source": "arxiv", "section": "computerScience"}, {"title": "Reassessing Noise Augmentation Methods in the Context of Adversarial Speech", "link": "https://arxiv.org/abs/2409.01813", "description": "arXiv:2409.01813v3 Announce Type: replace-cross \nAbstract: In this study, we investigate if noise-augmented training can concurrently improve adversarial robustness in automatic speech recognition (ASR) systems. We conduct a comparative analysis of the adversarial robustness of four different state-of-the-art ASR architectures, where each of the ASR architectures is trained under three different augmentation conditions: one subject to background noise, speed variations, and reverberations, another subject to speed variations only, and a third without any form of data augmentation. The results demonstrate that noise augmentation not only improves model performance on noisy speech but also the model's robustness to adversarial attacks.", "published": "2024-11-07 05:00:00", "id": "c73f6df1-f0f8-418f-8bd9-e020db7d80f6", "source": "arxiv", "section": "computerScience"}, {"title": "Cartan moving frames and the data manifolds", "link": "https://arxiv.org/abs/2409.12057", "description": "arXiv:2409.12057v2 Announce Type: replace-cross \nAbstract: The purpose of this paper is to employ the language of Cartan moving frames to study the geometry of the data manifolds and its Riemannian structure, via the data information metric and its curvature at data points. Using this framework and through experiments, explanations on the response of a neural network are given by pointing out the output classes that are easily reachable from a given input. This emphasizes how the proposed mathematical relationship between the output of the network and the geometry of its inputs can be exploited as an explainable artificial intelligence tool.", "published": "2024-11-07 05:00:00", "id": "255adf11-dc50-4a94-a3af-4ed3f2d15887", "source": "arxiv", "section": "computerScience"}, {"title": "Generalized Logistic Maps and Convergence", "link": "https://arxiv.org/abs/2409.15175", "description": "arXiv:2409.15175v3 Announce Type: replace-cross \nAbstract: We treat three cubic recurrences, two of which generalize the famous iterated map $x \\mapsto x (1-x)$ from discrete chaos theory. A feature of each asymptotic series developed here is a constant, dependent on the initial condition but otherwise intrinsic to the function at hand.", "published": "2024-11-07 05:00:00", "id": "1f28c590-bb56-48cf-b366-49e08f87dcfc", "source": "arxiv", "section": "computerScience"}, {"title": "The Bouc-Wen Model for Binary Direct Collinear Collisions of Convex Viscoplastic Bodies", "link": "https://arxiv.org/abs/2410.08147", "description": "arXiv:2410.08147v4 Announce Type: replace-cross \nAbstract: We study mathematical models of binary direct collinear collisions of convex viscoplastic bodies based on two incremental collision laws that employ the Bouc-Wen differential model of hysteresis to represent the elastoplastic behavior of the materials of the colliding bodies. These collision laws are the Bouc-Wen-Simon-Hunt-Crossley collision law (BWSHCCL) and the Bouc-Wen-Maxwell collision law (BWMCL). The BWSHCCL comprises of the Bouc-Wen model amended with a nonlinear Hertzian elastic spring element and connected in parallel to a nonlinear displacement-dependent and velocity-dependent energy dissipation element. The BWMCL comprises of the Bouc-Wen model amended with a nonlinear Hertzian elastic spring element and connected in series to a linear velocity-dependent energy dissipation element. The mathematical models of the collision process are presented in the form of finite-dimensional initial value problems. We show that the models possess favorable analytical properties (e.g., global existence, uniqueness, and boundedness of the solutions) under suitable restrictions on the values of their parameters. Furthermore, we show that excellent agreement can be achieved between experimental data and numerical approximations of the behavior of the mathematical models across a wide range of initial relative velocities of the colliding bodies while using parameterizations of the models that are independent of the initial relative velocity.", "published": "2024-11-07 05:00:00", "id": "2bfa8df2-7a54-4d71-8acc-851ecfe0a061", "source": "arxiv", "section": "computerScience"}, {"title": "The Effects of Multi-Task Learning on ReLU Neural Network Functions", "link": "https://arxiv.org/abs/2410.21696", "description": "arXiv:2410.21696v2 Announce Type: replace-cross \nAbstract: This paper studies the properties of solutions to multi-task shallow ReLU neural network learning problems, wherein the network is trained to fit a dataset with minimal sum of squared weights. Remarkably, the solutions learned for each individual task resemble those obtained by solving a kernel method, revealing a novel connection between neural networks and kernel methods. It is known that single-task neural network training problems are equivalent to minimum norm interpolation problem in a non-Hilbertian Banach space, and that the solutions of such problems are generally non-unique. In contrast, we prove that the solutions to univariate-input, multi-task neural network interpolation problems are almost always unique, and coincide with the solution to a minimum-norm interpolation problem in a Sobolev (Reproducing Kernel) Hilbert Space. We also demonstrate a similar phenomenon in the multivariate-input case; specifically, we show that neural network learning problems with large numbers of diverse tasks are approximately equivalent to an $\\ell^2$ (Hilbert space) minimization problem over a fixed kernel determined by the optimal neurons.", "published": "2024-11-07 05:00:00", "id": "24463802-8601-4845-a5c7-0e8ea9a797ad", "source": "arxiv", "section": "computerScience"}, {"title": "bit2bit: 1-bit quanta video reconstruction via self-supervised photon prediction", "link": "https://arxiv.org/abs/2410.23247", "description": "arXiv:2410.23247v2 Announce Type: replace-cross \nAbstract: Quanta image sensors, such as SPAD arrays, are an emerging sensor technology, producing 1-bit arrays representing photon detection events over exposures as short as a few nanoseconds. In practice, raw data are post-processed using heavy spatiotemporal binning to create more useful and interpretable images at the cost of degrading spatiotemporal resolution. In this work, we propose bit2bit, a new method for reconstructing high-quality image stacks at the original spatiotemporal resolution from sparse binary quanta image data. Inspired by recent work on Poisson denoising, we developed an algorithm that creates a dense image sequence from sparse binary photon data by predicting the photon arrival location probability distribution. However, due to the binary nature of the data, we show that the assumption of a Poisson distribution is inadequate. Instead, we model the process with a Bernoulli lattice process from the truncated Poisson. This leads to the proposal of a novel self-supervised solution based on a masked loss function. We evaluate our method using both simulated and real data. On simulated data from a conventional video, we achieve 34.35 mean PSNR with extremely photon-sparse binary input (<0.06 photons per pixel per frame). We also present a novel dataset containing a wide range of real SPAD high-speed videos under various challenging imaging conditions. The scenes cover strong/weak ambient light, strong motion, ultra-fast events, etc., which will be made available to the community, on which we demonstrate the promise of our approach. Both reconstruction quality and throughput substantially surpass the state-of-the-art methods (e.g., Quanta Burst Photography (QBP)). Our approach significantly enhances the visualization and usability of the data, enabling the application of existing analysis techniques.", "published": "2024-11-07 05:00:00", "id": "7938cccd-dc42-444d-a812-b32a2b50192b", "source": "arxiv", "section": "computerScience"}, {"title": "Gradient Methods with Online Scaling", "link": "https://arxiv.org/abs/2411.01803", "description": "arXiv:2411.01803v2 Announce Type: replace-cross \nAbstract: We introduce a framework to accelerate the convergence of gradient-based methods with online learning. The framework learns to scale the gradient at each iteration through an online learning algorithm and provably accelerates gradient-based methods asymptotically. In contrast with previous literature, where convergence is established based on worst-case analysis, our framework provides a strong convergence guarantee with respect to the optimal scaling matrix for the iteration trajectory. For smooth strongly convex optimization, our results provide an $O(\\kappa^\\star \\log(1/\\varepsilon)$) complexity result, where $\\kappa^\\star$ is the condition number achievable by the optimal preconditioner, improving on the previous $O(\\sqrt{n}\\kappa^\\star \\log(1/\\varepsilon))$ result. In particular, a variant of our method achieves superlinear convergence on convex quadratics. For smooth convex optimization, we show for the first time that the widely-used hypergradient descent heuristic improves on the convergence of gradient descent.", "published": "2024-11-07 05:00:00", "id": "0987c6cb-f84e-4364-9cce-6559a6d2f4a7", "source": "arxiv", "section": "computerScience"}, {"title": "Practical, optimal preparation of general quantum state with exponentially improved robustness", "link": "https://arxiv.org/abs/2411.02782", "description": "arXiv:2411.02782v2 Announce Type: replace-cross \nAbstract: Quantum state preparation, as a general process of loading classical data to quantum device, is essential for end-to-end implementation of quantum algorithms. Yet, existing methods suffer from either high circuit depth or complicated hardware, limiting their practicality and robustness. In this work, we overcome these limitations with a bucket-brigade approach. The tree architectures of our hardware represents the simplest connectivity required for achieving sub-exponential circuit depth. Leveraging the bucket-brigade mechanism that can suppress the error propagation between different branches, our approach exhibit exponential improvement on the robustness compared to existing depth-optimal methods. More specifically, the infidelity scales as $O(\\text{polylog}(N))$ with data size $N$, as oppose to $O(N)$ for conventional methods. Moreover, our approach is the first to simultaneously achieve linear Clifford$+T$ circuit depth, gate count number, and space-time allocation. These advancements offer the opportunity for processing big data in both near-term and fault-tolerant quantum devices.", "published": "2024-11-07 05:00:00", "id": "3383388f-8e2e-400f-a341-a043a56e8a0e", "source": "arxiv", "section": "computerScience"}, {"title": "Gradient Descent Finds Over-Parameterized Neural Networks with Sharp Generalization for Nonparametric Regression: A Distribution-Free Analysis", "link": "https://arxiv.org/abs/2411.02904", "description": "arXiv:2411.02904v2 Announce Type: replace-cross \nAbstract: We study nonparametric regression by an over-parameterized two-layer neural network trained by gradient descent (GD) in this paper. We show that, if the neural network is trained by GD with early stopping, then the trained network renders a sharp rate of the nonparametric regression risk of $\\cO(\\eps_n^2)$, which is the same rate as that for the classical kernel regression trained by GD with early stopping, where $\\eps_n$ is the critical population rate of the Neural Tangent Kernel (NTK) associated with the network and $n$ is the size of the training data. It is remarked that our result does not require distributional assumptions on the training data, in a strong contrast with many existing results which rely on specific distributions such as the spherical uniform data distribution or distributions satisfying certain restrictive conditions. The rate $\\cO(\\eps_n^2)$ is known to be minimax optimal for specific cases, such as the case that the NTK has a polynomial eigenvalue decay rate which happens under certain distributional assumptions. Our result formally fills the gap between training a classical kernel regression model and training an over-parameterized but finite-width neural network by GD for nonparametric regression without distributional assumptions. We also provide confirmative answers to certain open questions or address particular concerns in the literature of training over-parameterized neural networks by GD with early stopping for nonparametric regression, including the characterization of the stopping time, the lower bound for the network width, and the constant learning rate used in GD.", "published": "2024-11-07 05:00:00", "id": "5855bf7b-008b-4a22-8795-ff33cdef7842", "source": "arxiv", "section": "computerScience"}, {"title": "FedFMS: Exploring Federated Foundation Models for Medical Image Segmentation", "link": "https://arxiv.org/abs/2403.05408", "description": "arXiv:2403.05408v2 Announce Type: replace-cross \nAbstract: Medical image segmentation is crucial for clinical diagnosis. The Segmentation Anything Model (SAM) serves as a powerful foundation model for visual segmentation and can be adapted for medical image segmentation. However, medical imaging data typically contain privacy-sensitive information, making it challenging to train foundation models with centralized storage and sharing. To date, there are few foundation models tailored for medical image deployment within the federated learning framework, and the segmentation performance, as well as the efficiency of communication and training, remain unexplored. In response to these issues, we developed Federated Foundation models for Medical image Segmentation (FedFMS), which includes the Federated SAM (FedSAM) and a communication and training-efficient Federated SAM with Medical SAM Adapter (FedMSA). Comprehensive experiments on diverse datasets are conducted to investigate the performance disparities between centralized training and federated learning across various configurations of FedFMS. The experiments revealed that FedFMS could achieve performance comparable to models trained via centralized training methods while maintaining privacy. Furthermore, FedMSA demonstrated the potential to enhance communication and training efficiency. Our model implementation codes are available at https://github.com/LIU-YUXI/FedFMS.", "published": "2024-11-07 05:00:00", "id": "dfc4ccd9-7c23-4f23-9af9-1f7efc0cd600", "source": "arxiv", "section": "computerScience"}, {"title": "美国大选马斯克下注1.19亿：不是真爱特朗普，而是真恨哈里斯", "link": "https://www.huxiu.com/article/3660166.html?f=rss", "description": "“川马”联盟，同床异梦", "published": "2024-11-07 07:54:12", "id": "4961b6b2-fcba-40c8-b73b-833d6b23dda2", "source": "虎嗅", "section": "默认"}, {"title": "川大智胜大胜哈尔斯", "link": "https://www.huxiu.com/article/3659265.html?f=rss", "description": "股市的投机特质被娱乐化地展现了出来", "published": "2024-11-07 04:18:08", "id": "c6872d44-3938-4dd1-bc4b-733739b67cf1", "source": "虎嗅", "section": "默认"}, {"title": "川普回宫，放在整个科技界都是很炸裂的", "link": "https://www.huxiu.com/article/3660163.html?f=rss", "description": "“风浪越大，鱼越贵”", "published": "2024-11-07 08:40:00", "id": "b5fe1f5b-bdfb-4b0f-987b-80b58acc8cc4", "source": "虎嗅", "section": "默认"}, {"title": "播客选择特朗普", "link": "https://www.huxiu.com/article/3659236.html?f=rss", "description": "媒体精英写什么，大家才能看什么的时代，彻彻底底过去了。", "published": "2024-11-07 03:22:26", "id": "a392902d-4d40-4b9c-a650-64e5d6738c24", "source": "虎嗅", "section": "默认"}, {"title": "巨力集团vs黄圣依，谁才是杨子的真稻草？", "link": "https://www.huxiu.com/article/3658772.html?f=rss", "description": "豪门阔太变一线员工？扒开扬子背后的“商业”版图", "published": "2024-11-07 02:34:57", "id": "b969b045-f9ef-4b8b-bde9-b21339c84a45", "source": "虎嗅", "section": "默认"}, {"title": "米其林计划关闭两座工厂，欧洲汽车工业面临转型难题", "link": "https://www.huxiu.com/article/3657555.html?f=rss", "description": "欧洲工厂的关停潮还将继续？", "published": "2024-11-07 03:51:14", "id": "38d334ed-2a36-40e5-b612-224a0aff84aa", "source": "虎嗅", "section": "默认"}, {"title": "特朗普杀死ESG？", "link": "https://www.huxiu.com/article/3659229.html?f=rss", "description": "中国新能源产业，更难了？", "published": "2024-11-07 09:43:12", "id": "85efd260-9c47-4a0c-bcf9-5d475576e657", "source": "虎嗅", "section": "默认"}, {"title": "中层领导拿捏打工人的职场幸福感？", "link": "https://www.huxiu.com/article/3655850.html?f=rss", "description": "想要马儿快跑就不能心疼“好饲料”。", "published": "2024-11-07 03:00:00", "id": "8a2c66cf-8d20-4dae-92d3-32565a7a63af", "source": "虎嗅", "section": "默认"}, {"title": "“这个女的竟然会踢球”", "link": "https://www.huxiu.com/article/3660354.html?f=rss", "description": "", "published": "2024-11-07 08:07:00", "id": "f2f72266-221a-432d-8fdf-cc94e0d45456", "source": "虎嗅", "section": "默认"}, {"title": "熬过漫长的规培期，护士想去看心理医生", "link": "https://www.huxiu.com/article/3659246.html?f=rss", "description": "拿三位数的工资，熬夜干苦力", "published": "2024-11-07 06:15:29", "id": "da0c88b1-f399-4b03-b3d2-68b94db4a5b7", "source": "虎嗅", "section": "默认"}, {"title": "被嫌弃的海马体，老了", "link": "https://www.huxiu.com/article/3659237.html?f=rss", "description": "海马体想要回归初心，但时代未必还会给它机会。", "published": "2024-11-07 03:33:09", "id": "90964a2e-d83c-4c51-8f79-1cb7b227a529", "source": "虎嗅", "section": "默认"}, {"title": "在硅谷的秋天，中国大模型小老虎们流水般涌来", "link": "https://www.huxiu.com/article/3659209.html?f=rss", "description": "AI出海时代已经拉开帷幕", "published": "2024-11-07 04:00:05", "id": "68f80145-2282-4454-9297-29b25dd080cf", "source": "虎嗅", "section": "默认"}, {"title": "比美国大选还会花钱，举办16年的双十一彻底变了", "link": "https://www.huxiu.com/article/3659269.html?f=rss", "description": "双十一的四个变化", "published": "2024-11-07 07:10:23", "id": "437c3fb4-3480-41da-8561-5c749cda8621", "source": "虎嗅", "section": "默认"}, {"title": "百度两位副总裁双双离职，核心事业群持续调整管理层", "link": "https://www.huxiu.com/article/3660365.html?f=rss", "description": "百度对内部管理团队的调整仍未结束", "published": "2024-11-07 09:09:43", "id": "0f82ff10-7bcd-4792-bc64-973d2fcbc64e", "source": "虎嗅", "section": "默认"}, {"title": "当下硅谷最火的AI产品，NotebookLM什么来头？", "link": "https://www.huxiu.com/article/3656537.html?f=rss", "description": "AI生成播客为何爆火？", "published": "2024-11-07 02:35:23", "id": "00fe7852-5099-447d-a5d5-c699b2ab6aa1", "source": "虎嗅", "section": "默认"}, {"title": "史上大跳水，双十一年度真香机只建议考虑这些？", "link": "https://www.huxiu.com/article/3660131.html?f=rss", "description": "全价位不同品牌手机推荐", "published": "2024-11-07 08:47:57", "id": "4fc84f9f-b566-473a-b2ba-f7e284f1c102", "source": "虎嗅", "section": "默认"}, {"title": "“民主”的神经网络：向不完美妥协", "link": "https://www.huxiu.com/article/3659673.html?f=rss", "description": "能达成妥协本身，比“完美”更重要", "published": "2024-11-07 07:26:46", "id": "99b761e2-95c9-4f6e-9b5d-09771c34d5f9", "source": "虎嗅", "section": "默认"}, {"title": "马斯克：美国的“影子总统”，还是特朗普寿糕上的蜡烛？", "link": "https://www.huxiu.com/article/3658561.html?f=rss", "description": "“我们有了一颗新星，一颗新星诞生了，埃隆”", "published": "2024-11-07 08:07:54", "id": "58c95363-111a-4a1c-a88b-e305d5eb2f16", "source": "虎嗅", "section": "默认"}, {"title": "“特朗普2.0”的市场答案：谁是大赢家？", "link": "https://www.huxiu.com/article/3659216.html?f=rss", "description": "11月6日，美股三大指数创历史新高", "published": "2024-11-07 02:31:35", "id": "eed7d260-b717-454e-9754-4290fd3c6234", "source": "虎嗅", "section": "默认"}, {"title": "个人养老金基金两年成绩单：规模、业绩分化显著", "link": "https://www.huxiu.com/article/3659695.html?f=rss", "description": "股债持仓差异是主要原因", "published": "2024-11-07 06:36:28", "id": "ce60719a-0ba6-46cd-a4e3-97900388ee53", "source": "虎嗅", "section": "默认"}, {"title": "区域茶饮猛冲北上广：王侯将相宁有种乎？", "link": "https://www.huxiu.com/article/3658774.html?f=rss", "description": "大混战中谁会留在牌桌上还是未知数。", "published": "2024-11-07 02:46:33", "id": "8877f0c1-1172-4353-9ea8-98685771071b", "source": "虎嗅", "section": "默认"}, {"title": "特朗普当选，TikTok安全了吗？", "link": "https://www.huxiu.com/article/3659239.html?f=rss", "description": "特朗普今年多次公开支持TikTok，但竞选言论和实际施政是两码事", "published": "2024-11-07 04:39:44", "id": "8a3788be-8be0-405b-9a2b-a9616621a399", "source": "虎嗅", "section": "默认"}, {"title": "当一场十年的丁克婚姻“意外翻车”", "link": "https://www.huxiu.com/article/3652976.html?f=rss", "description": "丁克结束后，她心中的理想生活并没有到来。", "published": "2024-11-07 05:00:00", "id": "ef012ef7-582c-49fe-8360-021591442d7c", "source": "虎嗅", "section": "默认"}, {"title": "特朗普归来，美国科技行业将面临哪些巨变？", "link": "https://www.huxiu.com/article/3660136.html?f=rss", "description": "毫无疑问，马斯克会是最大的受益者", "published": "2024-11-07 07:18:16", "id": "d8f1f8bc-2c96-4d09-b32c-cbb4af733655", "source": "虎嗅", "section": "默认"}, {"title": "票价两万起步，中国高端火车的生意版图", "link": "https://www.huxiu.com/article/3660164.html?f=rss", "description": "高端火车目前还处于卖方市场", "published": "2024-11-07 09:09:14", "id": "119f4ac8-47be-4809-8f47-e00594382606", "source": "虎嗅", "section": "默认"}, {"title": "5万旗丁统治上亿汉人：满清靠的是骑射还是步兵？", "link": "https://www.huxiu.com/article/3649285.html?f=rss", "description": "满清征服策略揭秘", "published": "2024-11-07 08:00:54", "id": "c096ff32-9f5d-4c33-ba06-82b7e42e100d", "source": "虎嗅", "section": "默认"}, {"title": "2024年，特朗普当选，会对中国资产造成多大打击？", "link": "https://www.huxiu.com/article/3659235.html?f=rss", "description": "特朗普当选对股市的影响只是中期趋势", "published": "2024-11-07 03:45:29", "id": "1575927d-f92b-436d-b514-106bbd64e754", "source": "虎嗅", "section": "默认"}, {"title": "加缪诞辰：在对抗荒诞中重拾人的尊严", "link": "https://www.huxiu.com/article/3660147.html?f=rss", "description": "“我们必须想象，西西弗斯是幸福的”", "published": "2024-11-07 08:28:17", "id": "f3020700-01d9-44bc-a31a-a621a3e8e53a", "source": "虎嗅", "section": "默认"}, {"title": "马斯克在诺兰生日派对问了什么？", "link": "https://www.huxiu.com/article/3654777.html?f=rss", "description": "试想未来人类可以乘坐代际飞船穿越虫洞是怎样一种体验。", "published": "2024-11-07 07:40:33", "id": "f5cb7646-be3d-49e6-84b4-d7e9a8459a03", "source": "虎嗅", "section": "默认"}, {"title": "AI PC现“苗头”，高通第二春快来了？", "link": "https://www.huxiu.com/article/3659641.html?f=rss", "description": "手机新品上市季也带动了整体销量", "published": "2024-11-07 09:45:39", "id": "abf69e64-cff5-48cb-9d13-d11455c17cda", "source": "虎嗅", "section": "默认"}, {"title": "发几个“哈”才算有礼貌？。", "link": "https://www.huxiu.com/article/3658054.html?f=rss", "description": "文字为啥越来越廉价了", "published": "2024-11-07 03:11:35", "id": "52c725a5-3a97-4d69-951e-7ba1aadf4422", "source": "虎嗅", "section": "默认"}, {"title": "标准版这次怎么选？外观手感优先级横评（上）", "link": "https://www.huxiu.com/article/3657582.html?f=rss", "description": "新机发布，都先别买？", "published": "2024-11-07 08:37:44", "id": "b4fe802d-841d-4762-87f4-4c1fae5b87aa", "source": "虎嗅", "section": "默认"}, {"title": "中老年擦边，需要被看见", "link": "https://www.huxiu.com/article/3659242.html?f=rss", "description": "情欲背后的需求", "published": "2024-11-07 05:08:30", "id": "86ab1ebb-31f0-4218-8d32-6f2009894cab", "source": "虎嗅", "section": "默认"}, {"title": "特朗普再次获胜，到底为什么？", "link": "https://www.huxiu.com/article/3660374.html?f=rss", "description": "少聊些主义，多谈些实际", "published": "2024-11-07 10:07:56", "id": "39b400a8-76f5-4c84-a6d0-cc0995521766", "source": "虎嗅", "section": "默认"}, {"title": "中国装备制造业：不屈不挠，直至成功", "link": "https://www.huxiu.com/article/3656334.html?f=rss", "description": "“卡脖子”卡的就是装备制造业", "published": "2024-11-07 09:30:00", "id": "cae3f50d-aeab-41d7-89a2-955a72f1aa82", "source": "虎嗅", "section": "默认"}, {"title": "深漂12年，一个农村女孩的逆袭人生：从服务员变成对外汉语教师", "link": "https://www.huxiu.com/article/3660398.html?f=rss", "description": "", "published": "2024-11-07 09:49:14", "id": "769d73ac-4ce4-40c0-988c-436b537ed863", "source": "虎嗅", "section": "默认"}, {"title": "特朗普上任第一把火，先烧马斯克？", "link": "https://www.huxiu.com/article/3659682.html?f=rss", "description": "马斯克：梭哈是一种智慧，我只教一次", "published": "2024-11-07 06:59:34", "id": "2b3fee65-5f99-4592-8aeb-5a4f7c2b007d", "source": "虎嗅", "section": "默认"}, {"title": "Mac外接显示器颜色溢出、文字模糊、HDR异常？病根儿找到了", "link": "https://www.huxiu.com/article/3658765.html?f=rss", "description": "MacOS色度抽样问题到底有没有解法？", "published": "2024-11-07 07:25:17", "id": "1148b035-193e-4051-be51-f3a1c82effc7", "source": "虎嗅", "section": "默认"}, {"title": "零售商的烘焙生意做起来了？", "link": "https://www.huxiu.com/article/3658741.html?f=rss", "description": "山姆瑞士卷卖了10亿元，盒马卖爆榴莲千层", "published": "2024-11-07 10:06:45", "id": "93581d24-adf9-44fe-adc8-5950b0782980", "source": "虎嗅", "section": "默认"}, {"title": "在太空种粮、种菜进展到了哪一步？", "link": "https://www.huxiu.com/article/3658761.html?f=rss", "description": "如何在狭小的微重力环境下种菜？", "published": "2024-11-07 03:58:26", "id": "3600406e-7766-443f-b633-c9f674ffbd9c", "source": "虎嗅", "section": "默认"}, {"title": "一款神药，1200亿卖了", "link": "https://www.huxiu.com/article/3660151.html?f=rss", "description": "低调的私募巨头出手了", "published": "2024-11-07 07:03:00", "id": "98069b42-e053-4310-91d1-887843150d29", "source": "虎嗅", "section": "默认"}, {"title": "川普赢了，义乌老板转向", "link": "https://www.huxiu.com/article/3659217.html?f=rss", "description": "美国离不开义乌速度", "published": "2024-11-07 03:11:29", "id": "6463e176-d3ae-4cd9-b651-ff10169da684", "source": "虎嗅", "section": "默认"}, {"title": "欧美渐行渐远，马克龙急了，法国如何自救？", "link": "https://www.huxiu.com/article/3656509.html?f=rss", "description": "欧盟未来是否会受美国支配？", "published": "2024-11-07 10:00:02", "id": "e05e7bda-667e-47db-9d46-9ba628013927", "source": "虎嗅", "section": "默认"}, {"title": "机场地服两三事", "link": "https://www.huxiu.com/article/3659257.html?f=rss", "description": "", "published": "2024-11-07 03:29:00", "id": "84184592-5ff9-4a71-b034-7198dea5cbea", "source": "虎嗅", "section": "默认"}, {"title": "苹果的智能眼镜，有什么不一样？", "link": "https://www.huxiu.com/article/3657009.html?f=rss", "description": "苹果向左，Meta向右", "published": "2024-11-07 03:01:25", "id": "cd12ec02-5d49-494c-b624-5d2826d81702", "source": "虎嗅", "section": "默认"}, {"title": "特朗普想当戴高乐？", "link": "https://www.huxiu.com/article/3659259.html?f=rss", "description": "但显然，他没有戴高乐那样广泛的支持", "published": "2024-11-07 06:25:00", "id": "4cf5cdde-fcfe-4d60-a3e4-656e7b377ffc", "source": "虎嗅", "section": "默认"}, {"title": "时隔四年，特朗普宣布胜选", "link": "https://www.huxiu.com/article/3657747.html?f=rss", "description": "特朗普当选的六大影响", "published": "2024-11-07 02:33:10", "id": "0dad9a37-c98a-4061-be96-50eaf091862e", "source": "虎嗅", "section": "默认"}, {"title": "告别办公室内耗，年轻人决定做点“轻体力活”", "link": "https://www.huxiu.com/article/3659226.html?f=rss", "description": "换种工作，就能“跳出齿轮”吗？", "published": "2024-11-07 07:19:08", "id": "97c99cb4-7975-4c88-b4d4-d5fd30a101b0", "source": "虎嗅", "section": "默认"}, {"title": "燕云八百堡：藏在京西群山里的传奇小城", "link": "https://www.huxiu.com/article/3657047.html?f=rss", "description": "99%的人都会读错名字，古建浓度不输山西", "published": "2024-11-07 05:51:00", "id": "a5fbc885-24f8-4972-9fba-5b2771cc890c", "source": "虎嗅", "section": "默认"}, {"title": "特朗普上台，中国会推出大规模刺激计划吗？", "link": "https://www.huxiu.com/article/3659211.html?f=rss", "description": "全球资产回归“特朗普交易”", "published": "2024-11-07 03:01:29", "id": "4b4eff26-29b2-4fbb-9195-9743572e86ca", "source": "虎嗅", "section": "默认"}, {"title": "特朗普不爱电动汽车，马斯克为啥还要支持他？", "link": "https://www.huxiu.com/article/3659253.html?f=rss", "description": "成功押注特朗普，马斯克补上了“政治影响力”的核心资产", "published": "2024-11-07 04:05:43", "id": "0e801218-098a-4719-875a-581d594a3f40", "source": "虎嗅", "section": "默认"}, {"title": "“孤注一掷“的县城留学生，困在割裂的现实中", "link": "https://www.huxiu.com/article/3658744.html?f=rss", "description": "割裂的延伸", "published": "2024-11-07 02:23:20", "id": "74c373f9-6f57-4c19-8878-ca3ff00f1e9d", "source": "虎嗅", "section": "默认"}, {"title": "为啥全球富豪都爱“买买买”球队？篮网让蔡崇信赚翻了", "link": "https://www.huxiu.com/article/3660389.html?f=rss", "description": "", "published": "2024-11-07 09:33:15", "id": "1244cbd5-d701-438c-afc5-4525fb7dda09", "source": "虎嗅", "section": "默认"}, {"title": "社交媒体如何改变了我们交流的方式？（三）", "link": "https://www.huxiu.com/article/3659225.html?f=rss", "description": "不可能再有下一个“刘德华”?", "published": "2024-11-07 05:26:15", "id": "94faa515-e9e2-4afa-9918-2bc94d7a9809", "source": "虎嗅", "section": "默认"}, {"title": "特朗普胜选带飞比特币？挖矿会冲击AI发展吗？", "link": "https://www.huxiu.com/article/3657736.html?f=rss", "description": "比特币和AI可能会开启能源抢夺战？", "published": "2024-11-07 03:00:48", "id": "f33a80e4-e70e-46d8-8ea5-f4bb5d692cd4", "source": "虎嗅", "section": "默认"}, {"title": "中老年短剧是怎么“跑通”的？", "link": "https://www.huxiu.com/article/3657735.html?f=rss", "description": "引发共鸣，逻辑情绪并重，投流更多", "published": "2024-11-07 02:14:32", "id": "13ade3c4-61af-43b3-9488-c3a2b211f4c8", "source": "虎嗅", "section": "默认"}, {"title": "特朗普“二进宫”，HR介意离职员工再入职吗？", "link": "https://www.huxiu.com/article/3658754.html?f=rss", "description": "离职员工“二进宫”优势明显、劣势也明显", "published": "2024-11-07 02:14:30", "id": "d7e5daf0-a318-4ccf-9b3f-87120a63867c", "source": "虎嗅", "section": "默认"}, {"title": "“特朗普背后男人”的AI价值观", "link": "https://www.huxiu.com/article/3658747.html?f=rss", "description": "不要与马斯克做对手盘，不要不听从彼得·蒂尔的观点主张", "published": "2024-11-07 01:49:21", "id": "7134c5b6-7367-4f1d-a127-3b4785461c2a", "source": "虎嗅", "section": "默认"}, {"title": "中老年短视频消费的底层逻辑", "link": "https://www.huxiu.com/article/3657756.html?f=rss", "description": "“被需要”与“被爱”", "published": "2024-11-07 01:31:00", "id": "30d24e8d-58c3-456a-868f-84395b2ef5fc", "source": "虎嗅", "section": "默认"}, {"title": "线下实体商业在悄悄攻占双十一", "link": "https://www.huxiu.com/article/3658568.html?f=rss", "description": "一个有魅力的城市，一定是线下商业实体经济蓬勃发展的。", "published": "2024-11-07 01:26:14", "id": "17250668-0791-4238-b493-7bed22c5bd8f", "source": "虎嗅", "section": "默认"}, {"title": "普通人该如何做投资？", "link": "https://www.huxiu.com/article/3655604.html?f=rss", "description": "别人贪婪我恐惧，别人恐惧我贪婪， 这个“别人”指的就是我们", "published": "2024-11-07 01:20:13", "id": "7ce17b7d-b401-46a2-acd5-f7efbfde9be6", "source": "虎嗅", "section": "默认"}, {"title": "婚后负债几十万，他们不敢告诉另一半", "link": "https://www.huxiu.com/article/3658737.html?f=rss", "description": "“坦白才是正途”", "published": "2024-11-07 01:11:00", "id": "85194727-1739-4e8b-99ce-bb112eebf3dc", "source": "虎嗅", "section": "默认"}, {"title": "电动车市场火爆，可充电桩却不是门好生意？", "link": "https://www.huxiu.com/article/3656477.html?f=rss", "description": "如果没有国家补贴，建充电桩的早就赔惨了？", "published": "2024-11-07 01:00:00", "id": "031db51f-dcb4-439f-a7c2-a5fef159af14", "source": "虎嗅", "section": "默认"}, {"title": "诺和诺德警示复方仿制减肥药风险，已有10人死亡百余人住院", "link": "https://www.huxiu.com/article/3658736.html?f=rss", "description": "药品可及性应通过扩大制造能力的重大投资来扩展", "published": "2024-11-07 00:57:13", "id": "c08070ad-2aed-41c3-839c-93e98b1fa460", "source": "虎嗅", "section": "默认"}, {"title": "未来5年，环保行业的3个淘汰潮", "link": "https://www.huxiu.com/article/3658051.html?f=rss", "description": "在淘汰中重生和强大", "published": "2024-11-07 00:50:28", "id": "255d8ef0-b934-4b61-80a0-ffd11f8c637a", "source": "虎嗅", "section": "默认"}, {"title": "为什么旅游很难拉动地方GDP？", "link": "https://www.huxiu.com/article/3658580.html?f=rss", "description": "从“敦煌码”看中国旅游经济之困。", "published": "2024-11-07 00:43:36", "id": "babf3ed5-cc77-4743-9cc5-2ca9c9143ff0", "source": "虎嗅", "section": "默认"}, {"title": "抓考勤，管工时，不是HR一个人的事儿", "link": "https://www.huxiu.com/article/3655853.html?f=rss", "description": "不重视工时管理的业务管理者，不是合格的管理者", "published": "2024-11-07 00:32:49", "id": "3a49ad84-50cf-4a6e-8862-c5bbd5a285dd", "source": "虎嗅", "section": "默认"}, {"title": "特朗普回来了，留给人类的时间不多了", "link": "https://www.huxiu.com/article/3658581.html?f=rss", "description": "传统逻辑已经失效", "published": "2024-11-07 00:19:49", "id": "a65e5da5-fb45-4b82-83ef-79d214dcc71c", "source": "虎嗅", "section": "默认"}, {"title": "伯克希尔为何要卖出价值1200亿美元的苹果股票？", "link": "https://www.huxiu.com/article/3657075.html?f=rss", "description": "苹果股价已经远远超过了其内在价值", "published": "2024-11-07 00:19:27", "id": "f357b15a-5160-4256-af44-2e9a132ad944", "source": "虎嗅", "section": "默认"}, {"title": "韩国泡菜自信，被中国动摇了", "link": "https://www.huxiu.com/article/3658055.html?f=rss", "description": "泡菜鄙视链背后是市场，市场不说谎。", "published": "2024-11-07 00:09:37", "id": "5bdf49cc-9976-4934-a312-b1aaadbbbde9", "source": "虎嗅", "section": "默认"}, {"title": "LDO这些性能参数，也许你并没有参透", "link": "https://www.huxiu.com/article/3658724.html?f=rss", "description": "", "published": "2024-11-07 00:08:00", "id": "8c06737f-4b6b-446e-aab3-4df223eeb8c8", "source": "虎嗅", "section": "默认"}, {"title": "昆明前首富，敏感肌的故事讲不动了", "link": "https://www.huxiu.com/article/3658719.html?f=rss", "description": "", "published": "2024-11-07 00:05:13", "id": "a1c776c6-8cca-41b3-ba29-dbbab94bf7c0", "source": "虎嗅", "section": "默认"}, {"title": "特朗普交易横扫市场，三大指数齐创历史新高", "link": "https://www.huxiu.com/article/3658563.html?f=rss", "description": "哪些股票、概念出现异动？", "published": "2024-11-07 00:00:02", "id": "9f31e8c5-f540-4da7-a282-7166cd858215", "source": "虎嗅", "section": "默认"}, {"title": "Whole of Cuba loses power as Hurricane Rafael hits", "link": "https://www.bbc.com/news/articles/c8jy1xxv7rzo", "description": "The category three storm made landfall on Wednesday and is expected to bring storm surges and floods.", "published": "2024-11-07 04:47:32", "id": "760bd0ca-886d-4257-9618-59e75c909c3f", "source": "bbc", "section": "world"}, {"title": "'We live in fear' - forced expulsions taint Kenya's safe haven image", "link": "https://www.bbc.com/news/articles/clyv2610n6qo", "description": "Kenya's status as a sanctuary for refugees is questioned after the deportation of four Turkish nationals.", "published": "2024-11-07 00:06:20", "id": "c5377b38-1a9d-4ef8-aacd-9ce893489c84", "source": "bbc", "section": "world"}, {"title": "Watch: Fast-moving California wildfire burns out of control", "link": "https://www.bbc.com/news/videos/cp9z0l15yr7o", "description": "Thousands of people have been evacuated from their homes in Ventura County, near Los Angeles.", "published": "2024-11-07 03:13:08", "id": "a3f56097-cbeb-431a-8588-0e0dcf007f90", "source": "bbc", "section": "world"}, {"title": "German coalition collapses after Scholz fires key minister", "link": "https://www.bbc.com/news/articles/c7v3r046pzzo", "description": "The chancellor said he would call a vote of confidence in his government early next year.", "published": "2024-11-07 09:29:45", "id": "265d330e-c548-4479-90d1-da42aa9f6f09", "source": "bbc", "section": "world"}, {"title": "Israeli strikes kill at least 40 in east Lebanon - health ministry", "link": "https://www.bbc.com/news/articles/crr9q249pveo", "description": "An Israeli official said the strikes, in the Baalbek and Bekaa regions, targeted Hezbollah operatives.", "published": "2024-11-07 09:05:13", "id": "43abce8c-a669-4b61-8032-ffaa53b4fd49", "source": "bbc", "section": "world"}, {"title": "Europe's leaders face up to Trump victory at Hungarian summit", "link": "https://www.bbc.com/news/articles/cly2z73127vo", "description": "Leaders meeting in Budapest will be focused on Russia's war and fears of US isolationism.", "published": "2024-11-07 08:41:52", "id": "daa90a23-50da-44cf-8f24-c0a5838366c0", "source": "bbc", "section": "world"}, {"title": "What Elon Musk could gain from Trump's presidency", "link": "https://www.bbc.com/news/articles/cjdl22yrrk2o", "description": "One of the president-elect's most visible supporters, Musk could be given a role in Trump's White House.", "published": "2024-11-07 10:01:47", "id": "a70deae5-c1b2-4619-bfd0-854280d20ce7", "source": "bbc", "section": "world"}, {"title": "Faeces, drugs and oil: Mystery of Sydney’s ‘tar’ balls solved", "link": "https://www.bbc.com/news/articles/c5yr08xnxw8o", "description": "Beaches including Bondi were closed for days and a clean-up ordered after thousands of black deposits started appearing.", "published": "2024-11-07 04:43:36", "id": "60dc32b9-dafe-494b-a18a-c8fd6d84279d", "source": "bbc", "section": "world"}, {"title": "Why Kamala Harris lost: A flawed candidate or doomed campaign?", "link": "https://www.bbc.com/news/articles/cjr4l5j2v9do", "description": "The vice-president failed to make the case that she would be different from her boss, President Joe Biden.", "published": "2024-11-07 01:13:37", "id": "7819aeeb-9da8-4b4a-aa10-e2099a300958", "source": "bbc", "section": "world"}, {"title": "The view from countries where Trump's win really matters", "link": "https://www.bbc.com/news/articles/c4gpd2487e5o", "description": "An opportunity, a respite or a security fear - we assess how Trump's return to power is being viewed elsewhere.", "published": "2024-11-07 03:13:36", "id": "cfcb85f6-6ce8-4e4d-8a40-0fc66e192417", "source": "bbc", "section": "world"}, {"title": "This year set to be first to breach 1.5C global warming limit", "link": "https://www.bbc.com/news/articles/c1dpnxnvv2go", "description": "It is also set to be the world's first breach of 1.5C of warming across an entire calendar year.", "published": "2024-11-07 03:22:24", "id": "256899f3-e646-4ffb-a224-9e608492a9cb", "source": "bbc", "section": "world"}, {"title": "Trump victory is a major setback for climate action, experts say", "link": "https://www.bbc.com/news/articles/c5ygplyg09ro", "description": "Trump's election will hit immediate efforts to tackle climate change, experts say - but the longer-term effect is less certain.", "published": "2024-11-07 03:11:16", "id": "dae731e2-4a70-4276-8df9-01edc066d139", "source": "bbc", "section": "world"}, {"title": "Australia plans world-first social media ban for under-16s", "link": "https://www.bbc.com/news/articles/c4gzd62g1r3o", "description": "The government says it wants to mitigate the \"harm\" social media is inflicting on children.", "published": "2024-11-07 00:59:31", "id": "25d50635-74f4-4abc-81a6-96b7edd36a87", "source": "bbc", "section": "world"}, {"title": "'It's simple, really' - why Latinos flocked to Trump's working-class coalition", "link": "https://www.bbc.com/news/articles/cze3yr77j9wo", "description": "As well as winning over Hispanic voters, Trump improved his position in some surprising corners.", "published": "2024-11-07 00:08:52", "id": "db633204-c78d-4479-9b58-0d3c90cf6004", "source": "bbc", "section": "world"}, {"title": "Will Trump's victory spark a global trade war?", "link": "https://www.bbc.com/news/articles/cjw0n7jvlzxo", "description": "Trump has promised tariffs on all foreign goods. If he follows through, many smaller economies may be forced to respond in kind.", "published": "2024-11-07 00:01:56", "id": "5344b7d0-4d5e-43a3-9c5b-9c72f842d4b8", "source": "bbc", "section": "world"}, {"title": "Watch: Fast-moving California wildfire burns out of control", "link": "https://www.bbc.com/news/videos/cp9z0l15yr7o", "description": "Thousands of people have been evacuated from their homes in Ventura County, near Los Angeles.", "published": "2024-11-07 03:13:08", "id": "c4991a45-ec90-42b3-a301-4a6131cbd308", "source": "bbc", "section": "world"}, {"title": "Moldova cleans up its act to attract foreign businesses", "link": "https://www.bbc.com/news/articles/cly0zwpxjmwo", "description": "Deputy PM admits former Soviet state was until recently a 'highly corrupt country' - but insists things are changing fast.", "published": "2024-11-07 00:06:39", "id": "e8dd163a-0e27-4e42-9ffa-56263add1751", "source": "bbc", "section": "world"}, {"title": "Scot gets dream job as lighthouse keeper on remote Australian island", "link": "https://www.bbc.com/news/articles/cgk1x7kv2kko", "description": "Sandy Duthie's \"dream job\" involves solitude, a 160-year history, and a colony of little penguins.", "published": "2024-11-07 06:17:32", "id": "df9e7c77-57d6-43b3-998c-17f031621a78", "source": "bbc", "section": "world"}, {"title": "Will Trump's victory spark a global trade war?", "link": "https://www.bbc.com/news/articles/cjw0n7jvlzxo", "description": "Trump has promised tariffs on all foreign goods. If he follows through, many smaller economies may be forced to respond in kind.", "published": "2024-11-07 00:01:56", "id": "d4652925-8f5a-4fdc-950b-92e08bb37dd5", "source": "bbc", "section": "business"}, {"title": "Moldova cleans up its act to attract foreign businesses", "link": "https://www.bbc.com/news/articles/cly0zwpxjmwo", "description": "Deputy PM admits former Soviet state was until recently a 'highly corrupt country' - but insists things are changing fast.", "published": "2024-11-07 00:06:39", "id": "f07a4b3a-becb-45e6-819c-8429b297b311", "source": "bbc", "section": "business"}, {"title": "Sainsbury's and M&S warn Budget may push up prices", "link": "https://www.bbc.com/news/articles/c238g1x9l00o", "description": "A number of major firms have warned over the impact of higher National Insurance costs.", "published": "2024-11-07 10:56:32", "id": "a0bbf903-f057-4b66-8b65-c582b4dd07f9", "source": "bbc", "section": "business"}, {"title": "Australia plans social media ban for under-16s", "link": "https://www.bbc.com/news/articles/c4gzd62g1r3o", "description": "The government says it wants to mitigate the \"harm\" social media is inflicting on children.", "published": "2024-11-07 00:59:31", "id": "16ce24db-1625-41e5-81e5-1b9694055409", "source": "bbc", "section": "business"}, {"title": "How do UK interest rates affect me and my money?", "link": "https://www.bbc.co.uk/news/business-57764601", "description": "Bank of England interest rates affect the mortgage, loan and savings rates for millions of people.", "published": "2024-11-07 00:10:08", "id": "c34ae725-b0e0-4557-af94-e6368e65cca8", "source": "bbc", "section": "business"}, {"title": "House prices at record high, says Halifax", "link": "https://www.bbc.com/news/articles/cdrd38k0eg7o", "description": "Despite the increase, the lender warns mortgage costs could remain \"higher for longer\" following the Budget.", "published": "2024-11-07 10:22:29", "id": "8dcf7abc-974b-4b9b-b34e-69b55fe0917a", "source": "bbc", "section": "business"}, {"title": "Australia plans social media ban for under-16s", "link": "https://www.bbc.com/news/articles/c4gzd62g1r3o", "description": "The government says it wants to mitigate the \"harm\" social media is inflicting on children.", "published": "2024-11-07 00:59:31", "id": "8e554e7a-f1b1-4250-a9bd-74493d174afb", "source": "bbc", "section": "technology"}, {"title": "Roblox announces new safety features for under-13s", "link": "https://www.bbc.com/news/articles/cwy9kry4lvko", "description": "The gaming platform has previously been criticised for allowing young users to be exposed to harmful content.", "published": "2024-11-07 10:28:35", "id": "2fc9f869-da61-4315-9d4c-911319beb1e3", "source": "bbc", "section": "technology"}, {"title": "What Elon Musk could gain from Trump's presidency", "link": "https://www.bbc.com/news/articles/cjdl22yrrk2o", "description": "One of the president-elect's most visible supporters, Musk could be given a role in Trump's White House.", "published": "2024-11-07 10:01:47", "id": "14221a87-ccf5-47e0-b232-819b44ea3c37", "source": "bbc", "section": "technology"}, {"title": "Trump victory is a major setback for climate action, experts say", "link": "https://www.bbc.com/news/articles/c5ygplyg09ro", "description": "Trump's election will hit immediate efforts to tackle climate change, experts say - but the longer-term effect is less certain.", "published": "2024-11-07 03:11:16", "id": "45ead862-3baa-4109-9749-67a1e1b1a2e4", "source": "bbc", "section": "science"}, {"title": "This year set to be first to breach 1.5C global warming limit", "link": "https://www.bbc.com/news/articles/c1dpnxnvv2go", "description": "It is also set to be the world's first breach of 1.5C of warming across an entire calendar year.", "published": "2024-11-07 03:22:24", "id": "e6559b6a-48c5-4beb-b72f-59f15b852b5f", "source": "bbc", "section": "science"}, {"title": "Europe's leaders face up to Trump victory at Hungarian summit", "link": "https://www.bbc.com/news/articles/cly2z73127vo", "description": "Leaders meeting in Budapest will be focused on Russia's war and fears of US isolationism.", "published": "2024-11-07 08:41:52", "id": "b022fc1d-5f96-44ea-af4b-f08dd21151c4", "source": "bbc", "section": "politics"}, {"title": "New deals with Balkan states to target people smugglers", "link": "https://www.bbc.com/news/articles/cpdv1yxg8jqo", "description": "The agreements aim to increase intelligence sharing as part of efforts to tackle small boat crossings.", "published": "2024-11-07 11:17:56", "id": "87a55f87-019d-4685-a7f6-21c5db30ab46", "source": "bbc", "section": "politics"}, {"title": "Bank of England expected to cut interest rates", "link": "https://www.bbc.com/news/articles/c789n4l2xpgo", "description": "Most analysts predict the rate will fall from 5% to 4.75% when the decision is announced at 12:00 GMT.", "published": "2024-11-07 00:05:33", "id": "3d95da47-66f7-48b3-9add-94fbc5d89345", "source": "bbc", "section": "politics"}, {"title": "Will Trump's victory spark a global trade war?", "link": "https://www.bbc.com/news/articles/cjw0n7jvlzxo", "description": "Trump has promised tariffs on all foreign goods. If he follows through, many smaller economies may be forced to respond in kind.", "published": "2024-11-07 00:01:56", "id": "f5557fc4-f1cd-459d-8293-488d6f937cee", "source": "bbc", "section": "politics"}, {"title": "Paralympian leads effort to improve travel for disabled people", "link": "https://www.bbc.com/news/articles/c62j810dlnmo", "description": "The new taskforce will work to make flying accessible for all \"from booking to baggage claim\".", "published": "2024-11-07 10:01:13", "id": "1a6ac353-788c-40af-a1b8-9315cac65276", "source": "bbc", "section": "politics"}, {"title": "Tenants may not be able to buy new council homes - Rayner", "link": "https://www.bbc.com/news/articles/cwygr168717o", "description": "Angela Rayner told the BBC restrictions would be placed on new social homes in England.", "published": "2024-11-07 00:02:35", "id": "6eb886a7-7399-4e95-a41d-2eb165bd2847", "source": "bbc", "section": "politics"}]