[{"title": "众鑫股份：美国商务部对公司产品发起反倾销、反补贴调查", "link": "https://36kr.com/newsflashes/3016228996195846?f=rss", "description": "36氪获悉，众鑫股份公告，美国商务部于美国时间2024年10月29日发布公告，对原产自中国、越南的热成型模塑纤维产品正式发起反倾销、反补贴调查。公司出口至美国的热成型模塑纤维产品的销售金额占公司当期总收入的比例较高。公司已成立专项工作组，并聘请专业律师团队积极应对本次“双反调查”，同时加快泰国工厂的建设进度，力争在2025年一季度正式投产，以承接美国客户的订单。", "published": "2024-10-31 09:46:48", "id": "7a4ffdd9-4b92-49b3-9217-288b6bbf3b24", "source": "36氪", "section": "综合资讯"}, {"title": "证监会同意钧崴电子创业板IPO注册申请", "link": "https://36kr.com/newsflashes/3016246883264000?f=rss", "description": "36氪获悉，证监会同意钧崴电子科技股份有限公司首次公开发行股票并在创业板上市的注册申请。", "published": "2024-10-31 10:04:59", "id": "52628a8b-71a1-434d-ad31-8d461c5abe1a", "source": "36氪", "section": "综合资讯"}, {"title": "氪星晚报｜SpaceX完成第200次星链发射任务，马斯克祝贺；丰田汽车：与NTT公司2025年开始开发人工智能平台", "link": "https://36kr.com/p/3016214601934087?f=rss", "description": "<h2>大公司：</h2>\n  <p><a href=\"https://36kr.com/newsflashes/3016178799158532\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>旭升集团：控股股东筹划控制权变更，股票继续停牌</strong></a></p>\n  <p>36氪获悉，旭升集团公告，公司接到控股股东徐旭东通知，徐旭东及其一致行动人正在筹划涉及所持公司股份的转让事宜，可能导致控制权变更。由于该事项存在重大不确定性，公司股票及转债于2024年10月30日至31日已停牌两个交易日。经向上海证券交易所申请，自2024年11月1日起继续停牌，预计不超过三个交易日。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016141164586505\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>三星暗示有望近期开始向英伟达供应HBM芯片</strong></a></p>\n  <p>韩国三星电子公司周四暗示，有可能在近期向美国人工智能巨头英伟达提供先进的高带宽存储器（HBM）。这家韩国科技巨头一直在努力让其HBM3E芯片通过英伟达的质量测试，而其本土竞争对手SK海力士公司最近已开始量产业界领先的12层HBM3E芯片。三星电子内存业务副总裁Kim Jae-june在第三季度财报公布后召开的电话会议上表示：“目前，我们正在量产8层和12层HBM3E产品。”（新浪财经）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015929760720392\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>ZOLOZ作为亚太唯一厂商入选Gartner身份验证魔力象限</strong></a></p>\n  <p>36氪获悉，近日，全球信息技术研究和顾问公司Gartner发布《身份验证魔力象限》报告，全球范围内有11家机构入选，蚂蚁数科旗下ZOLOZ成为亚太地区唯一入选的厂商。据介绍，这是Gartner首个专注于身份验证领域的魔力象限报告。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016101576074504\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>壳牌第三季度盈利超市场预期</strong></a></p>\n  <p>由于天然气业务不断增长，壳牌的收益超过了市场预期，部分抵消了低油价和炼油利润率疲软对第三季度业绩的影响。能源巨头壳牌周四公布，本季度调整后收益为60.3亿美元，同比下降4%，但超过了该公司普遍预期的53.6亿美元。按市值计算，该公司宣布季度股息为34.40美分，并表示将在第四季度回购价值35亿美元的股票，这与之前的指导一致。（新浪财经）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015942920021511\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>现代汽车发布氢燃料电池概念车INITIUM，明年上半年推出量产车</strong></a></p>\n  <p>现代汽车于韩国首尔发布了最新名为INITIUM的氢燃料电池概念车。基于INITIUM概念车，现代汽车将于2025年上半年推出全新的量产氢燃料电池车。据介绍，INITIUM概念车配备了低风阻轮毂并搭载低滚阻轮胎，以减少阻力，其续航里程超过650公里。现代汽车计划在11月份的广州车展和洛杉矶车展上对外展示INITIUM概念车。（界面）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015937271735560\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>大众汽车向工人提出节省成本计划，希望避免关闭德国工厂</strong></a></p>\n  <p>大众汽车向工人提出了一项可以避免德国工厂关闭的成本节约建议。这家汽车制造商的首席谈判代表Arne Meiswinkel表示，该计划包括减薪10%和修改奖金制度。当前大众汽车品牌面临欧洲需求疲弱和来自中国竞争加剧的局面，这些措施意在重振雄风。大众汽车和劳工领袖警告说，如果不能就其他措施达成充分的协议，那么关闭工厂仍有可能。（新浪财经）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016167497164289\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>理想汽车：第三季度净利润28.2亿元，同比增长0.3%</strong></a></p>\n  <p>36氪获悉，理想汽车发布2024年第三季度财报。财报显示，该季度理想汽车实现净利润28.2亿元，同比增长0.3%；预计第四季度交付量16万至17万辆，同比增长21.4%至29.0%。理想汽车美股盘前跌超4%。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016048261490184\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>飞猪双11主题乐园及热门景区活动商品已卖出超50万件</strong></a></p>\n  <p>36氪获悉，据飞猪消息，截至10月30日24时，双11主题乐园及热门景区相关活动商品已售出超50万件，超越去年双11全程。其中，部分头部乐园品牌爆款商品的预约率达90%，部分滑雪季旅游套餐的预约率超过40%。</p>\n  <h2>投融资：</h2>\n  <p><a href=\"https://36kr.com/newsflashes/3016055138182657\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>西门子同意以106亿美元现金收购模拟软件公司Altair</strong></a></p>\n  <p>当地时间10月30日，西门子宣布同意斥资106亿美元以全现金交易方式收购模拟软件公司Altair Engineering。西门子将为Altair每股支付113美元现金，后者估值达到106亿美元。这一报价较2024年10月21日Altair未受影响的收盘价溢价19%。Altair总部位于美国密歇根州，向工业制造、消费品、能源和其他行业的大型企业客户销售数据分析技术和服务。（界面）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015970656052741\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>“临科智华”完成2300万元种子轮融资</strong></a></p>\n  <p>36氪获悉，“临科智华”近日宣布完成2300万元种子轮融资，投资方为谦益资本。本轮融资资金，临科智华将用于团队建设、技术研发，以及人工智能核心技术基础建设。临科智华成立于2024年，致力于为各行业公司提供数据智能解决方案。</p>\n  <h2>新产品：</h2>\n  <p><a href=\"https://36kr.com/newsflashes/3016047124375048\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>百川智能发布一站式解决方案</strong></a></p>\n  <p>36氪获悉，今日，百川智能推出一站式大模型商业化解决方案，即1+3产品矩阵（全链路优质通用训练数据，Baichuan4-Turbo、Baichuan4-Air两款模型和全链路领域增强工具链），该方案“工具多、速度快、效果好、成本低”，能够帮助企业以最低成本实现效果最佳的私有化部署。并支持企业将专有数据与百川智能自用的全链路优质训练数据混合，对Baichuan4-Turbo、Baichuan4-Air两款模型进行调优和增强，实现了行业最高的96%多场景可用率。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015956651844871\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>思必驰发布AI办公本Turbo</strong></a></p>\n  <p>36氪获悉，思必驰发布AI办公本Turbo，搭载了专业级跨模态会议大模型。思必驰IOT事业部首席产品官马斌斌表示，这一模型基于千万小时的会议训练数据优化，能够实现手写输入、图像扫描、语音输入以及历史笔记文档的跨模态融合。基于大模型技术的智能笔记是思必驰AI办公本的核心功能，包括会议录音实时转文字、AI笔记结构化提炼要点和会后自动生成会议纪要等。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015956121937417\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>丰田汽车：与NTT公司2025年开始开发人工智能平台</strong></a></p>\n  <p>丰田汽车表示，与NTT公司2025年开始开发人工智能平台，预计到2030年与NTT对人工智能平台的投资总额将达5000亿日元。（财联社）</p>\n  <h2>今日观点：</h2>\n  <p><a href=\"https://36kr.com/newsflashes/3016042640942344\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>SpaceX完成第200次星链发射任务，马斯克祝贺</strong></a></p>\n  <p>马斯克的SpaceX公司在社交平台X上发帖称，该公司的“猎鹰9号”火箭周三完成了第200次近地轨道“星链”发射任务。当地时间周三晚上，一枚“猎鹰9号”火箭从佛罗里达州向太空发射了23颗星链卫星，这是该公司第200次执行“星链”发射任务。星链是SpaceX的一个分支，在轨道卫星网络的帮助下，为全球400多万人提供低延迟网络连接。今年9月初，该公司表示已向太空发射了7000多颗星链卫星。SpaceX首席执行官埃隆·马斯克发帖祝贺SpaceX团队发射成功。（新浪财经）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016036902659333\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>摩根士丹利：将AMD目标价从178美元下调至169美元</strong></a></p>\n  <p>36氪获悉，摩根士丹利的报告显示，AMD的季度表现符合预期，但市场反应表明公司面临高期望的挑战。该行仍然看好2024至2025年在人工智能领域的投资机会，尽管有部分收入和盈利的预期可能过高。摩根士丹利将AMD的目标价从178美元下调至169美元，维持“与大市同步”的评级,预计AMD截至明年3月的季度收入为69.86亿美元，2025年全年收入为310.7亿美元，2026年收入将增长25%至29%。</p>\n  <h2>其他值得关注的新闻：</h2>\n  <p><a href=\"https://36kr.com/newsflashes/3016207431968000\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>北交所：拟于11月2日开展交易支持平台优化第一次全网测试</strong></a></p>\n  <p>36氪获悉，10月31日，北京证券交易所办公室、全国股转公司办公室发布通知，拟于近期开展交易支持平台优化第一次全网测试，参测机构包括北交所、全国股转公司、中国结算、深证通、证券公司、基金公司、信息商等。测试时间为11月2日。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016204332918020\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>国家外汇管理局扩大3项跨境投融资便利化试点</strong></a></p>\n  <p>36氪获悉，日前，国家外汇管理局在总结前期试点经验的基础上，决定将开展外商投资企业境内再投资免登记试点和银行直接办理外债登记试点的地区扩大至天津市、安徽省、山东省（含青岛市）、湖北省和四川省，将“科汇通”试点地区扩大至上海市、北京市、天津市、河北雄安、南京市、苏州市、杭州市、合肥市、武汉市、长沙市、广州市、重庆市、成都市、绵阳市、西安市和深圳市等16个地区。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015997187466503\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>广东省内11家发电公司发函建言：设置年度交易电量比例限制，优化月度供需比机制</strong></a></p>\n  <p>2025年，电力市场将进入年度长协签约的时间窗口，但目前电力中长期市场因机制不够完善给发电企业带来了困难。10月25日，广东省内11家发电公司联合向广东省能源局、国家能源局南方监管局致函要求“进一步完善中长期市场机制”。（21世纪经济报道）</p>", "published": "2024-10-31 09:43:22", "id": "5b566432-deb7-460a-b240-6bfae28b5f6c", "source": "36氪", "section": "综合资讯"}, {"title": "「私董会」的奇幻漂流：蹲在视频号门口的老板们｜深氪", "link": "https://36kr.com/p/3015867578426633?f=rss", "description": "<p><strong>文｜</strong>王毓婵</p>\n  <p><strong>编辑｜</strong>杨轩 乔芊</p>\n  <p><strong>来源｜</strong>36氪未来消费（ID：lslb168)</p>\n  <p><strong>封面来源｜</strong>作者拍摄</p>\n  <p>周末早上九点，2000多个小企业老板已经占满了一间会议厅的所有椅子，很多来迟的人不得不坐在地上。他们来学习怎么在视频号上做生意。</p>\n  <p>每张椅子上都放着已经打印好的演讲稿和一支笔。这些平均年入百万以上的老板们，像小学生一样把纸放在膝盖上，又圈又写。</p>\n  <p>去年，同样的活动只来了700人，今年翻了一倍还多。</p>\n  <p>“今年谁还搞抖音大会？全TM搞视频号了。为啥？因为做抖音没钱赚了，很简单。”刘思毅站在台上说。</p>\n  <p>刘思毅是流量操盘手社群“群响”的主理人，一年花费2399元入会，你就可以像这两千人一样，一起学着站上风口。前几年，群响的大会主题还是抖音电商，今年则变成了视频号、小红书和个人IP。</p>\n  <p>不过，在两千人的大会场，当视频号讲师展示三张女主播照片，问台下谁是“视频号一姐”时，出声作答的人寥寥无几。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_22fc8159436446c488fc08ae74456f54@10269314_oswg748222oswg960oswg720_img_000?x-oss-process=image/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">36氪摄影</p>\n  <p>这群过去主做抖音的操盘手们对视频号是陌生的。“今天在场的两千个操盘手，还有百分之七八十的人根本没有入局视频号，但是愿意用两天来学。”刘思毅说。私董会将带领大家逐帧学习头部主播，随后，他把“抄”字大大地打在会场PPT上。</p>\n  <p>大会的一个重头环节，是刘思毅在台上带着两千人逐字逐句分析张小龙2021年的演讲。因为张小龙已经久不在公开场合露面发言，所以这份演讲稿几乎成为了《红楼梦》甲戌抄本一般的传世经典，被“龙学家”们翻过来倒过去地解读。</p>\n  <p>“我叫张小龙爷爷，因为你们是我爸爸，而张小龙也是你们的爸爸，所以说张小龙是我爷爷。”刘思毅以他高于一般人声量的嗓门举着麦克风大声说：“每一个私域操盘手，请都叫张小龙爷爷！因为张小龙爷爷的价值观和一举一动，会决定各位能不能赚钱！”</p>\n  <p>台下没有人笑。</p>\n  <p>私董会、企业家社群、商业俱乐部等等一切与之大同小异的组织，其实都是观察商业社会的显微镜。今天讲师展示一个爆品，明天许多直播间里就会出现同款；今天讲师展示一种投流技巧，明天电商老板们就能快速共享一波红利。</p>\n  <p>流量在哪里，这群老板就在哪里。</p>\n  <p>但字节跳动和腾讯是两家截然不同的公司。狠狠花钱，再拼命挣钱，是字节跳动从上到下的共识，这催生了抖音生态内巨大、快速、确定性的赚钱机会。但在腾讯内部，用户思维和商业化欲望共同左右着视频号的走向，甚至前者更占上风，这让赚钱的机会没那么确定。</p>\n  <p>而这种“不确定”，恰恰成了私董会的机会。</p>\n  <h3><strong>视频号的不足，私董会的商机</strong></h3>\n  <p>“我这个门，没有几万块钱进不来。”李柔指着自己的新办公室门说。然后她一指周围人说：“他们都是交了钱的人。”李柔的保时捷就停在楼下。</p>\n  <p>李柔是一位身处中国西南部某城市的私董会老板，为想做视频号的老板们传授经验、答疑解惑。</p>\n  <p>她也做直播电商，在抖音上赚了几年“轻松钱”，办公室也从之前又暗又旧又闷的老楼，摇身一变为如今的窗明几净。只是她的员工们看起来却不像白领，闹闹哄哄，总有人跑来跑去，搬设备、念口播、录视频，氛围热火朝天。</p>\n  <p>几个付了几万才进来的学员，苦于无法在这种气氛中捉住李柔说几句话，只得坐在一旁从白天等到黑夜。</p>\n  <p>李柔的会员多是在电商圈里打滚的老江湖，在微信视频号上，他们最关心，也最弄不清的，是如何解决限流、封号、投流效果差等等问题。简单来说：就是“什么不能做”。</p>\n  <p>伴随着微信视频号2023年交易额的3倍增长，它的管理也越加严格。从今年4月开始，“微信视频创作安全中心”每月发布违规处理公告，封禁视频号的数量从每月数千量级，很快增长到过万。</p>\n  <p>李柔的商家群里哀鸿遍野，她自己也未能幸免。</p>\n  <p>“我的公司昨天一天被封了好些账号，一整层楼没有一个账号是正常的。”李柔说，“经常是一个账号违规，导致一条网线甚至一个基站下所有的账号‘连坐’。</p>\n  <p>找到视频号的人不容易。之前，花了广告费的商家还能绕道去找腾讯广告，让他们帮忙答疑。不过，在7月腾讯广告优化了从事带货运营和商业治理工作的团队后，这项工作彻底被移交给微信事业群。很快，就有不少商家向36氪反映，海量问题堆积给视频号的官方人员后，对方无暇人工处理。</p>\n  <p>“我们账号莫名其妙出了问题，在群里找小二，只有机器人回复。”一位商家说。“要想走人工通道，还要排队。最久的一次我们等了7天。”</p>\n  <p>“腾讯的人是很死板的，”李柔用略带夸张的语气说。“你只能问他我这个账号什么情况，对方就只会回答你两个字，‘实锤’或‘误判’，你问他哪个地方实锤？他不告诉你，没时间理你。”</p>\n  <p>这个时候，商家们就需要私董会出现，扮演一个导师，和一个“替自己说话”的话事人。</p>\n  <p>不少私董会都会重点介绍，自己有“腾讯系离职”的讲师，或者是私董会主理人本人有腾讯内部的人脉。</p>\n  <p>“你们不能再刻意制造矛盾了，吵架的内容是不会给流量的。”一位腾讯广告出身的私董会讲师说。商家恍然大悟，说“完了，我跟他（指着身边的合作伙伴）最近正在直播间扮演一对小夫妻，通过吵架来带货。”</p>\n  <p>这一点拨，就节省了商家的时间和金钱。相比之下，商家为获得点拨而付出的几万块学费就不算什么了。</p>\n  <p>如李柔所说，一个平台的电商业务从小到大，通常都有一个规矩从松到严的过程。先把闸门打开，让第一波商家成长起来，把用户的兴趣标签打起来，随着广告越来越精准，用户也养成了消费习惯，平台再强调合规，给商家立规矩。</p>\n  <p>但是视频号不是这样。从视频号开始电商业务的第一天起，就呈现“一夫当关，万夫莫开”的局面。视频号官方一直保持着很小的团队，主持着很严格的规则。</p>\n  <p>所以才有这个差别: 在抖音小红书主题的私董会大课上，大家更关心“怎么做”、“如何发财”，但在视频号主题的课上，大家最关心“不能做什么”。</p>\n  <p>抖音电商业务在发力伊始的2020年，定下“3年内在上海增员2万人”的目标，并花数十亿一举在上海杨浦区买下19.5万平方米的办公项目，用来安置庞大的抖音电商团队。</p>\n  <p>从2020年的“视频号电商元年”到“微信小店”终于上线，大家等了整整4年。四年后，视频号仍然只用一支数百人的小团队，做抖音用一整栋楼在做的事情。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_b8eb862ca25e4f6f97c079acf18c1269@10269314_oswg168228oswg1080oswg844_img_000?x-oss-process=image/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">字节跳动电商业务所在大楼</p>\n  <h3><strong>腾讯不是字节，视频号不是抖音</strong></h3>\n  <p>“微信有这么多的用户，为什么不去把电商生态做得更健全一点？可能是他怕影响他的用户。”李柔说。“电商生态和用户体验，是两条背离的路线。如果要做电商，也许会伤害一些用户的体验。问题就是，腾讯不愿意去做这个事情。”</p>\n  <p>一位商家对36氪说，在与视频号官方人员接触的过程中，对他们的印象就是8个字：不求有功，但求无过。与其说小二们的目标是让商家赚更多钱，不如说他们更在乎“不要出乱子”。</p>\n  <p>有腾讯内部人士透露说，当腾讯广告部门每周与视频号团队开会时，常常会提出“做个金融专题”或“做个大健康专题”之类的议案，以吸引相关行业的金主投放广告，而视频号团队通常会拒绝这类需求。</p>\n  <p>而且，视频号一直都保持着极低的广告加载率，年轻用户通常在停留40分钟之后才会收到广告，这是远低于其他同体量平台的。今年5月，腾讯首席战略官詹姆斯·米歇尔称，视频号广告加载率只有其他主流短视频产品的1/4左右。</p>\n  <p>一种巨大的撕裂产生了——当你去研读腾讯财报，会发现每一季度的电话会议上，腾讯高管们都强调视频号的成长空间；但当商家真正去跟视频号团队发生业务交集时，又会发现他们“过于佛系”。</p>\n  <p>虽然商家们会抱怨今天视频号的爆发力不如早期的抖音，但他们确实已经不需要第二个抖音，把从盛到卷再到衰的流程再走一遍——腾讯也清楚这一点。</p>\n  <p>今年Q2的财报电话会议上，腾讯公司总裁刘炽平说，传统的直播电商存在一个自然的增长上限，而腾讯对抗这一“自然衰退”的方式，就是“构建一个生态系统，使其区别于单纯的直播电商。”</p>\n  <p>刘炽平在电话会议上说：腾讯“重新定位了直播电商业务，使其更趋近于微信电商。”也就是说，腾讯要做的不是第二个抖音电商，而是一个前无古人的产品。</p>\n  <p>但是，每过一阵，都会有一些受不了缓慢增长和严格规则的商家离开；但同时，留在生态内的商家，又乐于享受“内卷不起来”的环境，盛赞视频号的良好氛围。</p>\n  <p>在这样复杂的局势中，作为一个普通商家，想要在视频号获得安全感太难了。那么提供安全感，就成了这些私董会、商业社群、企业家俱乐部的共同责任。</p>\n  <p>首先，私董会的主理人们，承担了像心理医生一样“作出解释”的责任。</p>\n  <p>“今天的腾讯，如果没有游戏业务、广告业务、金融业务，肯定会拼了命地把电商业务做起来。”李柔对她的学员们说，“但今天腾讯的选择太多了，这家公司更担心的不是增长慢，而是出乱子。”</p>\n  <p>以及，像刘思毅、铁头梁以及其他非常多的私董会主理人一样，李柔也会向她的学员们解读张小龙。</p>\n  <p>“张小龙是产品经理出身，他的思维不是商人思维，而是产品思维。”李柔说。“只要你不伤害他的用户，留在生态里，等他判断时机OK的时候，自然就会给你机会的。”</p>\n  <p>这类的话，在36氪调查期间，听过数不清多少次。研读张小龙，就是寻求确定性和安全感的一种表现。几乎没有一个视频号的创业者，在跟你谈论视频号的未来时，会不谈张小龙、不引用张小龙。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_dbfb0804b6bc425f994dbfa8f237624d@10269314_oswg782484oswg959oswg720_img_000?x-oss-process=image/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">36氪摄影</p>\n  <p>但是张小龙的演讲稿还是太少了，一个合格的私董会主理人，要有自己“制造信心”的能力。</p>\n  <p>“你不下牌桌，就一定有机会！”李柔说。“而且我们经历了这么多年腾讯的起伏，知道腾讯肯定是要做电商的，这只是一个时间问题。”</p>\n  <p>铁头梁也在用他自己的方式，给员工和学员们制造安全感。在那场2000人的大会上，他在大屏幕上亮出了一张照片，引发全场人心照不宣的笑声。</p>\n  <p>那张照片是他直播间的一面墙，墙上挂了一幅腾讯集团CEO马化腾的照片，左联“私域承接不封号”，右联“公域引流天天爆”，横批“化马腾飞”。</p>\n  <p>现在，每天开播之前，他都会带着全体员工对着照片拜一拜，并且把这一招也教给了他的学员们。</p>\n  <p>“有人学着我拜了，当天的销量真的就上去了。”铁头梁说。“如果你也实在想不通问题在那儿，就试试玄学吧。”</p>\n  <h3><strong>要在视频号上岸，做个好人吧</strong></h3>\n  <p>去年，余白花了将近200万加各种私董会。他对胡鼎说：“3万块以下的群你随便帮我拉，5万块以上的群我要稍微斟酌一下。”很快，他就靠对这些精准客群销售一款全球知名的减重产品而回本。</p>\n  <p>胡鼎能帮余白做这件事，因为他是私董会云林学社的创始人之一，而且他本人也花真金白银买了非常多私董会、商学院、企业家俱乐部等等的入场券。他跟他的合伙人光在交学费上，就花了600多万。</p>\n  <p>不过，许多会员他买过之后，一次活动也没去过，因为真的很忙。在工作稍微有些间隙的时候，胡鼎就有一大堆“欠下的课程”要处理。</p>\n  <p>胡鼎并不是富二代，但他盖着浙江人的思想烙印。“我从来就没有一天想过我要去给别人打工。”胡鼎大一就辍学创业，他说，“从小我父母对我的教育就是，你可以读不好书，但是不能不会做生意。”</p>\n  <p>过去几年，胡鼎在各家私董会见证了太多人踩在时代红利上突然起飞，然后又销声匿迹。这群人有更强的不安全感，更希望找到跨越周期的答案。</p>\n  <p>李柔就是这样。她本人吃到了好几波投机红利，从公众号，到广点通广告，到朋友圈，再到视频号初期，过了几年“简直是捡钱”的日子。</p>\n  <p>“经历了几轮电商平台的迭代之后，你会发现其实每个电商平台都一样，刚开始我们进场时间早，就快速地挣了钱，但随着电商平台越来越规规范化，利润就会变得非常少。”李柔说。</p>\n  <p>她的旧办公室看起来黄、旧且闷热，人在电梯里一会儿立着不动，就会被蚊子叮两个大包。“我们刚开始起家的时候就在老办公室做，那边就土一点。其实做电商就是这样，装修的太豪华，容易死掉。”李柔说。</p>\n  <p>在电商平台监管不严的早期时代，许多商家惯于使用浮夸的广告+巨额投流+杂牌货的组合拳。但是那样的日子已经结束了——投抖音ROI达不到1:1的惨案发生得也越来越频繁。</p>\n  <p>投机的机会没有了，投机者去哪呢？</p>\n  <p>“我们已经见证了抖音红利的从有到无。大家有没有想过，如果以后视频号的流量红利没了，我们该怎么办？我经常在深夜问自己这样一个问题。”铁头梁在刘思毅的大课上压轴演讲，他这样问在场的观众。</p>\n  <p>今年，直播电商GMV增长失速，许多商家都尝到了从风口上掉下来的失重感。公域的流量总会从贱到贵，从有到无。如果继续把视频号的流量耗尽，还能去哪呢？</p>\n  <p>“如果有一天视频号的流量红利也没了，下一步就是私域。”铁头梁说。那个他经常在晚上思考的问题，可能只有一个答案。那就是趁着视频号还在成长，把公域的流量抓到自己的私域来，与这些用户建立牢固的信任关系，从而不断重复下单。</p>\n  <p>铁头梁团队伙伴曾经也“走过捷径”。最开始测试视频号的时候，被封了多达100个账号。搞过无人直播测试，做过搬运混剪测试，也测试过质量不那么好的货。但是最后都放弃了。</p>\n  <p>现在，在他的私董会“梁山会”的大课上，他劝大家“在视频号，做个好人”。</p>\n  <p>“我的建议是，大家如果在视频号里想做正向循环，就老老实实，安安心心地做私域，做流量，做好产品，做高客单价，因为这种人群才是最有价值的。”铁头梁说。</p>\n  <p>劝大家这么做，有两个原因：一是因为微信的私域属性，视频号受众更依赖信任关系，也更愿意为高品质多付费，确实不适合再搞以前那一套；二是许多投机者真的把视频号，把向来更宽容、更让利的微信视作人生“对抗周期”的机会。</p>\n  <p>他们不甘心再打一枪换一个地方。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_51a63fbbbf6841e8a67b2085e9ffa357@10269314_oswg1143081oswg959oswg720_img_000?x-oss-process=image/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">36氪摄影</p>\n  <h3><strong>天派地派，沟壑纵横的中国</strong></h3>\n  <p>一个私董会会员曾跟会里的其他200个老板去某个城市旅行。他发现，起初，200个人都在1个群里没有分组，但他发现，大家很快就形成了自然分化——到聚餐的时候，十亿跟十亿的人坐到了一桌，一亿跟一亿的人坐到了一桌，千万跟千万的人坐到了一桌。</p>\n  <p>不同圈层的人，关注的问题是不一样的。在视频号这个赛道，分化也更加显著。</p>\n  <p>一个私董会往往吸引的是同类人，有的面向拧螺丝出身一夜暴富的操盘手，有的圈子是名校毕业经商世家的老钱或富二代。本来这两类私董会井水不犯河水，但视频号这个“卷入所有人”的战场把双方赶到了一起，有主理人在活动上公开批评其他私董会，说对方粗野、不尊重客户、价值观有问题，引发舌战。</p>\n  <p>“有些私董会的主理人本身就是做小生意出身的，他们拿到流量之后，再去吸引跟他一样的小老板。”王博轩把这些草莽电商人群定义为“地派”。“地派”们的草莽电商打法虽然在视频号也能延续，但视频号上特有一些属于“天派”的空间。</p>\n  <p>王博轩定义自己的社群Newmoney则为“天派”，因为他的人脉来自于在一线财经媒体接触的公司老板，他们不会教这些老板们“如何钻平台的空子”，也不需要帮他们去找人解决封号问题。他要做的，是帮他们了解如何用视频号把他们原本已经成功的事业变得更成功。</p>\n  <p>比如，一个做桥梁生意的老板，在竞标政府的桥梁订单时频频获胜。他的小秘诀就是——每逢公务员上班时间，就在视频号上推送自己的广告，让筹备竞标的工作人员总能看到自己的品牌，然后竞标时就不知不觉地比同行优势大一些。</p>\n  <p>“这是视频号上才有的熟人或者半熟人生意，是抖音或者小红书做不到的。”王博轩说。“我这儿的老板们不是要当网红。他们是在向过去的积累要结果。”</p>\n  <p>一个人，一张桌，对着镜头说三分钟。偶尔“出外景”，就是拍拍工厂和流水线。很多企业老板的个人视频号，场景都千篇一律，播放量几百。但他们并不在乎播放量，只想撬动微信里成百上千个上下游的合作伙伴，收获精准的生意线索。</p>\n  <p>王博轩觉得乐观，这样打破认知的案例还有很多，每天都有新消息。李柔的“地派”会员们，却为新环境迟迟不进化而感到焦虑。</p>\n  <p>“中文互联网，是一个信息鸿沟巨大的世界”。铁头梁在群响的活动上，对着台下的2000个人说。“在座的各位，其实你们已经领先了。今天的中国还有很多人根本不知道视频号是什么东西，甚至从来没体验过电商。你的认知，代表不了中国人的认知。”</p>\n  <p>他见过有人削尖脑袋钻平台的漏洞，研究怎么才能绕过监管快速卖出一批垃圾货；见过有人靠在直播间里跳舞、聊天，招来打赏千万；也见过有人利用舆论情绪，批量生产内容偏颇的短视频，然后转眼开播带货。</p>\n  <p>如果不能正确地认识中国的复杂性，就理解不了视频号的谨慎和缓慢，也自然看不到其中的机会。“对那些认知已经遥遥领先的老板们来说，在今天唱衰视频号没有意义。”铁头梁说。</p>\n  <p>“不要急！张小龙说：慢慢走，比较快。”刘思毅在大会上再次引用张小龙。试图安抚那些在微信慢慢走的这三年里，积压了越来越多的期望和失望的老板们。</p>\n  <p>焦虑之余，在微信慢慢走的节奏里，老板们只好进行自我心理疏导。</p>\n  <p>研读张小龙讲话当然是一种显学。不过，36氪发现，在客户资产规模较高的“天派”私董会中，普遍流行研读《毛选》——有的是主理人与好友小规模“共读”，有的是干脆组织大课开讲。</p>\n  <p>余白把这阵《毛选》热想得很明白。“这其实是一种‘爽’课。因为你再苦苦不过毛主席，你遇到困难再大也大不过毛主席。我们中的大多数人其实挣的钱都不知道怎么挣的，说白了就是赶上了。”余白说。</p>\n  <p>年轻的朋友们则求助于命理。</p>\n  <p>蓝茵所在的私董会的会员，大部分是靠短视频红利成长起来的年轻创业者。在一次大课结束后的晚饭上，蓝茵问在场学员，是否相信紫微斗数。在场的所有人都举手表示相信，其中八成人是95后。蓝茵见状，笑笑分享了自己的“命盘”。</p>\n  <p>“如果算出来命好，那就信命。如果算出来不好，那就去他妈的。”蓝茵说。在场的年轻人们一起开怀大笑。</p>\n  <p>“这一代人经历了太多轮红利，但是，属于下一代创业者的红利在哪里呢？”26岁的胡鼎发问。</p>\n  <p>有人说，是AI。但AI的门槛听起来太高了，现在的AI离成为一个“给所有人机会”的暴富时机也太远了。</p>\n  <p>相比之下，“劳动密集型产业”的视频号看起来才更像“能给所有人一杯羹”。</p>\n  <p>所以，视频号的成功，不会只是一个巨头公司的成功，不会只是腾讯股价拉升的希望，它身上还寄托了太多人的财富期待。</p>\n  <p>去年3月，铁头梁对36氪说：“我就喜欢看到别人骂视频号。他们越说这里没机会，我越高兴。这代表他们不会来跟我抢。我想当沙漠动物。不能在江河湖海里称王，能在沙漠里称王也很好啊。”</p>\n  <p>今年9月，我再次向他提起这句话，他说，他已经感受到了雨水，现在沙漠里已经有了绿洲。</p>\n  <p>在沙漠中盼甘霖的不止铁头梁。李柔决定干私董会的一个主要原因，就是为了在社群里物色合适的视频号项目，然后，投资他们，让打湿别人的雨水也打湿自己。</p>\n  <p>“风口来的时候，就像下暴雨。你只拿一个锅，根本就接不过来。所以你要做的，就是想办法把锅给弄多，让别人的锅也能为你接雨。”李柔说。“现在嘛，是雷阵雨，一会儿下雨一会儿烈日。但我相信，后面肯定还有更大的雨。”</p>\n  <p>（本文李柔、蓝茵、余白为化名）</p>", "published": "2024-10-31 04:02:37", "id": "11dee4eb-459a-44cb-8f85-4151a049acdc", "source": "36氪", "section": "综合资讯"}, {"title": "Stellantis集团第三季度净营收同比下滑27%", "link": "https://36kr.com/newsflashes/3016230052505090?f=rss", "description": "10月31日，Stellantis集团发布财报显示，第三季度实现净营收33亿欧元，同比下滑27%，这主要是由于出货量的减少、不利的结构差以及产品定价和外汇所带来的影响。第三季度，集团不含旗下合资企业的出货量为114.8万台，同比下滑20%。集团重申于9月30日更新的2024年度全年财务业绩预期：调整后经营利润率为5.5%至7.0%，工业自由现金流为负50亿欧元至负100亿欧元。（界面）", "published": "2024-10-31 09:47:52", "id": "b3ba9622-1657-4982-9e07-1b48f8d17bdf", "source": "36氪", "section": "综合资讯"}, {"title": "世茂集团：前三季度营业收入约39.87亿元", "link": "https://36kr.com/newsflashes/3016209064060418?f=rss", "description": "36氪获悉，世茂集团公告，2024年前9个月营业收入约为39.87亿元，上年同期约为33.94亿元；归属于上海世茂所有者的净亏损约27.24亿元，上年同期归属于上海世茂所有者的净亏损约21.26亿元。", "published": "2024-10-31 09:26:31", "id": "d071d43f-4501-40a2-aed5-938d17845fb6", "source": "36氪", "section": "综合资讯"}, {"title": "科氪 |荣耀Magic7系列发布：开创AI智能体新纪元，重塑智能手机未来", "link": "https://36kr.com/p/3016182774048001?f=rss", "description": "<p>2024年10月30日，荣耀于深圳正式发布了年度AI旗舰手机——荣耀Magic7系列，这不仅标志着智能手机行业正式迈入AI智能体时代，更是一次对智能手机未来发展方向的深刻探索与重塑。凭借独树一帜的创新理念与卓越技术实力，以及领先行业的AI能力，荣耀Magic7系列重新定义了智能手机的想象力边界。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_731ae43b2ef74b1cb1a0a383e6d3f740@517825446_oswg1017596oswg1280oswg853_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">官方图片</p>\n  <p>荣耀终端有限公司CEO赵明表示：“AI毫无疑问是现在最引人注目的科技魔法，但荣耀很早就看到了AI让手机进化的魔力，我们坚信AI是智能手机的未来。从拍照、屏幕、续航到通信，我们用AI魔法使能和重构⼀切，包括操作系统。荣耀Magic7系列将会是引领未来的AI手机。”</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_0f5598f35ddc4104804ec9e56abcb6cf@517825446_oswg362996oswg1269oswg423_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">官方图片</p>\n  <p>作为集荣耀AI技术创新大成之作的旗舰手机，荣耀Magic7系列在系统、影像、屏幕、通信、续航、性能等多个维度，均实现了AI全面赋能的革新。尤其在搭载荣耀自主研发的YOYO智能体之后，可实现自动执行、一语到位的高阶智慧能力，为用户带来了颠覆性体验。</p>\n  <p>据了解，荣耀Magic7系列首发搭载的MagicOS 9.0的AI大模型能力，获得中国信通院权威行业认证，获颁泰尔测评证书卓越级；在中国信通院颁发的终端智能化分级能力证书中，首发搭载MagicOS 9.0的荣耀Magic7系列通过《终端智能化分级测试方案》评估，终端智能化水平达到行业目前最高等级L3。并且荣耀也是业内唯一一家达到该智能化水平的终端厂商。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_1d84e57d590e48449eb357de27a04f15@517825446_oswg560886oswg1269oswg423_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">官方图片</p>\n  <p>在智能手机市场面临创新瓶颈的当下，荣耀Magic7系列的发布，不仅是对智能手机未来的深刻探索，更为行业注入了新的活力与灵感。以荣耀为代表的中国企业，终于站在了AI浪潮的前列，率先进入了智能手机的”自动驾驶”时代。</p>\n  <p><strong>用真AI开启智能手机的“自动驾驶” &nbsp;</strong></p>\n  <p>在AI手机元年拉开序幕的2024年，几乎所有的旗舰新机和操作系统都纷纷打出了“AI化”的旗号，市场上充斥着各种声称具备AI功能的手机和操作系统，各种新功能也都纷纷冠以“AI”之名。然而，荣耀Magic7系列却凭借其深入底层的AI技术创新，真正树立了AI手机的里程碑之作，开启了AI手机“自动驾驶”的新时代。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_22a6d95ea1dd46d8afa58c040651554f@517825446_oswg314348oswg1269oswg423_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">官方图片</p>\n  <p>目前，多数手机厂商仍然以嫁接式的生成式AI服务作为其可以被称作“AI手机”的理由，但此类AI能力更多是通过开放接口，将大模型技术集成到手机的具体应用中，如照片编辑、语言翻译、记笔记、发短信、搜索等。然而，真正的AI手机所追求的，绝非仅限于这种“应用层AI”的浅尝辄止，而是要用AI从操作系统的底层开始，彻底重构服务逻辑、业务流程和资源分配，超越现有以应用程序为基础的操作系统框架。</p>\n  <p>在荣耀看来，真正的AI手机需要用AI技术全面重塑底层的硬件和操作系统，从用户体验到业务逻辑的每一个细节，都需经历深刻的变革。荣耀Magic7系列搭载业界首个实现商业化落地的AI智能操作系统MagicOS 9.0正是平台级AI能力的真正体现。</p>\n  <p>荣耀Magic7系列通过全新的YOYO智能体，实现了纯AI视觉、无需生态适配的任务自主执行新突破。无论是单一指令的系统级任务，还是第三方应用任务，甚至是多应用的协同执行，YOYO智能体都能游刃有余地处理。从“一句话点咖啡”到“一句话关闭应用权限”，YOYO智能体以精准的理解和自动执行，为用户带来了前所未有的便捷体验。这一创新不仅改变了“人理解手机”和“人找服务”的传统模式，更让手机拥有了自主行动力，率先引领智能手机从“手动驾驶”迈入“自动驾驶”的新时代。</p>\n  <p>此外，YOYO智能体还能根据当前屏幕内容，主动提供智慧服务，如英文翻译、文章摘要、日程创建等，实现多轮、多意图、全屏意图的主动理解与响应。这种智能化的服务方式，不仅提升了人机交互的便捷性和效率，更让用户感受到了仿佛“自动驾驶”般的智能体验。</p>\n  <p>除了前沿的AI体验外，荣耀Magic7系列在数据安全与隐私保护方面也展现出了卓越的能力。通过创新的端侧AI换脸检测技术和系统默认守护模式，荣耀Magic7系列能够实时分析视频通话，准确识别并预警AI换脸风险，且所有检测均在本地完成，确保用户信息安全无虞。</p>\n  <p><strong>里程碑式的AI旗舰，全面赋能硬件</strong></p>\n  <p>AI作为核心基石，深度融入手机的每一个层面，方能称之为真正的AI手机。在这一新兴领域中，AI手机需通过智能技术无缝链接软硬件，确保每台设备都能根据用户的独特需求，转化为专属的、高度个性化的超级智能伙伴。依托其强大的平台级AI能力，荣耀Magic7系列手机不仅在操作系统层面实现了质的飞跃，更在摄影、显示、通信、电池续航、性能优化及音频体验等多个维度，带来了颠覆性的提升与智能化变革，重新界定了智能手机的极限。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_a5a9cb903123428c972ad3dc156d75b3@517825446_oswg721141oswg2286oswg810_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">官方图片</p>\n  <p>在影像技术领域，荣耀Magic7系列搭载了开创性的荣耀AI驭光引擎，将拍摄与后期处理巧妙融合。同时在AI技术的助力下，荣耀鹰眼相机与舞台模式实现了更为精准、高效的拍摄表现。这种前所未有的软硬协同能力，不仅突破了当前移动影像技术的瓶颈，更为整个行业开辟了一片由AI引领的移动影像新天地。</p>\n  <p>在屏幕护眼方面，荣耀Magic7系列开创性地搭载了业界唯一的全局全天候荣耀AI自然光绿洲护眼屏，该技术通过平台级AI算法，精妙地模拟自然光，从波动、亮度、节律、色彩、频闪和光谱六大维度进行全面优化，集成了圆偏振光护眼、4320Hz超高频PWM调光、类自然光护眼、自然色彩显示、硬件级低蓝光、AI离焦护眼技术、AI干眼友好技术、AI助眠显示功能的八大护眼技术，这标志着手机屏幕护眼技术迈入了一个崭新的时代。</p>\n  <p>在通信技术领域，荣耀Magic7系列的荣耀优速通功能凭借AI智能识别网络拥堵场景，实现专线加速，显著提升网络流畅度。荣耀Magic7 Pro首次搭载荣耀通信芯片 HONOR C2，全面覆盖36种用户通信场景，实现更佳信号表现，行业首发双Wi-Fi芯片，可实现双Wi-Fi聚合下载，通过调用主Wi-Fi芯片2.4GHz和5GHz以及HONOR C2备份Wi-Fi芯片的5GHz频段，在咖啡、酒店、商场、校园网、公司等限速场景下， 应用市场、王者荣耀更新下载等可以带来更快的下载体验，缩短用户等待时间。同时，荣耀鸿燕通信也借助AI技术对卫星通信功能进行了优化，确保实机使用的稳定性和易用性。</p>\n  <p>在电池续航方面，荣耀Magic7系列搭载的全新升级的第三代青海湖电池技术和自研能效增强芯片HONOR E2，重塑续航边界，让每一份电量都充满智慧与力量。通过尖端硬件与智能AI算法的深度融合，进行全方位、多层次的能效优化，实现了荣耀Magic7系列的超长续航能力。值得一提的是荣耀Magic7 Pro推出了行业首创的第三代三极耳技术，这一创新设计提供了最佳的10%硅碳负极+100W有线+80W无线快充综合解决方案，实现了高能量密度和快充能力的极致均衡设计。在性能方面，骁龙®️8至尊版移动平台与荣耀AI技术的深度融合，充分激发了端侧AI的潜能，为产品创作和生产力提升注入了澎湃动力。同时，散热系统也在AI技术的优化下，达到了业界领先的散热效果。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_46d887825c224360bc7de59702669be1@517825446_oswg509000oswg1269oswg423_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">官方图片</p>\n  <p>荣耀Magic7系列的问世，标志着荣耀正带领行业向更智能、更人性化的未来挺进，触发了一场由荣耀主导的“荣耀效应”变革，凭借AI与硬科技的双重引擎，荣耀正加速推动整个行业向新高度进发。</p>\n  <p><strong>独立四周年&nbsp;荣耀艰难而正确的路径迎来开花结果</strong></p>\n  <p>在发布会现场，一张意味深长的图文：“用自己的名字，去自己的远方”，被外界视为荣耀独立四周年的真实写照。自从独立以来，荣耀选择的是面向未来的“创新引领”路线，站在明天看今天，以此不断牵引带动国内产业价值链条攀升，相比行业盛行的拿来主义、看重短期利益的“创新变现”做法，这注定是一条艰难但是正确的道路。时至今日，荣耀的坚持已经逐渐开花结果。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_64ea939b634247e8bd6cabc591789f99@517825446_oswg1592706oswg2386oswg792_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">官方图片</p>\n  <p>第三方机构预测，荣耀即将迎来的是一次井喷式的历史机遇：面对生成式AI手机市场预计的爆发式增长——IDC预测2024年出货量将激增364%至2.342亿部，2028年更将达到9.12亿部的广阔蓝海。荣耀凭借深厚的技术底蕴与不懈的创新追求，蓄势待发，准备继续引领智能手机行业的未来走向。</p>\n  <p>荣耀Magic 7系列堪称是荣耀技术创新的集大成者，不仅在AI能力上实现了断档式领先，也巩固了荣耀在高端旗舰市场的领先地位。这一旗舰系列的问世，背后是荣耀在端侧AI领域多年的深耕细作与不断突破技术界限的坚持。</p>\n  <p>早在2016年，荣耀便以前瞻性的布局，从系统底层开始构建全面的AI技术优势。从第一代荣耀Magic系列智能手机搭载荣耀Magic Live智慧引擎，到2018年荣耀Magic第二代启用自进化、自学习的智慧生命体YOYO，再到2022年底发布AI使能的个人化全场景操作系统MagicOS 7.0，荣耀在AI技术的探索上从未停歇。2023年，荣耀更是首次提出将AI大模型引入端侧，进一步推动了AI技术在智能手机领域的应用。2024年，荣耀首次提出AI的四层架构，为智能终端的发展提供了清晰的路径。如今，随着荣耀Magic7系列的发布，荣耀YOYO智能体再次实现了端侧AI的创新叠加效应和用户体验增值，标志着智能手机行业正式迈入智能体时代。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_243adb2857b7492782fd3872e6d9d47d@517825446_oswg216695oswg1269oswg423_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">官方图片</p>\n  <p>荣耀AI的成功并非偶然，背后是其在技术研发上的坚定投入。2023年，荣耀整体研发投入占到总营收的11.5%，AI研发费用累计已达100亿，AI专利成果达2100篇，其中AI意图识别相关专利就有600类。同时，荣耀持续加大AI高精尖人才的招聘力度，近两年校招博士浓度高达36.2%，且对顶级AI人才薪酬不设上限，为公司的持续创新提供了坚实的人才保障。</p>\n  <p>&nbsp;</p>\n  <p>并且，荣耀的技术创新并不仅限于AI领域。在通信、续航、屏幕、玻璃、影像以及折叠屏等多个领域，荣耀同样取得了显著的领先优势。从鸿燕通信技术的突破，到青海湖电池技术的革新，从绿洲护眼屏的推出，到巨犀玻璃的应用，再到鹰眼相机的问世，荣耀不断为智能手机市场带来新的亮点与惊喜，为行业提供了极具价值的解决方案，推动了智能手机技术的全面发展与进步。</p>", "published": "2024-10-31 09:02:07", "id": "e3be35b7-d8f2-45b2-bde8-35af53abcae7", "source": "36氪", "section": "综合资讯"}, {"title": "「临科智华」完成2300万元种子轮融资，明年预计营收1.5亿元 | 36氪首发", "link": "https://36kr.com/p/3013441972348416?f=rss", "description": "<p>文 | 田哲</p>\n  <p>编辑 | 苏建勋</p>\n  <p>36氪获悉，临科智华近日宣布完成2300万元种子轮融资，投资方为谦益资本。本轮融资资金，临科智华将用于团队建设、技术研发，以及人工智能核心技术基础建设。</p>\n  <p>临科智华成立于2024年，以人工智能最重要的部分“高质量数据”为核心，致力于为各行业公司提供数据智能解决方案。据悉，临科智华核心团队拥有十年以上人工智能数据服务经验，其CEO王旭辉为美国Scale AI核心科学家、美国计算机学会会员、国际人工智能学会会员。</p>\n  <p>随着AI和大数据技术的逐渐成熟，越来越多的传统行业开启智能化转型。然而，企业在智能化转型过程中，可能会出现异构数据统一难、研发成本高、安全风险高等难题。此外，构建智能化系统的过程中，需要大量算力、存储、云服务等基础设施，这对企业来讲成本较高。智能化过程需要专业的技术人才、运维和产品人员，这是传统企业所不具备的。</p>\n  <p>临科智华的解决方案正是解决这一痛点，其采用数据处理引擎和硬件系统的结合模式，为企业客户提供数据智能解决方案。这将是一个潜力巨大的市场，数据公司IDC指出，2024-2028年，中国企业开发和运营数字化业务相关的ICT支出总额将达到2.99万亿美元。</p>\n  <p>临科智华CEO王旭辉告诉36氪，针对日益庞大的市场需求，临科智华推出了训推一体机「曦华智驱AW2000」，其搭载多款自研人工智能大模型和垂直领域系统， 可以适配各行业的定制化需求，快速适配各行业需求。</p>\n  <p>据悉，AW2000采用气液两相散热技术，在保证AI算力的情况下，可降低对IDC机房的要求，可以部署在企业内部，保证数据私密与安全性。自研模型通过智能调度算力，从而大幅降低算力消耗，提升GPU利用率。&nbsp;</p>\n  <p>此外，临科智华的模型训练架构支持多模态架构，使用各种训练、推理加速技术，高效支持多模态需求。并能够根据企业业务需求进行定制，满足不同场景下的智能化需求。&nbsp;</p>\n  <p>系统方面，临科有四大平台：异构算力平台、大模型基础平台、低代码智能Agent平台，临科多模态数据标注处理平台。临科智华通过这四大平台为各行业不同客户需求提供智能系统全链路解决方案</p>\n  <p>目前，临科智华的服务客户涵盖自动驾驶、智能客服、智能制造、教育、智能医疗等场景。</p>\n  <p>据悉，临科智华正在构建千卡超算中心，以满足大规模AI计算需求。该超算中心将集成业界尖端的计算资源，拥有处理海量数据集与复杂计算任务的能力，以支持地方科研机构及企业用户。</p>\n  <p>王旭辉表示，临科智华计划在未来两年内拓展其在制造、金融、教育等领域的市场份额，进一步赋能各行各业，让AI真正在各行各业落地，发挥更大的作用。预计明年，临科智华将实现营收1.5亿元。</p>", "published": "2024-10-31 01:00:00", "id": "c6efa3ec-43bc-496c-9435-58942b1f2c44", "source": "36氪", "section": "综合资讯"}, {"title": "一年服务千万亩次，觉物科技让农业机械化更精细｜早期项目", "link": "https://36kr.com/p/3015729080198405?f=rss", "description": "<p>作者｜叶丹璇</p>\n  <p>编辑｜袁斯来</p>\n  <p>农业机械化第一次进入中国时，第一台拖拉机把“耕地不用牛”的理念拉进了中国的田间地头。</p>\n  <p>农业机械化和智能化时代的到来，使得越来越多的农机新设备开始进入农业生产的环节。伴随着这一农业新浪潮的，是另一个尖锐的事实：农业生产人口正在下降。根据第三次全国农业普查信息，当前农业劳动力基本是1990年之前出生，且以1960年之前出生的老人为主。经学者测算，2030年，我国的农业劳动力将会减少20%甚至更多。</p>\n  <p>与农业老龄化问题相伴相生的是，目前我国的农业生产过程中专业人才的缺乏。传统农业生产中，耕、种、管、收四个环节，“管”是持续时间最长，也是农机设备介入程度较低的一个环节。田间管理环节涉及的环节多，操作复杂，作物的收成和地块的可持续发展都和农民在这一环节的专业操作分不开。</p>\n  <p>在田间管理过程中，农业机械的精细化作业能力至关重要。传统农机设备在参与田间管理时，需要人工在机耕道上进行换行、转弯等操作，容易碾轧植被，造成对植株的机械损伤。同时，传统农机设备在普洒农药的过程中，由于缺乏精准作业的能力，肥料滥用和农资浪费问题突出，土壤板结化严重。</p>\n  <p>能够精准作业的农业机器人，成为留在耕地上的“新农人”最迫切的需求。</p>\n  <p>硬氪注意到，觉物科技推出的“鹤出”农业机器人（型号Function Robot，FR）正在新疆百万亩的辽阔棉田中作业，并在抖音、视频号等平台获得了许多在地农户的好评。</p>\n  <p>觉物科技2020年成立于广东深圳，是全球最早通过mRaaS(modularized Robot as a Service)模式直接提供农业种植服务的机器人公司之一。其核心产品“鹤出”农业机器人，采取觉物科技全球首创的模块化变形机器人系统，结合人工智能、农田自动驾驶、大数据技术，为全球农业客户提供零碳纯电、数字化、无人化的“耕种管收”全流程农业服务，目前已在新疆农田实现规模化应用。</p>\n  <p>与市面上常见的农机企业整机售卖模式不同，觉物科技选择以社会化服务作业切入市场，致力于解决农业作业季集中爆发的需求高峰。农户只要在农服小程序上自助下单，即可预约专业植保服务。</p>\n  <p>觉物团队在新疆调研的时候发现，农业的时效性非常强，但目前农户采购单一农机只能在单一种植环节专用，导致农机设备利用率很低。“比如除草、采棉这些关键环节，留给农民的时间窗口非常短，你可能要在7-10天内把草全部除掉，采棉机每年只工作40天。”觉物科技创始人宋佳音对硬氪表示，觉物提供的社会化服务作业能够解决这一行业痛点，由更专业、更精细的系统和机器人来为农户提供农业服务，更高效地作用于农业生产。</p>\n  <p>除了农业服务模式优势之外，觉物科技的“鹤出”机器人在实际的农业操作中，也解决了现有植保方式作业质量不佳的问题，并通过在作物生长期提高病虫害防治质量，达到增产10%-15%的效果。</p>\n  <p>目前，市面上的植保机器人尺寸大小基本固定，但在实际的农业生产中，植株间距、高度无序，现有植保方式中，地面式农业机械存在人工驾驶难度大、机械损伤严重等问题；新型的空中设备存在水量不足、药害漂散严重等问题。值得注意的是，现有的所有植保设备都无法实现精准打药。</p>\n  <p>在研发过程中，觉物团队按照深度模块化设计的原则，优化不同功能不同层级的组件，灵活组合出自动变形的多种机器人模态，实现了像乐高一样快速拼装的机器人系统。如“鹤出”变形机器⼈(Code Name: Function Robot)可以在大田场景并通过不同的模态变形自适应不同的作物和种植模式。机器人采用自动驾驶，全向灵活的轮边驱动独立线控技术和自适应变形技术，可以实现360°运动横移倒退换行，几乎实现零机械损伤。</p>\n  <p>同时“鹤出”机器人采取模块化风送系统，在不同的植株发育阶段实现靶向变量施药，精准打透需要施药的部位。在“鹤出”机器人精准作业模式下，施药量低至0.015克/亩，相比传统模式节约90%以上的药量，减少滥用农药的土地破坏，也为农民节省了农资投入。</p>\n  <p>值得注意的是，新疆棉花在采收前，需要对植株喷洒脱叶剂。在以往的农���生产中，利用其它设备喷洒脱叶剂时，由于棉株处于生长最茂盛、最高大的时期，药剂往往难以覆盖中低部的叶片，导致棉花青叶残留在植株上，成为成品棉的杂质。同时，传统普洒设备穿透力不足、脱叶效果不佳，往往需要对棉花植株进行重复施药，造成棉花纤维受损，影响成品棉的品质等级。</p>\n  <p>宋佳音透露，“鹤出”机器人在新疆合作基地的应用，精准解决了二十年来当地棉花脱叶剂滥用的问题，极大地提高了当地棉花采收品质。不仅在新疆农户中有口皆碑，复购率接近100%，还吸引了巴西等地的外国客户。</p>\n  <p>“目前全球的农业都在面临老龄化的问题，农机产品的用户也正在变成新一代的农民、农场主。”想要抓住这一代新农人，精准作业和高效专业的社会化服务将是两个最重要的核心竞争力。“我们认为这是农业机器人的好时代，也是觉物科技的机会。”宋佳音告诉硬氪。</p>\n  <p>日前，觉物科技（深圳）有限公司宣布已完成Pre-A轮融资，本轮融资由浙江机器人产业集团领投，同时获得深圳市投控东海投资有限公司跟投。本轮融资将主要用于推动觉物科技模块化机器人系统的研发进程，加速产品迭代，并进一步推动mRaaS（机器人即服务）模式在农业社会化服务领域的推广。</p>\n  <p><span style=\"color: #999999; font-size: 12px; letter-spacing: 0px; text-align: center;\"></span></p>\n  <p><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_b80b281dc9de436e9badfdbc4e562210@6129731_oswg90987oswg1080oswg336_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\" contenteditable=\"false\">36氪供图</p>\n  <p><span style=\"color: #999999; font-size: 12px; letter-spacing: 0px; text-align: center;\">&nbsp;</span><br /></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_36b47fb2df4a46c781acf09994b27304@6129731_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">36氪供图</p>", "published": "2024-10-31 01:30:00", "id": "6184a505-f57b-4859-9139-5bd72bc0b596", "source": "36氪", "section": "综合资讯"}, {"title": "雷神携手BOE（京东方）发布全球首款仿生科技蜂鸟屏", "link": "https://36kr.com/newsflashes/3016233028232455?f=rss", "description": "36氪获悉，雷神携手BOE（京东方）发布全球首款仿生科技蜂鸟屏，由京雷显示创新联合实验室推出。据介绍，雷神蜂鸟屏采用了最新的量子点技术和优化背光系统，融入了BOE（京东方）全新升级的ACR技术，能够实现200:1的ACR超高环境光对比度。", "published": "2024-10-31 09:50:54", "id": "c6dcdc77-e484-48ca-9520-7aeefcb92d49", "source": "36氪", "section": "综合资讯"}, {"title": "富士通继续研究出售空调业务的可能性", "link": "https://36kr.com/newsflashes/3016212181116160?f=rss", "description": "10月31日消息，富士通公司首席财务官表示，该公司仍在继续寻求出售空调业务，并正在努力提升其空调业务的价值。他补充称，目前没有什么新消息可以提供。（界面）", "published": "2024-10-31 09:29:41", "id": "37861a83-e290-4092-806d-700e7e6a6cfd", "source": "36氪", "section": "综合资讯"}, {"title": "农业银行：张旭光辞去公司执行董事、副行长等职务", "link": "https://36kr.com/newsflashes/3016236316255490?f=rss", "description": "36氪获悉，农业银行公告 ，因到龄退休，张旭光请求辞去公司执行董事、副行长及董事会战略规划与可持续发展委员会、风险管理与消费者权益保护委员会兼美国区域机构风险委员会委员职务。张旭光的辞职信于2024年10月31日送达公司董事会并生效。", "published": "2024-10-31 09:54:14", "id": "8f8e26ac-0498-4aa8-b2b8-aa274f94c667", "source": "36氪", "section": "综合资讯"}, {"title": "获文和友关联基金千万元投资，「麻蒲碳烤肉」“好吃不贵”的十年养成之路｜早期项目", "link": "https://36kr.com/p/3009146435986953?f=rss", "description": "<p>每个城市都有几条出名的网红商业街，广州也不例外，远景路就是其中一条颇具特色的街道。</p>\n  <p>时间回到二十年前，远景路普通且偏僻，而后随着韩国人的到来，他们在此聚集，开设了服装店、超市和餐馆，经过演变，这里逐渐成为了华南地区最具影响的韩国社区之一。</p>\n  <p>远景路不仅是韩国文化的缩影，也是美食爱好者的天堂。你可以在这里找到各种美食，其中以韩式烤肉最为出名，近期36氪接触到的「麻蒲碳烤肉」第一家店便位于此地。</p>\n  <p>麻蒲碳烤肉是一家成立于2014年的韩式烤肉连锁品牌，不久前，刚获得近千万元投资，投资方为文和友主导的湖南谦泰基金，融资主要用于门店扩张，<a href=\"https://36kr.com/newsflashes/2983280608514304\" rel=\"noopener noreferrer\" target=\"_blank\">36氪曾对该轮融资做了首发披露。</a></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241030/v2_c86e6d3e3eb1452abc8a328710d8210f@5654145_oswg1829029oswg1269oswg846_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">麻蒲碳烤肉菜品，受访者供图</p>\n  <p>麻蒲碳烤肉创始人李永哲曾在韩国餐饮店工作多年，后来和爱人回国后，因为爱人特别喜欢吃烤肉，便萌生了开烤肉店的念头，拿出几乎所有积蓄60多万元盘了一个80平左右的店面，以七张桌台开启了创业之路，凭借正宗的韩式烤肉风味，迅速赢得了顾客们口碑，仅三个月时间便开始出现排队现象，店门口等位长龙时常堵住街道，日翻台率近15次。他回忆道：&nbsp;“记得当时为了给顾客排队等位，我们把附近一家五金店的两三百把塑料凳子都买光了，甚至出现顾客之间为了早点吃到烤肉而大打出手的局面。”</p>\n  <p>时至今日，麻蒲碳烤肉从一家80平的小店已逐步扩张为超过600平的大店，成为远景路上知名的美食招牌，2022年到2024年连续三年蝉联大众点评必吃榜。</p>\n  <p>麻蒲碳烤肉在过去十年的发展历程中，品牌在宣传和推广方面的动作非常少，在餐饮营销竞争白热化的今天，李永哲更愿意相信依靠扎实的产品所带来的复购。</p>\n  <p>在价格方面，麻蒲碳烤肉践行“好吃不贵”的产品主义。不同于市面上动辄百元以上的客单价，麻蒲碳烤肉人均消费在80元左右，这也构成了品牌的差异化竞争优势。</p>\n  <p>性价比背后有坚实的供应链支撑，麻蒲碳烤肉建有自己的工厂，实现了从原材料采购到加工的全链路控制，不仅保证了食材的品质和新鲜度，还使成本得到有效的控制。</p>\n  <p>十年时间里，麻蒲碳烤肉在广州和佛山等地开设近30家门店，扩张步伐可以称得上缓慢，这与创始人的有意为之有关，实际上在第一家门店走红之后就不断有人上门表示加盟意向，但考虑到自己当时各项体系及供应链尚未完善，几乎都被李永哲一一婉拒，后面拗不过一些老顾客以及朋友的坚持，他才试着做一些合作，目前近半数门店为内部员工所开。</p>\n  <p>现在，各方面条件日趋成熟，麻蒲碳烤肉逐渐放开速度，计划在未来18个月内将门店扩张至100家，重点布局珠三角地区，并考虑进入长三角等重点省市。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241030/v2_814f7a6cad734bfcb26776542d3ca649@5654145_oswg288633oswg1393oswg784_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">麻蒲碳烤肉全新品牌形象，受访者供图</p>\n  <p>与此同时，品牌也在进行形象升级，在创始人看来，麻蒲碳烤肉的顾客以年轻女性为主，她们对门店形象有着较高的要求，虽然过去公司在这方面做得并不好的情况下依然取得了非常好的业绩，但基于更好地满足顾客需求，于是决定做出这样的改变，提升品牌竞争力。</p>\n  <p>根据36氪了解，麻蒲碳烤肉远景路门店已在升级改造中，将打造成为形象升级后的旗舰店，预计12月会以全新面貌示人。随着品牌升级和市场扩张，李永哲希望麻蒲碳烤肉能长成顾客心中“品质烤肉，好吃不贵”的代表。</p>", "published": "2024-10-31 01:30:00", "id": "11a106fa-c829-4485-bd30-ee1576f31424", "source": "36氪", "section": "综合资讯"}, {"title": "“胖化”的永辉，决定先快速瘦身", "link": "https://36kr.com/p/3015895686047233?f=rss", "description": "<p>文｜杨亚飞</p>\n  <p>编辑｜乔芊</p>\n  <p>永辉的股价在过去四个月涨了近1.4 倍。在三季度报披露之前，市场对永辉超市的预期已经拉满——这是他们学习胖东来以来的第一份成绩单。</p>\n  <p>但结果可能要让一部分感到人失望。截止 9 月底已开业的 8 家“胖化”调改门店，有 7 家是在三季度开业。这个季度，永辉营收 167.7 亿元，同比下滑 16.4%，归母净亏损 3.53 亿元，较去年同期下降 0.32 亿元。环比由盈转亏，在今年上半年时，永辉还是在赚钱的，归母净利润为 2.75 亿元。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_28863a3895ec4aa79296ad13309c6cac@1282423258_oswg147835oswg1310oswg470_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">永辉 2024前三季度营收及利润变化</p>\n  <p>导致三季度亏损最核心的原因是，“瘦身”和“胖化”同时在进行。</p>\n  <p>从目前的情况来看，调改闭店约 30 天时间，不仅改造需要花钱，闭店也会损失部分收入。此外，永辉也已经“暴瘦”，报告期内，今年已关闭186家扭亏困难的尾部门店。第三季度，他们因关闭处置门店产生的未经审计的损失金额便达到 4.65 亿元。</p>\n  <p>“永辉生活”app 覆盖的门店，也从去年底的 920 家，减少 140 家至 780 家，其中仅三季度便减少 103 家。</p>\n  <p>对于一家传统商超来说，三个月时间基本面通常不会发生太大变化，但永辉过去的三季度，转型的决心已经写在明面。</p>\n  <p>&nbsp;学习胖东来的门店调改是他们的主动求变，而关闭经营不善的门店也是如此，为了尽快腾出精力和资源，集中力量做更多的门店调改。&nbsp;</p>\n  <p>三季度的亏损，也是永辉超市决心用短期阵痛的方式，快速改善经营基本面。“胖化”之前，永辉决定先让自己快速瘦身。</p>\n  <p>对永辉超市学习胖东来方向看好的，还包括名创优品创始人叶国富，并在 9 月末决定豪掷 62.7 亿“抄底”永辉。</p>\n  <p>在《高能量》播客的访谈里，叶国富难掩对收购永辉超市的兴奋，“交易的（谈判）时间用了两个月，”叶国富说，但思考这件事，他只用了大概一个星期，因为“这是千载难逢的机会。”</p>\n  <p>这种乐观背后，即是名创优品在找机会从可选消费延伸到必选消费，也是他对永辉以学习胖东来的方式，成为类似Trader Joe’s、costco 或者山姆等零售标杆企业的看好。</p>\n  <p>与亏损结果呈现鲜明落差，调改门店的业绩确实有大的改观：首家调改店郑州信万广场店，截至9月30日日均营收约153万元，并在9月实现盈利。北京调改首店喜隆多店，开业10日日均营收约160万元，是调改前的 6 倍。</p>\n  <p>永辉“胖化”的调改还在提速。据永辉超市方面透露，在春节前调改店将达到约 40-50 家，新增上海、兰州、天津、重庆、沈阳、深圳等多个城市。这也意味着，除了目前已知的开业/待开业的 18 家店，12 月和来年 1 月，至少还有22 家要完成调改。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_b243bcaf2d704e919a1337a4fbe53181@1282423258_oswg2223517oswg2560oswg1707_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">今年 5 月，于东来在永辉郑州信万广场店调改启动仪式上的演讲，图据 IC photo</p>\n  <p>尽管胖东来被嘲笑走不出河南，但永辉把他们的货卖到了全国。</p>\n  <p>永辉的胖东来化最直观的改变是产品结构的调整，调改门店多是胖东来商品结构的 90%，几乎是按照胖东来的商品结构 1:1 复制，且从过去收进场费、条码费、陈列费的大卖场模式，改成裸价和控后台，通过砍掉中间环节和后台成本，提升产品性价比。</p>\n  <p>代价是毛利率还在下滑，永辉三季度毛利率仅 19.19%，较去年同期下滑 1.69个百分点。但如果跟 Costco 相比，毛利率仍然有大幅下降的空间，后者把毛利率控制在 11% 左右。他们并不赚高差价，而是靠着高性价比的自有商品，让付费会员乐于持续续费。</p>\n  <p>事实上，永辉的自有品牌已经做了很多年，早在 2018年的 2.0 升级时，便明确要通过直达源头的方式，做高性价比的产品定位。但这都不及胖东来直接开放供应商名录，以及在商品价码上标出成本价和毛利率的方式，让消费者如此心甘情愿买单。</p>\n  <p>胖东来并非那么容易复制，永辉也并非于东来唯一的“学生”，但他们可能是最积极的。在已开业的 10 家调改店，其中 7 家均是他们自主调改，并计划派约 50 名店长到许昌胖东来跟岗学习。</p>\n  <p>对于调改的决心，还体现在一则新披露的聘任公告。永辉宣布聘任王守诚为公司副总裁，这位90 后最初以管培生身份进入永辉，聘任 VP之前他的身份是，永辉全国调改小组负责人。</p>\n  <p>渠道改革还体现在，永辉希望借助美团打开线上业务。根据公告，永辉合作美团斑马超市，在美团闪购平台开设闪电仓项目，并成立全资子公司“郑州叮叮猫超市有限责任公司”。而有 2 年美团买菜背景的永辉线上运营部总经理林红东，也同期升任 VP。</p>\n  <p>一个背景信息是，永辉新晋股东名创优品也刚刚宣布与美团达成战略合作，年内计划在美团上线超过 800 家闪电仓形态的 24 H 超级店。</p>\n  <p>这一部分是试图挽回线上的颓势。在调改背景下，永辉前三季度的线上业务营收为 115.7 亿元，同比下滑5.63%。其中，相比于自有 APP 平台，第三方平台到家业务的销售额下滑更加明显，前三季度销售额为 52.6 亿元，同比下滑 10.54%。</p>\n  <p>但线上零售不会是永辉的主阵地。未来很长一段时间，外界最关心的仍然是门店调改的进度。从目前的表现来看，消费者会被许昌胖东来的特色商品吸引到店，但永辉的调改并不能只是停留在表面，基于胖东来化的组织和体系的重整，是一块更难啃的骨头。</p>", "published": "2024-10-31 07:37:25", "id": "bfe6ccc1-690a-475e-a8d0-6e1359a528e3", "source": "36氪", "section": "综合资讯"}, {"title": "科氪 | 全面AI，为消费者打造最惊艳的产品！荣耀Magic 7系列", "link": "https://36kr.com/p/3016197913765124?f=rss", "description": "<h3><strong>2024年10月30日，深圳</strong>&nbsp;— 在科技界万众瞩目的荣耀Magic7新品发布会上，荣耀公司CEO赵明以一场深刻而详尽的群访，为公众揭开了这款集科技与艺术于一身的智能手机的神秘面纱。此次发布会不仅是对荣耀Magic系列的一次重要迭代，更是荣耀在AI技术领域深耕细作、持续创新的集中展现。赵明就新品定价、AI技术应用、市场策略以及公司未来发展等多个维度，与在场数十家媒体进行了深入而坦诚的交流。</h3>\n  <p><strong>一、定价哲学：坚守核心价位，传递消费者价值</strong></p>\n  <p>在谈及荣耀Magic7的定价策略时，赵明展现出了其作为行业领导者的深思熟虑与远见卓识。他强调，荣耀始终坚守在核心价位段为消费者打造最为认可和惊艳的产品的理念。这一理念不仅体现在荣耀Magic7的定价上，更是荣耀品牌精神的集中体现。</p>\n  <p>赵明指出，尽管当前全球供应链面临诸多挑战，芯片等关键元器件价格大幅上涨，但荣耀并未因此将成本压力转嫁给消费者。相反，荣耀选择通过内部优化、技术创新等方式，吸收成本上涨带来的压力，确保荣耀Magic7在保持高品质的同时，价格依然亲民。</p>\n  <p>“我们坚信，只有真正站在消费者的角度，才能赢得市场的认可。”赵明表示，“荣耀Magic7的定价策略，正是我们这一理念的生动体现。我们希望通过这款产品，让更多的消费者能够享受到科技带来的便利与乐趣。”</p>\n  <p><strong>二、AI技术：重构手机体验，引领未来趋势</strong></p>\n  <p>AI技术作为荣耀Magic7的核心竞争力之一，成为了群访中的另一大焦点。赵明详细介绍了荣耀在AI技术领域的布局与成果，展现了荣耀在科技创新上的雄厚实力与前瞻视野。</p>\n  <p>他回顾道，荣耀早在4年前就敏锐地洞察到了AI技术的巨大潜力，并开始了前瞻性的布局。从最初的低功耗地理围栏技术，到如今AI在操作系统、屏幕、通讯、拍照、续航等多个方面的广泛应用，荣耀的AI技术已经实现了从量变到质变的飞跃。</p>\n  <p>赵明强调，AI技术不仅提升了手机的使用体验，更使手机变得更加智能、更加懂消费者。例如，通过AI技术，荣耀Magic7能够根据用户的使用习惯和需求，智能调整屏幕亮度、优化拍照效果、提升通讯质量等，为用户带来更加个性化、更加贴心的服务。</p>\n  <p>“AI技术正在深刻改变着我们的生活和工作方式。”赵明表示，“荣耀将继续加大在AI技术领域的投入和研发力度，推动手机行业向更加智能化、更加人性化的方向发展。”</p>\n  <p><strong>三、GT系列回归：强化品牌基因，满足多元化需求</strong></p>\n  <p>在群访中，赵明还就荣耀GT系列的回归进行了详细解读。他表示，GT系列的回归是荣耀强化互联网手机和年轻人品牌基因的重要举措，也是荣耀满足消费者多元化需求的重要布局。</p>\n  <p>赵明指出，当前手机市场竞争日益激烈，消费者需求也日益多元化。荣耀GT系列以其卓越的性能、时尚的设计和亲民的价格，成为了年轻人喜爱的手机品牌。此次GT系列的回归，将进一步提升荣耀在互联网手机市场的竞争力，满足更多年轻消费者的需求。</p>\n  <p>同时，赵明也强调，荣耀GT系列的回归并非简单的产品复刻或价格竞争。相反，荣耀将通过优质的研发实力和市场能力，为GT系列注入新的活力和内涵，使其成为年轻人追求时尚、个性与品质的首选品牌。</p>\n  <p><strong>四、展望未来：坚持创新驱动，引领行业发展</strong></p>\n  <p>在群访的最后环节，赵明展望了荣耀的未来发展。他表示，荣耀将继续坚持创新驱动的发展战略，加大在新技术、新领域的研发投入和布局。同时，荣耀也将积极拓展国际市场，提升品牌影响力和竞争力。</p>\n  <p>赵明强调，荣耀的未来发展离不开消费者的支持和信任。他表示，荣耀将始终坚持以消费者为中心的理念，不断提升产品和服务质量，为消费者带来更加优质、更加智能的科技体验。</p>\n  <p>“我们相信，只有不断创新、不断进步，才能赢得消费者的认可和支持。”赵明表示，“荣耀将继续努力，成为消费者信赖的智能手机品牌，引领手机行业的发展和进步。”</p>\n  <p>荣耀Magic7的发布不仅展示了荣耀在智能手机领域的创新实力和技术底蕴，更体现了公司对消费者需求的深刻洞察和满足。通过坚守核心价位、深耕AI技术、强化GT系列品牌基因以及坚持创新驱动的发展战略，荣耀正逐步构建起一个更加完整、更具竞争力的产品体系和市场布局。未来，荣耀将继续以消费者为中心，推动智能手机行业的发展和进步，为消费者带来更加美好的科技生活。</p>", "published": "2024-10-31 09:44:44", "id": "8f574ff5-3f32-46eb-87a6-fb161811278e", "source": "36氪", "section": "综合资讯"}, {"title": "光大证券：获准发行不超150亿元短期公司债券", "link": "https://36kr.com/newsflashes/3016213135697414?f=rss", "description": "36氪获悉，光大证券公告，公司近日收到中国证券监督管理委员会《关于同意光大证券股份有限公司向专业投资者公开发行短期公司债券注册的批复》，批复内容包括同意公司向专业投资者公开发行短期公司债券，面值余额不超过150亿元。", "published": "2024-10-31 09:30:40", "id": "4ad3cc75-c9c8-4a35-baae-144368a3ccc5", "source": "36氪", "section": "综合资讯"}, {"title": "国家外汇管理局扩大3项跨境投融资便利化试点", "link": "https://36kr.com/newsflashes/3016204332918020?f=rss", "description": "36氪获悉，日前，国家外汇管理局在总结前期试点经验的基础上，决定将开展外商投资企业境内再投资免登记试点和银行直接办理外债登记试点的地区扩大至天津市、安徽省、山东省（含青岛市）、湖北省和四川省，将“科汇通”试点地区扩大至上海市、北京市、天津市、河北雄安、南京市、苏州市、杭州市、合肥市、武汉市、长沙市、广州市、重庆市、成都市、绵阳市、西安市和深圳市等16个地区。", "published": "2024-10-31 09:21:42", "id": "e5952971-6efc-407e-904d-0dd2ae395857", "source": "36氪", "section": "综合资讯"}, {"title": "姚明不再担任篮协主席", "link": "https://36kr.com/newsflashes/3016240819971586?f=rss", "description": "10月31日，第十届中国篮球协会会员代表大会执行委员会在北京举行会议，审议通过姚明辞去中国篮球协会主席职务的申请，选举郭振明为新一任中国篮球协会主席。 ​​​（央视新闻）", "published": "2024-10-31 09:58:49", "id": "6b56bb6e-980a-40b5-b79b-c4d27883cc3e", "source": "36氪", "section": "综合资讯"}, {"title": "智能宠物监控革命，灵予科技要做毛孩子的AI保姆｜早期项目", "link": "https://36kr.com/p/3015741200835848?f=rss", "description": "<p>作者｜叶丹璇</p>\n  <p>编辑｜袁斯来</p>\n  <p>随着AI越来越广泛地应用于人类的日常生活，许多传统硬件行业都正在积极拥抱算法的改造，宠物监控也在此列。</p>\n  <p>对于当代人而言，宠物早已超出豢养动物的范畴，而更多地成为互相陪伴的“毛孩子 ”家人。宠物主也更愿意在宠物的照护和日常监测上投入精力和金钱：上班族在家 里安装监控，在离家的间隙通过摄像头查看宠物的状况，远程与之对话，正在变成一种常见现象。</p>\n  <p>硬氪近期接触的灵予科技，团队通过接入自研的AI视觉算法体系，推出一款可以自主记录宠物精彩瞬间与分析异常行为的宠物摄像头——SiiPet。</p>\n  <p>灵予科技创始人付星昱和万纬韬具备丰富的智能硬件和算法开发经验。基于对宠物家庭和市场的观察，发现目前市面上传统的宠物监控在诸如高速追踪、行为理解等垂直场景中非常重要的特性上，效果都不如人意，依然存在较为显著的技术痛点，需要更深入的AI算法和数据积累才能突破。</p>\n  <p>一个属于上班族宠物主的常见烦恼是，每天真正陪伴宠物的时间只有下班后的几 小时，时常加班或出差的宠物主的陪伴时间则更少。此外的时间里 ，“毛孩子 ”只能在家里独自生活，大量的宠物生活内容无法被发现和记录。更重要的是，即使宠物出现了健康相关的异常行为，宠物主也很难通过传统监控和短暂的相处发现。</p>\n  <p>基于对此问题的思考，灵予科技将自主研发的一系列AI视觉算法嵌入SiiPet宠物监控摄像头中，通过核心端侧算法及云端大模型工具，结合宠物真实行为数据、临床数据与美学评估数据等底层大数据集，实现宠物高光画面自动捕捉、异常行为提醒与多宠识别。</p>\n  <p>在具体的使用过程中，SiiPet通过搭载了AI视觉系统的4k摄像头，能够对高速移动的宠物进行精准识别和超高速追踪。同时，摄像头会对高光画面进行自动捕捉与构图，确保画面尽可能符合人类的拍照审美，区别于传统的监控画面。</p>\n  <p>不仅如此，SiiPet目前已经能够准确进行多宠物识别，并在后台将高光片段按不<span style=\"letter-spacing: 0px;\">同宠物归档推送，宠物主可以实时切换查看不同宠物的状态，同时一键分享每日的高光图片和短视频在喜爱的社交媒体上。</span></p>\n  <p>值得注意的是，SiiPet特有的异常行为捕捉功能，填补了目前宠物摄像头领域对宠物行为和健康监测的空白。</p>\n  <p>呕吐、蹭屁股、抓挠、甩头、跛行或抽搐等行为及其出现频率，都是判断宠物异常健康状况的重要指标。但大量宠物主即使安装了现有的宠物监控，也无法准确监测到上述行为以及对应的的出现频率，大量早期健康问题因此被忽视，宠物也容易错过最佳治疗窗口。</p>\n  <p>目前，SiiPet的异常行为捕捉功能，可以通过其智能化系统自动监测、捕捉，根据内置的兽医动物行为学知识和后台用户数据不断学习、准确判定，并推送给宠物主。</p>\n  <p>付星昱对硬氪表示，由于目前宠物用品市场的硬件供应链已经非常成熟，行业正在进入一个在硬件指标和成本上“ 内卷”的阶段，亟需通过技术上的革新，对一直存在的难题进行攻克和解决。</p>\n  <p>“摄像头的追踪、识别与分析等能力本质上是由算法带来的智能化差异。我坚定地认为，宠物用品从联网与自动化，向真正的智能化发展是一个明确的趋势。 ”付星昱说。他留意到，近期部分宠物公司在寻求算法支持，引入更多AI技术，灵予科技正在与他们建立合作。</p>\n  <p>团队方面，灵予科技的核心技术团队均来自智能硬件大厂，CEO付星昱和系清华大学电子工程系硕士，曾担任tp-link与小米高级产品经理，负责多个过亿收入的智能家居产品；CTO万纬韬系清华大学电子工程系博士，曾担任微信通用物体检测和小程序AI视觉能力负责人，发表多篇AI顶会论文。</p>\n  <p><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_ad94226257c8469097ba51f1c786e99b@6129731_oswg90987oswg1080oswg336_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\" contenteditable=\"false\">36氪供图</p>\n  <p><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_3654ad1b75564d03bd8bf088b9a31fc2@6129731_oswg83785oswg1080oswg336_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\" contenteditable=\"false\">36氪供图</p>\n  <p class=\"img-desc\"><br /></p>", "published": "2024-10-31 01:32:54", "id": "6790872e-a0ad-40b3-85a3-7c7ec10c2630", "source": "36氪", "section": "综合资讯"}, {"title": "南向资金今日净买入26.83亿港元，美团净卖出额居首", "link": "https://36kr.com/newsflashes/3016217730049287?f=rss", "description": "36氪获悉，南向资金净买入26.83亿港元，小米集团-W、腾讯控股、协鑫科技分别获净买入6.6亿港元、5.34亿港元、2.37亿港元；美团-W净卖出额居首，金额为4.27亿港元。（界面）", "published": "2024-10-31 09:35:20", "id": "38840155-c64e-49e6-8951-e6a48bcd6d30", "source": "36氪", "section": "综合资讯"}, {"title": "6连板申华控股：近三年一期营业毛利率呈现下滑状态", "link": "https://36kr.com/newsflashes/3016242155250946?f=rss", "description": "36氪获悉，申华控股公告，公司股票自2024年10月24日以来连续6个交易日累计涨幅达79.22%，短期涨幅高于同期上证指数，存在市场情绪过热的情形。公司近期日常经营情况及外部环境未发生重大变化。公司近两年一期经营业绩亏损，2022年度、2023年度、2024年1-9月归属于上市公司股东的净利润分别为-1.73亿元，-1.99亿元、-5623.83万元。公司近三年一期营业毛利率呈现下滑状态，分别为10.09%、7.08%、6.96%、6.33%。", "published": "2024-10-31 10:00:11", "id": "20b235d8-b15f-43f8-8bf2-94f561b8c1d5", "source": "36氪", "section": "综合资讯"}, {"title": "联想集团董事长兼CEO杨元庆：出海是联想做过的最正确的战略抉择之一 | 最前线", "link": "https://36kr.com/p/3016125754238469?f=rss", "description": "<p>“回顾过往，我觉得出海是联想做过的最正确的战略抉择之一。”</p>\n  <p>10月30日，北京，在联想集团主办的“领航者征途：2024中国企业高质量出海论坛”上，联想集团董事长兼CEO杨元庆谈到，“如果没有改革开放，如果没有全球化，就没有今天的联想。”他说。</p>\n  <p>2004年12月，一场被喻为“蛇吞象”的并购案中，联想以三十亿美元收购了一百亿美元规模的IBM PC业务，这一举动令全球瞩目，至今仍被广泛提及。</p>\n  <p>杨元庆回顾了联想全球化的起点，“2000年，我带领团队前往美国，拜访了包括微软、英特尔、惠普、思科在内的很多家高科技企业。在加州圆石滩，我们下定决心，要在接下来的十年内，将联想打造成为一家名副其实的全球化企业。为了实现这个理想，联想尝试过不同路径，比如自建式发展，几经探索，最终选择在2004年通过并购IBM PC业务的方式正式扬帆出海”。</p>\n  <p>但要想实现真正的全球化，并购只是起点，整合才是关键。</p>\n  <p>在杨元庆看来，整合不仅是财务报表的合并，更涉及从产品、品牌到供应链、组织文化等各方面的系统性整合，复杂度极高。</p>\n  <p>以产品与品牌���例，为了在并购后避免员工流失和客户流失风险，联想选择在过渡期内联想和IBM的产品、品牌各自独立运行的模式，业务稳定之后，才开始深入整合，并且根据不同品类的不同特点，采取不同程度的整合路径。</p>\n  <p>组织文化整合就更难了。老联想的流程和经营偏重垂直管理，IBM则偏重矩阵管理；老联想有自己长期形成的中文工作语言和工作术语体系，而IBM则是完全不同的英文体系，光特定缩写和术语就有十几页；老联想基于单一国家业务的管理方式是事业部直接触达区域市场的具体管理，而IBM在全球市场上则是通过各国家/地区的业务团队来间接管理；文化上，老联想引以为豪的是“主人翁精神”和“说到做到”，他们则是经理人文化等。</p>\n  <p>经历了从磨合到融合的方方面面，最终让联想有更强的竞争力，也沉淀下更多的经验与方法论。演讲中，杨元庆首度对联想全球化20年的实战方法论进行了提炼，总结了全球供应链、全球研发体系及全球市场营销体系三大关键支柱，以及数字化与ESG两大基座，这也是每一家出海的中国企业需要锻造的关键能力。</p>\n  <p>“中国企业在全球市场上发展壮大的基础，一定是扎根中国。回看过去这20年，联想不仅是对外的拓展，更是一种对内的赋能”，联想集团董事长兼CEO杨元庆表示，联想约80%的生产制造、70%的研发人员、60%的员工都布局在中国大本营。通过深耕海外市场，联想能够更有效地整合全球资源，实现对国内市场的有力回馈，进而为国家经济的繁荣发展注入新的活力。这样的出海之路，正是中国扩大高水平对外开放的应有之义。</p>\n  <p>然而，中国企业“出海”的外在环境也在不断变化。此时此刻的世界，正处于一个全球贸易格局、产业链价值链重构与技术变革浪潮交汇的关键时刻。</p>\n  <p>联想集团董事长兼CEO杨元庆表示，作为中国企业，“走出去”是开拓海外市场、提升企业争力的有效路径。但光“走出去”是不够的，中国企业还需要加速“走进去”和“走上去”。</p>\n  <p>如何达成这样的目标？杨元庆进一步提出了三点建议：一是重视通过本地化产品创新构建全球知名品牌；二是重视通过贴近本地市场构建韧性供应链；三是重视通过合作共赢塑造当地市场企业公民形象。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_c9b5805a1bc048539434d257cd9cc723@405798_oswg565465oswg1080oswg720_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">联想集团董事长兼CEO杨元庆</p>\n  <h3>以下是联想集团董事长兼CEO杨元庆的演讲全文，经编辑后发布：</h3>\n  <p>杨元庆： 尊敬的各位来宾、朋友们，大家好！很高兴参加“领航者征途”中国企业高质量出海论坛。距离这里不远的地方就是上世纪80年代有名的“中关村电子一条街”，那里不仅见证着中国科技创新的蝶变，也是联想“计算梦”与“出海梦”的起点。40年前，我们从一间传达室创业出发，一步步从代理别人的品牌到发展自主品牌，从国际化到多元化，从摘取全球个人电脑市场冠军，再到今天引领新一代人工智能发展浪潮，我们用20年的时间成长为中国全球化程度最高的企业之一。</p>\n  <p>如果说20年前联想国际化是一次冒险的下水试航，如今，越来越多的中国企业正在以更加自信的姿态走出国门，勇敢地去探索更广阔的世界，出海品类日益丰富，从服装、家具、家电的“老三样”，到口袋至云端的信息产品，从新能源汽车、锂电池、光伏产品的“新三样”，再到新餐饮出海、游戏出海、文化出海，为全球经济注入了一股来自中国的全新活力。</p>\n  <p>刚才白院长从宏观趋势层面分享了他的真知灼见，下面我想基于企业实践，谈谈出海及全球化如何塑造了今天的联想，并对中国企业在新一轮出海浪潮中如何加速“走上去”，谈谈我的思考和建议。</p>\n  <p>作为在中国IT产业摸爬滚打了整整40年的企业，联想是借助改革开放的东风成长起来的最早一批民营企业之一，也是第一批树立国际化愿景并成功实现的中国企业。</p>\n  <p>时间倒回到新世纪初年的2000年，当时我带领我们的团队前往美国，拜访了包括微软、英特尔、惠普、思科在内的很多家高科技企业。在加州Pebble Beach圆石滩，我们下定决心，要在接下来的十年内，将联想打造成为一家名副其实的全球化企业。为了实现这个理想，我们尝试过不同路径，比如自建式发展，但很快就发现，作为面向消费者的出海品牌先行者，不但不能像今天得到中国国家品牌这样的强力背书，还要背负长期以来人家给我们打上的“价廉质次”这样的先入为主的标签，所以别说打动客户，连招个员工都难，没有长时间的资源投入和经验积累是不可能做成的。后面的故事，大家都知道，2004年，我们选择了通过并购IBM个人电脑业务的方式正式扬帆出海。</p>\n  <p>三十亿美元的公司并购一百亿美元的业务，这桩收购被喻为“蛇吞象”，大家在为我们叫好的同时，也都为我们捏了把汗。当时没有中国企业成功并购海外品牌的先例，我们只能怀着不成功便成仁的心态“摸着石头过河”。</p>\n  <p>并购成功之所以难，最大的难度还不在于谈判的拉扯难，而是在于整合的过程难。它不仅仅是简单的财务报表的合并，更是从前端到后端、从业务到职能的系统性的整合，不可能停下高速运行的企业运营，等整合完毕再前行，更不能一刀切，而需要根据不同领域的不同情况做细致的、针对性的策略设计，更要在执行过程中保持灵活，在妥协和坚持之间找到最佳平衡。</p>\n  <p>以产品与品牌为例，为了在并购后避免员工流失和客户流失的风险，我们选择了在过渡期内联想和IBM的产品、品牌各自独立运行的模式，业务稳定之后，才开始深入整合，并且根据不同品类的不同特点，采取不同程度的整合路径。像台式电脑，已经是非常成熟、大宗化的产品，效率和成本的优先级更高，我们就做了快速、彻底的整合，把原来IBM产品从研发到生产制造的整个链条从美国完整地搬到了中国，从而让它从完成彻底整合之初就一直成为我们的现金牛；而对于笔记本电脑，则采用了循序渐进、分工协作的方式，我们珍视ThinkPad这个在商用客户中拥有最高美誉度的品牌，完整地保留了基于美国和日本的研发团队，把它的创新优势和精湛工艺发扬光大，同时充分利用联想多年打造的卓越运营的优势，把这个在IBM时代年亏损两到三亿美元的产品线，扭转到盈利水平行业领先。我们还基于整合后的研发和供应链优势，推出了面向全球的消费品牌YOGA，与Think形成互补，把联想电脑的市场地位不断提升，直到作为一个整体在2013年登上了全球个人电脑市场的冠军宝座。</p>\n  <p>不仅产品和品牌，销售、服务、供应链、生产制造、研发；乃至人力资源、组织、流程、文化等方方面面都有这样的从磨合到融合，再到竞争力更强的过程。对于中国企业来说，开辟海外市场从来就是一场危与机并存的探险，既需要无所畏惧的勇气与魄力，更需要长期主义的韧性与毅力。可以这么说：一直到联想成为全球个人电脑冠军，且能保持整体营收和利润的持续增长，各个大区均衡发展时，我们才敢说，联想完成了最大的一次冒险，实现了“走出去”的阶段性胜利。</p>\n  <p>回顾过往，我觉得出海是联想做过的最正确的战略抉择之一，甚至可以说，如果没有改革开放，如果没有全球化，就没有今天的联想。主动全球化20年不但为我们带来了年营收18倍以上的增长，更让联想稳步打造了植根中国、致胜全球的均衡布局和韧性竞争力。今天我们在全球拥有18个研发基地和30多家制造工厂，在全球180个市场开展业务，75%以上营收来自于海外，是全球市场上最受信赖与赞赏的中国品牌之一。</p>\n  <p>如果说并购整合是联想国际化的路径的话，那么在登上全球化舞台之后要锻造怎样的关键能力，我们也总结出几个要点，希望对有志于出海的中国企业有参考借鉴的意义，那就是——三大关键支柱和两大基座。</p>\n  <p>首先是三大关键支柱，分别是全球供应链、全球研发体系以及全球市场营销体系。这也构成了联想独有的“全球资源、本地交付”运营模式中最核心的内容。</p>\n  <p>一方面，我们充分调用全球优质资源，打造全球供应链、全球市场销售系统、全球创新研发体系，实现全球资源的高效整合；另一方面，我们又充分调动各区域市场的主人翁意识与灵活性，通过本地特色的产品和服务创新，高效灵活的本地交付，无限贴近本地市场。</p>\n  <p>不同国家和市场各自具有日积月累形成的比较优势，中国有产业链集群优势，日本有工程化优势，美国有创新设计优势，印度有软件服务优势，东欧国家有多语种商务支持优势等等，我们充分利用各地的优势资源，博采众长凝结成更具创新性的技术、产品和方案，以及更具竞争力的价值链，所以我们不仅形成了以中国-日本-美国为支点的研发三角，全球统一配置和管理的采购、制造、物流网络，最后一公里的生产交付服务中心更是遍布各地，辐射全球：墨西哥供应整个北美，匈牙利供应欧洲，巴西、阿根廷、日本、印度供应客户偏好独特的本土市场，正在规划建设的沙特生产基地则供应数字化进程不断提速的中东-非洲。</p>\n  <p>其次是两大基座，指的是支撑三大关键支柱的数字化基座与ESG基座。</p>\n  <p>自完成IBM个人电脑业务并购后，我们耗时8年，整合部署了一套贯穿联想“研产供销服”全价值链的数字化基石，不仅支撑着联想全球体系实现规模、效率与协同，更贯穿助力我们实现从硬件产品到解决方案和服务提供商的转型。今天，我们用自身的数字化、智能化实践经验和能力为各行各业的转型赋能，为中国制造、中国品牌走向全球产业链中高端赋能。</p>\n  <p>而ESG企业社会价值则构成了联想的软实力，帮助联想在复杂多变的环境中赢得更多尊重。作为上世纪90年代就在香港上市的企业，我们本身就具有与国际接轨的治理基础。在全球化过程中，联想又组建了真正国际化、多元化的董事会及高管团队，采用高度规范、透明的公司治理和管理架构。不管走到哪里，联想都将合规视为企业的生命线，以诚信正直的方式开展业务，尊重当地市场的法律法规和文化习俗。而可持续发展的理念，又确保联想在全球每一个市场提供创新优质的绿色产品，通过公益实践、尊重支持弱势群体来贡献社会价值，并以海纳百川的胸怀包罗天下人才。</p>\n  <p>可以说，数字化让联想走得快，ESG则让联想行得稳，两大基座提供扎实的支撑，让我们规避了许多水面之下的风险和挑战。</p>\n  <p>云路鹏程九万里，雪窗萤火二十年。20年出海征程的砥砺前行，不仅由内而外重塑了联想，更锻造了联想引以为豪的核心竞争力；而这些核心竞争力又助力联想穿越经济周期，加速迈向更高层次、更高质量的全球化。</p>\n  <p>在这里，我还要特别强调的是，中国企业在全球市场上发展壮大的基础，一定是扎根中国。回看过去这20年，联想不仅是对外的拓展，更是一种对内的赋能。我们约80%的生产制造、70%的研发人员、60%的员工都布局在中国大本营。通过深耕海外市场，我们能够更有效地整合全球资源，实现对国内市场的有力回馈，进而为国家经济的繁荣发展注入新的活力。这样的出海之路，正是中国扩大高水平对外开放的应有之义。</p>\n  <p>当我们为这一波中国企业出海所取得的成绩感到振奋时，我们也要清楚地看到，此时此刻的世界，正处于一个全球贸易格局、产业链价值链重构与技术变革浪潮交汇的关键时刻，内外部环境可以说是充满挑战。</p>\n  <p>作为中国企业，“走出去”是我们开拓海外市场、提升企业竞争力的有效路径。但仅仅走出去是不够的，还需要加速“走进去”和“走上去”。那么，具体要如何做才能达到这样的目标呢？从联想20年全球化经验出发，我有三方面的建议。</p>\n  <p>第一个建议，要重视通过本地化产品创新构建全球知名品牌。如今，全球消费者不再局限于购买传统品牌，而是更愿意尝试、探索新品牌，为更好的产品和服务买单，这意味着中国品牌有望凭借更具竞争力的产品与服务在海外市场迎来更蓬勃的发展空间。而构建品牌力的核心是产品创新，而产品创新则一定要基于对当地消费者需求的挖掘，不仅仅要物美价优，更要质量过硬。只有这样，才能得到全球不同市场消费者的信任和认可。</p>\n  <p>第二个建议，要重视通过贴近本地市场构建韧性供应链。目前全球供应链开始呈现出脆弱多变、复杂交织的新态势。对于中国企业来说，只有从出口导向跨越到深度融合的本地化，串联起更多产业链环节，搭建起更加高效、抗风险性更强的供应链，才能更加贴近本地市场，服务好当地的消费者与客户。这也是联想在日本、印度、阿根廷、巴西等多个“出海困难模式”的市场逆袭成功的关键。例如日本消费者偏爱Made in Japan的产品，我们就通过与NEC和富士通的合资，利用他们在米泽和岛根的工厂生产电脑提供给日本用户，又学习他们精良的工艺标准，以及严苛的质量把控，反哺我们国内制造能力的提升。</p>\n  <p>最后，要重视通过合作共赢塑造当地市场企业公民形象。我们选择出海，不是为了征服某个市场，而是为了融入他们。我们销售的产品与服务，要给当地消费者带来更好的体验，而并非只为了销售业绩；我们雇佣当地的员工，是为了让他们和联想实现共同发展。只有在出海时思考如何为当地创造价值，共享发展红利，成为负责任的企业公民，才能真正融入海外市场。</p>\n  <p>我相信，未来会有更多的中国企业走出国门，通过成功的跨国运营将中国智造、中国品牌的技术和产品带到更广阔的市场，增强国内国际两个市场、两种资源的联动效应，加速构建“双循环”新格局，培育国际经济合作和竞争的新优势，以高水平对外开放促进世界合作共赢。</p>\n  <p>回顾人类文明史，无论是中国古代的“丝绸之路”，还是欧洲近代的大航海时代，只有秉持探索、开放、勤奋的精神才能不断登上新大陆，桥接起自己跟外面的世界。《天工开物》说得好：“梯航万国，能使帝京元气充然”，只有融入世界的中国才是有朝气的中国。</p>\n  <p>正所谓“一花独放不是春,百花齐放春满园”。联想一直是全球化的受惠者与推动者，我们也将持续发挥自身优势，助力中国企业走向世界，推动中国与全球市场的互联互通、价值共享、共同繁荣。不仅让世界的市场，成为中国的机遇；更让中国的发展，成为世界的动力。谢谢大家！</p>", "published": "2024-10-31 08:02:08", "id": "7f97caca-7766-4e62-9a38-f69c0e0a27a7", "source": "36氪", "section": "综合资讯"}, {"title": "北交所：拟于11月2日开展交易支持平台优化第一次全网测试", "link": "https://36kr.com/newsflashes/3016207431968000?f=rss", "description": "36氪获悉，10月31日，北京证券交易所办公室、全国股转公司办公室发布通知，拟于近期开展交易支持平台优化第一次全网测试，参测机构包括北交所、全国股转公司、中国结算、深证通、证券公司、基金公司、信息商等。测试时间为11月2日。", "published": "2024-10-31 09:24:51", "id": "2df56c99-e2ac-4b42-816c-d07e422f916e", "source": "36氪", "section": "综合资讯"}, {"title": "3连板三房巷：日常经营情况正常，内外部经营环境未发生重大变化", "link": "https://36kr.com/newsflashes/3016203256161794?f=rss", "description": "36氪获悉，三房巷日公告，公司股票于2024年10月28日、29日、30日连续3个交易日内日收盘价格涨幅偏离值累计超过20%，属于股票交易异常波动情形。2024年10月31日，公司股票再次涨停。公司的主营业务为瓶级聚酯切片、PTA的生产与销售。经公司自查，公司目前日常经营情况正常，内外部经营环境未发生重大变化，不存在应披露未披露的重大信息。", "published": "2024-10-31 09:20:37", "id": "ecbd591a-eeb4-44f4-aa71-79b35e5fba77", "source": "36氪", "section": "综合资讯"}, {"title": "前三季度国铁集团实现营业总收入9007亿元，净利润盈利129亿元", "link": "https://36kr.com/newsflashes/3016200638506501?f=rss", "description": "36氪获悉，中国国家铁路集团有限公司披露了2024年前三季度财务决算。前三季度，国铁集团实现营业总收入9007亿元，净利润盈利129亿元。前三季度，全国铁路完成固定资产投资5612亿元、同比增长10.3%，投产铁路新线1820公里，其中高铁1210公里。国庆前夕，全国铁路营业里程突破16万公里，其中高铁超4.6万公里。", "published": "2024-10-31 09:17:57", "id": "0bf1a57b-0de4-439a-a379-759824402cf2", "source": "36氪", "section": "综合资讯"}, {"title": "同兴达：董事长提议回购2.5亿元-4亿元公司股份", "link": "https://36kr.com/newsflashes/3016195997902086?f=rss", "description": "36氪获悉，同兴达公告，公司董事长万锋提议公司以自筹资金等方式通过深圳证券交易所交易系统以集中竞价方式回购公司已发行的部分人民币普通股（A股）股票。回购股份拟用于实施股权激励或员工持股计划。回购股份资金总额不低于人民币2.5亿元，不高于人民币4亿元。回购价格上限不高于公司董事会审议通过回购方案决议前30个交易日公司股票交易均价的150%。回购期限为自董事会审议通过本回购股份方案后12个月内。", "published": "2024-10-31 09:13:14", "id": "4a6f049d-b8e1-4a45-b470-f7a046cb260c", "source": "36氪", "section": "综合资讯"}, {"title": "央行：10月开展了5000亿元买断式逆回购操作", "link": "https://36kr.com/newsflashes/3016192775824648?f=rss", "description": "36氪获悉，央行公告，为维护银行体系流动性合理充裕，2024年10月人民银行以固定数量、利率招标、多重价位中标方式开展了5000亿元买断式逆回购操作。", "published": "2024-10-31 09:09:57", "id": "8a776dfd-8294-43dc-9fba-264ff610f503", "source": "36氪", "section": "综合资讯"}, {"title": "2连板晋亿实业：目前生产经营活动正常", "link": "https://36kr.com/newsflashes/3016191572534792?f=rss", "description": "36氪获悉，晋亿实业公告，公司股票于2024年10月30日、10月31日连续两个交易日内收盘价格涨幅偏离值累计超过20%，属于股票交易异常波动情形。经本公司自查，公司目前生产经营活动正常，公司已披露的经营情况、内外部环境未发生重大变化。不存在影响公司股票交易价格异常波动的重大事项。", "published": "2024-10-31 09:08:43", "id": "5702fcdd-9dd1-4b70-a082-dd9eec1644ec", "source": "36氪", "section": "综合资讯"}, {"title": "香港证监会就市场探盘指引发表咨询总结", "link": "https://36kr.com/newsflashes/3016184304281097?f=rss", "description": "10月31日，香港证监会就适用于市场探盘的建议指引发表咨询总结。该指引载述了持牌人或注册人在进行最常见于大手交易的市场探盘时所适用的原则及规定，当中包括实施规程以保护在市场探盘过程中交托予他们的机密资料或消息。有关咨询的回应者普遍支持建议在市场探盘的过程中维护市场廉洁稳健的目标，其中有多名回应者提供了具建设性的反馈意见。该指引将于2024年11月1日刊宪，并于2025年5月2日生效。中介人将有六个月的过渡期来遵从有关指引。（财联社）", "published": "2024-10-31 09:01:20", "id": "32f0e20d-1936-4dbe-afbf-0c8db281b6b5", "source": "36氪", "section": "综合资讯"}, {"title": "2连板凌志软件：近期日常经营情况未发生重大变化", "link": "https://36kr.com/newsflashes/3016181323752709?f=rss", "description": "凌志软件10月31日公告，公司股票于2024年10月30日、10月31日连续两个交易日内日收盘价格涨幅偏离值累计达到30%，属于股票交易异常波动情形。经公司自查，公司近期日常经营情况未发生重大变化，内外部经营环境未发生重大变化。", "published": "2024-10-31 08:58:18", "id": "6345a888-68ef-424c-a491-0fb0bfcdbca6", "source": "36氪", "section": "综合资讯"}, {"title": "恒进感应前三季度经营性净现金流大增27倍：资产状况稳健 获北证50主题基金增持", "link": "https://36kr.com/p/3015036456117505?f=rss", "description": "<p>文 | 挖贝网 高慧</p>\n  <p>北交所上市企业恒进感应（838670.BJ）发布2024年三季报显示，前三季度实现营收4346万元，归母净利润958万元。现金流状况明显向好，前三季度经营活动产生的现金流量净额为2106万元，较去年同期增长27倍，主要是公司加强了客户跟踪力度，应收账款的回收速度提高。</p>\n  <p>分析资产负债表，恒进感应资产状况持续保持稳健。截至9月末，公司账上货币资金和交易性金融资产一共有3.16亿元，无长、短期借款，应收账款和应付账款规模均不高，公司发展资金充裕。</p>\n  <p>另外，公司9月末合同负债4729万元，较年初增长1.5倍，主要是预收客户货款增加所致，为未来业绩成长打下基础。</p>\n  <p>值得一提的是，根据三季报披露，恒进感应报告期内获北证50主题基金增持。中信建投证券股份有限公司－招商北证50成份指数型发起式证券投资基金增持了6.4万股，持股数增至29.4万股。</p>\n  <p>挖贝研究院资料显示，恒进感应从事中高档数控感应热处理成套设备及其关键功能部件研发、生产、销售和技术服务，以中高档数控感应淬火机床作为核心产品，已经实现核心技术自主可控。公司在风电装备、工程机械、汽车制造等领域具有明显市场竞争优势。</p>\n  <p>恒进感应深耕热处理技术，研发创新能力强，自主研发的多项核心技术及产品处于国内领先水平。公司拥有“湖北省企业技术中心”、“湖北省工业设计中心”、“湖北省校企联合创新中心”等多个研发机构，支持企业创新发展。截止2024年6月30日，公司拥有已授权的专利共160项，其中发明专利21项（国内发明专利19项、国际发明专利2项）、实用新型专利106项、外观设计33项（其中欧盟外观专利1项），公司另拥有软件著作权5项。</p>\n  <p>-<strong>END</strong>-</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s?__biz=MzA4NjAxODgzNg==&amp;mid=2652214124&amp;idx=2&amp;sn=60f24346afc3f15cbfe0d109f6020cc7&amp;chksm=856b9773467bdb0028233ae528423c895ed1303e35642160839aa109752bb3877f5ecf131699&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“挖贝网”（ID：wabeiwang）</a>，作者：让信披更及时，36氪经授权发布。</p>", "published": "2024-10-31 09:37:05", "id": "eb8f2322-2e48-4042-9a24-cc13207bd5e6", "source": "36氪", "section": "文章资讯"}, {"title": "湖南“扛把子”华天酒店，要抱“生活服务”大腿？", "link": "https://36kr.com/p/3015822217442436?f=rss", "description": "<p>近日，华天酒店表示在优化和强化酒店主业的基础上，还要积极发展酒店商贸、洗涤、家政、物业及安保等生活服务业。作为湖南第一家上市的酒店，36岁的华天酒店因为曾经重资产的扩张模式，导致存量资产过剩，产生固定成本高居不下的困境。现在，华天酒店积极发展生活服务业之路是摆脱困境的无奈之举，还是必要手段？老牌国资酒店面对重资产模式下带来的阵痛该如何面对，走出桎梏？</p>\n  <h2><strong>01&nbsp;搞家政、洗涤、物业的酒店</strong></h2>\n  <p>近日，华天酒店披露投资者关系活动记录表显示，公司将立足优化和强化酒店主业，积极发展酒店商贸、洗涤、家政、物业及安保等生活服务业，并通过轻资产化运营和品牌驱动等战略，推动公司高质量可持续发展并提升经营业绩。</p>\n  <p>上文所描述的生活服务业，华天酒店早在2016年就成立了湖南华天生活服务有限公司（以下简称“华天服务”），其公司隶属于湖南华天酒店集团股份有限公司全资控股子公司。该公司以“华天服务”品牌为依托，专注于现代都市大生活服务领域，具备大生活服务管理体系，大生活服务信息平台、大生活服务运营与管理等全方位现代综合型服务公司。简而言之，华天服务的业务范围就是以家政服务、洗涤服务、物业管理服务、团餐管理服务等为主的四大业务板块，构建起围绕大生活服务平台的生态圈。</p>\n  <p>有意思的是，华天服务提供的生活服务与普通酒店集团生活服务不同，后者的定义是满足客户多元化需求，致力于创造超越客户期待的服务体验，而前者的概念是不仅为酒店客户提供增值服务，还通过上平台和广泛的服务网络，为更广泛的第三方客户提供服务。如华天e生活，一个华天集团旗下高端型到家生活服务平台，提供洗衣到家以及家政到家服务，依托华天集团五星级服务理念，想让更多客户在家能感受五星酒店的服务。搜索了解到，华天服务的服务对象包括党政机关、央企/国企、金融机构、大中专院校等企事业单位和个人客户。如2022年在中国银行成立110周年之际，华天服务正式承接中国银行物业服务。</p>\n  <p>可见，华天酒店是一家以酒店服务业为主，覆盖物业管理、洗涤、家政、团餐及商贸等大生活服务内容的跨区域综合性现代服务企业，形成“1+N”多业态并进的产业布局，并早早进入生活服务业赛道，想走轻资产的道路。然而虽然提前意识到重资产会对自己产生众多成本方面的影响，将精力分散给生活服务业板块上，但是效果还是一般。</p>\n  <p>根据2024年上半年财报显示，华天酒店实现营业收入3.06亿元，同比增长0.24%，其中酒店服务业作为公司的主要收入来源，占营业收入的比重为89.72%，同比上升47.28%。另一边的生活服务业，实现了稳定的增长，占营业收入的比重为9.25%，同比增加32.46%。尽管华天酒店在酒店和生活服务业板块实现了同比增长，但是 2024 上半年归母净利润亏损 7877 万元，只是较2019 年同期亏损额 13640 万元相比有所减缓。</p>\n  <h2><strong>02&nbsp;华天身上的“大山”</strong></h2>\n  <p>曾几何时的湖南酒店“扛把子”，现在却抱住生活服务业的腿，想要得到一些喘息。36岁的华天酒店，身上的“大山”从什么时候开始背上的？</p>\n  <p>1988年，华天酒店正式开业。1992年，华天大酒店成为湖南省第一家四星级酒店，填补了当时湖南没有高星级涉外宾馆的空白。1997年12月28日，华天大酒店成为湖南省第一家五星级酒店。华天酒店于1996年在深圳证券交易所上市。彼时的锦江酒店刚刚上市2年，首旅如家、华住、君亭等品牌甚至还未问世。</p>\n  <p>此后，华天酒店的业绩长期以来都表现比较稳定。华天酒店在很多湖南人记忆中是“高档、优质、有品位”的代名词，也是湖南省酒店行业中的“标杆”和“门面”。然而，好景不长，2014年华天酒店首次出现亏损，净亏损达到9884万元，并且此后基本一直处于亏损状态，持续了10年之久。为何华天酒店会沦为此番局面？</p>\n  <p><strong>/ “内忧”</strong></p>\n  <p>2007年，华天酒店为适应经济型酒店市场的发展，投资成立了酒店管理公司华天之星，在短短几年内占据了湖南经济型酒店市场份额的第一位。但随后几年业绩不如预期且培育期业务资金需求较大，带来的负担，促使2011年将其以1.36亿元转手7天连锁酒店集团，剥离自营经济型酒店业务，并表示之所以将华天之星对外转让，是因为公司的发展模式已向“酒店+商业地产+旅游”转变，想将资金集中用于高星级酒店的经营管理与旅游资源的开发。</p>\n  <p>当时正是酒店业发展黄金期阶段，出售华天之星，错失了经济酒店带来的红利，为随后低迷的业绩埋下了伏笔。而且，后来的华天酒店并没有实现新的发展模式，并未直接涉及旅游资源开发业务。</p>\n  <p>很不巧的是，自2012年底以来，受“严控三公经费”“八项规定”等政策的影响，国内高端酒店市场行情急转直下。华天酒店“高星级酒店”的业务遭遇增长“瓶颈期”，想实现“酒店+旅游+地产”的模式最终只停留在了纸面构想上，成为业绩增长的阻碍。</p>\n  <p>意识到问题的华天酒店，计划开展多元化经营，在2015年引入民营资本华信恒源，希望达到1+1＞2的效果。自启动混改之后，华天酒店对产业链进行延伸，包括健康、理财、旅游等。然而，多年过去，不但没有实现大的突破，业绩反而每况愈下。</p>\n  <p>华天酒店战略上的失误将其带入一次次泥潭中，处在时代风口，却错失一次次机遇令人惋惜。</p>\n  <p><strong>/ “外患”</strong></p>\n  <p>目前，根据华天酒店集团官网公布，华天酒店在湖南省可预订的酒店为21家，其中坐落在长沙的只有6家，且全是高端酒店，另外还有三家在省外，分别在北京、湖北武汉、吉林长春。作为老牌的湖南上市酒店企业，华天只能用“成绩平平”来形容了。</p>\n  <p>单从湖南市场来看，相关数据显示，截至2022年底，湖南各档次酒店存量共计14617家，位列全国第八；连锁化率仅23%左右，和排名第一的上海相差了将近37个百分点。在酒店存量市场的红海下，湖南酒店市场，尤其是新一线城市的网红长沙，已经成为酒店集团进入华中市场的必争之地。如今，长沙五星级酒店的平均出租率达到了72.48%，在全国重点旅游城市中排名第一（详细可见往期文章“出租率70%全国第一，五星级酒店为何青睐‘顶流’长沙？”），可见高端市场竞争之激烈。</p>\n  <p>作为长沙曾经的酒店“扛把子”，华天酒店在高端市场上的酒店份额正在被不断挤兑，外部的竞争压力和内部的战略失误使得华天酒店亟需“求生”。</p>\n  <h2><strong>03&nbsp;华天的“自救”之路</strong></h2>\n  <p>内忧外患的华天酒店身上的“大山”可能太重了，因此华天酒店在2012年提出“重资本、轻资产”的经营模式，开始对部分酒店资产保留经营权、按照市场价格对外出售所有权来盘活手中沉淀的重资产，这标志着华天酒店开始有意识地向轻资产路径转型。从这几年华天酒店在轻资产转型的动作上，可以将其大致分成三个方向。</p>\n  <p><strong>/ 屡次出售重资产</strong></p>\n  <p>华天酒店首次出售自己的资产可以追溯到2015年，以3.9亿元出售了旗下紫东阁华天大酒店100%的股权。此后，2016年华天酒店以1.2亿元出售了旗下银城华天大酒店，以及在2017年出售了北京世纪华天酒店管理有限公司51%的股权，转让价格为5.4亿元。</p>\n  <p>有意思的是，华天曾经推崇的“酒店+旅游+地产”模式下，以“房地产开发销售”为主营业务的10个子公司中，仅有北京世纪华天酒店管理有限公司盈利338.26万元，其他从事房地产开发销售的子公司均出现不同程度的亏损。在2017年前三季度连续亏损的阴影下，同年12月份，华天酒店出售北京世纪华天酒店管理有限公司51%的股权，最终使得第四季度扭亏转盈，“卖子保壳”的动作明显，也为后来退出房地产业务，主营酒店服务业务埋下伏笔。</p>\n  <p>时间来到2020年，伴随“混改”效果甚微，加之疫情的冲击，华天酒店业绩再一次掉入泥潭，又开始“卖子之路”。2021年，华天酒店将北京浩搏项目通过破产拍卖方式以7.2亿元成功挂牌转让，完成首次债权清偿收回资金2.13亿元；同年张家界华天城项目公司70%股权与债权转让，交易价款为8141万元。2022年，华星物业房屋及土地使用权资产实现去化将产生处置收益预计6263.63万。</p>\n  <p><strong>/ 发展多元化业态</strong></p>\n  <p>走“去重化”的轻资产路不能只通过出售资产来摆脱亏损，如果单纯依赖对原来重资产的处置和盘活，也还是难以扭转华天的亏损局面，即使短期内实现扭亏，也并非长久之计。因此，华天酒店在推进轻资产战略的同时，探索多元化发展途径，寻求更稳健的第二增长曲线。</p>\n  <p>从具体做法来看，华天酒店以上市公司为融资平台，继续开拓酒店相关业态。其一，华天酒店拓展物业、团餐等新业态，形成洗衣、家政、物业、团餐一体化业务结构和竞争优势，这便是上文所提及的“生活服务”板块。该板块从2020年1747.48万元一路上涨至2023年6359.13万元，增长速度迅速。其二，华天酒店发展酒店物资贸易业态，大力推进企事业单位、外部连锁酒店、学校食堂等外部大宗贸易业务市场，强化与公司优质集采供应商双向联动，从而实现业务市场内外协同闭环。其三，华天酒店还发展教育培训业态，与省旅游饭店协会开展深度合作，统筹资源；同时还密切联系各地级市饭店协会等，承办协会活动，扩大品牌影响力。</p>\n  <p><strong>/ 强调品牌输出管理</strong></p>\n  <p>在酒店业务板块，华天酒店致力于品牌输出，注重打造“华天大酒店”“华天国际酒店”“华天假日酒店”“华天精选酒店”等品牌，涵盖五星级、四星级、度假酒店以及中端商务等不同市场定位。酒店以自营高星级酒店发展为主、品牌输出为辅进行酒���连锁经营管理。</p>\n  <p>数据显示，截至2023年末，华天酒店自营加托管开业酒店共40家，其中自营酒店17家，托管酒店23家。2015年至2020年以来，华天酒店的托管酒店占比始终高于66%。但是，目前来看华天酒店无论是自营还是托管酒店数量都在减少，2023年托管酒店的占比只有42.5%，下降趋势明显，酒店业务的格局似乎又回归到最初。</p>\n  <p>生活服务业务的注入和其他轻资产的行为，使得华天酒店固定资产总金额在不断减少，但是固定资产在总资产中的占比无明显下降趋势，资料显示截至2023年8月末，华天酒店的固定资产占总资产比重为61.73%，“大象转身”依旧艰难重重。</p>\n  <h2><strong>04&nbsp;“第二增长曲线”的背后</strong></h2>\n  <p>如今，华天酒店“腹背夹击”，走轻资产的路，做品牌输出固然是大方向，但是身处在湖南“大本营”的华天酒店，该如何在竞争激烈的酒店市场中站稳脚跟？</p>\n  <p><strong>/ 清晰具象化的品牌特色</strong></p>\n  <p>品牌是一家酒店集团的门面，其特色是酒店集团差异化的显现。谈及酒店集团可能消费者们还不太熟知，但是如果一家品牌的位置、装饰、文化、氛围、故事、服务足以吸引人，那么会给消费者留下深刻的印象，因此，酒店集团在酒店激烈的竞争下，清晰具象化的品牌特色是酒店集团打出竞争优势的关键。</p>\n  <p>如雷迪森旗下奢华精选酒店品牌雷迪森庄园，将传统文化、酒店文化和品牌文化融合打造主题酒店，如主打“茶文化”的杭州雷迪森龙井庄园和主打“禅文化”的雷迪森普陀山庄园。一个出圈的品牌与传统文化的巧妙结合，打造出独特的品牌特色，对国资酒管轻资产输出的作用不言而喻。华天酒店尽管也有多个品牌，但是品牌特色对于消费者来说还是比较模糊，需要提炼标签，在占领消费者心智上下点功夫。</p>\n  <p><strong>/ 专业可靠的运营管理能力</strong></p>\n  <p>值得注意的是，轻资产模式的确是国资酒管盘活存量资产、助推规模扩张，有效摆脱重资产枷锁的一种方式，但是在这过程中国资酒店还是会出现连年亏损、资不抵债的情况，面对这些问题还需要更专业可靠的运营管理能力。</p>\n  <p>伴随酒旅行业消费者逐渐理性、房地产红利的消失，地方国资酒店在品牌输出的营销服务上需要调整战略，从盲目扩张转为精细化、专业化的运营。一方面，引进专业管理团队和先进经验，打造一支专业、懂技术、会运营的酒店人才队伍。另一方面，加快数字化转型步伐，通过智能化系统提升服务效率和客户体验，如金陵饭店建设直销平台“尊享金陵”小程序，实现GMV(商品交易总额)&nbsp;1.81亿元，同比提升67.59%。对于华天酒店来说，除了战略定位，这么多年的“命途多舛”本质上还是出在运营管理问题上。一位不具名的华天酒店内部员工告诉空间秘探，华天酒店既国资背景，也有民企模式，还有地产思维，所以在管理上确实存在着比较复杂的“挣扎”，不能说“朝令夕改”，但是近年来各种变化确实多了点。</p>\n  <p><strong>/ 多双手协同合作</strong></p>\n  <p>国资酒店品牌一方面背靠地方国资背景，可以积极利用国旗平台优势，把国有性质的酒店进行业务整合；另一方面也可以跳脱国企思维，与更多酒店集团合作，打造更多品牌之间的可能。</p>\n  <p>空间秘探认为，华天酒店在“第二增长曲线”提早布局“生活服务”，取得一定的成绩，并且未来可能持续重仓这一板块，战略上并无问题。但回顾华天酒店近些年的曲折路，最重要的还是要做强华天酒店这个曾经的金字招牌，不能像狗熊闯进玉米地，掰一个丢一个。华天酒店在湖南的“朋友圈”众多，各种资源自然丰富，利用这样的“人脉”去开拓各类“生活服务”产业水到渠成。不过，需要提醒的是，“生活服务”固然是好，但毕竟是“第二曲线”。如果主业都做不好，“第二曲线”的那点收入很可能杯水车薪。</p>\n  <p>综上，积极发展生活服务业是华天酒店探索轻资产模式的“新路”，无可厚非，但在紧抱“生活服务”大腿的同时，华天酒店的去债减重、资产优化、品牌战略或许更是要花大力气解决的问题。</p>\n  <p>本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/QMgHUgSC5m3bE6kLbwNIBA\" rel=\"noopener noreferrer\" target=\"_blank\">“空间秘探”</a>，作者：秦敏慧，36氪经授权发布。</p>", "published": "2024-10-31 09:42:00", "id": "702213e1-247f-4ff0-ac3e-1cbb4a1296c7", "source": "36氪", "section": "文章资讯"}, {"title": "最好的人生：既认真，又不认真", "link": "https://36kr.com/p/3015930406905096?f=rss", "description": "<h2><strong>01</strong></h2>\n  <p>怎样的人生状态是最好的？&nbsp;</p>\n  <p>我的答案是：既认真，又不认真。</p>\n  <p>在你的一生中，如果<strong>只有认真，</strong>你就很容易在日复一日的认真中，陷入执著，甚至痛苦、沉重的就像是背了一整座山。</p>\n  <p>相反，在你的一生中，如果<strong>没有认真，</strong>你又很容易会感受到生命的虚无，对一切越来越无所谓，于是不再努力，也没有追求。</p>\n  <p><strong>由此可见，太认真，会陷入执着，不认真，则会走向虚无。</strong></p>\n  <p>而这种既认真，又不认真的态度，才是一个人的最好状态，它会让你对每一天都很投入、很努力，同时又会让你很超脱、很自由。</p>\n  <h2><strong>02</strong></h2>\n  <p>那么，在平时的生活工作中，我们又该如何做到“既认真，又不认真”呢？</p>\n  <p>我认为主要是以下三个方面：</p>\n  <h3><strong>1、对过程认真，对结果不那么认真</strong></h3>\n  <p>这里的“对结果不认真”，说的并不是不考虑结果，也不是不设定目标。</p>\n  <p>“对结果不认真”说的是：<strong>不总是把结果的好坏挂在心上，不总是为结果担心焦虑，甚至会提前体会到结果落空后的恐惧。</strong></p>\n  <p>同时又对过程认真，这点说的是：<strong>关注过程、在过程中保持持续投入、努力与深入的感受。</strong></p>\n  <p>比如，当我写书的时候，我对写书的过程极其认真、非常投入，我把这些年读过的书、思考过的问题、经历过的人生、体验过的一切，酿成了一壶浓郁的酒，然后认认真真地把它呈现在读者的面前。</p>\n  <p>所以，写书时的每一天都是我充满心流，非常享受的时光。</p>\n  <p>然而，这本书在出版后能否成为畅销书，能否在某某平台得到高分评价，虽然我也有所期望，却不为之牵肠挂肚、日日操心，也就是说这些结果都不是写书的我所关心的事。</p>\n  <p>当我写书的时候，我就只对这个酝酿、创造和写作的过程非常认真，一万分的认真和投入。</p>\n  <p>这就是对结果不认真，但对过程非常认真和投入的体现。</p>\n  <p><strong>相反，如果我对结果认真，对过程不认真，那又会带来什么呢？</strong></p>\n  <p>那会让我做不好写书这件事，因为我在写书的每一天看似在写书，实际却是在忧虑、焦虑，甚至恐惧中度过，写着写着我就开始担心起来，担心自己写的书没人喜欢看，担心最后卖的不好。</p>\n  <p>这样做会带来怎样的结果呢？</p>\n  <p>1、我写不出好书，因为我根本没有认真投入。</p>\n  <p>2、我写书时的每一天都不快乐。</p>\n  <p>简言之，就是既痛苦又没拿到好结果。</p>\n  <p>幸好，我不是那么做的，我对过程非常认真，但对结果不那么认真，于是我就在做这件事的过程中获得了美妙的心流体验，并收获了体悟和成长。</p>\n  <p>正如乔布斯所说：<strong>“The Journey Is The Reward（过程本身就是奖励）”。</strong></p>\n  <p>最终，也许你会收获意外之喜 - 正是因为你对过程给予了全身心的投入，所以它也更可能会为你带来无比美妙的果实与你期盼的结果。</p>\n  <h3><strong>2、对当下认真，对过去和未来不那么认真。</strong></h3>\n  <p>曾经的我，要么反省和后悔过去，要么担忧和憧憬未来，总之，很少有时间完完全全的活在当下。</p>\n  <p>后来，我则大不相同 - 对于未来，我只做畅想和规划，对于过去，我做复盘和学习。然后，我会把大多数的时间和精力都投入到当下的每一刻里，或沉浸于阅读、思考、工作的心流，或沉浸于对自然和艺术的感知，或全心全意的与家人朋友交流，或感受彻彻底底的放空下来。</p>\n  <p>当然，直到现在我也做不到100%的活在当下，但是这个处于当下的时间比例比起多年以前已经有了巨大的提升。</p>\n  <p>可是，这个转变究竟是如何发生的？</p>\n  <p><strong>其关键在于：我对过去发生的一切与未来也许会发生的事情变得越来越不认真了，也就是越来越不在乎了，相反，我把自己的精力和关注都集中在了当下，我对当下十万分的认真。</strong></p>\n  <p>事实上，当下才是我们每一个人唯一能够把控的东西，过去的事既然已经过去，就是无法改变的，我们要柔顺地接纳过去。如果过去令人痛苦，我们就更加不必认真，可以把它当作一场梦，或是一个已经结束的游戏，然后把过去归零，以全新的状态进入当下刚刚开始的游戏中，认认真真地把握当下。</p>\n  <p>至于未来，我们当然要有梦想、愿景、方向，但是因为一切结果都是由内因外因一起决定的，即便我们拥有明确的梦想和愿景，即便我们非常非常的努力，依然无法100%的把控未来可能出现的事，更无法保证未来一定会出现某个必定的结果。</p>\n  <p><strong>既然过去不能改变，未来无法100%把控，那么我们要做的就是对当下这一刻无比认真地投入。</strong></p>\n  <p>同时，因为未来是由现在决定的，所以与其担忧未来，不如满怀热情的投入当下，用当下的努力去创造想要的未来。</p>\n  <h3><strong>3、对自己的成长认真，对身外之物不那么认真。</strong></h3>\n  <p>很多人每天都在琢磨“我啥时候能升职”、“我啥时候能换个大房子”、“我啥时候能财务自由”。这些，就是我们的身外之物。</p>\n  <p>身外之物要如何获得？</p>\n  <p>它需要两方面的条件：一方面，需要我们的内因，也就是足够的天赋与努力。另一方面，它需要恰如其时的外因，只有二者配合得好，我们才有可能获得一个又一个的身外之物。</p>\n  <p>前者，我们可以通过投入去获得，后者则需要机缘巧合，需要天时地利人和。</p>\n  <p>换句话说，身外之物不是我们100%保证一定会获得的。</p>\n  <p>这样一来，如果你对自己的身外之物非常认真，甚至是执著，那么最终的结果就早已注定 -&nbsp;<strong>既然你无法100%保证一定会得到你想要的身外之物，那你自然就会在得不到时陷入痛苦。</strong></p>\n  <p>如果从另一个方面来讲，如果把你已经拥有的，以及想要拥有的一切身外之物放到足够长的历史长河中去看，相信你很快就会发现，这些物质财富，最终都是过眼云烟，最终都会一一失去。</p>\n  <p><strong>然而，你却为了这些过眼云烟耗尽了自己的青春、自己的人生、自己的梦想与自己的热情，简言之，你为了获得令自己满意的“身外之物”付出了自己唯一一次的宝贵人生，可你却丝毫不曾意识到。</strong></p>\n  <p>有句话说出了很多人的真实人生写照：<strong>“做着自己根本不喜欢的工作，为的是去买自己根本不需要的物品，然后在不喜欢的人面前显摆。”&nbsp;</strong>而这也是我一直在说的：<strong>“很多人过得都是本末倒置的人生。”</strong></p>\n  <p>所以，对待自己已经拥有的身外之物，以及想要的身外之物，其实真的不必那么认真，因为它不仅无法保证100%的获得，同时最终也会成为过眼云烟。</p>\n  <p>那么，你究竟应该对什么认真呢？</p>\n  <p><strong>你应该对自己能够100%掌控的事情，且对你的一生至关重要的事情认真。</strong></p>\n  <p>这个事说的是什么？</p>\n  <p><strong>我说的正是你的自我成长。</strong></p>\n  <p>自我成长是可以通过努力及正确的方法实现的，而且自我成长是对我们一生都至关重要的。</p>\n  <p>与追求身外之物不同，与其把钱拿去买那些并不那么需要的物品，然后人前显摆或填补内心空洞与恐惧，<strong>倒不如好好的投资在自己的Being上，也就是“我的存在状态”上，从而支持自己获得不断成长与进化。</strong></p>\n  <p>从我自己这些年的亲身经验来看，我发现：<strong>当一个人的内在开始持续成长和进化后，他/她的外在就会发生非常大的变化，甚至是翻天覆地的变化，这时，你会发现人生虽然还是那个人生，但它却已完全不同了，与此同时，以前想要获得的事业发展、关系进展都会自然而然的变得顺利，而身外之物的财富也会跑上门来找你。</strong></p>\n  <p>因此，对于自我成长，你要非常认真，100%地投入，而对身外之物则无须认真，不妨超脱一些、洒脱一些。</p>\n  <p>以上三点，综合起来就是我所说的最好的人生态度 - 既认真，又不认真。</p>\n  <h2><strong>最后的话</strong></h2>\n  <p>这个人生态度真的很好，它让我既不会躺平，又不会执着于占有；既不会没有成就，又不会被想要得到的结果折磨得忧心忡忡，因为忧虑、担忧、恐惧而睡不着觉。</p>\n  <p>这个人生态度，给了我一种非常美妙的平衡，现在我也把它送给你 - 它能让我们从看不透、舍不得、放不下的状态中走出来，走向通透、豁达和自在，它让我们有机会在投入与超脱间自由转换、轻盈起舞，并收获既投入、又超脱的人生境界。</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MzA4NTU3NjAwNg==&amp;mid=2650073008&amp;idx=1&amp;sn=d249e48a6e7a6092f8560ec6f63da2dc&amp;chksm=866659797a88c8c24bacd08118ac9c782bfd39a89833b88c97134eabcfe3b9f64b2e01a98738&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“艾菲的理想”（ID：aifeidelixiang）</a>，作者：艾菲的理想，36氪经授权发布。</p>", "published": "2024-10-31 09:38:49", "id": "dca64d23-4b8f-47a0-aa8a-8d6dba61399c", "source": "36氪", "section": "文章资讯"}, {"title": "三峡水利10月31日缩量上涨0.27%", "link": "https://36kr.com/p/3016221171934727?f=rss", "description": "", "published": "2024-10-31 09:39:04", "id": "5a58de2d-ae40-411b-9187-f7fdf8c3ab14", "source": "36氪", "section": "文章资讯"}, {"title": "毛利率超过LV，国货美妆崛起了？", "link": "https://36kr.com/p/3016102290220296?f=rss", "description": "<p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_396e4a57865c47ad820c278a8a40d41e@000000_oswg1335076oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p><strong>｜GUIDE｜</strong></p>\n  <p>■国货美妆品牌的路径依赖</p>\n  <p>■盈利能力已赶超国际大牌</p>\n  <p>■国货美妆能不能卖贵？</p>\n  <p>今年双11，国货美妆出尽风头。&nbsp;</p>\n  <p>“美妆品牌厮杀正酣 国货首轮交锋中领先”“国货美妆跑出加速度”“'史上'最长双十一预售开启优质国货品牌持续赶超国际大牌”，此类报道比比皆是。&nbsp;</p>\n  <p>这边是烈火烹油、热闹喧嚣，那边，国际大牌虽然仍然有重要的市场地位和市场份额，但也显得落寞不少。&nbsp;</p>\n  <p>欧莱雅，今年前三个季度，中国所在的北亚成为欧莱雅集团唯一负增长地区，在今年第三季度还有跌幅��大的趋势。欧莱雅首席执行官叶鸿慕，将中国市场的表现称为“出乎意料的动荡”。&nbsp;</p>\n  <p>雅诗兰黛，受中国大陆地区高端美妆消费疲软和上半财年亚太区旅游零售下滑，2024财年收入下滑1.9%。&nbsp;</p>\n  <p>一进一退之间，颇有一种国货支棱起来，早晚把国际大牌打回老家的快意恩仇感。&nbsp;</p>\n  <h2><strong>01 中国人更懂中国人？</strong></h2>\n  <p>国货这几年确实发展不错，韩束在抖音焕发第二春，珀莱雅通过早C晚A占住心智，花西子通过李佳琦和国风出圈，毛戈平以专业圈粉，成功在香港IPO，薇诺娜几乎被奉为敏感肌这一赛道里的神。&nbsp;</p>\n  <p><strong>众所周知，近几年，供给端是越来越饱和，取悦消费者越来越难，国货美妆品牌于是在销售环节下了大功夫。</strong></p>\n  <p>用户喜欢刷视频，品牌就在看短视频的平台生产视频；用户喜欢看爽剧，品牌就投资拍摄；用户喜欢在直播间里蹲着，品牌就一二三上链接；用户喜欢能提供情绪价值的主播，品牌就排着队给主播送钱。&nbsp;</p>\n  <p>主打一个“宠粉”。&nbsp;</p>\n  <p><strong>国际大牌也不是不懂入乡随俗这一套，早在2021年底，倩碧就在快手推出了短剧《狐系女友惹不起》，只不过相比较来说，国际大牌更加克制、收敛。</strong></p>\n  <p>有媒体不完全统计，从2023年到2024年9月，有超过20个国内外美妆品牌定制了80部短剧，其中韩束最多达到28部，其次是珀莱雅11部，然后是OLAY、丸美等品牌。&nbsp;</p>\n  <p>尝到甜头的上美股份（韩束母公司）2023年收入增长了56%。&nbsp;</p>\n  <p>成为短剧品宣典范之后，韩束的创始人吕义雄曾发朋友圈称，称韩束在2023年11月以后，基本不做短剧。但短剧营销这个赛道还是不断有后来者加入。&nbsp;</p>\n  <p>《短剧营销正当时：2024年H1微短剧行业观察与营销指南》数据显示，2024 年上半年品牌合作商业微短剧数量同比增长 68%，几乎比去年翻了一倍。&nbsp;</p>\n  <p>短剧，是美妆品牌无孔不入的营销里的一部分。&nbsp;</p>\n  <p><strong>花在销售环节的钱，基本都可以算是销售费用，美妆品类的销售费用率这个环节花费高，并不稀奇，这也是京东发力美妆的原因。</strong></p>\n  <p>关键是，国货美妆品牌的销售费用率现在已经高得过分了。&nbsp;</p>\n  <h2><strong>02 销售用力过猛，溢价能力赶超大牌</strong></h2>\n  <p>以韩束的母公司上美股份为例，今年上半年，销售费用从8.5亿涨到了21亿，增加了1.4倍，其中增加最多的不是多给员工开工资了，而是营销和推广开支，增加1.7倍。&nbsp;</p>\n  <p>高营销、高推广，的确换来了上美的增长，但是收入增幅远不及销售费用增幅。这也说明，在销售方面花的钱越来越难撬动收入增长。原来营销上多花一块钱，收入可能能增加两块，现在只能多增加一块七的收入。&nbsp;</p>\n  <p><strong>换句话说，用销售换增长的性价比越来越低。</strong></p>\n  <p>今年上半年，上美的销售费用率达到了57.6%，2022和2023同期，分别是48.2%和53.6%。两年提升了近10个百分点。&nbsp;</p>\n  <p>所以，上美很可能并没有放弃以短剧等方式换增长，路径依赖是很难摆脱的。&nbsp;</p>\n  <p>珀莱雅销售费用率的增长比较平缓，2020年之前基本在40%以下，2020年之后在40%——45%之间，今年到了46%，落入到45%——50%区间。&nbsp;</p>\n  <p>薇诺娜的母公司贝泰妮，甚至因为在销售方面投入过多，比如主动加大某短视频平台渠道种草、引流等宣传投入和增加品牌代言、联名活动等广告营销，而出现了第三季度单季度亏损，这也是贝泰妮上市以来的首个亏损季。&nbsp;</p>\n  <p>再来看国外大牌。国外上市公司用的口径是广告营销开支占收入的比重，与销售费用率略有不同。&nbsp;</p>\n  <p>雅诗兰黛2024财年（2023.7——2024.6）为23.4%，欧莱雅2024年上半年为32.5%，参照国外的口径，上美股份约在47%，珀莱雅在41%左右。&nbsp;</p>\n  <p>销售环节花的钱越来越高，带来的收入越来越低，正常情况下，净利润率会受损。&nbsp;</p>\n  <p>但上美、珀莱雅、毛戈平都没有出现净利率下降，甚至还在上行。尤其是上美，2022年，净利率5%，2023年接近11%，今年上半年高于11%。&nbsp;</p>\n  <p><strong>因为他们发现，销售环节烧的钱，可以通过提价的方式补回来。于是他们毛利率也在上涨。</strong></p>\n  <p>上美股份、珀莱雅的毛利率和他们各自的销售费用率的变动很相似。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_da96a399b8d448e2ba702c06de363371@000000_oswg41557oswg987oswg586_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>近两年，上美股份销售费用率和毛利率都提了10个百分点左右，毛利率最高达到了76%。珀莱雅的毛利率在2021年之前，基本在60%—65%区间，之后在65%—70%区间。毛戈平的毛利率更高，一直稳定在80%—85%。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_bfd5a8233a2a401d9d0815b1acb69ee8@000000_oswg41158oswg953oswg577_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>毛利率代表了品牌的溢价能力，是非常能说明市场地位的一个指标。&nbsp;</p>\n  <p><strong>国货美妆的这个毛利率水平，一点不输欧莱雅、资生堂、雅诗兰黛。这三大品牌，不说是奢侈品吧，至少也是国际大牌，功效能不能赶得上，这个见仁见智，品牌力肯定落了一大截。</strong></p>\n  <p>实际上，代表奢侈品的LV集团毛利率和我们的国货美妆比起来，也稍显逊色。&nbsp;</p>\n  <h2><strong>03 国货能不能卖高价？</strong></h2>\n  <p>关于国货能不能卖高价，这个争议从羽绒服到手机、美妆品牌，一直都有。&nbsp;</p>\n  <p>有人说，国货可以卖高价，但要贵得有道理，而不是反向指责消费者不努力。&nbsp;</p>\n  <p>也有人说，卖得贵才能给员工、工人发更多的工资，带动就业，才能促进消费——再生产的正循环，这种说法理论上是对的。&nbsp;</p>\n  <p><strong>按照现在的运作模式，你花1000块钱，有200多付给了生产这个商品要用到的料、工、费，有500多给了主播，给了拍短剧的，给了投流的平台，给了销售人员的工资……。这其中，生产人员、销售人员工资占的比重很小。</strong></p>\n  <p>还有观点认为，舆论是国货品牌附加值的拦路虎，是阻挡我们文化自信的拦路虎。&nbsp;</p>\n  <p>真自信，就该赚洋人的钱。&nbsp;</p>\n  <p>手机品牌海外定价比国内贵，哪个不拍手称好，当年的瑞幸，在国内补贴消费者，在国外上市融资，那可是被称为民族之光的，当然这不是说提倡欺诈、违反商业道德，就单纯说，我们的产品、品牌、股票到了国外，受到外国人的追捧，是不是才算真正的扬眉吐气。&nbsp;</p>\n  <p><strong>上面提到的几个品牌，都还没怎么走出大陆这个圈。</strong></p>\n  <p>除了自信这个层面，品牌赚钱，那是管理层、股东的宏大叙事，消费者首先要关心的是自身利益，其他都要往后排。&nbsp;</p>\n  <p>而且毛利率到了百分之七八十的水平，管理层、股东也应该警惕了，毕竟毛利率不能高到天上，到这个水平之后，要么稳，要么降。&nbsp;</p>\n  <p>比如贝泰妮2020年以前的毛利率在80%+，后来因为薇诺娜改换销售渠道、工艺包装等方面的变动，以及原本收入增幅有大幅放缓，贝泰妮选择收购姬芮（Za）和泊美（PURE&amp;MILD）等原因，整体毛利率降到了73%左右。&nbsp;</p>\n  <p>乐观一点的情况是，毛利率稳定在高水平，但按照现在营销投放回报越来越低的趋势，销售费用率是很难往下降的，那么净利率就要往下走。&nbsp;</p>\n  <p><strong>保持高毛利率的根本在于“长红”而不是“网红”，长红品牌，必须维持产品力、渠道力、品牌力之间的动态协同平衡，任何要素都不应成为长期的短板。</strong></p>\n  <p>保持高毛利率的根本在于你一直有好东西，而不是一直换着花样“说”你有好东西。如果过于专注价值传递和传播，而价值创造跟不上，那么早晚会走歪，甚至翻车。&nbsp;</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5ODY1NTIzNg==&amp;mid=2247494279&amp;idx=1&amp;sn=71fd614ee9aa7bd765e9d12e58e65da4&amp;chksm=c1b364800fb2bb35f126cc35d102355959f874f0cc46b7e66d41f45e09bf3f08cd760fe9df84&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“市值榜”（ID：shizhibang2021）</a>，作者：贾乐乐，36氪经授权发布。</p>", "published": "2024-10-31 09:32:46", "id": "dbf6ad3e-3e7b-4b11-a283-21e318fe03d4", "source": "36氪", "section": "文章资讯"}, {"title": "光线传媒10月31日缩量上涨0.8%；光线传媒前三季度营收增长超五成", "link": "https://36kr.com/p/3016253385024775?f=rss", "description": "", "published": "2024-10-31 10:11:59", "id": "91c1c7d0-6a5f-4c1f-82b5-c826a27d87e1", "source": "36氪", "section": "文章资讯"}, {"title": "美国最强500家公司中，为什么有1/3的总部在小镇上？", "link": "https://36kr.com/p/3015927542211845?f=rss", "description": "<p>沃尔玛，响当当。&nbsp;</p>\n  <p>如果拿营业额来排名的话，沃尔玛是全球最大的公司。&nbsp;</p>\n  <p>不过，很多人可能不知道，它的起源地竟然在一个小镇。&nbsp;</p>\n  <p>1945年二战结束后，沃尔玛创始人山姆·沃尔顿拿着25000美金租下了阿肯色州新港小镇一家因经营不善快要倒闭的杂货店。&nbsp;</p>\n  <p>自他接手后，杂货店的营业额直接从之前的7万美元飙升至第一年的10万美元、第二年的14万美元、第三年的17万美元。&nbsp;</p>\n  <p>后面这家店的原店主看见杂货店生意不错，就把店面收回了。&nbsp;</p>\n  <p>无奈山姆·沃尔顿只能在1951年搬到阿肯色州的另一个小镇本顿维尔。&nbsp;</p>\n  <p>他买下了一家400㎡的杂货店，取名“沃尔顿5分~1角商店”。&nbsp;</p>\n  <p>那时候，本顿维尔的常住人口只有3000人左右，还是一个没有成型的mini镇。&nbsp;</p>\n  <p>1960年底，沃尔玛已经有15家商店分布在小镇附近，年营业额达到140万美元。&nbsp;</p>\n  <p>1969年11月，沃尔顿又在本顿维尔城南建起了自己的公司总部，占地5万多平方米。&nbsp;</p>\n  <p>同时，山姆·沃尔顿雇佣了包括33位分店经理、45位助理经理、9位主管和采购人员在内的650位员工，并付给管理人员远超小镇平均水平的工资。&nbsp;</p>\n  <p>走到这一步的沃尔玛早已开始反哺本顿维尔，不仅拉动了当地就业和消费，更是促进了小镇通讯和交通设施完善。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_0db0d9b71b1b40e2b5757653da3a8d8a@000000_oswg39996oswg597oswg398_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">山姆·沃尔顿和他的商业帝国沃尔玛&nbsp;</p>\n  <p>其实不止沃尔玛，在美国有个很有意思的现象：&nbsp;</p>\n  <p>很多大企业都发源于小镇，还把总部定在小镇。&nbsp;</p>\n  <p>根据2018年福布斯排行榜数据统计，美国最大的500家公司中，有接近1/3的公司把总部定在小镇。&nbsp;</p>\n  <p>比如，百事可乐的总部在美国纽约州威斯特彻斯特县的哈里森镇；强生公司的总部在新泽西州的罗斯兰德镇；麦当劳的总部在芝加哥近郊的橡树溪镇。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_f6975a084186481087d606ba1f710f80@000000_oswg65668oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">百事可乐&nbsp;</p>\n  <p>为什么这么多美国大企业都发源于小镇，最后把公司总部也定在小镇，这些小镇究竟有什么魅力？&nbsp;</p>\n  <h2><strong>搞企业，靠自己</strong></h2>\n  <p>美国总体上，对微观经济直接干预不多。&nbsp;</p>\n  <p>这一个是说，政府不打扰企业；但同时，想从政府拿钱也不容易。&nbsp;</p>\n  <p>在这样的市场环境里，企业发展是很少能得到政府的政策倾斜、财政补贴和税收减免的。&nbsp;</p>\n  <p>所以，很多企业在一开始根本没有能力去大城市发展。&nbsp;</p>\n  <p>就拿山姆·沃尔顿来说，当时他手里只有25000美元，租下新港小镇的一家杂货店才刚刚够。&nbsp;</p>\n  <p>像文章上面说的本顿维尔、哈里森镇和罗斯兰德。&nbsp;</p>\n  <p>这些偏远小镇现在的人口数量也不过几万人，他们政策松、税收少、地皮便宜，非常适合企业在创始初期发展。&nbsp;</p>\n  <p>很多企业在发展后期，甚至能让小镇政府服务它。&nbsp;</p>\n  <h2><strong>小镇，也有小镇的好</strong></h2>\n  <p>美国大企业发源落户小镇，还有一个很重要原因：小镇基础设施完善，各种设备齐全。&nbsp;</p>\n  <p>因为，美国经济现代化起步早，所以城市化率非常高。&nbsp;</p>\n  <p>截至2023年底，我国常住人口的城市化率达66.16%，但早在2005年左右，美国的城市化率就达到了82%。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_056404671f13468587744ef69af3653b@000000_oswg30084oswg759oswg432_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">中美城市化率变化趋势&nbsp;</p>\n  <p>而且在城市化进程中，不同于我国的“中心化”城市建设，美国的走的是“摊大饼”和“跳跃式”建设，从城市到郊区迅速扩张。&nbsp;</p>\n  <p>这种以“道路”为中心，低密度的城市开发模式，造成了对湿地、农田和其他非城市用地的侵蚀；也导致基础设施的布局分散，建设维护费用大的问题。&nbsp;</p>\n  <p>比如交通设施方面。&nbsp;</p>\n  <p>美国联邦公路管理局的不完全数据统计，美国公路建设市场的总体规模在过去几年持续扩大。2019年，美国公路建设的总投资达到了大概1500亿美元。&nbsp;</p>\n  <p>根据官方趋势预测，美国的公路建设市场会持续稳定增长，绝大部分花费用在道路维护和更新方面。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_4416181080f84c78b90228e9b82125f9@000000_oswg163374oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">美国交错复杂的道路系统&nbsp;</p>\n  <p>美国的这种分散式建设，虽然后续成本高，但也有好处，就是发展空间大。&nbsp;</p>\n  <p>就拿美国小镇来讲，它其实和我们国人想象中的那种小镇有很大区别。&nbsp;</p>\n  <p>大家说到小镇，可能第一时间想到的就是寥寥的几户人家，大街上看到的只有老人和小孩，年轻人都外出打工。&nbsp;</p>\n  <p>但是美国很多小镇建有小中高学校、医院、教堂、公园、百货商场，该有的设施应有尽有。&nbsp;</p>\n  <p>如果在小镇有什么不方便的，开个车不出两小时就到了周边的大城市。&nbsp;</p>\n  <p>位于美国康涅狄格州的格林尼治小镇，距离首都纽约只有42公里，开个车不出半小时就到了。&nbsp;</p>\n  <p>所以说，与其说它是小镇，倒不如把它看成我们大城市里的片区。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_c70f0e3488eb466bbf87545b83940f96@000000_oswg152129oswg1080oswg723_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">美国某小镇俯瞰图&nbsp;</p>\n  <p>而且美国的汽车普及率真的很高，截至2022年达到83.7%，汽车保有量为2.8亿辆，平均每千人汽车保有量837辆。&nbsp;</p>\n  <p>在这样的条件下，企业建到大城市和小镇的区别其实并不是很大，很大程度上是非常有优势的。&nbsp;</p>\n  <h2><strong>还有独特的乡镇精神</strong></h2>\n  <p>说完了客观因素，其实还有一个相当重要的主观因素：美国人独特的乡镇精神。&nbsp;</p>\n  <p>美国的城市化率很高，但与之相反的是，更多的人却想住在小镇。&nbsp;</p>\n  <p>除却小镇的许多客观优势外，还得益于“乡镇精神”这一美国社会治理的逻辑。&nbsp;</p>\n  <p>法国的历史、政治和社会学家托克维尔早在19世纪就发现了美国特有的“乡镇自由”。&nbsp;</p>\n  <p>当时的美国乡镇人口，大约在2000-3000，很多的行政工作都是在普罗大众面前完成的。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_d398072a05f24374a3dedcc6a0c3dc58@000000_oswg51891oswg640oswg445_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">美国某小镇正在进行选举&nbsp;</p>\n  <p>如果居民们选出行政官员后，这些乡镇官员要按照本镇居民早先通过的规矩办事，居民参与程度非常高。&nbsp;</p>\n  <p>这也没什么奇怪的，毕竟，个人是本身利益最好的裁判。&nbsp;</p>\n  <p>这种乡镇精神一直影响到今天。&nbsp;</p>\n  <p>美国社会学家罗伯特·伍斯诺在《小镇美国》书中写道：&nbsp;</p>\n  <p>一位小镇居民谈到了他所在的3000人小镇中被选举出来的官员时说，“他们待我不错，我比较信任他们。”&nbsp;</p>\n  <p>这也带来一个结果就是，居民对自己的小镇更加热爱，长大后自然也更愿意为自己的小镇服务。&nbsp;</p>\n  <p>罗伯特·伍斯诺调研的700个小镇居民中，有576人表示自己自愿待在小镇，与小镇一起变得更好。&nbsp;</p>\n  <p>2016年《华尔街日报》做过一项调查统计，在1900年之前的美国商业巨头，有70%-80%是出生在城市，另外30%出生在小镇或者农村。&nbsp;</p>\n  <p>但在二战之后，只有30%的商业巨头出生在城市，剩下的70%开始诞生于小镇和农村。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_8117fe9b30e94d078a3c60a2a02a2c4e@000000_oswg31123oswg757oswg430_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">美国商业巨头出生地变化比较&nbsp;</p>\n  <p>这些商业巨头出生于小镇，成长于小镇，受“乡镇精神”的熏陶长大，更愿意待在小镇生活。&nbsp;</p>\n  <p>山姆·沃尔顿在自传中提到为什么把沃尔玛总部也定在本顿维尔，是因为妻子一直要求居住在小镇，她不愿意去大城市生活。&nbsp;</p>\n  <p>其实，这是个良性循环：&nbsp;</p>\n  <p>居民愿意在小镇生活、创业，而同时，产业繁荣又带来小镇的发展。&nbsp;</p>\n  <p>最终，可能能满足大部分人对生活的期待：离土不离乡。&nbsp;</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MTU3Mzk2OA==&amp;mid=2654893967&amp;idx=2&amp;sn=918837fd5dcb872f965cb48631c3788f&amp;chksm=bc46dfc5c6e952083d95ad580855b3a8c3572c4dccde0de252b53c72cb0322a4ed643bf40ea2&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“正解局”（ID：zhengjieclub）</a>，作者：正解局，36氪经授权发布。</p>", "published": "2024-10-31 09:29:46", "id": "4311e1fc-7203-4b0c-8c36-3474ffefe2bc", "source": "36氪", "section": "文章资讯"}, {"title": "保利发展10月31日放量上涨1.22%；保利发展转让旗下公司股权及债权", "link": "https://36kr.com/p/3016231310992640?f=rss", "description": "", "published": "2024-10-31 09:49:27", "id": "5c9bfdad-699f-44b0-9e50-86014f57faf7", "source": "36氪", "section": "文章资讯"}, {"title": "再升科技10月31日放量上涨1.22%；再升科技拟进行年度分红", "link": "https://36kr.com/p/3016225455252736?f=rss", "description": "", "published": "2024-10-31 09:43:32", "id": "9594ba1f-a0d3-4e22-9053-ad7ea1b9a941", "source": "36氪", "section": "文章资讯"}, {"title": "莱美药业10月31日放量上涨2.73%；莱美药业获得尼莫地平注射液药品注册证书", "link": "https://36kr.com/p/3016228927038724?f=rss", "description": "", "published": "2024-10-31 09:47:09", "id": "cb1cf00f-4fc8-4557-897a-47facd3c0826", "source": "36氪", "section": "文章资讯"}, {"title": "AI做PPT的15个细节", "link": "https://36kr.com/p/3015991983449605?f=rss", "description": "<p><strong>前几天，我录制一个视频。</strong></p>\n  <p>视频里，我展示如何使用Kimi Chat等人工智能工具来制作PPT。发布后，一些朋友尝试工具，并给出了反馈。&nbsp;</p>\n  <p>他们中有些人觉得工具不好用，认为生成效果呆板。&nbsp;</p>\n  <p>我心想，人工智能已经能够一键生成包含几十页文本的PPT，并且还提供多种版面和自定义颜色的选择。难道这样还不够方便吗？&nbsp;</p>\n  <p>经过一番调研，我发现，他们真正的期待是：&nbsp;</p>\n  <p><strong>只要给出一个工作场景的主题，AI就能一键生成完整的文本和演示稿，他们还希望AI能够理解提供的文案和视觉要求。</strong></p>\n  <p>回顾思考之后，我意识到，大家对于AI制作PPT认知存在一些偏差。哪些偏差呢？&nbsp;</p>\n  <h2><strong>01</strong></h2>\n  <p><strong>第一点，AI创意能力很强，它能从文本生成、排版布局到调性设计；但是，人们希望AI像人一样，拥有超越自我的理解能力，这不太现实。</strong></p>\n  <p>比如：&nbsp;</p>\n  <p>领导让我根据客户需求设计PPT。AI虽然能提供多种设计方案，但它的创意是基于算法、已有数据完成的，它无法真正理解一个人的需求。&nbsp;</p>\n  <p>如果你不给AI品牌故事，它就不理解背景是什么。AI也无法像设计师那样，从品牌历史、文化、价值观中找到灵感；所以，AI创造力需要经过训练，或者说，先给它资料让它学习后再提取。&nbsp;</p>\n  <p><strong>第二点，复杂任务的处理。</strong></p>\n  <p>用“一口吃个胖子”来形容初级使用AI的人，很合适。一个人做PPT要经过很多步骤：结构设计、文案提取、主题风格定调、排版布局，最后完成所有。&nbsp;</p>\n  <p>这每一个环节都要时间。我们总想着AI能一下搞定，这种想法不现实； AI也要你给它投喂数据，它每接到一个任务，就像初学者学自行车一样，多试几次，才会熟练。&nbsp;</p>\n  <p><strong>第三点，AI对细节把控不精准。</strong> 当我听到这个问题时，差点哭晕在厕所。换个角度想想：为什么AI在细节上把控不精准呢？&nbsp;</p>\n  <p>AI学习模式有三种：监督学习（Supervised Learning）、无监督学习（Unsupervised Learning）和强化学习（Reinforcement Learning）。&nbsp;</p>\n  <p>这就像我们学习一样。监督学习是老师指导学生，通过大量练习和反馈，帮助学生找到正确答案。&nbsp;</p>\n  <p>无监督学习是自己探索，通过观察和分析，发现数据中的规律。强化学习是从实践中来，到实践中去，看看哪些能带来好的结果。&nbsp;</p>\n  <p><strong>如果你没有监督AI，或者没有给它足够的数据，就别谈它把控不准确了。它能做出来就不错了</strong> ；还有诸多有趣的问题，我不一一列举。&nbsp;</p>\n  <p>你知道吗，幻灯片已经有40年的历史了。&nbsp;</p>\n  <p>自从1984年PPT被发明以来，无论是打工人、学生、家长、公务员、企业家还是科学家，大家都得熬夜做PPT，总是在截止日期前赶工，可以说，全社会都受够了PPT的苦。&nbsp;</p>\n  <p>就连PPT发明者罗伯特·加斯金斯（Robert Gaskins）也自嘲说：“确实有很多人在PPT上浪费时间，就像在其他事情上浪费时间一样。”&nbsp;</p>\n  <p>但大家好像忘了，<strong>PPT最初是为了让我们摆脱枯燥的文档，让信息展示更生动、更互动而诞生的。</strong>现在有了AI的帮助，这一点更是得到了加强。</p>\n  <h2><strong>02‍</strong></h2>\n  <p>那么，曾经屠龙勇士是怎么变成恶龙的？AI又是如何治疗PPT“耗时、难制作”的问题？<strong>要回答这一切，得先从PPT的制作过程说起。</strong></p>\n  <p>通常，PPT制作分为5个环节：&nbsp;</p>\n  <blockquote>\n   <p>1）确认主题、目标受众和演示目的；2）编写PPT的大纲和内容结构以及每页细节；3）制作PPT；4）美化和调整PPT、5）交付，演讲。&nbsp;</p>\n  </blockquote>\n  <p>目前，AI不能取代第1步和第5步，但第2步到第4步，AI可以帮忙完成。&nbsp;</p>\n  <p>在开始讲这五个步骤之前，提醒一下：接到“做PPT”的任务时，不要急着动手。正确的做法是，按照流程，一步一步来。 <strong>不然，最终要在2-4之间反复横跳，这是所谓的卡点部分。</strong></p>\n  <p>确定PPT的主题、目标观众和演示目的，其实并不难。&nbsp;</p>\n  <p>简单来说，就是要知道： <strong>谁来看？他们想看到什么？你又想展示什么？</strong> 只要把这三个问题弄明白，PPT的内容就有了大概的方向。&nbsp;</p>\n  <p>举个例子：&nbsp;</p>\n  <p>领导对你说：“小王，你去给客户介绍一下AI客服产品。”在这种情况下，我们可以首先在Word文档上梳理一下：&nbsp;</p>\n  <blockquote>\n   <p>目的：介绍产品；受众：潜在的客户；背景：客户是一家电商公司；诉求：客户对AI客服感到好奇；关注点：AI如何降本增效。&nbsp;</p>\n  </blockquote>\n  <p>这样一来，思路就清晰了。那么，接下来，就可以开始写主题。&nbsp;</p>\n  <p>比如：“AI智能客服如何助力电商降本增效。” <strong>如果不会写，就做填空题，把上述填好给AI，告诉它：你是一名PPT大师，现在要为我的诉求，做PPT主题的提炼。</strong></p>\n  <p>当它给出答案，你再修正。这样，第一页就搞定了。&nbsp;</p>\n  <p>制作PPT大纲和内容结构，也不复杂，而且，这个过程比写文案要简单多了。&nbsp;</p>\n  <p>为什么呢？因为PPT结构像鱼骨架一样，是列出一个框架，不用逐字逐句地写出来，只要确定每个部分的主要点，围绕这些点来展开内容就行。&nbsp;</p>\n  <p><strong>所以，PPT结构本质上是用简洁的“子弹点”来概述观点，再用图表和图片来辅助说明，就这么简单。</strong></p>\n  <p>让我们想象一下，一个鱼骨是什么样子？&nbsp;</p>\n  <p>是不是先有一个主题作为脊柱，然后，接下来有背景介绍（客户诉求介绍）、公司介绍、产品介绍、解决方案、客户见证，最后是结尾？这六个部分，就构成鱼骨的中间部分。&nbsp;</p>\n  <p><strong>客户诉求之所以放前面，是因为演讲时，没有人喜欢上来就听一个人讲一堆关于你们产品的东西。</strong></p>\n  <p>美国哈佛大学教授凯斯·桑斯坦（Cass R. Sunstein）说过一句话，意思是：用户只关注和他们有关的信息。</p>\n  <h2><strong>03‍</strong></h2>\n  <p>问题来了：怎么让AI帮忙做PPT第二部分？这部分包括客户的需求、公司的介绍、产品的特点、我们提供的解决方案，还有客户的好评。</p>\n  <p>具体来说，当谈到第二部分，其实在说两件事：&nbsp;</p>\n  <p><strong>第一，手头有一些基本的资料，资料不全，需要整理一下后放到PPT里，让它们看起来有个清晰的结构；第二，什么都没有，要从头开始，一步步地写和提炼出内容。</strong></p>\n  <p>先说第一方面，我的常规做法是，让它分步骤学习。&nbsp;</p>\n  <p>比如说：&nbsp;</p>\n  <p>我会用Kimi打开一个新的聊天窗口，上传一些关于公司介绍的PDF、Word文档和PPT文件。上传完，我会告诉AI：&nbsp;</p>\n  <p>“你是一位PPT大师，先学习这些资料。学习完，我要你帮我提炼出公司介绍部分，用在新的PPT里。大概要3页内容，最好把框架和内容都准备好给我。”&nbsp;</p>\n  <p>这样，AI就可以开始工作了。为了方便，我会把AI提供的内容先复制出来，放在一个协同文档里。我们不用急着确定每个部分，因为还在梳理整个结构。&nbsp;</p>\n  <p>另外，如果你要数据，AI也能帮忙。 <strong>它可以帮你制作表格、进行网上查询、分析财报，或者引用信息等等。这些都没问题。</strong></p>\n  <p>对于，数据表达是门艺术。对于展示者来说，它是一种技能；对于观众来说，它是一种警觉。&nbsp;</p>\n  <p>想想看：如果一个手机性能的市场调查显示“性能提高了30%”，但并不意味着每个方面都提高了30%。实际上，这可能意味着：&nbsp;</p>\n  <ul>\n   <li>有些功能变快了‍</li>\n   <li>有些功能变慢了‍</li>\n   <li>还有些功能根本没变化‍</li>\n  </ul>\n  <p>所以，做数据时最好挖掘下，具体到30%在哪方面。&nbsp;</p>\n  <p>再聊聊第二种情况：手头没有资料，该怎么做PPT呢？我的做法是这样的：去搜。 <strong>实际上，每页PPT的标题都应该是一个小结论。我要针对每个标题，把结论展开来说明。</strong></p>\n  <p>比如：&nbsp;</p>\n  <p>用「市场数据」「客户情况」来支撑我的观点。这些信息，通常在网上或者公司里都能找到。真正厉害的人会直接给出结论。&nbsp;</p>\n  <p>以「解决方案」为例：&nbsp;</p>\n  <p>你可以直接写上：“电商圈里70%的头部客户都在使用我们的产品。”如果对方有时间，他们会看看详细的表格、图表。如果时间紧迫，至少能记住这个结论，这样一来，信息传达得既快速又有效。&nbsp;</p>\n  <p>其他页面的做法也一样，至于到底哪页要用数据、哪页要用图表，可以根据实际情况定。 <strong>整个逻辑下来，PPT框架、细节都有了。</strong></p>\n  <p>该怎么用AI做PPT呢？现在，市面有很多AI可以帮助我们做PPT，使用方法大致相同：&nbsp;</p>\n  <p>一，确定一个主题和大纲。通过之前的讨论，我们已经知道了主题和大纲是什么；如果你还没有自己的大纲，可以把整理好的文档给AI，让它帮你生成一个。&nbsp;</p>\n  <p>二，在AI-PPT软件中，选择一个模板。有的软件允许你上传公司的logo，选择你喜欢的颜色。&nbsp;</p>\n  <p>三，一键生成。很快，几乎是一秒钟一张，整个PPT就完成了；想想看，如果是以前，光是新建一个空白的PPT，可能都要花上好几分钟。&nbsp;</p>\n  <p><strong>你会发现，一开始就把大纲和内容确定好，之后微调会变得非常简单</strong> ；即使有些素材不喜欢，或者文案要修改，这些调整也都不难处理，更何况，现在AI PPT工具还能对文案提出建议。&nbsp;</p>\n  <p><strong>换句话说，如果觉得某段文字写得不够好，又不确定怎么改，可以直接告诉PPT你的想法。</strong></p>\n  <p>比如：你希望这段文字更加吸引人，或者更简洁明了。AI会根据你的要求，帮你改写这段文案；这样，制作PPT的过程就变得更轻松和高效了。&nbsp;</p>\n  <p>那么，用AI做PPT时，应该选哪种字体呢？&nbsp;</p>\n  <p>很多PPT的书籍都推荐使用“思源黑体”，这种字体在演示时看起来效果很好，因为它的字形立体，容易辨认。&nbsp;</p>\n  <p>如果PPT不是用来讲的，而是要打印出来给领导看，可以用楷体。 <strong>很多咨询公司做PPT时就喜欢用楷体，它看起来既优雅，又容易阅读。</strong></p>\n  <p>所以，用AI做PPT轻松好多，你觉的难，难在工作流上。</p>\n  <h2><strong>04‍</strong></h2>\n  <p>这里还有一些额外心得分享给你：<strong>如果PPT内容超过15页，要加一个摘要页。</strong></p>\n  <p>记住，听众通常没有时间仔细看你写的每一个字，所以我们的任务是提炼和总结，让对方能迅速抓住重点。&nbsp;</p>\n  <p>如果PPT内容25页以上，要建立一个导航系统。什么是导航系统？&nbsp;</p>\n  <p>简单讲，先给观众一个概览，告诉他们，PPT里有哪几部分，每部分要讲什么？不然，到了中间，听着容易云里雾里。&nbsp;</p>\n  <p><strong>我们得注意，PPT是给别人看的，所以炫酷还是简单，要看受众是谁。</strong></p>\n  <p>比如说：&nbsp;</p>\n  <p>对于大佬们，他们时间很宝贵，不会在意PPT做得好不好看；我参加过一个大会，有个老板上台演讲，他的PPT只有20页，每页都很简单，只有结论和支持结论的数据，但大家都记得很清楚。&nbsp;</p>\n  <p>当然，也有老板比较重视UI，他们认为拿出去是面子，这就另当别论了。&nbsp;</p>\n  <p>对于年轻人群体，PPT炫酷、美观权重会大一些，因为，演讲时即便表现不好，别人也��因为几个画面记住你。&nbsp;</p>\n  <p><strong>PPT最后不要总放一个thanks，你可以试试把整个PPT的每段结论放进去，帮大家复习一下，这样会加深记忆，尤其是一些你认为重要的观点。</strong></p>\n  <p>还有，到底要不要准备逐字稿呢？最好准备一份。&nbsp;</p>\n  <p>特别是当你要去一个不熟悉的地方做汇报时，我们很容易高估自己的记忆力和应变能力。&nbsp;</p>\n  <p>记得有一次，我参加了一个沙龙，有位朋友准备了PPT，一开始人不多，后来人越来越多，他就开始紧张了，最后甚至紧张到说话都结结巴巴。&nbsp;</p>\n  <p>有些大佬演讲都要准备逐字稿，更何况我们？ <strong>逐字稿是一种潜在的安全感，写逐字稿本身也是一种排练，相信我，这样做会让你更有信心。</strong></p>\n  <p>值得一提的是，如果要把PPT发给别人，最好导出一个PDF压缩版；这样做的好处，不管在电脑上看，还是通过微信分享，文件格式、排版都能保持原样。&nbsp;</p>\n  <p>有时，因为对方软件的不兼容，直接发送PPT文件会排版错乱、格式丢失，不仅影响信息传达，还给人留下不专业的印象。&nbsp;</p>\n  <p>以上15个小要点，再用关键词重复下。 <strong>三个认知</strong> ：AI创意能力很强，AI能处理复杂任务，AI对细节把控也不错，但都要靠你来培养。&nbsp;</p>\n  <p><strong>PPT的制作</strong> ：明确主题，回答他们想看到什么？你又想展示什么？； <strong>结构像鱼骨一样，要清晰</strong> ； <strong>细节用现有资料，或者上网搜</strong> ；每一页PPT都应该是一个清晰的结论，并用数据、证据来支持。&nbsp;</p>\n  <p><strong>用AI来帮忙</strong> ：让AI根据已有的内容生成大纲，然后制作成PPT； <strong>视觉简要还是炫酷，取决于对方</strong> ；PPT内容过多，最好建立一套导航；最后不要总放一个thanks； <strong>文字用思源黑体或楷体。</strong></p>\n  <p>别忘了，为了演讲更流畅，最好准备一个逐字稿；给别人发送PPT时，用PDF格式，这样不管在哪里打开，格式都不会乱。</p>\n  <h2><strong>总结</strong></h2>\n  <p>做PPT，是细心工作。&nbsp;</p>\n  <p>你无法完全复制一切，剩下实操部分，就要刻意练习； <strong>毕竟每一个人都有一套自己与AI协同的方法。</strong></p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MzU5ODMyNDEyNw==&amp;mid=2247501290&amp;idx=1&amp;sn=a0988dc829b7c381e73d35ae43ae9aaa&amp;chksm=ff49dbadc8b9ff741d72ec3d339250b9ee91a2b1952d23c9b831efa8b4e92acdbcc58bd47ef7&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“王智远”（ID：Z201440）</a>，作者：王智远，36氪经授权发布。</p>", "published": "2024-10-31 10:06:52", "id": "b7c9587a-f152-448e-aca0-15da459256d4", "source": "36氪", "section": "文章资讯"}, {"title": "比爱马仕毛利率还高，“衣中茅台”瞄上年轻人", "link": "https://36kr.com/p/3016153314518531?f=rss", "description": "<p>家住北京、经常旅游的格子（化名）发现，几乎每个城市的机场都有比音勒芬的门店。上千元一件的T恤，让她很快记住了这个牌子。“以至于我现在一看到这个牌子，就感觉自己马上要上飞机了。”格子说。</p>\n  <p>相比格子，不少A股的投资者对比音勒芬更为熟悉。10月30日，比音勒芬公布的2024年三季报显示，该公司前三季度实现营业收入30亿元，同比增长7.3%；扣非归母净利润7.35亿元，同比增长1.3%。</p>\n  <p>在A股61家服装类上市公司中，比音勒芬的毛利率已经连续三年（2021年-2023年）位居榜首，也让其有了“衣中茅台”的称号。<strong>Wind数据显示，2024年比音勒芬三季度销售毛利率为76.42%，再次位居服装板块之首。</strong></p>\n  <p>排在它后面的是拥有DAZZLE等中高端女装品牌的地素时尚、TEENIEWEENIE母公司锦泓集团、瞄准中产女性的歌力思、“男裤专家”九牧王等。至于凭借印小天魔性舞蹈出圈的海澜之家，毛利率为44.32%。</p>\n  <h2><strong>“高尔夫+机场”</strong></h2>\n  <p>比音勒芬的logo是一个拄着高尔夫球杆的球手站在一串英文字母中间。根据其2016年披露的招股书，公司产品定位于高尔夫运动与时尚休闲生活相结合的细分市场，目标群体为高尔夫爱好者以及认同高尔夫文化、着装倾向于高尔夫风格的中产收入以上消费人群。</p>\n  <p>除了绑定高尔夫这一中产青睐的运动外，在机场开店也是近年来比音勒芬扩张市场的重要策略之一。</p>\n  <p>比音勒芬在2023年年报中指出，公司打造“优质线下渠道 + 数字化新零售”的全模式覆盖的营销网络，其中优质线下渠道已覆盖全国高端百货商场、购物中心、机场高铁交通枢纽以及高尔夫球场。在已公布的历年财报中，比音勒芬未披露其机场门店的具体数量，中新经纬根据其官网截至2020年的数据统计，当时比音勒芬在全国有900余家门店，在其布局的31个省市间仅有4地没有开设机场店。</p>\n  <p>2016年12月23日，比音勒芬正式在深交所上市，截至当年底，其终端门店的数量为602个。7年过去，比音勒芬的门店数量已经翻倍，其中光直营店就有607家，加盟店数量648家。</p>\n  <p>时尚产业独立分析师、上海良栖品牌管理有限公司总经理程伟雄指出，机场开店实际上租金成本不低，但比音勒芬高价高倍率可以摊销租金成本。能够经常飞机出行的用户自然是有消费能力的商务人士，同时高尔夫这一运动方式能够满足商务社交需求。</p>\n  <p>“日常的商场满足消费者生活、休闲、时尚需求，选择面比较宽泛，机场选择面相对更加集中和聚焦，中国国内一般在机场开店的品牌偏高单价、中高端定位。”程伟雄说。</p>\n  <p>而给格子留下深刻印象的千元T恤，正是比音勒芬着力打造的超级品类。比音勒芬在2023年年报中指出，报告期内，公司持续从自身品类优势出发，聚焦核心品类——T恤，将比音勒芬打造成为“T恤第一联想品牌”。根据中国商业联合会和中华全国商业信息中心数据统计，比音勒芬的T恤单品类产品连续六年(2018-2023)获市场综合占有率第一位。</p>\n  <p>近日，中新经纬走访比音勒芬北京通州万达店时，店员介绍称，来店里买衣服的30岁到60岁都有，只要喜欢这种风格的就会买，这种风格就是“不是特别正式，但也不是特别年轻”。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_c7efcb48023242818ffcbd35bff03346@000000_oswg1251600oswg1007oswg755_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">▲比音勒芬门店 中新经纬 实习生 秦海齐摄</p>\n  <p>中新经纬注意到，该店T恤售价多在800元左右，也有上千元的。新款羽绒服、外套定价普遍在3000元以上，会员可打九五折，达到10000积分以上折扣会更大。该店有反季节折扣，多为五到七折。</p>\n  <p>2019年，浙商证券曾发布报告分析比音勒芬的消费者画像，这一群体月可支配收入3万元左右，年龄在35岁-55岁之间，40岁以上为主力人群，注重品牌，价格敏感性低，注重体验与产品质量，品牌忠诚度高。</p>\n  <p>但现在，比音勒芬瞄准的不止中年人。<strong>2022年年��中，比音勒芬提出“国际化、高端化、年轻化、标准化”作为公司新阶段的建设目标。在2024年半年报中，比音勒芬称，秉承品牌形象全面年轻化、高端化发展，在2024 年上半年与多位明星、名人达成形象合作，</strong>包括陈靖可、王安宇、任敏、蒋勤勤、吴千语、陆川、吴晓波等，演绎品牌精英穿搭新范式。</p>\n  <p>对此，盘古智库高级研究员江瀚指出，比音勒芬实施年轻化策略，是一个积极的市场尝试。这有助于打破传统“大叔”形象，吸引更多年轻消费者的关注。其次，年轻化策略不仅体现在代言人选择上，还应贯穿于产品设计、营销策略等各个环节，形成全方位的品牌年轻化。</p>\n  <p>值得注意的是，尽管比音勒芬品牌形象绑定高尔夫，但买比音勒芬的人却不一定真的都打高尔夫。根据其招股书，比音勒芬称，“享受高尔夫似的闲情逸致，并不一定要打高尔夫”。</p>\n  <h2><strong>离全球奢侈品集团还有多远？</strong></h2>\n  <p>比音勒芬的毛利率不仅在一众服饰类A股上市公司中名列前茅，在国际顶级奢侈品集团面前也很“扛打”。今年上半年，顶级奢侈品品牌爱马仕的毛利率为70.6%，LV母公司路易威登集团毛利率为68.8%。</p>\n  <p>而比音勒芬也早有了冲刺全球奢侈品集团的野心。翻阅其历年财报，比音勒芬在介绍其设计研发团队时都强调，他们具有多年奢侈品品牌、国际知名品牌高尔夫服饰系列设计经验。</p>\n  <p>2023年一季度，比音勒芬通过子公司间接收购国际奢侈品牌“CERRUTI 1881”和“KENT＆CURWEN”的全球商标所有权。</p>\n  <p>比音勒芬称，收购的CERRUTI 1881和KENT＆CURWEN两个国际品牌，在品牌影响力和知名度等方面与比音勒芬形成互补，进一步推进公司品牌多样化、国际化、高端化布局，为公司打造全球奢侈品集团奠定了基础。</p>\n  <p>在2023年的半年报中，比音勒芬首次明确提出，立志成为全球奢侈品集团。&nbsp;</p>\n  <p>在2023年4月发布的2022年年报中，比音勒芬首次在其所处行业情况中加上了奢侈品行业的情况分析称，2022年，全球奢侈品市场进一步复苏，同比增长17%，市场规模达到25450亿元人民币。全球奢侈品市场近年来获得了较快发展，特别是头部奢侈品牌，平均市场规模比2019年提升30%以上。</p>\n  <p>上述年报中还提到，中国高端消费领域专业研究和顾问机构要客研究院发布的《2022中国奢侈品报告》数据显示，2022年，中国人奢侈品市场销售额最终实现9560亿元人民币，在全球奢侈品市场占比高达38%，中国人依然是全球奢侈品消费的最重要力量，国内奢侈品消费市场增长强势。</p>\n  <p>上述报告称，目前，中国中产人群已超过2.5亿人，预计未来随着中国中产收入数量的增加和消费观念的转变，中国奢侈品市场将会持续快速发展。随着中产人群规模扩大及消费升级带来的需求增加，2025年市场规模将达到1.1万亿元人民币，将成为全球最大的奢侈品消费市场。</p>\n  <p>眼下，在毛利率上已经不输奢侈品的比音勒芬，距离成为一家奢侈品集团还有多远？</p>\n  <p>江瀚指出，比音勒芬收购知名品牌的全球商标所有权，是其向成为全球奢侈品集团目标迈进的重要一步。虽然这两个品牌在奢侈品领域属于中低档，但它们各自拥有独特的历史底蕴和品牌价值，为比音勒芬的国际化战略提供了有力支持。然而，要实现这一目标，比音勒芬还面临诸多挑战，如如何有效整合收购品牌资源、提升品牌影响力、拓展国际市场等。此外，奢侈品市场竞争激烈，品牌忠诚度难以建立和维护，也是比音勒芬需要克服的难题。</p>\n  <p>程伟雄注意到，近期安踏旗下斐乐加码高尔夫球运动，利郎和日本迪桑特旗下高尔夫球品牌合作，随着众多品牌和资本的加入，高尔夫运动穿着市场竞争进一步加剧，而比音勒芬要想继续保持品牌先发优势，还需进一步夯实基本盘。</p>\n  <p>零售独立评论人马岗也指出，比音勒芬营收主要在中国，在全球化上缺乏实操。其次，奢侈品集团不是有商标权就够了，需要从产品、营销、渠道等多个视角进行布局。</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MzI0NDU5OTAzMA==&amp;mid=2247585117&amp;idx=1&amp;sn=a376d1e4d348762463034c25ccae05e0&amp;chksm=e8132a3bc47fc32fe50b3cd3e2764d4d30d56cc282a86cfa27935e8061a61ef7fdc2d82aa672&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“中新经纬”（ID：jwview）</a>，作者：罗琨；实习生 秦海齐，36氪经授权发布。</p>", "published": "2024-10-31 09:36:52", "id": "6c281e24-ecad-419c-a054-7dd18506d1e6", "source": "36氪", "section": "文章资讯"}, {"title": "国外禁用的防腐剂脱氢乙酸钠，我们为何还在用？", "link": "https://36kr.com/p/3016131303695618?f=rss", "description": "<p>谁也没想到，“<strong>脱氢乙酸钠</strong>”这个别扭的词儿，火了。</p>\n  <p>社交平台上的网友们齐呼“<strong>原来我吃了这么多年的毒</strong>”“<strong>含有脱氢乙酸钠的，都是毒面包</strong>”，痛恨自己没有提早发现这一危险分子。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_0c39b9d2bc014ea7882e49c4f5d4fba9@000000_oswg302526oswg378oswg653_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">社交平台上的相关内容丨小红书</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_0087c936aaa04197823e1d27b31e6d89@000000_oswg86306oswg364oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">网购平台上的相关提问丨淘宝</p>\n  <p>触角灵敏的电商，赶紧给自家产品海报加上了大字“<strong>不含脱氢乙酸钠</strong>”。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_cecb69f121f740b493311177f53e74b4@000000_oswg214019oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图丨淘宝</p>\n  <p>还有人更生气：<strong>凭什么国外都禁用的添加剂，我们还在用？我国的食品安全，到底有没有救</strong>？</p>\n  <p>疑惑、会焦虑，甚至生气，都是正常的反应。脱氢乙酸钠到底是怎么回事？食品添加剂为什么有不同标准？这篇推送，就把相关信息一次讲清楚。</p>\n  <h2><strong>好用，所以常用</strong></h2>\n  <p><strong>脱氢乙酸钠不是突然出来刷存在感的，它长期存在于我们身边</strong>，面包、点心、腌菜、熟肉制品，甚至化妆品里，都可能用到它。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_67e750a33837468498a14577260f10cd@000000_oswg129614oswg846oswg553_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">现行国标中，脱氢乙酸钠可以使用的范围和剂量，点击可看大图丨GB&nbsp;2760—2014</p>\n  <p>作为防腐剂的一员，脱氢乙酸钠保证食物即使远道而来，到你手上依然能吃。要是没有防腐剂，我们就得天天跑菜市场，也很难吃到没变质的外地特产了。</p>\n  <p><strong>之所以说脱氢乙酸钠真的很常见，是因为它真的好用</strong>！</p>\n  <h3>以一敌十</h3>\n  <p>相比于很多常见的食品防腐剂，脱氢乙酸钠具有<strong>广谱的抗菌能力</strong>，具有“以一敌十”的能力。</p>\n  <p>常见细菌？能对付！霉菌？能对付！酵母菌？也能对付！</p>\n  <p>只用添加脱氢乙酸钠一种防腐剂，就能有效压制多种让食物变质的微生物，实在方便省事。</p>\n  <h3>四两拨千斤</h3>\n  <p>脱氢乙酸钠发挥作用所需的浓度很低。也就是说，要实现相同的防腐效果，会用到较多的其他常见防腐剂，但<strong>只需要用一点儿脱氢乙酸钠就行了</strong>，也很省事。</p>\n  <h3>无惧酸碱</h3>\n  <p>苯甲酸钠、山梨酸钾，也是有名的防腐剂，但它们只能在酸性条件里发挥作用，比如汽水、果酱、泡菜等。</p>\n  <p>但<strong>脱氢乙酸钠的效果受酸碱环境影响很小，能运用到的场景更多</strong>，自然也就更常见了。</p>\n  <h3>没啥存在感</h3>\n  <p>作为一种食品添加剂，脱氢乙酸钠<strong>无色无味</strong>，不影响食物的味道、外观、口感，只默默杀菌，不留功与名。</p>\n  <p>相较之下，苯甲酸钠、山梨酸钾、丙酸钙等食品防腐剂，都多多少少有点特殊味道。</p>\n  <h2><strong>人无完人，剂无完剂</strong></h2>\n  <p><strong>上面说的脱氢乙酸钠的优点都是真的，但网友们口口相传的“毒性”也并非杜撰</strong>。</p>\n  <p>随着对脱氢乙酸钠研究的深入，越来越多的证据表明，<strong>长期、大量摄入脱氢乙酸钠可能中毒</strong>，表现为肝肾功能减弱、惊厥、颤抖、共济失调、体重减少、慢性肺水肿等。</p>\n  <p><strong>但这个结论并不意味着，我们平常吃的脱氢乙酸钠足以造成那么大的影响</strong>。</p>\n  <p>先说急性中毒。假设你是体重50公斤的成年人，每天吃1斤面包，而且这个面包里的脱氢乙酸钠用到了国家允许的最高剂量（每公斤0.5克），那也不过只摄入了0.25克脱氢乙酸钠——要知道，<strong>一次性摄入25克以上的脱氢乙酸钠才会急性中毒，那得是100斤顶格添加脱氢乙酸钠的面包</strong>。</p>\n  <p>再说慢性中毒。</p>\n  <p>如果一个人连着几年、坚持不懈每天吃含有脱氢乙酸钠的食物……</p>\n  <p><strong>对这样的饮食结构来说，他可能在达到脱氢乙酸钠慢性中毒剂量之前，就会因为营养失衡以及天天吃加工食品，而身心出现更显著的不利影响</strong>！</p>\n  <p>之所以要强调饮食均衡，其中一个原因也是，均衡的饮食不仅能提供各种重要营养素，更能压低不利于身体的摄入。</p>\n  <p>但如果你还是排斥脱氢乙酸钠，我也完全理解。</p>\n  <p>药物只要能治病救人，有一些毒副作用是可以接受的；食品只是果腹、提供营养，我们希望它的成分尽可能安全：被实锤有害的原料，必须被替换；有更好的替代品，我们也希望用更好的原料。</p>\n  <p><strong>就事论事，含有脱氢乙酸钠的食物确实不完美。</strong></p>\n  <p><strong>不过，它们也绝对算不上“毒品”</strong>。</p>\n  <h2><strong>添加剂“双标”，我们能安心吗？</strong></h2>\n  <p>有很多人完全理解“剂量 VS 毒性”的道理，真正让他们生气的，是包括脱氢乙酸钠在内的食品添加剂“双标”：<strong>为什么在国外禁用，在国内却处处可见？我们的食物真的不如进口的安全吗？</strong></p>\n  <h3>不同国家不同标准，谁在玩双标？</h3>\n  <p>确实，很多添加剂的使用标准，在国内国外有所不同，但<strong>“国外”是个非常宽泛的概念，“不同”也不意味着更好或更坏</strong>。</p>\n  <blockquote>\n   <p>比如这次的脱氢乙酸钠。</p>\n   <p>在我国能用，在美国可以用于切块/去皮南瓜，在日本可用于乳制品，在欧盟可以用于化妆品，在韩国则禁用于食品。</p>\n  </blockquote>\n  <blockquote>\n   <p>又比如金箔。</p>\n   <p>世界卫生组织食品添加剂法典委员会正式把黄金列入了食品添加剂范畴，允许其作为色素使用。所以我们看到一些外国人喝着加了金箔的酒、吃着加了金箔的餐点，我们却很少见到，因为我国明确禁止把黄金加到食物里去。</p>\n  </blockquote>\n  <blockquote>\n   <p>再来一个很有代表性的例子：硼砂。</p>\n   <p>在东南亚的传统食品中会用到硼砂，被认为是传统手艺；欧洲的鱼子酱里也会用到硼砂，不用就是不正宗。但这些东南亚粽子、欧洲鱼子酱没法进口到我国或美国，因为这两个地方是不允许食物里有硼砂的。</p>\n  </blockquote>\n  <p>从上面3个例子里，我们能看出<strong>各国制定添加剂标准，参考了很多标准</strong>。</p>\n  <p>首先当然是<strong>食品安全</strong>。</p>\n  <p>但食品安全不是非黑即白的问题，并非只有“吃一口就死”和“吃一辈子也没事”两种结局。各国、各地区怎么划出安全剂量这根线、这根线离公认的上限近一点还是远一点，还要考虑更多因素。</p>\n  <p>这些因素包括但不限于：</p>\n  <p><strong>饮食差异</strong>。各地区、民族、信仰的饮食习惯差异巨大，必须得考虑。上面说的硼砂，在中国和美国可以禁，但在东南亚和欧盟禁用，阻力恐怕不小，只能把标准放宽松些。</p>\n  <p><strong>经济发展水平/技术的差异、当地监管能力/资源的差异、国际标准的贸易的差异</strong>，也会影响食品添加剂的红线在哪里、离公认的上限有多远。温饱和营养还没达到的地区，就很难严格遵循发达国家的食品安全标准。贸易顺差逆差也会有影响。某种食品的出口国，往往希望把标准放宽松些，这样对国内产业更加有利。而如果是这种产品的进口国，往往更加挑剔，只想花钱买最优质的一批，就会把标准定得严格些。</p>\n  <p>总之，<strong>世界各地对某种食品添加剂的标准，都在当下和当地能达到的安全范围里</strong>，只是因为这样那样的原因，有的地方标准宽容一些、有的地方标准严格一些。</p>\n  <p>不同阶段不同标准，以前的人都在服毒？</p>\n  <p>不同国家不同标准，这是食品添加剂的“横向双标”；<strong>不同时期对食品添加剂有不同标准，这是“纵向双标”，也很常见</strong>。</p>\n  <blockquote>\n   <p>上文说的硼砂，早年间美国也是把它当合法的防腐剂用的。</p>\n   <p>后来随着研究深入、公众健康意识提高，人们发现硼砂有一定毒性，而且在技术上、习惯上，都并非不可取代，就逐渐把硼砂给禁用了。</p>\n  </blockquote>\n  <blockquote>\n   <p>风口浪尖的脱氢乙酸钠也差不多。</p>\n   <p>因为脱氢乙酸钠真的有很多优点，所以在现行的《食品安全国家标准食品添加剂使用标准（GB 2760-2014）》中，有12种食物里都可以添加它。</p>\n   <p>现在我们逐步发现了脱氢乙酸钠的潜在风险，同时又有条件禁用、替换它，所以经过重新评估后即将实行新的标准，缩小了脱氢乙酸钠的适用范围，以后的面包、糕点的食品里不能用它了，腌渍蔬菜里的用量也被降低（当然，除了脱氢乙酸钠，里面也可能有其他的防腐剂）。</p>\n  </blockquote>\n  <p>这不禁会让人担忧：那在禁用、限用某些添加剂之前，我们一直在服毒吗？还有多少添加剂是有毒却尚不为人所知的？相比后人，我们是不是“亏了”？</p>\n  <p>然而，任何选择，都无法脱离时代和环境的客观约束。</p>\n  <p>几十年前，我们的祖辈连饭都吃不饱，现在我们不仅能吃饱，还能吃得更安全和健康。</p>\n  <p>随着科研人员的不断努力，安全性更好的食品添加剂，也在不断替换安全性稍有不如的食品添加剂。</p>\n  <p><strong>如果实在担心食品添加剂，一个比较实用的建议是，少摄入深加工食品，多吃那些原始的天然食材</strong>：少喝一杯甜腻的奶茶，多来一口新鲜的鸡蛋和蔬菜，让<strong>入口的主力食物都新鲜又营养，是对食品安全最好的安排</strong>。</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MTg1MjI3MzY2MQ==&amp;mid=2652282367&amp;idx=1&amp;sn=c4f64b4f60866d2b94a210ecaf4b161d&amp;chksm=5c7d884cff5141fc0546cde5c7057a9e02a63eadd3cc880a1a34e0e4f64e209ac8d516d9b38f&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“果壳”（ID：Guokr42）</a>，作者：乌龙茶，36氪经授权发布。</p>", "published": "2024-10-31 09:37:44", "id": "5db896cb-9eb1-4ca1-8897-a355c739597d", "source": "36氪", "section": "文章资讯"}, {"title": "75亿，博士夫妇今日港股敲钟", "link": "https://36kr.com/p/3016175636952192?f=rss", "description": "<p>港股生物医药板块，又添一位重磅玩家。&nbsp;</p>\n  <p>今日，华昊中天在港挂牌上市，发行价格为16港元，早盘高开34.4%报21.5港元；截至当日休盘，每股涨28.44%至20.55港元，总市值74.92亿。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_2ff05ad7eb1e4d88880ef2436837bc37@5807375_oswg50790oswg628oswg519_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">来源：截图</p>\n  <p>华昊中天定位于一家合成生物学技术驱动的全球化生物医药公司，致力于开发肿瘤创新药。公司身后站着一对博士夫妇——唐莉和邱荣国，二人履历颇为亮眼。&nbsp;</p>\n  <p>资料显示，唐莉曾于1994年8月获得美国威斯康星大学麦迪逊分校博士学位，2006年12月至2012年9月担任大连理工大学分子药物研究中心教授，还曾在成都生物制品研究所、中国医学科学院医药生物技术研究所任职。&nbsp;</p>\n  <p>邱荣国在获得中国武汉大学病毒学学士学位及病毒生化学硕士学位后，于1997年5月获得乌得勒支大学细胞与分子生物学博士学位。&nbsp;</p>\n  <p>2002年，唐莉和邱荣国踏上了肿瘤创新药的研发之路，在北京中关村成立了华昊中天。二者的专业背景和研发经验，为公司在生物医药领域的发展奠定了基础。&nbsp;</p>\n  <p>成立以来，华昊中天成功开发了专注于微生物代谢产物新药研发的三大核心技术平台，拥有一款已商业化产品优替德隆注射液，以及19种其他管线在研产品。&nbsp;</p>\n  <p>2021年，公司的核心产品优替德隆注射液获得国家药监局的批准进行商业化，用于治疗接受过至少一种蒽环类或紫杉类药物化疗方案的复发或转移性乳腺癌患者。这一突破打破了我国长期以来晚期乳腺癌治疗的瓶颈，结束了国内近三十年来除紫杉醇外无突破性化疗药物的局面。&nbsp;</p>\n  <p>行至今日，华昊中天仍在积极扩展优替德隆注射液的产品线，开发包括优替德隆胶囊、优替德隆纳米剂型和优替德隆抗体偶联药物在内的新产品。&nbsp;</p>\n  <p>自成立以来，华昊中天已获得多家知名投资机构的青睐和支持，包括龙磐投资、达晨财智、 中关村发展集团、国投创业等。&nbsp;</p>\n  <p>2020年，华昊中天完成E轮融资，也就是IPO前最后一轮融资，融资额为8.9亿元，由倚锋资本和经纬中国共同领投，建银国际、国药中金、天创资本、成都生物城等跟投，彼时公司的估值已达到约44.9亿元。&nbsp;</p>\n  <p>公司曾在2022年6月递交科创板上市申请，后于2023年5月主动申请撤回公开发行股票在科创板上市的决定。2024年8月，华昊中天迈出了重要的一步，转而赴港 IPO。&nbsp;</p>\n  <p>业绩方面，2022年至2023年以及2024年1-5月，华昊中天的收入分别为3282.0万元、6663.5万元及2856.4万元；期内亏损1.61亿元、1.90亿元、5745.3万元；实现毛利分别为2388.0万元、4682.5万元及2429.5万元。&nbsp;</p>\n  <p>截至最后实际可行日期，Tang Li（唐莉）博士直接持股1.03%；唐莉、邱荣国、Baygen QT Inc.、北京北进缘、珠海华欣、珠海华锦、珠海京蓉及珠海华蓉合计有权行使公司约29.47%（略低于30%）投票权，并构成单一最大股东组别。此外，国投创业持股8.41%；倚锋投资通过倚锋睿华、倚锋十四分别持股4.68%、1.56%；崇德弘信通过北京崇德持股4.44%；龙磐创投，持股3.99%；达晨财智通过深圳达晨持股3.66%。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_071c217c714449cfab1b2650af33c927@5807375_oswg64181oswg1019oswg534_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">来源：招股书&nbsp;</p>\n  <p>IPO前，华昊中天还引入了基石投资者，合共认购2300万美元的发售股份；其中，知名天使投资人龚虹嘉全资拥有的富策认购1000万美元，润淼资产管理、TPG和百洋医药则分别认购800万美元、300万美元和200万美元。&nbsp;</p>\n  <p>本次冲刺上市，华昊中天计划将募资所得主要用于资助核心产品的临床试验；资助核心产品以外的试验；将用于加强国内商业化能力及建立全球营销网络；扩大产能；用作营运资金及一般公司用途等。&nbsp;</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/_O72M_PnrZr_E-OSA1w95g\" rel=\"noopener noreferrer\" target=\"_blank\">“直通IPO”</a>，作者：韩文静，36氪经授权发布。</p>", "published": "2024-10-31 10:08:30", "id": "3961b76e-ff81-41ca-9007-c6bb266a2d7e", "source": "36氪", "section": "文章资讯"}, {"title": "省广集团10月31日放量上涨9.97%", "link": "https://36kr.com/p/3016243860038921?f=rss", "description": "", "published": "2024-10-31 10:02:07", "id": "be205868-b30c-4983-8369-f2ec8a67523d", "source": "36氪", "section": "文章资讯"}, {"title": "公募基金排位新法则：得ETF者得天下", "link": "https://36kr.com/p/3015939892786055?f=rss", "description": "<p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_fabb50a7b4834f749375cb2e172c06bd@13164445_oswg869061oswg2019oswg1111_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>基金三季报已经落下帷幕。</p>\n  <p>透过公告的披露，可以直观地感知到：权益基金的氛围，被劈成了两半。</p>\n  <p>一边是主动权益的冷清。和前几年的意气风发不同，在主动权益消沉的三年多时间里，“明星基金经理们”仿佛逐渐丧失了表达欲。即便三季度末迎来了史无前例的暴涨，季报观点输出整体较为平淡，看点寥寥。</p>\n  <p>而泾渭分明的另一边，被动投资风头正盛。从最新披露的规模排名来看，ETF正在改写公募行业的格局。</p>\n  <p>为了抢占市场份额，近期，部分头部基金公司掀起了“降费潮”。那么，从过往案例回溯，低费率策略效果究竟如何？</p>\n  <h2><strong>ETF成流量密码</strong></h2>\n  <p>得ETF者得天下，成为公募排位新法则。</p>\n  <p>据Wind统计，三季度非货规模TOP20中，排名领先或排名提升显著的基金公司，都离不开ETF的加持。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_bf53f964af9c454e8a32778d499af1ec@13164445_oswg365256oswg1697oswg1238_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>以排在第一的易方达基金为例，三季度非货规模为1.37万亿元，环比增长了2136.01亿元。非货类型的产品中，只有债券型基金出现规模缩水，环比减少了386.91亿元。最大的规模增量来自股票型基金，达到2199.9亿元。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_92610d5855f94c19b8527c17ce6de2ef@13164445_oswg105240oswg1679oswg308_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>这里统计的股票型基金规模，是指普通股票基金和股票指数基金之和。而股票指数基金，又包含了场内的股票型ETF和场外的股票指数基金两个部分。</p>\n  <p>Wind数据显示，易方达三季度的非货ETF规模为5979.56亿元，环比增长了2242.9亿元。由于易方达旗下没有债券型ETF，所以这个非货ETF规模等同于股票型ETF规模。也就是说，易方达三季度的非货规模增量，几乎都是股票型ETF带来的。</p>\n  <p>排在第二的华夏基金，三季度非货规模环比增长了2260.03亿元，达到1.18万亿元，是继易方达之后，第二家非货规模突破万亿的基金公司。</p>\n  <p>华夏的情况和易方达如出一辙。非货类型的产品中，只有债券型基金规模缩水，环比减少了25.06亿元。股票型基金贡献了最多的增量，环比增长了1915.12亿元。</p>\n  <p>截至三季度末，华夏的非货ETF规模为6783.41亿元，环比增长了2073.21亿元。而华夏旗下只有1只债券ETF，三季度末规模仅2.47亿元。由此可知，依旧是“股票型ETF带来了绝大部分非货规模增量”。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_49b055f938d4436b9926501c5fdb5198@13164445_oswg103248oswg1679oswg308_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2><strong>两个“一哥”的较量</strong></h2>\n  <p>自去年ETF站上流量风口后，易方达和华夏的竞争变得胶着起来。</p>\n  <p>易方达曾凭借主动权益的优势，在上一轮牛市中大杀四方。先是在2019年成为“非货一哥”，又在2021年底成为中国公募史上首家非货规模突破万亿的基金公司，达到1.19万亿，比当时排在第二的华夏高出4938.35亿元，可谓断层式领先。</p>\n  <p>但随着主动权益业绩没落，ETF更受资金青睐。到2023年底时，格局已经发生改变，易方达的非货规模回落至9526.74亿元，而长期稳坐“ETF一哥”的华夏迎头追赶，二者的差距缩至1348.63亿元。</p>\n  <p>彼时，华夏的非货ETF规模为3994.18亿元，比易方达高出1385.63亿元。易方达似乎也意识到了ETF的战略地位，从2023年底开始，对旗下多只ETF产品进行了降费。</p>\n  <p>到2024年三季度末，华夏基金的非货ETF规模增至6783.41亿元，依旧处于行业第一，但和易方达的差距已经缩至803.85亿元。此外，从三季度的增量来看，易方达非货ETF规模环比增长了2242.9亿元，高于华夏的2073.21亿元。</p>\n  <h2><strong>排名逆袭靠ETF</strong></h2>\n  <p>三季度非货规模TOP20的基金公司中，有两家在ETF的助力下，排名大幅提升。</p>\n  <p>一家是华泰柏瑞基金，排名提升了5个名次，从二季度末的第13位提升到第8位。这一逆袭背后，ETF功不可没。Wind数据显示，截至三季度末，华泰柏瑞非货规模为5808.01亿元，环比增长了2055.51亿元。其中，非货ETF就贡献了1993.39亿元的规模增量。</p>\n  <p>另一家是南方基金，排名提升了3个名次，从二季度末的第8位提升到第5位。南方三季度的非货规模环比增长了1096.55亿元，而非货ETF的增量高于这个数字，达到1126.53亿元。这个缺口的产生，和前面情况类似，主要是因为债基规模缩水，环比减少了120.81亿元。</p>\n  <p>非货规模TOP20中，只有中欧基金和兴证全球基金还没有布局ETF。三季度，这两家基金公司的非货排名虽然各上升了1位，但规模增长并不显著，前者环比增长274.3亿元，后者环比增长3.11亿元。</p>\n  <h2><strong>头部公募狂卷费率</strong></h2>\n  <p>当下，ETF的战略地位不言而喻。为了抢占市场份额，业内掀起了“降费潮”。</p>\n  <p>10月30日，博时基金发布了两则降费公告，涉及两只ETF——博时上证科创板50ETF、博时上证科创板100及其联接基金。从降费力度来看，都是将管理费由0.5%调整为0.15%，托管费由0.1%调整为0.05%。</p>\n  <p>就在前不久，博时才宣布下调博时创业板ETF其联接基金费率，也是将管理费由0.5%调整为0.15%，托管费由0.1%调整为0.05%，公告日期是10月11日。</p>\n  <p>ETF降费并非个例。截至10月30日，月内有13只ETF宣布下调管理费和托管费，涉及6家头部基金公司。其中，华夏基金数量最多，有4只ETF及其联接基金宣布降费。</p>\n  <p>这些产品下调后的费率都是“0.15%管理费+0.05%托管费”，已经是目前国内ETF的最低费率水平，直接卷出了“地板价”。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_59ea6f8baf584c1b801d60329761e8d5@13164445_oswg358540oswg1784oswg875_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2><strong>ETF降费“众生相”</strong></h2>\n  <p>和主动权益产品不同，由于运作模式是跟踪指数，ETF产品同质化严重。在这种竞争环境下，降费无疑是最直接的促销手段。</p>\n  <p>降费效果究竟如何？</p>\n  <p>据Wind统计，截至今年三季度末，最近一年里有15只股票型ETF下调了管理费和托管费。</p>\n  <p>整体来看，有11只在降费后场内份额有所增长。其中，份额增长最多的是广发中证1000ETF，达到55.68亿份。景顺长城创业板50ETF、国泰上证综合ETF的份额也增长超过10亿份，分别为20.37亿份、19.8亿份。</p>\n  <p>此外，南方沪深300ETF、工银沪深300ETF、银华中证全指证券公司ETF份额增长过亿，分别净流入5.59亿份、4.31亿份、2.97亿份。</p>\n  <p>而易方达旗下3只去年四季度就启动降费的ETF，份额不增反减，易方达中证1000ETF、易方达中证2000ETF、易方达上证科创板100ETF分别净流出2.16亿份、1.12亿份、4500万份。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_bbcca9242692419ab7d0b472d2b7aa22@13164445_oswg402998oswg1991oswg926_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>虽然这几只ETF降费效果不佳，但易方达还是凭借低费率，在今年收获颇丰。据Wind统计，前三季度ETF场内份额增长TOP10榜单中，易方达有3只产品在列，其中2只费率较低。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_decb6987e44b47aaa187e109397f7438@13164445_oswg244782oswg1667oswg728_img_png?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>易方达沪深300ETF排在第2位，前三季度份额增长了364.05亿份，规模增长高达2145.33亿元，费率是业内最低的“0.15%管理费+0.05%托管费”。</p>\n  <p>排在第4位的易方达上证科创板50ETF，前三季度份额净流入277.95亿份，规模增长了255.45亿元，采取的费率是“0.4%管理费+0.05%托管费”。</p>\n  <p>而没有降费的易方达创业板ETF，是该宽基指数赛道规模最大的一只产品。这是目前业内的普遍做法，凡是单一指数赛道规模最大的产品都没有降费，而是采取“追赶策略”，通过下调规模落后或规模偏低的ETF的费率来吸引流量。</p>\n  <p>本文来自微信公众号&nbsp;“财经”（ID：mycaijing），作者：蒋金丽，36氪经授权发布。</p>", "published": "2024-10-31 10:01:47", "id": "48641080-59dc-4e97-850d-44cf05a0bdc4", "source": "36氪", "section": "文章资讯"}, {"title": "o1驾驶无人机后空翻，OpenAI开发者日惊掉下巴，2分钟爆改代码写App", "link": "https://36kr.com/p/3016057832433154?f=rss", "description": "<p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_add2c919e5e74938899ca1f1b870e2ac@46958_oswg268658oswg1069oswg397_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p><strong>【导读】</strong>OpenAI伦敦开发者日上，首次曝出了o1五大核心能力，还有图像理解。o1两分钟构建应用驾驶无人机、电话订餐、讲解太阳系，现场演示让所有开发者沸腾。</p>\n  <p>完整版o1的解禁，离我们不远了！&nbsp;</p>\n  <p>就在刚刚举办的OpenAI伦敦开发者日上，开发者体验主管Romain Huet带着o1模型来秀场了。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_5b9596bee22e42c5a446cf70fa7cd6d1@46958_oswg968810oswg1080oswg1153_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>o1 mini联动Cursor在不到2分钟时间内，搭建了一个可以交互的应用，驾驶无人机表演后空翻。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_82d61c64f89d4ec8918595f3ea548e4d@46958_oswg580891oswg1080oswg599_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>现场数百名开发者， 掌声不断。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_c5cc19a551c34e9f95c1f18a369bf16a@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>还有利用RealTimeAPI，构建的实时语音AI智能体向人一样，电话卖家订购200个派。而且，o1还不忘了幽默风趣，对话情商非常高。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_92eb012964214568b254b78bc3be380e@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>不仅如此，有了o1构建的太阳系可视化介绍应用，想必未来的教学一定非常有趣。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_40b44a905dbb4e0f9da500f207de91c4@46958_oswg500511oswg1080oswg421_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>这还仅仅是预览版+mini版o1的功能，在演讲末，一张PPT展示了未来o1的五大能力：&nbsp;</p>\n  <blockquote>\n   <p>函数调用、开发者message、流式传输、结构化输出、图像理解。&nbsp;</p>\n  </blockquote>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_50ac3090f69c40cd858dcc331fead049@46958_oswg1086470oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2><strong>o1演示炸场，台下观众欢呼不断</strong></h2>\n  <h3><strong>写代码搭App，驾驶无人机后空翻</strong></h3>\n  <p>整场最让人震撼的是，用o1 mini+Cursor搭建应用驾驶无人机飞行。&nbsp;</p>\n  <p>Romain Huet告诉o1，我现在有一架无人机，还缺少一个用JavaScript编写的交互界面，但是我不会如何编程。&nbsp;</p>\n  <p>接下来，他要求o1去构建这个应用，并设定好所有的交互按钮和组件。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_7acbad884f034c86930c2e2b0c0687fd@46958_oswg552601oswg1080oswg588_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>并且，他向模型发送了一个样本视频，作为参考。&nbsp;</p>\n  <p>o1收到请求后，开始执行所有的任务。&nbsp;</p>\n  <p>在这过程中，为了确保应用程序搭建能够实时更新，Huet通过在UDP数据库上发送可能与用户-按钮交互相关信息，从而实现实时数据传输。&nbsp;</p>\n  <p>并且，这个操作也非常简单，只需要点击每个按钮，并发送更改评论，便可以在应用中得到更新。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_341a1e16450d4ecda8a2bf2edb990e9a@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>最后，我们就得到了这样的一个交互界面。&nbsp;</p>\n  <p>左边黑的的框框是无人机摄像头显示屏，右边就是各种交互的按钮了。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_3b3f9310b29646adb281819dc2e37f31@46958_oswg421016oswg1080oswg670_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>见证奇迹的时刻到了，Huet将无人机放置在地面上，打开终端，开始运行o1搭建的应用。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_b2112aa254f949caac205dc053cf964b@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>只见o1驾驶的无人机演讲台上飞起，与台下的观众来了一张大合影。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_af4850134f574dbe8f7bd92450cb1fac@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>更惊喜的是，无人机现场还来一个360度的运镜。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_46f1a1356aa34227b91b2f8352b9acf6@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>整个应用构建，用了不到2分钟的时间。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_263aadaf458d477694ad1da898cf08af@46958_oswg83266oswg1080oswg145_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>无人机demo完整视频，如下：&nbsp;</p>\n  <h3><strong>AI实时语音订购派，堪比真人</strong></h3>\n  <p>另外，Huet还秀了一波用RealTimeAPI构建实现实时语音的能力。这一功能实际上在上个月已经推出。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_16f4249f137044dd850e3eca225a86f0@46958_oswg785050oswg1072oswg742_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>他表示，现在能够实现更长时间、更稳定的对话。&nbsp;</p>\n  <p>旅行应用程序Wanderlust中，Huet假设自己正计划伦敦和新加坡之旅，假设下周就要去新加坡。&nbsp;</p>\n  <p>他问道，你能给我提供一些游览的景点吗？&nbsp;</p>\n  <p>随后，在屏幕右边可视化图中，展示除了新加坡一些著名打卡点。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_fca8b4b0eb914805b0fe59c82d712442@46958_oswg527644oswg1080oswg552_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>紧接着，Huet又让他为自己推荐酒店，以及更多细节。&nbsp;</p>\n  <p>实时语音一边说，一边给出了结果。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_3335f9b4c6b847a28835a9c2803a3248@46958_oswg458225oswg1080oswg557_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>接下里，他又让o1在伦敦chiswell街区的当地商店订购一份pie。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_05abe3aa068246c78c5f216edf38722d@46958_oswg553927oswg1080oswg838_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">OpenAI开发者论坛负责人Spencer Bentley分享&nbsp;</p>\n  <p>Huet：我们台下有数百位开发者，他们可能喜欢吃一些甜点，你能帮我看看附近这儿可能有哪些商店？&nbsp;</p>\n  <p>o1：这是一些关于pie商店更多的细节。&nbsp;</p>\n  <p>不过，o1给出的结果中，第二个并非是真实存在的商店，只有其余两个是。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_19219b7423b04da1a86b5f8dd1bfb66b@46958_oswg509647oswg1080oswg596_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>为了方便演示，让现场工作人员担任卖家，Huet邀请同伴上台，一起来完成这个任务。&nbsp;</p>\n  <p>「在预算允许的情况下，帮我们订购200个pie，可以是肉和蔬菜的混合馅料」。&nbsp;</p>\n  <p>o1直接给IIan's Poah Pies打去了电话，并像人一样主动订购。&nbsp;</p>\n  <h3><strong>介绍太阳系，让教学更有趣</strong></h3>\n  <p>另外一个用RealTimeAPI构建太阳系导航应用程序，利用o1实时语音能力介绍星系。&nbsp;</p>\n  <p>从太阳系中最大的木星，到地球，再到火星深入介绍，o1全部都能娓娓道来。&nbsp;</p>\n  <p>OpenAI研究员表示，这一功能教会了自己：在教女儿新知识时如何成为有趣的父母。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_71411c7da30d457d8112b773a0c069d3@46958_oswg113442oswg1080oswg242_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <h2><strong>奥特曼QA环节，自曝最敬佩Cursor</strong></h2>\n  <p>没有Sam Altamn的开发者日，就不算是完整的。在整场演讲结束后，最后一个环节，就是Altamn QA问答了。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_40e87a41c1b94b5ca81449653fb5f336@46958_oswg79530oswg1080oswg143_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在线上，奥特曼抛出了一个深刻的思考：&nbsp;</p>\n  <p>人们总是倾向于用历史上的技术革命来类比当前的AI革命。&nbsp;</p>\n  <p>但这种类比方式本身是存在问题的。比如说，互联网革命就与现在的情况有很大的不同。&nbsp;</p>\n  <p>也许拿晶体管来做比较会更恰当。&nbsp;</p>\n  <p>晶体管是物理学领域的重大发现，它具有惊人的规模化潜力，并且迅速在全球范围内得到应用和普及。&nbsp;</p>\n  <p>虽然晶体管技术让整个人类社会受益，但现在人们并不会把那些最早开发晶体管的公司仅仅定义为「晶体管公司」。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_8bfded649ff447229ef81b4c6ce6a0c9@46958_oswg813538oswg1080oswg687_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">「我不祈求上帝站在我这边，而是祈求自己能够站在上帝这边。在开发这些人工智能模型的过程中，我确实感觉自己是在追随光明与正义的道路。」&nbsp;</p>\n  <p><strong>问：我们应该期待像o1这样的模型还是更大规模的模型？</strong></p>\n  <p>奥特曼：希望全面提升大语言模型的性能，但这个推理思路很重要。&nbsp;</p>\n  <p>「不方便透露太多细节...但我预计视觉模型领域会有突破性进展。」（这似乎暗示即将推出比GPT-4更强大的视觉模型）&nbsp;</p>\n  <p><strong>问：在技术整合方面会达到什么程度？基于OpenAI构建产品的AI创业公司应该如何规划？</strong></p>\n  <p>奥特曼：建议创始人应该打造这样的公司——既能充分利用当前大语言模型的优势，又能在未来模型升级时获得更大发展空间。&nbsp;</p>\n  <p><strong>问：开源的定位是什么？</strong></p>\n  <p>奥特曼：答案表明开源确实有其存在空间，但同时��需要很好地整合专有模型。不过，这个回答似乎没有提供太多实质性内容。&nbsp;</p>\n  <p><strong>问：什么是AI智能体（Agent）？</strong></p>\n  <p>奥特曼：「一个可以接受长期任务并且在执行过程中只需少量监督的系统。」我认为Harrison Chase在Langchain的博客中给出的定义更加严谨，但从商业角度来看，这个定义很实用。&nbsp;</p>\n  <p><strong>问：AI智能体能做什么？</strong></p>\n  <p>奥特曼：它们能够完成人类因能力限制而无法完成的任务，比如同时与300家餐厅进行通话，让AI智能体在每家餐厅进行交谈并即时收集信息。&nbsp;</p>\n  <p>或者说，它像一位极其智慧的高级同事，你可以放心地交给他两天或一周的工作任务。&nbsp;</p>\n  <p>说实话，我很讨厌「agentic」这个词。不让我们一起边讨论边思考，然后创造一个新词吧！&nbsp;</p>\n  <p><strong>问：在过去10年里，他的领导方式发生了哪些变化？</strong></p>\n  <p>奥特曼：公司发展速度惊人，仅用两年时间就实现了数十亿美元的营收规模。从追求10%的提升转向追求10倍的突破，这需要进行大量的调整和改变。&nbsp;</p>\n  <p><strong>问：对于Peter Thiel「要招聘30岁以下的员工」的建议，你怎么看？</strong></p>\n  <p>奥特曼：我创立OpenAI时就已经过了30岁。团队需要不同年龄层的人才，真正重要的是要始终保持极高的人才标准。&nbsp;</p>\n  <p><strong>问：你最担忧的是什么？</strong></p>\n  <p>奥特曼：从整个行业角度来看，我们正在尝试解决的问题的系统性复杂度。&nbsp;</p>\n  <p><strong>问：如果现在要创建新公司，他会选择什么方向？</strong></p>\n  <p>奥特曼：专注于某个特定领域，比如开发AI法律顾问或AI工程师助手。&nbsp;</p>\n  <p><strong>问：你觉得有什么重要信息需要让更多人知道？</strong></p>\n  <p>奥特曼：一个能够全面了解并陪伴你生活的智能助手。&nbsp;</p>\n  <p><strong>问：除了OpenAI的团队，你最敬佩谁？</strong></p>\n  <p>奥特曼：Cursor团队——他们打造了一个极具突破性的AI应用体验。&nbsp;</p>\n  <p><strong>问：如果能够实现理想中的未来，你觉得会是什么样子？</strong></p>\n  <p>奥特曼：在接下来的5年里，我们可能会看到AI技术以难以想象的速度进步。但有趣的是，社会表面的变化可能并不会那么剧烈——真正的影响可能要在更长远的未来才会完全显现。&nbsp;</p>\n  <p>参考资料：&nbsp;</p>\n  <p>https://x.com/tarekayed00/status/1851570058285232392</p>\n  <p>https://x.com/morqon/status/1851580985562779890</p>\n  <p>https://x.com/caromcc_/status/1851570587287601237</p>\n  <p>https://x.com/Foxalabs/status/1851574681112879535</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/av0SAV0oKCDpeEWvichRuQ\" rel=\"noopener noreferrer\" target=\"_blank\">“新智元”</a>，编辑：桃子 好困，36氪经授权发布。</p>", "published": "2024-10-31 09:32:28", "id": "dd831556-47ce-4384-9495-32985cc3659e", "source": "36氪", "section": "文章资讯"}, {"title": "全自动打工「人」，波士顿动力Atlas进厂视频火了，不断电不下班", "link": "https://36kr.com/p/3015930540434692?f=rss", "description": "<blockquote>\n   <p>波士顿动力Atlas进厂打工，不靠远程操控，转身动作像惊悚电影。</p>\n  </blockquote>\n  <p>波士顿动力的人形机器人，进厂了。</p>\n  <p>本周三，波士顿动力发来一条喜讯。其最新披露的视频展示了机器人在工厂环境中的任务完成能力。机器人现在已经可以全自动干活了，它可以在储物柜之间搬动汽车发动机零件：</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_54165d264d7f4cffb24036aee42805e5@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>搬运的这个东西是汽车的发动机盖。视频里可见新版 Atlas 机器人是在寻找零件并挑选位置放置，还附带识别过程的展示：</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_a2ce6a6141f34108a21303e2520116a8@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>搬着搬着 Atlas 看到有人拍摄，突然虎躯一震（其实是东西没放对位置）。没关系，我很稳：</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_e800cd4415b34ae2839443ee2c342276@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>我们注意到，在拿到东西和放好东西后需要转身的瞬间，Atlas 并没有像人类一样转过来，而是以腰部为中心进行旋转，该动作最大限度地减少了移动，从而节省了过程中宝贵的几秒钟。不过，这也让人联想到一些惊悚电影里，主人公身子不动，头直接转过来的画面。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_44cbf8695a344e6392dc1941d26ccbeb@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>‍</p>\n  <p>一通操作看下来，机器人在工厂完成一些简单工作看起来是游刃有余了。</p>\n  <p>在社交网络上，网友们纷纷表示：太强了，看起来已经可以商业化了。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_e61cb8c0d8344d7e87956f1320919075@000000_oswg283202oswg1029oswg618_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>但众所周知，实现这样的愿景还有很长一段路要走。</p>\n  <p>波士顿动力指出，目前该公司的人形机器人已经能够通过视觉、受力和本体感受传感器的组合来检测环境变化（例如移动固定装置）和动作故障（例如无法插入盖子、绊倒、环境碰撞）并做出反应。</p>\n  <p>需要注意的是：波士顿动力这次强调了<strong>演示视频中的机器人是完全自主运行的，没有「预设程序或遥控动作」</strong>，它可以使用机器学习算法理解并适应真实世界的环境。这一声明似乎是在 cue 谁，但就是没有明说。</p>\n  <p>最近一段时间，哪家的人形机器人上过头条？应该是在特斯拉「We, Robot」活动中大放异彩的擎天柱 Optimus。马斯克还说，人形机器人的数量将在不到 20 年内超过人类，「这工作要由我来干」。</p>\n  <p>特斯拉的 Optimus 机器人展示了与观众互动，玩游戏、跳舞，甚至进行简单对话的能力，好不先进。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_722bcbd65a78416eb6b77c56f8718af7@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>然而，很多人指出，Optimus 在展示过程中实际上部分依赖于人类的远程操控，这引发了外界对于其自主能力的质疑。由于种种原因，特斯拉的股价当时还瞬间跌了 10%。</p>\n  <p>与 Figure、Tesla 和 Apptronik 等竞争对手一样，波士顿动力公司人形机器人的首次应用包括在汽车工厂的工作。考虑到该公司现在属于现代汽车公司，而现代汽车公司刚刚选择与丰田汽车的研究部门达成协议，关注 Atlas 这一应用是很有意义的。几十年来，汽车行业在自动化领域也一直遥遥领先。或许有一天，Atlas 真的会变身一名「汽车工人」。</p>\n  <h2><strong>波士顿动力也玩转型：Atlas 电动化之后</strong></h2>\n  <p>今年 4 月，波士顿动力曾跟全世界开了一个玩笑，先是官宣人形机器人 Atlas 退役，狠狠来了一波回忆杀。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_15c4eecea82749dd96b8da80a41191dd@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>紧接着，就在第二天，他们又放出了一个新的人形机器人视频。新机器人也叫 Atlas，不过由原来的液压改为了电动，身材更为小巧、灵活。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_0f61506a196645c1b36c89728d9cf676@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>‍此时，外界才反应过来，原来波士顿动力并不是要放弃人形机器人，而是转变了研发方向，让机器人更加适应工业环境。当时，该公司表示，这个电动版的 Atlas 将于明年初在韩国现代汽车工厂里开始进行试点测试，并会在几年后全面投产。看来，试点的时间可能提前了一些。</p>\n  <p>和之前的液压版 Atlas 一样，电动版的 Atlas 也是有一些绝活在身上的，比如随手就来一个俯卧撑：&nbsp;&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_49543cbc972d445e9afbd372a38c0e2d@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_c98661e30fb94edd97288ec8296f2118@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>做完俯卧撑后，Atlas 还能自己站起来。</p>\n  <p>倒立行走：</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_ea0c4c9df70f4c70a0879cc10b8cac37@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>这些「绝活」是怎么做到的呢？前段时间，在机器人顶会 RSS 的一场技术分享中，MIT 博士、波士顿动力机器人工程师 Robin Deits 介绍了 Atlas 机器人过去几年的研发历程，以及从中学到的经验、教训。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_40dd2b3b9c2c42eabbe07d48a5001069@000000_oswg249648oswg1080oswg483_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>具体来说，Robin Deits 主要介绍了 Atlas 控制器的核心 ——MPC（模型预测控制）。他表示，波士顿动力从 2019 年以来实现的所有机器人动作都是依靠 MPC 来完成的，包括跑酷、体操、跳舞、后空翻等等。最近，他们还展示了 MPC 用于操纵物体的效果。2024 款纯电驱动的 Atlas 新版本也是由 MPC 驱动的。</p>\n  <p>对于这场技术分享，机器之心也做了详细报道，感兴趣的读者可以抽时间详细阅读（参见《波士顿动力技术揭秘：后空翻、俯卧撑与翻车，6 年经验、教训总结》）。</p>\n  <p>其实，除了内部研发，波士顿动力也在加强与外部的基础研究合作。就在两周前，波士顿动力和丰田研究院（TRI）官宣建立新的合作伙伴关系，以「利用 TRI 的大型行为模型和波士顿动力的 Atlas 机器人，加速通用人形机器人的开发」。</p>\n  <p>根据 IEEE Spectrum 的报道，TRI 的大型行为模型（LBM）其实类似于大型语言模型（LLM），只不过它的应用场景是在物理世界中工作的机器人。TRI 长期以来一直致力于开发基于人工智能的学习技术，以应对各种复杂的操作挑战。在与波士顿动力合作后，他们将通过 Atlas 获取更多物理世界的数据，这些数据将反过来用于支持高级 LBM 的训练。双方合作有一定的互补作用。</p>\n  <p>在基础研究层面，人工智能能否给 Atlas 带来新的突破，欢迎在评论区讨论。</p>\n  <p>参考内容：</p>\n  <p>https://techcrunch.com/2024/10/30/boston-dynamics-electric-atlas-humanoid-executes-autonomous-automotive-parts-picking/</p>\n  <p>https://x.com/BostonDynamics/status/1851624026424197434</p>\n  <p>https://spectrum.ieee.org/boston-dynamics-toyota-research</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650941110&amp;idx=1&amp;sn=4ad66cf26d54d7bb1e7af84a840fb1ca&amp;chksm=8531d80ed8ccef758b8b3abd5defb896f94619c0aab519f65609852a94bd46c4783e5a07226d&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“机器之心”（ID：almosthuman2014）</a>，编辑：泽南、张倩，36氪经授权发布。</p>", "published": "2024-10-31 09:33:18", "id": "fd4d6a27-503d-489e-babc-0714bc01f67e", "source": "36氪", "section": "文章资讯"}, {"title": "一个月生成1500万条广告，Meta继续加码AI", "link": "https://36kr.com/p/3016131273188612?f=rss", "description": "<p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_364f0fb96150457fa465cbac9bb929af@000000_oswg282143oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">来源 | ad exchanger</p>\n  <p>Meta在第三季度赚了个盆满钵满，但投资者对其AI方面的支出感到担忧。</p>\n  <p>北京时间10月31日，Facebook母公司Meta发布了该公司截至9月30日的2024财年��三季度未经审计财报。报告显示，Meta第三季度营收为405.80亿美元，与去年同期的341.46亿美元相比增长19%；净利润为156.88亿美元，与去年同期的115.83亿美元相比增长35%；每股摊薄收益为6.03美元，与去年同期的4.39美元相比增长37%。</p>\n  <p>尽管第三季度业绩超出预期，但Meta在发布第三季度财报后，该公司股价在盘后交易中下跌超过15%，原因是有消息称公司今年和明年的支出将增加。Meta公司2024年的资本支出将在380亿至400亿美元之间，比之前的预期高出约10亿美元。首席财务官Susan Li表示，Meta预计2025年将继续保持 \"大量资本支出\"。</p>\n  <p>这些钱主要用在哪里？答案就是AI。毕竟，由AI驱动的Ray-Ban Meta智能眼镜和支持它们的服务器不是Meta自己开发和生产的。</p>\n  <p>首席执行官扎克伯格说：“我们的人工智能投资仍然需要大量的基础设施。我也将继续在这方面进行大量投资。” Meta AI是Meta面向消费者的ChatGPT。<strong> 据扎克伯格称，今年到目前为止，已经有超过100万广告主使用了Meta的人工智能生成工具，仅在过去的一个月里，这些工具就生成了超过1500万条广告。据Meta估计，使用其图片生成技术的企业的转化率提高了约 7%。</strong>因此，Meta正全力加码人工智能，以提高盈利效率和整体营销业绩。</p>\n  <p>具体到业务层面，Meta最近部署了新的学习和建模技术，使其广告系统能够捕捉并且联系到一个人在看到广告前后所采取的一系列行动。这个技术可以帮助广告主了解在单个用户会话中何时何地显示广告最合适。</p>\n  <p>Susan Li表示：\"以前，我们的广告系统只能将这些行动汇总在一起，而不能映射这些行动的顺序，这种新方法使我们的系统能够更好地预测受众对特定广告的反应。这也使我们能够在不增加广告数量的情况下推动收入和转化率的增长。自今年上半年实施新模型以来，Meta的广告客户在某些细分市场的转化率提高了2%至4%。</p>\n  <p>模型的另一个改善领域在用户体验，包括改进内容推荐。Susan Li说，\"因为我们发现，如果我们将模型规模和计算能力扩大到一定程度，性能就无法扩展。所以最近，Meta 开始尝试大型语言模型的扩展规律，即当模型在越来越庞大的数据库里接受训练时，其质量会随着时间的推移而发生变化。”</p>\n  <p>去年，Meta开发了新的模型架构，能够更有效地从更大的数据群中学习。现在，Meta正在探索新模型是否能对其他平台的推荐带来类似的改进。</p>\n  <p>更长远来看，Meta甚至计划将不同网页界面的数据结合起来，为其模型提供支持。\"我们将寻求在这些模型中引入跨界面数据，这样我们的系统就能从Meta的界面上了解某人感兴趣的内容，并利用这些内容给另一个网站推荐更合适的内容”Susan Li说，“这需要时间来执行。”</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MzA3NDQ3NDEzMQ==&amp;mid=2653706146&amp;idx=2&amp;sn=78e093185b084f08a6dbb5d6691e1046&amp;chksm=85aa6e0d716e9c687713f1e6f2ef7a073a9004a9c56606881c59d753c7165e529f9cc2f44f8b&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“wj00816”（ID：Morketing）</a>，作者：Tiana，36氪经授权发布。</p>", "published": "2024-10-31 09:34:17", "id": "df5e33c8-f65d-45bb-809f-5058849b283c", "source": "36氪", "section": "文章资讯"}, {"title": "完美世界10月31日放量上涨1.42%；完美世界三季度业绩亏损 游戏业务环比改善", "link": "https://36kr.com/p/3016245343724802?f=rss", "description": "", "published": "2024-10-31 10:03:44", "id": "d6ba56fc-fd42-478e-aeba-e0ed658ed1bc", "source": "36氪", "section": "文章资讯"}, {"title": "从“模仿”到“被研究”，外国车企深入逆向解析中国新能源技术", "link": "https://36kr.com/p/3016180463137670?f=rss", "description": "<p>当中国车企在欧盟和北美地区接连遭遇高关税壁垒，在巴黎车展上表达了“不会推翻那些发展了100多年的车企”后，海外媒体和机构却对中国的新能源车更加感兴趣了。</p>\n  <p>中国新能源车已经开始被国外车企 “学习”：2021年，在日本电视台播出的一档节目中，作为当时备受关注的“国民神车”五菱宏光MINI EV被“大卸八块”，整体拆解后被研究，展示了中国电动汽车在成本控制方面的实力。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_e969591420b3420e8897819debff1608@5815735_oswg417763oswg831oswg511_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>去年，日经BP社（日本经济新闻社）同样拆解了比亚迪海豹，进行了全方位的研究并编纂成书。而近日，根据日经新闻报道，日本中部经济产业局举行了分享纯电动汽车技术动向的研修会，日本中部地区约70家汽车零部件企业访问了电动汽车的拆解展示设施，并学习中国产电动汽车的车身结构和零部件设计特点。</p>\n  <p>中国车企曾在发展前期模仿日本和欧洲的设计，拆解车型，研究技术，以期在国内市场上获得竞争优势。但在现在的新能源赛道，中国汽车企业凭借产业链、快速迭代的技术等优势，成为“研究对象”，开始了技术的反向输出。</p>\n  <h2><strong>拆车容易，“抄作业”难</strong></h2>\n  <p>早在几年前，日本车企就开始意识到新能源市场的重要性，并纷纷部署相关策略。这一次的组织学习，显然是他们进一步加速转型的手段之一。而从中国新能源车的成功中寻找灵感，也是迫于现实。</p>\n  <p>根据日本媒体的报道称，主持此事的三洋贸易购买了包括比亚迪ATTO3、蔚来的ET5、极氪007等16款车型，拆解了9万余个零部件。而针对这些拆解结果，当地也举行了多次EV技术动向的研修会，至今已有450家企业、6000多人前来参观学习。</p>\n  <p>据了解，其展示内容定期更新，本月末计划新增理想 L9、现代 IONIQ 6 等 4 款车型。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_e485fc5126624d61a9cfd8384435eb83@5815735_oswg697339oswg830oswg552_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>这次前来学习的日企，包括了一些知名的汽车制造商和零部件公司，他们纷纷派遣研究团队，深入了解中国新能源车的生产线、研发流程和设计理念。这样的步骤无疑是希望通过学习最先进的技术和理念，尽快缩短自身与中国新能源车之间的差距。</p>\n  <p>参与研修会的人员向媒体表示，零部件的通用化和自产化是中国企业能够生产出低价电动汽车的背景。“中国厂商非常重视低成本生产”，而为了降低成本，一是推进零部件的整合，不仅可以减重，还能降低成本，同时降低故障率，便于后期维护。另外，这些厂商们的很多零件部件，均来自于中国的供应链，还有很多零件是自产化，且旗下多车型，进行零部件共享，这样减少开模成本。</p>\n  <p>除了现场研习之外，日经BP社还对中国多款新能源车进行了“彻底分解”，并著书以便日本汽车行业学习。目前，已知日本已经对中国制新能源车进行了众多拆解，包括五菱宏光MINI EV、欧拉好猫、比亚迪ATTO3、蔚来的ET5、极氪007等车型外，也对近期备受关注的小米SU7进行了拆解。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_5dbd0569338d4bfdad9c1c34ec9ab714@5815735_oswg445705oswg829oswg412_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>除了日系车企外，各大跨国车企也在“拆解”中国新能源车。据了解，美国一家专门帮助车企降低成本的公司CaresoftGlobal，拆解了比亚迪海鸥，最后得出的结论是：“以美国的制造水平，相同的车子需要3倍以上的成本。比亚迪能生产出如此低价且品质感在线的汽车绝非奇迹，而是效率的体现。”</p>\n  <p>奔驰研发中心在去年也特别批准了一笔费用，用以独立拆解中国新能源畅销车。首款拆解对象为极氪001车型。此外，电动汽车初创公司Rivian首席执行官RJ Scaringe在近日出席活动时表示，公司购买并拆解了一辆小米SU7，主要目的是研究Rivian在制造成本方面需要如何模仿改进。</p>\n  <p>在欧洲市场，路透社在巴黎车展开幕时称，这是一个“关键时刻”：一方面是苦苦挣扎的欧洲车企需要证明自己仍拥有竞争力；另一方面是中国车企则希望在激烈的市场竞争中站稳脚跟。与此同时，欧洲电动汽车行业集体面临需求疲软的困境，中欧车企激烈竞争加剧。</p>\n  <h2><strong>路线“摇摆”成最大“阻尼”</strong></h2>\n  <p>有日本汽车专家认为：\"单纯的拆解研究解决不了根本问题。关键在于如何建立适应新时代的研发体系和商业模式。\"可以说这句话反映了日本车企面临的真正问题：长久以来的惯性造成的不是技术层面不可逾越的差距，而是思维方式和发展理念的快速切换问题。</p>\n  <p>日系车企对于发展电动汽车的态度，一直是有些矛盾的，甚至被贴上了抵触的标签。而丰田、本田、日产三家实质上代表了日系车企的路线选择。</p>\n  <p>以丰田为例，在2020年，丰田汽车社长丰田章男就警告说：“如果汽车行业过于仓促地转向电动汽车，那么汽车行业目前的商业模式将会崩溃。”</p>\n  <p>到2022年，丰田章男在接受采访时又表示：“汽车行业中大部分人是‘沉默的大多数’，他们想知道电动车作为单一选择是否真的可行，但是他们不敢大声说出这种质疑，因为电动车被认为是大势所趋。”这不是丰田一家的看法，本田汽车首席执行官八乡隆弘也曾表示电动汽车和自动驾驶在短期内不会成为主流。</p>\n  <p>不过，在2021年，丰田还是推出新能源战略，计划在2030年前投资350亿美元用于开发电动车，还计划投入350亿美元持续开发混动、插电式混动及氢燃料电池车型。</p>\n  <p>到2030年末，丰田预计纯电动汽车的年销量将达到350万辆。为此，丰田汽车计划到2030年推出30款纯电动汽车。但在电动化转型犹豫不决，甚至“技术路线摇摆”的情况下，这种被迫转型的效果还有待观察。</p>\n  <p>面对中国电动汽车的强势崛起，显然日本车企已经意识到问题的严重性，并开始采取措施追赶。不过日本车企能否重现昔日辉煌，在电动汽车时代继续领跑全球？</p>\n  <p>答案并不乐观。</p>\n  <p>中国电动汽车产业已经形成了一定的先发优势，并在技术、市场、规模等方面建立了较高的竞争壁垒。日本车企的转型还需要克服来自内部和外部的阻力。内部看，需要打破从传统燃油车时代所沿袭的思维定式和组织架构，重新起建立适应电动汽车发展的新机制；外部则需要争取政府的政策支持，以及消费者的认可。但如果没有壮士断腕的勇气，大象转身并不容易。</p>\n  <p>正如一位接受采访的日本工程师所说，中国新能源汽车的优势已不是简单的性价比，而是一整套完整的产业生态，从核心零部件的自主研发，到完善的供应链体系，再到规模化生产带来的成本优势，这些不是靠简单模仿就能获得的技术。而如果日本车企继续“摇摆”，不断的拆车学习只会越来越绝望。</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/ziBxScTeoY1Ujp1hQANNKA\" rel=\"noopener noreferrer\" target=\"_blank\">“车市睿见”</a>，作者：杨朔，36氪经授权发布。</p>", "published": "2024-10-31 10:10:28", "id": "a8641ec6-f721-4d5e-a329-771fbbf5f205", "source": "36氪", "section": "文章资讯"}, {"title": "星巴克玩不过中国咖啡", "link": "https://36kr.com/p/3016166335739015?f=rss", "description": "<p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_a0f69f61ff8e45b0bbd34e2eb49d77e5@5317423_oswg125980oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在宝马之后，第二个宣布放弃价格战的品牌出现了。</p>\n  <p>近日，<strong>星巴克宣布将放弃此前的“低价策略”，标志着“买一送一、降价50%”等优惠活动或将成为过去式。</strong>这一重大转变发生在布莱恩·尼科尔接任星巴克新CEO后。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_c7be311f6cc6412eab8f9994b3faa13d@5317423_oswg229116oswg830oswg868_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>放弃价格战，表面上看，是源于业绩压力。第四财季，星巴克营收下滑、盈利不及市场预期；在中美两个主要市场，同店销售额均出现下滑。</p>\n  <p><strong>但更深层次的原因，可能是星巴克对中国咖啡行业价格战的情况，已经做出较高把握的判断——即将结束，星巴克也熬到头了。</strong></p>\n  <p>不知道大家有没有发现，<strong>瑞幸正变得越来越贵</strong>。我翻看了最近自己的星巴克和瑞幸外卖订单，瑞幸加浓美式基本上到手要20元左右，而星巴克这么多年都是30元左右（星巴克免运费的时候要远比瑞幸多）。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_fc9ddb3a492a47b0b74f4e3bf80158f3@5317423_oswg154310oswg831oswg519_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>而作为多年来这两款咖啡轮流喝的消费者，我可以较肯定地说，以前大部分时间，瑞幸加浓咖啡大约就是星巴克美式咖啡的1/3到1/2，基本上不会超过星巴克的一半；但上述的最近数据显示，这个比例已经接近2/3了。</p>\n  <p>而20多块钱一杯的瑞幸，也让我无数次有“倒不如加多几块买杯星巴克算了”的念头，尤其是刚发工资时。</p>\n  <p>试想象一下，这个现象和心理，连我这种普通消费者都能察觉。作为全球咖啡龙头，星巴克又怎么不会发现，价格战正慢慢走向终结呢？</p>\n  <p>不过，价格战暂缓甚至慢慢退场后，星巴克真的就会好过了吗？</p>\n  <h2><strong>回归初心</strong></h2>\n  <p>星巴克放弃价格战早有预示。</p>\n  <p>在第四季度业绩发布后，布莱恩·尼科尔就提到了星巴克面临的问题和未来的发展计划，<strong>再提“重返星巴克”计划、明确社区咖啡馆定位</strong>。同时，他也表示，未来将改进门店人员配置、移动订单和支付、简化菜单、修复定价结构，确保每个消费者每次访问都是值得的。</p>\n  <p>无论是“重返星巴克”，还是社区咖啡馆定位，<strong>星巴克的言外之意，都是把方向盘扭回体验的差异化，不愿再和“9.9元”们赤身肉搏了。</strong></p>\n  <p>这背后有业绩压力下的无奈。</p>\n  <p>不久前，星巴克发布了截至9月29日的第四财季和2024财年的初步业绩情况。</p>\n  <p>公告显示，星巴克第四财季营业收入91亿美元，同比下滑3.2%，不及分析师此前预期的93.6亿美元营收；每股盈利0.80美元，不及分析师此前预期的1.03美元。此外，星巴克将暂停发布2025财年业绩指引。</p>\n  <p>随后交易日，星巴克美股盘前跌幅超过5%。</p>\n  <p>具体经营数据方面，星巴克第四财季业绩报告显示，全球同店销售额下降7%，跌幅高于分析师预期的3.48%。</p>\n  <p>此外，星巴克在美国、中国这两大主要市场的同店销售额均表现不理想。</p>\n  <p>第四财季，星巴克在美国市场的同店销售额下滑6%，可比交易量下降4%，但每笔交易的平均消费额还是提升了4%；相比之下，<strong>中国市场则惨淡得多，同店销售额下降14%，可比交易量下降6%，每笔交易的平均消费额下降8%，可以说是量价齐跌。</strong></p>\n  <p>值得注意的是，星巴克的同店销售额已经连续三个季度下降，第四财季的降幅更是进一步拉大。</p>\n  <p>星巴克表示，<strong>降价未能带来更多顾客。</strong>星巴克前任CEO纳思翰曾主张通过APP频繁发送优惠券以拉动用户消费频次，然而，这一策略并未能有效提升业绩。特别是在疫情后，市场上涌现出众多均价几块钱的低价咖啡品牌，使得星巴克的折扣价格在多个市场中失去优势。</p>\n  <p>星巴克首席财务官Rachel Ruggeri提到：“尽管我们加大了投资力度，但未能改变客流量下降的趋势，导致我们的营收和利润都面临压力。”</p>\n  <p>目前，星巴克在全球拥有超过4万家门店，中国市场门店数超过7300家。在星巴克的管理层看来，业绩下滑的根本原因在于“消费者开始减少星巴克的光顾次数”，这也是新任CEO提出“重返星巴克”计划的根本原因。</p>\n  <p>布莱恩·尼科尔认为，消费者访问频率较低，说明已经偏离了核心，为了欢迎消费者回归并恢复增长，需要从根本上改变最近的战略，“重返星巴克”就是这个根本性的变化。</p>\n  <p>在他看来，星巴克与众不同的地方在于，这是人们聚集的温馨咖啡馆，以及在这里，提供最好的咖啡，由熟练的咖啡师手工制作，这是星巴克永恒的身份。</p>\n  <p>“我们正在从根本上改变我们的营销方式，与所有的消费者保持沟通。未来将简化过于复杂的菜单，<strong>修复我们的定价结构</strong>。”布莱恩·尼科尔表示：“我近期的重点是美国，这是我们最大的业务，我们需要让他恢复增长。此外，我们在世界各地也有大量的机会，我们的团队<strong>专注于如何让星巴克中国回归增长。</strong>”</p>\n  <h2><strong>价格战结束的苗头</strong></h2>\n  <p>星巴克放弃价格战，除了有业绩压力，也是对行业价格战的未来做出了具标志性意义的判断。</p>\n  <p>星巴克、瑞幸、库迪这咖啡三巨头近年的竞争可谓白热化得令人诧异，它们也贡献了中国超半数咖啡店。</p>\n  <p>其中，瑞幸咖啡的门店数量达到21343家，稳居行业首位；库迪咖啡门店数量也超过了1万家；反倒是1999年就进入中国的星巴克，最新的门店数量只有7596家，相比瑞幸一个季度新增门店1382家，星巴克一整年才增加了790 家门店。</p>\n  <p>可见，星巴克近年的庞大压力，主要就是被瑞幸和库迪逼的。</p>\n  <p>陆正耀、钱治亚因为瑞幸造假事件离职后，曾创立餐饮品牌趣小面、预制菜品牌舌尖英雄，皆无果。2022年10月，陆正耀重回咖啡赛道，成立库迪咖啡，并由钱治亚担任CEO。</p>\n  <p><strong>库迪采用比瑞幸更轻资产的加盟模式。</strong>库迪首席策略官李颖波称，库迪向联营商（即加盟商）批发原材料和设备，不收取加盟费，而包括门店选址等在内，则依靠更加本地化的联营商。</p>\n  <p>果然，<strong>库迪开始时的发展势头像极了当年的瑞幸。</strong></p>\n  <p>2023年2月，库迪宣布开启“百城千店咖啡狂欢节”，全场饮品价格9.9元起；6月初，成为阿根廷国家足球队全球赞助商，并推出“App新客专享1元咖啡券”的拉新活动；7月，又将促销力度加大至“每周8.8元”。</p>\n  <p><strong>库迪多名联营商对媒体表示，因为超低客单价，门店要靠总部补贴平衡盈亏。据招商证券测算，2023年上半年，库迪总部在联营商补贴方面的支出约为2-3亿元。</strong></p>\n  <p>瑞幸马上跟进。</p>\n  <p>在2023年6月全国门店破万时，瑞幸推出“每周9.9”活动，瑞幸CEO郭谨一在公司财报会上声称“要把9.9优惠活动延长至少两年”。<strong>一名瑞幸加盟商在降价之初给总部发去邮件表示不想打价格战，降价活动在门店暂停了一个月，后又在总部的要求下再次推出。</strong></p>\n  <p>同时，瑞幸也在扩大加盟版图。据极海品牌监测，2023年一、二季度，瑞幸平均每月新增门店259家；而在7月、8月和9月，分别开店608家、842家、912家，扩张明显提速。</p>\n  <p>不过，<strong>在如此激烈的价格战下，库迪和瑞幸都没有赢家。</strong></p>\n  <p><strong>“很多库迪门店不是因为降价撑不下去，而是在瑞幸门店加密之后撑不下去了。”</strong>有库迪联营商说，其库迪门店周边开了三家瑞幸，距离最近的一家仅隔一条马路。</p>\n  <p>他表示，在2023年7月的联营商大会上，针对“友商”门店加密，库迪升级了补贴政策，以支持“贴身肉搏”：门店与瑞幸距离在50米以内，补贴1.5元/杯；距离在50—100米，补贴1元/杯；距离在100—150米，补贴0.5元/杯。</p>\n  <p>“我们监控到的数据显示，<strong>库迪联营商里大约有20—30%盈利、约20—30%打平，剩下绝大多数都是亏损的，库迪已经关了1000多家店。</strong>”一名一级市场投资人称。“转让门店的人太多了，现在整店10万元出售，别人都不敢收。”前述浙江联营商也说。</p>\n  <p><strong>库迪情况惨烈同时，瑞幸也不好过。</strong>2024年，瑞幸业绩像过山车一样波动，一季度更亏损超过8000万；尽管二季度扭亏，但净利同比依然没有转正；瑞幸最新发布的三季报显示净利13亿元，同比大涨32%，但也要看到成本与费用支出达到86.23亿元，同比增长了38.2%。</p>\n  <p>有业内人士认为，如果价格战持续下去，双方都会活得非常困难。</p>\n  <p>星巴克中国董事长兼CEO王静瑛表示，中国咖啡市场正经历过渡期，目前市场尚处于早期阶段且未完全分层，“大量涌入的竞争对手专注于快速扩张和低价策略来拉动生意增长，随着时间的推移，这种情况将会逐渐消失”。</p>\n  <p>结合文章开头“瑞幸越来越贵”的现象来看，现阶段咖啡行业，已经取得庞大市场规模，且处境都不好过的瑞幸和库迪，其实可能都有缓和甚至暂停价格战的意愿和试探。</p>\n  <p>星巴克也终于看到松一口气的希望，这可能是宣称放弃价格战的底气。</p>\n  <h2><strong>骑虎难下</strong></h2>\n  <p>如果瑞幸和库迪都愿意慢慢暂缓价格战，星巴克无疑将成为赢家，至少能继续舒服地躺在舒适圈，但代价同样不小。</p>\n  <p>在行业竞争最惨烈时，星巴克也做了不少措施应对。</p>\n  <p>首先，<strong>在营销上，一直偏谨慎的星巴克开始加大动作。</strong></p>\n  <p>2023年，联名营销成了咖啡品牌一轮轮拉动销量、争抢用户的重要手段。瑞幸在2023年9月与茅台联名推出酱香拿铁，次日公布战报销售额破1亿元，11月宣布聘请年轻演员易烊千玺为新代言人；库迪紧跟着请来了另一名流量明星王一博。</p>\n  <p><strong>2023年末，星巴克中国也请来资历足够老的华裔歌星费翔作为品牌大使，并在2024年初联名动画大闹天宫IP推出产品。</strong>此外，星巴克在产品端也频繁出新，继2023年下半年推出更小杯型后，又在2024年专门为外卖渠道定制产品，这是该系列产品继2023年秋天之后的第二次出新。</p>\n  <p>与此同时，<strong>星巴克还向上游布局。</strong></p>\n  <p>2023年9月，星巴克中国咖啡创新产业园落成投产，该项目是星巴克在华打造咖啡生产和物流基地的最大投资，总投资额15亿元人民币（约合2.2亿美元），将为星巴克国内所有门店的提供咖啡。此外，星巴克还宣布，将对位于深圳的星巴克中国创新科技中心再投资2.2亿美元，以促进数字化运营。</p>\n  <p><strong>但星巴克更重要的战略举动，就是加速下沉。</strong></p>\n  <p>近年来，星巴克加速中国下沉市场的布局。王静瑛此前在财报电话会上透露，在中国近3000个县级以上城市，星巴克已经覆盖了近900个。其中，仅在今年第三季度，星巴克就新进了38个县级市场。</p>\n  <p>但为了应对瑞幸和库迪的攻势而选择的加速下沉（星巴克也许有下沉意愿，但如果不是竞争环境所致，可能会更谨慎，而非速度如此快），其实是十分冒险的举动。</p>\n  <p>一名低线城市餐饮供应链人士指出，最近咖啡需求不足，考虑拓展奶茶业务：<strong>“县城消费者主要是返乡年轻人和老人小孩，嗜好糖奶、饮品，消费能力主要在10元以下，几乎不存在适合星巴克的商务需求。”</strong></p>\n  <p>另一名重庆地区咖啡设备加盟商则称，2023年以来，从“幸运咖”“本来不该有”两个品牌回收了不少设备，“不少店开业不到一年就关了，<strong>下沉市场的咖啡需求其实没有那么大</strong>”。</p>\n  <p>消费力不高，甚至对咖啡���接受度都不高，星巴克的下沉由一开始就注定了并不顺利。更重要的是，星巴克还不能像瑞幸或者库迪那样，<strong>当战略出错时，割了加盟商韭菜后就能轻松走人，星巴克的全直营管理意味着下沉市场出错会令它处于骑虎难下的地步</strong>，甚至付出极大代价。</p>\n  <p>与瑞幸和库迪“高度线上化、店铺轻资产、即拿即走、低客单价”的典型互联网思维做连锁咖啡不同，星巴克在2017年，即瑞幸创立时，就全部收回特许经营权。这是星巴克“第三空间”模式——家庭和工作空间之外，第三个供人放松、聚集和社交的空间的品牌理念的代价。</p>\n  <p>而这种全直营杀进持续性并不稳定的下沉市场的举动，是十分冒险的，无论从前期的固定成本，还是脱不了身的浮动成本，都有令星巴克付出沉重代价的风险。</p>\n  <p>看似价格战快结束了，星巴克快熬出头了，但未来很长一段时间还要为应对竞争的举动继续买单。</p>\n  <p>参考资料：</p>\n  <p>金角财经《瑞幸不幸，命中注定》</p>\n  <p>羊城派《星巴克宣布放弃价格战，“买一送一”或成过去式》</p>\n  <p>蓝鲸财经《星巴克遭遇业绩滑坡，CEO称要让星巴克中国重归增长》</p>\n  <p>财新《咖啡战争升级，星巴克们能挺多久》</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/p3c6hxD3OV4BktTqAPfrMw\" rel=\"noopener noreferrer\" target=\"_blank\">“金角财经”</a>，作者：Chong&nbsp;Lei，36氪经授权发布。</p>", "published": "2024-10-31 10:13:28", "id": "d680c4f7-93e8-404b-884c-607772aebe50", "source": "36氪", "section": "文章资讯"}, {"title": "中油工程10月31日放量上涨2.59%", "link": "https://36kr.com/p/3016248302020096?f=rss", "description": "", "published": "2024-10-31 10:06:39", "id": "35421ddd-2d35-4e2d-9033-82b4884b9d41", "source": "36氪", "section": "文章资讯"}, {"title": "一汽解放10月31日放量上涨0.23%；一汽解放“车联网大数据云脑平台”获国家级大奖", "link": "https://36kr.com/p/3016240187729415?f=rss", "description": "", "published": "2024-10-31 09:58:30", "id": "c928813f-bd90-43fd-960d-53fc333bfc35", "source": "36氪", "section": "文章资讯"}, {"title": "慈星股份10月31日缩量下跌0.49%", "link": "https://36kr.com/p/3016237346596104?f=rss", "description": "", "published": "2024-10-31 09:55:30", "id": "6f9fea69-f494-4e5d-b796-1f9d5a06440d", "source": "36氪", "section": "文章资讯"}, {"title": "三羊马10月31日放量下跌0.3%；三羊马第三季度营收增长近两成", "link": "https://36kr.com/p/3016220491785480?f=rss", "description": "", "published": "2024-10-31 09:38:27", "id": "30a8c392-ab57-4ae6-975b-a2a9b0b45cd9", "source": "36氪", "section": "文章资讯"}, {"title": "氪星晚报｜SpaceX完成第200次星链发射任务，马斯克祝贺；丰田汽车：与NTT公司2025年开始开发人工智能平台", "link": "https://36kr.com/p/3016214601934087?f=rss", "description": "<h2>大公司：</h2>\n  <p><a href=\"https://36kr.com/newsflashes/3016178799158532\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>旭升集团：控股股东筹划控制权变更，股票继续停牌</strong></a></p>\n  <p>36氪获悉，旭升集团公告，公司接到控股股东徐旭东通知，徐旭东及其一致行动人正在筹划涉及所持公司股份的转让事宜，可能导致控制权变更。由于该事项存在重大不确定性，公司股票及转债于2024年10月30日至31日已停牌两个交易日。经向上海证券交易所申请，自2024年11月1日起继续停牌，预计不超过三个交易日。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016141164586505\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>三星暗示有望近期开始向英伟达供应HBM芯片</strong></a></p>\n  <p>韩国三星电子公司周四暗示，有可能在近期向美国人工智能巨头英伟达提供先进的高带宽存储器（HBM）。这家韩国科技巨头一直在努力让其HBM3E芯片通过英伟达的质量测试，而其本土竞争对手SK海力士公司最近已开始量产业界领先的12层HBM3E芯片。三星电子内存业务副总裁Kim Jae-june在第三季度财报公布后召开的电话会议上表示：“目前，我们正在量产8层和12层HBM3E产品。”（新浪财经）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015929760720392\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>ZOLOZ作为亚太唯一厂商入选Gartner身份验证魔力象限</strong></a></p>\n  <p>36氪获悉，近日，全球信息技术研究和顾问公司Gartner发布《身份验证魔力象限》报告，全球范围内有11家机构入选，蚂蚁数科旗下ZOLOZ成为亚太地区唯一入选的厂商。据介绍，这是Gartner首个专注于身份验证领域的魔力象限报告。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016101576074504\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>壳牌第三季度盈利超市场预期</strong></a></p>\n  <p>由于天然气业务不断增长，壳牌的收益超过了市场预期，部分抵消了低油价和炼油利润率疲软对第三季度业绩的影响。能源巨头壳牌周四公布，本季度调整后收益为60.3亿美元，同比下降4%，但超过了该公司普遍预期的53.6亿美元。按市值计算，该公司宣布季度股息为34.40美分，并表示将在第四季度回购价值35亿美元的股票，这与之前的指导一致。（新浪财经）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015942920021511\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>现代汽车发布氢燃料电池概念车INITIUM，明年上半年推出量产车</strong></a></p>\n  <p>现代汽车于韩国首尔发布了最新名为INITIUM的氢燃料电池概念车。基于INITIUM概念车，现代汽车将于2025年上半年推出全新的量产氢燃料电池车。据介绍，INITIUM概念车配备了低风阻轮毂并搭载低滚阻轮胎，以减少阻力，其续航里程超过650公里。现代汽车计划在11月份的广州车展和洛杉矶车展上对外展示INITIUM概念车。（界面）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015937271735560\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>大众汽车向工人提出节省成本计划，希望避免关闭德国工厂</strong></a></p>\n  <p>大众汽车向工人提出了一项可以避免德国工厂关闭的成本节约建议。这家汽车制造商的首席谈判代表Arne Meiswinkel表示，该计划包括减薪10%和修改奖金制度。当前大众汽车品牌面临欧洲需求疲弱和来自中国竞争加剧的局面，这些措施意在重振雄风。大众汽车和劳工领袖警告说，如果不能就其他措施达成充分的协议，那么关闭工厂仍有可能。（新浪财经）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016167497164289\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>理想汽车：第三季度净利润28.2亿元，同比增长0.3%</strong></a></p>\n  <p>36氪获悉，理想汽车发布2024年第三季度财报。财报显示，该季度理想汽车实现净利润28.2亿元，同比增长0.3%；预计第四季度交付量16万至17万辆，同比增长21.4%至29.0%。理想汽车美股盘前跌超4%。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016048261490184\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>飞猪双11主题乐园及热门景区活动商品已卖出超50万件</strong></a></p>\n  <p>36氪获悉，据飞猪消息，截至10月30日24时，双11主题乐园及热门景区相关活动商品已售出超50万件，超越去年双11全程。其中，部分头部乐园品牌爆款商品的预约率达90%，部分滑雪季旅游套餐的预约率超过40%。</p>\n  <h2>投融资：</h2>\n  <p><a href=\"https://36kr.com/newsflashes/3016055138182657\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>西门子同意以106亿美元现金收购模拟软件公司Altair</strong></a></p>\n  <p>当地时间10月30日，西门子宣布同意斥资106亿美元以全现金交易方式收购模拟软件公司Altair Engineering。西门子将为Altair每股支付113美元现金，后者估值达到106亿美元。这一报价较2024年10月21日Altair未受影响的收盘价溢价19%。Altair总部位于美国密歇根州，向工业制造、消费品、能源和其他行业的大型企业客户销售数据分析技术和服务。（界面）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015970656052741\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>“临科智华”完成2300万元种子轮融资</strong></a></p>\n  <p>36氪获悉，“临科智华”近日宣布完成2300万元种子轮融资，投资方为谦益资本。本轮融资资金，临科智华将用于团队建设、技术研发，以及人工智能核心技术基础建设。临科智华成立于2024年，致力于为各行业公司提供数据智能解决方案。</p>\n  <h2>新产品：</h2>\n  <p><a href=\"https://36kr.com/newsflashes/3016047124375048\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>百川智能发布一站式解决方案</strong></a></p>\n  <p>36氪获悉，今日，百川智能推出一站式大模型商业化解决方案，即1+3产品矩阵（全链路优质通用训练数据，Baichuan4-Turbo、Baichuan4-Air两款模型和全链路领域增强工具链），该方案“工具多、速度快、效果好、成本低”，能够帮助企业以最低成本实现效果最佳的私有化部署。并支持企业将专有数据与百川智能自用的全链路优质训练数据混合，对Baichuan4-Turbo、Baichuan4-Air两款模型进行调优和增强，实现了行业最高的96%多场景可用率。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015956651844871\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>思必驰发布AI办公本Turbo</strong></a></p>\n  <p>36氪获悉，思必驰发布AI办公本Turbo，搭载了专业级跨模态会议大模型。思必驰IOT事业部首席产品官马斌斌表示，这一模型基于千万小时的会议训练数据优化，能够实现手写输入、图像扫描、语音输入以及历史笔记文档的跨模态融合。基于大模型技术的智能笔记是思必驰AI办公本的核心功能，包括会议录音实时转文字、AI笔记结构化提炼要点和会后自动生成会议纪要等。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015956121937417\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>丰田汽车：与NTT公司2025年开始开发人工智能平台</strong></a></p>\n  <p>丰田汽车表示，与NTT公司2025年开始开发人工智能平台，预计到2030年与NTT对人工智能平台的投资总额将达5000亿日元。（财联社）</p>\n  <h2>今日观点：</h2>\n  <p><a href=\"https://36kr.com/newsflashes/3016042640942344\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>SpaceX完成第200次星链发射任务，马斯克祝贺</strong></a></p>\n  <p>马斯克的SpaceX公司在社交平台X上发帖称，该公司的“猎鹰9号”火箭周三完成了第200次近地轨道“星链”发射任务。当地时间周三晚上，一枚“猎鹰9号”火箭从佛罗里达州向太空发射了23颗星链卫星，这是该公司第200次执行“星链”发射任务。星链是SpaceX的一个分支，在轨道卫星网络的帮助下，为全球400多万人提供低延迟网络连接。今年9月初，该公司表示已向太空发射了7000多颗星链卫星。SpaceX首席执行官埃隆·马斯克发帖祝贺SpaceX团队发射成功。（新浪财经）</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016036902659333\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>摩根士丹利：将AMD目标价从178美元下调至169美元</strong></a></p>\n  <p>36氪获悉，摩根士丹利的报告显示，AMD的季度表现符合预期，但市场反应表明公司面临高期望的挑战。该行仍然看好2024至2025年在人工智能领域的投资机会，尽管有部分收入和盈利的预期可能过高。摩根士丹利将AMD的目标价从178美元下调至169美元，维持“与大市同步”的评级,预计AMD截至明年3月的季度收入为69.86亿美元，2025年全年收入为310.7亿美元，2026年收入将增长25%至29%。</p>\n  <h2>其他值得关注的新闻：</h2>\n  <p><a href=\"https://36kr.com/newsflashes/3016207431968000\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>北交所：拟于11月2日开展交易支持平台优化第一次全网测试</strong></a></p>\n  <p>36氪获悉，10月31日，北京证券交易所办公室、全国股转公司办公室发布通知，拟于近期开展交易支持平台优化第一次全网测试，参测机构包括北交所、全国股转公司、中国结算、深证通、证券公司、基金公司、信息商等。测试时间为11月2日。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3016204332918020\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>国家外汇管理局扩大3项跨境投融资便利化试点</strong></a></p>\n  <p>36氪获悉，日前，国家外汇管理局在总结前期试点经验的基础上，决定将开展外商投资企业境内再投资免登记试点和银行直接办理外债登记试点的地区扩大至天津市、安徽省、山东省（含青岛市）、湖北省和四川省，将“科汇通”试点地区扩大至上海市、北京市、天津市、河北雄安、南京市、苏州市、杭州市、合肥市、武汉市、长沙市、广州市、重庆市、成都市、绵阳市、西安市和深圳市等16个地区。</p>\n  <p><a href=\"https://36kr.com/newsflashes/3015997187466503\" rel=\"noopener noreferrer\" target=\"_blank\"><strong>广东省内11家发电公司发函建言：设置年度交易电量比例限制，优化月度供需比机制</strong></a></p>\n  <p>2025年，电力市场将进入年度长协签约的时间窗口，但目前电力中长期市场因机制不够完善给发电企业带来了困难。10月25日，广东省内11家发电公司联合向广东省能源局、国家能源局南方监管局致函要求“进一步完善中长期市场机制”。（21世纪经济报道）</p>", "published": "2024-10-31 09:43:22", "id": "233bb8ae-8dfc-4381-a84a-a770ff467647", "source": "36氪", "section": "文章资讯"}, {"title": "中国联通10月31日放量下跌0.4%；中国联通圆满完成神舟十九号载人飞船发射通信保障任务", "link": "https://36kr.com/p/3016234337494536?f=rss", "description": "", "published": "2024-10-31 09:52:34", "id": "c83129f9-ccd4-4a5e-9410-598128b2d27f", "source": "36氪", "section": "文章资讯"}, {"title": "中国铁物10月31日放量上涨1.82%", "link": "https://36kr.com/p/3016240398460167?f=rss", "description": "", "published": "2024-10-31 09:58:38", "id": "6ebd3fe3-6eaa-4fc3-9824-c7f905796322", "source": "36氪", "section": "文章资讯"}, {"title": "海尔智家10月31日放量下跌2.27%；海尔智家创新设计中心引领设计趋势改变用户生活", "link": "https://36kr.com/p/3016237138847234?f=rss", "description": "", "published": "2024-10-31 09:55:24", "id": "26576318-01a5-43ba-8596-aa67bf35eae2", "source": "36氪", "section": "文章资讯"}, {"title": "常山北明10月31日放量上涨10.01%；常山北明拟实施资产置换引入新能源及智慧城市业务", "link": "https://36kr.com/p/3016250773644802?f=rss", "description": "", "published": "2024-10-31 10:09:19", "id": "1e852b87-ed2e-408f-9f0c-df6c283b19c4", "source": "36氪", "section": "文章资讯"}, {"title": "一个家庭往上走的10个建议", "link": "https://36kr.com/p/3015928611022087?f=rss", "description": "<p>哈喽大家好，我是阿秀。&nbsp;</p>\n  <p>最近在跟朋友聊了一个话题，感觉蛮有意思。&nbsp;</p>\n  <p>个人的成长可能比较明确，但是一个家庭整体怎么成长，感觉现在市面上聊得还比较少。&nbsp;</p>\n  <p>在这里分享给大家，家庭如何才能跨越阶层的秘诀。&nbsp;</p>\n  <p>能够做到这几点，多数普通家庭，都能够生活得更好。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_d12609837e9b45cdbb01e823260fa62f@000000_oswg475735oswg839oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">电影《爱》剧照&nbsp;</p>\n  <h2><strong>01 &nbsp;在婚姻之中，尽量减少日常损耗</strong></h2>\n  <p>夫妻之间难免吵架，但是有些吵架，往往是因为很小的事。&nbsp;</p>\n  <p>比如有些家庭，频繁因为谁刷碗的事情吵架，不如买一台洗碗机，直接解决问题。&nbsp;</p>\n  <p>比如有些家庭，频繁因为谁拖地、扫地的事情吵架，不如一周请一次保洁，一百多块就能避免摩擦。&nbsp;</p>\n  <p>还有日常的，谁送孩子，谁扔垃圾……这些摩擦都不大，但是能让你们吵几个小时。&nbsp;</p>\n  <p><strong>很多家庭争端，都可以通过分工，购买电器，购买服务的方式解决。</strong></p>\n  <h2><strong>02 &nbsp;重视教育，但也要考虑孩子是不是那块料。</strong></h2>\n  <p>朋友说北京很多家长，鸡娃无上限，有些孩子从幼儿园到大学，能花几百万。&nbsp;</p>\n  <p>因为很多父母都有望子成龙的想法，更不接受孩子学历不行的风险，于是疯狂鸡娃，双方都很痛苦。&nbsp;</p>\n  <p>其实类似新闻很多，高三花70万补课，高考300分；花300万出国留学，回国月薪4000；因学习压力过大，孩子重度抑郁……&nbsp;</p>\n  <p><strong>有些孩子就不是那块料，再怎么折腾也没用，更何况现在时代变了，高学历未必就有高回报，没必要无脑鸡娃，让全家都痛苦。</strong></p>\n  <h2><strong>03 &nbsp;孩子多会严重影响家庭生活质量和个人成就，照顾吃喝拉撒还是其次的，关键是培养太耗精力。</strong></h2>\n  <p>有些人向往生两个、三个、四个，花多少钱都是次要的，关键是要花巨大的力气培养。&nbsp;</p>\n  <p>很多家长把自己奋斗的时间，花在让孩子奋斗上，很难说就是负责任。&nbsp;</p>\n  <p>毕竟<strong>如果你好好干，你的孩子才能少走很多弯路。</strong></p>\n  <p>最后多孩家庭，往往只能让孩子自由生长，因为根本管不上，但是照顾生活依然会耗费父母大量精力，影响个人成就的取得。&nbsp;</p>\n  <h2><strong>04 &nbsp;不要总想着打工赚钱，一点点积累是很慢的。</strong></h2>\n  <p>一个家庭里最好的配置，是一个追求稳定，一个追求高收入，既能抗风险，又能尽快积累第一桶金，让家庭突破圈层。&nbsp;</p>\n  <p>大家要知道，虽然做生意有风险，但是同样是年入百万，做生意可比上班，更容易拿到这个结果。&nbsp;</p>\n  <h2><strong>05 &nbsp;面子其实不重要，很多人是为了面子活受罪，买更大的房子、更贵的车、更名牌的包，对家庭财富的增长并没有显著的帮助。</strong></h2>\n  <h2><strong>06 &nbsp;家庭财富的暴增，往往依赖两个途径，一是夫妻双方增加收入，逐渐积累，二是投资资产增值。</strong></h2>\n  <p>反之亦然，家庭财富的暴减，一是夫妻双方挥霍无度，二是资产贬值。&nbsp;</p>\n  <p>挥霍无度这个就不说了，说说资产增值和贬值。&nbsp;</p>\n  <p>过去十年房地产暴涨，给很多人种下了必须买房的思想钢印，觉得买房就会暴涨。&nbsp;</p>\n  <p>但实际上， <strong>资产的增值是跟时代息息相关的，你多么会看盘，你多么懂地段，其实意义没那么大，关键还是选对时机。</strong></p>\n  <p>要知道，不管你房子卖不卖，买了就是接盘，资产的贬值，可是要命的。&nbsp;</p>\n  <h2><strong>07 &nbsp;每个人都应该为家庭做贡献，有钱的出钱，有力的出力，就算什么都做不了，也得捧个人场。</strong></h2>\n  <p>任何时候，我穷我有理，我菜我不管的人，都没前途。&nbsp;</p>\n  <h2><strong>08 &nbsp;一个家庭往上走，最重要的是团结。</strong></h2>\n  <p>谁也别把谁当外人，谁也别把谁当提款机，谁也别把谁当免费保姆，谁也别把对方付出当做理所当然。&nbsp;</p>\n  <p>互相体谅，互相尊重，互相扶持，日子就不会太差。&nbsp;</p>\n  <h2><strong>09 &nbsp;钱聚人散，钱散人聚，一家人不要把钱看得太重，更不要互相隐瞒财产，对家人如果都不大方，就很难走到最后。</strong></h2>\n  <h2><strong>10 &nbsp; 不要躺平，也不要让配偶、孩子躺平，更不要轻易为别人兜底。</strong></h2>\n  <p>可能你们家条件不错，觉得可以有全职太太、全职儿女。&nbsp;</p>\n  <p>但这就有两个问题，一是人需要工作，来跟社会接触，全职在家，就很容易变得呆呆傻傻。二是人需要有独立的经济来源，否则在生活上被人供养，就很容易失去独立人格。&nbsp;</p>\n  <p>不要说年轻人，就是刚刚退休的人，如果有合适的机会，也应该再奋斗几年，多赚一点钱。&nbsp;</p>\n  <p>这不是内卷，而是很多人工作了一辈子，猛然间闲下来，反而会导致生理、心理上出问题，倒不如继续找份工作返聘回去，不光为了赚钱，生活也能更加规律健康。&nbsp;</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MzAwNjg2MDkwNA==&amp;mid=2247632439&amp;idx=1&amp;sn=9ee0d982140cb22fb13ab7158ae9e4eb&amp;chksm=9adffc0f4b665703e71890cc2b800c6676af4246bfc3aea14991e955e2561c8773a8f6a9fcc2&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“进击的阿秀”（ID：zchxuexi）</a>，作者：进击的阿秀，36氪经授权发布。</p>", "published": "2024-10-31 09:30:28", "id": "40ae8fde-9a89-4ecf-a19b-6603701a4a19", "source": "36氪", "section": "文章资讯"}, {"title": "士兰微10月31日放量上涨5.22%", "link": "https://36kr.com/p/3016237776004616?f=rss", "description": "", "published": "2024-10-31 09:55:57", "id": "7e5ab537-71da-4655-8a61-dff58918b154", "source": "36氪", "section": "文章资讯"}, {"title": "国投电力10月31日放量下跌1.81%；国投电力前三季度业绩增长", "link": "https://36kr.com/p/3016219125294336?f=rss", "description": "", "published": "2024-10-31 09:37:07", "id": "052239e6-b4a5-4d2b-afd7-a5f415e5a723", "source": "36氪", "section": "文章资讯"}, {"title": "云从科技10月31日放量下跌0.92%", "link": "https://36kr.com/p/3016243319432456?f=rss", "description": "", "published": "2024-10-31 10:01:35", "id": "c65bb953-3e74-47ec-8d8d-d39f6b36aeaf", "source": "36氪", "section": "文章资讯"}, {"title": "智飞生物10月31日缩量下跌0.18%；智飞生物四价流感病毒裂解疫苗获批临床试验", "link": "https://36kr.com/p/3016223714206978?f=rss", "description": "", "published": "2024-10-31 09:41:48", "id": "1be3c916-decd-4ee1-befa-8b3e7a94c487", "source": "36氪", "section": "文章资讯"}, {"title": "明月镜片10月31日缩量下跌1.08%", "link": "https://36kr.com/p/3016240699237641?f=rss", "description": "", "published": "2024-10-31 09:58:55", "id": "be2a4d0e-9122-4947-90d2-6c23806e41dc", "source": "36氪", "section": "文章资讯"}, {"title": "中油资本10月31日放量上涨8.21%；中油资本将于11月27日召开股东大会", "link": "https://36kr.com/p/3016247847118341?f=rss", "description": "", "published": "2024-10-31 10:06:23", "id": "39ae3498-b6e0-48fd-bb5d-3f4b73f56d2b", "source": "36氪", "section": "文章资讯"}, {"title": "科氪 | 全面AI，为消费者打造最惊艳的产品！荣耀Magic 7系列", "link": "https://36kr.com/p/3016197913765124?f=rss", "description": "<h3><strong>2024年10月30日，深圳</strong>&nbsp;— 在科技界万众瞩目的荣耀Magic7新品发布会上，荣耀公司CEO赵明以一场深刻而详尽的群访，为公众揭开了这款集科技与艺术于一身的智能手机的神秘面纱。此次发布会不仅是对荣耀Magic系列的一次重要迭代，更是荣耀在AI技术领域深耕细作、持续创新的集中展现。赵明就新品定价、AI技术应用、市场策略以及公司未来发展等多个维度，与在场数十家媒体进行了深入而坦诚的交流。</h3>\n  <p><strong>一、定价哲学：坚守核心价位，传递消费者价值</strong></p>\n  <p>在谈及荣耀Magic7的定价策略时，赵明展现出了其作为行业领导者的深思熟虑与远见卓识。他强调，荣耀始终坚守在核心价位段为消费者打造最为认可和惊艳的产品的理念。这一理念不仅体现在荣耀Magic7的定价上，更是荣耀品牌精神的集中体现。</p>\n  <p>赵明指出，尽管当前全球供应链面临诸多挑战，芯片等关键元器件价格大幅上涨，但荣耀并未因此将成本压力转嫁给消费者。相反，荣耀选择通过内部优化、技术创新等方式，吸收成本上涨带来的压力，确保荣耀Magic7在保持高品质的同时，价格依然亲民。</p>\n  <p>“我们坚信，只有真正站在消费者的角度，才能赢得市场的认可。”赵明表示，“荣耀Magic7的定价策略，正是我们这一理念的生动体现。我们希望通过这款产品，让更多的消费者能够享受到科技带来的便利与乐趣。”</p>\n  <p><strong>二、AI技术：重构手机体验，引领未来趋势</strong></p>\n  <p>AI技术作为荣耀Magic7的核心竞争力之一，成为了群访中的另一大焦点。赵明详细介绍了荣耀在AI技术领域的布局与成果，展现了荣耀在科技创新上的雄厚实力与前瞻视野。</p>\n  <p>他回顾道，荣耀早在4年前就敏锐地洞察到了AI技术的巨大潜力，并开始了前瞻性的布局。从最初的低功耗地理围栏技术，到如今AI在操作系统、屏幕、通讯、拍照、续航等多个方面的广泛应用，荣耀的AI技术已经实现了从量变到质变的飞跃。</p>\n  <p>赵明强调，AI技术不仅提升了手机的使用体验，更使手机变得更加智能、更加懂消费者。例如，通过AI技术，荣耀Magic7能够根据用户的使用习惯和需求，智能调整屏幕亮度、优化拍照效果、提升通讯质量等，为用户带来更加个性化、更加贴心的服务。</p>\n  <p>“AI技术正在深刻改变着我们的生活和工作方式。”赵明表示，“荣耀将继续加大在AI技术领域的投入和研发力度，推动手机行业向更加智能化、更加人性化的方向发展。”</p>\n  <p><strong>三、GT系列回归：强化品牌基因，满足多元化需求</strong></p>\n  <p>在群访中，赵明还就荣耀GT系列的回归进行了详细解读。他表示，GT系列的回归是荣耀强化互联网手机和年轻人品牌基因的重要举措，也是荣耀满足消费者多元化需求的重要布局。</p>\n  <p>赵明指出，当前手机市场竞争日益激烈，消费者需求也日益多元化。荣耀GT系列以其卓越的性能、时尚的设计和亲民的价格，成为了年轻人喜爱的手机品牌。此次GT系列的回归，将进一步提升荣耀在互联网手机市场的竞争力，满足更多年轻消费者的需求。</p>\n  <p>同时，赵明也强调，荣耀GT系列的回归并非简单的产品复刻或价格竞争。相反，荣耀将通过优质的研发实力和市场能力，为GT系列注入新的活力和内涵，使其成为年轻人追求时尚、个性与品质的首选品牌。</p>\n  <p><strong>四、展望未来：坚持创新驱动，引领行业发展</strong></p>\n  <p>在群访的最后环节，赵明展望了荣耀的未来发展。他表示，荣耀将继续坚持创新驱动的发展战略，加大在新技术、新领域的研发投入和布局。同时，荣耀也将积极拓展国际市场，提升品牌影响力和竞争力。</p>\n  <p>赵明强调，荣耀的未来发展离不开消费者的支持和信任。他表示，荣耀将始终坚持以消费者为中心的理念，不断提升产品和服务质量，为消费者带来更加优质、更加智能的科技体验。</p>\n  <p>“我们相信，只有不断创新、不断进步，才能赢得消费者的认可和支持。”赵明表示，“荣耀将继续努力，成为消费者信赖的智能手机品牌，引领手机行业的发展和进步。”</p>\n  <p>荣耀Magic7的发布不仅展示了荣耀在智能手机领域的创新实力和技术底蕴，更体现了公司对消费者需求的深刻洞察和满足。通过坚守核心价位、深耕AI技术、强化GT系列品牌基因以及坚持创新驱动的发展战略，荣耀正逐步构建起一个更加完整、更具竞争力的产品体系和市场布局。未来，荣耀将继续以消费者为中心，推动智能手机行业的发展和进步，为消费者带来更加美好的科技生活。</p>", "published": "2024-10-31 09:44:44", "id": "d02fd92e-ae6d-4241-86ae-e6bfadf3e96d", "source": "36氪", "section": "文章资讯"}, {"title": "还在狂奔的新茶饮，今年有不少新品牌获融资？", "link": "https://36kr.com/p/3015931934205443?f=rss", "description": "<p>这几年，消费领域的融资持续降温遇冷。而新茶饮，作为新消费里面为数不多还有新融资的细分赛道，时刻用新的故事吸引资本持续地下注。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_e086a13548bf4b8bb1bdce74fd20b642@000000_oswg264988oswg1080oswg718_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>IT桔子数据显示，新茶饮的融资浪潮可以追溯到2016年。在这一年，头部新茶饮品牌奈雪的茶、喜茶纷纷获得了首轮融资。当年刘强东和章泽天还花了5亿元投资了原麦当劳中国COO、原金钱豹自助餐品牌CEO缪钦创办的因味茶inWE，成为当时业内一起轰动的投资事件。&nbsp;</p>\n  <p>2019年后现制茶饮融资逐渐火热，到高峰时期的2021年就有25家新茶饮品牌获得了融资，整个赛道的融资总额达到了惊人的70亿元。&nbsp;</p>\n  <p>这几年新消费虽然有所降温，但新茶饮市场目前正在激烈酣战，新的品牌异军突起、一路狂奔，老的品牌或发力开辟新天地或固守一隅。&nbsp;</p>\n  <p>据IT桔子数据，新茶饮融资热度不减，截至今年10月中旬，就有12家品牌获得了新的融资，可谓是新消费赛道里的一股清流。&nbsp;</p>\n  <p>我们重点来看看最近一年内获得新融资的现制茶饮品牌们都有谁呢，他们有什么特色？&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_a1716355551840c98986703db51c3579@000000_oswg314241oswg1080oswg1179_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">14家新茶饮品牌获新融资，2024年融资的就有12家 &nbsp; &nbsp;图源：IT桔子投资事件库-茶饮&nbsp;</p>\n  <h2><strong>老网红品牌沪上阿姨获新融资并启动IPO</strong></h2>\n  <p>在一众有些陌生的新面孔中，出现了个别老的网红茶饮品牌的身影，比如沪上阿姨。&nbsp;</p>\n  <p>继去年8月完成B轮2.3亿元融资后，时隔半年，沪上阿姨在今年2月又宣布了新的C轮融资，融资总额为1.215亿元。&nbsp;</p>\n  <p>成立于2013年的沪上阿姨，虽然品牌运营时间很长，但开启对外股权融资的时间却明显晚于同期成立的其他茶饮品牌。&nbsp;</p>\n  <p>据IT桔子数据，沪上阿姨的A轮融资是在2020年底宣布的，此后一直保持着良好的融资节奏和势头，基本上每年都宣布了新的融资，也是今年唯一有新融资进入的老茶饮品牌了。&nbsp;</p>\n  <p>值得一提的是，最新的投资方名单显示，除了金鼎资本、瀚晖资本两家VC/PE机构，还有一家是产业链上市公司海融科技——专注于提供奶油小料。&nbsp;</p>\n  <p>此外，IT桔子还注意到，奈雪的茶和沪上阿姨两家新茶饮品牌在2021年底均在茶饮供应链上游发力，参与了田野股份的增资。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_f5fe03175d924e7887f2823089ed0786@000000_oswg249456oswg1080oswg584_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图源：IT桔子《2022年中国现制茶饮投融资报告》&nbsp;</p>\n  <p>同时，沪上阿姨正在申请港交所上市，是目前正冲刺港股IPO的第四家茶饮企业。前三家分别是古茗、蜜雪冰城和茶百道。&nbsp;</p>\n  <p>招股书显示，截至2023年9月30日，<strong>沪上阿姨拥有7297家门店，是中国第四大现制茶饮店品牌</strong>；其中，由加盟商经营的达到7245家，占比99.3%。&nbsp;</p>\n  <p>财务数据显示，沪上阿姨2021年至2023年前9个月，营收分别为16.4亿元、21.99亿元、25.35亿元，毛利分别为3.58亿元、5.86亿元、7.9亿元，毛利率分别为21.8%、26.7%、31.2%，期内利润分别为8339.9万元、1.49亿元、3.24亿元。&nbsp;</p>\n  <h2><strong>新锐茶饮品牌是融资主力，但鲜有头部VC接力</strong></h2>\n  <p>新锐品牌可谓是今年新茶饮融资的主力，他们大都是成立三年以内，并获得了A轮、天使轮这样的早期投资。&nbsp;</p>\n  <p>值得关注的是在这个月，阿里本地生活领投新中式茶饮品牌「茉莉奶白」近亿元融资。&nbsp;</p>\n  <p>据36kr报道，2021年，茉莉奶白在深圳开出了第一家门店，是第一家聚焦茉莉品类的茶饮品牌。创始人张伯丞是一名连续创业者，涉足中餐、烘焙和饮品，拥有十多年餐饮行业创业经验。&nbsp;</p>\n  <p>相比三年前，现制茶饮的竞争呈现指数级增长。此前茉莉奶白主要集中于一流商圈，门店面积以60平米为主，到了今年年中，茉莉奶白调整店型，推出了35-40平米的小店模型，来降低前期开店的投入成本，缩短回本周期。&nbsp;</p>\n  <p>融资后，<strong>茉莉奶白的拓店速度也在加快，预计到年底门店将超千家</strong>，同时做了出海布局，海外第一家店开在了美国纽约。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_69873318dec14d4baf49334e313bb1ae@000000_oswg430486oswg1051oswg507_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图源：茉莉奶白官网&nbsp;</p>\n  <p>此外，一些具有地域特色的地方茶饮品牌被资本关注到，包括：&nbsp;</p>\n  <p>邓氏阿嬷手作，融合台湾与广西两地特色的手作奶茶品牌，获年年有余资本投资；</p>\n  <p>成都本土新咖啡茶饮品牌蓉小乔，主打萃咖、原叶茶，去年11月获中南金服控股投资；</p>\n  <p>西安健康茶饮品牌豆斯基DOUSKI，主要研发豆乳茶新饮品。</p>\n  <p>从今年新茶饮的投资方来看，可以说几乎没有出现头部超级一线VC机构的身影，更多是新的中小机构的接力。&nbsp;</p>\n  <p>对于主流机构来说，他们前些年已经参与了头部茶饮品牌的融资，更急于寻求退出之道。&nbsp;</p>\n  <p>此外，我们判断，对于现阶段的新茶饮来说，大浪淘沙，头部梯队已经形成，再投资新品牌很难有高的回报，或许像滴灌通和小数桔创投这样的生意合伙投资模式才更愿意去下定。&nbsp;</p>\n  <p>另外不得不说的是，在我们复盘今年新茶饮赛道融资时，发现一些融资消息的媒体源对原文信息做了删除处理，使其对应融资消息的真实性大打折扣。&nbsp;</p>\n  <p>总的来说，新茶饮投资当下确实不再是主流VC们的选择了，更多新品牌想要立足市场，还是需要依靠自身的努力经营。&nbsp;</p>\n  <h2><strong>潜在投资标的，打出创新的概念和形式</strong></h2>\n  <p>虽然新茶饮赛道在资本层面已然不会激起多大的浪花，但在线下这个万亿的战场，新品牌层出不穷，一些新茶饮品牌打出了创新的概念和营销方式，他们或是潜在的投资标的。&nbsp;</p>\n  <p>比如<strong>爷爷不泡茶</strong>，品牌创立于2018年，总部位于武汉，前身为“爷爷泡的茶”，取名就来自周杰伦的同名歌曲《爷爷泡的茶》。&nbsp;</p>\n  <p>起初，品牌还定位为水果鲜茶，在2022年品牌调整后更名为爷爷不泡茶，以老武汉香片茶为灵感，提供空山栀子、爷爷荔枝冰酿、咸宁桂花、武汉茉莉等东方香茶饮品。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_095499b197974078b661aebd5233d873@000000_oswg358682oswg700oswg394_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图源：爷爷不泡茶官网&nbsp;</p>\n  <p>同时，品牌开始布局全国，主要开在南方江苏、昆明、广东等地。近期爷爷不泡茶在北京开设了10家新店，进驻潮流地标处三里屯SOHO、朝阳大悦城、五道口、西直门、崇文门等核心商圈。&nbsp;</p>\n  <p>借着国庆黄金周的出游，爷爷不泡茶首次在首都和北方区域开店，试试水温。&nbsp;</p>\n  <p>在营销方式上，爷爷不泡茶也追求创新，尽力贴合年轻人，包括赞助音乐节，开启社交媒体打卡活动，邀请明星等。&nbsp;</p>\n  <p>比如在南京、上海、广州等地开店时，品牌还邀请了焉栩嘉、张颜齐等流量明星作为“明星店长”，以吸引粉丝消费。&nbsp;</p>\n  <p>想把自己打造成为“武汉名片”的爷爷不泡茶，会是下一个“茶颜悦色”吗？&nbsp;</p>\n  <p><strong>从鲜果茶到鲜奶茶再到花香茶，新茶饮的故事还在继续，但市场竞争也不断升级，</strong>除了应对产品研发挑战，叠加价格战、营销战，还要争夺门店位置，拼后端供应链的稳定，卷到全国性的头部连锁品牌几乎九死一生、九牛一毛。&nbsp;</p>\n  <p>假如换一条赛道，<strong>卷一卷地方特色的新茶饮品牌</strong>，或许还有机会卷土重来。&nbsp;</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MjQ2NzA2Mg==&amp;mid=2649616793&amp;idx=1&amp;sn=73f29c044ee94205b4d1bf1018426bd7&amp;chksm=bf52653b2ef940bbfa669261d68120a49987c493bc805438649b932defbeda79709d9d5006f1&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“IT桔子”（ID：itjuzi521）</a>，作者：吴梅梅，36氪经授权发布。</p>", "published": "2024-10-31 10:04:51", "id": "32813792-40d3-4d36-aebb-05ce39779f3d", "source": "36氪", "section": "文章资讯"}, {"title": "旷视联合创始人印奇“二次创业”押注智驾，正招兵买马中", "link": "https://36kr.com/p/3015976006218626?f=rss", "description": "<p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_395572ea7a00489984873a6d04b9d584@1883322323_oswg614820oswg1080oswg782_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p><strong>导语：此番押注自动驾驶，印奇等人或将选择与重庆合作。长安汽车、赛力斯等均为当地龙头企业。</strong></p>\n  <p>凤凰网科技独家获悉，<strong>人工智能企业旷视科技联合创始人兼CEO印奇，近日正式入局智能驾驶赛道，探索人工智能与汽车产业的结合。</strong></p>\n  <p>一位接近旷视科技的人士告诉凤凰网科技，<strong>“旷视旗下自动驾驶业务近期新招了很多人，几乎都入职在重庆那边，可以说是在持续招兵买马中”。</strong></p>\n  <p>旷视科技诞生于2011年，三个联合创始人分别为印奇、唐文斌与杨沐，三者均出自清华大学计算机科学实验班（“姚班”）， 师从“图灵奖”唯一的华裔得主、现代密码学基础的奠基人姚期智。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_2e9c36230a2540dc839a19e36f8da914@1883322323_oswg50100oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图 ｜旷视科技三位联合创始人&nbsp;</p>\n  <p>早期创业时，旷视科技就被业内评价为整个团队的实力都很强。其专注于计算机视觉与深度学习两大领域，在图像识别、人脸识别等方面有深厚积累，市场上多数手机厂商的人脸识别技术供应商几乎都是旷视。此外，其还重点布局在物联网与自动驾驶领域，探索应用智慧城市与智驾方案。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_472be4329ae9429cacf364f107b3ee25@1883322323_oswg619652oswg753oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图｜来源于网络&nbsp;</p>\n  <p>在创立后的几年时间里，旷视科技与商汤科技、依图科技以及云从科技并称为“AI四小龙”。四者也成为资本市场内炙手可热的追捧对象。</p>\n  <p>2019年，旷视在港交所正式递交IPO文件，然而在2020年，便有媒体报道旷视科技终止了港交所的IPO进程。随即在2021年3月，旷视科技转战科创板。此后在2021年12月，商汤科技在港交所正式挂牌上市，总市值约1301亿港元，但此后股价就一路下跌，目前仅剩550亿港元，以商汤为参照，旷视的上市路也走得颇为坎坷。同样在这几年时间里，已有多家企业主动撤回IPO申请，包括同为AI四小龙之一的依图科技。</p>\n  <p>据凤凰网科技了解，<strong>此番押注自动驾驶，印奇等人或将选择与重庆合作。</strong>今年1-6月，重庆汽车产量121.4万辆，汽车产量位列全国城市第一。其中，长安汽车、赛力斯等均为当地龙头企业。目前，重庆也在推进发力智能网联新能源汽车产业。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_47ae1ef94160480489dc536932ed5e3a@1883322323_oswg511953oswg700oswg451_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图｜来源于网络&nbsp;</p>\n  <p>今年7月，重庆上市车企力帆科技发布股份变动公告，称收到持股5%以上股东江河汇的控股股东吉利科技集团的通知，获悉吉利科技集团于2024年7月1���与江河顺遂签署了《股权转让协议》，吉利科技集团拟向江河顺遂转让其持有的江河汇100%股权，转让价款合计为24.3亿元。江河汇直接持有力帆科技9亿股股份，占公司总股本的19.91%。</p>\n  <p>爱企查显示，江河顺遂成立于今年7月1日，法定代表人为印奇。也就是说，<strong>印奇自今年7月起，正式成为了力帆科技的股东。</strong></p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_d5b1bb57001548e59aebfb69d9c7d0f8@1883322323_oswg51588oswg752oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">图 ｜来源于网络&nbsp;</p>\n  <p>10月25日 ，力帆科技再度召开董事会，提名印奇为公司第六届董事会非独立董事候选人，任期自股东大会审议通过之日起至本届董事会换届完成时止。</p>\n  <p>据了解，旷视智驾业务起步于2021年，旷视科技智驾业务总裁刘伟在2023年8月接受媒体采访时表示，公司智驾部门已有数百名员工，其中近三分之二是算法研发团队，剩下三分之一左右则是工程交付团队。此外，旷视自动驾驶业务此前主张走性价比路线，强调量产与规模化的辅助驾驶方案。</p>\n  <p>至此，AI四小龙或已走上截然不同的道路。今年10月，商汤董事长兼CEO徐立发布内部信，表示商汤科技致力于成为最懂算力的大模型服务商，和最懂大模型的算力服务商。随后商汤开启组织调整，一位接近商汤的人士对凤凰网科技表示，这意味着商汤的业务更聚焦了，“城市里的安防业务没什么赚钱空间了，而智驾像商汤这样的企业很难卷过车企本身，现在头部的汽车厂商都在自己布局智驾，人家有自己的落地场景可以验证调教”。</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/MSHjpm3ENKFPmd_RMAWSeQ\" rel=\"noopener noreferrer\" target=\"_blank\">“凤凰网科技”</a>，作者：董雨晴，36氪经授权发布。</p>", "published": "2024-10-31 10:00:40", "id": "b281f707-cb27-4668-9b20-c57b01c8dc49", "source": "36氪", "section": "文章资讯"}, {"title": "重庆钢铁10月31日放量上涨10.13%；重庆钢铁展现应对市场挑战的韧性", "link": "https://36kr.com/p/3016226938430981?f=rss", "description": "", "published": "2024-10-31 09:44:56", "id": "0c64fb41-8c7c-4db2-9d08-370dcc3cd9d4", "source": "36氪", "section": "文章资讯"}, {"title": "壶化股份10月31日缩量下跌0.63%；壶化股份前三季度营收与净利润双降", "link": "https://36kr.com/p/3016251973690883?f=rss", "description": "", "published": "2024-10-31 10:10:26", "id": "175325b2-0e67-4c2a-9b5d-5aebc32d32f0", "source": "36氪", "section": "文章资讯"}, {"title": "AI中的三门生意：修塔、搬砖和好奇心", "link": "https://36kr.com/p/3016233901073671?f=rss", "description": "<p>作者：吴炳见</p>\n  <p>AI中有三门生意：修塔、搬砖、和好奇心产品。</p>\n  <p>如果加一个讨论范围，那就界定是AI中的2C产品好了。三门生意对应三种不同体量的投入，也对应了三种收益。</p>\n  <p><strong>修塔就是平台型产品，需要花巨大的成本把塔修起来，把用户圈在塔里</strong>，这个 super App 的塔一旦修成，能把用户圈住十年、二十年，相对稳固。</p>\n  <p>修塔的生意注定稀少，比如微信、抖音、快手、美团、小红书，每个时代能称之为修塔的产品也就十多个，是经过严峻竞争筛选出来的生意。</p>\n  <p>这类产品是国民级产品，可能几千万日活是基本的，用户留存率极高。这类生意通常有垄断属性，商业模式上有很强的定价权。<strong>只要用户留在这里，就会源源不断生出钱来，这是LTV的生意</strong>(Life Time Value，客户终生价值)。因为LTV够大，CAC再贵也划得来（Customer Acquisition Cost，客户获取成本），所以修塔的玩家不算小账，算大账。</p>\n  <p>理解了修塔，就能理解搬砖了。</p>\n  <p><strong>搬砖比修塔容易很多，上来就能搬，搬了就能赚钱</strong>，不垄断，很多人都可以做搬砖生意。比如我基于大模型做了一款小游戏，需要向抖音和微信购买用户，引导用户玩游戏、在游戏里付费，如果长期留存率不是显著的高，这就是搬砖的生意，也可以简单理解成流量生意。</p>\n  <p>在这类产品里，用户或许会留存数月，但很难留存数年，大多数情况下是没有高复购率的。这类生意很难奢求 LTV，而要看 ROI（Return On Investment）。</p>\n  <p><strong>搬砖生意的本质是 ROI</strong>，我买一个用户多少钱，这是 I，这个用户过来后我收多少钱，这是 R，ROI必须大于1，不然就是赔钱买卖。中间的利润就是我的搬砖辛苦费<strong>。</strong></p>\n  <p>搬砖的人有很多，总有高手能做成了搬砖第一名，年净利润几亿、甚至几十亿。但都苦于一个事，每搬一块砖，就需要向修塔者纳税，剩下多少利润，取决于搬砖税多少。</p>\n  <p><strong>什么是好奇心产品？约等于现象级产品，激发了用户的好奇心，用户但很愿意尝鲜试用</strong>，但未必长期用。最典型的代表是Midjourney，起来快，但流量流失也快，现在的流量比去年同期已经下降了四成。</p>\n  <p>好奇心是最好的拉新方式，对于这类产品，我们更应该看他有多炸，用户来的有多猛，至于长期留存可能是过分的奢求了。谁是第一个推出的，谁将吸引最多的注意力，Sora是第一个发出惊艳demo的视频模型，可灵是第一个可用的视频模型，都吸引了很多注意力，大V会为此狂发twitter，这些twitter又成为新闻素材，这些新闻又吸引了更多用户前来观光。</p>\n  <p>用户来体验AI中的好奇心产品，就是在追模型的进展，观光团在体验完产品后通常都会发一条朋友圈，产品的效果越新奇，用户越有动力发朋友圈，通过朋友圈吸引来的新用户越多。</p>\n  <p>无论是做修塔、搬砖、还是好奇心产品，只要认清自己是什么，大家都有光明的前途。<strong>实际创业中的痛苦，往往来自于错配！</strong>明明做的是搬砖的生意，非要认为自己做的是修塔的生意，付出修塔的成本，赚着搬砖的钱，怎么算都算不平。</p>\n  <p>这三门生意的目标是不一样的。</p>\n  <p><strong>对修塔来说，创业团队的大部分收益来自股权</strong>，短期的盈利并不重要，只要建塔成功，盈利是迟早的事，二级市场会给一个合理的 PE，通常 PE 在 20 以上是轻松的事情，市值通常在百亿美金以上。创始人和高管的收益大都来自股权的变现，这是投资人最喜闻乐见的方式了。</p>\n  <p><strong>对搬砖来说，大部分收益自利润分红，少部分来自股权收益</strong>。这里有个巨大的陷阱，很多时候，创始人会看砖成塔，错以为自己在做修塔的生意，会投入巨大的成本，组超大型团队，来做一个本质是搬砖的生意，这导致这门生意迟迟难盈利，自然也就谈不上分红。</p>\n  <p>又因为融了巨额的钱，引入了太多投资人，签定了合格 IPO 的时间，只能华山一条路去冲IPO。但二级市场极为理性，这类生意不易获得高 PE，这时创始人才会意识到，与其赚股权的钱，不如踏踏实实赚利润分红。</p>\n  <p>这种陷阱比比皆是，原因很多，很多人并没有修塔和搬砖的意识，听到的都是字节的创业故事，宏大叙事想的多，生意想的少，自然就朝着修塔去了。即便有意识，但创始人太有梦想，愿力太强了，一不小心自己把自己忽悠了，看砖像塔。也可能因为创业之初缺本钱，就融了VC的钱，遇到资本市场行情好，就一路融了很多轮。有时是因为市场出现了资产荒，投资人硬把搬砖的生意炒成了修塔的生意。</p>\n  <p><strong>好奇心生意就比较简单了，第一步根本不用考虑赚钱，就是赚注意力</strong>，“爆”是唯一的短期目标，爆了后，就意味着获客成本几乎为零，不用走“买用户”这条路，也就不用向修塔者纳税了。至于长期留存，那是后面要考虑的事了。</p>\n  <p>AI中好奇心产品的玩法，已经有几个标准范式了，比如从 Midjourney开始，到 Pika，到Viggle，都是把模型接入 discord，利用 discord快速完成冷启动，吸引到百万千万量级的用户。这种产品通常需要一些技术创新，能实现之前无法实现的效果。或者需要一些产品形态的大创新，越奇越好。这才会吸引好奇心群众来围观，一旦爆了后，媒体会自发的评测，用户会在朋友圈里自发晒体验。</p>\n  <p>好奇心产品很适合技术导向和融资导向的项目，技术足够领先，可以交付一个很炸的好奇心产品，投石问路。成为现象级产品后，总有投资人会看到其中潜力，追加投资支持做一个完整产品。</p>\n  <p>技术、好奇心产品、融资，这三者是自洽的。</p>\n  <p>我们泾渭分明的讨论了修塔、搬砖、好奇心产品，这只是个思考框架，<strong>实际创业中，未必这么清晰</strong>。</p>\n  <p>比如一款产品稳定在 100 万日活，长期留存率很高，但无法扩大用户群，这是修塔还是搬砖呢？</p>\n  <p>比如先做了个内涵段子，再做今日头条和抖音，这是不是先搬砖，再修塔呢？</p>\n  <p>比如Midjourney，他的用户中肯定有相当比例的好奇心用户了，但也有每天都用、把Midjourney融到业务流程中的忠实用户，那他是修塔、还是好奇心产品呢？</p>\n  <p>可能还是要根据数字来定性，有多少好奇心用户，有多少忠实用户。</p>\n  <p>现在还处于AI行业的极早期，搬砖生意和好奇心产品多一些，塔还不多。分清修塔、搬砖、好奇心产品，可能最大的好处是，让我们不再纠结，<strong>不再既要又要还要，做什么样的生意，付什么样的代价</strong>。</p>\n  <p>So，你是在做修塔、搬砖、还是好奇心产品？</p>\n  <p>作者介绍：吴炳见，心资本Soul Capital合伙人，前某大厂mobile产品经理+战略分析，之前就职于险峰和联想之星。参与投资过多个大模型和AI应用项目。关键词LLM、AI Native、AI infra、Robotics。</p>\n  <p class=\"editor-note\">本文来自微信公众号<a href=\"https://mp.weixin.qq.com/s/lAhJIOtExX87W1WFNrmV9w\" rel=\"noopener noreferrer\" target=\"_blank\">“AI大航海”</a>，作者：吴炳见，36氪经授权发布。</p>", "published": "2024-10-31 09:53:07", "id": "b932f36f-ce7d-42dc-8875-02984c6b1886", "source": "36氪", "section": "文章资讯"}, {"title": "三花智控10月31日放量下跌3.36%；三花智控拟境外发行H股", "link": "https://36kr.com/p/3016242031912455?f=rss", "description": "", "published": "2024-10-31 10:00:20", "id": "403570a0-1168-4681-b956-0532d534f374", "source": "36氪", "section": "文章资讯"}, {"title": "当一辆智能汽车有了「直觉」，会发生什么？", "link": "https://36kr.com/p/3011983733961600?f=rss", "description": "<p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241029/v2_0c7938bb83a043328fe7b8e3d9cf5fcc@6129457_oswg1803888oswg4032oswg3024_img_jpg?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">头图来源：智己官方</p>\n  <p>作为大自然赋予人类的生存密码，「直觉」往往可以在某些微妙瞬间帮助我们提前感知危险，甚至是化险为夷。&nbsp;</p>\n  <p>这种能力的背后是，人类在亿万年来经历了无穷无尽的危急场景锤炼，再基于对过往经验的强化记忆以及持续思考，进化出来的无意识的信息处理过程。&nbsp;</p>\n  <p>眼下，智能汽车的发展正在模仿人类的驾驶行为以及思考方式。&nbsp;</p>\n  <p>譬如在应对黄金800ms处理加塞、大车智慧躲避等典型场景；或是进一步应对插空变道、加减速变道等复杂场景上。&nbsp;</p>\n  <p>智己汽车已经率先进入Next Level：&nbsp;</p>\n  <p>今天，智己汽车举办「直觉·新时代」智能驾驶技术发布日，宣布IM AD 3.0已经具备了基于人工智能的直觉能力。因此，即便面对未知障碍，IM AD 3.0也可以实现以本能反应为主导、省时果断的快思考。&nbsp;</p>\n  <p>实际上，IM AD 3.0的直觉能力得益于智己汽车研发的量产一段式端到端智驾大模型。&nbsp;</p>\n  <p>在端到端大模型的支持下，智己汽车已进化出无图城市NOA全国全系可开的能力，IM AD在德、法等欧洲国家也能驾驶流畅、安全。&nbsp;</p>\n  <p>当市场上绝大部分主流汽车产品还在「模仿人类」的时候，当端到端大模型的一段式/两段式路线之争不绝于耳的时候，智己汽车的智驾技术已经实现了断代式进化。&nbsp;</p>\n  <h2><strong>在正确的赛道狂奔、领先</strong></h2>\n  <p>人类大脑的直觉，犹如一套精密算法，基于经验持续进化而来。&nbsp;</p>\n  <p>实际上，智能汽车的大脑也一样。&nbsp;</p>\n  <p>对于早期的智能汽车而言，受限于智能化技术程度以及软硬件性能，汽车行业玩家的普遍做法是，将车辆可能遇到的道路场景预先定义，然后将对应的代码写进智驾系统里。&nbsp;</p>\n  <p>例如，研发人员人为汽车输入「水坑」场景的定义，并使用大量数据训练感知模型来识别水坑、再训练规划模型绕开水坑。&nbsp;</p>\n  <p>然而，真实世界的场景是无穷无尽的。如果车辆遇到新出现的场景，则需要研发人员持续更新算法规则。这样不仅效率低，还容易出错。&nbsp;</p>\n  <p>端到端大模型技术的兴起，改变了这样的局面。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241029/v2_47bf8e4de67e424883f2ef80f55e78cd@6129457_oswg34526oswg1080oswg359_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">来源：智己官方&nbsp;</p>\n  <p>基于过往积累的海量行车场景信息以及仿真测试数据，智己汽车的IM AD智驾大模型已经能够如同人类驾驶员一般，凭直觉预判并处理突发状况。&nbsp;</p>\n  <p>而且，通过模拟人类的直觉与思考，高阶智驾系统不仅可以直接「看路开车」，在面对人车混行、高峰期拥堵等特殊场景时也能处理得当。&nbsp;</p>\n  <p>作为行业内为屈指可数的「全国无图NOA」品牌之一，智己汽车在高阶智驾方面真正实现了全场景可用。&nbsp;</p>\n  <p>地区方面，IM AD 3.0能够摆脱对高精地图的依赖，从容应对各种长尾场景，比如无保护左转博弈、礼让盲区横穿。无论是在国内，还是在德、法等海外国家，都能纵享丝滑。&nbsp;</p>\n  <p>智己汽车之所以能做到如此成绩，很大程度上离不开其对一段式端到端大模型技术路线的坚定选择。&nbsp;</p>\n  <p>现阶段，智能汽车玩家对端到端大模型的研发主要分为两派，即一段式和两段式。&nbsp;</p>\n  <p>我们可以这么来理解：&nbsp;</p>\n  <p>l 一段式方案将传统智驾系统的感知、规划、决策等多个环节融合到一个大模型之中，当外部信息通过传感器输入至系统，大模型可以快速地给输出决策，帮助车辆进行下一步动作；&nbsp;</p>\n  <p>l 两段式方案通常由感知模型和规控模型两个部分组成，外部信息的处理步骤是，经过感知模型过滤，再传输到规控模型进行计算和决策输出。&nbsp;</p>\n  <p>相比起两段式方案，智己汽车所拥趸的一段式方案决策链路更短、效率更高、对场景的理解更全面。即便遇到未定义的物体时，智驾大模型也可以学习和应对这一场景，成功绕开障碍物。&nbsp;</p>\n  <p>这一技术突破了感知模型的局限性，实现了更加智能的路径规划和驾驶决策，为用户带来更优异的使用体验。&nbsp;</p>\n  <h2><strong>技术创新，断代进化的基石</strong></h2>\n  <p>如前所言，一段式端到端大模型技术路线虽好，但想要将它的效果做到极致也并非易事。这项技术对数据规模以及数据质量的要求非常高。&nbsp;</p>\n  <p>对于智驾大模型而言，数据量越大，能力提升就越快；学习场景越多元化，路径规划就越准确。&nbsp;</p>\n  <p>但是基于多年的发展，当下智能驾驶车辆已经能够处理绝大部分常见的道路场景，高价值的Corner Case数据可遇不可求。&nbsp;</p>\n  <p>另外，大模型还会学习人类驾驶员的驾驶行为，一旦某一种驾驶风格的样本量过大，就可能影响整个智驾系统的效果。&nbsp;</p>\n  <p>因此，怎么在保证数据数量的同时控制数据质量，就成为了一段式端到端技术路线玩家必须解决的问题。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241029/v2_60c8a1a9c3cb4a77807d35ab78581f43@6129457_oswg52468oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">来源：智己官方&nbsp;</p>\n  <p>跻身智能驾驶第一梯队的智己汽车给出的创新思考是——行业首创「长短期记忆」结合模式，学习人脑「直觉推理+逻辑分析」的问题处理方式。&nbsp;</p>\n  <p>简单来说就是，将智驾大模型的数据处理分为短期记忆和长期记忆两条支路。&nbsp;</p>\n  <p>短期记忆的目的在于快速验证算法有效性以及评估数据质量，训练周期以天计算；&nbsp;</p>\n  <p>长期记忆则是将筛选过后的优质数据以人脑类似的记忆原理进行积累，应用于端到端大模型。&nbsp;</p>\n  <p>长短期记忆的支路同时也对应着「快」和「慢」两个系统。&nbsp;</p>\n  <p>快系统即直觉推理，善于直觉与经验快速处理问题，形成决策。慢系统即逻辑分析，通过端到端大模型中的安全逻辑网，增强智驾系统的决策安全性。&nbsp;</p>\n  <p>直觉与安全逻辑模型共同赋能智己IM AD，使其达到最为理想的平衡状态。&nbsp;</p>\n  <p>这样一来，不但数据质量有了保证，也减少了不必要的数据处理成本，训练成本常规方式小10到100倍，而智驾系统的安全性则超人类驾驶员10倍以上。&nbsp;</p>\n  <p>至于数据规模，智己汽车已经积累了亿级别的事件优质数据。通过海量数据的积累和自动化闭环数据链路的驱动，IM AD数据飞轮不断迭代，反哺用户体验。&nbsp;</p>\n  <p>除了软件能力，硬件在IM AD架构中也起到至关重要的作用。&nbsp;</p>\n  <p>据介绍，智己汽车是当下汽车行业唯二完成Xavier/Orin高低算力双平台的自研玩家，最大化激发硬件的潜能。比如，通过不断的模型优化，智驾大模型的运行效率能够提升500%，算力需求降低90%。&nbsp;</p>\n  <p>因此，软硬结合之下，IM AD才能做到仅需单激光雷达和单OrinX，实现「全球都能开」的无图NOA。&nbsp;</p>\n  <p>智己汽车也由此成为领跑行业的全球首批量产一段式端到端大模型的品牌。&nbsp;</p>\n  <h2><strong>十年磨一剑，出鞘必惊人</strong></h2>\n  <p>根据智己汽车的调研数据，IM AD智驾安全水平已达到人类驾驶的6.7倍；常用IM AD智驾功能的用户，安全行驶里程比常规用户提升了3.1倍。&nbsp;</p>\n  <p>与此同时，智己汽车的智驾合规道路测试里程超10万公里、仿真道路测试里程超150万公里、算法开发测试里程超250万公里、安全场景仿真近9.5万例。&nbsp;</p>\n  <p>从结果来看的话，智己汽车正在朝着其完全自动驾驶的终极愿景大步迈进，IM AD也是为此而生的。&nbsp;</p>\n  <p>2014年，上汽前瞻团队开始对前沿的智驾领域展开调研，并在三年内决定设立上汽人工智能实验室，对深度学习进行全面布局。&nbsp;</p>\n  <p>在过去的这十年里，上汽从未停止对智能驾驶技术研发以及商业落地的探索，包括催化了智能驾驶第一梯队成员智己汽车的诞生。&nbsp;</p>\n  <p>为了保证技术迭代的连续性、以及通过不同级别的智能驾驶技术为用户提供多维服务，智己L2、L3、L4共享一段式端到端大模型，只需根据不同级别的智驾需求增减硬件即可。&nbsp;</p>\n  <p>基于同源开发架构，上述三者之间可形成牢固的互补关系。&nbsp;</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241029/v2_a67cfd1fe02a4d93b1160b33e5e1b60c@6129457_oswg81936oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p class=\"img-desc\">来源：智己官方&nbsp;</p>\n  <p>通过L2级别大量的工程实践、数据获取及训练，反哺L3、L4级别的技术迭代；同时，L3、L4级别的技术研发成果，又能进一步赋能于L2场景，实现更安全、舒适的智驾体验。&nbsp;</p>\n  <p>如今正值十年的关键节点，智己汽车也交上了一份亮眼的智驾答卷，成为了全国首个同时具备L2、L3、L4智能驾驶量产能力的品牌。&nbsp;</p>\n  <p>比如前文提到的，今年10月，“IM AD 3.0 无图NOA”全国开通，推送全系车型。&nbsp;</p>\n  <p>再比如，今年7月，智己汽车拿下中国首批L3自动驾驶上路通行试点名单，顺利开启L3级自动驾驶道路测试；目前，华为小鹏等玩家尚不在名单之中。&nbsp;</p>\n  <p>智己汽车计划，今年之内获得L4级无驾驶人道路测试牌照；到2026年，正式具备L3级自动驾驶方案量产条件。&nbsp;</p>\n  <p>可以预见的是，随着L3/L4高级自动驾驶的落地和推进，智己汽车的L2量产智能驾驶在未来几年内还会迎来新一轮能力提升。&nbsp;</p>\n  <p>在智己汽车的看来，智能驾驶将遵循摩尔定律，软件体验呈现出指数级提升，两年提升10倍、四年提升100倍。&nbsp;</p>\n  <p>他们的决心是，让所有智己用户的智驾体验领先一代。&nbsp;</p>", "published": "2024-10-31 09:26:00", "id": "ff0c3db3-bc53-4b53-9f73-22e44462b790", "source": "36氪", "section": "文章资讯"}, {"title": "万达电影10月31日缩量上涨1.86%；万达电影探索影院经营新模式", "link": "https://36kr.com/p/3016207222613257?f=rss", "description": "", "published": "2024-10-31 09:24:55", "id": "545fd7f6-a617-444e-a899-bedc65dab800", "source": "36氪", "section": "文章资讯"}, {"title": "中信证券10月31日放量上涨2.4%；中信证券助力新铝时代成功登陆创业板", "link": "https://36kr.com/p/3016205543532037?f=rss", "description": "", "published": "2024-10-31 09:23:22", "id": "7b43170d-788f-4933-8fc3-43b2092ee808", "source": "36氪", "section": "文章资讯"}, {"title": "飞书上浮，钉钉下沉", "link": "https://36kr.com/p/3016146270905603?f=rss", "description": "<p>中国的to B软件发展缓慢，很大一个原因是中国企业分布是头部很大，尾部很多，但腰部企业很少。</p>\n  <p>王慧文在多年前对企服市场的判断有如一道魔咒，要求大多数企服企业必须上浮或是下沉，才能定位到足量的客群与市场，从而有针对性地开发产品。</p>\n  <p>仅协同办公三巨头来看，除了背靠微信私域护城河的企微外，钉钉与飞书的路径均在相似中走向了分化。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_226996181f33493393cdade60d1f0463@000000_oswg137865oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>相似的是，两者均在死磕AI的路上，将低代码作为底层重要的落地载体。钉钉布道低代码多年，本就是钉钉开放生态中的底层设计；反观飞书，其明星产品多维表格本身就是低代码的一种落地形式，而亮相于今年飞书大会的多维表格数据库与低代码平台则可被视作是AI+低代码的进一步落地实践。</p>\n  <p>不同的是，一贯奉行开放生态的钉钉兜售能力，或主动或被动地“选择”下沉，在普惠的道路上一骑绝尘；而从未放弃all in one的飞书兜售工具，不可避免地上浮，试图以极致工具提效来做高客单价。</p>\n  <p>这一点，我们自两者不同的定价模型中可窥一二：钉钉按组织收费，而飞书则是按人头计算。以基础付费为例，200人的组织便是分水岭。</p>\n  <p>愈发明晰的路径分野，指向了钉钉与飞书各自的“舒适区”。</p>\n  <h2><strong>PaaS让步aPaaS？</strong></h2>\n  <p>大厂做to B都是有基因的，马云那句“让天下没有难做的生意”，催生了堪称最成功的“PaaS生态”淘宝，这也一定程度上推动钉钉成为时下用户最多的协同办公产品。</p>\n  <p>海量的用户分属不同群体，对应着的是极为复杂的落地场景，这意味着打造一个满足所有人的通用产品基本不可能。另一方面，作为协同办公龙头，钉钉是为这个市场做出完整用户教育的先行者，在投资人眼中，它同样承载着这个市场想象空间的上限。</p>\n  <p>“如果中国企业更愿意为办公软件付钱的话，必然发生的变化是钉钉一定更赚钱。”按照这个逻辑，规模化成为钉钉故事里的主线，底座定位与开放生态亦由此衍生。与其自己越做越重，不如开放生态让合作伙伴一起做大做强。</p>\n  <p>钉钉的低代码也是该逻辑下的产物：既然无法满足企业组织的精细化需求，那就打造一个通用的低代码平台，有什么业务需求，需要什么业务逻辑，“让他们自己搞”。</p>\n  <p>在这个“剧本”中，钉钉只需要不断扩大生态做一个流量入口，安心等待国内企业付费意愿增长。不过在这一过程中，钉钉与合作伙伴逐渐从合作走向了“竞合”。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_befd20f59b6e4295a03bfd0419b59a28@000000_oswg188288oswg660oswg330_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>在钉钉这个基座之上，低代码平台（aPaaS）“宜搭”是第二层，而“酷应用”（PaaS生态应用）则是第三层。当宜搭在开发侧的门槛足够低，且企业自主搭建的内部应用足够满足基础数字化需求之后，可能会对应用市场的生态造成挤压。</p>\n  <p>通常来说，钉钉PaaS生态内的合作伙伴如北极星与e签宝等，在钉钉应用分发平台上发布的产品一般是入门级别的标准款。这些应用大多年费一万元上下，即使只面向OKR、CRM等套件级别的类目或某条垂直赛道，其精细化程度依旧有限，甚至可以说是吸引企业主进一步按项目付费的“试用版”。</p>\n  <p>而企业自主通过宜搭搭建的内部应用可以起到“平替”的作用。由于自主搭建这一过程与定制化无二，低代码应用甚至会相对更适配企业本身。随着低代码的AI化，无论是自开发侧将AI能力更顺畅地输出自台前，或是通过AI识别逻辑等面向无经验开发者的功能，都进一步放大了低代码可触达的空间。</p>\n  <p>另一方面，低代码本身不过是购买钉钉专属版的“附加产品”，9800元的年费几乎就是企业唯一的软件支出。</p>\n  <p>自ROI的角度来看，使用宜搭自建应用相对更有“性价比”。</p>\n  <p>不受限地使用低代码以及随之而来的数据存储、流转等能力，是钉钉撬动渴望数字化转型的海量中小企业的重要杠杆。但这也带出了一个新问题：低代码与生态之间的关系该如何处理？</p>\n  <p>目前来看，钉钉的解法是与生态伙伴共同开发开箱即用的原子化套件，为生态伙伴增加创收渠道和露出机会。</p>\n  <p>比较典型的是钉钉协同套件，作为生态底座自己的开箱即用工具，据官方今年6月在生态大会上放出的消息，包括北极星、e签宝、Moka在内的生态伙伴在钉钉套件的合作收入已接近1亿元。</p>\n  <p>另一方面，钉钉也在生态的基础上不断巩固开放性。以电商行业为例，国内头部电商平台均向钉钉开放了数据接口，其便可以作为数据汇总与处理的中台。而不同电商生态的企服工具也能自其中找到变现空间。</p>\n  <p>PaaS与开放生态并非易事，因为生态伙伴的渠道权重会随着平台商业化的脚步而不断变化。公约数越做越大的同时，钉钉也需要思考该怎么把好这根平衡木。</p>\n  <h2><strong>认清现实</strong></h2>\n  <p>大厂的to B基因论放到飞书上同样适用，不过出于赛道的特殊性，飞书在继承了部分字节的基因的同时，还在极力对抗其中的某些东西。</p>\n  <p>字节的核心是效率，从头条、内涵段子到抖音、西瓜视频和番茄小说，本质上都是信息流的变体。而这“吸引人眼球”的生意，都遵循相似的商业模式——提升获客+留存（时长+频次）的效率，便足以一定程度上构建信息的入口效应，掌握分发权。</p>\n  <p>至此，字节商业化需要做的只有尽可能提高单位时间内的变现效率。无论是商业化的前置链路还是本身，极致效率都是其追求的至高目标。这一点延伸到飞书上，具体呈现为我们所看到的多维表格、People、仪表盘等产品，但是to B却是南辕北辙的一套逻辑。</p>\n  <p>流量与算法的不适用，以及老生常谈的以to C思维做to B都是飞书需要对抗的。此外，更大的问题或许在于其在产品上的过度投入，与产品变现效率的倒挂。</p>\n  <p>于外部来看，中小企业用人成本偏低，而边际亦不明显，这意味着飞书在其之上的变现效率并不高。为了匹配飞书all in one式产品的开发维护强度，提高客单价成为飞书最后不得不走的“独木桥”。</p>\n  <p>试问一下，按飞书最新发布的产品来看，什么规格的企业用得上单表容量突破100万行的多维表格，或是可以统计1000万行数据的仪表盘？</p>\n  <p>更进一步说，在飞书的产品矩阵中，原子化的套件工具是其输出效率的核心。在AI的重构下，前述其亮眼的产品表现也是集成了包括月之暗面、智谱AI等明星创企的能力。例如新多维表格的“字段捷径”功能，便是通过封装AI来批量操作表格中的结构化数据。</p>\n  <p>当集成的工具已经达到一定整合程度，其他内部应用就愈发显得多余——客户需要按飞书的逻辑开展业务，而低代码平台不过是开放给少数客户“打补丁”的工具。反观钉钉则视低代码为抓手和底座，更大的权限留在客户手上，AI相对更偏向于“打辅助”的定位。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_6029491573a0499fa28e24020142b52a@000000_oswg407229oswg719oswg551_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>如此一来，变现效率低的中小企业组织很“自然”地被飞书所抛弃。我们了解到，东南地区一家约200人的销售组织，其每年在飞书上的开销就达到了20万。而另一家千人规模的SaaS企业，飞书年费高达200万，占据公司现金流的五分之一。</p>\n  <p>按舶来的概念做定义的话，飞书的增长逻辑被迫从相对纯粹的PLG（产品驱动）演变为PLG+SLG（销售驱动）。不过，正如此前提到的基因冲突，飞书既无法在内部负担庞杂的销售组织，也未能打造成熟的层级代理体系。</p>\n  <p>一位曾与飞书有过接触的集成商告诉光子星球，飞书的代理体系一度不够清晰，还出现过内部直销和代理“抢食”的情况：“基本上直销接触过的客户，我们很难拿到返点”。</p>\n  <p>此外，飞书对集成商的组织亦有要求，除少数一线城市，难有集成商能满足飞书需求的售前组织规模。</p>\n  <p>幸运的是，作为字节落地自身理念的“工具”，飞书的增长还有字节背书的助力。一位接近飞书人士表示，飞书囿于自身的定位，做KA的决心相比另外两家友商更大。另一方面，字节的高速增长也让KA客群产生了一定FOMO心态。这让飞书成为2020~2022年间啃下相当多KA，收入规模上一度成为三家之首。</p>\n  <p>“（高客单价下）客户不会轻易迁移，你稍微涨涨价他也能接受，这就保证了稳定的收入。”</p>\n  <p>在明晰自身定位以及战略性放弃中小组织后，飞书果断发起裁员，自负盈亏似乎也近在眼前。在KA战略下一路狂奔的飞书，守着很大但很少的头部，离腰尾部好像更远了。</p>\n  <h2><strong>找到新故事</strong></h2>\n  <p>上浮与下沉既是战略，也是钉钉与飞书在企服市场寻求增长的必然。但这并不意味着其完全放弃在优势领域之外的增长机会。</p>\n  <p>正如我们看到时下越来越臃肿的Super App，当一个产品做到规模化后，产品本身是无法收敛的。于是我们能看到飞书在积极开放生态，而钉钉也在持续推出原子化的套件。</p>\n  <p>不过这些动作的意义更多在于“覆盖”，随着AI潜移默化地改变我们生活的方方面面，由AI赋能的个人成为协同巨头新一轮财富分配的机会。</p>\n  <p>众所周知，早在AI浪潮前，钉钉文档的前身Wolai与飞书文档便早已是许多内容生产者与数字游民的心头好。这足以证明移动互联网时代下，个体与组织具备相似的对效率的追求。</p>\n  <p>随着协同巨头在OA基础上的扩张，这些原“属于”个体的效率应用也在市场作用下为其所鲸吞。这并不意味着个体对效率的需求就此消弭，反倒是个体先于企业一步感受并接纳了AI带来的生产力革命。</p>\n  <p>微软和 LinkedIn 此前发布的 2024 年工作趋势指数年度报告指出，有 78% 的精通 AI 的员工，在未经雇主许可或是在雇主不知情的情况下使用了AI。个体的敏捷性决定了其必然会先于组织拥抱技术革命，甚至产品在海量个体的使用中，其边界还能得到更有有效的拓展。</p>\n  <p class=\"image-wrapper\"><img src=\"https://img.36krcdn.com/hsossms/20241031/v2_cb003aec4d014e20be2437ffbf0b54f8@000000_oswg86180oswg1080oswg593_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1\" /></p>\n  <p>学者吴晨在一次小规模分享中也提到，AI时代不一定诞生超级巨头，但一定会催生超级个体。正如开源社区对AI发展的推动一般，个体相对企业也是更敏捷的反馈体系建立者。</p>\n  <p>甚至在商业模式上，我们也能找到路径相似的先行者。据WPS的母公司金山办公2023年报，其2023年收入45亿，其中订阅收入36亿，净利润13亿。</p>\n  <p>做个体，或者说to P（professional ）的生意，飞书的产品本身便存在一定优势。不过自布局上看，钉钉却是两家中的先行者。据悉，钉钉最新推出的钉钉365会员便是针对这个市场的订阅制付费产品，集成了包括AI助理、AI搜索以及包括自动回复在内的更为个性化的设置。</p>\n  <p>此外 ，协同办公的新变化，还很可能发生在出海与国内企业新旧交替的这一轮重新分配上。数月前钉钉出海，以及其与飞书围绕具身智能、AI创企等新兴市场的客户争夺，便是产品之外的拉锯战。</p>\n  <p>随着钉钉与飞书这两家公司的战略与路径愈发明晰，僵持的格局也开始有了被打破的可能。这为更有可能打破僵局的AI，争取了“发育时间”。</p>\n  <p>本文来自微信公众号 <a href=\"https://mp.weixin.qq.com/s?__biz=MzA4MjUxODMwMg==&amp;mid=2649660082&amp;idx=1&amp;sn=a5dc2f07bd5a3e32cf964bced8d09908&amp;chksm=86fceb365114d0279fb914ed90d2abe8de2fb76eda7de3e46259c4fa79b12d8c119472ab308a&amp;scene=0&amp;xtrack=1#rd\" rel=\"noopener noreferrer\" target=\"_blank\">“guangzi0088”（ID：TMTweb）</a>，作者：吴坤谚，36氪经授权发布。</p>", "published": "2024-10-31 09:22:31", "id": "4ada10e3-5346-4b2d-ac95-2acf24451e05", "source": "36氪", "section": "文章资讯"}, {"title": "中金公司10月31日放量上涨0.11%；中金公司因保荐业务未勤勉尽责被证监会重罚", "link": "https://36kr.com/p/3016202520454403?f=rss", "description": "", "published": "2024-10-31 09:20:15", "id": "8dbec045-d80d-4c70-86d8-2b4ab209000d", "source": "36氪", "section": "文章资讯"}, {"title": "姚明不再担任篮协主席", "link": "https://36kr.com/newsflashes/3016240819971586?f=rss", "description": "10月31日，第十届中国篮球协会会员代表大会执行委员会在北京举行会议，审议通过姚明辞去中国篮球协会主席职务的申请，选举郭振明为新一任中国篮球协会主席。 ​​​（央视新闻）", "published": "2024-10-31 09:58:49", "id": "5c7f0749-2f48-4b7c-835e-cc5a85785387", "source": "36氪", "section": "最新快讯"}, {"title": "光大证券：获准发行不超150亿元短期公司债券", "link": "https://36kr.com/newsflashes/3016213135697414?f=rss", "description": "36氪获悉，光大证券公告，公司近日收到中国证券监督管理委员会《关于同意光大证券股份有限公司向专业投资者公开发行短期公司债券注册的批复》，批复内容包括同意公司向专业投资者公开发行短期公司债券，面值余额不超过150亿元。", "published": "2024-10-31 09:30:40", "id": "ec766213-829a-4dd6-958a-c6ce21e105ee", "source": "36氪", "section": "最新快讯"}, {"title": "3连板三房巷：日常经营情况正常，内外部经营环境未发生重大变化", "link": "https://36kr.com/newsflashes/3016203256161794?f=rss", "description": "36氪获悉，三房巷日公告，公司股票于2024年10月28日、29日、30日连续3个交易日内日收盘价格涨幅偏离值累计超过20%，属于股票交易异常波动情形。2024年10月31日，公司股票再次涨停。公司的主营业务为瓶级聚酯切片、PTA的生产与销售。经公司自查，公司目前日常经营情况正常，内外部经营环境未发生重大变化，不存在应披露未披露的重大信息。", "published": "2024-10-31 09:20:37", "id": "157598c4-ae21-4475-9901-162f511f4916", "source": "36氪", "section": "最新快讯"}, {"title": "Stellantis集团第三季度净营收同比下滑27%", "link": "https://36kr.com/newsflashes/3016230052505090?f=rss", "description": "10月31日，Stellantis集团发布财报显示，第三季度实现净营收33亿欧元，同比下滑27%，这主要是由于出货量的减少、不利的结构差以及产品定价和外汇所带来的影响。第三季度，集团不含旗下合资企业的出货量为114.8万台，同比下滑20%。集团重申于9月30日更新的2024年度全年财务业绩预期：调整后经营利润率为5.5%至7.0%，工业自由现金流为负50亿欧元至负100亿欧元。（界面）", "published": "2024-10-31 09:47:52", "id": "9cf152f4-0c14-43b4-8f2b-984002582622", "source": "36氪", "section": "最新快讯"}, {"title": "众鑫股份：美国商务部对公司产品发起反倾销、反补贴调查", "link": "https://36kr.com/newsflashes/3016228996195846?f=rss", "description": "36氪获悉，众鑫股份公告，美国商务部于美国时间2024年10月29日发布公告，对原产自中国、越南的热成型模塑纤维产品正式发起反倾销、反补贴调查。公司出口至美国的热成型模塑纤维产品的销售金额占公司当期总收入的比例较高。公司已成立专项工作组，并聘请专业律师团队积极应对本次“双反调查”，同时加快泰国工厂的建设进度，力争在2025年一季度正式投产，以承接美国客户的订单。", "published": "2024-10-31 09:46:48", "id": "ca04e9d3-c619-4905-8f00-981bccb6e7c0", "source": "36氪", "section": "最新快讯"}, {"title": "6连板申华控股：近三年一期营业毛利率呈现下滑状态", "link": "https://36kr.com/newsflashes/3016242155250946?f=rss", "description": "36氪获悉，申华控股公告，公司股票自2024年10月24日以来连续6个交易日累计涨幅达79.22%，短期涨幅高于同期上证指数，存在市场情绪过热的情形。公司近期日常经营情况及外部环境未发生重大变化。公司近两年一期经营业绩亏损，2022年度、2023年度、2024年1-9月归属于上市公司股东的净利润分别为-1.73亿元，-1.99亿元、-5623.83万元。公司近三年一期营业毛利率呈现下滑状态，分别为10.09%、7.08%、6.96%、6.33%。", "published": "2024-10-31 10:00:11", "id": "794a3c11-15c2-4147-a715-c40f7a0f8d95", "source": "36氪", "section": "最新快讯"}, {"title": "农业银行：张旭光辞去公司执行董事、副行长等职务", "link": "https://36kr.com/newsflashes/3016236316255490?f=rss", "description": "36氪获悉，农业银行公告 ，因到龄退休，张旭光请求辞去公司执行董事、副行长及董事会战略规划与可持续发展委员会、风险管理与消费者权益保护委员会兼美国区域机构风险委员会委员职务。张旭光的辞职信于2024年10月31日送达公司董事会并生效。", "published": "2024-10-31 09:54:14", "id": "993dc13f-757f-4fa8-b80a-06d6d7da822a", "source": "36氪", "section": "最新快讯"}, {"title": "2连板晋亿实业：目前生产经营活动正常", "link": "https://36kr.com/newsflashes/3016191572534792?f=rss", "description": "36氪获悉，晋亿实业公告，公司股票于2024年10月30日、10月31日连续两个交易日内收盘价格涨幅偏离值累计超过20%，属于股票交易异常波动情形。经本公司自查，公司目前生产经营活动正常，公司已披露的经营情况、内外部环境未发生重大变化。不存在影响公司股票交易价格异常波动的重大事项。", "published": "2024-10-31 09:08:43", "id": "8aa0c05a-69b4-4d58-baa8-22fefabdb30d", "source": "36氪", "section": "最新快讯"}, {"title": "北交所：拟于11月2日开展交易支持平台优化第一次全网测试", "link": "https://36kr.com/newsflashes/3016207431968000?f=rss", "description": "36氪获悉，10月31日，北京证券交易所办公室、全国股转公司办公室发布通知，拟于近期开展交易支持平台优化第一次全网测试，参测机构包括北交所、全国股转公司、中国结算、深证通、证券公司、基金公司、信息商等。测试时间为11月2日。", "published": "2024-10-31 09:24:51", "id": "36fcee82-38fa-439c-b533-468953119a3d", "source": "36氪", "section": "最新快讯"}, {"title": "前三季度国铁集团实现营业总收入9007亿元，净利润盈利129亿元", "link": "https://36kr.com/newsflashes/3016200638506501?f=rss", "description": "36氪获悉，中国国家铁路集团有限公司披露了2024年前三季度财务决算。前三季度，国铁集团实现营业总收入9007亿元，净利润盈利129亿元。前三季度，全国铁路完成固定资产投资5612亿元、同比增长10.3%，投产铁路新线1820公里，其中高铁1210公里。国庆前夕，全国铁路营业里程突破16万公里，其中高铁超4.6万公里。", "published": "2024-10-31 09:17:57", "id": "609f267a-02a3-484d-a78b-3ea18411e4f0", "source": "36氪", "section": "最新快讯"}, {"title": "香港证监会就市场探盘指引发表咨询总结", "link": "https://36kr.com/newsflashes/3016184304281097?f=rss", "description": "10月31日，香港证监会就适用于市场探盘的建议指引发表咨询总结。该指引载述了持牌人或注册人在进行最常见于大手交易的市场探盘时所适用的原则及规定，当中包括实施规程以保护在市场探盘过程中交托予他们的机密资料或消息。有关咨询的回应者普遍支持建议在市场探盘的过程中维护市场廉洁稳健的目标，其中有多名回应者提供了具建设性的反馈意见。该指引将于2024年11月1日刊宪，并于2025年5月2日生效。中介人将有六个月的过渡期来遵从有关指引。（财联社）", "published": "2024-10-31 09:01:20", "id": "5545be11-39b4-4b88-9d99-9fd85e1058c5", "source": "36氪", "section": "最新快讯"}, {"title": "国家外汇管理局扩大3项跨境投融资便利化试点", "link": "https://36kr.com/newsflashes/3016204332918020?f=rss", "description": "36氪获悉，日前，国家外汇管理局在总结前期试点经验的基础上，决定将开展外商投资企业境内再投资免登记试点和银行直接办理外债登记试点的地区扩大至天津市、安徽省、山东省（含青岛市）、湖北省和四川省，将“科汇通”试点地区扩大至上海市、北京市、天津市、河北雄安、南京市、苏州市、杭州市、合肥市、武汉市、长沙市、广州市、重庆市、成都市、绵阳市、西安市和深圳市等16个地区。", "published": "2024-10-31 09:21:42", "id": "3f85e742-aa2d-443a-b0d5-08f8af404251", "source": "36氪", "section": "最新快讯"}, {"title": "央行：10月开展了5000亿元买断式逆回购操作", "link": "https://36kr.com/newsflashes/3016192775824648?f=rss", "description": "36氪获悉，央行公告，为维护银行体系流动性合理充裕，2024年10月人民银行以固定数量、利率招标、多重价位中标方式开展了5000亿元买断式逆回购操作。", "published": "2024-10-31 09:09:57", "id": "dae98df1-7a52-440c-98ab-15d0498cca1e", "source": "36氪", "section": "最新快讯"}, {"title": "雷神携手BOE（京东方）发布全球首款仿生科技蜂鸟屏", "link": "https://36kr.com/newsflashes/3016233028232455?f=rss", "description": "36氪获悉，雷神携手BOE（京东方）发布全球首款仿生科技蜂鸟屏，由京雷显示创新联合实验室推出。据介绍，雷神蜂鸟屏采用了最新的量子点技术和优化背光系统，融入了BOE（京东方）全新升级的ACR技术，能够实现200:1的ACR超高环境光对比度。", "published": "2024-10-31 09:50:54", "id": "36d40629-0ee1-41b3-98bd-c3e8a0ffe21b", "source": "36氪", "section": "最新快讯"}, {"title": "证监会同意钧崴电子创业板IPO注册申请", "link": "https://36kr.com/newsflashes/3016246883264000?f=rss", "description": "36氪获悉，证监会同意钧崴电子科技股份有限公司首次公开发行股票并在创业板上市的注册申请。", "published": "2024-10-31 10:04:59", "id": "9ae9506a-2fbd-4bbf-a312-5132eaeb1689", "source": "36氪", "section": "最新快讯"}, {"title": "同兴达：董事长提议回购2.5亿元-4亿元公司股份", "link": "https://36kr.com/newsflashes/3016195997902086?f=rss", "description": "36氪获悉，同兴达公告，公司董事长万锋提议公司以自筹资金等方式通过深圳证券交易所交易系统以集中竞价方式回购公司已发行的部分人民币普通股（A股）股票。回购股份拟用于实施股权激励或员工持股计划。回购股份资金总额不低于人民币2.5亿元，不高于人民币4亿元。回购价格上限不高于公司董事会审议通过回购方案决议前30个交易日公司股票交易均价的150%。回购期限为自董事会审议通过本回购股份方案后12个月内。", "published": "2024-10-31 09:13:14", "id": "7dbf7a31-7733-4dd3-a986-0423047ea4c3", "source": "36氪", "section": "最新快讯"}, {"title": "南向资金今日净买入26.83亿港元，美团净卖出额居首", "link": "https://36kr.com/newsflashes/3016217730049287?f=rss", "description": "36氪获悉，南向资金净买入26.83亿港元，小米集团-W、腾讯控股、协鑫科技分别获净买入6.6亿港元、5.34亿港元、2.37亿港元；美团-W净卖出额居首，金额为4.27亿港元。（界面）", "published": "2024-10-31 09:35:20", "id": "a8e84007-627c-4398-bf9d-e1e01b123e97", "source": "36氪", "section": "最新快讯"}, {"title": "富士通继续研究出售空调业务的可能性", "link": "https://36kr.com/newsflashes/3016212181116160?f=rss", "description": "10月31日消息，富士通公司首席财务官表示，该公司仍在继续寻求出售空调业务，并正在努力提升其空调业务的价值。他补充称，目前没有什么新消息可以提供。（界面）", "published": "2024-10-31 09:29:41", "id": "ae7de161-e029-4132-b0c3-930e7f618085", "source": "36氪", "section": "最新快讯"}, {"title": "世茂集团：前三季度营业收入约39.87亿元", "link": "https://36kr.com/newsflashes/3016209064060418?f=rss", "description": "36氪获悉，世茂集团公告，2024年前9个月营业收入约为39.87亿元，上年同期约为33.94亿元；归属于上海世茂所有者的净亏损约27.24亿元，上年同期归属于上海世茂所有者的净亏损约21.26亿元。", "published": "2024-10-31 09:26:31", "id": "84ac8b8d-f366-44d3-9fbf-262184435601", "source": "36氪", "section": "最新快讯"}, {"title": "2连板凌志软件：近期日常经营情况未发生重大变化", "link": "https://36kr.com/newsflashes/3016181323752709?f=rss", "description": "凌志软件10月31日公告，公司股票于2024年10月30日、10月31日连续两个交易日内日收盘价格涨幅偏离值累计达到30%，属于股票交易异常波动情形。经公司自查，公司近期日常经营情况未发生重大变化，内外部经营环境未发生重大变化。", "published": "2024-10-31 08:58:18", "id": "15af81dc-ba1e-4561-8f15-673dbaa9bfcf", "source": "36氪", "section": "最新快讯"}, {"title": "Do Large Language Models Align with Core Mental Health Counseling Competencies?", "link": "https://arxiv.org/abs/2410.22446", "description": "arXiv:2410.22446v1 Announce Type: new \nAbstract: The rapid evolution of Large Language Models (LLMs) offers promising potential to alleviate the global scarcity of mental health professionals. However, LLMs' alignment with essential mental health counseling competencies remains understudied. We introduce CounselingBench, a novel NCMHCE-based benchmark evaluating LLMs across five key mental health counseling competencies. Testing 22 general-purpose and medical-finetuned LLMs, we find frontier models exceed minimum thresholds but fall short of expert-level performance, with significant variations: they excel in Intake, Assessment & Diagnosis yet struggle with Core Counseling Attributes and Professional Practice & Ethics. Medical LLMs surprisingly underperform generalist models accuracy-wise, while at the same time producing slightly higher-quality justifications but making more context-related errors. Our findings highlight the complexities of developing AI systems for mental health counseling, particularly for competencies requiring empathy and contextual understanding. We found that frontier LLMs perform at a level exceeding the minimal required level of aptitude for all key mental health counseling competencies, but fall short of expert-level performance, and that current medical LLMs do not significantly improve upon generalist models in mental health counseling competencies. This underscores the critical need for specialized, mental health counseling-specific fine-tuned LLMs that rigorously aligns with core competencies combined with appropriate human supervision before any responsible real-world deployment can be considered.", "published": "2024-10-31 04:00:00", "id": "39a75f90-fb4f-4d26-85c2-0830b2667671", "source": "arxiv", "section": "computerScience"}, {"title": "A Systematic Literature Review of Spatio-Temporal Graph Neural Network Models for Time Series Forecasting and Classification", "link": "https://arxiv.org/abs/2410.22377", "description": "arXiv:2410.22377v1 Announce Type: new \nAbstract: In recent years, spatio-temporal graph neural networks (GNNs) have attracted considerable interest in the field of time series analysis, due to their ability to capture dependencies among variables and across time points. The objective of the presented systematic literature review is hence to provide a comprehensive overview of the various modeling approaches and application domains of GNNs for time series classification and forecasting. A database search was conducted, and over 150 journal papers were selected for a detailed examination of the current state-of-the-art in the field. This examination is intended to offer to the reader a comprehensive collection of proposed models, links to related source code, available datasets, benchmark models, and fitting results. All this information is hoped to assist researchers in future studies. To the best of our knowledge, this is the first systematic literature review presenting a detailed comparison of the results of current spatio-temporal GNN models in different domains. In addition, in its final part this review discusses current limitations and challenges in the application of spatio-temporal GNNs, such as comparability, reproducibility, explainability, poor information capacity, and scalability.", "published": "2024-10-31 04:00:00", "id": "2697cecd-c147-4274-8996-0dcc491c9c64", "source": "arxiv", "section": "computerScience"}, {"title": "The PV-ALE Dataset: Enhancing Apple Leaf Disease Classification Through Transfer Learning with Convolutional Neural Networks", "link": "https://arxiv.org/abs/2410.22490", "description": "arXiv:2410.22490v1 Announce Type: new \nAbstract: As the global food security landscape continues to evolve, the need for accurate and reliable crop disease diagnosis has never been more pressing. To address global food security concerns, we extend the widely used PlantVillage dataset with additional apple leaf disease classes, enhancing diversity and complexity. Experimental evaluations on both original and extended datasets reveal that existing models struggle with the new additions, highlighting the need for more robust and generalizable computer vision models. Test F1 scores of 99.63% and 97.87% were obtained on the original and extended datasets, respectively. Our study provides a more challenging and diverse benchmark, paving the way for the development of accurate and reliable models for identifying apple leaf diseases under varying imaging conditions. The expanded dataset is available at https://www.kaggle.com/datasets/akinyemijoseph/apple-leaf-disease-dataset-6-classes-v2 enabling future research to build upon our findings.", "published": "2024-10-31 04:00:00", "id": "06305b7d-ef63-4e29-a9ea-a15302e504c6", "source": "arxiv", "section": "computerScience"}, {"title": "Quality-Aware End-to-End Audio-Visual Neural Speaker Diarization", "link": "https://arxiv.org/abs/2410.22350", "description": "arXiv:2410.22350v1 Announce Type: new \nAbstract: In this paper, we propose a quality-aware end-to-end audio-visual neural speaker diarization framework, which comprises three key techniques. First, our audio-visual model takes both audio and visual features as inputs, utilizing a series of binary classification output layers to simultaneously identify the activities of all speakers. This end-to-end framework is meticulously designed to effectively handle situations of overlapping speech, providing accurate discrimination between speech and non-speech segments through the utilization of multi-modal information. Next, we employ a quality-aware audio-visual fusion structure to address signal quality issues for both audio degradations, such as noise, reverberation and other distortions, and video degradations, such as occlusions, off-screen speakers, or unreliable detection. Finally, a cross attention mechanism applied to multi-speaker embedding empowers the network to handle scenarios with varying numbers of speakers. Our experimental results, obtained from various data sets, demonstrate the robustness of our proposed techniques in diverse acoustic environments. Even in scenarios with severely degraded video quality, our system attains performance levels comparable to the best available audio-visual systems.", "published": "2024-10-31 04:00:00", "id": "070d732c-e0ba-4e3c-9947-baec2084d6bb", "source": "arxiv", "section": "computerScience"}, {"title": "A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents", "link": "https://arxiv.org/abs/2410.22476", "description": "arXiv:2410.22476v1 Announce Type: new \nAbstract: In task-oriented dialogue systems, intent detection is crucial for interpreting user queries and providing appropriate responses. Existing research primarily addresses simple queries with a single intent, lacking effective systems for handling complex queries with multiple intents and extracting different intent spans. Additionally, there is a notable absence of multilingual, multi-intent datasets. This study addresses three critical tasks: extracting multiple intent spans from queries, detecting multiple intents, and developing a multi-lingual multi-label intent dataset. We introduce a novel multi-label multi-class intent detection dataset (MLMCID-dataset) curated from existing benchmark datasets. We also propose a pointer network-based architecture (MLMCID) to extract intent spans and detect multiple intents with coarse and fine-grained labels in the form of sextuplets. Comprehensive analysis demonstrates the superiority of our pointer network-based system over baseline approaches in terms of accuracy and F1-score across various datasets.", "published": "2024-10-31 04:00:00", "id": "dc9f5bb7-10ab-4769-89d2-920186850d57", "source": "arxiv", "section": "computerScience"}, {"title": "Learning Goal-oriented Bimanual Dough Rolling Using Dynamic Heterogeneous Graph Based on Human Demonstration", "link": "https://arxiv.org/abs/2410.22355", "description": "arXiv:2410.22355v1 Announce Type: new \nAbstract: Soft object manipulation poses significant challenges for robots, requiring effective techniques for state representation and manipulation policy learning. State representation involves capturing the dynamic changes in the environment, while manipulation policy learning focuses on establishing the relationship between robot actions and state transformations to achieve specific goals. To address these challenges, this research paper introduces a novel approach: a dynamic heterogeneous graph-based model for learning goal-oriented soft object manipulation policies. The proposed model utilizes graphs as a unified representation for both states and policy learning. By leveraging the dynamic graph, we can extract crucial information regarding object dynamics and manipulation policies. Furthermore, the model facilitates the integration of demonstrations, enabling guided policy learning. To evaluate the efficacy of our approach, we designed a dough rolling task and conducted experiments using both a differentiable simulator and a real-world humanoid robot. Additionally, several ablation studies were performed to analyze the effect of our method, demonstrating its superiority in achieving human-like behavior.", "published": "2024-10-31 04:00:00", "id": "944722a4-8488-4179-bfb9-2b7a45c29f64", "source": "arxiv", "section": "computerScience"}, {"title": "Multimodality Helps Few-Shot 3D Point Cloud Semantic Segmentation", "link": "https://arxiv.org/abs/2410.22489", "description": "arXiv:2410.22489v1 Announce Type: new \nAbstract: Few-shot 3D point cloud segmentation (FS-PCS) aims at generalizing models to segment novel categories with minimal annotated support samples. While existing FS-PCS methods have shown promise, they primarily focus on unimodal point cloud inputs, overlooking the potential benefits of leveraging multimodal information. In this paper, we address this gap by introducing a cost-free multimodal FS-PCS setup, utilizing textual labels and the potentially available 2D image modality. Under this easy-to-achieve setup, we present the MultiModal Few-Shot SegNet (MM-FSS), a model effectively harnessing complementary information from multiple modalities. MM-FSS employs a shared backbone with two heads to extract intermodal and unimodal visual features, and a pretrained text encoder to generate text embeddings. To fully exploit the multimodal information, we propose a Multimodal Correlation Fusion (MCF) module to generate multimodal correlations, and a Multimodal Semantic Fusion (MSF) module to refine the correlations using text-aware semantic guidance. Additionally, we propose a simple yet effective Test-time Adaptive Cross-modal Calibration (TACC) technique to mitigate training bias, further improving generalization. Experimental results on S3DIS and ScanNet datasets demonstrate significant performance improvements achieved by our method. The efficacy of our approach indicates the benefits of leveraging commonly-ignored free modalities for FS-PCS, providing valuable insights for future research. The code is available at https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot .", "published": "2024-10-31 04:00:00", "id": "b2a3ff1d-af8e-4795-ab1e-d1fa2d7d16de", "source": "arxiv", "section": "computerScience"}, {"title": "Requirements for a Digital Library System: A Case Study in Digital Humanities (Technical Report)", "link": "https://arxiv.org/abs/2410.22358", "description": "arXiv:2410.22358v1 Announce Type: new \nAbstract: Archives of libraries contain many materials, which have not yet been made available to the public. The prioritization of which content to provide and especially how to design effective access paths depend on potential users' needs. As a case study we interviewed researchers working on topics related to one German philosopher to map out their information interaction workflow. Additionally, we deeply analyze study participants' requirements for a digital library system. Moreover, we discuss how existing methods may meet their requirements, but we also discuss what implications these methods have in practice, e.g., computational costs and hallucinations. In brief, this paper contributes the findings of our digital humanities case study resulting in system requirements.", "published": "2024-10-31 04:00:00", "id": "a4b84663-cd0f-489e-8bd9-0bd322f10ec0", "source": "arxiv", "section": "computerScience"}, {"title": "Analytic Continual Test-Time Adaptation for Multi-Modality Corruption", "link": "https://arxiv.org/abs/2410.22373", "description": "arXiv:2410.22373v1 Announce Type: new \nAbstract: Test-Time Adaptation (TTA) aims to help pre-trained model bridge the gap between source and target datasets using only the pre-trained model and unlabelled test data. A key objective of TTA is to address domain shifts in test data caused by corruption, such as weather changes, noise, or sensor malfunctions. Multi-Modal Continual Test-Time Adaptation (MM-CTTA), an extension of TTA with better real-world applications, further allows pre-trained models to handle multi-modal inputs and adapt to continuously-changing target domains. MM-CTTA typically faces challenges including error accumulation, catastrophic forgetting, and reliability bias, with few existing approaches effectively addressing these issues in multi-modal corruption scenarios. In this paper, we propose a novel approach, Multi-modality Dynamic Analytic Adapter (MDAA), for MM-CTTA tasks. We innovatively introduce analytic learning into TTA, using the Analytic Classifiers (ACs) to prevent model forgetting. Additionally, we develop Dynamic Selection Mechanism (DSM) and Soft Pseudo-label Strategy (SPS), which enable MDAA to dynamically filter reliable samples and integrate information from different modalities. Extensive experiments demonstrate that MDAA achieves state-of-the-art performance on MM-CTTA tasks while ensuring reliable model adaptation.", "published": "2024-10-31 04:00:00", "id": "4a1806cb-23be-419b-a8d6-76950925022f", "source": "arxiv", "section": "computerScience"}, {"title": "RuleRAG: Rule-guided retrieval-augmented generation with language models for question answering", "link": "https://arxiv.org/abs/2410.22353", "description": "arXiv:2410.22353v1 Announce Type: new \nAbstract: Retrieval-augmented generation (RAG) framework has shown promising potential in knowledge-intensive question answering (QA) by retrieving external corpus and generating based on augmented context. However, existing approaches only consider the query itself, neither specifying the retrieval preferences for the retrievers nor informing the generators of how to refer to the retrieved documents for the answers, which poses a significant challenge to the QA performance. To address these issues, we propose Rule-Guided Retrieval-Augmented Generation with LMs, which explicitly introduces symbolic rules as demonstrations for in-context learning (RuleRAG-ICL) to guide retrievers to retrieve logically related documents in the directions of rules and uniformly guide generators to generate answers attributed by the guidance of the same set of rules. Moreover, the combination of queries and rules can be further used as supervised fine-tuning data to update retrievers and generators (RuleRAG-FT) to achieve better rule-based instruction following capability, leading to retrieve more supportive results and generate more acceptable answers. To emphasize the attribution of rules, we construct five rule-aware QA benchmarks, including three temporal and two static scenarios, and equip RuleRAG with several kinds of retrievers and generators. Experiments demonstrate that training-free RuleRAG-ICL effectively improves the retrieval quality of +89.2% in Recall@10 scores and generation accuracy of +103.1% in exact match scores over standard RAG on average across the five benchmarks, and further fine-tuned RuleRAG-FT consistently yields more significant performance enhancement. Extensive analyses indicate that RuleRAG scales well with increasing numbers of retrieved documents and exhibits generalization ability for untrained rules.", "published": "2024-10-31 04:00:00", "id": "b6d285fe-5ebb-406c-91c5-e06933867dc8", "source": "arxiv", "section": "computerScience"}, {"title": "GleanVec: Accelerating vector search with minimalist nonlinear dimensionality reduction", "link": "https://arxiv.org/abs/2410.22347", "description": "arXiv:2410.22347v1 Announce Type: new \nAbstract: Embedding models can generate high-dimensional vectors whose similarity reflects semantic affinities. Thus, accurately and timely retrieving those vectors in a large collection that are similar to a given query has become a critical component of a wide range of applications. In particular, cross-modal retrieval (e.g., where a text query is used to find images) is gaining momentum rapidly. Here, it is challenging to achieve high accuracy as the queries often have different statistical distributions than the database vectors. Moreover, the high vector dimensionality puts these search systems under compute and memory pressure, leading to subpar performance. In this work, we present new linear and nonlinear methods for dimensionality reduction to accelerate high-dimensional vector search while maintaining accuracy in settings with in-distribution (ID) and out-of-distribution (OOD) queries. The linear LeanVec-Sphering outperforms other linear methods, trains faster, comes with no hyperparameters, and allows to set the target dimensionality more flexibly. The nonlinear Generalized LeanVec (GleanVec) uses a piecewise linear scheme to further improve the search accuracy while remaining computationally nimble. Initial experimental results show that LeanVec-Sphering and GleanVec push the state of the art for vector search.", "published": "2024-10-31 04:00:00", "id": "0fc43573-e5c9-47a0-a767-84a2a384dfaf", "source": "arxiv", "section": "computerScience"}, {"title": "Scaling LLM Inference with Optimized Sample Compute Allocation", "link": "https://arxiv.org/abs/2410.22480", "description": "arXiv:2410.22480v1 Announce Type: new \nAbstract: Sampling is a basic operation in many inference-time algorithms of large language models (LLMs). To scale up inference efficiently with a limited compute, it is crucial to find an optimal allocation for sample compute budgets: Which sampling configurations (model, temperature, language, etc.) do we use? How many samples do we generate in each configuration? We formulate these choices as a learning problem and propose OSCA, an algorithm that Optimizes Sample Compute Allocation by finding an optimal mix of different inference configurations. Our experiments show that with our learned mixed allocation, we can achieve accuracy better than the best single configuration with 128x less compute on code generation and 25x less compute on 4 reasoning tasks. OSCA is also shown to be effective in agentic workflows beyond single-turn tasks, achieving a better accuracy on SWE-Bench with 3x less compute than the default configuration. Our code and generations are released at https://github.com/LeiLiLab/OSCA.", "published": "2024-10-31 04:00:00", "id": "02b8079e-2ab7-402c-92cd-2f4a1b33f2fa", "source": "arxiv", "section": "computerScience"}, {"title": "Robust training of implicit generative models for multivariate and heavy-tailed distributions with an invariant statistical loss", "link": "https://arxiv.org/abs/2410.22381", "description": "arXiv:2410.22381v1 Announce Type: new \nAbstract: Traditional implicit generative models are capable of learning highly complex data distributions. However, their training involves distinguishing real data from synthetically generated data using adversarial discriminators, which can lead to unstable training dynamics and mode dropping issues. In this work, we build on the \\textit{invariant statistical loss} (ISL) method introduced in \\cite{de2024training}, and extend it to handle heavy-tailed and multivariate data distributions.\n  The data generated by many real-world phenomena can only be properly characterised using heavy-tailed probability distributions, and traditional implicit methods struggle to effectively capture their asymptotic behavior. To address this problem, we introduce a generator trained with ISL, that uses input noise from a generalised Pareto distribution (GPD). We refer to this generative scheme as Pareto-ISL for conciseness. Our experiments demonstrate that Pareto-ISL accurately models the tails of the distributions while still effectively capturing their central characteristics.\n  The original ISL function was conceived for 1D data sets. When the actual data is $n$-dimensional, a straightforward extension of the method was obtained by targeting the $n$ marginal distributions of the data. This approach is computationally infeasible and ineffective in high-dimensional spaces. To overcome this, we extend the 1D approach using random projections and define a new loss function suited for multivariate data, keeping problems tractable by adjusting the number of projections. We assess its performance in multidimensional generative modeling and explore its potential as a pretraining technique for generative adversarial networks (GANs) to prevent mode collapse, reporting promising results and highlighting its robustness across various hyperparameter settings.", "published": "2024-10-31 04:00:00", "id": "cb3f1898-1add-4b67-bcca-ec676ecabbce", "source": "arxiv", "section": "computerScience"}, {"title": "Image2Struct: Benchmarking Structure Extraction for Vision-Language Models", "link": "https://arxiv.org/abs/2410.22456", "description": "arXiv:2410.22456v1 Announce Type: new \nAbstract: We introduce Image2Struct, a benchmark to evaluate vision-language models (VLMs) on extracting structure from images. Our benchmark 1) captures real-world use cases, 2) is fully automatic and does not require human judgment, and 3) is based on a renewable stream of fresh data. In Image2Struct, VLMs are prompted to generate the underlying structure (e.g., LaTeX code or HTML) from an input image (e.g., webpage screenshot). The structure is then rendered to produce an output image (e.g., rendered webpage), which is compared against the input image to produce a similarity score. This round-trip evaluation allows us to quantitatively evaluate VLMs on tasks with multiple valid structures. We create a pipeline that downloads fresh data from active online communities upon execution and evaluates the VLMs without human intervention. We introduce three domains (Webpages, LaTeX, and Musical Scores) and use five image metrics (pixel similarity, cosine similarity between the Inception vectors, learned perceptual image patch similarity, structural similarity index measure, and earth mover similarity) that allow efficient and automatic comparison between pairs of images. We evaluate Image2Struct on 14 prominent VLMs and find that scores vary widely, indicating that Image2Struct can differentiate between the performances of different VLMs. Additionally, the best score varies considerably across domains (e.g., 0.402 on sheet music vs. 0.830 on LaTeX equations), indicating that Image2Struct contains tasks of varying difficulty. For transparency, we release the full results at https://crfm.stanford.edu/helm/image2struct/v1.0.1/.", "published": "2024-10-31 04:00:00", "id": "af912bef-a413-464e-b03a-d89f12eb8ec6", "source": "arxiv", "section": "computerScience"}, {"title": "Discrete Modeling via Boundary Conditional Diffusion Processes", "link": "https://arxiv.org/abs/2410.22380", "description": "arXiv:2410.22380v1 Announce Type: new \nAbstract: We present an novel framework for efficiently and effectively extending the powerful continuous diffusion processes to discrete modeling. Previous approaches have suffered from the discrepancy between discrete data and continuous modeling. Our study reveals that the absence of guidance from discrete boundaries in learning probability contours is one of the main reasons. To address this issue, we propose a two-step forward process that first estimates the boundary as a prior distribution and then rescales the forward trajectory to construct a boundary conditional diffusion model. The reverse process is proportionally adjusted to guarantee that the learned contours yield more precise discrete data. Experimental results indicate that our approach achieves strong performance in both language modeling and discrete image generation tasks. In language modeling, our approach surpasses previous state-of-the-art continuous diffusion language models in three translation tasks and a summarization task, while also demonstrating competitive performance compared to auto-regressive transformers. Moreover, our method achieves comparable results to continuous diffusion models when using discrete ordinal pixels and establishes a new state-of-the-art for categorical image generation on the Cifar-10 dataset.", "published": "2024-10-31 04:00:00", "id": "1ef43f92-1b13-491d-8a86-608392237e1f", "source": "arxiv", "section": "computerScience"}, {"title": "The State of Data Curation at NeurIPS: An Assessment of Dataset Development Practices in the Datasets and Benchmarks Track", "link": "https://arxiv.org/abs/2410.22473", "description": "arXiv:2410.22473v1 Announce Type: new \nAbstract: Data curation is a field with origins in librarianship and archives, whose scholarship and thinking on data issues go back centuries, if not millennia. The field of machine learning is increasingly observing the importance of data curation to the advancement of both applications and fundamental understanding of machine learning models - evidenced not least by the creation of the Datasets and Benchmarks track itself. This work provides an analysis of dataset development practices at NeurIPS through the lens of data curation. We present an evaluation framework for dataset documentation, consisting of a rubric and toolkit developed through a literature review of data curation principles. We use the framework to assess the strengths and weaknesses in current dataset development practices of 60 datasets published in the NeurIPS Datasets and Benchmarks track from 2021-2023. We summarize key findings and trends. Results indicate greater need for documentation about environmental footprint, ethical considerations, and data management. We suggest targeted strategies and resources to improve documentation in these areas and provide recommendations for the NeurIPS peer-review process that prioritize rigorous data curation in ML. Finally, we provide results in the format of a dataset that showcases aspects of recommended data curation practices. Our rubric and results are of interest for improving data curation practices broadly in the field of ML as well as to data curation and science and technology studies scholars studying practices in ML. Our aim is to support continued improvement in interdisciplinary research on dataset practices, ultimately improving the reusability and reproducibility of new datasets and benchmarks, enabling standardized and informed human oversight, and strengthening the foundation of rigorous and responsible ML research.", "published": "2024-10-31 04:00:00", "id": "3c8e203d-c3d0-43de-ac3b-09036f62f0ad", "source": "arxiv", "section": "computerScience"}, {"title": "Exploiting Semantic Scene Reconstruction for Estimating Building Envelope Characteristics", "link": "https://arxiv.org/abs/2410.22383", "description": "arXiv:2410.22383v1 Announce Type: new \nAbstract: Achieving the EU's climate neutrality goal requires retrofitting existing buildings to reduce energy use and emissions. A critical step in this process is the precise assessment of geometric building envelope characteristics to inform retrofitting decisions. Previous methods for estimating building characteristics, such as window-to-wall ratio, building footprint area, and the location of architectural elements, have primarily relied on applying deep-learning-based detection or segmentation techniques on 2D images. However, these approaches tend to focus on planar facade properties, limiting their accuracy and comprehensiveness when analyzing complete building envelopes in 3D.\n  While neural scene representations have shown exceptional performance in indoor scene reconstruction, they remain under-explored for external building envelope analysis. This work addresses this gap by leveraging cutting-edge neural surface reconstruction techniques based on signed distance function (SDF) representations for 3D building analysis. We propose BuildNet3D, a novel framework to estimate geometric building characteristics from 2D image inputs. By integrating SDF-based representation with semantic modality, BuildNet3D recovers fine-grained 3D geometry and semantics of building envelopes, which are then used to automatically extract building characteristics. Our framework is evaluated on a range of complex building structures, demonstrating high accuracy and generalizability in estimating window-to-wall ratio and building footprint. The results underscore the effectiveness of BuildNet3D for practical applications in building analysis and retrofitting.", "published": "2024-10-31 04:00:00", "id": "f579e9aa-cec1-4363-86a5-ae6b38bbde46", "source": "arxiv", "section": "computerScience"}, {"title": "Error Bounds for Deep Learning-based Uncertainty Propagation in SDEs", "link": "https://arxiv.org/abs/2410.22371", "description": "arXiv:2410.22371v1 Announce Type: new \nAbstract: Stochastic differential equations are commonly used to describe the evolution of stochastic processes. The uncertainty of such processes is best represented by the probability density function (PDF), whose evolution is governed by the Fokker-Planck partial differential equation (FP-PDE). However, it is generally infeasible to solve the FP-PDE in closed form. In this work, we show that physics-informed neural networks (PINNs) can be trained to approximate the solution PDF using existing methods. The main contribution is the analysis of the approximation error: we develop a theory to construct an arbitrary tight error bound with PINNs. In addition, we derive a practical error bound that can be efficiently constructed with existing training methods. Finally, we explain that this error-bound theory generalizes to approximate solutions of other linear PDEs. Several numerical experiments are conducted to demonstrate and validate the proposed methods.", "published": "2024-10-31 04:00:00", "id": "64d33141-319d-4fea-a413-4502d1c1389a", "source": "arxiv", "section": "computerScience"}, {"title": "How Artists Improvise and Provoke Robotics", "link": "https://arxiv.org/abs/2410.22462", "description": "arXiv:2410.22462v1 Announce Type: new \nAbstract: We explore transdisciplinary collaborations between artists and roboticists across a portfolio of artworks. Brendan Walker's Broncomatic was a breath controlled mechanical rodeo bull ride. Blast Theory's Cat Royale deployed a robot arm to play with a family of three cats for twelve days. Different Bodies is a prototype improvised dance performance in which dancers with disabilities physically manipulate two mirrored robot arms. We reflect on these to explore how artists shape robotics research through the two key strategies of improvisation and provocation. Artists are skilled at improvising extended robot experiences that surface opportunities for technology-focused design, but which also require researchers to improvise their research processes. Artists may provoke audiences into reflecting on the societal implications of robots, but at the same time challenge the established techno-centric concepts, methods and underlying epistemology of robotics research.", "published": "2024-10-31 04:00:00", "id": "31a19db7-9597-4986-9cf0-882fb0910618", "source": "arxiv", "section": "computerScience"}, {"title": "Unleashing Multicore Strength for Efficient Execution of Transactions", "link": "https://arxiv.org/abs/2410.22460", "description": "arXiv:2410.22460v1 Announce Type: new \nAbstract: Blockchain technology is booming up the digital world in recent days and thus paved a way for creating separate blockchain network for various industries. This technology is characterized by its distributed, decentralized, and immutable ledger system which serves as a fundamental platform for managing smart contract transactions (SCTs). However, these self-executing codes implemented using blockchains undergo sequential validation within a block which introduces performance bottlenecks. In response, this paper introduces a framework called the Multi-Bin Parallel Scheduler (MBPS) designed for parallelizing blockchain smart contract transactions to leverage the capabilities of multicore systems. Our proposed framework facilitates concurrent execution of SCTs, enhancing performance by allowing non-conflicting transactions to be processed simultaneously while preserving deterministic order. The framework comprises of three vital stages: conflict detection, bin creation and execution. We conducted an evaluation of our MBPS framework in Hyperledger Sawtooth v1.2.6, revealing substantial performance enhancements compared to existing parallel SCT execution frameworks across various smart contract applications. This research contributes to the ongoing optimization efforts in blockchain technology demonstrating its potential for scalability and efficiency in real-world scenarios.", "published": "2024-10-31 04:00:00", "id": "2f4d36fc-984f-42ba-abfc-9767615c2de0", "source": "arxiv", "section": "computerScience"}, {"title": "Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset", "link": "https://arxiv.org/abs/2410.22457", "description": "arXiv:2410.22457v1 Announce Type: new \nAbstract: Advancements in Large Language Models (LLMs) are revolutionizing the development of autonomous agentic systems by enabling dynamic, context-aware task decomposition and automated tool selection. These sophisticated systems possess significant automation potential across various industries, managing complex tasks, interacting with external systems to enhance knowledge, and executing actions independently. This paper presents three primary contributions to advance this field:\n  - Advanced Agentic Framework: A system that handles multi-hop queries, generates and executes task graphs, selects appropriate tools, and adapts to real-time changes.\n  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural Similarity Index (SSI), and Tool F1 Score to comprehensively assess agentic systems.\n  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing agent behavior across different task complexities.\n  Our findings reveal that asynchronous and dynamic task graph decomposition significantly enhances system responsiveness and scalability, particularly for complex, multi-step tasks. Detailed analysis shows that structural and node-level metrics are crucial for sequential tasks, while tool-related metrics are more important for parallel tasks. Specifically, the Structural Similarity Index (SSI) is the most significant predictor of performance in sequential tasks, and the Tool F1 Score is essential for parallel tasks. These insights highlight the need for balanced evaluation methods that capture both structural and operational dimensions of agentic systems. Additionally, our evaluation framework, validated through empirical analysis and statistical testing, provides valuable insights for improving the adaptability and reliability of agentic systems in dynamic environments.", "published": "2024-10-31 04:00:00", "id": "2a60c21c-786d-4e24-9a82-e2504fa0ef14", "source": "arxiv", "section": "computerScience"}, {"title": "Rethinking Code Refinement: Learning to Judge Code Efficiency", "link": "https://arxiv.org/abs/2410.22375", "description": "arXiv:2410.22375v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated impressive capabilities in understanding and generating codes. Due to these capabilities, many recent methods are proposed to automatically refine the codes with LLMs. However, we should rethink that the refined codes (from LLMs and even humans) are not always more efficient than their original versions. On the other hand, running two different versions of codes and comparing them every time is not ideal and time-consuming. Therefore, in this work, we propose a novel method based on the code language model that is trained to judge the efficiency between two different codes (generated across humans and machines) by either classifying the superior one or predicting the relative improvement. We validate our method on multiple programming languages with multiple refinement steps, demonstrating that the proposed method can effectively distinguish between more and less efficient versions of code.", "published": "2024-10-31 04:00:00", "id": "1f2d0011-a965-4d72-b6d7-9baade195f5c", "source": "arxiv", "section": "computerScience"}, {"title": "Developing Convolutional Neural Networks using a Novel Lamarckian Co-Evolutionary Algorithm", "link": "https://arxiv.org/abs/2410.22487", "description": "arXiv:2410.22487v1 Announce Type: new \nAbstract: Neural Architecture Search (NAS) methods autonomously discover high-accuracy neural network architectures, outperforming manually crafted ones. However, The NAS methods require high computational costs due to the high dimension search space and the need to train multiple candidate solutions. This paper introduces LCoDeepNEAT, an instantiation of Lamarckian genetic algorithms, which extends the foundational principles of the CoDeepNEAT framework. LCoDeepNEAT co-evolves CNN architectures and their respective final layer weights. The evaluation process of LCoDeepNEAT entails a single epoch of SGD, followed by the transference of the acquired final layer weights to the genetic representation of the network. In addition, it expedites the process of evolving by imposing restrictions on the architecture search space, specifically targeting architectures comprising just two fully connected layers for classification. Our method yields a notable improvement in the classification accuracy of candidate solutions throughout the evolutionary process, ranging from 2% to 5.6%. This outcome underscores the efficacy and effectiveness of integrating gradient information and evolving the last layer of candidate solutions within LCoDeepNEAT. LCoDeepNEAT is assessed across six standard image classification datasets and benchmarked against eight leading NAS methods. Results demonstrate LCoDeepNEAT's ability to swiftly discover competitive CNN architectures with fewer parameters, conserving computational resources, and achieving superior classification accuracy compared to other approaches.", "published": "2024-10-31 04:00:00", "id": "5c0c9ba1-57b8-4b17-b67e-fcc4dc344842", "source": "arxiv", "section": "computerScience"}, {"title": "Unpacking SDXL Turbo: Interpreting Text-to-Image Models with Sparse Autoencoders", "link": "https://arxiv.org/abs/2410.22366", "description": "arXiv:2410.22366v1 Announce Type: new \nAbstract: Sparse autoencoders (SAEs) have become a core ingredient in the reverse engineering of large-language models (LLMs). For LLMs, they have been shown to decompose intermediate representations that often are not interpretable directly into sparse sums of interpretable features, facilitating better control and subsequent analysis. However, similar analyses and approaches have been lacking for text-to-image models. We investigated the possibility of using SAEs to learn interpretable features for a few-step text-to-image diffusion models, such as SDXL Turbo. To this end, we train SAEs on the updates performed by transformer blocks within SDXL Turbo's denoising U-net. We find that their learned features are interpretable, causally influence the generation process, and reveal specialization among the blocks. In particular, we find one block that deals mainly with image composition, one that is mainly responsible for adding local details, and one for color, illumination, and style. Therefore, our work is an important first step towards better understanding the internals of generative text-to-image models like SDXL Turbo and showcases the potential of features learned by SAEs for the visual domain.\n  Code is available at https://github.com/surkovv/sdxl-unbox", "published": "2024-10-31 04:00:00", "id": "1f921ebf-88aa-4522-af48-e4f61a40e75e", "source": "arxiv", "section": "computerScience"}, {"title": "AAAR-1.0: Assessing AI's Potential to Assist Research", "link": "https://arxiv.org/abs/2410.22394", "description": "arXiv:2410.22394v1 Announce Type: new \nAbstract: Numerous studies have assessed the proficiency of AI systems, particularly large language models (LLMs), in facilitating everyday tasks such as email writing, question answering, and creative content generation. However, researchers face unique challenges and opportunities in leveraging LLMs for their own work, such as brainstorming research ideas, designing experiments, and writing or reviewing papers. In this study, we introduce AAAR-1.0, a benchmark dataset designed to evaluate LLM performance in three fundamental, expertise-intensive research tasks: (i) EquationInference, assessing the correctness of equations based on the contextual information in paper submissions; (ii) ExperimentDesign, designing experiments to validate research ideas and solutions; (iii) PaperWeakness, identifying weaknesses in paper submissions; and (iv) REVIEWCRITIQUE, identifying each segment in human reviews is deficient or not. AAAR-1.0 differs from prior benchmarks in two key ways: first, it is explicitly research-oriented, with tasks requiring deep domain expertise; second, it is researcher-oriented, mirroring the primary activities that researchers engage in on a daily basis. An evaluation of both open-source and proprietary LLMs reveals their potential as well as limitations in conducting sophisticated research tasks. We will keep iterating AAAR-1.0 to new versions.", "published": "2024-10-31 04:00:00", "id": "5cffb951-a6cb-480a-bb04-c066fd17dd33", "source": "arxiv", "section": "computerScience"}, {"title": "Faster Algorithms for Average-Case Orthogonal Vectors and Closest Pair Problems", "link": "https://arxiv.org/abs/2410.22477", "description": "arXiv:2410.22477v1 Announce Type: new \nAbstract: We study the average-case version of the Orthogonal Vectors problem, in which one is given as input $n$ vectors from $\\{0,1\\}^d$ which are chosen randomly so that each coordinate is $1$ independently with probability $p$. Kane and Williams [ITCS 2019] showed how to solve this problem in time $O(n^{2 - \\delta_p})$ for a constant $\\delta_p > 0$ that depends only on $p$. However, it was previously unclear how to solve the problem faster in the hardest parameter regime where $p$ may depend on $d$.\n  The best prior algorithm was the best worst-case algorithm by Abboud, Williams and Yu [SODA 2014], which in dimension $d = c \\cdot \\log n$, solves the problem in time $n^{2 - \\Omega(1/\\log c)}$. In this paper, we give a new algorithm which improves this to $n^{2 - \\Omega(\\log\\log c /\\log c)}$ in the average case for any parameter $p$.\n  As in the prior work, our algorithm uses the polynomial method. We make use of a very simple polynomial over the reals, and use a new method to analyze its performance based on computing how its value degrades as the input vectors get farther from orthogonal.\n  To demonstrate the generality of our approach, we also solve the average-case version of the closest pair problem in the same running time.", "published": "2024-10-31 04:00:00", "id": "c0c7d0d0-f5c4-4441-a163-d5b5fabfc49b", "source": "arxiv", "section": "computerScience"}, {"title": "Designing robot swarms: a puzzle, a problem, and a mess", "link": "https://arxiv.org/abs/2410.22478", "description": "arXiv:2410.22478v1 Announce Type: new \nAbstract: Framing an issue as a puzzle, problem, or mess is an illustrative approach to characterizing the issue's complexity within organizational theory and systems thinking. We use this approach to characterize the issue of designing collective behaviors for robot swarms and discuss how various research goals have shaped the current state of the field. We contextualize our discussion at these three levels by highlighting relevant literature. Our aim is to emphasize key challenges that arise in the development of robot swarms for real-world applications and to motivate further work on promising research directions.", "published": "2024-10-31 04:00:00", "id": "2992d37b-d389-47e6-ae9e-221ea126aa9d", "source": "arxiv", "section": "computerScience"}, {"title": "Learning Identifiable Factorized Causal Representations of Cellular Responses", "link": "https://arxiv.org/abs/2410.22472", "description": "arXiv:2410.22472v1 Announce Type: new \nAbstract: The study of cells and their responses to genetic or chemical perturbations promises to accelerate the discovery of therapeutic targets. However, designing adequate and insightful models for such data is difficult because the response of a cell to perturbations essentially depends on its biological context (e.g., genetic background or cell type). For example, while discovering therapeutic targets, one may want to enrich for drugs that specifically target a certain cell type. This challenge emphasizes the need for methods that explicitly take into account potential interactions between drugs and contexts. Towards this goal, we propose a novel Factorized Causal Representation (FCR)\n  learning method that reveals causal structure in single-cell perturbation data from several cell lines. Based on the framework of identifiable deep generative models, FCR learns multiple cellular representations that are disentangled, comprised of covariate-specific ($\\mathbf{z}_x$), treatment-specific ($\\mathbf{z}_{t}$), and interaction-specific ($\\mathbf{z}_{tx}$) blocks. Based on recent advances in non-linear ICA theory, we prove the component-wise identifiability of $\\mathbf{z}_{tx}$ and block-wise identifiability of $\\mathbf{z}_t$ and $\\mathbf{z}_x$. Then, we present our implementation of FCR, and empirically demonstrate that it outperforms state-of-the-art baselines in various tasks across four single-cell datasets.", "published": "2024-10-31 04:00:00", "id": "be27dcb0-6fd3-4203-9b07-5c83168bb824", "source": "arxiv", "section": "computerScience"}, {"title": "Survey of User Interface Design and Interaction Techniques in Generative AI Applications", "link": "https://arxiv.org/abs/2410.22370", "description": "arXiv:2410.22370v1 Announce Type: new \nAbstract: The applications of generative AI have become extremely impressive, and the interplay between users and AI is even more so. Current human-AI interaction literature has taken a broad look at how humans interact with generative AI, but it lacks specificity regarding the user interface designs and patterns used to create these applications. Therefore, we present a survey that comprehensively presents taxonomies of how a human interacts with AI and the user interaction patterns designed to meet the needs of a variety of relevant use cases. We focus primarily on user-guided interactions, surveying interactions that are initiated by the user and do not include any implicit signals given by the user. With this survey, we aim to create a compendium of different user-interaction patterns that can be used as a reference for designers and developers alike. In doing so, we also strive to lower the entry barrier for those attempting to learn more about the design of generative AI applications.", "published": "2024-10-31 04:00:00", "id": "2adceec8-987c-46c8-97ca-0998b7e5a978", "source": "arxiv", "section": "computerScience"}, {"title": "Addressing Issues with Working Memory in Video Object Segmentation", "link": "https://arxiv.org/abs/2410.22451", "description": "arXiv:2410.22451v1 Announce Type: new \nAbstract: Contemporary state-of-the-art video object segmentation (VOS) models compare incoming unannotated images to a history of image-mask relations via affinity or cross-attention to predict object masks. We refer to the internal memory state of the initial image-mask pair and past image-masks as a working memory buffer. While the current state of the art models perform very well on clean video data, their reliance on a working memory of previous frames leaves room for error. Affinity-based algorithms include the inductive bias that there is temporal continuity between consecutive frames. To account for inconsistent camera views of the desired object, working memory models need an algorithmic modification that regulates the memory updates and avoid writing irrelevant frames into working memory. A simple algorithmic change is proposed that can be applied to any existing working memory-based VOS model to improve performance on inconsistent views, such as sudden camera cuts, frame interjections, and extreme context changes. The resulting model performances show significant improvement on video data with these frame interjections over the same model without the algorithmic addition. Our contribution is a simple decision function that determines whether working memory should be updated based on the detection of sudden, extreme changes and the assumption that the object is no longer in frame. By implementing algorithmic changes, such as this, we can increase the real-world applicability of current VOS models.", "published": "2024-10-31 04:00:00", "id": "b1ec6ddb-6e70-4f13-bfbf-8227e04a8772", "source": "arxiv", "section": "computerScience"}, {"title": "Gradient Distance Function", "link": "https://arxiv.org/abs/2410.22422", "description": "arXiv:2410.22422v1 Announce Type: new \nAbstract: Unsigned Distance Functions (UDFs) can be used to represent non-watertight surfaces in a deep learning framework. However, UDFs tend to be brittle and difficult to learn, in part because the surface is located exactly where the UDF is non-differentiable. In this work, we show that Gradient Distance Functions (GDFs) can remedy this by being differentiable at the surface while still being able to represent open surfaces. This is done by associating to each 3D point a 3D vector whose norm is taken to be the unsigned distance to the surface and whose orientation is taken to be the direction towards the closest surface point. We demonstrate the effectiveness of GDFs on ShapeNet Car, Multi-Garment, and 3D-Scene datasets with both single-shape reconstruction networks or categorical auto-decoders.", "published": "2024-10-31 04:00:00", "id": "4f7263dc-e7a5-4cbc-b6a9-f83975fcab15", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient Machine Translation with a BiLSTM-Attention Approach", "link": "https://arxiv.org/abs/2410.22335", "description": "arXiv:2410.22335v1 Announce Type: new \nAbstract: With the rapid development of Natural Language Processing (NLP) technology, the accuracy and efficiency of machine translation have become hot topics of research. This paper proposes a novel Seq2Seq model aimed at improving translation quality while reducing the storage space required by the model. The model employs a Bidirectional Long Short-Term Memory network (Bi-LSTM) as the encoder to capture the context information of the input sequence; the decoder incorporates an attention mechanism, enhancing the model's ability to focus on key information during the translation process. Compared to the current mainstream Transformer model, our model achieves superior performance on the WMT14 machine translation dataset while maintaining a smaller size.\n  The study first introduces the design principles and innovative points of the model architecture, followed by a series of experiments to verify the effectiveness of the model. The experimental includes an assessment of the model's performance on different language pairs, as well as comparative analysis with traditional Seq2Seq models. The results show that while maintaining translation accuracy, our model significantly reduces the storage requirements, which is of great significance for translation applications in resource-constrained scenarios. our code are available at https://github.com/mindspore-lab/models/tree/master/research/arxiv_papers/miniformer . Thanks for the support provided by MindSpore Community.", "published": "2024-10-31 04:00:00", "id": "51d68d37-9abd-4f32-b588-e97ffe2bbd8c", "source": "arxiv", "section": "computerScience"}, {"title": "DAWN: Designing Distributed Agents in a Worldwide Network", "link": "https://arxiv.org/abs/2410.22339", "description": "arXiv:2410.22339v1 Announce Type: new \nAbstract: The rapid evolution of Large Language Models (LLMs) has transformed them from basic conversational tools into sophisticated entities capable of complex reasoning and decision-making. These advancements have led to the development of specialized LLM-based agents designed for diverse tasks such as coding and web browsing. As these agents become more capable, the need for a robust framework that facilitates global communication and collaboration among them towards advanced objectives has become increasingly critical. Distributed Agents in a Worldwide Network (DAWN) addresses this need by offering a versatile framework that integrates LLM-based agents with traditional software systems, enabling the creation of agentic applications suited for a wide range of use cases. DAWN enables distributed agents worldwide to register and be easily discovered through Gateway Agents. Collaborations among these agents are coordinated by a Principal Agent equipped with reasoning strategies. DAWN offers three operational modes: No-LLM Mode for deterministic tasks, Copilot for augmented decision-making, and LLM Agent for autonomous operations. Additionally, DAWN ensures the safety and security of agent collaborations globally through a dedicated safety, security, and compliance layer, protecting the network against attackers and adhering to stringent security and compliance standards. These features make DAWN a robust network for deploying agent-based applications across various industries.", "published": "2024-10-31 04:00:00", "id": "e6b28a67-af76-40e6-b2a8-77e0cd11fe53", "source": "arxiv", "section": "computerScience"}, {"title": "Improving the accuracy of food security predictions by integrating conflict data", "link": "https://arxiv.org/abs/2410.22342", "description": "arXiv:2410.22342v1 Announce Type: new \nAbstract: Violence and armed conflicts have emerged as prominent factors driving food crises. However, the extent of their impact remains largely unexplored. This paper provides an in-depth analysis of the impact of violent conflicts on food security in Africa. We performed a comprehensive correlation analysis using data from the Famine Early Warning Systems Network (FEWSNET) and the Armed Conflict Location Event Data (ACLED). Our results show that using conflict data to train machine learning models leads to a 1.5% increase in accuracy compared to models that do not incorporate conflict-related information. The key contribution of this study is the quantitative analysis of the impact of conflicts on food security predictions.", "published": "2024-10-31 04:00:00", "id": "c2182b40-eb78-476b-aab3-bf3ec1d6754e", "source": "arxiv", "section": "computerScience"}, {"title": "RealCQA-V2 : Visual Premise Proving", "link": "https://arxiv.org/abs/2410.22492", "description": "arXiv:2410.22492v1 Announce Type: new \nAbstract: We introduce Visual Premise Proving (VPP), a novel task tailored to refine the process of chart question answering by deconstructing it into a series of logical premises. Each of these premises represents an essential step in comprehending a chart's content and deriving logical conclusions, thereby providing a granular look at a model's reasoning abilities. This approach represents a departure from conventional accuracy-based evaluation methods, emphasizing the model's ability to sequentially validate each premise and ideally mimic human analytical processes. A model adept at reasoning is expected to demonstrate proficiency in both data retrieval and the structural understanding of charts, suggesting a synergy between these competencies. However, in our zero-shot study using the sophisticated MATCHA model on a scientific chart question answering dataset, an intriguing pattern emerged. The model showcased superior performance in chart reasoning (27\\%) over chart structure (19\\%) and data retrieval (14\\%). This performance gap suggests that models might more readily generalize reasoning capabilities across datasets, benefiting from consistent mathematical and linguistic semantics, even when challenged by changes in the visual domain that complicate structure comprehension and data retrieval. Furthermore, the efficacy of using accuracy of binary QA for evaluating chart reasoning comes into question if models can deduce correct answers without parsing chart data or structure. VPP highlights the importance of integrating reasoning with visual comprehension to enhance model performance in chart analysis, pushing for a balanced approach in evaluating visual data interpretation capabilities.", "published": "2024-10-31 04:00:00", "id": "361ca820-625c-4fdf-aa01-2e8bd5db971e", "source": "arxiv", "section": "computerScience"}, {"title": "Embedding Watermarks in Diffusion Process for Model Intellectual Property Protection", "link": "https://arxiv.org/abs/2410.22445", "description": "arXiv:2410.22445v1 Announce Type: new \nAbstract: In practical application, the widespread deployment of diffusion models often necessitates substantial investment in training. As diffusion models find increasingly diverse applications, concerns about potential misuse highlight the imperative for robust intellectual property protection. Current protection strategies either employ backdoor-based methods, integrating a watermark task as a simpler training objective with the main model task, or embedding watermarks directly into the final output samples. However, the former approach is fragile compared to existing backdoor defense techniques, while the latter fundamentally alters the expected output. In this work, we introduce a novel watermarking framework by embedding the watermark into the whole diffusion process, and theoretically ensure that our final output samples contain no additional information. Furthermore, we utilize statistical algorithms to verify the watermark from internally generated model samples without necessitating triggers as conditions. Detailed theoretical analysis and experimental validation demonstrate the effectiveness of our proposed method.", "published": "2024-10-31 04:00:00", "id": "414e08c7-1ce9-4415-aacf-2cbd922c57de", "source": "arxiv", "section": "computerScience"}, {"title": "Unified Domain Generalization and Adaptation for Multi-View 3D Object Detection", "link": "https://arxiv.org/abs/2410.22461", "description": "arXiv:2410.22461v1 Announce Type: new \nAbstract: Recent advances in 3D object detection leveraging multi-view cameras have demonstrated their practical and economical value in various challenging vision tasks. However, typical supervised learning approaches face challenges in achieving satisfactory adaptation toward unseen and unlabeled target datasets (\\ie, direct transfer) due to the inevitable geometric misalignment between the source and target domains. In practice, we also encounter constraints on resources for training models and collecting annotations for the successful deployment of 3D object detectors. In this paper, we propose Unified Domain Generalization and Adaptation (UDGA), a practical solution to mitigate those drawbacks. We first propose Multi-view Overlap Depth Constraint that leverages the strong association between multi-view, significantly alleviating geometric gaps due to perspective view changes. Then, we present a Label-Efficient Domain Adaptation approach to handle unfamiliar targets with significantly fewer amounts of labels (\\ie, 1$\\%$ and 5$\\%)$, while preserving well-defined source knowledge for training efficiency. Overall, UDGA framework enables stable detection performance in both source and target domains, effectively bridging inevitable domain gaps, while demanding fewer annotations. We demonstrate the robustness of UDGA with large-scale benchmarks: nuScenes, Lyft, and Waymo, where our framework outperforms the current state-of-the-art methods.", "published": "2024-10-31 04:00:00", "id": "1e677dea-ff10-4238-981c-768aea9240a8", "source": "arxiv", "section": "computerScience"}, {"title": "Project MPG: towards a generalized performance benchmark for LLM capabilities", "link": "https://arxiv.org/abs/2410.22368", "description": "arXiv:2410.22368v1 Announce Type: new \nAbstract: There exists an extremely wide array of LLM benchmarking tasks, whereas oftentimes a single number is the most actionable for decision-making, especially by non-experts. No such aggregation schema exists that is not Elo-based, which could be costly or time-consuming. Here we propose a method to aggregate performance across a general space of benchmarks, nicknamed Project \"MPG,\" dubbed Model Performance and Goodness, additionally referencing a metric widely understood to be an important yet inaccurate and crude measure of car performance. Here, we create two numbers: a \"Goodness\" number (answer accuracy) and a \"Fastness\" number (cost or QPS). We compare models against each other and present a ranking according to our general metric as well as subdomains. We find significant agreement between the raw Pearson correlation of our scores and those of Chatbot Arena, even improving on the correlation of the MMLU leaderboard to Chatbot Arena.", "published": "2024-10-31 04:00:00", "id": "3ebb4745-2238-4b99-a064-bcef7f219d65", "source": "arxiv", "section": "computerScience"}, {"title": "Predicting Future Actions of Reinforcement Learning Agents", "link": "https://arxiv.org/abs/2410.22459", "description": "arXiv:2410.22459v1 Announce Type: new \nAbstract: As reinforcement learning agents become increasingly deployed in real-world scenarios, predicting future agent actions and events during deployment is important for facilitating better human-agent interaction and preventing catastrophic outcomes. This paper experimentally evaluates and compares the effectiveness of future action and event prediction for three types of RL agents: explicitly planning, implicitly planning, and non-planning. We employ two approaches: the inner state approach, which involves predicting based on the inner computations of the agents (e.g., plans or neuron activations), and a simulation-based approach, which involves unrolling the agent in a learned world model. Our results show that the plans of explicitly planning agents are significantly more informative for prediction than the neuron activations of the other types. Furthermore, using internal plans proves more robust to model quality compared to simulation-based approaches when predicting actions, while the results for event prediction are more mixed. These findings highlight the benefits of leveraging inner states and simulations to predict future agent actions and events, thereby improving interaction and safety in real-world deployments.", "published": "2024-10-31 04:00:00", "id": "17be85b8-3b3c-4b9c-a7ff-75759b3f5459", "source": "arxiv", "section": "computerScience"}, {"title": "Heterogeneous Team Coordination on Partially Observable Graphs with Realistic Communication", "link": "https://arxiv.org/abs/2410.22482", "description": "arXiv:2410.22482v1 Announce Type: new \nAbstract: Team Coordination on Graphs with Risky Edges (\\textsc{tcgre}) is a recently proposed problem, in which robots find paths to their goals while considering possible coordination to reduce overall team cost. However, \\textsc{tcgre} assumes that the \\emph{entire} environment is available to a \\emph{homogeneous} robot team with \\emph{ubiquitous} communication. In this paper, we study an extended version of \\textsc{tcgre}, called \\textsc{hpr-tcgre}, with three relaxations: Heterogeneous robots, Partial observability, and Realistic communication. To this end, we form a new combinatorial optimization problem on top of \\textsc{tcgre}. After analysis, we divide it into two sub-problems, one for robots moving individually, another for robots in groups, depending on their communication availability. Then, we develop an algorithm that exploits real-time partial maps to solve local shortest path(s) problems, with a A*-like sub-goal(s) assignment mechanism that explores potential coordination opportunities for global interests. Extensive experiments indicate that our algorithm is able to produce team coordination behaviors in order to reduce overall cost even with our three relaxations.", "published": "2024-10-31 04:00:00", "id": "7093e1f5-b6ff-4b8b-81a8-a675565e28b4", "source": "arxiv", "section": "computerScience"}, {"title": "ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models", "link": "https://arxiv.org/abs/2410.22360", "description": "arXiv:2410.22360v1 Announce Type: new \nAbstract: When conducting literature reviews, scientists often create literature review tables - tables whose rows are publications and whose columns constitute a schema, a set of aspects used to compare and contrast the papers. Can we automatically generate these tables using language models (LMs)? In this work, we introduce a framework that leverages LMs to perform this task by decomposing it into separate schema and value generation steps. To enable experimentation, we address two main challenges: First, we overcome a lack of high-quality datasets to benchmark table generation by curating and releasing arxivDIGESTables, a new dataset of 2,228 literature review tables extracted from ArXiv papers that synthesize a total of 7,542 research papers. Second, to support scalable evaluation of model generations against human-authored reference tables, we develop DecontextEval, an automatic evaluation method that aligns elements of tables with the same underlying aspects despite differing surface forms. Given these tools, we evaluate LMs' abilities to reconstruct reference tables, finding this task benefits from additional context to ground the generation (e.g. table captions, in-text references). Finally, through a human evaluation study we find that even when LMs fail to fully reconstruct a reference table, their generated novel aspects can still be useful.", "published": "2024-10-31 04:00:00", "id": "62f60354-e721-4d5a-bf23-c34477c99f37", "source": "arxiv", "section": "computerScience"}, {"title": "Search Engines in an AI Era: The False Promise of Factual and Verifiable Source-Cited Responses", "link": "https://arxiv.org/abs/2410.22349", "description": "arXiv:2410.22349v1 Announce Type: new \nAbstract: Large Language Model (LLM)-based applications are graduating from research prototypes to products serving millions of users, influencing how people write and consume information. A prominent example is the appearance of Answer Engines: LLM-based generative search engines supplanting traditional search engines. Answer engines not only retrieve relevant sources to a user query but synthesize answer summaries that cite the sources. To understand these systems' limitations, we first conducted a study with 21 participants, evaluating interactions with answer vs. traditional search engines and identifying 16 answer engine limitations. From these insights, we propose 16 answer engine design recommendations, linked to 8 metrics. An automated evaluation implementing our metrics on three popular engines (You.com, Perplexity.ai, BingChat) quantifies common limitations (e.g., frequent hallucination, inaccurate citation) and unique features (e.g., variation in answer confidence), with results mirroring user study insights. We release our Answer Engine Evaluation benchmark (AEE) to facilitate transparent evaluation of LLM-based applications.", "published": "2024-10-31 04:00:00", "id": "3af68ee4-8931-40a5-99c9-20b391fb716f", "source": "arxiv", "section": "computerScience"}, {"title": "A Large Recurrent Action Model: xLSTM enables Fast Inference for Robotics Tasks", "link": "https://arxiv.org/abs/2410.22391", "description": "arXiv:2410.22391v1 Announce Type: new \nAbstract: In recent years, there has been a trend in the field of Reinforcement Learning (RL) towards large action models trained offline on large-scale datasets via sequence modeling. Existing models are primarily based on the Transformer architecture, which result in powerful agents. However, due to slow inference times, Transformer-based approaches are impractical for real-time applications, such as robotics. Recently, modern recurrent architectures, such as xLSTM and Mamba, have been proposed that exhibit parallelization benefits during training similar to the Transformer architecture while offering fast inference. In this work, we study the aptitude of these modern recurrent architectures for large action models. Consequently, we propose a Large Recurrent Action Model (LRAM) with an xLSTM at its core that comes with linear-time inference complexity and natural sequence length extrapolation abilities. Experiments on 432 tasks from 6 domains show that LRAM compares favorably to Transformers in terms of performance and speed.", "published": "2024-10-31 04:00:00", "id": "80e194cc-df3f-4570-8dae-dff44e5c2866", "source": "arxiv", "section": "computerScience"}, {"title": "Machine Unlearning using Forgetting Neural Networks", "link": "https://arxiv.org/abs/2410.22374", "description": "arXiv:2410.22374v1 Announce Type: new \nAbstract: Modern computer systems store vast amounts of personal data, enabling advances in AI and ML but risking user privacy and trust. For privacy reasons, it is desired sometimes for an ML model to forget part of the data it was trained on. This paper presents a new approach to machine unlearning using forgetting neural networks (FNN). FNNs are neural networks with specific forgetting layers, that take inspiration from the processes involved when a human brain forgets. While FNNs had been proposed as a theoretical construct, they have not been previously used as a machine unlearning method. We describe four different types of forgetting layers and study their properties. In our experimental evaluation, we report our results on the MNIST handwritten digit recognition and fashion datasets. The effectiveness of the unlearned models was tested using Membership Inference Attacks (MIA). Successful experimental results demonstrate the great potential of our proposed method for dealing with the machine unlearning problem.", "published": "2024-10-31 04:00:00", "id": "9263d244-0694-46d2-83e7-c4f89bbcec7f", "source": "arxiv", "section": "computerScience"}, {"title": "Using Normalization to Improve SMT Solver Stability", "link": "https://arxiv.org/abs/2410.22419", "description": "arXiv:2410.22419v1 Announce Type: new \nAbstract: In many applications, SMT solvers are used to solve similar or identical tasks over time. When the performance of the solver varies significantly despite only small changes, this leads to frustration for users. This has been called the stability problem, and it represents an important usability challenge for SMT solvers. In this paper, we introduce an approach for mitigating the stability problem based on normalizing solver inputs. We show that a perfect normalizing algorithm exists but is computationally expensive. We then describe an approximate algorithm and evaluate it on a set of benchmarks from related work, as well as a large set of benchmarks sampled from SMT-LIB. Our evaluation shows that our approximate normalizer reduces runtime variability with minimal overhead and is able to normalize a large class of mutated benchmarks to a unique normal form.", "published": "2024-10-31 04:00:00", "id": "a7c48125-d053-4006-84ba-8ff6b8948ac7", "source": "arxiv", "section": "computerScience"}, {"title": "Testing GPT-4-o1-preview on math and science problems: A follow-up study", "link": "https://arxiv.org/abs/2410.22340", "description": "arXiv:2410.22340v1 Announce Type: new \nAbstract: In August 2023, Scott Aaronson and I reported the results of testing GPT4 with the Wolfram Alpha and Code Interpreter plug-ins over a collection of 105 original high-school level and college-level science and math problems (Davis and Aaronson, 2023). In September 2024, I tested the recently released model GPT-4o1-preview on the same collection. Overall I found that performance had significantly improved, but was still considerably short of perfect. In particular, problems that involve spatial reasoning are often stumbling blocks.", "published": "2024-10-31 04:00:00", "id": "93611a7a-df7f-4e38-a429-93cb0972ed34", "source": "arxiv", "section": "computerScience"}, {"title": "Brain age identification from diffusion MRI synergistically predicts neurodegenerative disease", "link": "https://arxiv.org/abs/2410.22454", "description": "arXiv:2410.22454v1 Announce Type: new \nAbstract: Estimated brain age from magnetic resonance image (MRI) and its deviation from chronological age can provide early insights into potential neurodegenerative diseases, supporting early detection and implementation of prevention strategies. Diffusion MRI (dMRI), a widely used modality for brain age estimation, presents an opportunity to build an earlier biomarker for neurodegenerative disease prediction because it captures subtle microstructural changes that precede more perceptible macrostructural changes. However, the coexistence of macro- and micro-structural information in dMRI raises the question of whether current dMRI-based brain age estimation models are leveraging the intended microstructural information or if they inadvertently rely on the macrostructural information. To develop a microstructure-specific brain age, we propose a method for brain age identification from dMRI that minimizes the model's use of macrostructural information by non-rigidly registering all images to a standard template. Imaging data from 13,398 participants across 12 datasets were used for the training and evaluation. We compare our brain age models, trained with and without macrostructural information minimized, with an architecturally similar T1-weighted (T1w) MRI-based brain age model and two state-of-the-art T1w MRI-based brain age models that primarily use macrostructural information. We observe difference between our dMRI-based brain age and T1w MRI-based brain age across stages of neurodegeneration, with dMRI-based brain age being older than T1w MRI-based brain age in participants transitioning from cognitively normal (CN) to mild cognitive impairment (MCI), but younger in participants already diagnosed with Alzheimer's disease (AD). Approximately 4 years before MCI diagnosis, dMRI-based brain age yields better performance than T1w MRI-based brain ages in predicting transition from CN to MCI.", "published": "2024-10-31 04:00:00", "id": "0282189d-bae8-4004-bd7c-b05fa5042edf", "source": "arxiv", "section": "computerScience"}, {"title": "A Hierarchical Language Model For Interpretable Graph Reasoning", "link": "https://arxiv.org/abs/2410.22372", "description": "arXiv:2410.22372v1 Announce Type: new \nAbstract: Large language models (LLMs) are being increasingly explored for graph tasks. Despite their remarkable success in text-based tasks, LLMs' capabilities in understanding explicit graph structures remain limited, particularly with large graphs. In this work, we introduce Hierarchical Language Model for Graph (HLM-G), which employs a two-block architecture to capture node-centric local information and interaction-centric global structure, effectively enhancing graph structure understanding abilities. The proposed scheme allows LLMs to address various graph queries with high efficacy, efficiency, and robustness, while reducing computational costs on large-scale graph tasks. Furthermore, we demonstrate the interpretability of our model using intrinsic attention weights and established explainers. Comprehensive evaluations across diverse graph reasoning and real-world tasks of node, link, and graph-levels highlight the superiority of our method, marking a significant advancement in the application of LLMs to graph understanding.", "published": "2024-10-31 04:00:00", "id": "160080a6-507d-4048-b424-e72491ee02ed", "source": "arxiv", "section": "computerScience"}, {"title": "Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance", "link": "https://arxiv.org/abs/2410.22376", "description": "arXiv:2410.22376v1 Announce Type: new \nAbstract: State-of-the-art text-to-image (T2I) diffusion models often struggle to generate rare compositions of concepts, e.g., objects with unusual attributes. In this paper, we show that the compositional generation power of diffusion models on such rare concepts can be significantly enhanced by the Large Language Model (LLM) guidance. We start with empirical and theoretical analysis, demonstrating that exposing frequent concepts relevant to the target rare concepts during the diffusion sampling process yields more accurate concept composition. Based on this, we propose a training-free approach, R2F, that plans and executes the overall rare-to-frequent concept guidance throughout the diffusion inference by leveraging the abundant semantic knowledge in LLMs. Our framework is flexible across any pre-trained diffusion models and LLMs, and can be seamlessly integrated with the region-guided diffusion approaches. Extensive experiments on three datasets, including our newly proposed benchmark, RareBench, containing various prompts with rare compositions of concepts, R2F significantly surpasses existing models including SD3.0 and FLUX by up to 28.1%p in T2I alignment. Code is available at https://github.com/krafton-ai/Rare2Frequent.", "published": "2024-10-31 04:00:00", "id": "8ab076a4-e832-4358-859b-f19ae9d7f6e3", "source": "arxiv", "section": "computerScience"}, {"title": "Accelerating Augmentation Invariance Pretraining", "link": "https://arxiv.org/abs/2410.22364", "description": "arXiv:2410.22364v1 Announce Type: new \nAbstract: Our work tackles the computational challenges of contrastive learning methods, particularly for the pretraining of Vision Transformers (ViTs). Despite the effectiveness of contrastive learning, the substantial computational resources required for training often hinder their practical application. To mitigate this issue, we propose an acceleration framework, leveraging ViT's unique ability to generalize across inputs of varying sequence lengths. Our method employs a mix of sequence compression strategies, including randomized token dropout and flexible patch scaling, to reduce the cost of gradient estimation and accelerate convergence. We further provide an in-depth analysis of the gradient estimation error of various acceleration strategies as well as their impact on downstream tasks, offering valuable insights into the trade-offs between acceleration and performance.\n  We also propose a novel procedure to identify an optimal acceleration schedule to adjust the sequence compression ratios to the training progress, ensuring efficient training without sacrificing downstream performance. Our approach significantly reduces computational overhead across various self-supervised learning algorithms on large-scale datasets. In ImageNet, our method achieves speedups of 4$\\times$ in MoCo, 3.3$\\times$ in SimCLR, and 2.5$\\times$ in DINO, demonstrating substantial efficiency gains.", "published": "2024-10-31 04:00:00", "id": "522d4257-9712-4213-b95b-aa85ef4e53f1", "source": "arxiv", "section": "computerScience"}, {"title": "Neuromorphic Programming: Emerging Directions for Brain-Inspired Hardware", "link": "https://arxiv.org/abs/2410.22352", "description": "arXiv:2410.22352v1 Announce Type: new \nAbstract: The value of brain-inspired neuromorphic computers critically depends on our ability to program them for relevant tasks. Currently, neuromorphic hardware often relies on machine learning methods adapted from deep learning. However, neuromorphic computers have potential far beyond deep learning if we can only harness their energy efficiency and full computational power. Neuromorphic programming will necessarily be different from conventional programming, requiring a paradigm shift in how we think about programming. This paper presents a conceptual analysis of programming within the context of neuromorphic computing, challenging conventional paradigms and proposing a framework that aligns more closely with the physical intricacies of these systems. Our analysis revolves around five characteristics that are fundamental to neuromorphic programming and provides a basis for comparison to contemporary programming methods and languages. By studying past approaches, we contribute a framework that advocates for underutilized techniques and calls for richer abstractions to effectively instrument the new hardware class.", "published": "2024-10-31 04:00:00", "id": "8335622e-ded5-4c7d-a19b-0c486d915a02", "source": "arxiv", "section": "computerScience"}, {"title": "Power side-channel leakage localization through adversarial training of deep neural networks", "link": "https://arxiv.org/abs/2410.22425", "description": "arXiv:2410.22425v1 Announce Type: new \nAbstract: Supervised deep learning has emerged as an effective tool for carrying out power side-channel attacks on cryptographic implementations. While increasingly-powerful deep learning-based attacks are regularly published, comparatively-little work has gone into using deep learning to defend against these attacks. In this work we propose a technique for identifying which timesteps in a power trace are responsible for leaking a cryptographic key, through an adversarial game between a deep learning-based side-channel attacker which seeks to classify a sensitive variable from the power traces recorded during encryption, and a trainable noise generator which seeks to thwart this attack by introducing a minimal amount of noise into the power traces. We demonstrate on synthetic datasets that our method can outperform existing techniques in the presence of common countermeasures such as Boolean masking and trace desynchronization. Results on real datasets are weak because the technique is highly sensitive to hyperparameters and early-stop point, and we lack a holdout dataset with ground truth knowledge of leaking points for model selection. Nonetheless, we believe our work represents an important first step towards deep side-channel leakage localization without relying on strong assumptions about the implementation or the nature of its leakage. An open-source PyTorch implementation of our experiments is provided.", "published": "2024-10-31 04:00:00", "id": "eba14077-d429-462b-9bfd-dac80ea60c5c", "source": "arxiv", "section": "computerScience"}, {"title": "Lecture Notes on Grid Modeling of Renewable Energy", "link": "https://arxiv.org/abs/2410.22361", "description": "arXiv:2410.22361v1 Announce Type: new \nAbstract: These lecture notes provide a comprehensive guide on Grid Modeling of Renewable Energy, offering a foundational overview of power system network modeling, power flow, and load flow algorithms critical for electrical and renewable energy engineering. Key topics include steady-state, dynamic, and frequency domain models, with a particular focus on renewable energy integration, simulation techniques, and their effects on grid stability and power quality. Practical examples using Matpower and Pandapower tools are included to reinforce concepts, ensuring that students gain hands-on experience in modeling and analyzing modern energy systems under variable conditions.", "published": "2024-10-31 04:00:00", "id": "9ac7423e-f274-4d6c-a129-a5bc35d57169", "source": "arxiv", "section": "computerScience"}, {"title": "FNDEX: Fake News and Doxxing Detection with Explainable AI", "link": "https://arxiv.org/abs/2410.22390", "description": "arXiv:2410.22390v1 Announce Type: new \nAbstract: The widespread and diverse online media platforms and other internet-driven communication technologies have presented significant challenges in defining the boundaries of freedom of expression. Consequently, the internet has been transformed into a potential cyber weapon. Within this evolving landscape, two particularly hazardous phenomena have emerged: fake news and doxxing. Although these threats have been subjects of extensive scholarly analysis, the crossroads where they intersect remain unexplored. This research addresses this convergence by introducing a novel system. The Fake News and Doxxing Detection with Explainable Artificial Intelligence (FNDEX) system leverages the capabilities of three distinct transformer models to achieve high-performance detection for both fake news and doxxing. To enhance data security, a rigorous three-step anonymization process is employed, rooted in a pattern-based approach for anonymizing personally identifiable information. Finally, this research emphasizes the importance of generating coherent explanations for the outcomes produced by both detection models. Our experiments on realistic datasets demonstrate that our system significantly outperforms the existing baselines", "published": "2024-10-31 04:00:00", "id": "11d208f2-5f69-47fd-b5aa-1690d4f280ad", "source": "arxiv", "section": "computerScience"}, {"title": "Mobile Phone Application Data for Activity Plan Generation", "link": "https://arxiv.org/abs/2410.22386", "description": "arXiv:2410.22386v1 Announce Type: new \nAbstract: Activity-based models in transport are crucial for providing a comprehensive and realistic understanding of individuals' activity-travel patterns. Traditionally, travel surveys have been used to develop these models, but they are often costly and have small sample sizes. Mobile phone application data, one example of emerging data sources, offers an alternative with wider population coverage over extended periods for developing activity-based models. However, the challenges of using these data include sampling biases in the population coverage and individual-level data sparsity due to intermittent and irregular data collection. To synthesise activity-travel plans, we propose a novel model that combines mobile phone application data with travel survey data, addressing their limitations. Our generative model simulates multiple average weekday activity schedules for over 263,000 individuals living in Sweden, approximately 2.6% of Sweden's population. We also introduce a temporal-score approach to improve home and work location identification approaches. We assess the model's performance against an existing large-scale agent-based model of Sweden (SySMo) and a dummy model using only mobile application data. The generated activity-travel plans are comparable to the SySMo model's output and significantly surpass the dummy model's results, suggesting the proposed model's capability to generate reasonable activity-travel schedules. The proposed model is adaptable to other regions with similar travel surveys and emerging data sources, like call detail records, advancing the use of these data for activity-based models in a cost-effective, easily updated manner.", "published": "2024-10-31 04:00:00", "id": "c9bad48d-afb7-4116-a37f-74556a67f789", "source": "arxiv", "section": "computerScience"}, {"title": "Unlocking Point Processes through Point Set Diffusion", "link": "https://arxiv.org/abs/2410.22493", "description": "arXiv:2410.22493v1 Announce Type: new \nAbstract: Point processes model the distribution of random point sets in mathematical spaces, such as spatial and temporal domains, with applications in fields like seismology, neuroscience, and economics. Existing statistical and machine learning models for point processes are predominantly constrained by their reliance on the characteristic intensity function, introducing an inherent trade-off between efficiency and flexibility. In this paper, we introduce Point Set Diffusion, a diffusion-based latent variable model that can represent arbitrary point processes on general metric spaces without relying on the intensity function. By directly learning to stochastically interpolate between noise and data point sets, our approach enables efficient, parallel sampling and flexible generation for complex conditional tasks defined on the metric space. Experiments on synthetic and real-world datasets demonstrate that Point Set Diffusion achieves state-of-the-art performance in unconditional and conditional generation of spatial and spatiotemporal point processes while providing up to orders of magnitude faster sampling than autoregressive baselines.", "published": "2024-10-31 04:00:00", "id": "60291e46-ccd2-4013-a507-6f0c92a03708", "source": "arxiv", "section": "computerScience"}, {"title": "Anticipating Future with Large Language Model for Simultaneous Machine Translation", "link": "https://arxiv.org/abs/2410.22499", "description": "arXiv:2410.22499v1 Announce Type: new \nAbstract: Simultaneous machine translation (SMT) takes streaming input utterances and incrementally produces target text. Existing SMT methods only use the partial utterance that has already arrived at the input and the generated hypothesis. Motivated by human interpreters' technique to forecast future words before hearing them, we propose $\\textbf{T}$ranslation by $\\textbf{A}$nticipating $\\textbf{F}$uture (TAF), a method to improve translation quality while retraining low latency. Its core idea is to use a large language model (LLM) to predict future source words and opportunistically translate without introducing too much risk. We evaluate our TAF and multiple baselines of SMT on four language directions. Experiments show that TAF achieves the best translation quality-latency trade-off and outperforms the baselines by up to 5 BLEU points at the same latency (three words).", "published": "2024-10-31 04:00:00", "id": "88a0e5c2-f854-40bb-b674-d5ad246e5781", "source": "arxiv", "section": "computerScience"}, {"title": "AffectNet+: A Database for Enhancing Facial Expression Recognition with Soft-Labels", "link": "https://arxiv.org/abs/2410.22506", "description": "arXiv:2410.22506v1 Announce Type: new \nAbstract: Automated Facial Expression Recognition (FER) is challenging due to intra-class variations and inter-class similarities. FER can be especially difficult when facial expressions reflect a mixture of various emotions (aka compound expressions). Existing FER datasets, such as AffectNet, provide discrete emotion labels (hard-labels), where a single category of emotion is assigned to an expression. To alleviate inter- and intra-class challenges, as well as provide a better facial expression descriptor, we propose a new approach to create FER datasets through a labeling method in which an image is labeled with more than one emotion (called soft-labels), each with different confidences. Specifically, we introduce the notion of soft-labels for facial expression datasets, a new approach to affective computing for more realistic recognition of facial expressions. To achieve this goal, we propose a novel methodology to accurately calculate soft-labels: a vector representing the extent to which multiple categories of emotion are simultaneously present within a single facial expression. Finding smoother decision boundaries, enabling multi-labeling, and mitigating bias and imbalanced data are some of the advantages of our proposed method. Building upon AffectNet, we introduce AffectNet+, the next-generation facial expression dataset. This dataset contains soft-labels, three categories of data complexity subsets, and additional metadata such as age, gender, ethnicity, head pose, facial landmarks, valence, and arousal. AffectNet+ will be made publicly accessible to researchers.", "published": "2024-10-31 04:00:00", "id": "080f3834-332c-4100-8a6d-b2c454d1d7c1", "source": "arxiv", "section": "computerScience"}, {"title": "Attention Speaks Volumes: Localizing and Mitigating Bias in Language Models", "link": "https://arxiv.org/abs/2410.22517", "description": "arXiv:2410.22517v1 Announce Type: new \nAbstract: We explore the internal mechanisms of how bias emerges in large language models (LLMs) when provided with ambiguous comparative prompts: inputs that compare or enforce choosing between two or more entities without providing clear context for preference. Most approaches for bias mitigation focus on either post-hoc analysis or data augmentation. However, these are transient solutions, without addressing the root cause: the model itself. Numerous prior works show the influence of the attention module towards steering generations. We believe that analyzing attention is also crucial for understanding bias, as it provides insight into how the LLM distributes its focus across different entities and how this contributes to biased decisions. To this end, we first introduce a metric to quantify the LLM's preference for one entity over another. We then propose $\\texttt{ATLAS}$ (Attention-based Targeted Layer Analysis and Scaling), a technique to localize bias to specific layers of the LLM by analyzing attention scores and then reduce bias by scaling attention in these biased layers. To evaluate our method, we conduct experiments across 3 datasets (BBQ, Crows-Pairs, and WinoGender) using $\\texttt{GPT-2 XL}$ (1.5B), $\\texttt{GPT-J}$ (6B), $\\texttt{LLaMA-2}$ (7B) and $\\texttt{LLaMA-3}$ (8B). Our experiments demonstrate that bias is concentrated in the later layers, typically around the last third. We also show how $\\texttt{ATLAS}$ effectively mitigates bias through targeted interventions without compromising downstream performance and an average increase of only 0.82% in perplexity when the intervention is applied. We see an average improvement of 0.28 points in the bias score across all the datasets.", "published": "2024-10-31 04:00:00", "id": "a7b75e36-0e58-4fce-b853-c4015005e6b5", "source": "arxiv", "section": "computerScience"}, {"title": "Multimodal Structure Preservation Learning", "link": "https://arxiv.org/abs/2410.22520", "description": "arXiv:2410.22520v1 Announce Type: new \nAbstract: When selecting data to build machine learning models in practical applications, factors such as availability, acquisition cost, and discriminatory power are crucial considerations. Different data modalities often capture unique aspects of the underlying phenomenon, making their utilities complementary. On the other hand, some sources of data host structural information that is key to their value. Hence, the utility of one data type can sometimes be enhanced by matching the structure of another. We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality. We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications. The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities.", "published": "2024-10-31 04:00:00", "id": "77c517d9-b2e6-4e59-b99f-74c43bc4a8f9", "source": "arxiv", "section": "computerScience"}, {"title": "Lyapunov Characterization for ISS of Impulsive Switched Systems", "link": "https://arxiv.org/abs/2410.22521", "description": "arXiv:2410.22521v1 Announce Type: new \nAbstract: In this study, we investigate the ISS of impulsive switched systems that have modes with both stable and unstable flows. We assume that the switching signal satisfies mode-dependent average dwell and leave time conditions. To establish ISS conditions, we propose two types of time-varying ISS-Lyapunov functions: one that is non-decreasing and another one that is decreasing. Our research proves that the existence of either of these ISS-Lyapunov functions is a necessary and sufficient condition for ISS. We also present a technique for constructing a decreasing ISS-Lyapunov function from a non-decreasing one, which is useful for its own sake. Our findings also have added value to previous research that only studied sufficient conditions for ISS, as our results apply to a broader class of systems. This is because we impose less restrictive dwell and leave time constraints on the switching signal and our ISS-Lyapunov functions are time-varying with general nonlinear conditions imposed on them. Moreover, we provide a method to guarantee the ISS of a particular class of impulsive switched systems when the switching signal is unknown.", "published": "2024-10-31 04:00:00", "id": "4d393d1b-1189-45fd-97af-50ebb8e2ac5f", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient Learned Query Execution over Text and Tables [Technical Report]", "link": "https://arxiv.org/abs/2410.22522", "description": "arXiv:2410.22522v1 Announce Type: new \nAbstract: In this paper, we present ELEET, a novel execution engine that allows one to seamlessly query and process text as a first-class citizen along with tables. To enable such a seamless integration of text and tables, ELEET leverages learned multi-modal operators (MMOps) such as joins and unions that seamlessly combine structured with unstructured textual data. While large language models (LLM) such as GPT-4 are interesting candidates to enable such learned multimodal operations, we deliberately do not follow this trend to enable MMOps, since it would result in high overhead at query runtime. Instead, to enable MMOps, ELEET comes with a more efficient small language model (SLM) that is targeted to extract structured data from text. Thanks to our novel architecture and pre-training procedure, the ELEET-model enables high-accuracy extraction with low overheads. In our evaluation, we compare query execution based on ELEET to baselines leveraging LLMs such as GPT-4 and show that ELEET can speed up multi-modal queries over tables and text by up to 575x without sacrificing accuracy.", "published": "2024-10-31 04:00:00", "id": "6cf70838-a387-4257-b557-ec1b071d8086", "source": "arxiv", "section": "computerScience"}, {"title": "Hindsight Experience Replay Accelerates Proximal Policy Optimization", "link": "https://arxiv.org/abs/2410.22524", "description": "arXiv:2410.22524v1 Announce Type: new \nAbstract: Hindsight experience replay (HER) accelerates off-policy reinforcement learning algorithms for environments that emit sparse rewards by modifying the goal of the episode post-hoc to be some state achieved during the episode. Because post-hoc modification of the observed goal violates the assumptions of on-policy algorithms, HER is not typically applied to on-policy algorithms. Here, we show that HER can dramatically accelerate proximal policy optimization (PPO), an on-policy reinforcement learning algorithm, when tested on a custom predator-prey environment.", "published": "2024-10-31 04:00:00", "id": "43f5887d-222f-4b89-a539-10ffcfa77220", "source": "arxiv", "section": "computerScience"}, {"title": "From Silos to Systems: Process-Oriented Hazard Analysis for AI Systems", "link": "https://arxiv.org/abs/2410.22526", "description": "arXiv:2410.22526v1 Announce Type: new \nAbstract: To effectively address potential harms from AI systems, it is essential to identify and mitigate system-level hazards. Current analysis approaches focus on individual components of an AI system, like training data or models, in isolation, overlooking hazards from component interactions or how they are situated within a company's development process. To this end, we draw from the established field of system safety, which considers safety as an emergent property of the entire system, not just its components. In this work, we translate System Theoretic Process Analysis (STPA) - a recognized system safety framework - for analyzing AI operation and development processes. We focus on systems that rely on machine learning algorithms and conducted STPA on three case studies involving linear regression, reinforcement learning, and transformer-based generative models. Our analysis explored how STPA's control and system-theoretic perspectives apply to AI systems and whether unique AI traits - such as model opacity, capability uncertainty, and output complexity - necessitate significant modifications to the framework. We find that the key concepts and steps of conducting an STPA readily apply, albeit with a few adaptations tailored for AI systems. We present the Process-oriented Hazard Analysis for AI Systems (PHASE) as a guideline that adapts STPA concepts for AI, making STPA-based hazard analysis more accessible. PHASE enables four key affordances for analysts responsible for managing AI system harms: 1) detection of hazards at the systems level, including those from accumulation of disparate issues; 2) explicit acknowledgment of social factors contributing to experiences of algorithmic harms; 3) creation of traceable accountability chains between harms and those who can mitigate the harm; and 4) ongoing monitoring and mitigation of new hazards.", "published": "2024-10-31 04:00:00", "id": "2d347b63-447a-41cc-a3db-e9f169e94f50", "source": "arxiv", "section": "computerScience"}, {"title": "Intelligent Mobility System with Integrated Motion Planning and Control Utilizing Infrastructure Sensor Nodes", "link": "https://arxiv.org/abs/2410.22527", "description": "arXiv:2410.22527v1 Announce Type: new \nAbstract: This paper introduces a framework for an indoor autonomous mobility system that can perform patient transfers and materials handling. Unlike traditional systems that rely on onboard perception sensors, the proposed approach leverages a global perception and localization (PL) through Infrastructure Sensor Nodes (ISNs) and cloud computing technology. Using the global PL, an integrated Model Predictive Control (MPC)-based local planning and tracking controller augmented with Artificial Potential Field (APF) is developed, enabling reliable and efficient motion planning and obstacle avoidance ability while tracking predefined reference motions. Simulation results demonstrate the effectiveness of the proposed MPC controller in smoothly navigating around both static and dynamic obstacles. The proposed system has the potential to extend to intelligent connected autonomous vehicles, such as electric or cargo transport vehicles with four-wheel independent drive/steering (4WID-4WIS) configurations.", "published": "2024-10-31 04:00:00", "id": "c5904017-f4fc-4094-84f5-d034818d0ec4", "source": "arxiv", "section": "computerScience"}, {"title": "A Demonic Outcome Logic for Randomized Nondeterminism", "link": "https://arxiv.org/abs/2410.22540", "description": "arXiv:2410.22540v1 Announce Type: new \nAbstract: Programs increasingly rely on randomization in applications such as cryptography and machine learning. Analyzing randomized programs has been a fruitful research direction, but there is a gap when programs also exploit nondeterminism (for concurrency, efficiency, or algorithmic design). In this paper, we introduce Demonic Outcome Logic for reasoning about programs that exploit both randomization and nondeterminism. The logic includes several novel features, such as reasoning about multiple executions in tandem and manipulating pre- and postconditions using familiar equational laws -- including the distributive law of probabilistic choices over nondeterministic ones. We also give rules for loops that both establish termination and quantify the distribution of final outcomes from a single premise. We illustrate the reasoning capabilities of Demonic Outcome Logic through several case studies, including the Monty Hall problem, an adversarial protocol for simulating fair coins, and a heuristic based probabilistic SAT solver.", "published": "2024-10-31 04:00:00", "id": "4f2fda16-b745-4d29-aeca-c505d67c342c", "source": "arxiv", "section": "computerScience"}, {"title": "FairSkin: Fair Diffusion for Skin Disease Image Generation", "link": "https://arxiv.org/abs/2410.22551", "description": "arXiv:2410.22551v1 Announce Type: new \nAbstract: Image generation is a prevailing technique for clinical data augmentation for advancing diagnostic accuracy and reducing healthcare disparities. Diffusion Model (DM) has become a leading method in generating synthetic medical images, but it suffers from a critical twofold bias: (1) The quality of images generated for Caucasian individuals is significantly higher, as measured by the Frechet Inception Distance (FID). (2) The ability of the downstream-task learner to learn critical features from disease images varies across different skin tones. These biases pose significant risks, particularly in skin disease detection, where underrepresentation of certain skin tones can lead to misdiagnosis or neglect of specific conditions. To address these challenges, we propose FairSkin, a novel DM framework that mitigates these biases through a three-level resampling mechanism, ensuring fairer representation across racial and disease categories. Our approach significantly improves the diversity and quality of generated images, contributing to more equitable skin disease detection in clinical settings.", "published": "2024-10-31 04:00:00", "id": "49331e21-a5f8-4662-97c7-bd70cb7036d5", "source": "arxiv", "section": "computerScience"}, {"title": "Auto-Intent: Automated Intent Discovery and Self-Exploration for Large Language Model Web Agents", "link": "https://arxiv.org/abs/2410.22552", "description": "arXiv:2410.22552v1 Announce Type: new \nAbstract: In this paper, we introduce Auto-Intent, a method to adapt a pre-trained large language model (LLM) as an agent for a target domain without direct fine-tuning, where we empirically focus on web navigation tasks. Our approach first discovers the underlying intents from target domain demonstrations unsupervisedly, in a highly compact form (up to three words). With the extracted intents, we train our intent predictor to predict the next intent given the agent's past observations and actions. In particular, we propose a self-exploration approach where top-k probable intent predictions are provided as a hint to the pre-trained LLM agent, which leads to enhanced decision-making capabilities. Auto-Intent substantially improves the performance of GPT-{3.5, 4} and Llama-3.1-{70B, 405B} agents on the large-scale real-website navigation benchmarks from Mind2Web and online navigation tasks from WebArena with its cross-benchmark generalization from Mind2Web.", "published": "2024-10-31 04:00:00", "id": "7a4dd9f5-f29f-413c-93a0-b7748c6d56e5", "source": "arxiv", "section": "computerScience"}, {"title": "ML Research Benchmark", "link": "https://arxiv.org/abs/2410.22553", "description": "arXiv:2410.22553v1 Announce Type: new \nAbstract: Artificial intelligence agents are increasingly capable of performing complex tasks across various domains. As these agents advance, there is a growing need to accurately measure and benchmark their capabilities, particularly in accelerating AI research and development. Current benchmarks focus on general machine learning tasks, but lack comprehensive evaluation methods for assessing AI agents' abilities in tackling research-level problems and competition-level challenges in the field of AI. We present the ML Research Benchmark (MLRB), comprising 7 competition-level tasks derived from recent machine learning conference tracks. These tasks span activities typically undertaken by AI researchers, including model training efficiency, pretraining on limited data, domain specific fine-tuning, and model compression. This paper introduces a novel benchmark and evaluates it using agent scaffolds powered by frontier models, including Claude-3 and GPT-4o. The results indicate that the Claude-3.5 Sonnet agent performs best across our benchmark, excelling in planning and developing machine learning models. However, both tested agents struggled to perform non-trivial research iterations. We observed significant performance variations across tasks, highlighting the complexity of AI development and the challenges in creating versatile agent scaffolds. While current AI agents can successfully navigate complex instructions and produce baseline results, they fall short of the capabilities required for advanced AI research. The ML Research Benchmark provides a valuable framework for assessing and comparing AI agents on tasks mirroring real-world AI research challenges.", "published": "2024-10-31 04:00:00", "id": "44d9f01a-e650-490f-ab18-cee89667043f", "source": "arxiv", "section": "computerScience"}, {"title": "Remote Sensing for Weed Detection and Control", "link": "https://arxiv.org/abs/2410.22554", "description": "arXiv:2410.22554v1 Announce Type: new \nAbstract: Italian ryegrass is a grass weed commonly found in winter wheat fields that are competitive with winter wheat for moisture and nutrients. Ryegrass can cause substantial reductions in yield and grain quality if not properly controlled with the use of herbicides. To control the cost and environmental impact we detect weeds in drone and satellite imagery. Satellite imagery is too coarse to be used for precision spraying, but can aid in planning drone flights and treatments. Drone images on the other hand have sufficiently good resolution for precision spraying. However, ryegrass is hard to distinguish from the crop and annotation requires expert knowledge. We used the Python segmentation models library to test more than 600 different neural network architectures for weed segmentation in drone images and we map accuracy versus the cost of the model prediction for these. Our best system applies herbicides to over 99% of the weeds while only spraying an area 30% larger than the annotated weed area. These models yield large savings if the weed covers a small part of the field.", "published": "2024-10-31 04:00:00", "id": "c214c37d-6ce3-484e-928e-408b349a0b1a", "source": "arxiv", "section": "computerScience"}, {"title": "Lost and Found in Speculation: Hybrid Speculative Vulnerability Detection", "link": "https://arxiv.org/abs/2410.22555", "description": "arXiv:2410.22555v1 Announce Type: new \nAbstract: Microarchitectural attacks represent a challenging and persistent threat to modern processors, exploiting inherent design vulnerabilities in processors to leak sensitive information or compromise systems. Of particular concern is the susceptibility of Speculative Execution, a fundamental part of performance enhancement, to such attacks. We introduce Specure, a novel pre-silicon verification method composing hardware fuzzing with Information Flow Tracking (IFT) to address speculative execution leakages. Integrating IFT enables two significant and non-trivial enhancements over the existing fuzzing approaches: i) automatic detection of microarchitectural information leakages vulnerabilities without golden model and ii) a novel Leakage Path coverage metric for efficient vulnerability detection. Specure identifies previously overlooked speculative execution vulnerabilities on the RISC-V BOOM processor and explores the vulnerability search space 6.45x faster than existing fuzzing techniques. Moreover, Specure detected known vulnerabilities 20x faster.", "published": "2024-10-31 04:00:00", "id": "54b2d6a7-d2bf-4327-9ac7-f070e100172e", "source": "arxiv", "section": "computerScience"}, {"title": "Unsupervised Multimodal Fusion of In-process Sensor Data for Advanced Manufacturing Process Monitoring", "link": "https://arxiv.org/abs/2410.22558", "description": "arXiv:2410.22558v1 Announce Type: new \nAbstract: Effective monitoring of manufacturing processes is crucial for maintaining product quality and operational efficiency. Modern manufacturing environments generate vast amounts of multimodal data, including visual imagery from various perspectives and resolutions, hyperspectral data, and machine health monitoring information such as actuator positions, accelerometer readings, and temperature measurements. However, interpreting this complex, high-dimensional data presents significant challenges, particularly when labeled datasets are unavailable. This paper presents a novel approach to multimodal sensor data fusion in manufacturing processes, inspired by the Contrastive Language-Image Pre-training (CLIP) model. We leverage contrastive learning techniques to correlate different data modalities without the need for labeled data, developing encoders for five distinct modalities: visual imagery, audio signals, laser position (x and y coordinates), and laser power measurements. By compressing these high-dimensional datasets into low-dimensional representational spaces, our approach facilitates downstream tasks such as process control, anomaly detection, and quality assurance. We evaluate the effectiveness of our approach through experiments, demonstrating its potential to enhance process monitoring capabilities in advanced manufacturing systems. This research contributes to smart manufacturing by providing a flexible, scalable framework for multimodal data fusion that can adapt to diverse manufacturing environments and sensor configurations.", "published": "2024-10-31 04:00:00", "id": "fe311c91-d796-4169-9fca-e845a523e347", "source": "arxiv", "section": "computerScience"}, {"title": "Unpicking Data at the Seams: VAEs, Disentanglement and Independent Components", "link": "https://arxiv.org/abs/2410.22559", "description": "arXiv:2410.22559v1 Announce Type: new \nAbstract: Disentanglement, or identifying salient statistically independent factors of the data, is of interest in many areas of machine learning and statistics, with relevance to synthetic data generation with controlled properties, robust classification of features, parsimonious encoding, and a greater understanding of the generative process underlying the data. Disentanglement arises in several generative paradigms, including Variational Autoencoders (VAEs), Generative Adversarial Networks and diffusion models. Particular progress has recently been made in understanding disentanglement in VAEs, where the choice of diagonal posterior covariance matrices is shown to promote mutual orthogonality between columns of the decoder's Jacobian. We continue this thread to show how this linear independence translates to statistical independence, completing the chain in understanding how the VAE's objective identifies independent components of, or disentangles, the data.", "published": "2024-10-31 04:00:00", "id": "afc7a270-0c94-47cd-83fb-ef8238578d6b", "source": "arxiv", "section": "computerScience"}, {"title": "BBR Fairness Evaluation Using NS-3", "link": "https://arxiv.org/abs/2410.22560", "description": "arXiv:2410.22560v1 Announce Type: new \nAbstract: This paper evaluates the fairness of BBR congestion control using NS-3 simulator. While BBR improves performance over loss-based methods in single flows, unfairness issues emerge with competing BBR and BBR/Cubic flows. Unfairness correlates with factors like round-trip time and buffer size. The core reason is the lack of responding mechanisms for the flows to converge on fair bandwidth share.", "published": "2024-10-31 04:00:00", "id": "2a0a4417-79ed-49e7-a77a-464bcb0cd6d0", "source": "arxiv", "section": "computerScience"}, {"title": "Fuzzerfly Effect: Hardware Fuzzing for Memory Safety", "link": "https://arxiv.org/abs/2410.22561", "description": "arXiv:2410.22561v1 Announce Type: new \nAbstract: Hardware-level memory vulnerabilities severely threaten computing systems. However, hardware patching is inefficient or difficult postfabrication. We investigate the effectiveness of hardware fuzzing in detecting hardware memory vulnerabilities and highlight challenges and potential future research directions to enhance hardware fuzzing for memory safety.", "published": "2024-10-31 04:00:00", "id": "05dc97b7-dc19-42ca-8c39-fd240e37e653", "source": "arxiv", "section": "computerScience"}, {"title": "Plane stress finite element modelling of arbitrary compressible hyperelastic materials", "link": "https://arxiv.org/abs/2410.22562", "description": "arXiv:2410.22562v1 Announce Type: new \nAbstract: Modelling the large deformation of hyperelastic solids under plane stress conditions for arbitrary compressible and nearly incompressible material models is challenging. This is in contrast to the case of full incompressibility where the out-of-plane deformation can be entirely characterised by the in-plane components. A rigorous general procedure for the incorporation of the plane stress condition for the compressible case (including the nearly incompressible case) is provided here, accompanied by a robust and open source finite element code. An isochoric/volumetric decomposition is adopted for nearly incompressible materials yielding a robust single-field finite element formulation. The nonlinear equation for the out-of-plane component of the deformation gradient is solved using a Newton-Raphson procedure nested at the quadrature point level. The model's performance and accuracy are made clear via a series of simulations of benchmark problems. Additional challenging numerical examples of composites reinforced with particles and fibres further demonstrate the capability of this general computational framework.", "published": "2024-10-31 04:00:00", "id": "87ce4753-fa3a-4b7b-8ab3-0829ac6b594b", "source": "arxiv", "section": "computerScience"}, {"title": "Vertical Federated Learning with Missing Features During Training and Inference", "link": "https://arxiv.org/abs/2410.22564", "description": "arXiv:2410.22564v1 Announce Type: new \nAbstract: Vertical federated learning trains models from feature-partitioned datasets across multiple clients, who collaborate without sharing their local data. Standard approaches assume that all feature partitions are available during both training and inference. Yet, in practice, this assumption rarely holds, as for many samples only a subset of the clients observe their partition. However, not utilizing incomplete samples during training harms generalization, and not supporting them during inference limits the utility of the model. Moreover, if any client leaves the federation after training, its partition becomes unavailable, rendering the learned model unusable. Missing feature blocks are therefore a key challenge limiting the applicability of vertical federated learning in real-world scenarios. To address this, we propose LASER-VFL, a vertical federated learning method for efficient training and inference of split neural network-based models that is capable of handling arbitrary sets of partitions. Our approach is simple yet effective, relying on the strategic sharing of model parameters and on task-sampling to train a family of predictors. We show that LASER-VFL achieves a $\\mathcal{O}({1}/{\\sqrt{T}})$ convergence rate for nonconvex objectives in general, $\\mathcal{O}({1}/{T})$ for sufficiently large batch sizes, and linear convergence under the Polyak-{\\L}ojasiewicz inequality. Numerical experiments show improved performance of LASER-VFL over the baselines. Remarkably, this is the case even in the absence of missing features. For example, for CIFAR-100, we see an improvement in accuracy of $21.4\\%$ when each of four feature blocks is observed with a probability of 0.5 and of $12.2\\%$ when all features are observed.", "published": "2024-10-31 04:00:00", "id": "ace347e9-dbcf-42b1-b2f4-4d797eb86e5e", "source": "arxiv", "section": "computerScience"}, {"title": "Flow Matching for Posterior Inference with Simulator Feedback", "link": "https://arxiv.org/abs/2410.22573", "description": "arXiv:2410.22573v1 Announce Type: new \nAbstract: Flow-based generative modeling is a powerful tool for solving inverse problems in physical sciences that can be used for sampling and likelihood evaluation with much lower inference times than traditional methods. We propose to refine flows with additional control signals based on a simulator. Control signals can include gradients and a problem-specific cost function if the simulator is differentiable, or they can be fully learned from the simulator output. In our proposed method, we pretrain the flow network and include feedback from the simulator exclusively for finetuning, therefore requiring only a small amount of additional parameters and compute. We motivate our design choices on several benchmark problems for simulation-based inference and evaluate flow matching with simulator feedback against classical MCMC methods for modeling strong gravitational lens systems, a challenging inverse problem in astronomy. We demonstrate that including feedback from the simulator improves the accuracy by $53\\%$, making it competitive with traditional techniques while being up to $67$x faster for inference.", "published": "2024-10-31 04:00:00", "id": "4b5ab55c-8332-498e-a45f-a2a408f2651b", "source": "arxiv", "section": "computerScience"}, {"title": "An AD based library for Efficient Hessian and Hessian-Vector Product Computation on GPU", "link": "https://arxiv.org/abs/2410.22575", "description": "arXiv:2410.22575v1 Announce Type: new \nAbstract: The Hessian-vector product computation appears in many scientific applications such as in optimization and finite element modeling. Often there is a need for computing Hessian-vector products at many data points concurrently. We propose an automatic differentiation (AD) based method, CHESSFAD (Chunked HESSian using Forward-mode AD), that is designed with efficient parallel computation of Hessian and Hessian-Vector products in mind. CHESSFAD computes second-order derivatives using forward mode and exposes parallelism at different levels that can be exploited on accelerators such as NVIDIA GPUs. In CHESSFAD approach, the computation of a row of the Hessian matrix is independent of the computation of other rows. Hence rows of the Hessian matrix can be computed concurrently. The second level of parallelism is exposed because CHESSFAD approach partitions the computation of a Hessian row into chunks, where different chunks can be computed concurrently. CHESSFAD is implemented as a lightweight header-based C++ library that works both for CPUs and GPUs. We evaluate the performance of CHESSFAD for performing a large number of independent Hessian-Vector products on a set of standard test functions and compare its performance to other existing header-based C++ libraries such as {\\tt autodiff}. Our results show that CHESSFAD performs better than {\\tt autodiff}, on all these functions with improvement ranging from 5-50\\% on average.", "published": "2024-10-31 04:00:00", "id": "fedba88a-1000-4212-9198-d45dc7acd2af", "source": "arxiv", "section": "computerScience"}, {"title": "Do Stubborn Users Always Cause More Polarization and Disagreement? A Mathematical Study", "link": "https://arxiv.org/abs/2410.22577", "description": "arXiv:2410.22577v1 Announce Type: new \nAbstract: We study how the stubbornness of social network users influences opinion polarization and disagreement. Our work is in the context of the popular Friedkin-Johnson opinion formation model, where users update their opinion as a function of the opinion of their connections and their own innate opinion. Stubbornness then is formulated in terms of the stress a user puts on its innate opinion.\n  We examine two scenarios: one where all nodes have uniform stubbornness levels (homogeneous) and another where stubbornness varies among nodes (inhomogeneous). In the homogeneous scenario, we prove that as the network's stubbornness factor increases, the polarization and disagreement index grows. In the more general inhomogeneous scenario, our findings surprisingly demonstrate that increasing the stubbornness of some users (particularly, neutral/unbiased users) can reduce the polarization and disagreement. We characterize specific conditions under which this phenomenon occurs. Finally, we conduct an extensive set of experiments on real-world network data to corroborate and complement our theoretical findings.", "published": "2024-10-31 04:00:00", "id": "206e8570-a027-4770-b557-eb1411fd52d7", "source": "arxiv", "section": "computerScience"}, {"title": "Energy-Aware Multi-Agent Reinforcement Learning for Collaborative Execution in Mission-Oriented Drone Networks", "link": "https://arxiv.org/abs/2410.22578", "description": "arXiv:2410.22578v1 Announce Type: new \nAbstract: Mission-oriented drone networks have been widely used for structural inspection, disaster monitoring, border surveillance, etc. Due to the limited battery capacity of drones, mission execution strategy impacts network performance and mission completion. However, collaborative execution is a challenging problem for drones in such a dynamic environment as it also involves efficient trajectory design. We leverage multi-agent reinforcement learning (MARL) to manage the challenge in this study, letting each drone learn to collaboratively execute tasks and plan trajectories based on its current status and environment. Simulation results show that the proposed collaborative execution model can successfully complete the mission at least 80% of the time, regardless of task locations and lengths, and can even achieve a 100% success rate when the task density is not way too sparse. To the best of our knowledge, our work is one of the pioneer studies on leveraging MARL on collaborative execution for mission-oriented drone networks; the unique value of this work lies in drone battery level driving our model design.", "published": "2024-10-31 04:00:00", "id": "58a73037-6b10-405a-bcf6-1bea13431b11", "source": "arxiv", "section": "computerScience"}, {"title": "Analytical Solution for Inverse Kinematics", "link": "https://arxiv.org/abs/2410.22582", "description": "arXiv:2410.22582v1 Announce Type: new \nAbstract: This paper introduces a closed-form analytical solution for the inverse kinematics (IK) of a 6 Degrees of Freedom (DOF) serial robotic manipulator arm, configured with six revolute joints and utilized within the Lunar Exploration Rover System (LERS). As a critical asset for conducting precise operations in the demanding lunar environment, this robotic arm relies on the IK solution to determine joint parameters required for precise end-effector positioning, essential for tasks such as sample collection, infrastructure assembly, and equipment deployment. By applying geometric principles, the proposed method offers a highly efficient and accurate approach to solving the IK problem, significantly reducing computational demands compared to traditional numerical methods. This advancement not only enhances real-time operational capabilities but is also optimized for space robotics, where precision and speed are critical. Additionally, the paper explores the integration of the LERS robotic system, underscoring the importance of this work in supporting autonomous lunar exploration within the ARTEMIS program and future missions", "published": "2024-10-31 04:00:00", "id": "2a03dc48-1741-4d9a-90bb-f935d431d757", "source": "arxiv", "section": "computerScience"}, {"title": "An eikonal model with re-excitability for fast simulations in cardiac electrophysiology", "link": "https://arxiv.org/abs/2410.22583", "description": "arXiv:2410.22583v1 Announce Type: new \nAbstract: Precision cardiology based on cardiac digital twins requires accurate simulations of cardiac arrhythmias. However, detailed models, such as the monodomain model, are computationally costly and have limited applicability in practice. Thus, it desirable to have fast models that can still represent the main physiological features presented during cardiac arrhythmias. The eikonal model is an approximation of the monodomain model that is widely used to describe the arrival times of the electrical wave. However, the standard eikonal model does not generalize to the complex re-entrant dynamics that characterize the cardiac arrhythmias. In this work, we propose an eikonal model that includes the tissue re-excitability, which allows to describe re-entries. The re-excitability properties are inferred from the monodomain model. Our eikonal model also handles the tissue anisotropy and heterogeneity. We compare the eikonal model to the monodomain model in various numerical experiments in the atria and the ventricles. The eikonal model is qualitatively accurate in the simulation of re-entries and can be potentially ran in real-time, opening the door to its clinical applicability.", "published": "2024-10-31 04:00:00", "id": "eec799a6-8596-4be0-8767-c51110d26a29", "source": "arxiv", "section": "computerScience"}, {"title": "BENCHAGENTS: Automated Benchmark Creation with Agent Interaction", "link": "https://arxiv.org/abs/2410.22584", "description": "arXiv:2410.22584v1 Announce Type: new \nAbstract: Evaluations are limited by benchmark availability. As models evolve, there is a need to create benchmarks that can measure progress on new generative capabilities. However, creating new benchmarks through human annotations is slow and expensive, restricting comprehensive evaluations for any capability. We introduce BENCHAGENTS, a framework that methodically leverages large language models (LLMs) to automate benchmark creation for complex capabilities while inherently ensuring data and metric quality. BENCHAGENTS decomposes the benchmark creation process into planning, generation, data verification, and evaluation, each of which is executed by an LLM agent. These agents interact with each other and utilize human-in-the-loop feedback from benchmark developers to explicitly improve and flexibly control data diversity and quality. We use BENCHAGENTS to create benchmarks to evaluate capabilities related to planning and constraint satisfaction during text generation. We then use these benchmarks to study seven state-of-the-art models and extract new insights on common failure modes and model differences.", "published": "2024-10-31 04:00:00", "id": "78e64c84-6433-443d-a3b3-24a82f2000dc", "source": "arxiv", "section": "computerScience"}, {"title": "Pre-Trained Vision Models as Perception Backbones for Safety Filters in Autonomous Driving", "link": "https://arxiv.org/abs/2410.22585", "description": "arXiv:2410.22585v1 Announce Type: new \nAbstract: End-to-end vision-based autonomous driving has achieved impressive success, but safety remains a major concern. The safe control problem has been addressed in low-dimensional settings using safety filters, e.g., those based on control barrier functions. Designing safety filters for vision-based controllers in the high-dimensional settings of autonomous driving can similarly alleviate the safety problem, but is significantly more challenging. In this paper, we address this challenge by using frozen pre-trained vision representation models as perception backbones to design vision-based safety filters, inspired by these models' success as backbones of robotic control policies. We empirically evaluate the offline performance of four common pre-trained vision models in this context. We try three existing methods for training safety filters for black-box dynamics, as the dynamics over representation spaces are not known. We use the DeepAccident dataset that consists of action-annotated videos from multiple cameras on vehicles in CARLA simulating real accident scenarios. Our results show that the filters resulting from our approach are competitive with the ones that are given the ground truth state of the ego vehicle and its environment.", "published": "2024-10-31 04:00:00", "id": "7b2cdf0b-356c-4038-9eae-cde2d328c7bf", "source": "arxiv", "section": "computerScience"}, {"title": "Toxicity of the Commons: Curating Open-Source Pre-Training Data", "link": "https://arxiv.org/abs/2410.22587", "description": "arXiv:2410.22587v1 Announce Type: new \nAbstract: Open-source large language models are becoming increasingly available and popular among researchers and practitioners. While significant progress has been made on open-weight models, open training data is a practice yet to be adopted by the leading open-weight models creators. At the same time, there researchers are working to make language models safer. We propose a data curation pipeline to reduce harmful outputs by models trained on public domain data. There are unique challenges to working with public domain data, as these sources differ from web text in both form and content. Many sources are historical documents and are the result of Optical Character Recognition (OCR). Consequently, current state-of-the-art approaches to toxicity filtering are often infeasible or inappropriate for open data models. In this paper, we introduce a new fully open-source pipeline for open-data toxicity filtering. Our contributions are threefold. We create a custom training dataset, ToxicCommons, which is composed of texts which have been classified across five different dimensions (racial/origin-based, gender/sex-based, religious, ability-based discrimination, and violence). We use this dataset to train a custom classifier, Celadon, that can be used to detect toxic content in open data more efficiently at a larger scale. Finally, we describe the balanced approach to content filtration that optimizes safety filtering with respect to the filtered data available for training.", "published": "2024-10-31 04:00:00", "id": "3d25dcca-2356-4d8f-9b3c-b694a03969ed", "source": "arxiv", "section": "computerScience"}, {"title": "Characterizing the Role of Similarity in the Property Inferences of Language Models", "link": "https://arxiv.org/abs/2410.22590", "description": "arXiv:2410.22590v1 Announce Type: new \nAbstract: Property inheritance -- a phenomenon where novel properties are projected from higher level categories (e.g., birds) to lower level ones (e.g., sparrows) -- provides a unique window into how humans organize and deploy conceptual knowledge. It is debated whether this ability arises due to explicitly stored taxonomic knowledge vs. simple computations of similarity between mental representations. How are these mechanistic hypotheses manifested in contemporary language models? In this work, we investigate how LMs perform property inheritance with behavioral and causal representational analysis experiments. We find that taxonomy and categorical similarities are not mutually exclusive in LMs' property inheritance behavior. That is, LMs are more likely to project novel properties from one category to the other when they are taxonomically related and at the same time, highly similar. Our findings provide insight into the conceptual structure of language models and may suggest new psycholinguistic experiments for human subjects.", "published": "2024-10-31 04:00:00", "id": "e944ff25-0b92-469b-b427-b95fb1c80c4c", "source": "arxiv", "section": "computerScience"}, {"title": "FGCE: Feasible Group Counterfactual Explanations for Auditing Fairness", "link": "https://arxiv.org/abs/2410.22591", "description": "arXiv:2410.22591v1 Announce Type: new \nAbstract: This paper introduces the first graph-based framework for generating group counterfactual explanations to audit model fairness, a crucial aspect of trustworthy machine learning. Counterfactual explanations are instrumental in understanding and mitigating unfairness by revealing how inputs should change to achieve a desired outcome. Our framework, named Feasible Group Counterfactual Explanations (FGCEs), captures real-world feasibility constraints and constructs subgroups with similar counterfactuals, setting it apart from existing methods. It also addresses key trade-offs in counterfactual generation, including the balance between the number of counterfactuals, their associated costs, and the breadth of coverage achieved. To evaluate these trade-offs and assess fairness, we propose measures tailored to group counterfactual generation. Our experimental results on benchmark datasets demonstrate the effectiveness of our approach in managing feasibility constraints and trade-offs, as well as the potential of our proposed metrics in identifying and quantifying fairness issues.", "published": "2024-10-31 04:00:00", "id": "8883753f-3cea-4f7a-a402-8aebf2bcc8cb", "source": "arxiv", "section": "computerScience"}, {"title": "GRADE: Quantifying Sample Diversity in Text-to-Image Models", "link": "https://arxiv.org/abs/2410.22592", "description": "arXiv:2410.22592v1 Announce Type: new \nAbstract: Text-to-image (T2I) models are remarkable at generating realistic images based on textual descriptions. However, textual prompts are inherently underspecified: they do not specify all possible attributes of the required image. This raises two key questions: Do T2I models generate diverse outputs on underspecified prompts? How can we automatically measure diversity? We propose GRADE: Granular Attribute Diversity Evaluation, an automatic method for quantifying sample diversity. GRADE leverages the world knowledge embedded in large language models and visual question-answering systems to identify relevant concept-specific axes of diversity (e.g., ``shape'' and ``color'' for the concept ``cookie''). It then estimates frequency distributions of concepts and their attributes and quantifies diversity using (normalized) entropy. GRADE achieves over 90% human agreement while exhibiting weak correlation to commonly used diversity metrics. We use GRADE to measure the overall diversity of 12 T2I models using 400 concept-attribute pairs, revealing that all models display limited variation. Further, we find that these models often exhibit default behaviors, a phenomenon where the model consistently generates concepts with the same attributes (e.g., 98% of the cookies are round). Finally, we demonstrate that a key reason for low diversity is due to underspecified captions in training data. Our work proposes a modern, semantically-driven approach to measure sample diversity and highlights the stunning homogeneity in outputs by T2I models.", "published": "2024-10-31 04:00:00", "id": "6bbb31ce-1157-4ae8-b66b-91ef2bff94c9", "source": "arxiv", "section": "computerScience"}, {"title": "Gaussian Derivative Change-point Detection for Early Warnings of Industrial System Failures", "link": "https://arxiv.org/abs/2410.22594", "description": "arXiv:2410.22594v1 Announce Type: new \nAbstract: An early warning of future system failure is essential for conducting predictive maintenance and enhancing system availability. This paper introduces a three-step framework for assessing system health to predict imminent system breakdowns. First, the Gaussian Derivative Change-Point Detection (GDCPD) algorithm is proposed for detecting changes in the high-dimensional feature space. GDCPD conducts a multivariate Change-Point Detection (CPD) by implementing Gaussian derivative processes for identifying change locations on critical system features, as these changes eventually will lead to system failure. To assess the significance of these changes, Weighted Mahalanobis Distance (WMD) is applied in both offline and online analyses. In the offline setting, WMD helps establish a threshold that determines significant system variations, while in the online setting, it facilitates real-time monitoring, issuing alarms for potential future system breakdowns. Utilizing the insights gained from the GDCPD and monitoring scheme, Long Short-Term Memory (LSTM) network is then employed to estimate the Remaining Useful Life (RUL) of the system. The experimental study of a real-world system demonstrates the effectiveness of the proposed methodology in accurately forecasting system failures well before they occur. By integrating CPD with real-time monitoring and RUL prediction, this methodology significantly advances system health monitoring and early warning capabilities.", "published": "2024-10-31 04:00:00", "id": "7979889e-b2b4-44e2-93ae-22e097959b7f", "source": "arxiv", "section": "computerScience"}, {"title": "Systolic Array Data Flows for Efficient Matrix Multiplication in Deep Neural Networks", "link": "https://arxiv.org/abs/2410.22595", "description": "arXiv:2410.22595v1 Announce Type: new \nAbstract: The paper discusses how Systolic Arrays can improve matrix multiplication for deep neural networks (DNNs). With AI models like OpenAI's GPT now containing trillions of parameters, the need for efficient matrix multiplication is more critical than ever. In this paper, the three main systolic array data flows: Weight Stationary (WS), Input Stationary (IS), and Output Stationary (OS) are discussed. Each data flow's energy consumption and efficiency across various matrix sizes are calculated using the SCALE-Sim simulator. The results show that selecting the right data flow for specific matrix configurations can drastically reduce energy consumption. The conclusions provide helpful insights into optimizing hardware for AI and machine learning applications, offering potential improvements in designing energy-efficient DNN accelerators.", "published": "2024-10-31 04:00:00", "id": "c11b3a75-b12e-4c9d-8579-c31ecde7b670", "source": "arxiv", "section": "computerScience"}, {"title": "Are Large-Language Models Graph Algorithmic Reasoners?", "link": "https://arxiv.org/abs/2410.22597", "description": "arXiv:2410.22597v1 Announce Type: new \nAbstract: We seek to address a core challenge facing current Large Language Models (LLMs). LLMs have demonstrated superior performance in many tasks, yet continue to struggle with reasoning problems on explicit graphs that require multiple steps. To address this gap, we introduce a novel benchmark designed to evaluate LLM performance on classical algorithmic reasoning tasks on explicit graphs. Our benchmark encompasses five fundamental algorithms: Breadth-First Search (BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we assess the capabilities of state-of-the-art LLMs in executing these algorithms step-by-step and systematically evaluate their performance at each stage. Our findings highlight the persistent challenges LLMs face in this domain and underscore the necessity for advanced prompting techniques and algorithmic instruction to enhance their graph reasoning abilities. This work presents MAGMA, the first comprehensive benchmark focused on LLMs completing classical graph algorithms, and provides a critical step toward understanding and improving their structured problem-solving skills.", "published": "2024-10-31 04:00:00", "id": "c333fea7-cc38-4fe5-b0c5-8384c9f91dc4", "source": "arxiv", "section": "computerScience"}, {"title": "Solving Minimum-Cost Reach Avoid using Reinforcement Learning", "link": "https://arxiv.org/abs/2410.22600", "description": "arXiv:2410.22600v1 Announce Type: new \nAbstract: Current reinforcement-learning methods are unable to directly learn policies that solve the minimum cost reach-avoid problem to minimize cumulative costs subject to the constraints of reaching the goal and avoiding unsafe states, as the structure of this new optimization problem is incompatible with current methods. Instead, a surrogate problem is solved where all objectives are combined with a weighted sum. However, this surrogate objective results in suboptimal policies that do not directly minimize the cumulative cost. In this work, we propose RC-PPO, a reinforcement-learning-based method for solving the minimum-cost reach-avoid problem by using connections to Hamilton-Jacobi reachability. Empirical results demonstrate that RC-PPO learns policies with comparable goal-reaching rates to while achieving up to 57% lower cumulative costs compared to existing methods on a suite of minimum-cost reach-avoid benchmarks on the Mujoco simulator. The project page can be found at https://oswinso.xyz/rcppo.", "published": "2024-10-31 04:00:00", "id": "492f99e5-e1da-4b8e-ab7b-6925de81889d", "source": "arxiv", "section": "computerScience"}, {"title": "A Cascade Approach for APT Campaign Attribution in System Event Logs: Technique Hunting and Subgraph Matching", "link": "https://arxiv.org/abs/2410.22602", "description": "arXiv:2410.22602v1 Announce Type: new \nAbstract: As Advanced Persistent Threats (APTs) grow increasingly sophisticated, the demand for effective detection methods has intensified. This study addresses the challenge of identifying APT campaign attacks through system event logs. A cascading approach, name SFM, combines Technique hunting and APT campaign attribution. Our approach assumes that real-world system event logs contain a vast majority of normal events interspersed with few suspiciously malicious ones and that these logs are annotated with Techniques of MITRE ATT&amp;CK framework for attack pattern recognition. Then, we attribute APT campaign attacks by aligning detected Techniques with known attack sequences to determine the most likely APT campaign. Evaluations on five real-world APT campaigns indicate that the proposed approach demonstrates reliable performance.", "published": "2024-10-31 04:00:00", "id": "83ea4912-40bb-4ac0-aaf6-9d842cd19c3b", "source": "arxiv", "section": "computerScience"}, {"title": "Testing Tensor Products of Algebraic Codes", "link": "https://arxiv.org/abs/2410.22606", "description": "arXiv:2410.22606v1 Announce Type: new \nAbstract: Motivated by recent advances in locally testable codes and quantum LDPCs based on robust testability of tensor product codes, we explore the local testability of tensor products of (an abstraction of) algebraic geometry codes. Such codes are parameterized by, in addition to standard parameters such as block length $n$ and dimension $k$, their genus $g$. We show that the tensor product of two algebraic geometry codes is robustly locally testable provided $n = \\Omega((k+g)^2)$. Apart from Reed-Solomon codes, this seems to be the first explicit family of codes of super-constant dual distance that is robustly locally testable.", "published": "2024-10-31 04:00:00", "id": "02f44737-f2b6-41d8-aab7-2bf11663689c", "source": "arxiv", "section": "computerScience"}, {"title": "CoGS: Model Agnostic Causality Constrained Counterfactual Explanations using goal-directed ASP", "link": "https://arxiv.org/abs/2410.22615", "description": "arXiv:2410.22615v1 Announce Type: new \nAbstract: Machine learning models are increasingly used in critical areas such as loan approvals and hiring, yet they often function as black boxes, obscuring their decision-making processes. Transparency is crucial, as individuals need explanations to understand decisions, primarily if the decisions result in an undesired outcome. Our work introduces CoGS (Counterfactual Generation with s(CASP)), a model-agnostic framework capable of generating counterfactual explanations for classification models. CoGS leverages the goal-directed Answer Set Programming system s(CASP) to compute realistic and causally consistent modifications to feature values, accounting for causal dependencies between them. By using rule-based machine learning algorithms (RBML), notably the FOLD-SE algorithm, CoGS extracts the underlying logic of a statistical model to generate counterfactual solutions. By tracing a step-by-step path from an undesired outcome to a desired one, CoGS offers interpretable and actionable explanations of the changes required to achieve the desired outcome. We present details of the CoGS framework along with its evaluation.", "published": "2024-10-31 04:00:00", "id": "67a7796e-6254-4b54-b422-c8844bf2b452", "source": "arxiv", "section": "computerScience"}, {"title": "Cops & Robber on Periodic Temporal Graphs", "link": "https://arxiv.org/abs/2410.22618", "description": "arXiv:2410.22618v1 Announce Type: new \nAbstract: We consider the Cops and Robber pursuit-evasion game when the edge-set of the graph is allowed to change in time, possibly at every round. Specifically, the game is played on an infinite periodic sequence $\\mathcal{G} = (G_0, \\dots, G_{p-1})^*$ of graphs on the same set $V$ of $n$ vertices: in round $t$, the topology of $\\mathcal{G}$ is $G_i=(V,E_i)$ where $i\\equiv t \\pmod{p}$.\n  Concentrating on the case of a single cop, we provide a characterization of copwin periodic temporal graphs, establishing several basic properties on their nature, and extending to the temporal domain classical C&amp;R concepts such as covers and corners. Based on these results, we design an efficient algorithm for determining if a periodic temporal graph is copwin.\n  We also consider the case of $k>1$ cops. By shifting from a representation in terms of directed graphs to one in terms of directed multi-hypergraphs, we prove that all the fundamental properties established for $k=1$ continue to hold, providing a characterization of $k$-copwin periodic graphs, as well as a general strategy to determine if a periodic graph is $k$-copwin.\n  Our results do not rely on any assumption on properties such as connectivity, symmetry, reflexivity held by the individual graphs in the sequence. They are established for a unified version of the game that includes the standard games studied in the literature, both for undirected and directed graphs, and both when the players are fully active and when they are not. They hold also for a variety of settings not considered in the literature.", "published": "2024-10-31 04:00:00", "id": "ec397ef5-afcc-4332-82d8-aca01ced4352", "source": "arxiv", "section": "computerScience"}, {"title": "FISC: Federated Domain Generalization via Interpolative Style Transfer and Contrastive Learning", "link": "https://arxiv.org/abs/2410.22622", "description": "arXiv:2410.22622v1 Announce Type: new \nAbstract: Federated Learning (FL) shows promise in preserving privacy and enabling collaborative learning. However, most current solutions focus on private data collected from a single domain. A significant challenge arises when client data comes from diverse domains (i.e., domain shift), leading to poor performance on unseen domains. Existing Federated Domain Generalization approaches address this problem but assume each client holds data for an entire domain, limiting their practicality in real-world scenarios with domain-based heterogeneity and client sampling.\n  To overcome this, we introduce FISC, a novel FL domain generalization paradigm that handles more complex domain distributions across clients. FISC enables learning across domains by extracting an interpolative style from local styles and employing contrastive learning. This strategy gives clients multi-domain representations and unbiased convergent targets. Empirical results on multiple datasets, including PACS, Office-Home, and IWildCam, show FISC outperforms state-of-the-art (SOTA) methods. Our method achieves accuracy improvements ranging from 3.64% to 57.22% on unseen domains. Our code is available at https://anonymous.4open.science/r/FISC-AAAI-16107.", "published": "2024-10-31 04:00:00", "id": "39a531bc-ce27-45f4-90f6-c0ee1be26c74", "source": "arxiv", "section": "computerScience"}, {"title": "PV-VTT: A Privacy-Centric Dataset for Mission-Specific Anomaly Detection and Natural Language Interpretation", "link": "https://arxiv.org/abs/2410.22623", "description": "arXiv:2410.22623v1 Announce Type: new \nAbstract: Video crime detection is a significant application of computer vision and artificial intelligence. However, existing datasets primarily focus on detecting severe crimes by analyzing entire video clips, often neglecting the precursor activities (i.e., privacy violations) that could potentially prevent these crimes. To address this limitation, we present PV-VTT (Privacy Violation Video To Text), a unique multimodal dataset aimed at identifying privacy violations. PV-VTT provides detailed annotations for both video and text in scenarios. To ensure the privacy of individuals in the videos, we only provide video feature vectors, avoiding the release of any raw video data. This privacy-focused approach allows researchers to use the dataset while protecting participant confidentiality. Recognizing that privacy violations are often ambiguous and context-dependent, we propose a Graph Neural Network (GNN)-based video description model. Our model generates a GNN-based prompt with image for Large Language Model (LLM), which deliver cost-effective and high-quality video descriptions. By leveraging a single video frame along with relevant text, our method reduces the number of input tokens required, maintaining descriptive quality while optimizing LLM API-usage. Extensive experiments validate the effectiveness and interpretability of our approach in video description tasks and flexibility of our PV-VTT dataset.", "published": "2024-10-31 04:00:00", "id": "47799bf1-b875-48d3-8097-202b2b241e54", "source": "arxiv", "section": "computerScience"}, {"title": "Symbolic Graph Inference for Compound Scene Understanding", "link": "https://arxiv.org/abs/2410.22626", "description": "arXiv:2410.22626v1 Announce Type: new \nAbstract: Scene understanding is a fundamental capability needed in many domains, ranging from question-answering to robotics. Unlike recent end-to-end approaches that must explicitly learn varying compositions of the same scene, our method reasons over their constituent objects and analyzes their arrangement to infer a scene's meaning. We propose a novel approach that reasons over a scene's scene- and knowledge-graph, capturing spatial information while being able to utilize general domain knowledge in a joint graph search. Empirically, we demonstrate the feasibility of our method on the ADE20K dataset and compare it to current scene understanding approaches.", "published": "2024-10-31 04:00:00", "id": "ce1a0256-8ffe-4ece-a363-5dbaf4a1fd88", "source": "arxiv", "section": "computerScience"}, {"title": "CrossEarth: Geospatial Vision Foundation Model for Domain Generalizable Remote Sensing Semantic Segmentation", "link": "https://arxiv.org/abs/2410.22629", "description": "arXiv:2410.22629v1 Announce Type: new \nAbstract: The field of Remote Sensing Domain Generalization (RSDG) has emerged as a critical and valuable research frontier, focusing on developing models that generalize effectively across diverse scenarios. Despite the substantial domain gaps in RS images that are characterized by variabilities such as location, wavelength, and sensor type, research in this area remains underexplored: (1) Current cross-domain methods primarily focus on Domain Adaptation (DA), which adapts models to predefined domains rather than to unseen ones; (2) Few studies targeting the RSDG issue, especially for semantic segmentation tasks, where existing models are developed for specific unknown domains, struggling with issues of underfitting on other unknown scenarios; (3) Existing RS foundation models tend to prioritize in-domain performance over cross-domain generalization. To this end, we introduce the first vision foundation model for RSDG semantic segmentation, CrossEarth. CrossEarth demonstrates strong cross-domain generalization through a specially designed data-level Earth-Style Injection pipeline and a model-level Multi-Task Training pipeline. In addition, for the semantic segmentation task, we have curated an RSDG benchmark comprising 28 cross-domain settings across various regions, spectral bands, platforms, and climates, providing a comprehensive framework for testing the generalizability of future RSDG models. Extensive experiments on this benchmark demonstrate the superiority of CrossEarth over existing state-of-the-art methods.", "published": "2024-10-31 04:00:00", "id": "896adbd7-044e-4bba-a318-69a7a061b680", "source": "arxiv", "section": "computerScience"}, {"title": "DECRL: A Deep Evolutionary Clustering Jointed Temporal Knowledge Graph Representation Learning Approach", "link": "https://arxiv.org/abs/2410.22631", "description": "arXiv:2410.22631v1 Announce Type: new \nAbstract: Temporal Knowledge Graph (TKG) representation learning aims to map temporal evolving entities and relations to embedded representations in a continuous low-dimensional vector space. However, existing approaches cannot capture the temporal evolution of high-order correlations in TKGs. To this end, we propose a Deep Evolutionary Clustering jointed temporal knowledge graph Representation Learning approach (DECRL). Specifically, a deep evolutionary clustering module is proposed to capture the temporal evolution of high-order correlations among entities. Furthermore, a cluster-aware unsupervised alignment mechanism is introduced to ensure the precise one-to-one alignment of soft overlapping clusters across timestamps, thereby maintaining the temporal smoothness of clusters. In addition, an implicit correlation encoder is introduced to capture latent correlations between any pair of clusters under the guidance of a global graph. Extensive experiments on seven real-world datasets demonstrate that DECRL achieves the state-of-the-art performances, outperforming the best baseline by an average of 9.53%, 12.98%, 10.42%, and 14.68% in MRR, Hits@1, Hits@3, and Hits@10, respectively.", "published": "2024-10-31 04:00:00", "id": "a215af1a-c94e-4cbc-8886-f5e0a68bca24", "source": "arxiv", "section": "computerScience"}, {"title": "Consistency Diffusion Bridge Models", "link": "https://arxiv.org/abs/2410.22637", "description": "arXiv:2410.22637v1 Announce Type: new \nAbstract: Diffusion models (DMs) have become the dominant paradigm of generative modeling in a variety of domains by learning stochastic processes from noise to data. Recently, diffusion denoising bridge models (DDBMs), a new formulation of generative modeling that builds stochastic processes between fixed data endpoints based on a reference diffusion process, have achieved empirical success across tasks with coupled data distribution, such as image-to-image translation. However, DDBM's sampling process typically requires hundreds of network evaluations to achieve decent performance, which may impede their practical deployment due to high computational demands. In this work, inspired by the recent advance of consistency models in DMs, we tackle this problem by learning the consistency function of the probability-flow ordinary differential equation (PF-ODE) of DDBMs, which directly predicts the solution at a starting step given any point on the ODE trajectory. Based on a dedicated general-form ODE solver, we propose two paradigms: consistency bridge distillation and consistency bridge training, which is flexible to apply on DDBMs with broad design choices. Experimental results show that our proposed method could sample $4\\times$ to $50\\times$ faster than the base DDBM and produce better visual quality given the same step in various tasks with pixel resolution ranging from $64 \\times 64$ to $256 \\times 256$, as well as supporting downstream tasks such as semantic interpolation in the data space.", "published": "2024-10-31 04:00:00", "id": "e2bb600a-98fa-40fe-b093-0a3386e30349", "source": "arxiv", "section": "computerScience"}, {"title": "Unbiased Regression Loss for DETRs", "link": "https://arxiv.org/abs/2410.22638", "description": "arXiv:2410.22638v1 Announce Type: new \nAbstract: In this paper, we introduce a novel unbiased regression loss for DETR-based detectors. The conventional $L_{1}$ regression loss tends to bias towards larger boxes, as they disproportionately contribute more towards the overall loss compared to smaller boxes. Consequently, the detection performance for small objects suffers. To alleviate this bias, the proposed new unbiased loss, termed Sized $L_{1}$ loss, normalizes the size of all boxes based on their individual width and height. Our experiments demonstrate consistent improvements in both fully-supervised and semi-supervised settings using the MS-COCO benchmark dataset.", "published": "2024-10-31 04:00:00", "id": "5828d150-fcc7-4b60-8d92-3843c1006612", "source": "arxiv", "section": "computerScience"}, {"title": "Prove Your Point!: Bringing Proof-Enhancement Principles to Argumentative Essay Generation", "link": "https://arxiv.org/abs/2410.22642", "description": "arXiv:2410.22642v1 Announce Type: new \nAbstract: Argumentative essay generation (AEG) aims to generate complete texts on specific controversial topics or debates. Although current AEG methods can generate individual opinions, they often overlook the high-level connections between these opinions. This often leads to the generated results being mired in logical confusion, unable to proof their own arguments effectively. The generated essay may present evidence that contradicts the claims or they may fail to assemble the claims into logical flow. In this paper, we present a unified two-stage framework: Proof-Enhancement and Self-Annotation (PESA) for AEG with a focus on logical enhancement. Specifically, we first construct pseudo-labels for logical information,claims and grounds, using a large language model. We then propose a tree planning approach that introduces proof principles and ensures logical consistency. Extensive experimental results show that, benefiting from proof principle guidance, PESA generates argumentative essays with better logical validity and persuasiveness than strong baseline models.", "published": "2024-10-31 04:00:00", "id": "1ddf1a0d-494a-4fbb-baf6-4bfc79c96260", "source": "arxiv", "section": "computerScience"}, {"title": "An Overtaking Trajectory Planning Framework Based on Spatio-temporal Topology and Reachable Set Analysis Ensuring Time Efficiency", "link": "https://arxiv.org/abs/2410.22643", "description": "arXiv:2410.22643v1 Announce Type: new \nAbstract: Generating overtaking trajectories in high-speed scenarios presents significant challenges and is typically addressed through hierarchical planning methods. However, this method has two primary drawbacks. First, heuristic algorithms can only provide a single initial solution, which may lead to local optima and consequently diminish the quality of the solution. Second, the time efficiency of trajectory refinement based on numerical optimization is insufficient. To overcome these limitations, this paper proposes an overtaking trajectory planning framework based on spatio-temporal topology and reachable set analysis (SROP), to improve trajectory quality and time efficiency. Specifically, this paper introduces topological classes to describe trajectories representing different overtaking behaviors, which support the spatio-temporal topological search method employed by the upper-layer planner to identify diverse initial paths. This approach helps prevent getting stuck in local optima, enhancing the overall solution quality by considering multiple initial solutions from distinct topologies. Moreover, the reachable set method is integrated into the lower-layer planner for parallel trajectory evaluation. This method enhances planning efficiency by decoupling vehicle model constraints from the optimization process, enabling parallel computation while ensuring control feasibility. Simulation results show that the proposed method improves the smoothness of generated trajectories by 66.8% compared to state-of-the-art methods, highlighting its effectiveness in enhancing trajectory quality. Additionally, this method reduces computation time by 62.9%, demonstrating its efficiency.", "published": "2024-10-31 04:00:00", "id": "cc41b649-e006-4260-924e-589108af2a8b", "source": "arxiv", "section": "computerScience"}, {"title": "Controlling the Wireless Power Transfer Mechanism of the Both-Sides Retrodirective System", "link": "https://arxiv.org/abs/2410.22644", "description": "arXiv:2410.22644v1 Announce Type: new \nAbstract: To achieve efficient long-range wireless power transfer (WPT), large antenna systems are necessary spanning lengths of tens to thousands of meters in one dimension. This creates an array in the order of at least hundreds of thousands to billions of elements. This makes the implementation of beamforming control a challenge. Various works focus on iterative optimization or channel estimation to maintain high efficiency in a time-varying environment requiring complex processing capabilities. A simpler alternative is the both-sides retrodirective antenna array (BS-RDAA) system where iterative optimization or channel estimation is not required. In a previous study, it was observed that this system achieves maximum WPT efficiency if the system is marginally stable. Thus, there is a need to regulate the system to maintain marginal stability regardless of the transmission channel conditions. In this paper, we present a plant model for the system and design a control system to drive it to marginal stability. The result is a WPT implementation that is not dependent on complex processing capabilities present in other established high efficiency methods. We also confirmed the ability of the proposed design to maintain maximum efficiency in a dynamic environment through the results of an electromagnetic simulator and a time domain simulator.", "published": "2024-10-31 04:00:00", "id": "e5f99f90-d7e7-4c91-ae85-a67df51889c5", "source": "arxiv", "section": "computerScience"}, {"title": "SimpsonsVQA: Enhancing Inquiry-Based Learning with a Tailored Dataset", "link": "https://arxiv.org/abs/2410.22648", "description": "arXiv:2410.22648v1 Announce Type: new \nAbstract: Visual Question Answering (VQA) has emerged as a promising area of research to develop AI-based systems for enabling interactive and immersive learning. Numerous VQA datasets have been introduced to facilitate various tasks, such as answering questions or identifying unanswerable ones. However, most of these datasets are constructed using real-world images, leaving the performance of existing models on cartoon images largely unexplored. Hence, in this paper, we present \"SimpsonsVQA\", a novel dataset for VQA derived from The Simpsons TV show, designed to promote inquiry-based learning. Our dataset is specifically designed to address not only the traditional VQA task but also to identify irrelevant questions related to images, as well as the reverse scenario where a user provides an answer to a question that the system must evaluate (e.g., as correct, incorrect, or ambiguous). It aims to cater to various visual applications, harnessing the visual content of \"The Simpsons\" to create engaging and informative interactive systems. SimpsonsVQA contains approximately 23K images, 166K QA pairs, and 500K judgments (https://simpsonsvqa.org). Our experiments show that current large vision-language models like ChatGPT4o underperform in zero-shot settings across all three tasks, highlighting the dataset's value for improving model performance on cartoon images. We anticipate that SimpsonsVQA will inspire further research, innovation, and advancements in inquiry-based learning VQA.", "published": "2024-10-31 04:00:00", "id": "c37c4475-b84a-45ae-b377-c75b91c5a0b7", "source": "arxiv", "section": "computerScience"}, {"title": "WaveRoRA: Wavelet Rotary Route Attention for Multivariate Time Series Forecasting", "link": "https://arxiv.org/abs/2410.22649", "description": "arXiv:2410.22649v1 Announce Type: new \nAbstract: In recent years, Transformer-based models (Transformers) have achieved significant success in multivariate time series forecasting (MTSF). However, previous works focus on extracting features either from the time domain or the frequency domain, which inadequately captures the trends and periodic characteristics. To address this issue, we propose a wavelet learning framework to model complex temporal dependencies of the time series data. The wavelet domain integrates both time and frequency information, allowing for the analysis of local characteristics of signals at different scales. Additionally, the Softmax self-attention mechanism used by Transformers has quadratic complexity, which leads to excessive computational costs when capturing long-term dependencies. Therefore, we propose a novel attention mechanism: Rotary Route Attention (RoRA). Unlike Softmax attention, RoRA utilizes rotary position embeddings to inject relative positional information to sequence tokens and introduces a small number of routing tokens $r$ to aggregate information from the $KV$ matrices and redistribute it to the $Q$ matrix, offering linear complexity. We further propose WaveRoRA, which leverages RoRA to capture inter-series dependencies in the wavelet domain. We conduct extensive experiments on eight real-world datasets. The results indicate that WaveRoRA outperforms existing state-of-the-art models while maintaining lower computational costs.", "published": "2024-10-31 04:00:00", "id": "1605a6d5-5bbd-4413-b124-aa13eb2dd867", "source": "arxiv", "section": "computerScience"}, {"title": "Error correction in interference-limited wireless systems", "link": "https://arxiv.org/abs/2410.22650", "description": "arXiv:2410.22650v1 Announce Type: new \nAbstract: We introduce a novel approach to error correction decoding in the presence of additive alpha-stable noise, which serves as a model of interference-limited wireless systems. In the absence of modifications to decoding algorithms, treating alpha-stable distributions as Gaussian results in significant performance loss. Building on Guessing Random Additive Noise Decoding (GRAND), we consider two approaches. The first accounts for alpha-stable noise in the evaluation of log-likelihood ratios (LLRs) that serve as input to Ordered Reliability Bits GRAND (ORBGRAND). The second builds on an ORBGRAND variant that was originally designed to account for jamming that treats outlying LLRs as erasures. This results in a hybrid error and erasure correcting decoder that corrects errors via ORBGRAND and corrects erasures via Gaussian elimination. The block error rate (BLER) performance of both approaches are similar. Both outperform decoding assuming that the LLRs originated from Gaussian noise by 2 to 3 dB for [128,112] 5G NR CA-Polar and CRC codes.", "published": "2024-10-31 04:00:00", "id": "d9d1e946-f684-4938-b752-74a653459e36", "source": "arxiv", "section": "computerScience"}, {"title": "FT-PrivacyScore: Personalized Privacy Scoring Service for Machine Learning Participation", "link": "https://arxiv.org/abs/2410.22651", "description": "arXiv:2410.22651v1 Announce Type: new \nAbstract: Training data privacy has been a top concern in AI modeling. While methods like differentiated private learning allow data contributors to quantify acceptable privacy loss, model utility is often significantly damaged. In practice, controlled data access remains a mainstream method for protecting data privacy in many industrial and research environments. In controlled data access, authorized model builders work in a restricted environment to access sensitive data, which can fully preserve data utility with reduced risk of data leak. However, unlike differential privacy, there is no quantitative measure for individual data contributors to tell their privacy risk before participating in a machine learning task. We developed the demo prototype FT-PrivacyScore to show that it's possible to efficiently and quantitatively estimate the privacy risk of participating in a model fine-tuning task. The demo source code will be available at \\url{https://github.com/RhincodonE/demo_privacy_scoring}.", "published": "2024-10-31 04:00:00", "id": "2d38e403-85ea-49bb-9f84-b672a366fb2d", "source": "arxiv", "section": "computerScience"}, {"title": "Development of a Python-Based Software for Calculating the Jones Polynomial: Insights into the Behavior of Polymers and Biopolymers", "link": "https://arxiv.org/abs/2410.22652", "description": "arXiv:2410.22652v1 Announce Type: new \nAbstract: This thesis details a Python-based software designed to calculate the Jones polynomial, a vital mathematical tool from Knot Theory used for characterizing the topological and geometrical complexity of curves in \\( \\mathbb{R}^3 \\), which is essential in understanding physical systems of filaments, including the behavior of polymers and biopolymers. The Jones polynomial serves as a topological invariant capable of distinguishing between different knot structures. This capability is fundamental to characterizing the architecture of molecular chains, such as proteins and DNA. Traditional computational methods for deriving the Jones polynomial have been limited by closure-schemes and high execution costs, which can be impractical for complex structures like those that appear in real life. This software implements methods that significantly reduce calculation times, allowing for more efficient and practical applications in the study of biological polymers. It utilizes a divide-and-conquer approach combined with parallel computing and applies recursive Reidemeister moves to optimize the computation, transitioning from an exponential to a near-linear runtime for specific configurations. This thesis provides an overview of the software's functions, detailed performance evaluations using protein structures as test cases, and a discussion of the implications for future research and potential algorithmic improvements.", "published": "2024-10-31 04:00:00", "id": "25301feb-2d7a-4cb7-ba20-7f1c491e8c63", "source": "arxiv", "section": "computerScience"}, {"title": "FlowDCN: Exploring DCN-like Architectures for Fast Image Generation with Arbitrary Resolution", "link": "https://arxiv.org/abs/2410.22655", "description": "arXiv:2410.22655v1 Announce Type: new \nAbstract: Arbitrary-resolution image generation still remains a challenging task in AIGC, as it requires handling varying resolutions and aspect ratios while maintaining high visual quality. Existing transformer-based diffusion methods suffer from quadratic computation cost and limited resolution extrapolation capabilities, making them less effective for this task. In this paper, we propose FlowDCN, a purely convolution-based generative model with linear time and memory complexity, that can efficiently generate high-quality images at arbitrary resolutions. Equipped with a new design of learnable group-wise deformable convolution block, our FlowDCN yields higher flexibility and capability to handle different resolutions with a single model. FlowDCN achieves the state-of-the-art 4.30 sFID on $256\\times256$ ImageNet Benchmark and comparable resolution extrapolation results, surpassing transformer-based counterparts in terms of convergence speed (only $\\frac{1}{5}$ images), visual quality, parameters ($8\\%$ reduction) and FLOPs ($20\\%$ reduction). We believe FlowDCN offers a promising solution to scalable and flexible image synthesis.", "published": "2024-10-31 04:00:00", "id": "174dd908-b414-4108-8338-de2d557a6b86", "source": "arxiv", "section": "computerScience"}, {"title": "Reweighting Local Mimina with Tilted SAM", "link": "https://arxiv.org/abs/2410.22656", "description": "arXiv:2410.22656v1 Announce Type: new \nAbstract: Sharpness-Aware Minimization (SAM) has been demonstrated to improve the generalization performance of overparameterized models by seeking flat minima on the loss landscape through optimizing model parameters that incur the largest loss within a neighborhood. Nevertheless, such min-max formulations are computationally challenging especially when the problem is highly non-convex. Additionally, focusing only on the worst-case local solution while ignoring potentially many other local solutions may be suboptimal when searching for flat minima. In this work, we propose Tilted SAM (TSAM), a generalization of SAM inspired by exponential tilting that effectively assigns higher priority to local solutions that are flatter and that incur larger losses. TSAM is parameterized by a tilt hyperparameter t and reduces to SAM as t approaches infinity. We prove that (1) the TSAM objective is smoother than SAM and thus easier to optimize; and (2) TSAM explicitly favors flatter minima as t increases. This is desirable as flatter minima could have better generalization properties for certain tasks. We develop algorithms motivated by the discretization of Hamiltonian dynamics to solve TSAM. Empirically, TSAM arrives at flatter local minima and results in superior test performance than the baselines of SAM and ERM across a range of image and text tasks.", "published": "2024-10-31 04:00:00", "id": "526123d6-5b94-49b8-859b-8848af1db046", "source": "arxiv", "section": "computerScience"}, {"title": "Automatic programming via large language models with population self-evolution for dynamic job shop scheduling problem", "link": "https://arxiv.org/abs/2410.22657", "description": "arXiv:2410.22657v1 Announce Type: new \nAbstract: Heuristic dispatching rules (HDRs) are widely regarded as effective methods for solving dynamic job shop scheduling problems (DJSSP) in real-world production environments. However, their performance is highly scenario-dependent, often requiring expert customization. To address this, genetic programming (GP) and gene expression programming (GEP) have been extensively used for automatic algorithm design. Nevertheless, these approaches often face challenges due to high randomness in the search process and limited generalization ability, hindering the application of trained dispatching rules to new scenarios or dynamic environments. Recently, the integration of large language models (LLMs) with evolutionary algorithms has opened new avenues for prompt engineering and automatic algorithm design. To enhance the capabilities of LLMs in automatic HDRs design, this paper proposes a novel population self-evolutionary (SeEvo) method, a general search framework inspired by the self-reflective design strategies of human experts. The SeEvo method accelerates the search process and enhances exploration capabilities. Experimental results show that the proposed SeEvo method outperforms GP, GEP, end-to-end deep reinforcement learning methods, and more than 10 common HDRs from the literature, particularly in unseen and dynamic scenarios.", "published": "2024-10-31 04:00:00", "id": "807db536-e07e-4995-80b2-75cd4da2efa1", "source": "arxiv", "section": "computerScience"}, {"title": "Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation", "link": "https://arxiv.org/abs/2410.22658", "description": "arXiv:2410.22658v1 Announce Type: new \nAbstract: Continual Imitation Learning (CiL) involves extracting and accumulating task knowledge from demonstrations across multiple stages and tasks to achieve a multi-task policy. With recent advancements in foundation models, there has been a growing interest in adapter-based CiL approaches, where adapters are established parameter-efficiently for tasks newly demonstrated. While these approaches isolate parameters for specific tasks and tend to mitigate catastrophic forgetting, they limit knowledge sharing among different demonstrations. We introduce IsCiL, an adapter-based CiL framework that addresses this limitation of knowledge sharing by incrementally learning shareable skills from different demonstrations, thus enabling sample-efficient task adaptation using the skills particularly in non-stationary CiL environments. In IsCiL, demonstrations are mapped into the state embedding space, where proper skills can be retrieved upon input states through prototype-based memory. These retrievable skills are incrementally learned on their corresponding adapters. Our CiL experiments with complex tasks in Franka-Kitchen and Meta-World demonstrate robust performance of IsCiL in both task adaptation and sample-efficiency. We also show a simple extension of IsCiL for task unlearning scenarios.", "published": "2024-10-31 04:00:00", "id": "f9468f11-abd0-4324-9f4e-94466535924d", "source": "arxiv", "section": "computerScience"}, {"title": "Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models", "link": "https://arxiv.org/abs/2410.22660", "description": "arXiv:2410.22660v1 Announce Type: new \nAbstract: Code-switching, the phenomenon of alternating between two or more languages in a single conversation, presents unique challenges for Natural Language Processing (NLP). Most existing research focuses on either syntactic constraints or neural generation, with few efforts to integrate linguistic theory with large language models (LLMs) for generating natural code-switched text. In this paper, we introduce EZSwitch, a novel framework that combines Equivalence Constraint Theory (ECT) with LLMs to produce linguistically valid and fluent code-switched text. We evaluate our method using both human judgments and automatic metrics, demonstrating a significant improvement in the quality of generated code-switching sentences compared to baseline LLMs. To address the lack of suitable evaluation metrics, we conduct a comprehensive correlation study of various automatic metrics against human scores, revealing that current metrics often fail to capture the nuanced fluency of code-switched text. Additionally, we create CSPref, a human preference dataset based on human ratings and analyze model performance across ``hard`` and ``easy`` examples. Our findings indicate that incorporating linguistic constraints into LLMs leads to more robust and human-aligned generation, paving the way for scalable code-switching text generation across diverse language pairs.", "published": "2024-10-31 04:00:00", "id": "e8480f0d-05bf-4519-9321-cd456ce4cb75", "source": "arxiv", "section": "computerScience"}, {"title": "$\\textbf{EMOS}$: $\\textbf{E}$mbodiment-aware Heterogeneous $\\textbf{M}$ulti-robot $\\textbf{O}$perating $\\textbf{S}$ystem with LLM Agents", "link": "https://arxiv.org/abs/2410.22662", "description": "arXiv:2410.22662v1 Announce Type: new \nAbstract: Heterogeneous multi-robot systems (HMRS) have emerged as a powerful approach for tackling complex tasks that single robots cannot manage alone. Current large-language-model-based multi-agent systems (LLM-based MAS) have shown success in areas like software development and operating systems, but applying these systems to robot control presents unique challenges. In particular, the capabilities of each agent in a multi-robot system are inherently tied to the physical composition of the robots, rather than predefined roles. To address this issue, we introduce a novel multi-agent framework designed to enable effective collaboration among heterogeneous robots with varying embodiments and capabilities, along with a new benchmark named Habitat-MAS. One of our key designs is $\\textit{Robot Resume}$: Instead of adopting human-designed role play, we propose a self-prompted approach, where agents comprehend robot URDF files and call robot kinematics tools to generate descriptions of their physics capabilities to guide their behavior in task planning and action execution. The Habitat-MAS benchmark is designed to assess how a multi-agent framework handles tasks that require embodiment-aware reasoning, which includes 1) manipulation, 2) perception, 3) navigation, and 4) comprehensive multi-floor object rearrangement. The experimental results indicate that the robot's resume and the hierarchical design of our multi-agent system are essential for the effective operation of the heterogeneous multi-robot system within this intricate problem context.", "published": "2024-10-31 04:00:00", "id": "0ca0acbd-5938-4c1d-af36-c84723068d8c", "source": "arxiv", "section": "computerScience"}, {"title": "Automated Trustworthiness Oracle Generation for Machine Learning Text Classifiers", "link": "https://arxiv.org/abs/2410.22663", "description": "arXiv:2410.22663v1 Announce Type: new \nAbstract: Machine learning (ML) for text classification has been widely used in various domains, such as toxicity detection, chatbot consulting, and review analysis. These applications can significantly impact ethics, economics, and human behavior, raising serious concerns about trusting ML decisions. Several studies indicate that traditional metrics, such as model confidence and accuracy, are insufficient to build human trust in ML models. These models often learn spurious correlations during training and predict based on them during inference. In the real world, where such correlations are absent, their performance can deteriorate significantly. To avoid this, a common practice is to test whether predictions are reasonable. Along with this, a challenge known as the trustworthiness oracle problem has been introduced. Due to the lack of automated trustworthiness oracles, the assessment requires manual validation of the decision process disclosed by explanation methods, which is time-consuming and not scalable. We propose TOKI, the first automated trustworthiness oracle generation method for text classifiers, which automatically checks whether the prediction-contributing words are related to the predicted class using explanation methods and word embeddings. To demonstrate its practical usefulness, we introduce a novel adversarial attack method targeting trustworthiness issues identified by TOKI. We compare TOKI with a naive baseline based solely on model confidence using human-created ground truths of 6,000 predictions. We also compare TOKI-guided adversarial attack method with A2T, a SOTA adversarial attack method. Results show that relying on prediction uncertainty cannot distinguish between trustworthy and untrustworthy predictions, TOKI achieves 142% higher accuracy than the naive baseline, and TOKI-guided adversarial attack method is more effective with fewer perturbations than A2T.", "published": "2024-10-31 04:00:00", "id": "f47d437b-ddc4-45fa-918e-9f5af578088e", "source": "arxiv", "section": "computerScience"}, {"title": "A Walsh Hadamard Derived Linear Vector Symbolic Architecture", "link": "https://arxiv.org/abs/2410.22669", "description": "arXiv:2410.22669v1 Announce Type: new \nAbstract: Vector Symbolic Architectures (VSAs) are one approach to developing Neuro-symbolic AI, where two vectors in $\\mathbb{R}^d$ are `bound' together to produce a new vector in the same space. VSAs support the commutativity and associativity of this binding operation, along with an inverse operation, allowing one to construct symbolic-style manipulations over real-valued vectors. Most VSAs were developed before deep learning and automatic differentiation became popular and instead focused on efficacy in hand-designed systems. In this work, we introduce the Hadamard-derived linear Binding (HLB), which is designed to have favorable computational efficiency, and efficacy in classic VSA tasks, and perform well in differentiable systems. Code is available at https://github.com/FutureComputing4AI/Hadamard-derived-Linear-Binding", "published": "2024-10-31 04:00:00", "id": "cbe99145-7282-4ab2-a64d-158db9936ebe", "source": "arxiv", "section": "computerScience"}, {"title": "IM-GIV: an effective integrity monitoring scheme for tightly-coupled GNSS/INS/Vision integration based on factor graph optimization", "link": "https://arxiv.org/abs/2410.22672", "description": "arXiv:2410.22672v1 Announce Type: new \nAbstract: Global Navigation Satellite System/Inertial Navigation System (GNSS/INS)/Vision integration based on factor graph optimization (FGO) has recently attracted extensive attention in navigation and robotics community. Integrity monitoring (IM) capability is required when FGO-based integrated navigation system is used for safety-critical applications. However, traditional researches on IM of integrated navigation system are mostly based on Kalman filter. It is urgent to develop effective IM scheme for FGO-based GNSS/INS/Vision integration. In this contribution, the position error bounding formula to ensure the integrity of the GNSS/INS/Vision integration based on FGO is designed and validated for the first time. It can be calculated by the linearized equations from the residuals of GNSS pseudo-range, IMU pre-integration and visual measurements. The specific position error bounding is given in the case of GNSS, INS and visual measurement faults. Field experiments were conducted to evaluate and validate the performance of the proposed position error bounding. Experimental results demonstrate that the proposed position error bounding for the GNSS/INS/Vision integration based on FGO can correctly fit the position error against different fault modes, and the availability of integrity in six fault modes is 100% after correct and timely fault exclusion.", "published": "2024-10-31 04:00:00", "id": "cc24e3ad-f6f3-4a11-ae5e-13de8f265c95", "source": "arxiv", "section": "computerScience"}, {"title": "Calibrating Practical Privacy Risks for Differentially Private Machine Learning", "link": "https://arxiv.org/abs/2410.22673", "description": "arXiv:2410.22673v1 Announce Type: new \nAbstract: Differential privacy quantifies privacy through the privacy budget $\\epsilon$, yet its practical interpretation is complicated by variations across models and datasets. Recent research on differentially private machine learning and membership inference has highlighted that with the same theoretical $\\epsilon$ setting, the likelihood-ratio-based membership inference (LiRA) attacking success rate (ASR) may vary according to specific datasets and models, which might be a better indicator for evaluating real-world privacy risks. Inspired by this practical privacy measure, we study the approaches that can lower the attacking success rate to allow for more flexible privacy budget settings in model training. We find that by selectively suppressing privacy-sensitive features, we can achieve lower ASR values without compromising application-specific data utility. We use the SHAP and LIME model explainer to evaluate feature sensitivities and develop feature-masking strategies. Our findings demonstrate that the LiRA $ASR^M$ on model $M$ can properly indicate the inherent privacy risk of a dataset for modeling, and it's possible to modify datasets to enable the use of larger theoretical $\\epsilon$ settings to achieve equivalent practical privacy protection. We have conducted extensive experiments to show the inherent link between ASR and the dataset's privacy risk. By carefully selecting features to mask, we can preserve more data utility with equivalent practical privacy protection and relaxed $\\epsilon$ settings. The implementation details are shared online at the provided GitHub URL \\url{https://anonymous.4open.science/r/On-sensitive-features-and-empirical-epsilon-lower-bounds-BF67/}.", "published": "2024-10-31 04:00:00", "id": "037c213e-941c-4505-9676-c7a2204c895c", "source": "arxiv", "section": "computerScience"}, {"title": "Is Function Similarity Over-Engineered? Building a Benchmark", "link": "https://arxiv.org/abs/2410.22677", "description": "arXiv:2410.22677v1 Announce Type: new \nAbstract: Binary analysis is a core component of many critical security tasks, including reverse engineering, malware analysis, and vulnerability detection. Manual analysis is often time-consuming, but identifying commonly-used or previously-seen functions can reduce the time it takes to understand a new file. However, given the complexity of assembly, and the NP-hard nature of determining function equivalence, this task is extremely difficult. Common approaches often use sophisticated disassembly and decompilation tools, graph analysis, and other expensive pre-processing steps to perform function similarity searches over some corpus. In this work, we identify a number of discrepancies between the current research environment and the underlying application need. To remedy this, we build a new benchmark, REFuSE-Bench, for binary function similarity detection consisting of high-quality datasets and tests that better reflect real-world use cases. In doing so, we address issues like data duplication and accurate labeling, experiment with real malware, and perform the first serious evaluation of ML binary function similarity models on Windows data. Our benchmark reveals that a new, simple basline, one which looks at only the raw bytes of a function, and requires no disassembly or other pre-processing, is able to achieve state-of-the-art performance in multiple settings. Our findings challenge conventional assumptions that complex models with highly-engineered features are being used to their full potential, and demonstrate that simpler approaches can provide significant value.", "published": "2024-10-31 04:00:00", "id": "f0cd780f-019a-47e8-83cf-060e12cd5837", "source": "arxiv", "section": "computerScience"}, {"title": "Backdoor Attack Against Vision Transformers via Attention Gradient-Based Image Erosion", "link": "https://arxiv.org/abs/2410.22678", "description": "arXiv:2410.22678v1 Announce Type: new \nAbstract: Vision Transformers (ViTs) have outperformed traditional Convolutional Neural Networks (CNN) across various computer vision tasks. However, akin to CNN, ViTs are vulnerable to backdoor attacks, where the adversary embeds the backdoor into the victim model, causing it to make wrong predictions about testing samples containing a specific trigger. Existing backdoor attacks against ViTs have the limitation of failing to strike an optimal balance between attack stealthiness and attack effectiveness.\n  In this work, we propose an Attention Gradient-based Erosion Backdoor (AGEB) targeted at ViTs. Considering the attention mechanism of ViTs, AGEB selectively erodes pixels in areas of maximal attention gradient, embedding a covert backdoor trigger. Unlike previous backdoor attacks against ViTs, AGEB achieves an optimal balance between attack stealthiness and attack effectiveness, ensuring the trigger remains invisible to human detection while preserving the model's accuracy on clean samples. Extensive experimental evaluations across various ViT architectures and datasets confirm the effectiveness of AGEB, achieving a remarkable Attack Success Rate (ASR) without diminishing Clean Data Accuracy (CDA). Furthermore, the stealthiness of AGEB is rigorously validated, demonstrating minimal visual discrepancies between the clean and the triggered images.", "published": "2024-10-31 04:00:00", "id": "d854ad6f-5343-4991-b8f8-5a9bf4ef4252", "source": "arxiv", "section": "computerScience"}, {"title": "Practical and Accurate Reconstruction of an Illuminant's Spectral Power Distribution for Inverse Rendering Pipelines", "link": "https://arxiv.org/abs/2410.22679", "description": "arXiv:2410.22679v1 Announce Type: new \nAbstract: Inverse rendering pipelines are gaining prominence in realizing photo-realistic reconstruction of real-world objects for emulating them in virtual reality scenes. Apart from material reflectances, spectral rendering and in-scene illuminants' spectral power distributions (SPDs) play important roles in producing photo-realistic images. We present a simple, low-cost technique to capture and reconstruct the SPD of uniform illuminants. Instead of requiring a costly spectrometer for such measurements, our method uses a diffractive compact disk (CD-ROM) and a machine learning approach for accurate estimation. We show our method to work well with spotlights under simulations and few real-world examples. Presented results clearly demonstrate the reliability of our approach through quantitative and qualitative evaluations, especially in spectral rendering of iridescent materials.", "published": "2024-10-31 04:00:00", "id": "cd022c2f-df53-4e40-8c12-2c690127ef8e", "source": "arxiv", "section": "computerScience"}, {"title": "Byzantine-Robust Federated Learning: An Overview With Focus on Developing Sybil-based Attacks to Backdoor Augmented Secure Aggregation Protocols", "link": "https://arxiv.org/abs/2410.22680", "description": "arXiv:2410.22680v1 Announce Type: new \nAbstract: Federated Learning (FL) paradigms enable large numbers of clients to collaboratively train Machine Learning models on private data. However, due to their multi-party nature, traditional FL schemes are left vulnerable to Byzantine attacks that attempt to hurt model performance by injecting malicious backdoors. A wide variety of prevention methods have been proposed to protect frameworks from such attacks. This paper provides a exhaustive and updated taxonomy of existing methods and frameworks, before zooming in and conducting an in-depth analysis of the strengths and weaknesses of the Robustness of Federated Learning (RoFL) protocol. From there, we propose two novel Sybil-based attacks that take advantage of vulnerabilities in RoFL. Finally, we conclude with comprehensive proposals for future testing, describe and detail implementation of the proposed attacks, and offer direction for improvements in the RoFL protocol as well as Byzantine-robust frameworks as a whole.", "published": "2024-10-31 04:00:00", "id": "bb7ee933-dab8-4aa0-977c-ded24dd23ce6", "source": "arxiv", "section": "computerScience"}, {"title": "Persistent Homology for MCI Classification: A Comparative Analysis between Graph and Vietoris-Rips Filtrations", "link": "https://arxiv.org/abs/2410.22681", "description": "arXiv:2410.22681v1 Announce Type: new \nAbstract: Mild cognitive impairment (MCI), often linked to early neurodegeneration, is characterized by subtle cognitive declines and disruptions in brain connectivity. The present study offers a detailed analysis of topological changes associated with MCI, focusing on two subtypes: Early MCI and Late MCI. This analysis utilizes fMRI time series data from two distinct populations: the publicly available ADNI dataset (Western cohort) and the in-house TLSA dataset (Indian Urban cohort). Persistent Homology, a topological data analysis method, is employed with two distinct filtration techniques - Vietoris-Rips and graph filtration-for classifying MCI subtypes. For Vietoris-Rips filtration, inter-ROI Wasserstein distance matrices between persistent diagrams are used for classification, while graph filtration relies on the top ten most persistent homology features. Comparative analysis shows that the Vietoris-Rips filtration significantly outperforms graph filtration, capturing subtle variations in brain connectivity with greater accuracy. The Vietoris-Rips filtration method achieved the highest classification accuracy of 85.7\\% for distinguishing between age and gender matched healthy controls and MCI, whereas graph filtration reached a maximum accuracy of 71.4\\% for the same task. This superior performance highlights the sensitivity of Vietoris-Rips filtration in detecting intricate topological features associated with neurodegeneration. The findings underscore the potential of persistent homology, particularly when combined with the Wasserstein distance, as a powerful tool for early diagnosis and precise classification of cognitive impairments, offering valuable insights into brain connectivity changes in MCI.", "published": "2024-10-31 04:00:00", "id": "38e9bdef-0179-45a7-ab38-eb571389d25f", "source": "arxiv", "section": "computerScience"}, {"title": "Improving Uncertainty Quantification in Large Language Models via Semantic Embeddings", "link": "https://arxiv.org/abs/2410.22685", "description": "arXiv:2410.22685v1 Announce Type: new \nAbstract: Accurately quantifying uncertainty in large language models (LLMs) is crucial for their reliable deployment, especially in high-stakes applications. Current state-of-the-art methods for measuring semantic uncertainty in LLMs rely on strict bidirectional entailment criteria between multiple generated responses and also depend on sequence likelihoods. While effective, these approaches often overestimate uncertainty due to their sensitivity to minor wording differences, additional correct information, and non-important words in the sequence. We propose a novel approach that leverages semantic embeddings to achieve smoother and more robust estimation of semantic uncertainty in LLMs. By capturing semantic similarities without depending on sequence likelihoods, our method inherently reduces any biases introduced by irrelevant words in the answers. Furthermore, we introduce an amortised version of our approach by explicitly modelling semantics as latent variables in a joint probabilistic model. This allows for uncertainty estimation in the embedding space with a single forward pass, significantly reducing computational overhead compared to existing multi-pass methods. Experiments across multiple question-answering datasets and frontier LLMs demonstrate that our embedding-based methods provide more accurate and nuanced uncertainty quantification than traditional approaches.", "published": "2024-10-31 04:00:00", "id": "6b5ff234-ead8-4373-be6a-fa2d89e047ec", "source": "arxiv", "section": "computerScience"}, {"title": "An optimal parallel-in-time preconditioner for parabolic optimal control problems", "link": "https://arxiv.org/abs/2410.22686", "description": "arXiv:2410.22686v1 Announce Type: new \nAbstract: In this work, we propose a novel diagonalization-based preconditioner for the all-at-once linear system arising from the optimal control problem of parabolic equations. The proposed preconditioner is constructed based on an $\\epsilon$-circulant modification to the rotated block diagonal (RBD) preconditioning technique, which can be efficiently diagonalized by fast Fourier transforms in a parallel-in-time fashion. \\textcolor{black}{To our knowledge, this marks the first application of the $\\epsilon$-circulant modification to RBD preconditioning. Before our work, the studies of PinT preconditioning techniques for the optimal control problem are mainly focused on $\\epsilon$-circulant modification to Schur complement based preconditioners, which involves multiplication of forward and backward evolutionary processes and thus square the condition number. Compared with those Schur complement based preconditioning techniques in the literature, the advantage of the proposed $\\epsilon$-circulant modified RBD preconditioning is that it does not involve the multiplication of forward and backward evolutionary processes. When the generalized minimal residual method is deployed on the preconditioned system, we prove that when choosing $\\epsilon=\\mathcal{O}(\\sqrt{\\tau})$ with $\\tau$ being the temporal step-size , the convergence rate of the preconditioned GMRES solver is independent of the matrix size and the regularization parameter. Such restriction on $\\epsilon$ is more relax than the assumptions on $\\epsilon$ from other works related to $\\epsilon$-circulant based preconditioning techniques for the optimal control problem. Numerical results are provided to demonstrate the effectiveness of our proposed solvers.", "published": "2024-10-31 04:00:00", "id": "2e61fdca-14be-49f2-b02c-f7f843b16c9a", "source": "arxiv", "section": "computerScience"}, {"title": "Multi-Task Interactive Robot Fleet Learning with Visual World Models", "link": "https://arxiv.org/abs/2410.22689", "description": "arXiv:2410.22689v1 Announce Type: new \nAbstract: Recent advancements in large-scale multi-task robot learning offer the potential for deploying robot fleets in household and industrial settings, enabling them to perform diverse tasks across various environments. However, AI-enabled robots often face challenges with generalization and robustness when exposed to real-world variability and uncertainty. We introduce Sirius-Fleet, a multi-task interactive robot fleet learning framework to address these challenges. Sirius-Fleet monitors robot performance during deployment and involves humans to correct the robot's actions when necessary. We employ a visual world model to predict the outcomes of future actions and build anomaly predictors to predict whether they will likely result in anomalies. As the robot autonomy improves, the anomaly predictors automatically adapt their prediction criteria, leading to fewer requests for human intervention and gradually reducing human workload over time. Evaluations on large-scale benchmarks demonstrate Sirius-Fleet's effectiveness in improving multi-task policy performance and monitoring accuracy. We demonstrate Sirius-Fleet's performance in both RoboCasa in simulation and Mutex in the real world, two diverse, large-scale multi-task benchmarks. More information is available on the project website: https://ut-austin-rpl.github.io/sirius-fleet", "published": "2024-10-31 04:00:00", "id": "1251a9c2-4419-4163-9a92-2fbad380b11d", "source": "arxiv", "section": "computerScience"}, {"title": "Choice between Partial Trajectories", "link": "https://arxiv.org/abs/2410.22690", "description": "arXiv:2410.22690v1 Announce Type: new \nAbstract: As AI agents generate increasingly sophisticated behaviors, manually encoding human preferences to guide these agents becomes more challenging. To address this, it has been suggested that agents instead learn preferences from human choice data. This approach requires a model of choice behavior that the agent can use to interpret the data. For choices between partial trajectories of states and actions, previous models assume choice probabilities to be determined by the partial return or the cumulative advantage.\n  We consider an alternative model based instead on the bootstrapped return, which adds to the partial return an estimate of the future return. Benefits of the bootstrapped return model stem from its treatment of human beliefs. Unlike partial return, choices based on bootstrapped return reflect human beliefs about the environment. Further, while recovering the reward function from choices based on cumulative advantage requires that those beliefs are correct, doing so from choices based on bootstrapped return does not.\n  To motivate the bootstrapped return model, we formulate axioms and prove an Alignment Theorem. This result formalizes how, for a general class of human preferences, such models are able to disentangle goals from beliefs. This ensures recovery of an aligned reward function when learning from choices based on bootstrapped return.\n  The bootstrapped return model also affords greater robustness to choice behavior. Even when choices are based on partial return, learning via a bootstrapped return model recovers an aligned reward function. The same holds with choices based on the cumulative advantage if the human and the agent both adhere to correct and consistent beliefs about the environment. On the other hand, if choices are based on bootstrapped return, learning via partial return or cumulative advantage models does not generally produce an aligned reward function.", "published": "2024-10-31 04:00:00", "id": "47227d81-2f11-40a5-8252-37ca7d65bbc7", "source": "arxiv", "section": "computerScience"}, {"title": "MiniTac: An Ultra-Compact 8 mm Vision-Based Tactile Sensor for Enhanced Palpation in Robot-Assisted Minimally Invasive Surgery", "link": "https://arxiv.org/abs/2410.22691", "description": "arXiv:2410.22691v1 Announce Type: new \nAbstract: Robot-assisted minimally invasive surgery (RAMIS) provides substantial benefits over traditional open and laparoscopic methods. However, a significant limitation of RAMIS is the surgeon's inability to palpate tissues, a crucial technique for examining tissue properties and detecting abnormalities, restricting the widespread adoption of RAMIS. To overcome this obstacle, we introduce MiniTac, a novel vision-based tactile sensor with an ultra-compact cross-sectional diameter of 8 mm, designed for seamless integration into mainstream RAMIS devices, particularly the Da Vinci surgical systems. MiniTac features a novel mechanoresponsive photonic elastomer membrane that changes color distribution under varying contact pressures. This color change is captured by an embedded miniature camera, allowing MiniTac to detect tumors both on the tissue surface and in deeper layers typically obscured from endoscopic view. MiniTac's efficacy has been rigorously tested on both phantoms and ex-vivo tissues. By leveraging advanced mechanoresponsive photonic materials, MiniTac represents a significant advancement in integrating tactile sensing into RAMIS, potentially expanding its applicability to a wider array of clinical scenarios that currently rely on traditional surgical approaches.", "published": "2024-10-31 04:00:00", "id": "80647a8d-2efa-4292-9919-945d7b7ae0dd", "source": "arxiv", "section": "computerScience"}, {"title": "Permutation Invariant Learning with High-Dimensional Particle Filters", "link": "https://arxiv.org/abs/2410.22695", "description": "arXiv:2410.22695v1 Announce Type: new \nAbstract: Sequential learning in deep models often suffers from challenges such as catastrophic forgetting and loss of plasticity, largely due to the permutation dependence of gradient-based algorithms, where the order of training data impacts the learning outcome. In this work, we introduce a novel permutation-invariant learning framework based on high-dimensional particle filters. We theoretically demonstrate that particle filters are invariant to the sequential ordering of training minibatches or tasks, offering a principled solution to mitigate catastrophic forgetting and loss-of-plasticity. We develop an efficient particle filter for optimizing high-dimensional models, combining the strengths of Bayesian methods with gradient-based optimization. Through extensive experiments on continual supervised and reinforcement learning benchmarks, including SplitMNIST, SplitCIFAR100, and ProcGen, we empirically show that our method consistently improves performance, while reducing variance compared to standard baselines.", "published": "2024-10-31 04:00:00", "id": "21268134-95bf-42f1-aee6-7dfdcc404389", "source": "arxiv", "section": "computerScience"}, {"title": "MassiveGNN: Efficient Training via Prefetching for Massively Connected Distributed Graphs", "link": "https://arxiv.org/abs/2410.22697", "description": "arXiv:2410.22697v1 Announce Type: new \nAbstract: Graph Neural Networks (GNN) are indispensable in learning from graph-structured data, yet their rising computational costs, especially on massively connected graphs, pose significant challenges in terms of execution performance. To tackle this, distributed-memory solutions such as partitioning the graph to concurrently train multiple replicas of GNNs are in practice. However, approaches requiring a partitioned graph usually suffer from communication overhead and load imbalance, even under optimal partitioning and communication strategies due to irregularities in the neighborhood minibatch sampling.\n  This paper proposes practical trade-offs for improving the sampling and communication overheads for representation learning on distributed graphs (using popular GraphSAGE architecture) by developing a parameterized continuous prefetch and eviction scheme on top of the state-of-the-art Amazon DistDGL distributed GNN framework, demonstrating about 15-40% improvement in end-to-end training performance on the National Energy Research Scientific Computing Center's (NERSC) Perlmutter supercomputer for various OGB datasets.", "published": "2024-10-31 04:00:00", "id": "0eea699d-a576-4e5f-8888-64e808e4bc43", "source": "arxiv", "section": "computerScience"}, {"title": "An Iterative Algorithm for Regularized Non-negative Matrix Factorizations", "link": "https://arxiv.org/abs/2410.22698", "description": "arXiv:2410.22698v1 Announce Type: new \nAbstract: We generalize the non-negative matrix factorization algorithm of Lee and Seung to accept a weighted norm, and to support ridge and Lasso regularization. We recast the Lee and Seung multiplicative update as an additive update which does not get stuck on zero values. We apply the companion R package rnnmf to the problem of finding a reduced rank representation of a database of cocktails.", "published": "2024-10-31 04:00:00", "id": "13447697-358f-494e-81ac-c95086984723", "source": "arxiv", "section": "computerScience"}, {"title": "Exactly Minimax-Optimal Locally Differentially Private Sampling", "link": "https://arxiv.org/abs/2410.22699", "description": "arXiv:2410.22699v1 Announce Type: new \nAbstract: The sampling problem under local differential privacy has recently been studied with potential applications to generative models, but a fundamental analysis of its privacy-utility trade-off (PUT) remains incomplete. In this work, we define the fundamental PUT of private sampling in the minimax sense, using the f-divergence between original and sampling distributions as the utility measure. We characterize the exact PUT for both finite and continuous data spaces under some mild conditions on the data distributions, and propose sampling mechanisms that are universally optimal for all f-divergences. Our numerical experiments demonstrate the superiority of our mechanisms over baselines, in terms of theoretical utilities for finite data space and of empirical utilities for continuous data space.", "published": "2024-10-31 04:00:00", "id": "ad74753f-9d99-43b5-9208-67366a3253e8", "source": "arxiv", "section": "computerScience"}, {"title": "Geometry Cloak: Preventing TGS-based 3D Reconstruction from Copyrighted Images", "link": "https://arxiv.org/abs/2410.22705", "description": "arXiv:2410.22705v1 Announce Type: new \nAbstract: Single-view 3D reconstruction methods like Triplane Gaussian Splatting (TGS) have enabled high-quality 3D model generation from just a single image input within seconds. However, this capability raises concerns about potential misuse, where malicious users could exploit TGS to create unauthorized 3D models from copyrighted images. To prevent such infringement, we propose a novel image protection approach that embeds invisible geometry perturbations, termed \"geometry cloaks\", into images before supplying them to TGS. These carefully crafted perturbations encode a customized message that is revealed when TGS attempts 3D reconstructions of the cloaked image. Unlike conventional adversarial attacks that simply degrade output quality, our method forces TGS to fail the 3D reconstruction in a specific way - by generating an identifiable customized pattern that acts as a watermark. This watermark allows copyright holders to assert ownership over any attempted 3D reconstructions made from their protected images. Extensive experiments have verified the effectiveness of our geometry cloak. Our project is available at https://qsong2001.github.io/geometry_cloak.", "published": "2024-10-31 04:00:00", "id": "4bb8a354-cd04-42fb-bf90-4a572d24641a", "source": "arxiv", "section": "computerScience"}, {"title": "Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization", "link": "https://arxiv.org/abs/2410.22707", "description": "arXiv:2410.22707v1 Announce Type: new \nAbstract: State recognition of the environment and objects, such as the open/closed state of doors and the on/off of lights, is indispensable for robots that perform daily life support and security tasks. Until now, state recognition methods have been based on training neural networks from manual annotations, preparing special sensors for the recognition, or manually programming to extract features from point clouds or raw images. In contrast, we propose a robotic state recognition method using a pre-trained vision-language model, which is capable of Image-to-Text Retrieval (ITR) tasks. We prepare several kinds of language prompts in advance, calculate the similarity between these prompts and the current image by ITR, and perform state recognition. By applying the optimal weighting to each prompt using black-box optimization, state recognition can be performed with higher accuracy. Experiments show that this theory enables a variety of state recognitions by simply preparing multiple prompts without retraining neural networks or manual programming. In addition, since only prompts and their weights need to be prepared for each recognizer, there is no need to prepare multiple models, which facilitates resource management. It is possible to recognize the open/closed state of transparent doors, the state of whether water is running or not from a faucet, and even the qualitative state of whether a kitchen is clean or not, which have been challenging so far, through language.", "published": "2024-10-31 04:00:00", "id": "baaec6b7-836f-4a66-9e10-548faa7fb3c1", "source": "arxiv", "section": "computerScience"}, {"title": "FilterViT and DropoutViT: Lightweight Vision Transformer Models for Efficient Attention Mechanisms", "link": "https://arxiv.org/abs/2410.22709", "description": "arXiv:2410.22709v1 Announce Type: new \nAbstract: In this study, we introduce FilterViT, an enhanced version of MobileViT, which leverages an attention-based mechanism for early-stage downsampling. Traditional QKV operations on high-resolution feature maps are computationally intensive due to the abundance of tokens. To address this, we propose a filter attention mechanism using a convolutional neural network (CNN) to generate an importance mask, focusing attention on key image regions. The method significantly reduces computational complexity while maintaining interpretability, as it highlights essential image areas. Experimental results show that FilterViT achieves substantial gains in both efficiency and accuracy compared to other models. We also introduce DropoutViT, a variant that uses a stochastic approach for pixel selection, further enhancing robustness.", "published": "2024-10-31 04:00:00", "id": "cb9daa6f-66fb-434a-9fab-fb6101b6d60a", "source": "arxiv", "section": "computerScience"}, {"title": "LoFLAT: Local Feature Matching using Focused Linear Attention Transformer", "link": "https://arxiv.org/abs/2410.22710", "description": "arXiv:2410.22710v1 Announce Type: new \nAbstract: Local feature matching is an essential technique in image matching and plays a critical role in a wide range of vision-based applications. However, existing Transformer-based detector-free local feature matching methods encounter challenges due to the quadratic computational complexity of attention mechanisms, especially at high resolutions. However, while existing Transformer-based detector-free local feature matching methods have reduced computational costs using linear attention mechanisms, they still struggle to capture detailed local interactions, which affects the accuracy and robustness of precise local correspondences. In order to enhance representations of attention mechanisms while preserving low computational complexity, we propose the LoFLAT, a novel Local Feature matching using Focused Linear Attention Transformer in this paper. Our LoFLAT consists of three main modules: the Feature Extraction Module, the Feature Transformer Module, and the Matching Module. Specifically, the Feature Extraction Module firstly uses ResNet and a Feature Pyramid Network to extract hierarchical features. The Feature Transformer Module further employs the Focused Linear Attention to refine attention distribution with a focused mapping function and to enhance feature diversity with a depth-wise convolution. Finally, the Matching Module predicts accurate and robust matches through a coarse-to-fine strategy. Extensive experimental evaluations demonstrate that the proposed LoFLAT outperforms the LoFTR method in terms of both efficiency and accuracy.", "published": "2024-10-31 04:00:00", "id": "04ce10cb-3d4d-4634-be77-cdcfe0d53380", "source": "arxiv", "section": "computerScience"}, {"title": "SCRREAM : SCan, Register, REnder And Map:A Framework for Annotating Accurate and Dense 3D Indoor Scenes with a Benchmark", "link": "https://arxiv.org/abs/2410.22715", "description": "arXiv:2410.22715v1 Announce Type: new \nAbstract: Traditionally, 3d indoor datasets have generally prioritized scale over ground-truth accuracy in order to obtain improved generalization. However, using these datasets to evaluate dense geometry tasks, such as depth rendering, can be problematic as the meshes of the dataset are often incomplete and may produce wrong ground truth to evaluate the details. In this paper, we propose SCRREAM, a dataset annotation framework that allows annotation of fully dense meshes of objects in the scene and registers camera poses on the real image sequence, which can produce accurate ground truth for both sparse 3D as well as dense 3D tasks. We show the details of the dataset annotation pipeline and showcase four possible variants of datasets that can be obtained from our framework with example scenes, such as indoor reconstruction and SLAM, scene editing & object removal, human reconstruction and 6d pose estimation. Recent pipelines for indoor reconstruction and SLAM serve as new benchmarks. In contrast to previous indoor dataset, our design allows to evaluate dense geometry tasks on eleven sample scenes against accurately rendered ground truth depth maps.", "published": "2024-10-31 04:00:00", "id": "f6ef446d-fa90-4396-aa33-fea92674f1ea", "source": "arxiv", "section": "computerScience"}, {"title": "Exposing Cross-Platform Coordinated Inauthentic Activity in the Run-Up to the 2024 U.S. Election", "link": "https://arxiv.org/abs/2410.22716", "description": "arXiv:2410.22716v1 Announce Type: new \nAbstract: Coordinated information operations remain a persistent challenge on social media, despite platform efforts to curb them. While previous research has primarily focused on identifying these operations within individual platforms, this study shows that coordination frequently transcends platform boundaries. Leveraging newly collected data of online conversations related to the 2024 U.S. Election across $\\mathbb{X}$ (formerly, Twitter), Facebook, and Telegram, we construct similarity networks to detect coordinated communities exhibiting suspicious sharing behaviors within and across platforms. Proposing an advanced coordination detection model, we reveal evidence of potential foreign interference, with Russian-affiliated media being systematically promoted across Telegram and $\\mathbb{X}$. Our analysis also uncovers substantial intra- and cross-platform coordinated inauthentic activity, driving the spread of highly partisan, low-credibility, and conspiratorial content. These findings highlight the urgent need for regulatory measures that extend beyond individual platforms to effectively address the growing challenge of cross-platform coordinated influence campaigns.", "published": "2024-10-31 04:00:00", "id": "2c3b02e6-d076-4f70-8217-c7660b97aaa0", "source": "arxiv", "section": "computerScience"}, {"title": "Uniform Sampling of Negative Edge Weights in Shortest Path Networks", "link": "https://arxiv.org/abs/2410.22717", "description": "arXiv:2410.22717v1 Announce Type: new \nAbstract: We consider a maximum entropy edge weight model for shortest path networks that allows for negative weights. Given a graph $G$ and possible weights $\\mathcal{W}$ typically consisting of positive and negative values, the model selects edge weights $w \\in \\mathcal{W}^m$ uniformly at random from all weights that do not introduce a negative cycle. We propose an MCMC process and show that (i) it converges to the required distribution and (ii) that the mixing time on the cycle graph is polynomial. We then engineer an implementation of the process using a dynamic version of Johnson's algorithm in connection with a bidirectional Dijkstra search. We empirically study the performance characteristics of an implementation of the novel sampling algorithm as well as the output produced by the model.", "published": "2024-10-31 04:00:00", "id": "5226fb71-863f-4ef1-add4-d1c3e79f52c7", "source": "arxiv", "section": "computerScience"}, {"title": "Community search signatures as foundation features for human-centered geospatial modeling", "link": "https://arxiv.org/abs/2410.22721", "description": "arXiv:2410.22721v1 Announce Type: new \nAbstract: Aggregated relative search frequencies offer a unique composite signal reflecting people's habits, concerns, interests, intents, and general information needs, which are not found in other readily available datasets. Temporal search trends have been successfully used in time series modeling across a variety of domains such as infectious diseases, unemployment rates, and retail sales. However, most existing applications require curating specialized datasets of individual keywords, queries, or query clusters, and the search data need to be temporally aligned with the outcome variable of interest. We propose a novel approach for generating an aggregated and anonymized representation of search interest as foundation features at the community level for geospatial modeling. We benchmark these features using spatial datasets across multiple domains. In zip codes with a population greater than 3000 that cover over 95% of the contiguous US population, our models for predicting missing values in a 20% set of holdout counties achieve an average $R^2$ score of 0.74 across 21 health variables, and 0.80 across 6 demographic and environmental variables. Our results demonstrate that these search features can be used for spatial predictions without strict temporal alignment, and that the resulting models outperform spatial interpolation and state of the art methods using satellite imagery features.", "published": "2024-10-31 04:00:00", "id": "d78395c7-1e8c-47bd-bdb5-c051d2bef5c5", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing binary classification: A new stacking method via leveraging computational geometry", "link": "https://arxiv.org/abs/2410.22722", "description": "arXiv:2410.22722v1 Announce Type: new \nAbstract: Stacking, a potent ensemble learning method, leverages a meta-model to harness the strengths of multiple base models, thereby enhancing prediction accuracy. Traditional stacking techniques typically utilize established learning models, such as logistic regression, as the meta-model. This paper introduces a novel approach that integrates computational geometry techniques, specifically solving the maximum weighted rectangle problem, to develop a new meta-model for binary classification. Our method is evaluated on multiple open datasets, with statistical analysis showing its stability and demonstrating improvements in accuracy compared to current state-of-the-art stacking methods with out-of-fold predictions. This new stacking method also boasts two significant advantages: enhanced interpretability and the elimination of hyperparameter tuning for the meta-model, thus increasing its practicality. These merits make our method highly applicable not only in stacking ensemble learning but also in various real-world applications, such as hospital health evaluation scoring and bank credit scoring systems, offering a fresh evaluation perspective.", "published": "2024-10-31 04:00:00", "id": "d3731500-be36-4703-94c4-ef3a98fcab2d", "source": "arxiv", "section": "computerScience"}, {"title": "One Prompt to Verify Your Models: Black-Box Text-to-Image Models Verification via Non-Transferable Adversarial Attacks", "link": "https://arxiv.org/abs/2410.22725", "description": "arXiv:2410.22725v1 Announce Type: new \nAbstract: Recently, the success of Text-to-Image (T2I) models has led to the rise of numerous third-party platforms, which claim to provide cheaper API services and more flexibility in model options. However, this also raises a new security concern: Are these third-party services truly offering the models they claim? To address this problem, we propose the first T2I model verification method named Text-to-Image Model Verification via Non-Transferable Adversarial Attacks (TVN). The non-transferability of adversarial examples means that these examples are only effective on a target model and ineffective on other models, thereby allowing for the verification of the target model. TVN utilizes the Non-dominated Sorting Genetic Algorithm II (NSGA-II) to optimize the cosine similarity of a prompt's text encoding, generating non-transferable adversarial prompts. By calculating the CLIP-text scores between the non-transferable adversarial prompts without perturbations and the images, we can verify if the model matches the claimed target model, based on a 3-sigma threshold. The experiments showed that TVN performed well in both closed-set and open-set scenarios, achieving a verification accuracy of over 90\\%. Moreover, the adversarial prompts generated by TVN significantly reduced the CLIP-text scores of the target model, while having little effect on other models.", "published": "2024-10-31 04:00:00", "id": "b733e2d3-d770-4bca-8312-8a0bbf1941bd", "source": "arxiv", "section": "computerScience"}, {"title": "Offline Behavior Distillation", "link": "https://arxiv.org/abs/2410.22728", "description": "arXiv:2410.22728v1 Announce Type: new \nAbstract: Massive reinforcement learning (RL) data are typically collected to train policies offline without the need for interactions, but the large data volume can cause training inefficiencies. To tackle this issue, we formulate offline behavior distillation (OBD), which synthesizes limited expert behavioral data from sub-optimal RL data, enabling rapid policy learning. We propose two naive OBD objectives, DBC and PBC, which measure distillation performance via the decision difference between policies trained on distilled data and either offline data or a near-expert policy. Due to intractable bi-level optimization, the OBD objective is difficult to minimize to small values, which deteriorates PBC by its distillation performance guarantee with quadratic discount complexity $\\mathcal{O}(1/(1-\\gamma)^2)$. We theoretically establish the equivalence between the policy performance and action-value weighted decision difference, and introduce action-value weighted PBC (Av-PBC) as a more effective OBD objective. By optimizing the weighted decision difference, Av-PBC achieves a superior distillation guarantee with linear discount complexity $\\mathcal{O}(1/(1-\\gamma))$. Extensive experiments on multiple D4RL datasets reveal that Av-PBC offers significant improvements in OBD performance, fast distillation convergence speed, and robust cross-architecture/optimizer generalization.", "published": "2024-10-31 04:00:00", "id": "4c4d4088-1472-4c50-b8db-7f87eb9602af", "source": "arxiv", "section": "computerScience"}, {"title": "Extensional Properties of Recurrent Neural Networks", "link": "https://arxiv.org/abs/2410.22730", "description": "arXiv:2410.22730v1 Announce Type: new \nAbstract: A property of a recurrent neural network (RNN) is called \\emph{extensional} if, loosely speaking, it is a property of the function computed by the RNN rather than a property of the RNN algorithm. Many properties of interest in RNNs are extensional, for example, robustness against small changes of input or good clustering of inputs. Given an RNN, it is natural to ask whether it has such a property. We give a negative answer to the general question about testing extensional properties of RNNs. Namely, we prove a version of Rice's theorem for RNNs: any nontrivial extensional property of RNNs is undecidable.", "published": "2024-10-31 04:00:00", "id": "10bb2ab9-3a79-4043-a04e-285e6c1556fc", "source": "arxiv", "section": "computerScience"}, {"title": "ETO:Efficient Transformer-based Local Feature Matching by Organizing Multiple Homography Hypotheses", "link": "https://arxiv.org/abs/2410.22733", "description": "arXiv:2410.22733v1 Announce Type: new \nAbstract: We tackle the efficiency problem of learning local feature matching.Recent advancements have given rise to purely CNN-based and transformer-based approaches, each augmented with deep learning techniques. While CNN-based methods often excel in matching speed, transformer-based methods tend to provide more accurate matches. We propose an efficient transformer-based network architecture for local feature matching.This technique is built on constructing multiple homography hypotheses to approximate the continuous correspondence in the real world and uni-directional cross-attention to accelerate the refinement. On the YFCC100M dataset, our matching accuracy is competitive with LoFTR, a state-of-the-art transformer-based architecture, while the inference speed is boosted to 4 times, even outperforming the CNN-based methods.Comprehensive evaluations on other open datasets such as Megadepth, ScanNet, and HPatches demonstrate our method's efficacy, highlighting its potential to significantly enhance a wide array of downstream applications.", "published": "2024-10-31 04:00:00", "id": "b7f201fd-abb1-4390-ae5d-8b90b28671ff", "source": "arxiv", "section": "computerScience"}, {"title": "MIXAD: Memory-Induced Explainable Time Series Anomaly Detection", "link": "https://arxiv.org/abs/2410.22735", "description": "arXiv:2410.22735v1 Announce Type: new \nAbstract: For modern industrial applications, accurately detecting and diagnosing anomalies in multivariate time series data is essential. Despite such need, most state-of-the-art methods often prioritize detection performance over model interpretability. Addressing this gap, we introduce MIXAD (Memory-Induced Explainable Time Series Anomaly Detection), a model designed for interpretable anomaly detection. MIXAD leverages a memory network alongside spatiotemporal processing units to understand the intricate dynamics and topological structures inherent in sensor relationships. We also introduce a novel anomaly scoring method that detects significant shifts in memory activation patterns during anomalies. Our approach not only ensures decent detection performance but also outperforms state-of-the-art baselines by 34.30% and 34.51% in interpretability metrics.", "published": "2024-10-31 04:00:00", "id": "99eb3c39-609c-4a87-8b12-ee2a0fdf191d", "source": "arxiv", "section": "computerScience"}, {"title": "Constructing Multimodal Datasets from Scratch for Rapid Development of a Japanese Visual Language Model", "link": "https://arxiv.org/abs/2410.22736", "description": "arXiv:2410.22736v1 Announce Type: new \nAbstract: To develop high-performing Visual Language Models (VLMs), it is essential to prepare multimodal resources, such as image-text pairs, interleaved data, and instruction data. While multimodal resources for English are abundant, there is a significant lack of corresponding resources for non-English languages, such as Japanese. To address this problem, we take Japanese as a non-English language and propose a method for rapidly creating Japanese multimodal datasets from scratch. We collect Japanese image-text pairs and interleaved data from web archives and generate Japanese instruction data directly from images using an existing VLM. Our experimental results show that a VLM trained on these native datasets outperforms those relying on machine-translated content.", "published": "2024-10-31 04:00:00", "id": "cf7fb833-e234-4815-a297-065dc44ae0cf", "source": "arxiv", "section": "computerScience"}, {"title": "Toward Designing Accessible and Meaningful Software for Cancer Survivors", "link": "https://arxiv.org/abs/2410.22740", "description": "arXiv:2410.22740v1 Announce Type: new \nAbstract: Cancer survivors experience a wide range of impairments arising from cancer or its treatment, such as chemo brain, visual impairments, and physical impairments. These impairments degrade their quality of life and potentially make software use more challenging for them. However, there has been limited research on designing accessible software for cancer survivors. To bridge this research gap, we conducted a formative study including a survey (n=46), semi-structured interviews (n=20), and a diary study (n=10) with cancer survivors. Our results revealed a wide range of impairments experienced by cancer survivors, including chemo brain, neuropathy, and visual impairments. Cancer survivors heavily relied on software for socialization, health purposes, and cancer advocacy, but their impairments made software use more challenging for them. Based on the results, we offer a set of accessibility guidelines that software designers can utilize when creating applications for cancer survivors. Further, we suggest design features for inclusion, such as health resources, socialization tools, and games, tailored to the needs of cancer survivors. This research aims to spotlight cancer survivors' software accessibility challenges and software needs and invite more research in this important yet under-investigated domain.", "published": "2024-10-31 04:00:00", "id": "b46a508e-f65b-40df-853f-e28cfba6f199", "source": "arxiv", "section": "computerScience"}, {"title": "Designing AI Personalities: Enhancing Human-Agent Interaction Through Thoughtful Persona Design", "link": "https://arxiv.org/abs/2410.22744", "description": "arXiv:2410.22744v1 Announce Type: new \nAbstract: In the rapidly evolving field of artificial intelligence (AI) agents, designing the agent's characteristics is crucial for shaping user experience. This workshop aims to establish a research community focused on AI agent persona design for various contexts, such as in-car assistants, educational tools, and smart home environments. We will explore critical aspects of persona design, such as voice, embodiment, and demographics, and their impact on user satisfaction and engagement. Through discussions and hands-on activities, we aim to propose practices and standards that enhance the ecological validity of agent personas. Topics include the design of conversational interfaces, the influence of agent personas on user experience, and approaches for creating contextually appropriate AI agents. This workshop will provide a platform for building a community dedicated to developing AI agent personas that better fit diverse, everyday interactions.", "published": "2024-10-31 04:00:00", "id": "e0044e7b-dc7c-4eaa-ae5a-9497fcd547c8", "source": "arxiv", "section": "computerScience"}, {"title": "Analysis of Classifier Training on Synthetic Data for Cross-Domain Datasets", "link": "https://arxiv.org/abs/2410.22748", "description": "arXiv:2410.22748v1 Announce Type: new \nAbstract: A major challenges of deep learning (DL) is the necessity to collect huge amounts of training data. Often, the lack of a sufficiently large dataset discourages the use of DL in certain applications. Typically, acquiring the required amounts of data costs considerable time, material and effort. To mitigate this problem, the use of synthetic images combined with real data is a popular approach, widely adopted in the scientific community to effectively train various detectors. In this study, we examined the potential of synthetic data-based training in the field of intelligent transportation systems. Our focus is on camera-based traffic sign recognition applications for advanced driver assistance systems and autonomous driving. The proposed augmentation pipeline of synthetic datasets includes novel augmentation processes such as structured shadows and gaussian specular highlights. A well-known DL model was trained with different datasets to compare the performance of synthetic and real image-based trained models. Additionally, a new, detailed method to objectively compare these models is proposed. Synthetic images are generated using a semi-supervised errors-guide method which is also described. Our experiments showed that a synthetic image-based approach outperforms in most cases real image-based training when applied to cross-domain test datasets (+10% precision for GTSRB dataset) and consequently, the generalization of the model is improved decreasing the cost of acquiring images.", "published": "2024-10-31 04:00:00", "id": "d624afa2-f6be-4a54-93aa-9d993568c0c4", "source": "arxiv", "section": "computerScience"}, {"title": "Understanding Aggregations of Proper Learners in Multiclass Classification", "link": "https://arxiv.org/abs/2410.22749", "description": "arXiv:2410.22749v1 Announce Type: new \nAbstract: Multiclass learnability is known to exhibit a properness barrier: there are learnable classes which cannot be learned by any proper learner. Binary classification faces no such barrier for learnability, but a similar one for optimal learning, which can in general only be achieved by improper learners. Fortunately, recent advances in binary classification have demonstrated that this requirement can be satisfied using aggregations of proper learners, some of which are strikingly simple. This raises a natural question: to what extent can simple aggregations of proper learners overcome the properness barrier in multiclass classification?\n  We give a positive answer to this question for classes which have finite Graph dimension, $d_G$. Namely, we demonstrate that the optimal binary learners of Hanneke, Larsen, and Aden-Ali et al. (appropriately generalized to the multiclass setting) achieve sample complexity $O\\left(\\frac{d_G + \\ln(1 / \\delta)}{\\epsilon}\\right)$. This forms a strict improvement upon the sample complexity of ERM. We complement this with a lower bound demonstrating that for certain classes of Graph dimension $d_G$, majorities of ERM learners require $\\Omega \\left( \\frac{d_G + \\ln(1 / \\delta)}{\\epsilon}\\right)$ samples. Furthermore, we show that a single ERM requires $\\Omega \\left(\\frac{d_G \\ln(1 / \\epsilon) + \\ln(1 / \\delta)}{\\epsilon}\\right)$ samples on such classes, exceeding the lower bound of Daniely et al. (2015) by a factor of $\\ln(1 / \\epsilon)$. For multiclass learning in full generality -- i.e., for classes of finite DS dimension but possibly infinite Graph dimension -- we give a strong refutation to these learning strategies, by exhibiting a learnable class which cannot be learned to constant error by any aggregation of a finite number of proper learners.", "published": "2024-10-31 04:00:00", "id": "20d2ad0d-30c1-4850-a122-a7cfb4e47db5", "source": "arxiv", "section": "computerScience"}, {"title": "SoftCTRL: Soft conservative KL-control of Transformer Reinforcement Learning for Autonomous Driving", "link": "https://arxiv.org/abs/2410.22752", "description": "arXiv:2410.22752v1 Announce Type: new \nAbstract: In recent years, motion planning for urban self-driving cars (SDV) has become a popular problem due to its complex interaction of road components. To tackle this, many methods have relied on large-scale, human-sampled data processed through Imitation learning (IL). Although effective, IL alone cannot adequately handle safety and reliability concerns. Combining IL with Reinforcement learning (RL) by adding KL divergence between RL and IL policy to the RL loss can alleviate IL's weakness but suffer from over-conservation caused by covariate shift of IL. To address this limitation, we introduce a method that combines IL with RL using an implicit entropy-KL control that offers a simple way to reduce the over-conservation characteristic. In particular, we validate different challenging simulated urban scenarios from the unseen dataset, indicating that although IL can perform well in imitation tasks, our proposed method significantly improves robustness (over 17\\% reduction in failures) and generates human-like driving behavior.", "published": "2024-10-31 04:00:00", "id": "fa04664b-9b0c-4071-9642-9f6edcc7da2e", "source": "arxiv", "section": "computerScience"}, {"title": "Synthesis of Timeline-Based Planning Strategies Avoiding Determinization", "link": "https://arxiv.org/abs/2410.22757", "description": "arXiv:2410.22757v1 Announce Type: new \nAbstract: Qualitative timeline-based planning models domains as sets of independent, but interacting, components whose behaviors over time, the timelines, are governed by sets of qualitative temporal constraints (ordering relations), called synchronization rules. Its plan-existence problem has been shown to be PSPACE-complete; in particular, PSPACE-membership has been proved via reduction to the nonemptiness problem for nondeterministic finite automata. However, nondeterministic automata cannot be directly used to synthesize planning strategies as a costly determinization step is needed. In this paper, we identify a large fragment of qualitative timeline-based planning whose plan-existence problem can be directly mapped into the nonemptiness problem of deterministic finite automata, which can then be exploited to synthesize strategies. In addition, we identify a  maximal subset of Allen's relations that fits into such a deterministic fragment.", "published": "2024-10-31 04:00:00", "id": "13c92baf-6a69-4a53-a800-d195ac595466", "source": "arxiv", "section": "computerScience"}, {"title": "Mapped Hermite Functions and their applications to two-dimensional weakly singular Fredholm-Hammerstein integral equations", "link": "https://arxiv.org/abs/2410.22759", "description": "arXiv:2410.22759v1 Announce Type: new \nAbstract: The Fredholm-Hammerstein integral equations (FHIEs) with weakly singular kernels exhibit multi-point singularity at the endpoints or boundaries. The dense discretized matrices result in high computational complexity when employing numerical methods. To address this, we propose a novel class of mapped Hermite functions, which are constructed by applying a mapping to Hermite polynomials.We establish fundamental approximation theory for the orthogonal functions. We propose MHFs-spectral collocation method and MHFs-smoothing transformation method to solve the two-point weakly singular FHIEs, respectively. Error analysis and numerical results demonstrate that our methods, based on the new orthogonal functions, are particularly effective for handling problems with weak singularities at two endpoints, yielding exponential convergence rate. We position this work as the first to directly study the mapped spectral method for multi-point singularity problems, to the best of our knowledge.", "published": "2024-10-31 04:00:00", "id": "5e68d5e6-c920-4789-a5bf-e35885f209b6", "source": "arxiv", "section": "computerScience"}, {"title": "Reactive Synthesis for Expected Impacts", "link": "https://arxiv.org/abs/2410.22760", "description": "arXiv:2410.22760v1 Announce Type: new \nAbstract: As business processes become increasingly complex,  effectively modeling decision points, their likelihood,  and resource consumption is crucial for optimizing operations.  To address this challenge, this paper introduces a formal  extension of the Business Process Model and Notation (BPMN)  that incorporates choices, probabilities, and impacts,  referred to as BPMN+CPI. This extension is motivated  by the growing emphasis on precise control within  business process management, where carefully  selecting decision pathways in repeated instances  is crucial for conforming to certain standards of multiple resource consumption and environmental impacts.  In this context we deal with the problem of synthesizing a  strategy (if any) that guarantees that the expected impacts on repeated execution of the input process  are below a given threshold.  We show that this problem belongs to   PSPACE complexity class; moreover we provide an effective procedure  for computing a strategy (if present).", "published": "2024-10-31 04:00:00", "id": "82c1edae-ff86-44a6-83c1-526f0586c9fb", "source": "arxiv", "section": "computerScience"}, {"title": "Deterministic Suffix-reading Automata", "link": "https://arxiv.org/abs/2410.22761", "description": "arXiv:2410.22761v1 Announce Type: new \nAbstract: We introduce deterministic suffix-reading automata (DSA), a new automaton model over finite words. Transitions in a DSA are labeled with words. From a state, a DSA triggers an outgoing transition on seeing a word ending with the transition's label. Therefore, rather than moving along an input word letter by letter, a DSA can jump along blocks of letters, with each block ending in a suitable suffix. This feature allows DSAs to recognize regular languages more concisely, compared to DFAs. In this work, we focus on questions around finding a \"minimal\" DSA for a regular language. The number of states is not a faithful measure of the size of a DSA, since the transition-labels contain strings of arbitrary length. Hence, we consider total-size (number of states + number of edges + total length of transition-labels) as the size measure of DSAs.\n  We start by formally defining the model and providing a DSA-to-DFA conversion that allows to compare the expressiveness and succinctness of DSA with related automata models.  Our main technical contribution is a method to derive DSAs from a given DFA: a DFA-to-DSA conversion. We make a surprising observation that the smallest DSA derived from the canonical DFA of a regular language L need not be a minimal DSA for L. This observation leads to a fundamental bottleneck in deriving a minimal DSA for a regular language. In fact, we prove that given a DFA and a number k, the problem of deciding if there exists an equivalent DSA of total-size at most k is NP-complete.", "published": "2024-10-31 04:00:00", "id": "e1755a04-bbea-49e2-bf3f-2363450319c1", "source": "arxiv", "section": "computerScience"}, {"title": "A Game-Theoretic Approach for Security Control Selection", "link": "https://arxiv.org/abs/2410.22762", "description": "arXiv:2410.22762v1 Announce Type: new \nAbstract: Selecting the combination of security controls that will most effectively protect a system's assets is a difficult task. If the wrong controls are selected, the system may be left vulnerable to cyber-attacks that can impact the confidentiality, integrity and availability of critical data and services. In practical settings, it is not possible to select and implement every control possible. Instead considerations, such as budget, effectiveness, and dependencies among various controls, must be considered to choose a combination of security controls that best achieve a set of system security objectives. In this paper, we propose a game-theoretic approach for selecting effective combinations of security controls based on expected attacker profiles and a set budget. The control selection problem is set up as a two-person zero-sum one-shot game. Valid control combinations for selection are generated using an algebraic formalism to account for dependencies among selected controls. We demonstrate the proposed approach on an illustrative financial system used in government departments under four different scenarios. The results illustrate how a security analyst can use the proposed approach to guide and support decision-making in the control selection activity when developing secure systems.", "published": "2024-10-31 04:00:00", "id": "f0ac7e0a-7838-489c-a43e-1ec474e75bf1", "source": "arxiv", "section": "computerScience"}, {"title": "Epistemic Skills: Logical Dynamics of Knowing and Forgetting", "link": "https://arxiv.org/abs/2410.22763", "description": "arXiv:2410.22763v1 Announce Type: new \nAbstract: We present a type of epistemic logics that encapsulates both the dynamics of acquiring knowledge (knowing) and losing information (forgetting), alongside the integration of group knowledge concepts. Our approach is underpinned by a system of weighted models, which introduces an \"epistemic skills\" metric to effectively represent the epistemic abilities associated with knowledge update. In this framework, the acquisition of knowledge is modeled as a result of upskilling, whereas forgetting is by downskilling. Additionally, our framework allows us to explore the concept of \"knowability,\" which can be defined as the potential to acquire knowledge through upskilling, and facilitates a nuanced understanding of the distinctions between epistemic de re and de dicto expressions. We study the computational complexity of model checking problems for these logics, providing insights into both the theoretical underpinnings and practical implications of our approach.", "published": "2024-10-31 04:00:00", "id": "1ead999c-210c-453a-8346-2d6a33f36c3c", "source": "arxiv", "section": "computerScience"}, {"title": "An Evaluation of Massively Parallel Algorithms for DFA Minimization", "link": "https://arxiv.org/abs/2410.22764", "description": "arXiv:2410.22764v1 Announce Type: new \nAbstract: We study parallel algorithms for the minimization of Deterministic Finite Automata (DFAs). In particular, we implement four different massively parallel algorithms on Graphics Processing Units (GPUs). Our results confirm the expectations that the algorithm with the theoretically best time complexity is not practically suitable to run on GPUs due to the large amount of resources needed. We empirically verify that parallel partition refinement algorithms from the literature perform better in practice, even though their time complexity is worse. Lastly, we introduce a novel algorithm based on partition refinement with an extra parallel partial transitive closure step and show that on specific benchmarks it has better run-time complexity and performs better in practice.", "published": "2024-10-31 04:00:00", "id": "49ae365b-aae7-41dd-be71-7a6632e75327", "source": "arxiv", "section": "computerScience"}, {"title": "Combinatorial Diffusion Auction Design", "link": "https://arxiv.org/abs/2410.22765", "description": "arXiv:2410.22765v1 Announce Type: new \nAbstract: Diffusion auction design for combinatorial settings is a long-standing challenge. One difficulty is that we cannot directly extend the solutions for simpler settings to combinatorial settings (like extending the Vickrey auction to VCG in the traditional settings). In this paper, we propose a different approach to leverage the diffusion auctions for single-item settings. We design a combinatorial diffusion auction framework which can use any desirable single-item diffusion auction to produce a combinatorial auction to satisfy incentive compatibility (IC), individual rationality (IR), and weak budget balance (WBB).", "published": "2024-10-31 04:00:00", "id": "1d93ced5-93ae-4f37-abb7-06b474afe733", "source": "arxiv", "section": "computerScience"}, {"title": "Self-Driving Car Racing: Application of Deep Reinforcement Learning", "link": "https://arxiv.org/abs/2410.22766", "description": "arXiv:2410.22766v1 Announce Type: new \nAbstract: This paper explores the application of deep reinforcement learning (RL) techniques in the domain of autonomous self-driving car racing. Motivated by the rise of AI-driven mobility and autonomous racing events, the project aims to develop an AI agent that efficiently drives a simulated car in the OpenAI Gymnasium CarRacing environment. We investigate various RL algorithms, including Deep Q-Network (DQN), Proximal Policy Optimization (PPO), and novel adaptations that incorporate transfer learning and recurrent neural networks (RNNs) for enhanced performance. The project demonstrates that while DQN provides a strong baseline for policy learning, integrating ResNet and LSTM models significantly improves the agent's ability to capture complex spatial and temporal dynamics. PPO, particularly in continuous action spaces, shows promising results for fine control, although challenges such as policy collapse remain. We compare the performance of these approaches and outline future research directions focused on improving computational efficiency and addressing model stability. Our findings contribute to the ongoing development of AI systems in autonomous driving and related control tasks.", "published": "2024-10-31 04:00:00", "id": "85f82e73-dd81-4760-a91a-f62448abcb40", "source": "arxiv", "section": "computerScience"}, {"title": "Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot", "link": "https://arxiv.org/abs/2410.22767", "description": "arXiv:2410.22767v1 Announce Type: new \nAbstract: Goal-oriented chatbots are essential for automating user tasks, such as booking flights or making restaurant reservations. A key component of these systems is Dialogue State Tracking (DST), which interprets user intent and maintains the dialogue state. However, existing DST methods often rely on fixed ontologies and manually compiled slot values, limiting their adaptability to open-domain dialogues. We propose a novel approach that leverages instruction tuning and advanced prompt strategies to enhance DST performance, without relying on any predefined ontologies. Our method enables Large Language Model (LLM) to infer dialogue states through carefully designed prompts and includes an anti-hallucination mechanism to ensure accurate tracking in diverse conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder (VGAE) to model and predict subsequent user intent. Our approach achieved state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST models, and performed well in open-domain real-world conversations. This work presents a significant advancement in creating more adaptive and accurate goal-oriented chatbots.", "published": "2024-10-31 04:00:00", "id": "1794297f-0121-4cb2-a97b-38eba996dd74", "source": "arxiv", "section": "computerScience"}, {"title": "InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models", "link": "https://arxiv.org/abs/2410.22770", "description": "arXiv:2410.22770v1 Announce Type: new \nAbstract: Prompt injection attacks pose a critical threat to large language models (LLMs), enabling goal hijacking and data leakage. Prompt guard models, though effective in defense, suffer from over-defense -- falsely flagging benign inputs as malicious due to trigger word bias. To address this issue, we introduce NotInject, an evaluation dataset that systematically measures over-defense across various prompt guard models. NotInject contains 339 benign samples enriched with trigger words common in prompt injection attacks, enabling fine-grained evaluation. Our results show that state-of-the-art models suffer from over-defense issues, with accuracy dropping close to random guessing levels (60%). To mitigate this, we propose InjecGuard, a novel prompt guard model that incorporates a new training strategy, Mitigating Over-defense for Free (MOF), which significantly reduces the bias on trigger words. InjecGuard demonstrates state-of-the-art performance on diverse benchmarks including NotInject, surpassing the existing best model by 30.8%, offering a robust and open-source solution for detecting prompt injection attacks. The code and datasets are released at https://github.com/SaFoLab-WISC/InjecGuard.", "published": "2024-10-31 04:00:00", "id": "149c3978-6856-4c6d-aa04-895874b985d3", "source": "arxiv", "section": "computerScience"}, {"title": "FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple Reference Images", "link": "https://arxiv.org/abs/2410.22771", "description": "arXiv:2410.22771v1 Announce Type: new \nAbstract: Facial parts swapping aims to selectively transfer regions of interest from the source image onto the target image while maintaining the rest of the target image unchanged. Most studies on face swapping designed specifically for full-face swapping, are either unable or significantly limited when it comes to swapping individual facial parts, which hinders fine-grained and customized character designs. However, designing such an approach specifically for facial parts swapping is challenged by a reasonable multiple reference feature fusion, which needs to be both efficient and effective. To overcome this challenge, FuseAnyPart is proposed to facilitate the seamless \"fuse-any-part\" customization of the face. In FuseAnyPart, facial parts from different people are assembled into a complete face in latent space within the Mask-based Fusion Module. Subsequently, the consolidated feature is dispatched to the Addition-based Injection Module for fusion within the UNet of the diffusion model to create novel characters. Extensive experiments qualitatively and quantitatively validate the superiority and robustness of FuseAnyPart. Source codes are available at https://github.com/Thomas-wyh/FuseAnyPart.", "published": "2024-10-31 04:00:00", "id": "de8aa2c3-e3a8-4605-bf48-ffdc5c61f7b7", "source": "arxiv", "section": "computerScience"}, {"title": "Reliability Assessment of Information Sources Based on Random Permutation Set", "link": "https://arxiv.org/abs/2410.22772", "description": "arXiv:2410.22772v1 Announce Type: new \nAbstract: In pattern recognition, handling uncertainty is a critical challenge that significantly affects decision-making and classification accuracy. Dempster-Shafer Theory (DST) is an effective reasoning framework for addressing uncertainty, and the Random Permutation Set (RPS) extends DST by additionally considering the internal order of elements, forming a more ordered extension of DST. However, there is a lack of a transformation method based on permutation order between RPS and DST, as well as a sequence-based probability transformation method for RPS. Moreover, the reliability of RPS sources remains an issue that requires attention. To address these challenges, this paper proposes an RPS transformation approach and a probability transformation method tailored for RPS. On this basis, a reliability computation method for RPS sources, based on the RPS probability transformation, is introduced and applied to pattern recognition. Experimental results demonstrate that the proposed approach effectively bridges the gap between DST and RPS and achieves superior recognition accuracy in classification problems.", "published": "2024-10-31 04:00:00", "id": "7c4302e4-fd82-4a5e-bb2b-4a3da842a71b", "source": "arxiv", "section": "computerScience"}, {"title": "Diffusion Beats Autoregressive: An Evaluation of Compositional Generation in Text-to-Image Models", "link": "https://arxiv.org/abs/2410.22775", "description": "arXiv:2410.22775v1 Announce Type: new \nAbstract: Text-to-image (T2I) generative models, such as Stable Diffusion and DALL-E, have shown remarkable proficiency in producing high-quality, realistic, and natural images from textual descriptions. However, these models sometimes fail to accurately capture all the details specified in the input prompts, particularly concerning entities, attributes, and spatial relationships. This issue becomes more pronounced when the prompt contains novel or complex compositions, leading to what are known as compositional generation failure modes. Recently, a new open-source diffusion-based T2I model, FLUX, has been introduced, demonstrating strong performance in high-quality image generation. Additionally, autoregressive T2I models like LlamaGen have claimed competitive visual quality performance compared to diffusion-based models. In this study, we evaluate the compositional generation capabilities of these newly introduced models against established models using the T2I-CompBench benchmark. Our findings reveal that LlamaGen, as a vanilla autoregressive model, is not yet on par with state-of-the-art diffusion models for compositional generation tasks under the same criteria, such as model size and inference time. On the other hand, the open-source diffusion-based model FLUX exhibits compositional generation capabilities comparable to the state-of-the-art closed-source model DALL-E3.", "published": "2024-10-31 04:00:00", "id": "0343cc81-0d84-4bb9-a225-6f8ef3524cb9", "source": "arxiv", "section": "computerScience"}, {"title": "Conflux-PSRO: Effectively Leveraging Collective Advantages in Policy Space Response Oracles", "link": "https://arxiv.org/abs/2410.22776", "description": "arXiv:2410.22776v1 Announce Type: new \nAbstract: Policy Space Response Oracle (PSRO) with policy population construction has been demonstrated as an effective method for approximating Nash Equilibrium (NE) in zero-sum games. Existing studies have attempted to improve diversity in policy space, primarily by incorporating diversity regularization into the Best Response (BR). However, these methods cause the BR to deviate from maximizing rewards, easily resulting in a population that favors diversity over performance, even when diversity is not always necessary. Consequently, exploitability is difficult to reduce until policies are fully explored, especially in complex games. In this paper, we propose Conflux-PSRO, which fully exploits the diversity of the population by adaptively selecting and training policies at state-level. Specifically, Conflux-PSRO identifies useful policies from the existing population and employs a routing policy to select the most appropriate policies at each decision point, while simultaneously training them to enhance their effectiveness. Compared to the single-policy BR of traditional PSRO and its diversity-improved variants, the BR generated by Conflux-PSRO not only leverages the specialized expertise of diverse policies but also synergistically enhances overall performance. Our experiments on various environments demonstrate that Conflux-PSRO significantly improves the utility of BRs and reduces exploitability compared to existing methods.", "published": "2024-10-31 04:00:00", "id": "0972b149-9002-469a-9e1f-f56a1804a59e", "source": "arxiv", "section": "computerScience"}, {"title": "Bregman implementation of Meyer's $G-$norm for cartoon + textures decomposition", "link": "https://arxiv.org/abs/2410.22777", "description": "arXiv:2410.22777v1 Announce Type: new \nAbstract: In this paper, we design a very simple algorithm based on Split Bregman iterations to numerically solve the cartoon + textures decomposition model of Meyer. This results in a significant gain in speed compared to Chambolle's nonlinear projectors.", "published": "2024-10-31 04:00:00", "id": "2ce36a84-deae-4c56-8c8d-0855a8e0d056", "source": "arxiv", "section": "computerScience"}, {"title": "Signal Processing via Cross-Dimensional Projection", "link": "https://arxiv.org/abs/2410.22779", "description": "arXiv:2410.22779v1 Announce Type: new \nAbstract: Using projection between Euclidian spaces of different dimensions, the signal compression and decompression become straightforward. This encoding/decoding technique requires no preassigned measuring matrix as in compressed sensing. Moreover, in application there is no dimension or size restrictions. General formulas for encoding/decoding of any finite dimensional signals are provided. Their main properties are revealed. Particularly, it is shown that under the equivalence assumption the technique provides the best approximation with least square error.", "published": "2024-10-31 04:00:00", "id": "14e50e1c-667d-45c3-81f9-5b43777b95d5", "source": "arxiv", "section": "computerScience"}, {"title": "MALoRA: Mixture of Asymmetric Low-Rank Adaptation for Enhanced Multi-Task Learning", "link": "https://arxiv.org/abs/2410.22782", "description": "arXiv:2410.22782v1 Announce Type: new \nAbstract: Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have significantly improved the adaptation of LLMs to downstream tasks in a resource-efficient manner. However, in multi-task scenarios, challenges such as training imbalance and the seesaw effect frequently emerge. Mixture-of-LoRA (MoLoRA), which combines LoRA with sparse Mixture-of-Experts, mitigates some of these issues by promoting task-specific learning across experts. Despite this, MoLoRA remains inefficient in terms of training speed, parameter utilization, and overall multi-task performance. In this paper, we propose Mixture of Asymmetric Low-Rank Adaptaion (MALoRA), a flexible fine-tuning framework that leverages asymmetric optimization across LoRA experts. MALoRA reduces the number of trainable parameters by 30% to 48%, increases training speed by 1.2x, and matches the computational efficiency of single-task LoRA models. Additionally, MALoRA addresses overfitting issues commonly seen in high-rank configurations, enhancing performance stability. Extensive experiments across diverse multi-task learning scenarios demonstrate that MALoRA consistently outperforms all baseline methods in both inter-domain and intra-domain tasks.", "published": "2024-10-31 04:00:00", "id": "ed1fea53-5363-4d64-82ad-94e55e785edc", "source": "arxiv", "section": "computerScience"}, {"title": "Contrastive Learning and Adversarial Disentanglement for Privacy-Preserving Task-Oriented Semantic Communications", "link": "https://arxiv.org/abs/2410.22784", "description": "arXiv:2410.22784v1 Announce Type: new \nAbstract: Task-oriented semantic communication systems have emerged as a promising approach to achieving efficient and intelligent data transmission, where only information relevant to a specific task is communicated. However, existing methods struggle to fully disentangle task-relevant and task-irrelevant information, leading to privacy concerns and subpar performance. To address this, we propose an information-bottleneck method, named CLAD (contrastive learning and adversarial disentanglement). CLAD leverages contrastive learning to effectively capture task-relevant features while employing adversarial disentanglement to discard task-irrelevant information. Additionally, due to the lack of reliable and reproducible methods to gain insight into the informativeness and minimality of the encoded feature vectors, we introduce a new technique to compute the information retention index (IRI), a comparative metric used as a proxy for the mutual information between the encoded features and the input, reflecting the minimality of the encoded features. The IRI quantifies the minimality and informativeness of the encoded feature vectors across different task-oriented communication techniques. Our extensive experiments demonstrate that CLAD outperforms state-of-the-art baselines in terms of task performance, privacy preservation, and IRI. CLAD achieves a predictive performance improvement of around 2.5-3%, along with a 77-90% reduction in IRI and a 57-76% decrease in adversarial accuracy.", "published": "2024-10-31 04:00:00", "id": "4ae991ab-6ead-466b-9afd-03be5a584e20", "source": "arxiv", "section": "computerScience"}, {"title": "Theoretical Investigations and Practical Enhancements on Tail Task Risk Minimization in Meta Learning", "link": "https://arxiv.org/abs/2410.22788", "description": "arXiv:2410.22788v1 Announce Type: new \nAbstract: Meta learning is a promising paradigm in the era of large models and task distributional robustness has become an indispensable consideration in real-world scenarios. Recent advances have examined the effectiveness of tail task risk minimization in fast adaptation robustness improvement \\citep{wang2023simple}. This work contributes to more theoretical investigations and practical enhancements in the field. Specifically, we reduce the distributionally robust strategy to a max-min optimization problem, constitute the Stackelberg equilibrium as the solution concept, and estimate the convergence rate. In the presence of tail risk, we further derive the generalization bound, establish connections with estimated quantiles, and practically improve the studied strategy. Accordingly, extensive evaluations demonstrate the significance of our proposal and its scalability to multimodal large models in boosting robustness.", "published": "2024-10-31 04:00:00", "id": "d7463735-fdd8-4fba-a643-d929ac0a119f", "source": "arxiv", "section": "computerScience"}, {"title": "Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation", "link": "https://arxiv.org/abs/2410.22790", "description": "arXiv:2410.22790v1 Announce Type: new \nAbstract: Sequential recommender systems (SRSs) aim to predict the subsequent items which may interest users via comprehensively modeling users' complex preference embedded in the sequence of user-item interactions. However, most of existing SRSs often model users' single low-level preference based on item ID information while ignoring the high-level preference revealed by item attribute information, such as item category. Furthermore, they often utilize limited sequence context information to predict the next item while overlooking richer inter-item semantic relations. To this end, in this paper, we proposed a novel hierarchical preference modeling framework to substantially model the complex low- and high-level preference dynamics for accurate sequential recommendation. Specifically, in the framework, a novel dual-transformer module and a novel dual contrastive learning scheme have been designed to discriminatively learn users' low- and high-level preference and to effectively enhance both low- and high-level preference learning respectively. In addition, a novel semantics-enhanced context embedding module has been devised to generate more informative context embedding for further improving the recommendation performance. Extensive experiments on six real-world datasets have demonstrated both the superiority of our proposed method over the state-of-the-art ones and the rationality of our design.", "published": "2024-10-31 04:00:00", "id": "2e49905e-041f-4e5f-a0db-34e66e3c87f8", "source": "arxiv", "section": "computerScience"}, {"title": "Open Turbulent Image Set (OTIS)", "link": "https://arxiv.org/abs/2410.22791", "description": "arXiv:2410.22791v1 Announce Type: new \nAbstract: Long distance imaging is subject to the impact of the turbulent atmosphere. This results into geometric distortions and some blur effect in the observed frames. Despite the existence of several turbulence mitigation algorithms in the literature, no common dataset exists to objectively evaluate their efficiency. In this paper, we describe a new dataset called OTIS (Open Turbulent Images Set) which contains several sequences (either static or dynamic) acquired through the turbulent atmosphere. For almost all sequences, we provide the corresponding groundtruth in order to make the comparison between algorithms easier. We also discuss possible metrics to perform such comparisons.", "published": "2024-10-31 04:00:00", "id": "429c4ec7-81de-4448-af7e-4682a1f064cf", "source": "arxiv", "section": "computerScience"}, {"title": "Less is More: DocString Compression in Code Generation", "link": "https://arxiv.org/abs/2410.22793", "description": "arXiv:2410.22793v1 Announce Type: new \nAbstract: The widespread use of Large Language Models (LLMs) in software engineering has intensified the need for improved model and resource efficiency. In particular, for neural code generation, LLMs are used to translate function/method signature and DocString to executable code. DocStrings which capture user re quirements for the code and used as the prompt for LLMs, often contains redundant information. Recent advancements in prompt compression have shown promising results in Natural Language Processing (NLP), but their applicability to code generation remains uncertain. Our empirical study show that the state-of-the-art prompt compression methods achieve only about 10% reduction, as further reductions would cause significant performance degradation. In our study, we propose a novel compression method, ShortenDoc, dedicated to DocString compression for code generation. Our extensive experiments on six code generation datasets, five open-source LLMs (1B to 10B parameters), and one closed-source LLM GPT-4o confirm that ShortenDoc achieves 25-40% compression while preserving the quality of generated code, outperforming other baseline methods at similar compression levels. The benefit of this research is to improve efficiency and reduce the cost while maintaining the quality of the generated code, especially when calling third-party APIs, and is able to reduce the token processing cost by 25-40%.", "published": "2024-10-31 04:00:00", "id": "ee3d9bf3-8785-46dc-9605-4f720f2bdc6b", "source": "arxiv", "section": "computerScience"}, {"title": "Solving Differential Equations with Constrained Learning", "link": "https://arxiv.org/abs/2410.22796", "description": "arXiv:2410.22796v1 Announce Type: new \nAbstract: (Partial) differential equations (PDEs) are fundamental tools for describing natural phenomena, making their solution crucial in science and engineering. While traditional methods, such as the finite element method, provide reliable solutions, their accuracy is often tied to the use of computationally intensive fine meshes. Moreover, they do not naturally account for measurements or prior solutions, and any change in the problem parameters requires results to be fully recomputed. Neural network-based approaches, such as physics-informed neural networks and neural operators, offer a mesh-free alternative by directly fitting those models to the PDE solution. They can also integrate prior knowledge and tackle entire families of PDEs by simply aggregating additional training losses. Nevertheless, they are highly sensitive to hyperparameters such as collocation points and the weights associated with each loss. This paper addresses these challenges by developing a science-constrained learning (SCL) framework. It demonstrates that finding a (weak) solution of a PDE is equivalent to solving a constrained learning problem with worst-case losses. This explains the limitations of previous methods that minimize the expected value of aggregated losses. SCL also organically integrates structural constraints (e.g., invariances) and (partial) measurements or known solutions. The resulting constrained learning problems can be tackled using a practical algorithm that yields accurate solutions across a variety of PDEs, neural network architectures, and prior knowledge levels without extensive hyperparameter tuning and sometimes even at a lower computational cost.", "published": "2024-10-31 04:00:00", "id": "135894c7-23c2-43e9-aaac-ded1d3ace7b6", "source": "arxiv", "section": "computerScience"}, {"title": "Wavelet Burst Accumulation for turbulence mitigation", "link": "https://arxiv.org/abs/2410.22802", "description": "arXiv:2410.22802v1 Announce Type: new \nAbstract: In this paper, we investigate the extension of the recently proposed weighted Fourier burst accumulation (FBA) method into the wavelet domain. The purpose of FBA is to reconstruct a clean and sharp image from a sequence of blurred frames. This concept lies in the construction of weights to amplify dominant frequencies in the Fourier spectrum of each frame. The reconstructed image is then obtained by taking the inverse Fourier transform of the average of all processed spectra. In this paper, we first suggest to replace the rigid registration step used in the original algorithm by a non-rigid registration in order to be able to process sequences acquired through atmospheric turbulence. Second, we propose to work in a wavelet domain instead of the Fourier one. This leads us to the construction of two types of algorithms. Finally, we propose an alternative approach to replace the weighting idea by an approach promoting the sparsity in the used space. Several experiments are provided to illustrate the efficiency of the proposed methods.", "published": "2024-10-31 04:00:00", "id": "6eb63d88-31e7-4a5f-97e8-cbdd28a41435", "source": "arxiv", "section": "computerScience"}, {"title": "DOA-Aware Audio-Visual Self-Supervised Learning for Sound Event Localization and Detection", "link": "https://arxiv.org/abs/2410.22803", "description": "arXiv:2410.22803v1 Announce Type: new \nAbstract: This paper describes sound event localization and detection (SELD) for spatial audio recordings captured by firstorder ambisonics (FOA) microphones. In this task, one may train a deep neural network (DNN) using FOA data annotated with the classes and directions of arrival (DOAs) of sound events. However, the performance of this approach is severely bounded by the amount of annotated data. To overcome this limitation, we propose a novel method of pretraining the feature extraction part of the DNN in a self-supervised manner. We use spatial audio-visual recordings abundantly available as virtual reality contents. Assuming that sound objects are concurrently observed by the FOA microphones and the omni-directional camera, we jointly train audio and visual encoders with contrastive learning such that the audio and visual embeddings of the same recording and DOA are made close. A key feature of our method is that the DOA-wise audio embeddings are jointly extracted from the raw audio data, while the DOA-wise visual embeddings are separately extracted from the local visual crops centered on the corresponding DOA. This encourages the latent features of the audio encoder to represent both the classes and DOAs of sound events. The experiment using the DCASE2022 Task 3 dataset of 20 hours shows non-annotated audio-visual recordings of 100 hours reduced the error score of SELD from 36.4 pts to 34.9 pts.", "published": "2024-10-31 04:00:00", "id": "863257a0-ff94-4d8a-abc5-7c3c49dce2e9", "source": "arxiv", "section": "computerScience"}, {"title": "Run-Time Adaptation of Neural Beamforming for Robust Speech Dereverberation and Denoising", "link": "https://arxiv.org/abs/2410.22805", "description": "arXiv:2410.22805v1 Announce Type: new \nAbstract: This paper describes speech enhancement for realtime automatic speech recognition (ASR) in real environments. A standard approach to this task is to use neural beamforming that can work efficiently in an online manner. It estimates the masks of clean dry speech from a noisy echoic mixture spectrogram with a deep neural network (DNN) and then computes a enhancement filter used for beamforming. The performance of such a supervised approach, however, is drastically degraded under mismatched conditions. This calls for run-time adaptation of the DNN. Although the ground-truth speech spectrogram required for adaptation is not available at run time, blind dereverberation and separation methods such as weighted prediction error (WPE) and fast multichannel nonnegative matrix factorization (FastMNMF) can be used for generating pseudo groundtruth data from a mixture. Based on this idea, a prior work proposed a dual-process system based on a cascade of WPE and minimum variance distortionless response (MVDR) beamforming asynchronously fine-tuned by block-online FastMNMF. To integrate the dereverberation capability into neural beamforming and make it fine-tunable at run time, we propose to use weighted power minimization distortionless response (WPD) beamforming, a unified version of WPE and minimum power distortionless response (MPDR), whose joint dereverberation and denoising filter is estimated using a DNN. We evaluated the impact of run-time adaptation under various conditions with different numbers of speakers, reverberation times, and signal-to-noise ratios (SNRs).", "published": "2024-10-31 04:00:00", "id": "e9e6dbc5-1bec-4d60-8ef5-ecbc029d455e", "source": "arxiv", "section": "computerScience"}, {"title": "MILP-StuDio: MILP Instance Generation via Block Structure Decomposition", "link": "https://arxiv.org/abs/2410.22806", "description": "arXiv:2410.22806v1 Announce Type: new \nAbstract: Mixed-integer linear programming (MILP) is one of the most popular mathematical formulations with numerous applications. In practice, improving the performance of MILP solvers often requires a large amount of high-quality data, which can be challenging to collect. Researchers thus turn to generation techniques to generate additional MILP instances. However, existing approaches do not take into account specific block structures -- which are closely related to the problem formulations -- in the constraint coefficient matrices (CCMs) of MILPs. Consequently, they are prone to generate computationally trivial or infeasible instances due to the disruptions of block structures and thus problem formulations. To address this challenge, we propose a novel MILP generation framework, called Block Structure Decomposition (MILP-StuDio), to generate high-quality instances by preserving the block structures. Specifically, MILP-StuDio begins by identifying the blocks in CCMs and decomposing the instances into block units, which serve as the building blocks of MILP instances. We then design three operators to construct new instances by removing, substituting, and appending block units in the original instances, enabling us to generate instances with flexible sizes. An appealing feature of MILP-StuDio is its strong ability to preserve the feasibility and computational hardness of the generated instances. Experiments on the commonly-used benchmarks demonstrate that using instances generated by MILP-StuDio is able to significantly reduce over 10% of the solving time for learning-based solvers.", "published": "2024-10-31 04:00:00", "id": "73346f0b-3522-41dc-b892-7ba5b901e0f2", "source": "arxiv", "section": "computerScience"}, {"title": "Causality-Enhanced Behavior Sequence Modeling in LLMs for Personalized Recommendation", "link": "https://arxiv.org/abs/2410.22809", "description": "arXiv:2410.22809v1 Announce Type: new \nAbstract: Recent advancements in recommender systems have focused on leveraging Large Language Models (LLMs) to improve user preference modeling, yielding promising outcomes. However, current LLM-based approaches struggle to fully leverage user behavior sequences, resulting in suboptimal preference modeling for personalized recommendations. In this study, we propose a novel Counterfactual Fine-Tuning (CFT) method to address this issue by explicitly emphasizing the role of behavior sequences when generating recommendations. Specifically, we employ counterfactual reasoning to identify the causal effects of behavior sequences on model output and introduce a task that directly fits the ground-truth labels based on these effects, achieving the goal of explicit emphasis. Additionally, we develop a token-level weighting mechanism to adjust the emphasis strength for different item tokens, reflecting the diminishing influence of behavior sequences from earlier to later tokens during predicting an item. Extensive experiments on real-world datasets demonstrate that CFT effectively improves behavior sequence modeling. Our codes are available at https://github.com/itsmeyjt/CFT.", "published": "2024-10-31 04:00:00", "id": "cabdcd01-e834-4d4c-b3f1-8bac0bcf79de", "source": "arxiv", "section": "computerScience"}, {"title": "Adaptive Multi Scale Document Binarisation Using Vision Mamba", "link": "https://arxiv.org/abs/2410.22811", "description": "arXiv:2410.22811v1 Announce Type: new \nAbstract: Enhancing and preserving the readability of document images, particularly historical ones, is crucial for effective document image analysis. Numerous models have been proposed for this task, including convolutional-based, transformer-based, and hybrid convolutional-transformer architectures. While hybrid models address the limitations of purely convolutional or transformer-based methods, they often suffer from issues like quadratic time complexity. In this work, we propose a Mamba-based architecture for document binarisation, which efficiently handles long sequences by scaling linearly and optimizing memory usage. Additionally, we introduce novel modifications to the skip connections by incorporating Difference of Gaussians (DoG) features, inspired by conventional signal processing techniques. These multiscale high-frequency features enable the model to produce high-quality, detailed outputs.", "published": "2024-10-31 04:00:00", "id": "c2024c50-0d92-4656-a39e-663dc17786ce", "source": "arxiv", "section": "computerScience"}, {"title": "Universality of the $\\pi^2/6$ Pathway in Avoiding Model Collapse", "link": "https://arxiv.org/abs/2410.22812", "description": "arXiv:2410.22812v1 Announce Type: new \nAbstract: Researchers in empirical machine learning recently spotlighted their fears of so-called Model Collapse. They imagined a discard workflow, where an initial generative model is trained with real data, after which the real data are discarded, and subsequently, the model generates synthetic data on which a new model is trained. They came to the conclusion that models degenerate as model-fitting generations proceed. However, other researchers considered an augment workflow, where the original real data continue to be used in each generation of training, augmented by synthetic data from models fit in all earlier generations. Empirical results on canonical datasets and learning procedures confirmed the occurrence of model collapse under the discard workflow and avoidance of model collapse under the augment workflow. Under the augment workflow, theoretical evidence also confirmed avoidance in particular instances; specifically, Gerstgrasser et al. (2024) found that for classical Linear Regression, test risk at any later generation is bounded by a moderate multiple, viz. pi-squared-over-6 of the test risk of training with the original real data alone. Some commentators questioned the generality of theoretical conclusions based on the generative model assumed in Gerstgrasser et al. (2024): could similar conclusions be reached for other task/model pairings? In this work, we demonstrate the universality of the pi-squared-over-6 augment risk bound across a large family of canonical statistical models, offering key insights into exactly why collapse happens under the discard workflow and is avoided under the augment workflow. In the process, we provide a framework that is able to accommodate a large variety of workflows (beyond discard and augment), thereby enabling an experimenter to judge the comparative merits of multiple different workflows by simulating a simple Gaussian process.", "published": "2024-10-31 04:00:00", "id": "a5e688db-cec7-489d-96da-7ffdb269d5b6", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients", "link": "https://arxiv.org/abs/2410.22815", "description": "arXiv:2410.22815v1 Announce Type: new \nAbstract: Federated fine-tuning for Large Language Models (LLMs) has recently gained attention due to the heavy communication overhead of transmitting large model updates. Low Rank Adaptation (LoRA) has been proposed as a solution, yet its application in federated learning is complicated by discordance in aggregation. Existing methods addressing this discordance often suffer from performance degradation at low ranks in heterogeneous data settings. In response, we introduce LoRA-A2 (Low Rank Adaptation with Alternating freeze and Adaptive rank selection), which demonstrates robustness in challenging settings with low ranks and high data heterogeneity. Our experimental findings reveal that LoRA-A2 maintains performance even under extreme heterogeneity and low rank conditions, achieving up to a 99.8% reduction in uploaded parameters compared to full fine-tuning without compromising performance. This adaptive mechanism boosts robustness and communication efficiency in federated fine-tuning, enabling the practical deployment of LLMs in resource-constrained environments.", "published": "2024-10-31 04:00:00", "id": "4b4f6535-fb82-4f95-bcbb-01ebfea57f5d", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Tool Manipulation of An Aerial Vehicle with A Dynamically Displacing Center-of-Mass", "link": "https://arxiv.org/abs/2410.22816", "description": "arXiv:2410.22816v1 Announce Type: new \nAbstract: As aerial robots gain traction in industrial applications, there is growing interest in enhancing their physical interaction capabilities. Pushing tasks performed by aerial manipulators have been successfully demonstrated in contact-based inspections. However, more complex industrial applications require these systems to support higher-DoF (Degree of Freedom) manipulators and generate larger forces while pushing (e.g., drilling, grinding). This paper builds on our previous work, where we introduced an aerial vehicle with a dynamically displacing CoM (Center of Mass) to improve force exertion during interactions. We propose a novel approach to further enhance this system's force generation by optimizing its CoM location during interactions. Additionally, we study the case of this aerial vehicle equipped with a 2-DoF manipulation arm to extend the system's functionality in tool-based tasks. The effectiveness of the proposed methods is validated through simulations, demonstrating the potential of this system for advanced aerial manipulation in practical settings.", "published": "2024-10-31 04:00:00", "id": "6816274b-e8c3-4ffc-9b24-b9bcbc776953", "source": "arxiv", "section": "computerScience"}, {"title": "Epipolar-Free 3D Gaussian Splatting for Generalizable Novel View Synthesis", "link": "https://arxiv.org/abs/2410.22817", "description": "arXiv:2410.22817v1 Announce Type: new \nAbstract: Generalizable 3D Gaussian splitting (3DGS) can reconstruct new scenes from sparse-view observations in a feed-forward inference manner, eliminating the need for scene-specific retraining required in conventional 3DGS. However, existing methods rely heavily on epipolar priors, which can be unreliable in complex realworld scenes, particularly in non-overlapping and occluded regions. In this paper, we propose eFreeSplat, an efficient feed-forward 3DGS-based model for generalizable novel view synthesis that operates independently of epipolar line constraints. To enhance multiview feature extraction with 3D perception, we employ a selfsupervised Vision Transformer (ViT) with cross-view completion pre-training on large-scale datasets. Additionally, we introduce an Iterative Cross-view Gaussians Alignment method to ensure consistent depth scales across different views. Our eFreeSplat represents an innovative approach for generalizable novel view synthesis. Different from the existing pure geometry-free methods, eFreeSplat focuses more on achieving epipolar-free feature matching and encoding by providing 3D priors through cross-view pretraining. We evaluate eFreeSplat on wide-baseline novel view synthesis tasks using the RealEstate10K and ACID datasets. Extensive experiments demonstrate that eFreeSplat surpasses state-of-the-art baselines that rely on epipolar priors, achieving superior geometry reconstruction and novel view synthesis quality. Project page: https://tatakai1.github.io/efreesplat/.", "published": "2024-10-31 04:00:00", "id": "67b6af54-694a-4be7-9ee4-50266df5980f", "source": "arxiv", "section": "computerScience"}, {"title": "A test-free semantic mistakes localization framework in Neural Code Translation", "link": "https://arxiv.org/abs/2410.22818", "description": "arXiv:2410.22818v1 Announce Type: new \nAbstract: In the task of code translation, neural network-based models have been shown to frequently produce semantically erroneous code that deviates from the original logic of the source code. This issue persists even with advanced large models. Although a recent approach proposed using test cases to identify these semantic errors, it relies heavily on the quality of the test cases and is not applicable to code snippets without test cases in real-world scenarios. Therefore, We present EISP, a static analysis framework based on the Large Language Model (LLM).First, the framework generates a semantic mapping between source code and translated code. Next, each sub-code fragment is identified by recursively traversing the abstract syntax tree of the source code, and its corresponding translated code fragment is found through the semantic mapping. Finally, EISP connects each pair of sub-code fragments with fine-grained knowledge hints through an AI chain to assist LLMs in discovering semantic mistakes in the translated code. In our benchmark evaluation, the EISP framework, based on GPT-4o mini, achieved an accuracy of 82.3\\%, representing a 20.3\\% improvement over baseline methods using the same base model, and a 7.4\\% improvement compared to dynamic analysis methods that require test cases and manual intervention. To our knowledge, EISP is the first tool to locate semantic errors in translated code without test cases or compilable code. This innovative tool provides the software engineering community with a new way to deal with code fragments without test cases.", "published": "2024-10-31 04:00:00", "id": "b6e3e418-98a6-4436-b6d5-48deedb54c16", "source": "arxiv", "section": "computerScience"}, {"title": "An invariance principle based concentration result for large-scale stochastic pairwise interaction network systems", "link": "https://arxiv.org/abs/2410.22820", "description": "arXiv:2410.22820v1 Announce Type: new \nAbstract: We study stochastic pairwise interaction network systems whereby a finite population of agents, identified with the nodes of a graph, update their states in response to both individual mutations and pairwise interactions with their neighbors. The considered class of systems include the main epidemic models -such as the SIS, SIR, and SIRS models-, certain social dynamics models -such as the voter and anti-voter models-, as well as evolutionary dynamics on graphs. Since these stochastic systems fall into the class of finite-state Markov chains, they always admit stationary distributions. We analyze the asymptotic behavior of these stationary distributions in the limit as the population size grows large while the interaction network maintains certain mixing properties. Our approach relies on the use of Lyapunov-type functions to obtain concentration results on these stationary distributions. Notably, our results are not limited to fully mixed population models, as they do apply to a much broader spectrum of interaction network structures, including, e.g., Erd\\\"oos-R\\'enyi random graphs.", "published": "2024-10-31 04:00:00", "id": "7d50e2b3-4a5e-416e-92eb-4b57c6466b40", "source": "arxiv", "section": "computerScience"}, {"title": "EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations", "link": "https://arxiv.org/abs/2410.22821", "description": "arXiv:2410.22821v1 Announce Type: new \nAbstract: How to evaluate Large Language Models (LLMs) in code generation remains an open question. Existing benchmarks have two limitations - data leakage and lack of domain-specific evaluation. The former hurts the fairness of benchmarks, and the latter hinders practitioners from selecting superior LLMs for specific programming domains. To address these two limitations, we propose a new benchmark - EvoCodeBench, which has the following advances: (1) Evolving data. EvoCodeBench will be dynamically updated every period (e.g., 6 months) to avoid data leakage. This paper releases the first version - EvoCodeBench-2403, containing 275 samples from 25 repositories. (2) A domain taxonomy and domain labels. Based on the statistics of open-source communities, we design a programming domain taxonomy consisting of 10 popular domains. Based on the taxonomy, we annotate each sample in EvoCodeBench with a domain label. (3) Domain-specific evaluations. Besides the Pass@k, we compute the Domain-Specific Improvement (DSI) and define LLMs' comfort and strange domains. These evaluations help practitioners select superior LLMs in specific domains and discover the shortcomings of existing LLMs. We evaluate 8 popular LLMs (e.g., gpt-4, DeepSeek Coder) on EvoCodeBench and summarize some insights. EvoCodeBench reveals the actual abilities of these LLMs in real-world repositories. For example, the highest Pass@1 of gpt-4 on EvoCodeBench-2403 is only 20.74%. Besides, we evaluate LLMs in different domains and discover their comfort and strange domains. For example, gpt-4 performs best in most domains but falls behind others in the Internet domain. StarCoder 2-15B unexpectedly performs well in the Database domain and even outperforms 33B LLMs. EvoCodeBench has been released.", "published": "2024-10-31 04:00:00", "id": "fc517c27-76ce-41b9-93d1-428b898ecf6a", "source": "arxiv", "section": "computerScience"}, {"title": "The Reconstruction of the Space-Dependent Thermal Conductivity from Sparse Temperature Measurements", "link": "https://arxiv.org/abs/2410.22822", "description": "arXiv:2410.22822v1 Announce Type: new \nAbstract: We present a novel method for reconstructing the thermal conductivity coefficient in 1D and 2D heat equations using moving sensors that dynamically traverse the domain to record sparse and noisy temperature measurements. We significantly reduce the computational cost associated with forward PDE evaluations by employing automatic differentiation, enabling a more efficient and scalable reconstruction process. This allows the inverse problem to be solved with fewer sensors and observations. Specifically, we demonstrate the successful reconstruction of thermal conductivity on the 1D circle and 2D torus, using one and four moving sensors, respectively, with their positions recorded over time. Our method incorporates sampling algorithms to compute confidence intervals for the reconstructed conductivity, improving robustness against measurement noise. Extensive numerical simulations of heat dynamics validate the efficacy of our approach, confirming both the accuracy and stability of the reconstructed thermal conductivity. Additionally, the method is thoroughly tested using large datasets from machine learning, allowing us to evaluate its performance across various scenarios and ensure its reliability. This approach provides a cost-effective and flexible solution for conductivity reconstruction from sparse measurements, making it a robust tool for solving inverse problems in complex domains.", "published": "2024-10-31 04:00:00", "id": "6ff86dff-6408-4160-8b8c-27d9282f2a0a", "source": "arxiv", "section": "computerScience"}, {"title": "Grasping Force Estimation for Markerless Visuotactile Sensors", "link": "https://arxiv.org/abs/2410.22825", "description": "arXiv:2410.22825v1 Announce Type: new \nAbstract: Tactile sensors have been used for force estimation in the past, especially Vision-Based Tactile Sensors (VBTS) have recently become a new trend due to their high spatial resolution and low cost. In this work, we have designed and implemented several approaches to estimate the normal grasping force using different types of markerless visuotactile representations obtained from VBTS. Our main goal is to determine the most appropriate visuotactile representation, based on a performance analysis during robotic grasping tasks. Our proposal has been tested on the dataset generated with our DIGIT sensors and another one obtained using GelSight Mini sensors from another state-of-the-art work. We have also tested the generalization capabilities of our best approach, called RGBmod. The results led to two main conclusions. First, the RGB visuotactile representation is a better input option than the depth image or a combination of the two for estimating normal grasping forces. Second, RGBmod achieved a good performance when tested on 10 unseen everyday objects in real-world scenarios, achieving an average relative error of 0.125 +- 0.153. Furthermore, we show that our proposal outperforms other works in the literature that use RGB and depth information for the same task.", "published": "2024-10-31 04:00:00", "id": "b87ff012-056c-48d8-a09c-d52bb83b8b9c", "source": "arxiv", "section": "computerScience"}, {"title": "How Well Do Large Language Models Disambiguate Swedish Words?", "link": "https://arxiv.org/abs/2410.22827", "description": "arXiv:2410.22827v1 Announce Type: new \nAbstract: We evaluate a battery of recent large language models on two benchmarks for word sense disambiguation in Swedish. At present, all current models are less accurate than the best supervised disambiguators in cases where a training set is available, but most models outperform graph-based unsupervised systems. Different prompting approaches are compared, with a focus on how to express the set of possible senses in a given context. The best accuracies are achieved when human-written definitions of the senses are included in the prompts.", "published": "2024-10-31 04:00:00", "id": "85d77dbd-dbaa-418c-aa07-10dd90ae54fc", "source": "arxiv", "section": "computerScience"}, {"title": "Situational Scene Graph for Structured Human-centric Situation Understanding", "link": "https://arxiv.org/abs/2410.22829", "description": "arXiv:2410.22829v1 Announce Type: new \nAbstract: Graph based representation has been widely used in modelling spatio-temporal relationships in video understanding. Although effective, existing graph-based approaches focus on capturing the human-object relationships while ignoring fine-grained semantic properties of the action components. These semantic properties are crucial for understanding the current situation, such as where does the action takes place, what tools are used and functional properties of the objects. In this work, we propose a graph-based representation called Situational Scene Graph (SSG) to encode both human-object relationships and the corresponding semantic properties. The semantic details are represented as predefined roles and values inspired by situation frame, which is originally designed to represent a single action. Based on our proposed representation, we introduce the task of situational scene graph generation and propose a multi-stage pipeline Interactive and Complementary Network (InComNet) to address the task. Given that the existing datasets are not applicable to the task, we further introduce a SSG dataset whose annotations consist of semantic role-value frames for human, objects and verb predicates of human-object relations. Finally, we demonstrate the effectiveness of our proposed SSG representation by testing on different downstream tasks. Experimental results show that the unified representation can not only benefit predicate classification and semantic role-value classification, but also benefit reasoning tasks on human-centric situation understanding. We will release the code and the dataset soon.", "published": "2024-10-31 04:00:00", "id": "46eac75b-dfa6-416a-b64c-0350ded5a082", "source": "arxiv", "section": "computerScience"}, {"title": "HijackRAG: Hijacking Attacks against Retrieval-Augmented Large Language Models", "link": "https://arxiv.org/abs/2410.22832", "description": "arXiv:2410.22832v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by integrating external knowledge, making them adaptable and cost-effective for various applications. However, the growing reliance on these systems also introduces potential security risks. In this work, we reveal a novel vulnerability, the retrieval prompt hijack attack (HijackRAG), which enables attackers to manipulate the retrieval mechanisms of RAG systems by injecting malicious texts into the knowledge database. When the RAG system encounters target questions, it generates the attacker's pre-determined answers instead of the correct ones, undermining the integrity and trustworthiness of the system. We formalize HijackRAG as an optimization problem and propose both black-box and white-box attack strategies tailored to different levels of the attacker's knowledge. Extensive experiments on multiple benchmark datasets show that HijackRAG consistently achieves high attack success rates, outperforming existing baseline attacks. Furthermore, we demonstrate that the attack is transferable across different retriever models, underscoring the widespread risk it poses to RAG systems. Lastly, our exploration of various defense mechanisms reveals that they are insufficient to counter HijackRAG, emphasizing the urgent need for more robust security measures to protect RAG systems in real-world deployments.", "published": "2024-10-31 04:00:00", "id": "e021ca1b-6251-4242-bd22-dcd2cb4cdef3", "source": "arxiv", "section": "computerScience"}, {"title": "SFDFusion: An Efficient Spatial-Frequency Domain Fusion Network for Infrared and Visible Image Fusion", "link": "https://arxiv.org/abs/2410.22837", "description": "arXiv:2410.22837v1 Announce Type: new \nAbstract: Infrared and visible image fusion aims to utilize the complementary information from two modalities to generate fused images with prominent targets and rich texture details. Most existing algorithms only perform pixel-level or feature-level fusion from different modalities in the spatial domain. They usually overlook the information in the frequency domain, and some of them suffer from inefficiency due to excessively complex structures. To tackle these challenges, this paper proposes an efficient Spatial-Frequency Domain Fusion (SFDFusion) network for infrared and visible image fusion. First, we propose a Dual-Modality Refinement Module (DMRM) to extract complementary information. This module extracts useful information from both the infrared and visible modalities in the spatial domain and enhances fine-grained spatial details. Next, to introduce frequency domain information, we construct a Frequency Domain Fusion Module (FDFM) that transforms the spatial domain to the frequency domain through Fast Fourier Transform (FFT) and then integrates frequency domain information. Additionally, we design a frequency domain fusion loss to provide guidance for the fusion process. Extensive experiments on public datasets demonstrate that our method produces fused images with significant advantages in various fusion metrics and visual effects. Furthermore, our method demonstrates high efficiency in image fusion and good performance on downstream detection tasks, thereby satisfying the real-time demands of advanced visual tasks.", "published": "2024-10-31 04:00:00", "id": "c8c42c0c-cc73-4397-9843-5963a901b97a", "source": "arxiv", "section": "computerScience"}, {"title": "Danoliteracy of Generative, Large Language Models", "link": "https://arxiv.org/abs/2410.22839", "description": "arXiv:2410.22839v1 Announce Type: new \nAbstract: The language technology moonshot moment of Generative, Large Language Models (GLLMs) was not limited to English: These models brought a surge of technological applications, investments and hype to low-resource languages as well. However, the capabilities of these models in languages such as Danish were until recently difficult to verify beyond qualitative demonstrations due to a lack of applicable evaluation corpora. We present a GLLM benchmark to evaluate Danoliteracy, a measure of Danish language and cultural competency, across eight diverse scenarios such Danish citizenship tests and abstractive social media question answering. This limited-size benchmark is found to produce a robust ranking that correlates to human feedback at $\\rho \\sim 0.8$ with GPT-4 and Claude Opus models achieving the highest rankings. Analyzing these model results across scenarios, we find one strong underlying factor explaining $95\\%$ of scenario performance variance for GLLMs in Danish, suggesting a $g$ factor of model consistency in language adaption.", "published": "2024-10-31 04:00:00", "id": "aec0c40e-b6fa-4023-beb8-2f25497b9757", "source": "arxiv", "section": "computerScience"}, {"title": "Understanding and Improving Adversarial Collaborative Filtering for Robust Recommendation", "link": "https://arxiv.org/abs/2410.22844", "description": "arXiv:2410.22844v1 Announce Type: new \nAbstract: Adversarial Collaborative Filtering (ACF), which typically applies adversarial perturbations at user and item embeddings through adversarial training, is widely recognized as an effective strategy for enhancing the robustness of Collaborative Filtering (CF) recommender systems against poisoning attacks. Besides, numerous studies have empirically shown that ACF can also improve recommendation performance compared to traditional CF. Despite these empirical successes, the theoretical understanding of ACF's effectiveness in terms of both performance and robustness remains unclear. To bridge this gap, in this paper, we first theoretically show that ACF can achieve a lower recommendation error compared to traditional CF with the same training epochs in both clean and poisoned data contexts. Furthermore, by establishing bounds for reductions in recommendation error during ACF's optimization process, we find that applying personalized magnitudes of perturbation for different users based on their embedding scales can further improve ACF's effectiveness. Building on these theoretical understandings, we propose Personalized Magnitude Adversarial Collaborative Filtering (PamaCF). Extensive experiments demonstrate that PamaCF effectively defends against various types of poisoning attacks while significantly enhancing recommendation performance.", "published": "2024-10-31 04:00:00", "id": "5b8880ef-7899-4071-9752-be7a4dbdd031", "source": "arxiv", "section": "computerScience"}, {"title": "Two-Way One-Counter Nets Revisited", "link": "https://arxiv.org/abs/2410.22845", "description": "arXiv:2410.22845v1 Announce Type: new \nAbstract: One Counter Nets (OCNs) are finite-state automata equipped with a counter that cannot become negative, but cannot be explicitly tested for zero. Their close connection to various other models (e.g., PDAs, Vector Addition Systems, and Counter Automata) make them an attractive modeling tool. The two-way variant of OCNs (2-OCNs) was introduced in the 1980's and shown to be more expressive than OCNs, so much so that the emptiness problem is undecidable already in the deterministic model (2-DOCNs). In a first part, we study the emptiness problem of natural restrictions of 2-OCNs, under the light of modern results about Vector Addition System with States (VASS). We show that emptiness is decidable for 2-OCNs over \\emph{bounded languages} i.e., languages contained in $a_1^*a_2^*\\cdots a_k^*$), and decidable and Ackermann-complete for \\emph{sweeping} 2-OCNs, where the head direction only changes at the end-markers. Both decidability results revolve around reducing the problem to VASS reachability, but they rely on strikingly different approaches.\n  In a second part, we study the expressive power of 2-OCNs, showing an array of connections between bounded languages, sweeping 2-OCNs, and semilinear languages. Most noteworthy among these connections, is that the bounded languages recognized by sweeping 2-OCNs are precisely those that are semilinear. Finally, we establish an intricate pumping lemma for 2-DOCNs and use it to show that there are OCN languages that are not 2-DOCN recognizable, improving on the known result that there are such 2-OCN languages.", "published": "2024-10-31 04:00:00", "id": "89ee7fa9-4748-4c68-b676-2ecb203e84f2", "source": "arxiv", "section": "computerScience"}, {"title": "Knowledge Graph Based Visual Search Application", "link": "https://arxiv.org/abs/2410.22846", "description": "arXiv:2410.22846v1 Announce Type: new \nAbstract: The FAIR data principles advocate for making scientific and research datasets 'Findable' and 'Accessible'. Yet, the sheer volume and diversity of these datasets present significant challenges. Despite advancements in data search technologies, techniques for representing search results are still traditional and inadequate, often returning extraneous results. To address these issues, we developed a knowledge graph based visual search application designed to enhance data search for Earth System Scientists. This application utilizes various chart widgets and a knowledge graph at the backend, connecting two disparate data repositories.", "published": "2024-10-31 04:00:00", "id": "6cf4f391-4293-4c64-bff7-22330b47f8e4", "source": "arxiv", "section": "computerScience"}, {"title": "Non-contact Dexterous Micromanipulation with Multiple Optoelectronic Robots", "link": "https://arxiv.org/abs/2410.22848", "description": "arXiv:2410.22848v1 Announce Type: new \nAbstract: Micromanipulation systems leverage automation and robotic technologies to improve the precision, repeatability, and efficiency of various tasks at the microscale. However, current approaches are typically limited to specific objects or tasks, which necessitates the use of custom tools and specialized grasping methods. This paper proposes a novel non-contact micromanipulation method based on optoelectronic technologies. The proposed method utilizes repulsive dielectrophoretic forces generated in the optoelectronic field to drive a microrobot, enabling the microrobot to push the target object in a cluttered environment without physical contact. The non-contact feature can minimize the risks of potential damage, contamination, or adhesion while largely improving the flexibility of manipulation. The feature enables the use of a general tool for indirect object manipulation, eliminating the need for specialized tools. A series of simulation studies and real-world experiments -- including non-contact trajectory tracking, obstacle avoidance, and reciprocal avoidance between multiple microrobots -- are conducted to validate the performance of the proposed method. The proposed formulation provides a general and dexterous solution for a range of objects and tasks at the micro scale.", "published": "2024-10-31 04:00:00", "id": "f69341be-7671-435c-90cd-5ab87f002925", "source": "arxiv", "section": "computerScience"}, {"title": "Centimeter-level Geometry Reconstruction and Material Identification in 300 GHz Monostatic Sensing", "link": "https://arxiv.org/abs/2410.22852", "description": "arXiv:2410.22852v1 Announce Type: new \nAbstract: Terahertz (THz) integrated sensing and communication (ISAC) technology is envisioned to achieve high communication performance alongside advanced sensing abilities. For various applications of ISAC, accurate environment reconstruction including geometry reconstruction and material identification is critical. This paper presents a highly precise geometry reconstruction algorithm and material identification scheme for a monostatic sensing case in a typical indoor scenario. Experiments are conducted in the frequency range from 290 GHz to 310 GHz using a vector network analyzer (VNA)-based channel sounder by co-locating the transmitter and receiver. A joint delay and angle space-alternating generalized expectation-maximization (SAGE)-based algorithm is implemented to estimate multipath component (MPC) parameters and the indoor geometry is reconstructed based on the extracted parameters. Furthermore, a geometry-based method is employed to model and remove the spurious path of the corner, reaching an accuracy of 1.75 cm. Additionally, a material database using THz time-domain spectroscopy (THz-TDS) is established, capturing reflection losses of over 200 common material samples. Applying this database to our monostatic sensing, the measured reflection losses of wall and window frame are accurately identified as cement and steel, respectively. Our results demonstrate the centimeter-level geometry reconstruction and accurate material identification for practical THz ISAC scenarios, which unleash unprecedented sensing potential compared to microwave and millimeter-wave bands.", "published": "2024-10-31 04:00:00", "id": "f1ced951-9374-4609-9718-052352417dc1", "source": "arxiv", "section": "computerScience"}, {"title": "DAVINCI: A Single-Stage Architecture for Constrained CAD Sketch Inference", "link": "https://arxiv.org/abs/2410.22857", "description": "arXiv:2410.22857v1 Announce Type: new \nAbstract: This work presents DAVINCI, a unified architecture for single-stage Computer-Aided Design (CAD) sketch parameterization and constraint inference directly from raster sketch images. By jointly learning both outputs, DAVINCI minimizes error accumulation and enhances the performance of constrained CAD sketch inference. Notably, DAVINCI achieves state-of-the-art results on the large-scale SketchGraphs dataset, demonstrating effectiveness on both precise and hand-drawn raster CAD sketches. To reduce DAVINCI's reliance on large-scale annotated datasets, we explore the efficacy of CAD sketch augmentations. We introduce Constraint-Preserving Transformations (CPTs), i.e. random permutations of the parametric primitives of a CAD sketch that preserve its constraints. This data augmentation strategy allows DAVINCI to achieve reasonable performance when trained with only 0.1% of the SketchGraphs dataset. Furthermore, this work contributes a new version of SketchGraphs, augmented with CPTs. The newly introduced CPTSketchGraphs dataset includes 80 million CPT-augmented sketches, thus providing a rich resource for future research in the CAD sketch domain.", "published": "2024-10-31 04:00:00", "id": "5c3195ce-8929-4143-a214-0b8a8a1250f7", "source": "arxiv", "section": "computerScience"}, {"title": "AtGCN: A Graph Convolutional Network For Ataxic Gait Detection", "link": "https://arxiv.org/abs/2410.22862", "description": "arXiv:2410.22862v1 Announce Type: new \nAbstract: Video-based gait analysis can be defined as the task of diagnosing pathologies, such as ataxia, using videos of patients walking in front of a camera. This paper presents a graph convolution network called AtGCN for detecting ataxic gait and identifying its severity using 2D videos. The problem is especially challenging as the deviation of an ataxic gait from a healthy gait is very subtle. The datasets for ataxic gait detection are also quite small, with the largest dataset having only 149 videos. The paper addresses the first problem using special spatiotemporal graph convolution that successfully captures important gait-related features. To handle the small dataset size, a deep spatiotemporal graph convolution network pre-trained on an action recognition dataset is systematically truncated and then fine-tuned on the ataxia dataset to obtain the AtGCN model. The paper also presents an augmentation strategy that segments a video sequence into multiple gait cycles. The proposed AtGCN model then operates on a graph of body part locations belonging to a single gait cycle. The evaluation results support the strength of the proposed AtGCN model, as it outperforms the state-of-the-art in detection and severity prediction with an accuracy of 93.46% and a MAE of 0.4169, respectively.", "published": "2024-10-31 04:00:00", "id": "bdc55658-7c23-4ef8-8bb8-6c8dfe79c2c7", "source": "arxiv", "section": "computerScience"}, {"title": "Prune and Repaint: Content-Aware Image Retargeting for any Ratio", "link": "https://arxiv.org/abs/2410.22865", "description": "arXiv:2410.22865v1 Announce Type: new \nAbstract: Image retargeting is the task of adjusting the aspect ratio of images to suit different display devices or presentation environments. However, existing retargeting methods often struggle to balance the preservation of key semantics and image quality, resulting in either deformation or loss of important objects, or the introduction of local artifacts such as discontinuous pixels and inconsistent regenerated content. To address these issues, we propose a content-aware retargeting method called PruneRepaint. It incorporates semantic importance for each pixel to guide the identification of regions that need to be pruned or preserved in order to maintain key semantics. Additionally, we introduce an adaptive repainting module that selects image regions for repainting based on the distribution of pruned pixels and the proportion between foreground size and target aspect ratio, thus achieving local smoothness after pruning. By focusing on the content and structure of the foreground, our PruneRepaint approach adaptively avoids key content loss and deformation, while effectively mitigating artifacts with local repainting. We conduct experiments on the public RetargetMe benchmark and demonstrate through objective experimental results and subjective user studies that our method outperforms previous approaches in terms of preserving semantics and aesthetics, as well as better generalization across diverse aspect ratios. Codes will be available at https://github.com/fhshen2022/PruneRepaint.", "published": "2024-10-31 04:00:00", "id": "0d60dc5f-8de3-4c75-a1ff-fc620ff0f6ca", "source": "arxiv", "section": "computerScience"}, {"title": "Scaling Molecular Dynamics with ab initio Accuracy to 149 Nanoseconds per Day", "link": "https://arxiv.org/abs/2410.22867", "description": "arXiv:2410.22867v1 Announce Type: new \nAbstract: Physical phenomena such as chemical reactions, bond breaking, and phase transition require molecular dynamics (MD) simulation with ab initio accuracy ranging from milliseconds to microseconds. However, previous state-of-the-art neural network based MD packages such as DeePMD-kit can only reach 4.7 nanoseconds per day on the Fugaku supercomputer. In this paper, we present a novel node-based parallelization scheme to reduce communication by 81%, then optimize the computationally intensive kernels with sve-gemm and mixed precision. Finally, we implement intra-node load balance to further improve the scalability. Numerical results on the Fugaku supercomputer show that our work has significantly improved the time-to-solution of the DeePMD-kit by a factor of 31.7x, reaching 149 nanoseconds per day on 12,000 computing nodes. This work has opened the door for millisecond simulation with ab initio accuracy within one week for the first time.", "published": "2024-10-31 04:00:00", "id": "c945fcf6-169b-49ae-a051-c537adfaaa96", "source": "arxiv", "section": "computerScience"}, {"title": "Conditioned quantum-assisted deep generative surrogate for particle-calorimeter interactions", "link": "https://arxiv.org/abs/2410.22870", "description": "arXiv:2410.22870v1 Announce Type: new \nAbstract: Particle collisions at accelerators such as the Large Hadron Collider, recorded and analyzed by experiments such as ATLAS and CMS, enable exquisite measurements of the Standard Model and searches for new phenomena. Simulations of collision events at these detectors have played a pivotal role in shaping the design of future experiments and analyzing ongoing ones. However, the quest for accuracy in Large Hadron Collider (LHC) collisions comes at an imposing computational cost, with projections estimating the need for millions of CPU-years annually during the High Luminosity LHC (HL-LHC) run \\cite{collaboration2022atlas}. Simulating a single LHC event with \\textsc{Geant4} currently devours around 1000 CPU seconds, with simulations of the calorimeter subdetectors in particular imposing substantial computational demands \\cite{rousseau2023experimental}. To address this challenge, we propose a conditioned quantum-assisted deep generative model. Our model integrates a conditioned variational autoencoder (VAE) on the exterior with a conditioned Restricted Boltzmann Machine (RBM) in the latent space, providing enhanced expressiveness compared to conventional VAEs. The RBM nodes and connections are meticulously engineered to enable the use of qubits and couplers on D-Wave's Pegasus-structured \\textit{Advantage} quantum annealer (QA) for sampling. We introduce a novel method for conditioning the quantum-assisted RBM using \\textit{flux biases}. We further propose a novel adaptive mapping to estimate the effective inverse temperature in quantum annealers. The effectiveness of our framework is illustrated using Dataset 2 of the CaloChallenge \\cite{calochallenge}.", "published": "2024-10-31 04:00:00", "id": "3971a071-0ecd-4f5a-9f1b-dd3d5f8aba0c", "source": "arxiv", "section": "computerScience"}, {"title": "Coupling deal.II and FROSch: A Sustainable and Accessible (O)RAS Preconditioner", "link": "https://arxiv.org/abs/2410.22871", "description": "arXiv:2410.22871v1 Announce Type: new \nAbstract: In this work, restricted additive Schwarz (RAS) and optimized restricted additive Schwarz (ORAS) preconditioners from the Trilinos package FROSch (Fast and Robust Overlapping Schwarz) are employed to solve model problems implemented using deal.II (differential equations analysis library). Therefore, a Tpetra-based interface for coupling deal.II and FROSch is implemented. While RAS preconditioners have been available before, ORAS preconditioners have been newly added to FROSch. The FROSch-deal.II interface works for both Lagrange-based and N\\'ed\\'elec finite elements. Here, as model problems, nonstationary, nonlinear, variational-monolithic fluid-structure interaction and the indefinite time-harmonic Maxwell's equations are considered. Several numerical experiments in two and three spatial dimensions confirm the performance of the preconditioners as well as the FROSch-deal.II interface. In conclusion, the overall software interface is straightforward and easy to use while giving satisfactory solver performances for challenging PDE systems.", "published": "2024-10-31 04:00:00", "id": "b5a616f2-d0fd-4528-80d7-90e935c4e6fd", "source": "arxiv", "section": "computerScience"}, {"title": "Data subsampling for Poisson regression with pth-root-link", "link": "https://arxiv.org/abs/2410.22872", "description": "arXiv:2410.22872v1 Announce Type: new \nAbstract: We develop and analyze data subsampling techniques for Poisson regression, the standard model for count data $y\\in\\mathbb{N}$. In particular, we consider the Poisson generalized linear model with ID- and square root-link functions. We consider the method of coresets, which are small weighted subsets that approximate the loss function of Poisson regression up to a factor of $1\\pm\\varepsilon$. We show $\\Omega(n)$ lower bounds against coresets for Poisson regression that continue to hold against arbitrary data reduction techniques up to logarithmic factors. By introducing a novel complexity parameter and a domain shifting approach, we show that sublinear coresets with $1\\pm\\varepsilon$ approximation guarantee exist when the complexity parameter is small. In particular, the dependence on the number of input points can be reduced to polylogarithmic. We show that the dependence on other input parameters can also be bounded sublinearly, though not always logarithmically. In particular, we show that the square root-link admits an $O(\\log(y_{\\max}))$ dependence, where $y_{\\max}$ denotes the largest count presented in the data, while the ID-link requires a $\\Theta(\\sqrt{y_{\\max}/\\log(y_{\\max})})$ dependence. As an auxiliary result for proving the tightness of the bound with respect to $y_{\\max}$ in the case of the ID-link, we show an improved bound on the principal branch of the Lambert $W_0$ function, which may be of independent interest. We further show the limitations of our analysis when $p$th degree root-link functions for $p\\geq 3$ are considered, which indicate that other analytical or computational methods would be required if such a generalization is even possible.", "published": "2024-10-31 04:00:00", "id": "ebb30e67-6355-4b1c-aaaa-d4b33ffdc73c", "source": "arxiv", "section": "computerScience"}, {"title": "Eliciting Critical Reasoning in Retrieval-Augmented Language Models via Contrastive Explanations", "link": "https://arxiv.org/abs/2410.22874", "description": "arXiv:2410.22874v1 Announce Type: new \nAbstract: Retrieval-augmented generation (RAG) has emerged as a critical mechanism in contemporary NLP to support Large Language Models(LLMs) in systematically accessing richer factual context. However, the integration of RAG mechanisms brings its inherent challenges, as LLMs need to deal with potentially noisy contexts. Recent studies have shown that LLMs still struggle to critically analyse RAG-based in-context information, a limitation that may lead to incorrect inferences and hallucinations. In this paper, we investigate how to elicit critical reasoning in RAG via contrastive explanations. In particular, we propose Contrastive-RAG (C-RAG), a framework that (i) retrieves relevant documents given a query, (ii) selects and exemplifies relevant passages, and (iii) generates explanations that explicitly contrast the relevance of the passages to (iv) support the final answer. We show the impact of C-RAG building contrastive reasoning demonstrations from LLMs to instruct smaller models for retrieval-augmented tasks. Extensive experiments demonstrate that C-RAG improves state-of-the-art RAG models while (a) requiring significantly fewer prompts and demonstrations and (b) being robust to perturbations in the retrieved documents.", "published": "2024-10-31 04:00:00", "id": "86da2471-280a-4dfe-bf8f-133acbab9bb3", "source": "arxiv", "section": "computerScience"}, {"title": "SFA-UNet: More Attention to Multi-Scale Contrast and Contextual Information in Infrared Small Object Segmentation", "link": "https://arxiv.org/abs/2410.22881", "description": "arXiv:2410.22881v1 Announce Type: new \nAbstract: Computer vision researchers have extensively worked on fundamental infrared visual recognition for the past few decades. Among various approaches, deep learning has emerged as the most promising candidate. However, Infrared Small Object Segmentation (ISOS) remains a major focus due to several challenges including: 1) the lack of effective utilization of local contrast and global contextual information; 2) the potential loss of small objects in deep models; and 3) the struggling to capture fine-grained details and ignore noise. To address these challenges, we propose a modified U-Net architecture, named SFA-UNet, by combining Scharr Convolution (SC) and Fast Fourier Convolution (FFC) in addition to vertical and horizontal Attention gates (AG) into UNet. SFA-UNet utilizes double convolution layers with the addition of SC and FFC in its encoder and decoder layers. SC helps to learn the foreground-to-background contrast information whereas FFC provide multi-scale contextual information while mitigating the small objects vanishing problem. Additionally, the introduction of vertical AGs in encoder layers enhances the model's focus on the targeted object by ignoring irrelevant regions. We evaluated the proposed approach on publicly available, SIRST and IRSTD datasets, and achieved superior performance by an average 0.75% with variance of 0.025 of all combined metrics in multiple runs as compared to the existing state-of-the-art methods", "published": "2024-10-31 04:00:00", "id": "bad9b0de-6cc0-4cde-a088-f85dceb87d27", "source": "arxiv", "section": "computerScience"}, {"title": "Adaptive Paradigm Synergy: Can a Cross-Paradigm Objective Enhance Long-Tailed Learning?", "link": "https://arxiv.org/abs/2410.22883", "description": "arXiv:2410.22883v1 Announce Type: new \nAbstract: Self-supervised learning (SSL) has achieved impressive results across several computer vision tasks, even rivaling supervised methods. However, its performance degrades on real-world datasets with long-tailed distributions due to difficulties in capturing inherent class imbalances. Although supervised long-tailed learning offers significant insights, the absence of labels in SSL prevents direct transfer of these strategies.To bridge this gap, we introduce Adaptive Paradigm Synergy (APS), a cross-paradigm objective that seeks to unify the strengths of both paradigms. Our approach reexamines contrastive learning from a spatial structure perspective, dynamically adjusting the uniformity of latent space structure through adaptive temperature tuning. Furthermore, we draw on a re-weighting strategy from supervised learning to compensate for the shortcomings of temperature adjustment in explicit quantity perception.Extensive experiments on commonly used long-tailed datasets demonstrate that APS improves performance effectively and efficiently. Our findings reveal the potential for deeper integration between supervised and self-supervised learning, paving the way for robust models that handle real-world class imbalance.", "published": "2024-10-31 04:00:00", "id": "77dcecc8-0fb1-4f4e-b036-50ad0a9beb4b", "source": "arxiv", "section": "computerScience"}, {"title": "Stealing User Prompts from Mixture of Experts", "link": "https://arxiv.org/abs/2410.22884", "description": "arXiv:2410.22884v1 Announce Type: new \nAbstract: Mixture-of-Experts (MoE) models improve the efficiency and scalability of dense language models by routing each token to a small number of experts in each layer. In this paper, we show how an adversary that can arrange for their queries to appear in the same batch of examples as a victim's queries can exploit Expert-Choice-Routing to fully disclose a victim's prompt. We successfully demonstrate the effectiveness of this attack on a two-layer Mixtral model, exploiting the tie-handling behavior of the torch.topk CUDA implementation. Our results show that we can extract the entire prompt using $O({VM}^2)$ queries (with vocabulary size $V$ and prompt length $M$) or 100 queries on average per token in the setting we consider. This is the first attack to exploit architectural flaws for the purpose of extracting user prompts, introducing a new class of LLM vulnerabilities.", "published": "2024-10-31 04:00:00", "id": "e603caf2-3be5-4f69-842a-41ea83428b39", "source": "arxiv", "section": "computerScience"}, {"title": "Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with Cognitively-Plausible Curriculum Learning Strategies", "link": "https://arxiv.org/abs/2410.22886", "description": "arXiv:2410.22886v1 Announce Type: new \nAbstract: Curriculum Learning has been a popular strategy to improve the cognitive plausibility of Small-Scale Language Models (SSLMs) in the BabyLM Challenge. However, it has not led to considerable improvements over non-curriculum models. We assess whether theoretical linguistic acquisition theories can be used to specify more fine-grained curriculum learning strategies, creating age-ordered corpora of Child-Directed Speech for four typologically distant language families to implement SSLMs and acquisition-inspired curricula cross-lingually. Comparing the success of three objective curricula (Growing, Inwards and MMM) that precisely replicate the predictions of acquisition theories on a standard SSLM architecture, we find fine-grained acquisition-inspired curricula can outperform non-curriculum baselines and performance benefits of curricula strategies in SSLMs can be derived by specifying fine-grained language-specific curricula that precisely replicate language acquisition theories.", "published": "2024-10-31 04:00:00", "id": "e2af0e25-3f4c-4433-8bee-d1e2435fe3b9", "source": "arxiv", "section": "computerScience"}, {"title": "Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector", "link": "https://arxiv.org/abs/2410.22888", "description": "arXiv:2410.22888v1 Announce Type: new \nAbstract: Visual Language Models (VLMs) are vulnerable to adversarial attacks, especially those from adversarial images, which is however under-explored in literature. To facilitate research on this critical safety problem, we first construct a new laRge-scale Adervsarial images dataset with Diverse hArmful Responses (RADAR), given that existing datasets are either small-scale or only contain limited types of harmful responses. With the new RADAR dataset, we further develop a novel and effective iN-time Embedding-based AdveRSarial Image DEtection (NEARSIDE) method, which exploits a single vector that distilled from the hidden states of VLMs, which we call the attacking direction, to achieve the detection of adversarial images against benign ones in the input. Extensive experiments with two victim VLMs, LLaVA and MiniGPT-4, well demonstrate the effectiveness, efficiency, and cross-model transferrability of our proposed method. Our code is available at https://github.com/mob-scu/RADAR-NEARSIDE", "published": "2024-10-31 04:00:00", "id": "68c9013e-fe88-429a-b429-89c7383e0487", "source": "arxiv", "section": "computerScience"}, {"title": "VPO: Leveraging the Number of Votes in Preference Optimization", "link": "https://arxiv.org/abs/2410.22891", "description": "arXiv:2410.22891v1 Announce Type: new \nAbstract: Direct Preference Optimization (DPO) trains a language model using human preference data, bypassing the explicit reward modeling phase of Reinforcement Learning from Human Feedback (RLHF). By iterating over sentence pairs in a preference dataset, DPO enhances generation quality by increasing the likelihood of producing preferred sentences over less favored ones. Preference datasets are typically created by selecting preferred sentences through a voting process involving multiple individuals, as opinions can vary due to the subjective nature of human preferences. While the number of votes offers insight into whether a sentence pair is clearly preferable or controversial, current methods do not fully leverage this information. In this paper, we introduce a technique that leverages user voting data to better align with diverse subjective preferences. We employ the Bayesian Minimum Mean Square Error (Bayesian MMSE) estimator to model the probability that one generation is preferable to another. Using this estimated probability as a target, we develop the Vote-based Preference Optimization (VPO) framework, which incorporates the number of votes on both sides to distinguish between controversial and obvious generation pairs. We show that previous algorithms, such as DPO and Identity Preference Optimization (IPO), can be extended using the proposed framework, termed VDPO and VIPO. Our experiments demonstrate that these proposed algorithms outperform various existing methods, including their base algorithms.", "published": "2024-10-31 04:00:00", "id": "39e3653d-891c-41d5-a198-ec06e7c33927", "source": "arxiv", "section": "computerScience"}, {"title": "Human-inspired Grasping Strategies of Fresh Fruits and Vegetables Applied to Robotic Manipulation", "link": "https://arxiv.org/abs/2410.22893", "description": "arXiv:2410.22893v1 Announce Type: new \nAbstract: Robotic manipulation of fresh fruits and vegetables, including the grasping of multiple loose items, has a strong industrial need but it still is a challenging task for robotic manipulation. This paper outlines the distinctive manipulation strategies used by humans to pick loose fruits and vegetables with the aim to better adopt them for robotic manipulation of diverse items. In this work we present a first version of a robotic setup designed to pick different single or multiple fresh items, featuring multi-fingered compliant robotic gripper. We analyse human grasping strategies from the perspective of industrial Key Performance Indicators (KPIs) used in the logistic sector. The robotic system was validated using the same KPIs, as well as taking into account human performance and strategies. This paper lays the foundation for future development of the robotic demonstrator for fresh fruit and vegetable intelligent manipulation, and outlines the need for generic approaches to handle the complexity of the task.", "published": "2024-10-31 04:00:00", "id": "91397f87-5537-4090-8c0a-69cf43f826d7", "source": "arxiv", "section": "computerScience"}, {"title": "Constrained Trajectory Optimization for Hybrid Dynamical Systems", "link": "https://arxiv.org/abs/2410.22894", "description": "arXiv:2410.22894v1 Announce Type: new \nAbstract: Hybrid dynamical systems pose significant challenges for effective planning and control, especially when additional constraints such as obstacle avoidance, state boundaries, and actuation limits are present. In this letter, we extend the recently proposed Hybrid iLQR method [1] to handle state and input constraints within an indirect optimization framework, aiming to preserve computational efficiency and ensure dynamic feasibility. Specifically, we incorporate two constraint handling mechanisms into the Hybrid iLQR: Discrete Barrier State and Augmented Lagrangian methods. Comprehensive simulations across various operational situations are conducted to evaluate and compare the performance of these extended methods in terms of convergence and their ability to handle infeasible starting trajectories. Results indicate that while the Discrete Barrier State approach is more computationally efficient, the Augmented Lagrangian method outperforms it in complex and real-world scenarios with infeasible initial trajectories.", "published": "2024-10-31 04:00:00", "id": "0c638409-9e4e-4cb4-8703-d5bd57c5fd95", "source": "arxiv", "section": "computerScience"}, {"title": "Combining psychoanalysis and computer science: an empirical study of the relationship between emotions and the Lacanian discourses", "link": "https://arxiv.org/abs/2410.22895", "description": "arXiv:2410.22895v1 Announce Type: new \nAbstract: This research explores the interdisciplinary interaction between psychoanalysis and computer science, suggesting a mutually beneficial exchange. Indeed, psychoanalytic concepts can enrich technological applications involving unconscious, elusive aspects of the human factor, such as social media and other interactive digital platforms. Conversely, computer science, especially Artificial Intelligence (AI), can contribute quantitative concepts and methods to psychoanalysis, identifying patterns and emotional cues in human expression. In particular, this research aims to apply computer science methods to establish fundamental relationships between emotions and Lacanian discourses. Such relations are discovered in our approach via empirical investigation and statistical analysis, and are eventually validated in a theoretical (psychoanalytic) way. It is worth noting that, although emotions have been sporadically studied in Lacanian theory, to the best of our knowledge a systematic, detailed investigation of their role is missing. Such fine-grained understanding of the role of emotions can also make the identification of Lacanian discourses more effective and easy in practise. In particular, our methods indicate the emotions with highest differentiation power in terms of corresponding discourses; conversely, we identify for each discourse the most characteristic emotions it admits. As a matter of fact, we develop a method which we call Lacanian Discourse Discovery (LDD), that simplifies (via systematizing) the identification of Lacanian discourses in texts. Although the main contribution of this paper is inherently theoretical (psychoanalytic), it can also facilitate major practical applications in the realm of interactive digital systems. Indeed, our approach can be automated through Artificial Intelligence methods that effectively identify emotions (and corresponding discourses) in texts.", "published": "2024-10-31 04:00:00", "id": "9a9ccca3-dc35-44d3-89e8-65a5222ae4ba", "source": "arxiv", "section": "computerScience"}, {"title": "A Graph-Based Model for Vehicle-Centric Data Sharing Ecosystem", "link": "https://arxiv.org/abs/2410.22897", "description": "arXiv:2410.22897v1 Announce Type: new \nAbstract: The development of technologies has prompted a paradigm shift in the automotive industry, with an increasing focus on connected services and autonomous driving capabilities. This transformation allows vehicles to collect and share vast amounts of vehicle-specific and personal data. While these technological advancements offer enhanced user experiences, they also raise privacy concerns. To understand the ecosystem of data collection and sharing in modern vehicles, we adopted the ontology 101 methodology to incorporate information extracted from different sources, including analysis of privacy policies using GPT-4, a small-scale systematic literature review, and an existing ontology, to develop a high-level conceptual graph-based model, aiming to get insights into how modern vehicles handle data exchange among different parties. This serves as a foundational model with the flexibility and scalability to further expand for modelling and analysing data sharing practices across diverse contexts. Two realistic examples were developed to demonstrate the usefulness and effectiveness of discovering insights into privacy regarding vehicle-related data sharing. We also recommend several future research directions, such as exploring advanced ontology languages for reasoning tasks, supporting topological analysis for discovering data privacy risks/concerns, and developing useful tools for comparative analysis, to strengthen the understanding of the vehicle-centric data sharing ecosystem.", "published": "2024-10-31 04:00:00", "id": "a79958dc-0080-4214-a785-947caa9413f1", "source": "arxiv", "section": "computerScience"}, {"title": "YOLOv11 for Vehicle Detection: Advancements, Performance, and Applications in Intelligent Transportation Systems", "link": "https://arxiv.org/abs/2410.22898", "description": "arXiv:2410.22898v1 Announce Type: new \nAbstract: Accurate vehicle detection is essential for the development of intelligent transportation systems, autonomous driving, and traffic monitoring. This paper presents a detailed analysis of YOLO11, the latest advancement in the YOLO series of deep learning models, focusing exclusively on vehicle detection tasks. Building upon the success of its predecessors, YOLO11 introduces architectural improvements designed to enhance detection speed, accuracy, and robustness in complex environments. Using a comprehensive dataset comprising multiple vehicle types-cars, trucks, buses, motorcycles, and bicycles we evaluate YOLO11's performance using metrics such as precision, recall, F1 score, and mean average precision (mAP). Our findings demonstrate that YOLO11 surpasses previous versions (YOLOv8 and YOLOv10) in detecting smaller and more occluded vehicles while maintaining a competitive inference time, making it well-suited for real-time applications. Comparative analysis shows significant improvements in the detection of complex vehicle geometries, further contributing to the development of efficient and scalable vehicle detection systems. This research highlights YOLO11's potential to enhance autonomous vehicle performance and traffic monitoring systems, offering insights for future developments in the field.", "published": "2024-10-31 04:00:00", "id": "fd948202-9698-4979-8639-6546b2a38062", "source": "arxiv", "section": "computerScience"}, {"title": "Wormhole Loss for Partial Shape Matching", "link": "https://arxiv.org/abs/2410.22899", "description": "arXiv:2410.22899v1 Announce Type: new \nAbstract: When matching parts of a surface to its whole, a fundamental question arises: Which points should be included in the matching process? The issue is intensified when using isometry to measure similarity, as it requires the validation of whether distances measured between pairs of surface points should influence the matching process. The approach we propose treats surfaces as manifolds equipped with geodesic distances, and addresses the partial shape matching challenge by introducing a novel criterion to meticulously search for consistent distances between pairs of points. The new criterion explores the relation between intrinsic geodesic distances between the points, geodesic distances between the points and surface boundaries, and extrinsic distances between boundary points measured in the embedding space. It is shown to be less restrictive compared to previous measures and achieves state-of-the-art results when used as a loss function in training networks for partial shape matching.", "published": "2024-10-31 04:00:00", "id": "ec23b123-4ea9-4c37-b8b0-255cb6526f32", "source": "arxiv", "section": "computerScience"}, {"title": "HelloMeme: Integrating Spatial Knitting Attentions to Embed High-Level and Fidelity-Rich Conditions in Diffusion Models", "link": "https://arxiv.org/abs/2410.22901", "description": "arXiv:2410.22901v1 Announce Type: new \nAbstract: We propose an effective method for inserting adapters into text-to-image foundation models, which enables the execution of complex downstream tasks while preserving the generalization ability of the base model. The core idea of this method is to optimize the attention mechanism related to 2D feature maps, which enhances the performance of the adapter. This approach was validated on the task of meme video generation and achieved significant results. We hope this work can provide insights for post-training tasks of large text-to-image models. Additionally, as this method demonstrates good compatibility with SD1.5 derivative models, it holds certain value for the open-source community. Therefore, we will release the related code (\\url{https://songkey.github.io/hellomeme}).", "published": "2024-10-31 04:00:00", "id": "50f11576-0ee7-4415-bd7e-5f0014da5239", "source": "arxiv", "section": "computerScience"}, {"title": "From Babble to Words: Pre-Training Language Models on Continuous Streams of Phonemes", "link": "https://arxiv.org/abs/2410.22906", "description": "arXiv:2410.22906v1 Announce Type: new \nAbstract: Language models are typically trained on large corpora of text in their default orthographic form. However, this is not the only option; representing data as streams of phonemes can offer unique advantages, from deeper insights into phonological language acquisition to improved performance on sound-based tasks. The challenge lies in evaluating the impact of phoneme-based training, as most benchmarks are also orthographic. To address this, we develop a pipeline to convert text datasets into a continuous stream of phonemes. We apply this pipeline to the 100-million-word pre-training dataset from the BabyLM challenge, as well as to standard language and grammatical benchmarks, enabling us to pre-train and evaluate a model using phonemic input representations. Our results show that while phoneme-based training slightly reduces performance on traditional language understanding tasks, it offers valuable analytical and practical benefits.", "published": "2024-10-31 04:00:00", "id": "df7c07d8-3af7-4c54-917b-57714e1b4004", "source": "arxiv", "section": "computerScience"}, {"title": "The Evolution Of The Digital Inheritance: Legal, Technical, And Practical Dimensions Of Cryptocurrency Transfer Through Succession In French-Inspired Legal Systems", "link": "https://arxiv.org/abs/2410.22907", "description": "arXiv:2410.22907v1 Announce Type: new \nAbstract: In recent years, cryptocurrencies have enjoyed increased popularity in all domains. Thus, in this context, it is important to understand how these digital assets can be transmitted, both legally and efficiently, in the event of the death of their owner. The present paper analyses the mechanisms of cryptocurrencies, analysing from a technical point of view aspects related to blockchain technology, virtual wallets or cryptographic keys, as well as various types of operations regarding this type of virtual currencies. The study also examines the legal aspects related to cryptocurrencies, with an emphasis on the diversity of their status in different global jurisdictions as well as the impact on inheritance planning. The case studies present tangible examples related to successions with cryptocurrencies as the main object, thus completing the exposition related to the main challenges faced by the heirs in the transfer process. In this way, this paper offers possible solutions and recommendations related to inheritance planning with cryptocurrencies as its main object, including the legal and fiscal aspects that must be taken into account when planning a digital succession.", "published": "2024-10-31 04:00:00", "id": "fc5b5765-7b4a-4aa4-8535-0867eaf5e0b5", "source": "arxiv", "section": "computerScience"}, {"title": "Federated UCBVI: Communication-Efficient Federated Regret Minimization with Heterogeneous Agents", "link": "https://arxiv.org/abs/2410.22908", "description": "arXiv:2410.22908v1 Announce Type: new \nAbstract: In this paper, we present the Federated Upper Confidence Bound Value Iteration algorithm ($\\texttt{Fed-UCBVI}$), a novel extension of the $\\texttt{UCBVI}$ algorithm (Azar et al., 2017) tailored for the federated learning framework. We prove that the regret of $\\texttt{Fed-UCBVI}$ scales as $\\tilde{\\mathcal{O}}(\\sqrt{H^3 |\\mathcal{S}| |\\mathcal{A}| T / M})$, with a small additional term due to heterogeneity, where $|\\mathcal{S}|$ is the number of states, $|\\mathcal{A}|$ is the number of actions, $H$ is the episode length, $M$ is the number of agents, and $T$ is the number of episodes. Notably, in the single-agent setting, this upper bound matches the minimax lower bound up to polylogarithmic factors, while in the multi-agent scenario, $\\texttt{Fed-UCBVI}$ has linear speed-up. To conduct our analysis, we introduce a new measure of heterogeneity, which may hold independent theoretical interest. Furthermore, we show that, unlike existing federated reinforcement learning approaches, $\\texttt{Fed-UCBVI}$'s communication complexity only marginally increases with the number of agents.", "published": "2024-10-31 04:00:00", "id": "e1c8b27b-2c8d-4fe0-96fb-adf0cc5c0138", "source": "arxiv", "section": "computerScience"}, {"title": "UniRiT: Towards Few-Shot Non-Rigid Point Cloud Registration", "link": "https://arxiv.org/abs/2410.22909", "description": "arXiv:2410.22909v1 Announce Type: new \nAbstract: Non-rigid point cloud registration is a critical challenge in 3D scene understanding, particularly in surgical navigation. Although existing methods achieve excellent performance when trained on large-scale, high-quality datasets, these datasets are prohibitively expensive to collect and annotate, e.g., organ data in authentic medical scenarios. With insufficient training samples and data noise, existing methods degrade significantly since non-rigid patterns are more flexible and complicated than rigid ones, and the distributions across samples are more distinct, leading to higher difficulty in representation learning with few data. In this work, we aim to deal with this challenging few-shot non-rigid point cloud registration problem. Based on the observation that complex non-rigid transformation patterns can be decomposed into rigid and small non-rigid transformations, we propose a novel and effective framework, UniRiT. UniRiT adopts a two-step registration strategy that first aligns the centroids of the source and target point clouds and then refines the registration with non-rigid transformations, thereby significantly reducing the problem complexity. To validate the performance of UniRiT on real-world datasets, we introduce a new dataset, MedMatch3D, which consists of real human organs and exhibits high variability in sample distribution. We further establish a new challenging benchmark for few-shot non-rigid registration. Extensive empirical results demonstrate that UniRiT achieves state-of-the-art performance on MedMatch3D, improving the existing best approach by 94.22%.", "published": "2024-10-31 04:00:00", "id": "1549f2d1-aa4d-4b1b-8800-64655f51eb94", "source": "arxiv", "section": "computerScience"}, {"title": "An Efficient Representation of Whole-body Model Predictive Control for Online Compliant Dual-arm Mobile Manipulation", "link": "https://arxiv.org/abs/2410.22910", "description": "arXiv:2410.22910v1 Announce Type: new \nAbstract: Dual-arm mobile manipulators can transport and manipulate large-size objects with simple end-effectors. To interact with dynamic environments with strict safety and compliance requirements, achieving whole-body motion planning online while meeting various hard constraints for such highly redundant mobile manipulators poses a significant challenge. We tackle this challenge by presenting an efficient representation of whole-body motion trajectories within our bilevel model-based predictive control (MPC) framework. We utilize B\\'ezier-curve parameterization to represent the optimized collision-free trajectories of two collaborating end-effectors in the first MPC, facilitating fast long-horizon object-oriented motion planning in SE(3) while considering approximated feasibility constraints. This approach is further applied to parameterize whole-body trajectories in the second MPC for whole-body motion generation with predictive admittance control in a relatively short horizon while satisfying whole-body hard constraints. This representation enables two MPCs with continuous properties, thereby avoiding inaccurate model-state transition and dense decision-variable settings in existing MPCs using the discretization method. It strengthens the online execution of the bilevel MPC framework in high-dimensional space and facilitates the generation of consistent commands for our hybrid position/velocity-controlled robot. The simulation comparisons and real-world experiments demonstrate the efficiency and robustness of this approach in various scenarios for static and dynamic obstacle avoidance, and compliant interaction control with the manipulated object and external disturbances.", "published": "2024-10-31 04:00:00", "id": "ca12a843-602a-4d82-a1ec-bc59b1623645", "source": "arxiv", "section": "computerScience"}, {"title": "CopRA: A Progressive LoRA Training Strategy", "link": "https://arxiv.org/abs/2410.22911", "description": "arXiv:2410.22911v1 Announce Type: new \nAbstract: Low-Rank Adaptation (LoRA) is a parameter-efficient technique for rapidly fine-tuning foundation models. In standard LoRA training dynamics, models tend to quickly converge to a local optimum near the initialization. However, this local optimum may not be ideal for out-of-distribution data or tasks such as merging and pruning. In this work, we propose a novel progressive training strategy for LoRA with random layer dropping. This strategy also optimizes the Shapley value of LoRA parameters in each layer, treating each layer as a player in a cooperative game. We refer to this method as Cooperative LoRA (CopRA). Our experimental results demonstrate that parameters trained with CopRA exhibit linear mode connectivity, which enables efficient model merging. This also paves the way for federated learning and multi-task learning via LoRA merging. Additionally, by optimizing the Shapley value, CopRA shows superior performance in pruning tasks.", "published": "2024-10-31 04:00:00", "id": "d0a94eca-3035-4da5-b77e-21225974323d", "source": "arxiv", "section": "computerScience"}, {"title": "Self-optimization in distributed manufacturing systems using Modular State-based Stackelberg Games", "link": "https://arxiv.org/abs/2410.22912", "description": "arXiv:2410.22912v1 Announce Type: new \nAbstract: In this study, we introduce Modular State-based Stackelberg Games (Mod-SbSG), a novel game structure developed for distributed self-learning in modular manufacturing systems. Mod-SbSG enhances cooperative decision-making among self-learning agents within production systems by integrating State-based Potential Games (SbPG) with Stackelberg games. This hierarchical structure assigns more important modules of the manufacturing system a first-mover advantage, while less important modules respond optimally to the leaders' decisions. This decision-making process differs from typical multi-agent learning algorithms in manufacturing systems, where decisions are made simultaneously. We provide convergence guarantees for the novel game structure and design learning algorithms to account for the hierarchical game structure. We further analyse the effects of single-leader/multiple-follower and multiple-leader/multiple-follower scenarios within a Mod-SbSG. To assess its effectiveness, we implement and test Mod-SbSG in an industrial control setting using two laboratory-scale testbeds featuring sequential and serial-parallel processes. The proposed approach delivers promising results compared to the vanilla SbPG, which reduces overflow by 97.1%, and in some cases, prevents overflow entirely. Additionally, it decreases power consumption by 5-13% while satisfying the production demand, which significantly improves potential (global objective) values.", "published": "2024-10-31 04:00:00", "id": "a426b959-035d-458f-a343-153fae8677c6", "source": "arxiv", "section": "computerScience"}, {"title": "Explainable Behavior Cloning: Teaching Large Language Model Agents through Learning by Demonstration", "link": "https://arxiv.org/abs/2410.22916", "description": "arXiv:2410.22916v1 Announce Type: new \nAbstract: Autonomous mobile app interaction has become increasingly important with growing complexity of mobile applications. Developing intelligent agents that can effectively navigate and interact with mobile apps remains a significant challenge. In this paper, we propose an Explainable Behavior Cloning LLM Agent (EBC-LLMAgent), a novel approach that combines large language models (LLMs) with behavior cloning by learning demonstrations to create intelligent and explainable agents for autonomous mobile app interaction. EBC-LLMAgent consists of three core modules: Demonstration Encoding, Code Generation, and UI Mapping, which work synergistically to capture user demonstrations, generate executable codes, and establish accurate correspondence between code and UI elements. We introduce the Behavior Cloning Chain Fusion technique to enhance the generalization capabilities of the agent. Extensive experiments on five popular mobile applications from diverse domains demonstrate the superior performance of EBC-LLMAgent, achieving high success rates in task completion, efficient generalization to unseen scenarios, and the generation of meaningful explanations.", "published": "2024-10-31 04:00:00", "id": "3e38484a-4887-4eea-939d-73f3e69074e0", "source": "arxiv", "section": "computerScience"}, {"title": "Simulation-Free Training of Neural ODEs on Paired Data", "link": "https://arxiv.org/abs/2410.22918", "description": "arXiv:2410.22918v1 Announce Type: new \nAbstract: In this work, we investigate a method for simulation-free training of Neural Ordinary Differential Equations (NODEs) for learning deterministic mappings between paired data. Despite the analogy of NODEs as continuous-depth residual networks, their application in typical supervised learning tasks has not been popular, mainly due to the large number of function evaluations required by ODE solvers and numerical instability in gradient estimation. To alleviate this problem, we employ the flow matching framework for simulation-free training of NODEs, which directly regresses the parameterized dynamics function to a predefined target velocity field. Contrary to generative tasks, however, we show that applying flow matching directly between paired data can often lead to an ill-defined flow that breaks the coupling of the data pairs (e.g., due to crossing trajectories). We propose a simple extension that applies flow matching in the embedding space of data pairs, where the embeddings are learned jointly with the dynamic function to ensure the validity of the flow which is also easier to learn. We demonstrate the effectiveness of our method on both regression and classification tasks, where our method outperforms existing NODEs with a significantly lower number of function evaluations. The code is available at https://github.com/seminkim/simulation-free-node.", "published": "2024-10-31 04:00:00", "id": "21aad891-391e-4e12-9177-bc638ea27197", "source": "arxiv", "section": "computerScience"}, {"title": "Cyber-physical WebAssembly: Secure Hardware Interfaces and Pluggable Drivers", "link": "https://arxiv.org/abs/2410.22919", "description": "arXiv:2410.22919v1 Announce Type: new \nAbstract: The rapid expansion of Internet of Things (IoT), edge, and embedded devices in the past decade has introduced numerous challenges in terms of security and configuration management. Simultaneously, advances in cloud-native development practices have greatly enhanced the development experience and facilitated quicker updates, thereby enhancing application security. However, applying these advances to IoT, edge, and embedded devices remains a complex task, primarily due to the heterogeneous environments and the need to support devices with extended lifespans. WebAssembly and the WebAssembly System Interface (WASI) has emerged as a promising technology to bridge this gap. As WebAssembly becomes more popular on IoT, edge, and embedded devices, there is a growing demand for hardware interface support in WebAssembly programs. This work presents WASI proposals and proof-of-concept implementations to enable hardware interaction with I2C and USB, which are two commonly used protocols in IoT, directly from WebAssembly applications. This is achieved by running the device drivers within WebAssembly as well. A thorough evaluation of the proof of concepts shows that WASI-USB introduces a minimal overhead of at most 8% compared to native operating system USB APIs. However, the results show that runtime initialization overhead can be significant in low-latency applications.", "published": "2024-10-31 04:00:00", "id": "332fac90-d752-4373-a20c-52ae57449a14", "source": "arxiv", "section": "computerScience"}, {"title": "High-Fidelity Document Stain Removal via A Large-Scale Real-World Dataset and A Memory-Augmented Transformer", "link": "https://arxiv.org/abs/2410.22922", "description": "arXiv:2410.22922v1 Announce Type: new \nAbstract: Document images are often degraded by various stains, significantly impacting their readability and hindering downstream applications such as document digitization and analysis. The absence of a comprehensive stained document dataset has limited the effectiveness of existing document enhancement methods in removing stains while preserving fine-grained details. To address this challenge, we construct StainDoc, the first large-scale, high-resolution ($2145\\times2245$) dataset specifically designed for document stain removal. StainDoc comprises over 5,000 pairs of stained and clean document images across multiple scenes. This dataset encompasses a diverse range of stain types, severities, and document backgrounds, facilitating robust training and evaluation of document stain removal algorithms. Furthermore, we propose StainRestorer, a Transformer-based document stain removal approach. StainRestorer employs a memory-augmented Transformer architecture that captures hierarchical stain representations at part, instance, and semantic levels via the DocMemory module. The Stain Removal Transformer (SRTransformer) leverages these feature representations through a dual attention mechanism: an enhanced spatial attention with an expanded receptive field, and a channel attention captures channel-wise feature importance. This combination enables precise stain removal while preserving document content integrity. Extensive experiments demonstrate StainRestorer's superior performance over state-of-the-art methods on the StainDoc dataset and its variants StainDoc\\_Mark and StainDoc\\_Seal, establishing a new benchmark for document stain removal. Our work highlights the potential of memory-augmented Transformers for this task and contributes a valuable dataset to advance future research.", "published": "2024-10-31 04:00:00", "id": "199a8584-315a-4591-ac45-51696128d9a8", "source": "arxiv", "section": "computerScience"}, {"title": "BIS: NL2SQL Service Evaluation Benchmark for Business Intelligence Scenarios", "link": "https://arxiv.org/abs/2410.22925", "description": "arXiv:2410.22925v1 Announce Type: new \nAbstract: NL2SQL (Natural Language to Structured Query Language) transformation has seen wide adoption in Business Intelligence (BI) applications in recent years. However, existing NL2SQL benchmarks are not suitable for production BI scenarios, as they are not designed for common business intelligence questions. To address this gap, we have developed a new benchmark focused on typical NL questions in industrial BI scenarios. We discuss the challenges of constructing a BI-focused benchmark and the shortcomings of existing benchmarks. Additionally, we introduce question categories in our benchmark that reflect common BI inquiries. Lastly, we propose two novel semantic similarity evaluation metrics for assessing NL2SQL capabilities in BI applications and services.", "published": "2024-10-31 04:00:00", "id": "a4d47c35-3633-40d7-985d-44c75b06865c", "source": "arxiv", "section": "computerScience"}, {"title": "An Individual Identity-Driven Framework for Animal Re-Identification", "link": "https://arxiv.org/abs/2410.22927", "description": "arXiv:2410.22927v1 Announce Type: new \nAbstract: Reliable re-identification of individuals within large wildlife populations is crucial for biological studies, ecological research, and wildlife conservation. Classic computer vision techniques offer a promising direction for Animal Re-identification (Animal ReID), but their backbones' close-set nature limits their applicability and generalizability. Despite the demonstrated effectiveness of vision-language models like CLIP in re-identifying persons and vehicles, their application to Animal ReID remains limited due to unique challenges, such as the various visual representations of animals, including variations in poses and forms. To address these limitations, we leverage CLIP's cross-modal capabilities to introduce a two-stage framework, the \\textbf{Indiv}idual \\textbf{A}nimal \\textbf{ID}entity-Driven (IndivAID) framework, specifically designed for Animal ReID. In the first stage, IndivAID trains a text description generator by extracting individual semantic information from each image, generating both image-specific and individual-specific textual descriptions that fully capture the diverse visual concepts of each individual across animal images. In the second stage, IndivAID refines its learning of visual concepts by dynamically incorporating individual-specific textual descriptions with an integrated attention module to further highlight discriminative features of individuals for Animal ReID. Evaluation against state-of-the-art methods across eight benchmark datasets and a real-world Stoat dataset demonstrates IndivAID's effectiveness and applicability. Code is available at \\url{https://github.com/ywu840/IndivAID}.", "published": "2024-10-31 04:00:00", "id": "4fa73b97-392d-4619-91e5-bc77433dea2b", "source": "arxiv", "section": "computerScience"}, {"title": "GPTR: Gaussian Process Trajectory Representation for Continuous-Time Motion Estimation", "link": "https://arxiv.org/abs/2410.22931", "description": "arXiv:2410.22931v1 Announce Type: new \nAbstract: Continuous-time trajectory representation has gained significant popularity in recent years, as it offers an elegant formulation that allows the fusion of a larger number of sensors and sensing modalities, overcoming limitations of traditional discrete-time frameworks. To bolster the adoption of the continuous-time paradigm, we propose a so-called Gaussian Process Trajectory Representation (GPTR) framework for continuous-time motion estimation (CTME) tasks. Our approach stands out by employing a third-order random jerk model, featuring closed-form expressions for both rotational and translational state derivatives. This model provides smooth, continuous trajectory representations that are crucial for precise estimation of complex motion. To support the wider robotics and computer vision communities, we have made the source code for GPTR available as a light-weight header-only library. This format was chosen for its ease of integration, allowing developers to incorporate GPTR into existing systems without needing extensive code modifications. Moreover, we also provide a set of optimization examples with LiDAR, camera, IMU, UWB factors, and closed-form analytical Jacobians under the proposed GP framework. Our experiments demonstrate the efficacy and efficiency of GP-based trajectory representation in various motion estimation tasks, and the examples can serve as the prototype to help researchers quickly develop future applications such as batch optimization, calibration, sensor fusion, trajectory planning, etc., with continuous-time trajectory representation. Our project is accessible at https://github.com/brytsknguyen/gptr .", "published": "2024-10-31 04:00:00", "id": "709a5c75-37ed-4fea-b309-9216a2870fb3", "source": "arxiv", "section": "computerScience"}, {"title": "Multi-Agent Large Language Models for Conversational Task-Solving", "link": "https://arxiv.org/abs/2410.22932", "description": "arXiv:2410.22932v1 Announce Type: new \nAbstract: In an era where single large language models have dominated the landscape of artificial intelligence for years, multi-agent systems arise as new protagonists in conversational task-solving. While previous studies have showcased their potential in reasoning tasks and creative endeavors, an analysis of their limitations concerning the conversational paradigms and the impact of individual agents is missing. It remains unascertained how multi-agent discussions perform across tasks of varying complexity and how the structure of these conversations influences the process. To fill that gap, this work systematically evaluates multi-agent systems across various discussion paradigms, assessing their strengths and weaknesses in both generative tasks and question-answering tasks. Alongside the experiments, I propose a taxonomy of 20 multi-agent research studies from 2022 to 2024, followed by the introduction of a framework for deploying multi-agent LLMs in conversational task-solving. I demonstrate that while multi-agent systems excel in complex reasoning tasks, outperforming a single model by leveraging expert personas, they fail on basic tasks. Concretely, I identify three challenges that arise: 1) While longer discussions enhance reasoning, agents fail to maintain conformity to strict task requirements, which leads to problem drift, making shorter conversations more effective for basic tasks. 2) Prolonged discussions risk alignment collapse, raising new safety concerns for these systems. 3) I showcase discussion monopolization through long generations, posing the problem of fairness in decision-making for tasks like summarization. This work uncovers both the potential and challenges that arise with multi-agent interaction and varying conversational paradigms, providing insights into how future research could improve the efficiency, performance, and safety of multi-agent LLMs.", "published": "2024-10-31 04:00:00", "id": "b3321153-6709-471b-b557-8e76758f4722", "source": "arxiv", "section": "computerScience"}, {"title": "Bringing NeRFs to the Latent Space: Inverse Graphics Autoencoder", "link": "https://arxiv.org/abs/2410.22936", "description": "arXiv:2410.22936v1 Announce Type: new \nAbstract: While pre-trained image autoencoders are increasingly utilized in computer vision, the application of inverse graphics in 2D latent spaces has been under-explored. Yet, besides reducing the training and rendering complexity, applying inverse graphics in the latent space enables a valuable interoperability with other latent-based 2D methods. The major challenge is that inverse graphics cannot be directly applied to such image latent spaces because they lack an underlying 3D geometry. In this paper, we propose an Inverse Graphics Autoencoder (IG-AE) that specifically addresses this issue. To this end, we regularize an image autoencoder with 3D-geometry by aligning its latent space with jointly trained latent 3D scenes. We utilize the trained IG-AE to bring NeRFs to the latent space with a latent NeRF training pipeline, which we implement in an open-source extension of the Nerfstudio framework, thereby unlocking latent scene learning for its supported methods. We experimentally confirm that Latent NeRFs trained with IG-AE present an improved quality compared to a standard autoencoder, all while exhibiting training and rendering accelerations with respect to NeRFs trained in the image space. Our project page can be found at https://ig-ae.github.io .", "published": "2024-10-31 04:00:00", "id": "478e2c66-8c3e-42b2-b14f-f21062519127", "source": "arxiv", "section": "computerScience"}, {"title": "Thoughtful Adoption of NLP for Civic Participation: Understanding Differences Among Policymakers", "link": "https://arxiv.org/abs/2410.22937", "description": "arXiv:2410.22937v1 Announce Type: new \nAbstract: Natural language processing (NLP) tools have the potential to boost civic participation and enhance democratic processes because they can significantly increase governments' capacity to gather and analyze citizen opinions. However, their adoption in government remains limited, and harnessing their benefits while preventing unintended consequences remains a challenge. While prior work has focused on improving NLP performance, this work examines how different internal government stakeholders influence NLP tools' thoughtful adoption. We interviewed seven politicians (politically appointed officials as heads of government institutions) and thirteen public servants (career government employees who design and administrate policy interventions), inquiring how they choose whether and how to use NLP tools to support civic participation processes. The interviews suggest that policymakers across both groups focused on their needs for career advancement and the need to showcase the legitimacy and fairness of their work when considering NLP tool adoption and use. Because these needs vary between politicians and public servants, their preferred NLP features and tool designs also differ. Interestingly, despite their differing needs and opinions, neither group clearly identifies who should advocate for NLP adoption to enhance civic participation or address the unintended consequences of a poorly considered adoption. This lack of clarity in responsibility might have caused the governments' low adoption of NLP tools. We discuss how these findings reveal new insights for future HCI research. They inform the design of NLP tools for increasing civic participation efficiency and capacity, the design of other tools and methods that ensure thoughtful adoption of AI tools in government, and the design of NLP tools for collaborative use among users with different incentives and needs.", "published": "2024-10-31 04:00:00", "id": "78c5b4e7-bfe0-4c12-bd75-adefac05e0eb", "source": "arxiv", "section": "computerScience"}, {"title": "DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data", "link": "https://arxiv.org/abs/2410.22938", "description": "arXiv:2410.22938v1 Announce Type: new \nAbstract: The application of reinforcement learning in traffic signal control (TSC) has been extensively researched and yielded notable achievements. However, most existing works for TSC assume that traffic data from all surrounding intersections is fully and continuously available through sensors. In real-world applications, this assumption often fails due to sensor malfunctions or data loss, making TSC with missing data a critical challenge. To meet the needs of practical applications, we introduce DiffLight, a novel conditional diffusion model for TSC under data-missing scenarios in the offline setting. Specifically, we integrate two essential sub-tasks, i.e., traffic data imputation and decision-making, by leveraging a Partial Rewards Conditioned Diffusion (PRCD) model to prevent missing rewards from interfering with the learning process. Meanwhile, to effectively capture the spatial-temporal dependencies among intersections, we design a Spatial-Temporal transFormer (STFormer) architecture. In addition, we propose a Diffusion Communication Mechanism (DCM) to promote better communication and control performance under data-missing scenarios. Extensive experiments on five datasets with various data-missing scenarios demonstrate that DiffLight is an effective controller to address TSC with missing data. The code of DiffLight is released at https://github.com/lokol5579/DiffLight-release.", "published": "2024-10-31 04:00:00", "id": "706bff1b-6bd8-4aa7-a642-8a0de6dfa74f", "source": "arxiv", "section": "computerScience"}, {"title": "AdaptiveISP: Learning an Adaptive Image Signal Processor for Object Detection", "link": "https://arxiv.org/abs/2410.22939", "description": "arXiv:2410.22939v1 Announce Type: new \nAbstract: Image Signal Processors (ISPs) convert raw sensor signals into digital images, which significantly influence the image quality and the performance of downstream computer vision tasks. Designing ISP pipeline and tuning ISP parameters are two key steps for building an imaging and vision system. To find optimal ISP configurations, recent works use deep neural networks as a proxy to search for ISP parameters or ISP pipelines. However, these methods are primarily designed to maximize the image quality, which are sub-optimal in the performance of high-level computer vision tasks such as detection, recognition, and tracking. Moreover, after training, the learned ISP pipelines are mostly fixed at the inference time, whose performance degrades in dynamic scenes. To jointly optimize ISP structures and parameters, we propose AdaptiveISP, a task-driven and scene-adaptive ISP. One key observation is that for the majority of input images, only a few processing modules are needed to improve the performance of downstream recognition tasks, and only a few inputs require more processing. Based on this, AdaptiveISP utilizes deep reinforcement learning to automatically generate an optimal ISP pipeline and the associated ISP parameters to maximize the detection performance. Experimental results show that AdaptiveISP not only surpasses the prior state-of-the-art methods for object detection but also dynamically manages the trade-off between detection performance and computational cost, especially suitable for scenes with large dynamic range variations. Project website: https://openimaginglab.github.io/AdaptiveISP/.", "published": "2024-10-31 04:00:00", "id": "ca408a08-9d2f-4c5a-b8ae-f0cea3e93334", "source": "arxiv", "section": "computerScience"}, {"title": "MMSE Channel Estimation in Fading MIMO Gaussian Channels With Blockage: A Novel Lower Bound via Poincar\\'e Inequality", "link": "https://arxiv.org/abs/2410.22941", "description": "arXiv:2410.22941v1 Announce Type: new \nAbstract: Integrated sensing and communication is regarded as a key enabler for next-generation wireless networks. To optimize the transmitted waveform for both sensing and communication, various performance metrics must be considered. This work focuses on sensing, and specifically on the mean square error (MSE) of channel estimation. Given the complexity of deriving the MSE, the Bayesian Cramer-Rao Bound (BCRB) is commonly recognized as a lower bound on the minimum MSE. However, the BCRB is not applicable to channels with discrete or mixed distributions. To address this limitation, a new lower bound based on a Poincar\\'e inequality is proposed and applied to fading MIMO AWGN channels with blockage probability, and the behavior of the lower bound at high SNR is precisely characterized.", "published": "2024-10-31 04:00:00", "id": "4f645cb3-d5a5-4e96-b4c5-4540427aff88", "source": "arxiv", "section": "computerScience"}, {"title": "Focus On This, Not That! Steering LLMs With Adaptive Feature Specification", "link": "https://arxiv.org/abs/2410.22944", "description": "arXiv:2410.22944v1 Announce Type: new \nAbstract: Despite the success of Instruction Tuning (IT) in training large language models (LLMs) to perform arbitrary user-specified tasks, these models often still leverage spurious or biased features learned from their training data, leading to undesired behaviours when deploying them in new contexts. In this work, we introduce Focus Instruction Tuning (FIT), which trains LLMs to condition their responses by focusing on specific features whilst ignoring others, leading to different behaviours based on what features are specified. Across several experimental settings, we show that focus-tuned models can be adaptively steered by focusing on different features at inference-time: for instance, robustness can be improved by focusing on task-causal features and ignoring spurious features, and social bias can be mitigated by ignoring demographic categories. Furthermore, FIT can steer behaviour in new contexts, generalising under distribution shift and to new unseen features at inference time, and thereby facilitating more robust, fair, and controllable LLM applications in real-world environments.", "published": "2024-10-31 04:00:00", "id": "233864b6-6af5-4a73-a32b-231c7937737e", "source": "arxiv", "section": "computerScience"}, {"title": "KALAM: toolKit for Automating high-Level synthesis of Analog computing systeMs", "link": "https://arxiv.org/abs/2410.22946", "description": "arXiv:2410.22946v1 Announce Type: new \nAbstract: Diverse computing paradigms have emerged to meet the growing needs for intelligent energy-efficient systems. The Margin Propagation (MP) framework, being one such initiative in the analog computing domain, stands out due to its scalability across biasing conditions, temperatures, and diminishing process technology nodes. However, the lack of digital-like automation tools for designing analog systems (including that of MP analog) hinders their adoption for designing large systems. The inherent scalability and modularity of MP systems present a unique opportunity in this regard. This paper introduces KALAM (toolKit for Automating high-Level synthesis of Analog computing systeMs), which leverages factor graphs as the foundational paradigm for synthesizing MP-based analog computing systems. Factor graphs are the basis of various signal processing tasks and, when coupled with MP, can be used to design scalable and energy-efficient analog signal processors. Using Python scripting language, the KALAM automation flow translates an input factor graph to its equivalent SPICE-compatible circuit netlist that can be used to validate the intended functionality. KALAM also allows the integration of design optimization strategies such as precision tuning, variable elimination, and mathematical simplification. We demonstrate KALAM's versatility for tasks such as Bayesian inference, Low-Density Parity Check (LDPC) decoding, and Artificial Neural Networks (ANN). Simulation results of the netlists align closely with software implementations, affirming the efficacy of our proposed automation tool.", "published": "2024-10-31 04:00:00", "id": "194646b0-59b3-4d47-b2cf-1bfc7bef3fef", "source": "arxiv", "section": "computerScience"}, {"title": "ELBOing Stein: Variational Bayes with Stein Mixture Inference", "link": "https://arxiv.org/abs/2410.22948", "description": "arXiv:2410.22948v1 Announce Type: new \nAbstract: Stein variational gradient descent (SVGD) [Liu and Wang, 2016] performs approximate Bayesian inference by representing the posterior with a set of particles. However, SVGD suffers from variance collapse, i.e. poor predictions due to underestimating uncertainty [Ba et al., 2021], even for moderately-dimensional models such as small Bayesian neural networks (BNNs). To address this issue, we generalize SVGD by letting each particle parameterize a component distribution in a mixture model. Our method, Stein Mixture Inference (SMI), optimizes a lower bound to the evidence (ELBO) and introduces user-specified guides parameterized by particles. SMI extends the Nonlinear SVGD framework [Wang and Liu, 2019] to the case of variational Bayes. SMI effectively avoids variance collapse, judging by a previously described test developed for this purpose, and performs well on standard data sets. In addition, SMI requires considerably fewer particles than SVGD to accurately estimate uncertainty for small BNNs. The synergistic combination of NSVGD, ELBO optimization and user-specified guides establishes a promising approach towards variational Bayesian inference in the case of tall and wide data.", "published": "2024-10-31 04:00:00", "id": "92ca8e89-7c92-4a2e-adcc-74725236cca1", "source": "arxiv", "section": "computerScience"}, {"title": "MutaPLM: Protein Language Modeling for Mutation Explanation and Engineering", "link": "https://arxiv.org/abs/2410.22949", "description": "arXiv:2410.22949v1 Announce Type: new \nAbstract: Studying protein mutations within amino acid sequences holds tremendous significance in life sciences. Protein language models (PLMs) have demonstrated strong capabilities in broad biological applications. However, due to architectural design and lack of supervision, PLMs model mutations implicitly with evolutionary plausibility, which is not satisfactory to serve as explainable and engineerable tools in real-world studies. To address these issues, we present MutaPLM, a unified framework for interpreting and navigating protein mutations with protein language models. MutaPLM introduces a protein delta network that captures explicit protein mutation representations within a unified feature space, and a transfer learning pipeline with a chain-of-thought (CoT) strategy to harvest protein mutation knowledge from biomedical texts. We also construct MutaDescribe, the first large-scale protein mutation dataset with rich textual annotations, which provides cross-modal supervision signals. Through comprehensive experiments, we demonstrate that MutaPLM excels at providing human-understandable explanations for mutational effects and prioritizing novel mutations with desirable properties. Our code, model, and data are open-sourced at https://github.com/PharMolix/MutaPLM.", "published": "2024-10-31 04:00:00", "id": "ca793c68-b392-46ce-a38a-9db81be8d9c4", "source": "arxiv", "section": "computerScience"}, {"title": "SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry", "link": "https://arxiv.org/abs/2410.22950", "description": "arXiv:2410.22950v1 Announce Type: new \nAbstract: Respiratory illnesses are a significant global health burden. Respiratory illnesses, primarily Chronic obstructive pulmonary disease (COPD), is the seventh leading cause of poor health worldwide and the third leading cause of death worldwide, causing 3.23 million deaths in 2019, necessitating early identification and diagnosis for effective mitigation. Among the diagnostic tools employed, spirometry plays a crucial role in detecting respiratory abnormalities. However, conventional clinical spirometry methods often entail considerable costs and practical limitations like the need for specialized equipment, trained personnel, and a dedicated clinical setting, making them less accessible. To address these challenges, wearable spirometry technologies have emerged as promising alternatives, offering accurate, cost-effective, and convenient solutions. The development of machine learning models for wearable spirometry heavily relies on the availability of high-quality ground truth spirometry data, which is a laborious and expensive endeavor. In this research, we propose using active learning, a sub-field of machine learning, to mitigate the challenges associated with data collection and labeling. By strategically selecting samples from the ground truth spirometer, we can mitigate the need for resource-intensive data collection. We present evidence that models trained on small subsets obtained through active learning achieve comparable/better results than models trained on the complete dataset.", "published": "2024-10-31 04:00:00", "id": "af309f8e-5764-41ac-bbf8-91ec608e9b30", "source": "arxiv", "section": "computerScience"}, {"title": "Sampling and counting triangle-free graphs near the critical density", "link": "https://arxiv.org/abs/2410.22951", "description": "arXiv:2410.22951v1 Announce Type: new \nAbstract: We study the following combinatorial counting and sampling problems: can we efficiently sample from the Erd\\H{o}s-R\\'{e}nyi random graph $G(n,p)$ conditioned on triangle-freeness? Can we efficiently approximate the probability that $G(n,p)$ is triangle-free? These are prototypical instances of forbidden substructure problems ubiquitous in combinatorics. The algorithmic questions are instances of approximate counting and sampling for a hypergraph hard-core model.\n  Estimating the probability that $G(n,p)$ has no triangles is a fundamental question in probabilistic combinatorics and one that has led to the development of many important tools in the field. Through the work of several authors, the asymptotics of the logarithm of this probability are known if $p =o( n^{-1/2})$ or if $p =\\omega( n^{-1/2})$. The regime $p = \\Theta(n^{-1/2})$ is more mysterious, as this range witnesses a dramatic change in the the typical structural properties of $G(n,p)$ conditioned on triangle-freeness. As we show, this change in structure has a profound impact on the performance of sampling algorithms.\n  We give two different efficient sampling algorithms for triangle-free graphs (and complementary algorithms to approximate the triangle-freeness large deviation probability), one that is efficient when $p < c/\\sqrt{n}$ and one that is efficient when $p > C/\\sqrt{n}$ for constants $c, C>0$. The latter algorithm involves a new approach for dealing with large defects in the setting of sampling from low-temperature spin models.", "published": "2024-10-31 04:00:00", "id": "ef1f1044-5932-4d67-80ca-8dcfb25003e9", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient Adaptation of Pre-trained Vision Transformer via Householder Transformation", "link": "https://arxiv.org/abs/2410.22952", "description": "arXiv:2410.22952v1 Announce Type: new \nAbstract: A common strategy for Parameter-Efficient Fine-Tuning (PEFT) of pre-trained Vision Transformers (ViTs) involves adapting the model to downstream tasks by learning a low-rank adaptation matrix. This matrix is decomposed into a product of down-projection and up-projection matrices, with the bottleneck dimensionality being crucial for reducing the number of learnable parameters, as exemplified by prevalent methods like LoRA and Adapter. However, these low-rank strategies typically employ a fixed bottleneck dimensionality, which limits their flexibility in handling layer-wise variations. To address this limitation, we propose a novel PEFT approach inspired by Singular Value Decomposition (SVD) for representing the adaptation matrix. SVD decomposes a matrix into the product of a left unitary matrix, a diagonal matrix of scaling values, and a right unitary matrix. We utilize Householder transformations to construct orthogonal matrices that efficiently mimic the unitary matrices, requiring only a vector. The diagonal values are learned in a layer-wise manner, allowing them to flexibly capture the unique properties of each layer. This approach enables the generation of adaptation matrices with varying ranks across different layers, providing greater flexibility in adapting pre-trained models. Experiments on standard downstream vision tasks demonstrate that our method achieves promising fine-tuning performance.", "published": "2024-10-31 04:00:00", "id": "85c5dcb6-5de4-47cf-abdf-f960cb1101c1", "source": "arxiv", "section": "computerScience"}, {"title": "Retrieval-Augmented Generation with Estimation of Source Reliability", "link": "https://arxiv.org/abs/2410.22954", "description": "arXiv:2410.22954v1 Announce Type: new \nAbstract: Retrieval-augmented generation (RAG) addresses key limitations of large language models (LLMs), such as hallucinations and outdated knowledge, by incorporating external databases. These databases typically consult multiple sources to encompass up-to-date and various information. However, standard RAG methods often overlook the heterogeneous source reliability in the multi-source database and retrieve documents solely based on relevance, making them prone to propagating misinformation. To address this, we propose Reliability-Aware RAG (RA-RAG) which estimates the reliability of multiple sources and incorporates this information into both retrieval and aggregation processes. Specifically, it iteratively estimates source reliability and true answers for a set of queries with no labelling. Then, it selectively retrieves relevant documents from a few of reliable sources and aggregates them using weighted majority voting, where the selective retrieval ensures scalability while not compromising the performance. We also introduce a benchmark designed to reflect real-world scenarios with heterogeneous source reliability and demonstrate the effectiveness of RA-RAG compared to a set of baselines.", "published": "2024-10-31 04:00:00", "id": "42fdf8aa-2bb4-4cab-9610-fde3a1bca302", "source": "arxiv", "section": "computerScience"}, {"title": "ISAC Prototype System for Multi-Domain Cooperative Communication Networks", "link": "https://arxiv.org/abs/2410.22956", "description": "arXiv:2410.22956v1 Announce Type: new \nAbstract: Future wireless networks are poised to transform into integrated sensing and communication (ISAC) networks, unlocking groundbreaking services such as digital twinning. To harness the full potential of ISAC networks, it is essential to experimentally validate their sensing capabilities and the role of sensing in boosting communication. However, current prototype systems fall short in supporting multiple sensing functions or validating sensing-assisted communication. In response, we have developed an advanced ISAC prototype system that incorporates monostatic, bistatic, and network sensing modes. This system supports multimodal data collection and synchronization, ensuring comprehensive experimental validation. On the communication front, it excels in sensing-aided beam tracking and real-time high-definition video transmission. For sensing applications, it provides precise angle and range measurements, real-time angle-range imaging, and radio-based simultaneous localization and mapping (SLAM). Our prototype aligns with the 5G New Radio standard, offering scalability for up to 16 user equipments (UEs) in uplink transmission and 10 UEs in downlink transmission. Real-world tests showcase the system's superior accuracy, with root mean square errors of 2.3 degrees for angle estimation and 0.3 meters (m) for range estimation. Additionally, the estimation errors for multimodal-aided real-time radio SLAM localization and mapping are 0.25 m and 0.8 m, respectively.", "published": "2024-10-31 04:00:00", "id": "cc862a65-ec78-40cf-a591-d3f71db7b095", "source": "arxiv", "section": "computerScience"}, {"title": "EnsIR: An Ensemble Algorithm for Image Restoration via Gaussian Mixture Models", "link": "https://arxiv.org/abs/2410.22959", "description": "arXiv:2410.22959v1 Announce Type: new \nAbstract: Image restoration has experienced significant advancements due to the development of deep learning. Nevertheless, it encounters challenges related to ill-posed problems, resulting in deviations between single model predictions and ground-truths. Ensemble learning, as a powerful machine learning technique, aims to address these deviations by combining the predictions of multiple base models. Most existing works adopt ensemble learning during the design of restoration models, while only limited research focuses on the inference-stage ensemble of pre-trained restoration models. Regression-based methods fail to enable efficient inference, leading researchers in academia and industry to prefer averaging as their choice for post-training ensemble. To address this, we reformulate the ensemble problem of image restoration into Gaussian mixture models (GMMs) and employ an expectation maximization (EM)-based algorithm to estimate ensemble weights for aggregating prediction candidates. We estimate the range-wise ensemble weights on a reference set and store them in a lookup table (LUT) for efficient ensemble inference on the test set. Our algorithm is model-agnostic and training-free, allowing seamless integration and enhancement of various pre-trained image restoration models. It consistently outperforms regression based methods and averaging ensemble approaches on 14 benchmarks across 3 image restoration tasks, including super-resolution, deblurring and deraining. The codes and all estimated weights have been released in Github.", "published": "2024-10-31 04:00:00", "id": "e33a0077-95d1-4922-a7ca-377e31fe9e38", "source": "arxiv", "section": "computerScience"}, {"title": "A Study of Secure Algorithms for Vertical Federated Learning: Take Secure Logistic Regression as an Example", "link": "https://arxiv.org/abs/2410.22960", "description": "arXiv:2410.22960v1 Announce Type: new \nAbstract: After entering the era of big data, more and more companies build services with machine learning techniques. However, it is costly for companies to collect data and extract helpful handcraft features on their own. Although it is a way to combine with other companies' data for boosting the model's performance, this approach may be prohibited by laws. In other words, finding the balance between sharing data with others and keeping data from privacy leakage is a crucial topic worthy of close attention. This paper focuses on distributed data and conducts secure model training tasks on a vertical federated learning scheme. Here, secure implies that the whole process is executed in the encrypted domain. Therefore, the privacy concern is released.", "published": "2024-10-31 04:00:00", "id": "c15565e1-ed3a-439a-ab1f-ec44adf6346f", "source": "arxiv", "section": "computerScience"}, {"title": "Even the \"Devil\" has Rights!", "link": "https://arxiv.org/abs/2410.22963", "description": "arXiv:2410.22963v1 Announce Type: new \nAbstract: There have been works discussing the adoption of a human rights framework for responsible AI, emphasizing various rights such as the right to contribute to scientific advancements. Yet, to the best of our knowledge, this is the first attempt to take this framework with special focus on computer vision and documenting human rights violations in its community. This work summarizes such incidents accompanied with evidence from the lens of a female African Muslim Hijabi researcher. While previous works resorted to qualitative surveys that gather opinions from various researchers in the field, this work argues that a single documented violation is sufficient to warrant attention regardless of the stature of this researcher. Incidents documented in this work include silence on Genocides that are occurring while promoting the governments contributing to it, a broken reviewing system and corruption in the faculty support systems. This work discusses that demonizing individuals for discrimination based on gender, ethnicity, creed or reprisal has been a successful tool for exclusion with documented evidence from a single case. We argue that human rights are guaranteed for every single individual even the ones that might be labelled as devils in the community for whichever reasons to dismantle such a tool from its roots.", "published": "2024-10-31 04:00:00", "id": "e3634d58-5af9-417d-8aa4-6758564d7152", "source": "arxiv", "section": "computerScience"}, {"title": "Scalable Sampling for High Utility Patterns", "link": "https://arxiv.org/abs/2410.22964", "description": "arXiv:2410.22964v1 Announce Type: new \nAbstract: Discovering valuable insights from data through meaningful associations is a crucial task. However, it becomes challenging when trying to identify representative patterns in quantitative databases, especially with large datasets, as enumeration-based strategies struggle due to the vast search space involved. To tackle this challenge, output space sampling methods have emerged as a promising solution thanks to its ability to discover valuable patterns with reduced computational overhead. However, existing sampling methods often encounter limitations when dealing with large quantitative database, resulting in scalability-related challenges. In this work, we propose a novel high utility pattern sampling algorithm and its on-disk version both designed for large quantitative databases based on two original theorems. Our approach ensures both the interactivity required for user-centered methods and strong statistical guarantees through random sampling. Thanks to our method, users can instantly discover relevant and representative utility pattern, facilitating efficient exploration of the database within seconds. To demonstrate the interest of our approach, we present a compelling use case involving archaeological knowledge graph sub-profiles discovery. Experiments on semantic and none-semantic quantitative databases show that our approach outperforms the state-of-the art methods.", "published": "2024-10-31 04:00:00", "id": "34d9074a-b645-46aa-a09c-843355b2376f", "source": "arxiv", "section": "computerScience"}, {"title": "Dynamic Threshold-based Two-layer Online Unsupervised Anomaly Detector", "link": "https://arxiv.org/abs/2410.22967", "description": "arXiv:2410.22967v1 Announce Type: new \nAbstract: The proliferation of the Internet of Things (IoT) has heightened the vulnerability to cyber threats, making it imperative to develop Anomaly Detection Systems (ADSs) capable of adapting to emerging or novel attacks. Prior research has predominantly concentrated on offline unsupervised learning techniques to protect ADSs, which are impractical for real-world applications. Furthermore, these studies often rely heavily on the assumption of known legitimate behaviors and fall short of meeting the interpretability requirements in security contexts, thereby hindering their practical adoption. In response, this paper introduces Adaptive NAD, a comprehensive framework aimed at enhancing and interpreting online unsupervised anomaly detection within security domains. We propose an interpretable two-layer anomaly detection approach that generates dependable, high-confidence pseudo-labels. Subsequently, we incorporate an online learning mechanism that updates Adaptive NAD using an innovative threshold adjustment method to accommodate new threats. Experimental findings reveal that Adaptive NAD surpasses state-of-the-art solutions by achieving improvements of over 5.4% and 23.0% in SPAUC on the CIC-Darknet2020 and CIC-DoHBrw-2020 datasets, respectively. The code for Adaptive NAD is publicly available at https://github.com/MyLearnCodeSpace/Adaptive-NAD.", "published": "2024-10-31 04:00:00", "id": "30ae205f-bf9b-43a2-afa7-a2d0317b2a28", "source": "arxiv", "section": "computerScience"}, {"title": "Private Synthetic Text Generation with Diffusion Models", "link": "https://arxiv.org/abs/2410.22971", "description": "arXiv:2410.22971v1 Announce Type: new \nAbstract: How capable are diffusion models of generating synthetics texts? Recent research shows their strengths, with performance reaching that of auto-regressive LLMs. But are they also good in generating synthetic data if the training was under differential privacy? Here the evidence is missing, yet the promises from private image generation look strong. In this paper we address this open question by extensive experiments. At the same time, we critically assess (and reimplement) previous works on synthetic private text generation with LLMs and reveal some unmet assumptions that might have led to violating the differential privacy guarantees. Our results partly contradict previous non-private findings and show that fully open-source LLMs outperform diffusion models in the privacy regime. Our complete source codes, datasets, and experimental setup is publicly available to foster future research.", "published": "2024-10-31 04:00:00", "id": "3bafefc8-635d-4f71-a644-9586e5ce03d2", "source": "arxiv", "section": "computerScience"}, {"title": "DataRec: A Framework for Standardizing Recommendation Data Processing and Analysis", "link": "https://arxiv.org/abs/2410.22972", "description": "arXiv:2410.22972v1 Announce Type: new \nAbstract: Thanks to the great interest posed by researchers and companies, recommendation systems became a cornerstone of machine learning applications. However, concerns have arisen recently about the need for reproducibility, making it challenging to identify suitable pipelines. Several frameworks have been proposed to improve reproducibility, covering the entire process from data reading to performance evaluation. Despite this effort, these solutions often overlook the role of data management, do not promote interoperability, and neglect data analysis despite its well-known impact on recommender performance. To address these gaps, we propose DataRec, which facilitates using and manipulating recommendation datasets. DataRec supports reading and writing in various formats, offers filtering and splitting techniques, and enables data distribution analysis using well-known metrics. It encourages a unified approach to data manipulation by allowing data export in formats compatible with several recommendation frameworks.", "published": "2024-10-31 04:00:00", "id": "7c151289-ff4b-4d22-a5dc-ef6ca6518c7d", "source": "arxiv", "section": "computerScience"}, {"title": "Bonafide at LegalLens 2024 Shared Task: Using Lightweight DeBERTa Based Encoder For Legal Violation Detection and Resolution", "link": "https://arxiv.org/abs/2410.22977", "description": "arXiv:2410.22977v1 Announce Type: new \nAbstract: In this work, we present two systems -- Named Entity Resolution (NER) and Natural Language Inference (NLI) -- for detecting legal violations within unstructured textual data and for associating these violations with potentially affected individuals, respectively. Both these systems are lightweight DeBERTa based encoders that outperform the LLM baselines. The proposed NER system achieved an F1 score of 60.01\\% on Subtask A of the LegalLens challenge, which focuses on identifying violations. The proposed NLI system achieved an F1 score of 84.73\\% on Subtask B of the LegalLens challenge, which focuses on resolving these violations by matching them with pre-existing legal complaints of class action cases. Our NER system ranked sixth and NLI system ranked fifth on the LegalLens leaderboard. We release the trained models and inference scripts.", "published": "2024-10-31 04:00:00", "id": "67c76368-39b2-4840-b175-62713140a160", "source": "arxiv", "section": "computerScience"}, {"title": "LumiSculpt: A Consistency Lighting Control Network for Video Generation", "link": "https://arxiv.org/abs/2410.22979", "description": "arXiv:2410.22979v1 Announce Type: new \nAbstract: Lighting plays a pivotal role in ensuring the naturalness of video generation, significantly influencing the aesthetic quality of the generated content. However, due to the deep coupling between lighting and the temporal features of videos, it remains challenging to disentangle and model independent and coherent lighting attributes, limiting the ability to control lighting in video generation. In this paper, inspired by the established controllable T2I models, we propose LumiSculpt, which, for the first time, enables precise and consistent lighting control in T2V generation models.LumiSculpt equips the video generation with strong interactive capabilities, allowing the input of custom lighting reference image sequences. Furthermore, the core learnable plug-and-play module of LumiSculpt facilitates remarkable control over lighting intensity, position, and trajectory in latent video diffusion models based on the advanced DiT backbone.Additionally, to effectively train LumiSculpt and address the issue of insufficient lighting data, we construct LumiHuman, a new lightweight and flexible dataset for portrait lighting of images and videos. Experimental results demonstrate that LumiSculpt achieves precise and high-quality lighting control in video generation.", "published": "2024-10-31 04:00:00", "id": "8d7b4c87-813c-439f-b2c8-6c31b76d116b", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient End-to-End 6-Dof Grasp Detection Framework for Edge Devices with Hierarchical Heatmaps and Feature Propagation", "link": "https://arxiv.org/abs/2410.22980", "description": "arXiv:2410.22980v1 Announce Type: new \nAbstract: 6-DoF grasp detection is critically important for the advancement of intelligent embodied systems, as it provides feasible robot poses for object grasping. Various methods have been proposed to detect 6-DoF grasps through the extraction of 3D geometric features from RGBD or point cloud data. However, most of these approaches encounter challenges during real robot deployment due to their significant computational demands, which can be particularly problematic for mobile robot platforms, especially those reliant on edge computing devices. This paper presents an Efficient End-to-End Grasp Detection Network (E3GNet) for 6-DoF grasp detection utilizing hierarchical heatmap representations. E3GNet effectively identifies high-quality and diverse grasps in cluttered real-world environments. Benefiting from our end-to-end methodology and efficient network design, our approach surpasses previous methods in model inference efficiency and achieves real-time 6-Dof grasp detection on edge devices. Furthermore, real-world experiments validate the effectiveness of our method, achieving a satisfactory 94% object grasping success rate.", "published": "2024-10-31 04:00:00", "id": "7f70344b-9f0c-4e01-a1bb-ee79f71575e0", "source": "arxiv", "section": "computerScience"}, {"title": "DisenTS: Disentangled Channel Evolving Pattern Modeling for Multivariate Time Series Forecasting", "link": "https://arxiv.org/abs/2410.22981", "description": "arXiv:2410.22981v1 Announce Type: new \nAbstract: Multivariate time series forecasting plays a crucial role in various real-world applications. Significant efforts have been made to integrate advanced network architectures and training strategies that enhance the capture of temporal dependencies, thereby improving forecasting accuracy. On the other hand, mainstream approaches typically utilize a single unified model with simplistic channel-mixing embedding or cross-channel attention operations to account for the critical intricate inter-channel dependencies. Moreover, some methods even trade capacity for robust prediction based on the channel-independent assumption. Nonetheless, as time series data may display distinct evolving patterns due to the unique characteristics of each channel (including multiple strong seasonalities and trend changes), the unified modeling methods could yield suboptimal results. To this end, we propose DisenTS, a tailored framework for modeling disentangled channel evolving patterns in general multivariate time series forecasting. The central idea of DisenTS is to model the potential diverse patterns within the multivariate time series data in a decoupled manner. Technically, the framework employs multiple distinct forecasting models, each tasked with uncovering a unique evolving pattern. To guide the learning process without supervision of pattern partition, we introduce a novel Forecaster Aware Gate (FAG) module that generates the routing signals adaptively according to both the forecasters' states and input series' characteristics. The forecasters' states are derived from the Linear Weight Approximation (LWA) strategy, which quantizes the complex deep neural networks into compact matrices. Additionally, the Similarity Constraint (SC) is further proposed to guide each model to specialize in an underlying pattern by minimizing the mutual information between the representations.", "published": "2024-10-31 04:00:00", "id": "bdf8f9af-d1f8-4104-b974-cf08b2b129a2", "source": "arxiv", "section": "computerScience"}, {"title": "PDSR: Efficient UAV Deployment for Swift and Accurate Post-Disaster Search and Rescue", "link": "https://arxiv.org/abs/2410.22982", "description": "arXiv:2410.22982v1 Announce Type: new \nAbstract: This paper introduces a comprehensive framework for Post-Disaster Search and Rescue (PDSR), aiming to optimize search and rescue operations leveraging Unmanned Aerial Vehicles (UAVs). The primary goal is to improve the precision and availability of sensing capabilities, particularly in various catastrophic scenarios. Central to this concept is the rapid deployment of UAV swarms equipped with diverse sensing, communication, and intelligence capabilities, functioning as an integrated system that incorporates multiple technologies and approaches for efficient detection of individuals buried beneath rubble or debris following a disaster. Within this framework, we propose architectural solution and address associated challenges to ensure optimal performance in real-world disaster scenarios. The proposed framework aims to achieve complete coverage of damaged areas significantly faster than traditional methods using a multi-tier swarm architecture. Furthermore, integrating multi-modal sensing data with machine learning for data fusion could enhance detection accuracy, ensuring precise identification of survivors.", "published": "2024-10-31 04:00:00", "id": "7e9711a0-17fb-4515-a8b6-47b5cac4da9c", "source": "arxiv", "section": "computerScience"}, {"title": "Dual-Optimized Adaptive Graph Reconstruction for Multi-View Graph Clustering", "link": "https://arxiv.org/abs/2410.22983", "description": "arXiv:2410.22983v1 Announce Type: new \nAbstract: Multi-view clustering is an important machine learning task for multi-media data, encompassing various domains such as images, videos, and texts. Moreover, with the growing abundance of graph data, the significance of multi-view graph clustering (MVGC) has become evident. Most existing methods focus on graph neural networks (GNNs) to extract information from both graph structure and feature data to learn distinguishable node representations. However, traditional GNNs are designed with the assumption of homophilous graphs, making them unsuitable for widely prevalent heterophilous graphs. Several techniques have been introduced to enhance GNNs for heterophilous graphs. While these methods partially mitigate the heterophilous graph issue, they often neglect the advantages of traditional GNNs, such as their simplicity, interpretability, and efficiency. In this paper, we propose a novel multi-view graph clustering method based on dual-optimized adaptive graph reconstruction, named DOAGC. It mainly aims to reconstruct the graph structure adapted to traditional GNNs to deal with heterophilous graph issues while maintaining the advantages of traditional GNNs. Specifically, we first develop an adaptive graph reconstruction mechanism that accounts for node correlation and original structural information. To further optimize the reconstruction graph, we design a dual optimization strategy and demonstrate the feasibility of our optimization strategy through mutual information theory. Numerous experiments demonstrate that DOAGC effectively mitigates the heterophilous graph problem.", "published": "2024-10-31 04:00:00", "id": "46f8389a-56e2-4f4d-b92e-43e2109fd492", "source": "arxiv", "section": "computerScience"}, {"title": "Higher-order Cross-structural Embedding Model for Time Series Analysis", "link": "https://arxiv.org/abs/2410.22984", "description": "arXiv:2410.22984v1 Announce Type: new \nAbstract: Time series analysis has gained significant attention due to its critical applications in diverse fields such as healthcare, finance, and sensor networks. The complexity and non-stationarity of time series make it challenging to capture the interaction patterns across different timestamps. Current approaches struggle to model higher-order interactions within time series, and focus on learning temporal or spatial dependencies separately, which limits performance in downstream tasks. To address these gaps, we propose Higher-order Cross-structural Embedding Model for Time Series (High-TS), a novel framework that jointly models both temporal and spatial perspectives by combining multiscale Transformer with Topological Deep Learning (TDL). Meanwhile, High-TS utilizes contrastive learning to integrate these two structures for generating robust and discriminative representations. Extensive experiments show that High-TS outperforms state-of-the-art methods in various time series tasks and demonstrate the importance of higher-order cross-structural information in improving model performance.", "published": "2024-10-31 04:00:00", "id": "7b48a1ee-19b5-4711-8d84-529f28a0d894", "source": "arxiv", "section": "computerScience"}, {"title": "Troubling Taxonomies in GenAI Evaluation", "link": "https://arxiv.org/abs/2410.22985", "description": "arXiv:2410.22985v1 Announce Type: new \nAbstract: To evaluate the societal impacts of GenAI requires a model of how social harms emerge from interactions between GenAI, people, and societal structures. Yet a model is rarely explicitly defined in societal impact evaluations, or in the taxonomies of societal impacts that support them. In this provocation, we argue that societal impacts should be conceptualised as application- and context-specific, incommensurable, and shaped by questions of social power. Doing so leads us to conclude that societal impact evaluations using existing taxonomies are inherently limited, in terms of their potential to reveal how GenAI systems may interact with people when introduced into specific social contexts. We therefore propose a governance-first approach to managing societal harms attended by GenAI technologies.", "published": "2024-10-31 04:00:00", "id": "e3af6c57-8e1f-4720-9e91-b9a9e6b6dc4f", "source": "arxiv", "section": "computerScience"}, {"title": "V2X-Assisted Distributed Computing and Control Framework for Connected and Automated Vehicles under Ramp Merging Scenario", "link": "https://arxiv.org/abs/2410.22987", "description": "arXiv:2410.22987v1 Announce Type: new \nAbstract: This paper investigates distributed computing and cooperative control of connected and automated vehicles (CAVs) in ramp merging scenario under transportation cyber-physical system. Firstly, a centralized cooperative trajectory planning problem is formulated subject to the safely constraints and traffic performance in ramp merging scenario, where the trajectories of all vehicles are jointly optimized. To get rid of the reliance on a central controller and reduce computation time, a distributed solution to this problem implemented among CAVs through Vehicles-to-Everything (V2X) communication is proposed. Unlike existing method, our method can distribute the computational task among CAVs and carry out parallel solving through V2X communication. Then, a multi-vehicles model predictive control (MPC) problem aimed at maximizing system stability and minimizing control input is formulated based on the solution of the first problem subject to strict safety constants and input limits. Due to these complex constraints, this problem becomes high-dimensional, centralized, and non-convex. To solve it in a short time, a decomposition and convex reformulation method, namely distributed cooperative iterative model predictive control (DCIMPC), is proposed. This method leverages the communication capability of CAVs to decompose the problem, making full use of the computational resources on vehicles to achieve fast solutions and distributed control. The two above problems with their corresponding solving methods form the systemic framework of the V2X assisted distributed computing and control. Simulations have been conducted to evaluate the framework's convergence, safety, and solving speed. Additionally, extra experiments are conducted to validate the performance of DCIMPC. The results show that our method can greatly improve computation speed without sacrificing system performance.", "published": "2024-10-31 04:00:00", "id": "608f0ff4-a554-4754-8945-eae4be07142b", "source": "arxiv", "section": "computerScience"}, {"title": "Adaptive finite elements for obstacle problems", "link": "https://arxiv.org/abs/2410.22991", "description": "arXiv:2410.22991v1 Announce Type: new \nAbstract: We summarise three applications of the obstacle problem to membrane contact, elastoplastic torsion and cavitation modelling, and show how the resulting models can be solved using mixed finite elements. It is challenging to construct fixed computational meshes for any inequality-constrained problem because the coincidence set has an unknown shape. Consequently, we demonstrate how $h$-adaptivity can be used to resolve the unknown coincidence set. We demonstrate some practical challenges that must be overcome in the application of the adaptive method.", "published": "2024-10-31 04:00:00", "id": "85e19070-51c2-45d0-b2b4-e0dfdf3b17ce", "source": "arxiv", "section": "computerScience"}, {"title": "Dynamic Matching with Post-allocation Service and its Application to Refugee Resettlement", "link": "https://arxiv.org/abs/2410.22992", "description": "arXiv:2410.22992v1 Announce Type: new \nAbstract: Motivated by our collaboration with a major refugee resettlement agency in the U.S., we study a dynamic matching problem where each new arrival (a refugee case) must be matched immediately and irrevocably to one of the static resources (a location with a fixed annual quota). In addition to consuming the static resource, each case requires post-allocation service from a server, such as a translator. Given the time-consuming nature of service, a server may not be available at a given time, thus we refer to it as a dynamic resource. Upon matching, the case will wait to avail service in a first-come-first-serve manner. Bursty matching to a location may result in undesirable congestion at its corresponding server. Consequently, the central planner (the agency) faces a dynamic matching problem with an objective that combines the matching reward (captured by pair-specific employment outcomes) with the cost for congestion for dynamic resources and over-allocation for the static ones. Motivated by the observed fluctuations in the composition of refugee pools across the years, we design algorithms that do not rely on distributional knowledge constructed based on past years' data. To that end, we develop learning-based algorithms that are asymptotically optimal in certain regimes, easy to interpret, and computationally fast. Our design is based on learning the dual variables of the underlying optimization problem; however, the main challenge lies in the time-varying nature of the dual variables associated with dynamic resources. To overcome this challenge, our theoretical development brings together techniques from Lyapunov analysis, adversarial online learning, and stochastic optimization. On the application side, when tested on real data from our partner agency, our method outperforms existing ones making it a viable candidate for replacing the current practice upon experimentation.", "published": "2024-10-31 04:00:00", "id": "7ab5cc3e-e99d-45ff-9407-12de6d3dea91", "source": "arxiv", "section": "computerScience"}, {"title": "VisAidMath: Benchmarking Visual-Aided Mathematical Reasoning", "link": "https://arxiv.org/abs/2410.22995", "description": "arXiv:2410.22995v1 Announce Type: new \nAbstract: Although previous research on large language models (LLMs) and large multi-modal models (LMMs) has systematically explored mathematical problem-solving (MPS) within visual contexts, the analysis of how these models process visual information during problem-solving remains insufficient. To address this gap, we present VisAidMath, a benchmark for evaluating the MPS process related to visual information. We follow a rigorous data curation pipeline involving both automated processes and manual annotations to ensure data quality and reliability. Consequently, this benchmark includes 1,200 challenging problems from various mathematical branches, vision-aid formulations, and difficulty levels, collected from diverse sources such as textbooks, examination papers, and Olympiad problems. Based on the proposed benchmark, we conduct comprehensive evaluations on ten mainstream LLMs and LMMs, highlighting deficiencies in the visual-aided reasoning process. For example, GPT-4V only achieves 45.33% accuracy in the visual-aided reasoning task, even with a drop of 2 points when provided with golden visual aids. In-depth analysis reveals that the main cause of deficiencies lies in hallucination regarding the implicit visual reasoning process, shedding light on future research directions in the visual-aided MPS process.", "published": "2024-10-31 04:00:00", "id": "cea9d8f4-4bae-4cc3-a57d-fd3d53b42508", "source": "arxiv", "section": "computerScience"}, {"title": "Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach", "link": "https://arxiv.org/abs/2410.22996", "description": "arXiv:2410.22996v1 Announce Type: new \nAbstract: A well structured collection of the various Quantum Cascade Laser (QCL) design and working properties data provides a platform to analyze and understand the relationships between these properties. By analyzing these relationships, we can gain insights into how different design features impact laser performance properties such as the working temperature. Most of these QCL properties are captured in scientific text. There is therefore need for efficient methodologies that can be utilized to extract QCL properties from text and generate a semantically enriched and interlinked platform where the properties can be analyzed to uncover hidden relations. There is also the need to maintain provenance and reference information on which these properties are based. Semantic Web technologies such as Ontologies and Knowledge Graphs have proven capability in providing interlinked data platforms for knowledge representation in various domains. In this paper, we propose an approach for generating a QCL properties Knowledge Graph (KG) from text for semantic enrichment of the properties. The approach is based on the QCL ontology and a Retrieval Augmented Generation (RAG) enabled information extraction pipeline based on GPT 4-Turbo language model. The properties of interest include: working temperature, laser design type, lasing frequency, laser optical power and the heterostructure. The experimental results demonstrate the feasibility and effectiveness of this approach for efficiently extracting QCL properties from unstructured text and generating a QCL properties Knowledge Graph, which has potential applications in semantic enrichment and analysis of QCL data.", "published": "2024-10-31 04:00:00", "id": "9335bbc1-2202-427c-aa24-af0d4826f327", "source": "arxiv", "section": "computerScience"}, {"title": "A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics", "link": "https://arxiv.org/abs/2410.22997", "description": "arXiv:2410.22997v1 Announce Type: new \nAbstract: Recent advances in LLM have been instrumental in autonomous robot control and human-robot interaction by leveraging their vast general knowledge and capabilities to understand and reason across a wide range of tasks and scenarios. Previous works have investigated various prompt engineering techniques for improving the performance of \\glspl{LLM} to accomplish tasks, while others have proposed methods that utilize LLMs to plan and execute tasks based on the available functionalities of a given robot platform. In this work, we consider both lines of research by comparing prompt engineering techniques and combinations thereof within the application of high-level task planning and execution in service robotics. We define a diverse set of tasks and a simple set of functionalities in simulation, and measure task completion accuracy and execution time for several state-of-the-art models.", "published": "2024-10-31 04:00:00", "id": "8c97808c-1c3f-4897-be5f-da55e3dea1e3", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Constraint-aware Learning for Resource Allocation in NFV-enabled Networks", "link": "https://arxiv.org/abs/2410.22999", "description": "arXiv:2410.22999v1 Announce Type: new \nAbstract: Virtual Network Embedding (VNE) is a challenging combinatorial optimization problem that refers to resource allocation associated with hard and multifaceted constraints in network function virtualization (NFV). Existing works for VNE struggle to handle such complex constraints, leading to compromised system performance and stability. In this paper, we propose a \\textbf{CON}straint-\\textbf{A}ware \\textbf{L}earning framework for VNE, named \\textbf{CONAL}, to achieve efficient constraint management. Concretely, we formulate the VNE problem as a constrained Markov decision process with violation tolerance. This modeling approach aims to improve both resource utilization and solution feasibility by precisely evaluating solution quality and the degree of constraint violation. We also propose a reachability-guided optimization with an adaptive reachability budget method that dynamically assigns budget values. This method achieves persistent zero violation to guarantee the feasibility of VNE solutions and more stable policy optimization by handling instances without any feasible solution. Furthermore, we propose a constraint-aware graph representation method to efficiently learn cross-graph relations and constrained path connectivity in VNE. Finally, extensive experimental results demonstrate the superiority of our proposed method over state-of-the-art baselines. Our code is available at https://github.com/GeminiLight/conal-vne.", "published": "2024-10-31 04:00:00", "id": "b256695f-dcaa-4f10-ae5f-73149065d268", "source": "arxiv", "section": "computerScience"}, {"title": "\\textsc{Long$^2$RAG}: Evaluating Long-Context \\& Long-Form Retrieval-Augmented Generation with Key Point Recall", "link": "https://arxiv.org/abs/2410.23000", "description": "arXiv:2410.23000v1 Announce Type: new \nAbstract: Retrieval-augmented generation (RAG) is a promising approach to address the limitations of fixed knowledge in large language models (LLMs). However, current benchmarks for evaluating RAG systems suffer from two key deficiencies: (1) they fail to adequately measure LLMs' capability in handling \\emph{long-context retrieval} due to a lack of datasets that reflect the characteristics of retrieved documents, and (2) they lack a comprehensive evaluation method for assessing LLMs' ability to generate \\emph{long-form responses} that effectively exploits retrieved information. To address these shortcomings, we introduce the \\textsc{Long$^2$RAG} benchmark and the Key Point Recall (\\textit{KPR}) metric. \\textsc{Long$^2$RAG} comprises 280 questions spanning 10 domains and across 8 question categories, each associated with 5 retrieved documents with an average length of 2,444 words. \\textit{KPR} evaluates the extent to which LLMs incorporate key points extracted from the retrieved documents into their generated responses, providing a more nuanced assessment of their ability to exploit retrieved information. Our dataset and scripts are available at https://github.com/QZH-777/longrag.", "published": "2024-10-31 04:00:00", "id": "846011d2-2492-4ae4-8da8-54f3652fe5f0", "source": "arxiv", "section": "computerScience"}, {"title": "Scoring Rules and Calibration for Imprecise Probabilities", "link": "https://arxiv.org/abs/2410.23001", "description": "arXiv:2410.23001v1 Announce Type: new \nAbstract: What does it mean to say that, for example, the probability for rain tomorrow is between 20% and 30%? The theory for the evaluation of precise probabilistic forecasts is well-developed and is grounded in the key concepts of proper scoring rules and calibration. For the case of imprecise probabilistic forecasts (sets of probabilities), such theory is still lacking. In this work, we therefore generalize proper scoring rules and calibration to the imprecise case. We develop these concepts as relative to data models and decision problems. As a consequence, the imprecision is embedded in a clear context. We establish a close link to the paradigm of (group) distributional robustness and in doing so provide new insights for it. We argue that proper scoring rules and calibration serve two distinct goals, which are aligned in the precise case, but intriguingly are not necessarily aligned in the imprecise case. The concept of decision-theoretic entropy plays a key role for both goals. Finally, we demonstrate the theoretical insights in machine learning practice, in particular we illustrate subtle pitfalls relating to the choice of loss function in distributional robustness.", "published": "2024-10-31 04:00:00", "id": "df96995e-f3a4-4a2c-a32c-2ea5167c2583", "source": "arxiv", "section": "computerScience"}, {"title": "DexGraspNet 2.0: Learning Generative Dexterous Grasping in Large-scale Synthetic Cluttered Scenes", "link": "https://arxiv.org/abs/2410.23004", "description": "arXiv:2410.23004v1 Announce Type: new \nAbstract: Grasping in cluttered scenes remains highly challenging for dexterous hands due to the scarcity of data. To address this problem, we present a large-scale synthetic benchmark, encompassing 1319 objects, 8270 scenes, and 427 million grasps. Beyond benchmarking, we also propose a novel two-stage grasping method that learns efficiently from data by using a diffusion model that conditions on local geometry. Our proposed generative method outperforms all baselines in simulation experiments. Furthermore, with the aid of test-time-depth restoration, our method demonstrates zero-shot sim-to-real transfer, attaining 90.7% real-world dexterous grasping success rate in cluttered scenes.", "published": "2024-10-31 04:00:00", "id": "47ad7747-3e45-4f40-8cdd-892e2127dcff", "source": "arxiv", "section": "computerScience"}, {"title": "Improving Musical Accompaniment Co-creation via Diffusion Transformers", "link": "https://arxiv.org/abs/2410.23005", "description": "arXiv:2410.23005v1 Announce Type: new \nAbstract: Building upon Diff-A-Riff, a latent diffusion model for musical instrument accompaniment generation, we present a series of improvements targeting quality, diversity, inference speed, and text-driven control. First, we upgrade the underlying autoencoder to a stereo-capable model with superior fidelity and replace the latent U-Net with a Diffusion Transformer. Additionally, we refine text prompting by training a cross-modality predictive network to translate text-derived CLAP embeddings to audio-derived CLAP embeddings. Finally, we improve inference speed by training the latent model using a consistency framework, achieving competitive quality with fewer denoising steps. Our model is evaluated against the original Diff-A-Riff variant using objective metrics in ablation experiments, demonstrating promising advancements in all targeted areas. Sound examples are available at: https://sonycslparis.github.io/improved_dar/.", "published": "2024-10-31 04:00:00", "id": "32e54e17-efe8-4ba7-825b-740cd4f12c80", "source": "arxiv", "section": "computerScience"}, {"title": "SoundCollage: Automated Discovery of New Classes in Audio Datasets", "link": "https://arxiv.org/abs/2410.23008", "description": "arXiv:2410.23008v1 Announce Type: new \nAbstract: Developing new machine learning applications often requires the collection of new datasets. However, existing datasets may already contain relevant information to train models for new purposes. We propose SoundCollage: a framework to discover new classes within audio datasets by incorporating (1) an audio pre-processing pipeline to decompose different sounds in audio samples and (2) an automated model-based annotation mechanism to identify the discovered classes. Furthermore, we introduce clarity measure to assess the coherence of the discovered classes for better training new downstream applications. Our evaluations show that the accuracy of downstream audio classifiers within discovered class samples and held-out datasets improves over the baseline by up to 34.7% and 4.5%, respectively, highlighting the potential of SoundCollage in making datasets reusable by labeling with newly discovered classes. To encourage further research in this area, we open-source our code at https://github.com/nokia-bell-labs/audio-class-discovery.", "published": "2024-10-31 04:00:00", "id": "5f701d1e-dd73-4b90-ab88-847797771742", "source": "arxiv", "section": "computerScience"}, {"title": "Proceedings Eighth Symposium on Working Formal Methods", "link": "https://arxiv.org/abs/2410.23020", "description": "arXiv:2410.23020v1 Announce Type: new \nAbstract: The Working Formal Methods Symposium (FROM) is a series of workshops that aim to bring together researchers and practitioners who work on formal methods by contributing new theoretical results, methods, techniques, and frameworks, and/or by creating or using software tools that apply theoretical contributions.", "published": "2024-10-31 04:00:00", "id": "8401e050-9e29-4e84-98aa-407c03025d85", "source": "arxiv", "section": "computerScience"}, {"title": "Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback", "link": "https://arxiv.org/abs/2410.23022", "description": "arXiv:2410.23022v1 Announce Type: new \nAbstract: Automatically synthesizing dense rewards from natural language descriptions is a promising paradigm in reinforcement learning (RL), with applications to sparse reward problems, open-ended exploration, and hierarchical skill design. Recent works have made promising steps by exploiting the prior knowledge of large language models (LLMs). However, these approaches suffer from important limitations: they are either not scalable to problems requiring billions of environment samples; or are limited to reward functions expressible by compact code, which may require source code and have difficulty capturing nuanced semantics; or require a diverse offline dataset, which may not exist or be impossible to collect. In this work, we address these limitations through a combination of algorithmic and systems-level contributions. We propose ONI, a distributed architecture that simultaneously learns an RL policy and an intrinsic reward function using LLM feedback. Our approach annotates the agent's collected experience via an asynchronous LLM server, which is then distilled into an intrinsic reward model. We explore a range of algorithmic choices for reward modeling with varying complexity, including hashing, classification, and ranking models. By studying their relative tradeoffs, we shed light on questions regarding intrinsic reward design for sparse reward problems. Our approach achieves state-of-the-art performance across a range of challenging, sparse reward tasks from the NetHack Learning Environment in a simple unified process, solely using the agent's gathered experience, without requiring external datasets nor source code. We make our code available at \\url{URL} (coming soon).", "published": "2024-10-31 04:00:00", "id": "5b4190da-c5e3-48b0-83cf-2b3aa72a3846", "source": "arxiv", "section": "computerScience"}, {"title": "A Universal Sets-level Optimization Framework for Next Set Recommendation", "link": "https://arxiv.org/abs/2410.23023", "description": "arXiv:2410.23023v1 Announce Type: new \nAbstract: Next Set Recommendation (NSRec), encompassing related tasks such as next basket recommendation and temporal sets prediction, stands as a trending research topic. Although numerous attempts have been made on this topic, there are certain drawbacks: (i) Existing studies are still confined to utilizing objective functions commonly found in Next Item Recommendation (NIRec), such as binary cross entropy and BPR, which are calculated based on individual item comparisons; (ii) They place emphasis on building sophisticated learning models to capture intricate dependency relationships across sequential sets, but frequently overlook pivotal dependency in their objective functions; (iii) Diversity factor within sequential sets is frequently overlooked. In this research, we endeavor to unveil a universal and S ets-level optimization framework for N ext Set Recommendation (SNSRec), offering a holistic fusion of diversity distribution and intricate dependency relationships within temporal sets. To realize this, the following contributions are made: (i) We directly model the temporal set in a sequence as a cohesive entity, leveraging the Structured Determinantal Point Process (SDPP), wherein the probabilistic DPP distribution prioritizes collections of structures (sequential sets) instead of individual items; (ii) We introduce a co-occurrence representation to discern and acknowledge the importance of different sets; (iii) We propose a sets-level optimization criterion, which integrates the diversity distribution and dependency relations across the entire sequence of sets, guiding the model to recommend relevant and diversified set. Extensive experiments on real-world datasets show that our approach consistently outperforms previous methods on both relevance and diversity.", "published": "2024-10-31 04:00:00", "id": "5c5dab9c-b389-4c5a-b313-24e5a8d36f0d", "source": "arxiv", "section": "computerScience"}, {"title": "Planning and Learning in Risk-Aware Restless Multi-Arm Bandit Problem", "link": "https://arxiv.org/abs/2410.23029", "description": "arXiv:2410.23029v1 Announce Type: new \nAbstract: In restless multi-arm bandits, a central agent is tasked with optimally distributing limited resources across several bandits (arms), with each arm being a Markov decision process. In this work, we generalize the traditional restless multi-arm bandit problem with a risk-neutral objective by incorporating risk-awareness. We establish indexability conditions for the case of a risk-aware objective and provide a solution based on Whittle index. In addition, we address the learning problem when the true transition probabilities are unknown by proposing a Thompson sampling approach and show that it achieves bounded regret that scales sublinearly with the number of episodes and quadratically with the number of arms. The efficacy of our method in reducing risk exposure in restless multi-arm bandits is illustrated through a set of numerical experiments.", "published": "2024-10-31 04:00:00", "id": "0ed2cddf-6594-4ba5-a5c7-4b7a58e8da18", "source": "arxiv", "section": "computerScience"}, {"title": "Offline Reinforcement Learning and Sequence Modeling for Downlink Link Adaptation", "link": "https://arxiv.org/abs/2410.23031", "description": "arXiv:2410.23031v1 Announce Type: new \nAbstract: Contemporary radio access networks employ link adaption (LA) algorithms to optimize the modulation and coding schemes to adapt to the prevailing propagation conditions and are near-optimal in terms of the achieved spectral efficiency. LA is a challenging task in the presence of mobility, fast fading, and imperfect channel quality information and limited knowledge of the receiver characteristics at the transmitter, which render model-based LA algorithms complex and suboptimal. Model-based LA is especially difficult as connected user equipment devices become increasingly heterogeneous in terms of receiver capabilities, antenna configurations and hardware characteristics. Recognizing these difficulties, previous works have proposed reinforcement learning (RL) for LA, which faces deployment difficulties due to their potential negative impacts on live performance. To address this challenge, this paper considers offline RL to learn LA policies from data acquired in live networks with minimal or no intrusive effects on the network operation. We propose three LA designs based on batch-constrained deep Q-learning, conservative Q-learning, and decision transformers, showing that offline RL algorithms can achieve performance of state-of-the-art online RL methods when data is collected with a proper behavioral policy.", "published": "2024-10-31 04:00:00", "id": "f8009f09-803e-47fa-a1db-1b446ce6dc79", "source": "arxiv", "section": "computerScience"}, {"title": "Camber-changing flapping hydrofoils for efficient and environmental-safe water propulsion system", "link": "https://arxiv.org/abs/2410.23032", "description": "arXiv:2410.23032v1 Announce Type: new \nAbstract: This research introduces a novel hydrofoil-based propulsion framework for unmanned aquatic robots, inspired by the undulating locomotion observed in select aquatic species. The proposed system incorporates a camber-modulating mechanism to enhance hydrofoil propulsive force generation and eventually efficiency. Through dynamic simulations, we validate the effectiveness of the camber-adjusting hydrofoil compared to a symmetric counterpart. The results demonstrate a significant improvement in horizontal thrust, emphasizing the potential of the cambering approach to enhance propulsive performance. Additionally, a prototype flipper design is presented, featuring individual control of heave and pitch motions, as well as a camber-adjustment mechanism. The integrated system not only provides efficient water-based propulsion but also offers the capacity for generating vertical forces during take-off maneuvers for seaplanes. The design is tailored to harness wave energy, contributing to the exploration of alternative energy resources. This work advances the understanding of bionic oscillatory principles for aquatic robots and provides a foundation for future developments in environmentally safe and agile underwater exploration.", "published": "2024-10-31 04:00:00", "id": "8870834e-1eac-49d4-a569-1e9af059e816", "source": "arxiv", "section": "computerScience"}, {"title": "Exploring the Potential of Multi-modal Sensing Framework for Forest Ecology", "link": "https://arxiv.org/abs/2410.23033", "description": "arXiv:2410.23033v1 Announce Type: new \nAbstract: Forests offer essential resources and services to humanity, yet preserving and restoring them presents challenges, particularly due to the limited availability of actionable data, especially in hard-to-reach areas like forest canopies. Accessibility continues to pose a challenge for biologists collecting data in forest environments, often requiring them to invest significant time and energy in climbing trees to place sensors. This operation not only consumes resources but also exposes them to danger. Efforts in robotics have been directed towards accessing the tree canopy using robots. A swarm of drones has showcased autonomous navigation through the canopy, maneuvering with agility and evading tree collisions, all aimed at mapping the area and collecting data. However, relying solely on free-flying drones has proven insufficient for data collection. Flying drones within the canopy generates loud noise, disturbing animals and potentially corrupting the data. Additionally, commercial drones often have limited autonomy for dexterous tasks where aerial physical interaction could be required, further complicating data acquisition efforts. Aerial deployed sensor placement methods such as bio-gliders and sensor shooting have proven effective for data collection within the lower canopy. However, these methods face challenges related to retrieving the data and sensors, often necessitating human intervention.", "published": "2024-10-31 04:00:00", "id": "e229ec60-879d-42f5-9995-867d46bb7fc8", "source": "arxiv", "section": "computerScience"}, {"title": "Accurate Solutions to Optimal Control Problems via a Flexible Mesh and Integrated Residual Transcription", "link": "https://arxiv.org/abs/2410.23037", "description": "arXiv:2410.23037v1 Announce Type: new \nAbstract: We propose joining a flexible mesh design with an integrated residual transcription in order to improve the accuracy of numerical solutions to optimal control problems. This approach is particularly useful when state or input trajectories are non-smooth, but it may also be beneficial when dynamics constraints are stiff. Additionally, we implement an initial phase that will ensure a feasible solution is found and can be implemented immediately in real-time controllers. Subsequent iterations with warm-starting will improve the solution until optimality is achieved. Optimizing over the mesh node locations allows for discontinuities to be captured exactly, while integrated residuals account for the approximation error in-between the nodal points. First, we numerically show the improved convergence order for the flexible mesh. We then present the feasibility-driven approach to solve control problems and show how flexible meshing and integrated residual methods can be used in practice. The presented numerical examples demonstrate for the first time the numerical implementation of a flexible mesh for an integrated residual transcription. The results show that our proposed method can be more than two times more accurate than conventional fixed mesh collocation for the same computational time and more than three times more accurate for the same problem size.", "published": "2024-10-31 04:00:00", "id": "0c06bdbb-ac6f-472a-92c7-49e3419c7145", "source": "arxiv", "section": "computerScience"}, {"title": "Neural Attention Field: Emerging Point Relevance in 3D Scenes for One-Shot Dexterous Grasping", "link": "https://arxiv.org/abs/2410.23039", "description": "arXiv:2410.23039v1 Announce Type: new \nAbstract: One-shot transfer of dexterous grasps to novel scenes with object and context variations has been a challenging problem. While distilled feature fields from large vision models have enabled semantic correspondences across 3D scenes, their features are point-based and restricted to object surfaces, limiting their capability of modeling complex semantic feature distributions for hand-object interactions. In this work, we propose the \\textit{neural attention field} for representing semantic-aware dense feature fields in the 3D space by modeling inter-point relevance instead of individual point features. Core to it is a transformer decoder that computes the cross-attention between any 3D query point with all the scene points, and provides the query point feature with an attention-based aggregation. We further propose a self-supervised framework for training the transformer decoder from only a few 3D pointclouds without hand demonstrations. Post-training, the attention field can be applied to novel scenes for semantics-aware dexterous grasping from one-shot demonstration. Experiments show that our method provides better optimization landscapes by encouraging the end-effector to focus on task-relevant scene regions, resulting in significant improvements in success rates on real robots compared with the feature-field-based methods.", "published": "2024-10-31 04:00:00", "id": "ad713759-958b-4508-b39e-67da04e33ec7", "source": "arxiv", "section": "computerScience"}, {"title": "Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval", "link": "https://arxiv.org/abs/2410.23041", "description": "arXiv:2410.23041v1 Announce Type: new \nAbstract: As LLMs exhibit a high degree of human-like capability, increasing attention has been paid to role-playing research areas in which responses generated by LLMs are expected to mimic human replies. This has promoted the exploration of role-playing agents in various applications, such as chatbots that can engage in natural conversations with users and virtual assistants that can provide personalized support and guidance. The crucial factor in the role-playing task is the effective utilization of character memory, which stores characters' profiles, experiences, and historical dialogues. Retrieval Augmented Generation (RAG) technology is used to access the related memory to enhance the response generation of role-playing agents. Most existing studies retrieve related information based on the semantic similarity of memory to maintain characters' personalized traits, and few attempts have been made to incorporate the emotional factor in the retrieval argument generation (RAG) of LLMs. Inspired by the Mood-Dependent Memory theory, which indicates that people recall an event better if they somehow reinstate during recall the original emotion they experienced during learning, we propose a novel emotion-aware memory retrieval framework, termed Emotional RAG, which recalls the related memory with consideration of emotional state in role-playing agents. Specifically, we design two kinds of retrieval strategies, i.e., combination strategy and sequential strategy, to incorporate both memory semantic and emotional states during the retrieval process. Extensive experiments on three representative role-playing datasets demonstrate that our Emotional RAG framework outperforms the method without considering the emotional factor in maintaining the personalities of role-playing agents. This provides evidence to further reinforce the Mood-Dependent Memory theory in psychology.", "published": "2024-10-31 04:00:00", "id": "5f1b5ded-6791-450b-8049-e7ef5ec94108", "source": "arxiv", "section": "computerScience"}, {"title": "Toward Understanding In-context vs. In-weight Learning", "link": "https://arxiv.org/abs/2410.23042", "description": "arXiv:2410.23042v1 Announce Type: new \nAbstract: It has recently been demonstrated empirically that in-context learning emerges in transformers when certain distributional properties are present in the training data, but this ability can also diminish upon further training. We provide a new theoretical understanding of these phenomena by identifying simplified distributional properties that give rise to the emergence and eventual disappearance of in-context learning. We do so by first analyzing a simplified model that uses a gating mechanism to choose between an in-weight and an in-context predictor. Through a combination of a generalization error and regret analysis we identify conditions where in-context and in-weight learning emerge. These theoretical findings are then corroborated experimentally by comparing the behaviour of a full transformer on the simplified distributions to that of the stylized model, demonstrating aligned results. We then extend the study to a full large language model, showing how fine-tuning on various collections of natural language prompts can elicit similar in-context and in-weight learning behaviour.", "published": "2024-10-31 04:00:00", "id": "3f83537a-9fdb-4bf7-b9c8-c7a7dec46048", "source": "arxiv", "section": "computerScience"}, {"title": "Legitimate ground-truth-free metrics for deep uncertainty classification scoring", "link": "https://arxiv.org/abs/2410.23046", "description": "arXiv:2410.23046v1 Announce Type: new \nAbstract: Despite the increasing demand for safer machine learning practices, the use of Uncertainty Quantification (UQ) methods in production remains limited. This limitation is exacerbated by the challenge of validating UQ methods in absence of UQ ground truth. In classification tasks, when only a usual set of test data is at hand, several authors suggested different metrics that can be computed from such test points while assessing the quality of quantified uncertainties. This paper investigates such metrics and proves that they are theoretically well-behaved and actually tied to some uncertainty ground truth which is easily interpretable in terms of model prediction trustworthiness ranking. Equipped with those new results, and given the applicability of those metrics in the usual supervised paradigm, we argue that our contributions will help promoting a broader use of UQ in deep learning.", "published": "2024-10-31 04:00:00", "id": "2283cd69-e505-4548-90de-fac5baa092b5", "source": "arxiv", "section": "computerScience"}, {"title": "TumblerBots: Tumbling Robotic sensors for Minimally-invasive Benthic Monitoring", "link": "https://arxiv.org/abs/2410.23049", "description": "arXiv:2410.23049v1 Announce Type: new \nAbstract: Robotic systems show significant promise for water environmental sensing applications such as water quality monitoring, pollution mapping and biodiversity data collection.\n  Conventional deployment methods often disrupt fragile ecosystems, preventing depiction of the undisturbed environmental condition. In response to this challenge, we propose a novel framework utilizing a lightweight tumbler system equipped with a sensing unit, deployed via a drone. This design minimizes disruption to the water habitat by maintaining a slow descent. The sensing unit is detached once on the water surface, enabling precise and non-invasive data collection from the benthic zone.\n  The tumbler is designed to be lightweight and compact, enabling deployment via a drone. The sensing pod, which detaches from the tumbler and descends to the bottom of the water body, is equipped with temperature and pressure sensors, as well as a buoyancy system. The later, activated upon task completion, utilizes a silicon membrane inflated via a chemical reaction. The reaction generates a pressure of 70 kPa, causing the silicon membrane to expand by 30\\%, which exceeds the 5.7\\% volume increase required for positive buoyancy. The tumblers, made from ecofriendly materials to minimize environmental impact when lost during the mission, were tested for their gliding ratio and descent rate. They exhibit a low descent rate, in the range of 0.8 to 2.5 meters per seconds, which minimizes disturbance to the ecosystem upon water landing. Additionally, the system demonstrated robustness in moderate to strong wind conditions during outdoor tests, validating the overall framework.", "published": "2024-10-31 04:00:00", "id": "cb329a43-1098-423f-8947-61ea18ba2924", "source": "arxiv", "section": "computerScience"}, {"title": "Controlling Language and Diffusion Models by Transporting Activations", "link": "https://arxiv.org/abs/2410.23054", "description": "arXiv:2410.23054v1 Announce Type: new \nAbstract: The increasing capabilities of large generative models and their ever more widespread deployment have raised concerns about their reliability, safety, and potential misuse. To address these issues, recent works have proposed to control model generation by steering model activations in order to effectively induce or prevent the emergence of concepts or behaviors in the generated output. In this paper we introduce Activation Transport (AcT), a general framework to steer activations guided by optimal transport theory that generalizes many previous activation-steering works. AcT is modality-agnostic and provides fine-grained control over the model behavior with negligible computational overhead, while minimally impacting model abilities. We experimentally show the effectiveness and versatility of our approach by addressing key challenges in large language models (LLMs) and text-to-image diffusion models (T2Is). For LLMs, we show that AcT can effectively mitigate toxicity, induce arbitrary concepts, and increase their truthfulness. In T2Is, we show how AcT enables fine-grained style control and concept negation.", "published": "2024-10-31 04:00:00", "id": "1d6613a8-2406-4018-b6ad-1dcc5b27ccd8", "source": "arxiv", "section": "computerScience"}, {"title": "The Days On Days Off Scheduling Problem", "link": "https://arxiv.org/abs/2410.23056", "description": "arXiv:2410.23056v1 Announce Type: new \nAbstract: Personnel scheduling problems have received considerable academic attention due to their relevance in various real-world applications. These problems involve preparing feasible schedules for an organization's employees and often account for factors such as qualifications of workers and holiday requests, resulting in complex constraints. While certain versions of the personnel rostering problem are widely acknowledged as NP-hard, there is limited theoretical analysis specific to many of its variants. Many studies simply assert the NP-hardness of the general problem without investigating whether the specific cases they address inherit this computational complexity.\n  In this paper, we examine a variant of the personnel scheduling problems, which involves scheduling a homogeneous workforce subject to constraints concerning both the total number and the number of consecutive work days and days off. This problem was claimed to be NP-complete by [Brunner+2013]. In this paper, we prove its NP-completeness and investigate how the combination of constraints contributes to this complexity. Furthermore, we analyze various special cases that arise from the omission of certain parameters, classifying them as either NP-complete or polynomial-time solvable. For the latter, we provide easy-to-implement and efficient algorithms to not only determine feasibility, but also compute a corresponding schedule.", "published": "2024-10-31 04:00:00", "id": "a41b455d-cb4f-43da-b5a2-c69abd716a0b", "source": "arxiv", "section": "computerScience"}, {"title": "FilMBot: A High-Speed Soft Parallel Robotic Micromanipulator", "link": "https://arxiv.org/abs/2410.23059", "description": "arXiv:2410.23059v1 Announce Type: new \nAbstract: Soft robotic manipulators are generally slow despite their great adaptability, resilience, and compliance. This limitation also extends to current soft robotic micromanipulators. Here, we introduce FilMBot, a 3-DOF film-based, electromagnetically actuated, soft kinematic robotic micromanipulator achieving speeds up to 2117 $\\deg$/s and 2456 $\\deg$/s in $\\alpha$ and $\\beta$ angular motions, with corresponding linear velocities of 1.61 m/s and 1.92 m/s using a 4-cm needle end-effector, and 1.57 m/s along the Z axis. The robot can reach ~1.50 m/s in path-following tasks, operates at frequencies up to 30 Hz, and remains functional up to 50 Hz. It demonstrates high precision (~6.3 $\\mu$m, or ~0.05% of its workspace) in small path-following tasks. The novel combination of the low-stiffness soft kinematic film structure and strong electromagnetic actuation in FilMBot opens new avenues for soft robotics. Furthermore, its simple construction and inexpensive, readily accessible components could broaden the application of micromanipulators beyond current academic and professional users.", "published": "2024-10-31 04:00:00", "id": "9347dacf-f0f0-4373-bc98-473b32ddd53f", "source": "arxiv", "section": "computerScience"}, {"title": "Learned RESESOP for solving inverse problems with inexact forward operator", "link": "https://arxiv.org/abs/2410.23061", "description": "arXiv:2410.23061v1 Announce Type: new \nAbstract: When solving inverse problems, one has to deal with numerous potential sources of model inexactnesses, like object motion, calibration errors, or simplified data models. Regularized Sequential Subspace Optimization (ReSeSOp) allows to compensate for such inaccuracies within the reconstruction step by employing consecutive projections onto suitably defined subspaces. However, this approach relies on a priori estimates for the model inexactness levels which are typically unknown. In dynamic imaging applications, where inaccuracies arise from the unpredictable dynamics of the object, these estimates are particularly challenging to determine in advance. To overcome this limitation, we propose a learned version of ReSeSOp which allows to approximate inexactness levels on the fly. The proposed framework generalizes established unrolled iterative reconstruction schemes to inexact forward operators and is particularly tailored to the structure of dynamic problems. We also present a comprehensive mathematical analysis regarding the effect of dependencies within the forward problem, clarifying when and why dividing the overall problem into subproblems is essential. The proposed method is evaluated on various examples from dynamic imaging, including datasets from a rheological CT experiment, brain MRI, and real-time cardiac MRI. The respective results emphasize improvements in reconstruction quality while ensuring adequate data consistency.", "published": "2024-10-31 04:00:00", "id": "26cb3dab-fb19-41c3-9a90-5a395b8d50fc", "source": "arxiv", "section": "computerScience"}, {"title": "Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification", "link": "https://arxiv.org/abs/2410.23066", "description": "arXiv:2410.23066v1 Announce Type: new \nAbstract: State-of-the-art Extreme Multi-Label Text Classification (XMTC) models rely heavily on multi-label attention layers to focus on key tokens in input text, but obtaining optimal attention weights is challenging and resource-intensive. To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- a novel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpasses existing state-of-the-art methods across all metrics on mimicfull, mimicfifty, mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shot scenarios, outperforming previous models specifically designed for few-shot scenarios by over 50 percentage points in F1 scores on mimicrare and by over 36 percentage points on mimicfew, demonstrating its superior capability in handling rare codes. PLANT also shows remarkable data efficiency in few-shot scenarios, achieving precision comparable to traditional models with significantly less data. These results are achieved through key technical innovations: leveraging a pretrained Learning-to-Rank model as the planted attention layer, integrating mutual-information gain to enhance attention, introducing an inattention mechanism, and implementing a stateful-decoder to maintain context. Comprehensive ablation studies validate the importance of these contributions in realizing the performance gains.", "published": "2024-10-31 04:00:00", "id": "2d7634ed-59c7-48a6-8d98-c178bf3f654a", "source": "arxiv", "section": "computerScience"}, {"title": "Adaptive and non-adaptive randomized approximation of high-dimensional vectors", "link": "https://arxiv.org/abs/2410.23067", "description": "arXiv:2410.23067v1 Announce Type: new \nAbstract: We study approximation of the embedding $\\ell_p^m \\hookrightarrow \\ell_q^m$, $1 \\leq p < q \\leq \\infty$, based on randomized algorithms that use up to $n$ arbitrary linear functionals as information on a problem instance where $n \\ll m$. By analysing adaptive methods we show upper bounds for which the information-based complexity $n$ exhibits only a $(\\log\\log m)$-dependence. In the case $q < \\infty$ we use a multi-sensitivity approach in order to reach optimal polynomial order in $n$ for the Monte Carlo error. We also improve on non-adaptive methods for $q < \\infty$ by denoising known algorithms for uniform approximation.", "published": "2024-10-31 04:00:00", "id": "25241037-6cca-481d-8b6f-4cc90f009921", "source": "arxiv", "section": "computerScience"}, {"title": "LLMs Integration in Software Engineering Team Projects: Roles, Impact, and a Pedagogical Design Space for AI Tools in Computing Education", "link": "https://arxiv.org/abs/2410.23069", "description": "arXiv:2410.23069v1 Announce Type: new \nAbstract: This work takes a pedagogical lens to explore the implications of generative AI (GenAI) models and tools, such as ChatGPT and GitHub Copilot, in a semester-long 2nd-year undergraduate Software Engineering Team Project. Qualitative findings from survey (39 students) and interviews (eight students) provide insights into the students' views on the impact of GenAI use on their coding experience, learning, and self-efficacy. Our results address a particular gap in understanding the role and implications of GenAI on teamwork, team-efficacy, and team dynamics. The analysis of the learning aspects is distinguished by the application of learning and pedagogy informed lenses to discuss the data. We propose a preliminary design space for GenAI-based programming learning tools highlighting the importance of considering the roles that GenAI can play during the learning process, the varying support-ability patterns that can be applied to each role, and the importance of supporting transparency in GenAI for team members and students in addition to educators.", "published": "2024-10-31 04:00:00", "id": "0f02e1ce-75bd-41e9-b532-f6bf95d206b2", "source": "arxiv", "section": "computerScience"}, {"title": "CNN Explainability with Multivector Tucker Saliency Maps for Self-Supervised Models", "link": "https://arxiv.org/abs/2410.23072", "description": "arXiv:2410.23072v1 Announce Type: new \nAbstract: Interpreting the decisions of Convolutional Neural Networks (CNNs) is essential for understanding their behavior, yet explainability remains a significant challenge, particularly for self-supervised models. Most existing methods for generating saliency maps rely on ground truth labels, restricting their use to supervised tasks. EigenCAM is the only notable label-independent alternative, leveraging Singular Value Decomposition to generate saliency maps applicable across CNN models, but it does not fully exploit the tensorial structure of feature maps. In this work, we introduce the Tucker Saliency Map (TSM) method, which applies Tucker tensor decomposition to better capture the inherent structure of feature maps, producing more accurate singular vectors and values. These are used to generate high-fidelity saliency maps, effectively highlighting objects of interest in the input. We further extend EigenCAM and TSM into multivector variants -Multivec-EigenCAM and Multivector Tucker Saliency Maps (MTSM)- which utilize all singular vectors and values, further improving saliency map quality. Quantitative evaluations on supervised classification models demonstrate that TSM, Multivec-EigenCAM, and MTSM achieve competitive performance with label-dependent methods. Moreover, TSM enhances explainability by approximately 50% over EigenCAM for both supervised and self-supervised models. Multivec-EigenCAM and MTSM further advance state-of-the-art explainability performance on self-supervised models, with MTSM achieving the best results.", "published": "2024-10-31 04:00:00", "id": "259fb9ee-99e5-4bd1-b274-006f2772b1e9", "source": "arxiv", "section": "computerScience"}, {"title": "RSNet: A Light Framework for The Detection of Multi-scale Remote Sensing Targets", "link": "https://arxiv.org/abs/2410.23073", "description": "arXiv:2410.23073v1 Announce Type: new \nAbstract: Recent developments in synthetic aperture radar (SAR) ship detection have seen deep learning techniques achieve remarkable progress in accuracy and speed. However, the detection of small targets against complex backgrounds remains a significant challenge. To tackle these difficulties, this letter presents RSNet, a lightweight framework aimed at enhancing ship detection capabilities in SAR imagery. RSNet features the Waveletpool-ContextGuided (WCG) backbone for enhanced accuracy with fewer parameters, and the Waveletpool-StarFusion (WSF) head for efficient parameter reduction. Additionally, a Lightweight-Shared (LS) module minimizes the detection head's parameter load. Experiments on the SAR Ship Detection Dataset (SSDD) and High-Resolution SAR Image Dataset (HRSID) demonstrate that RSNet achieves a strong balance between lightweight design and detection performance, surpassing many state-of-the-art detectors, reaching 72.5\\% and 67.6\\% in \\textbf{\\(\\mathbf{mAP_{.50:95}}\\) }respectively with 1.49M parameters. Our code will be released soon.", "published": "2024-10-31 04:00:00", "id": "2a8a152c-cc5d-4b1a-b454-ccfd833e7631", "source": "arxiv", "section": "computerScience"}, {"title": "Multi-Programming Language Sandbox for LLMs", "link": "https://arxiv.org/abs/2410.23074", "description": "arXiv:2410.23074v1 Announce Type: new \nAbstract: We introduce MPLSandbox, an out-of-the-box multi-programming language sandbox designed to provide unified and comprehensive feedback from compiler and analysis tools for Large Language Models (LLMs). It can automatically identify the programming language of the code, compiling and executing it within an isolated sub-sandbox to ensure safety and stability. In addition, MPLSandbox also integrates both traditional and LLM-based code analysis tools, providing a comprehensive analysis of generated code. MPLSandbox can be effortlessly integrated into the training and deployment of LLMs to improve the quality and correctness of their generated code. It also helps researchers streamline their workflows for various LLM-based code-related tasks, reducing the development cost. To validate the effectiveness of MPLSandbox, we integrate it into training and deployment approaches, and also employ it to optimize workflows for a wide range of real-world code-related tasks. Our goal is to enhance researcher productivity on LLM-based code-related tasks by simplifying and automating workflows through delegation to MPLSandbox.", "published": "2024-10-31 04:00:00", "id": "eabe2274-c5e4-41af-a01e-f76cc05d4138", "source": "arxiv", "section": "computerScience"}, {"title": "First Place Solution to the ECCV 2024 ROAD++ Challenge @ ROAD++ Spatiotemporal Agent Detection 2024", "link": "https://arxiv.org/abs/2410.23077", "description": "arXiv:2410.23077v1 Announce Type: new \nAbstract: This report presents our team's solutions for the Track 1 of the 2024 ECCV ROAD++ Challenge. The task of Track 1 is spatiotemporal agent detection, which aims to construct an \"agent tube\" for road agents in consecutive video frames. Our solutions focus on the challenges in this task, including extreme-size objects, low-light scenarios, class imbalance, and fine-grained classification. Firstly, the extreme-size object detection heads are introduced to improve the detection performance of large and small objects. Secondly, we design a dual-stream detection model with a low-light enhancement stream to improve the performance of spatiotemporal agent detection in low-light scenes, and the feature fusion module to integrate features from different branches. Subsequently, we develop a multi-branch detection framework to mitigate the issues of class imbalance and fine-grained classification, and we design a pre-training and fine-tuning approach to optimize the above multi-branch framework. Besides, we employ some common data augmentation techniques, and improve the loss function and upsampling operation. We rank first in the test set of Track 1 for the ROAD++ Challenge 2024, and achieve 30.82% average video-mAP.", "published": "2024-10-31 04:00:00", "id": "a3defb9c-e2d0-4afa-8f47-bbc7321fc2c3", "source": "arxiv", "section": "computerScience"}, {"title": "BUZZ: Beehive-structured Sparse KV Cache with Segmented Heavy Hitters for Efficient LLM Inference", "link": "https://arxiv.org/abs/2410.23079", "description": "arXiv:2410.23079v1 Announce Type: new \nAbstract: Large language models (LLMs) are essential in natural language processing but often struggle with inference speed and computational efficiency, limiting real-time deployment. The key-value (KV) cache mechanism reduces computational overhead in transformer models, but challenges in maintaining contextual understanding remain. In this paper, we propose BUZZ, a novel KV caching algorithm that leverages structured contextual information to minimize cache memory usage while enhancing inference speed. BUZZ employs a beehive-structured sparse cache, incorporating a sliding window to capture recent information and dynamically segmenting historical tokens into chunks to prioritize important tokens in local neighborhoods. We evaluate BUZZ on four real-world datasets: CNN/Daily Mail, XSUM, Wikitext, and 10-QA. Our results demonstrate that BUZZ (1) reduces cache memory usage by $\\textbf{2.5}\\times$ in LLM inference while maintaining over 99% accuracy in long-text summarization, and (2) surpasses state-of-the-art performance in multi-document question answering by $\\textbf{7.69%}$ under the same memory limit, where full cache methods encounter out-of-memory issues. Additionally, BUZZ achieves significant inference speedup with a $\\log{n}$ time complexity. The code is available at https://github.com/JunqiZhao888/buzz-llm.", "published": "2024-10-31 04:00:00", "id": "b14cbab6-2338-477d-a097-e2bad853336b", "source": "arxiv", "section": "computerScience"}, {"title": "An Event-Based Digital Compute-In-Memory Accelerator with Flexible Operand Resolution and Layer-Wise Weight/Output Stationarity", "link": "https://arxiv.org/abs/2410.23082", "description": "arXiv:2410.23082v1 Announce Type: new \nAbstract: Compute-in-memory (CIM) accelerators for spiking neural networks (SNNs) are promising solutions to enable $\\mu$s-level inference latency and ultra-low energy in edge vision applications. Yet, their current lack of flexibility at both the circuit and system levels prevents their deployment in a wide range of real-life scenarios. In this work, we propose a novel digital CIM macro that supports arbitrary operand resolution and shape, with a unified CIM storage for weights and membrane potentials. These circuit-level techniques enable a hybrid weight- and output-stationary dataflow at the system level to maximize operand reuse, thereby minimizing costly on- and off-chip data movements during the SNN execution. Measurement results of a fabricated FlexSpIM prototype in 40-nm CMOS demonstrate a 2$\\times$ increase in bit-normalized energy efficiency compared to prior fixed-precision digital CIM-SNNs, while providing resolution reconfiguration with bitwise granularity. Our approach can save up to 90% energy in large-scale systems, while reaching a state-of-the-art classification accuracy of 95.8% on the IBM DVS gesture dataset.", "published": "2024-10-31 04:00:00", "id": "b69b10e8-595e-4d86-a03c-d95cbf5e6976", "source": "arxiv", "section": "computerScience"}, {"title": "Developing a Self-Explanatory Transformer", "link": "https://arxiv.org/abs/2410.23083", "description": "arXiv:2410.23083v1 Announce Type: new \nAbstract: While IoT devices provide significant benefits, their rapid growth results in larger data volumes, increased complexity, and higher security risks. To manage these issues, techniques like encryption, compression, and mapping are used to process data efficiently and securely. General-purpose and AI platforms handle these tasks well, but mapping in natural language processing is often slowed by training times. This work explores a self-explanatory, training-free mapping transformer based on non-deterministic finite automata, designed for Field-Programmable Gate Arrays (FPGAs). Besides highlighting the advantages of this proposed approach in providing real-time, cost-effective processing and dataset-loading, we also address the challenges and considerations for enhancing the design in future iterations.", "published": "2024-10-31 04:00:00", "id": "2885b99d-429d-47cc-b466-149359231f49", "source": "arxiv", "section": "computerScience"}, {"title": "S3PT: Scene Semantics and Structure Guided Clustering to Boost Self-Supervised Pre-Training for Autonomous Driving", "link": "https://arxiv.org/abs/2410.23085", "description": "arXiv:2410.23085v1 Announce Type: new \nAbstract: Recent self-supervised clustering-based pre-training techniques like DINO and Cribo have shown impressive results for downstream detection and segmentation tasks. However, real-world applications such as autonomous driving face challenges with imbalanced object class and size distributions and complex scene geometries. In this paper, we propose S3PT a novel scene semantics and structure guided clustering to provide more scene-consistent objectives for self-supervised training. Specifically, our contributions are threefold: First, we incorporate semantic distribution consistent clustering to encourage better representation of rare classes such as motorcycles or animals. Second, we introduce object diversity consistent spatial clustering, to handle imbalanced and diverse object sizes, ranging from large background areas to small objects such as pedestrians and traffic signs. Third, we propose a depth-guided spatial clustering to regularize learning based on geometric information of the scene, thus further refining region separation on the feature level. Our learned representations significantly improve performance in downstream semantic segmentation and 3D object detection tasks on the nuScenes, nuImages, and Cityscapes datasets and show promising domain translation properties.", "published": "2024-10-31 04:00:00", "id": "14aca40a-ab1b-4c54-a9cc-c165491d89ba", "source": "arxiv", "section": "computerScience"}, {"title": "From Hype to Reality: The Road Ahead of Deploying DRL in 6G Networks", "link": "https://arxiv.org/abs/2410.23086", "description": "arXiv:2410.23086v1 Announce Type: new \nAbstract: The industrial landscape is rapidly evolving with the advent of 6G applications, which demand massive connectivity, high computational capacity, and ultra-low latency. These requirements present new challenges, which can no longer be efficiently addressed by conventional strategies. In response, this article underscores the transformative potential of Deep Reinforcement Learning (DRL) for 6G, highlighting its advantages over classic machine learning solutions in meeting the demands of 6G. The necessity of DRL is further validated through three DRL applications in an end-to-end communication procedure, including wireless access control, baseband function placement, and network slicing coordination. However, DRL-based network management initiatives are far from mature. We extend the discussion to identify the challenges of applying DRL in practical networks and explore potential solutions along with their respective limitations. In the end, these insights are validated through a practical DRL deployment in managing network slices on the testbed.", "published": "2024-10-31 04:00:00", "id": "fcb478b2-19bc-47e1-8506-4f141059ccff", "source": "arxiv", "section": "computerScience"}, {"title": "Statistical-Computational Trade-offs for Density Estimation", "link": "https://arxiv.org/abs/2410.23087", "description": "arXiv:2410.23087v1 Announce Type: new \nAbstract: We study the density estimation problem defined as follows: given $k$ distributions $p_1, \\ldots, p_k$ over a discrete domain $[n]$, as well as a collection of samples chosen from a ``query'' distribution $q$ over $[n]$, output $p_i$ that is ``close'' to $q$. Recently~\\cite{aamand2023data} gave the first and only known result that achieves sublinear bounds in {\\em both} the sampling complexity and the query time while preserving polynomial data structure space. However, their improvement over linear samples and time is only by subpolynomial factors.\n  Our main result is a lower bound showing that, for a broad class of data structures, their bounds cannot be significantly improved. In particular, if an algorithm uses $O(n/\\log^c k)$ samples for some constant $c>0$ and polynomial space, then the query time of the data structure must be at least $k^{1-O(1)/\\log \\log k}$, i.e., close to linear in the number of distributions $k$. This is a novel \\emph{statistical-computational} trade-off for density estimation, demonstrating that any data structure must use close to a linear number of samples or take close to linear query time. The lower bound holds even in the realizable case where $q=p_i$ for some $i$, and when the distributions are flat (specifically, all distributions are uniform over half of the domain $[n]$). We also give a simple data structure for our lower bound instance with asymptotically matching upper bounds. Experiments show that the data structure is quite efficient in practice.", "published": "2024-10-31 04:00:00", "id": "f353ef56-0b42-4d35-8082-e70b976810f5", "source": "arxiv", "section": "computerScience"}, {"title": "PIP-MM: Pre-Integrating Prompt Information into Visual Encoding via Existing MLLM Structures", "link": "https://arxiv.org/abs/2410.23089", "description": "arXiv:2410.23089v1 Announce Type: new \nAbstract: The Multimodal Large Language Models (MLLMs) have activated the capabilitiesof Large Language Models (LLMs) in solving visual-language tasks by integratingvisual information. The prevailing approach in existing MLLMs involvesemploying an image encoder to extract visual features, converting thesefeatures into visual tokens via an adapter, and then integrating them with theprompt into the LLM. However, because the process of image encoding isprompt-agnostic, the extracted visual features only provide a coarsedescription of the image, impossible to focus on the requirements of theprompt. On one hand, it is easy for image features to lack information aboutthe prompt-specified objects, resulting in unsatisfactory responses. On theother hand, the visual features contain a large amount of irrelevantinformation, which not only increases the burden on memory but also worsens thegeneration effectiveness. To address the aforementioned issues, we propose\\textbf{PIP-MM}, a framework that \\textbf{P}re-\\textbf{I}ntegrates\\textbf{P}rompt information into the visual encoding process using existingmodules of MLLMs. Specifically, We utilize the frozen LLM in the MLLM tovectorize the input prompt, which summarizes the requirements of the prompt.Then, we input the prompt vector into our trained Multi-Layer Perceptron (MLP)to align with the visual input requirements, and subsequently replace the classembedding in the image encoder. Since our model only requires adding atrainable MLP, it can be applied to any MLLM. To validate the effectiveness ofPIP-MM, we conducted experiments on multiple benchmarks. Automated evaluationmetrics and manual assessments demonstrate the strong performance of PIP-MM.Particularly noteworthy is that our model maintains excellent generationresults even when half of the visual tokens are reduced.", "published": "2024-10-31 04:00:00", "id": "c99ddb52-f4be-4014-ade8-5f6081a86f4e", "source": "arxiv", "section": "computerScience"}, {"title": "CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation", "link": "https://arxiv.org/abs/2410.23090", "description": "arXiv:2410.23090v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) has become a powerful paradigm for enhancing large language models (LLMs) through external knowledge retrieval. Despite its widespread attention, existing academic research predominantly focuses on single-turn RAG, leaving a significant gap in addressing the complexities of multi-turn conversations found in real-world applications. To bridge this gap, we introduce CORAL, a large-scale benchmark designed to assess RAG systems in realistic multi-turn conversational settings. CORAL includes diverse information-seeking conversations automatically derived from Wikipedia and tackles key challenges such as open-domain coverage, knowledge intensity, free-form responses, and topic shifts. It supports three core tasks of conversational RAG: passage retrieval, response generation, and citation labeling. We propose a unified framework to standardize various conversational RAG methods and conduct a comprehensive evaluation of these methods on CORAL, demonstrating substantial opportunities for improving existing approaches.", "published": "2024-10-31 04:00:00", "id": "aa00708d-1098-4db6-8426-c40b426db475", "source": "arxiv", "section": "computerScience"}, {"title": "CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense", "link": "https://arxiv.org/abs/2410.23091", "description": "arXiv:2410.23091v1 Announce Type: new \nAbstract: Despite ongoing efforts to defend neural classifiers from adversarial attacks, they remain vulnerable, especially to unseen attacks. In contrast, humans are difficult to be cheated by subtle manipulations, since we make judgments only based on essential factors. Inspired by this observation, we attempt to model label generation with essential label-causative factors and incorporate label-non-causative factors to assist data generation. For an adversarial example, we aim to discriminate the perturbations as non-causative factors and make predictions only based on the label-causative factors. Concretely, we propose a casual diffusion model (CausalDiff) that adapts diffusion models for conditional data generation and disentangles the two types of casual factors by learning towards a novel casual information bottleneck objective. Empirically, CausalDiff has significantly outperformed state-of-the-art defense methods on various unseen attacks, achieving an average robustness of 86.39% (+4.01%) on CIFAR-10, 56.25% (+3.13%) on CIFAR-100, and 82.62% (+4.93%) on GTSRB (German Traffic Sign Recognition Benchmark).", "published": "2024-10-31 04:00:00", "id": "129a67d3-4e7f-438b-bbd6-0e0fb2a3e458", "source": "arxiv", "section": "computerScience"}, {"title": "First Place Solution to the ECCV 2024 ROAD++ Challenge @ ROAD++ Atomic Activity Recognition 2024", "link": "https://arxiv.org/abs/2410.23092", "description": "arXiv:2410.23092v1 Announce Type: new \nAbstract: This report presents our team's technical solution for participating in Track 3 of the 2024 ECCV ROAD++ Challenge. The task of Track 3 is atomic activity recognition, which aims to identify 64 types of atomic activities in road scenes based on video content. Our approach primarily addresses the challenges of small objects, discriminating between single object and a group of objects, as well as model overfitting in this task. Firstly, we construct a multi-branch activity recognition framework that not only separates different object categories but also the tasks of single object and object group recognition, thereby enhancing recognition accuracy. Subsequently, we develop various model ensembling strategies, including integrations of multiple frame sampling sequences, different frame sampling sequence lengths, multiple training epochs, and different backbone networks. Furthermore, we propose an atomic activity recognition data augmentation method, which greatly expands the sample space by flipping video frames and road topology, effectively mitigating model overfitting. Our methods rank first in the test set of Track 3 for the ROAD++ Challenge 2024, and achieve 69% mAP.", "published": "2024-10-31 04:00:00", "id": "deecdc2a-0436-4d33-94f9-f5aa2f3ce97d", "source": "arxiv", "section": "computerScience"}, {"title": "Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning", "link": "https://arxiv.org/abs/2410.23099", "description": "arXiv:2410.23099v1 Announce Type: new \nAbstract: In-context learning can help Large Language Models (LLMs) to adapt new tasks without additional training. However, this performance heavily depends on the quality of the demonstrations, driving research into effective demonstration selection algorithms to optimize this process. These algorithms assist users in selecting the best $k$ input-label pairs (demonstration examples) based on a given test input, enabling LLMs to in-context learn the relationship between the provided examples and the test inputs. Despite all the proposed demonstration selection algorithms, their efficiency and effectiveness remain unclear. This lack of clarity make it difficult to apply these algorithms in real-world scenarios and poses challenges for future research aimed at developing improved methods. This paper revisits six proposed algorithms, evaluating them on five datasets from both efficiency and effectiveness perspectives. Our experiments reveal significant variations in algorithm performance across different tasks, with some methods struggling to outperform random selection in certain scenarios. We also find that increasing the number of demonstrations does not always lead to better performance, and that there are often trade-offs between accuracy and computational efficiency. Our code is available at https://github.com/Tizzzzy/Demonstration_Selection_Overview.", "published": "2024-10-31 04:00:00", "id": "5924fe15-e0e4-4d08-b7ce-1c65b95935ca", "source": "arxiv", "section": "computerScience"}, {"title": "Guided Game Level Repair via Explainable AI", "link": "https://arxiv.org/abs/2410.23101", "description": "arXiv:2410.23101v1 Announce Type: new \nAbstract: Procedurally generated levels created by machine learning models can be unsolvable without further editing. Various methods have been developed to automatically repair these levels by enforcing hard constraints during the post-processing step. However, as levels increase in size, these constraint-based repairs become increasingly slow. This paper proposes using explainability methods to identify specific regions of a level that contribute to its unsolvability. By assigning higher weights to these regions, constraint-based solvers can prioritize these problematic areas, enabling more efficient repairs. Our results, tested across three games, demonstrate that this approach can help to repair procedurally generated levels faster.", "published": "2024-10-31 04:00:00", "id": "7e65c10c-24cf-4929-9420-ada60af38727", "source": "arxiv", "section": "computerScience"}, {"title": "Automated Image-Based Identification and Consistent Classification of Fire Patterns with Quantitative Shape Analysis and Spatial Location Identification", "link": "https://arxiv.org/abs/2410.23105", "description": "arXiv:2410.23105v1 Announce Type: new \nAbstract: Fire patterns, consisting of fire effects that offer insights into fire behavior and origin, are traditionally classified based on investigators' visual observations, leading to subjective interpretations. This study proposes a framework for quantitative fire pattern classification to support fire investigators, aiming for consistency and accuracy. The framework integrates four components. First, it leverages human-computer interaction to extract fire patterns from surfaces, combining investigator expertise with computational analysis. Second, it employs an aspect ratio-based random forest model to classify fire pattern shapes. Third, fire scene point cloud segmentation enables precise identification of fire-affected areas and the mapping of 2D fire patterns to 3D scenes. Lastly, spatial relationships between fire patterns and indoor elements support an interpretation of the fire scene. These components provide a method for fire pattern analysis that synthesizes qualitative and quantitative data. The framework's classification results achieve 93% precision on synthetic data and 83% on real fire patterns.", "published": "2024-10-31 04:00:00", "id": "1ebac5d6-7d04-4ad7-9b46-809bd9537885", "source": "arxiv", "section": "computerScience"}, {"title": "Decoupling Semantic Similarity from Spatial Alignment for Neural Networks", "link": "https://arxiv.org/abs/2410.23107", "description": "arXiv:2410.23107v1 Announce Type: new \nAbstract: What representation do deep neural networks learn? How similar are images to each other for neural networks? Despite the overwhelming success of deep learning methods key questions about their internal workings still remain largely unanswered, due to their internal high dimensionality and complexity. To address this, one approach is to measure the similarity of activation responses to various inputs. Representational Similarity Matrices (RSMs) distill this similarity into scalar values for each input pair. These matrices encapsulate the entire similarity structure of a system, indicating which input leads to similar responses. While the similarity between images is ambiguous, we argue that the spatial location of semantic objects does neither influence human perception nor deep learning classifiers. Thus this should be reflected in the definition of similarity between image responses for computer vision systems. Revisiting the established similarity calculations for RSMs we expose their sensitivity to spatial alignment. In this paper, we propose to solve this through semantic RSMs, which are invariant to spatial permutation. We measure semantic similarity between input responses by formulating it as a set-matching problem. Further, we quantify the superiority of semantic RSMs over spatio-semantic RSMs through image retrieval and by comparing the similarity between representations to the similarity between predicted class probabilities.", "published": "2024-10-31 04:00:00", "id": "3b75095c-b5fb-4426-87a7-cf99f7a4fe1a", "source": "arxiv", "section": "computerScience"}, {"title": "Controllable Game Level Generation: Assessing the Effect of Negative Examples in GAN Models", "link": "https://arxiv.org/abs/2410.23108", "description": "arXiv:2410.23108v1 Announce Type: new \nAbstract: Generative Adversarial Networks (GANs) are unsupervised models designed to learn and replicate a target distribution. The vanilla versions of these models can be extended to more controllable models. Conditional Generative Adversarial Networks (CGANs) extend vanilla GANs by conditioning both the generator and discriminator on some additional information (labels). Controllable models based on complementary learning, such as Rumi-GAN, have been introduced. Rumi-GANs leverage negative examples to enhance the generator's ability to learn positive examples. We evaluate the performance of two controllable GAN variants, CGAN and Rumi-GAN, in generating game levels targeting specific constraints of interest: playability and controllability. This evaluation is conducted under two scenarios: with and without the inclusion of negative examples. The goal is to determine whether incorporating negative examples helps the GAN models avoid generating undesirable outputs. Our findings highlight the strengths and weaknesses of each method in enforcing the generation of specific conditions when generating outputs based on given positive and negative examples.", "published": "2024-10-31 04:00:00", "id": "74d4e96f-91e2-41cd-9f52-974cff601979", "source": "arxiv", "section": "computerScience"}, {"title": "NASM: Neural Anisotropic Surface Meshing", "link": "https://arxiv.org/abs/2410.23109", "description": "arXiv:2410.23109v1 Announce Type: new \nAbstract: This paper introduces a new learning-based method, NASM, for anisotropic surface meshing. Our key idea is to propose a graph neural network to embed an input mesh into a high-dimensional (high-d) Euclidean embedding space to preserve curvature-based anisotropic metric by using a dot product loss between high-d edge vectors. This can dramatically reduce the computational time and increase the scalability. Then, we propose a novel feature-sensitive remeshing on the generated high-d embedding to automatically capture sharp geometric features. We define a high-d normal metric, and then derive an automatic differentiation on a high-d centroidal Voronoi tessellation (CVT) optimization with the normal metric to simultaneously preserve geometric features and curvature anisotropy that exhibit in the original 3D shapes. To our knowledge, this is the first time that a deep learning framework and a large dataset are proposed to construct a high-d Euclidean embedding space for 3D anisotropic surface meshing. Experimental results are evaluated and compared with the state-of-the-art in anisotropic surface meshing on a large number of surface models from Thingi10K dataset as well as tested on extensive unseen 3D shapes from Multi-Garment Network dataset and FAUST human dataset.", "published": "2024-10-31 04:00:00", "id": "40893234-7a0e-4a67-9e52-f61dda60328a", "source": "arxiv", "section": "computerScience"}, {"title": "Why Gradient Subspace? Identifying and Mitigating LoRA's Bottlenecks in Federated Fine-Tuning of Large Language Models", "link": "https://arxiv.org/abs/2410.23111", "description": "arXiv:2410.23111v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, particularly in task generalization for both text and vision data. While fine-tuning these models can significantly enhance their performance on specific downstream tasks, it often requires high-quality data that cannot be shared due to privacy concerns. Federated Learning (FL) offers a promising solution for collaborative training without direct data sharing. However, many parameter-efficient fine-tuning strategies for LLMs in FL, particularly those based on Low-Rank Adaptation (LoRA), face limitations. In this paper, we critically analyze the convergence and performance guarantees of popular FL frameworks utilizing LoRA, highlighting its suboptimal nature due to constrained subspace learning of low-rank matrices. This limitation hinders effective fine-tuning of LLMs in federated settings. Through rigorous analytical and empirical evaluations, we demonstrate that direct weight averaging outperforms LoRA-based strategies, leading to superior performance for fine-tuned models. Our comprehensive comparison exposes inefficiencies in LoRA approaches and underscores the advantages of full-rank weight aggregation. We extend our analysis to low-rank gradient-based optimizers, such as GaLore, used during local training steps. Our findings show that GaLore is a more effective alternative, outperforming federated LoRA methods like FlexLoRA and FFA-LoRA across both text and image modalities. While privacy remains paramount in FL discourse, our focus is on assessing performance outcomes of federated fine-tuned models and evaluating various FL frameworks from both theoretical and empirical perspectives. Our findings advocate reassessing the reliance on LoRA within FL contexts, paving the way for more efficient training methodologies.", "published": "2024-10-31 04:00:00", "id": "b377135c-2ab7-4154-9335-6a51f4651c27", "source": "arxiv", "section": "computerScience"}, {"title": "Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models", "link": "https://arxiv.org/abs/2410.23114", "description": "arXiv:2410.23114v1 Announce Type: new \nAbstract: Despite the outstanding performance in vision-language reasoning, Large Vision-Language Models (LVLMs) might generate hallucinated contents that do not exist in the given image. Most existing LVLM hallucination benchmarks are constrained to evaluate the object-related hallucinations. However, the potential hallucination on the relations between two objects, i.e., relation hallucination, still lacks investigation. To remedy that, in this paper we design a unified framework to measure object and relation hallucination in LVLMs simultaneously. The core idea of our framework is to conduct hallucination evaluation on (object, relation, object) triplets extracted from LVLMs' responses, and thus, could be easily generalized to different vision-language tasks. Based on our framework, we further introduce Tri-HE, a novel Triplet-level Hallucination Evaluation benchmark which can be used to study both object and relation hallucination at the same time. We conduct comprehensive evaluations on Tri-HE and observe that the relation hallucination issue is even more serious than object hallucination among existing LVLMs, highlighting a previously neglected problem towards reliable LVLMs. Moreover, based on our findings, we design a simple yet effective training-free approach to mitigate hallucinations for LVLMs, with which, we exceed all open-sourced counterparts on Tri-HE, achieving comparable performance with the powerful GPT-4V. Our dataset and code for the reproduction of our experiments are available publicly at https://github.com/wujunjie1998/Tri-HE.", "published": "2024-10-31 04:00:00", "id": "294bca96-446a-4953-aabc-bc30e4846ff6", "source": "arxiv", "section": "computerScience"}, {"title": "Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set", "link": "https://arxiv.org/abs/2410.23118", "description": "arXiv:2410.23118v1 Announce Type: new \nAbstract: Language models can achieve high accuracy on natural language tasks such as NLI, but performance suffers on manually created adversarial examples. We investigate the performance of a language model trained on the Stanford Natural Language Inference (SNLI) corpus on a manually created adversarial test set. We then improve the model's performance by fine tuning the model on a small, manually created adversarial training set, designed to help the language model to learn to differentiate between similar words and phrases in the data. We show an increase in accuracy on the adversarial test set (+ 13%) while still maintaining good performance on the original NLI task. We also show an increase in accuracy from 91.2% to 92.9% on the most similar contradictions in the SNLI test set (as judged by cosine similarity).", "published": "2024-10-31 04:00:00", "id": "2f4f8d3a-cd4c-4a56-989e-66688a9e848f", "source": "arxiv", "section": "computerScience"}, {"title": "On Memorization of Large Language Models in Logical Reasoning", "link": "https://arxiv.org/abs/2410.23123", "description": "arXiv:2410.23123v1 Announce Type: new \nAbstract: Large language models (LLMs) achieve good performance on challenging reasoning benchmarks, yet could also make basic reasoning mistakes. This contrasting behavior is puzzling when it comes to understanding the mechanisms behind LLMs' reasoning capabilities. One hypothesis is that the increasingly high and nearly saturated performance on common reasoning benchmarks could be due to the memorization of similar problems. In this paper, we systematically investigate this hypothesis with a quantitative measurement of memorization in reasoning tasks, using a dynamically generated logical reasoning benchmark based on Knights and Knaves (K&amp;K) puzzles. We found that LLMs could interpolate the training puzzles (achieving near-perfect accuracy) after fine-tuning, yet fail when those puzzles are slightly perturbed, suggesting that the models heavily rely on memorization to solve those training puzzles. On the other hand, we show that while fine-tuning leads to heavy memorization, it also consistently improves generalization performance. In-depth analyses with perturbation tests, cross difficulty-level transferability, probing model internals, and fine-tuning with wrong answers suggest that the LLMs learn to reason on K&amp;K puzzles despite training data memorization. This phenomenon indicates that LLMs exhibit a complex interplay between memorization and genuine reasoning abilities. Finally, our analysis with per-sample memorization score sheds light on how LLMs switch between reasoning and memorization in solving logical puzzles. Our code and data are available at https://memkklogic.github.io.", "published": "2024-10-31 04:00:00", "id": "e0d40fa0-5b75-4f04-83b0-acbf70be9120", "source": "arxiv", "section": "computerScience"}, {"title": "Educating for Hardware Specialization in the Chiplet Era: A Path for the HPC Community", "link": "https://arxiv.org/abs/2410.23127", "description": "arXiv:2410.23127v1 Announce Type: new \nAbstract: The advent of chiplet technology introduces cutting-edge opportunities for constructing highly heterogeneous platforms with specialized accelerators. However, the HPC community currently lacks expertise in hardware development, a gap that must be bridged to leverage these advancements. Additionally, technologies like chiplet is cutting-edge with limited educational resource available. This paper addresses potential hardware specialization direction in HPC and how to cultivate these skills among students and staff, emphasizing the importance of understanding and developing custom hardware (e.g., rapid prototyping and resource estimation). We have been mentoring graduate-level students and new staff in hardware designs in a hands-on manner, encouraging them to utilize modern open-source hardware tools for their designs, which facilitates the sharing of research ideas. Additionally, we provide a summary of theses tools as part of our approach to prototyping and mentoring.", "published": "2024-10-31 04:00:00", "id": "9b5fa19f-5bee-45fa-9ca3-9a7e7851858e", "source": "arxiv", "section": "computerScience"}, {"title": "Leader-Follower 3D Formation for Underwater Robots", "link": "https://arxiv.org/abs/2410.23128", "description": "arXiv:2410.23128v1 Announce Type: new \nAbstract: The schooling behavior of fish is hypothesized to confer many survival benefits, including foraging success, safety from predators, and energy savings through hydrodynamic interactions when swimming in formation. Underwater robot collectives may be able to achieve similar benefits in future applications, e.g. using formation control to achieve efficient spatial sampling for environmental monitoring. Although many theoretical algorithms exist for multi-robot formation control, they have not been tested in the underwater domain due to the fundamental challenges in underwater communication. Here we introduce a leader-follower strategy for underwater formation control that allows us to realize complex 3D formations, using purely vision-based perception and a reactive control algorithm that is low computation. We use a physical platform, BlueSwarm, to demonstrate for the first time an experimental realization of inline, side-by-side, and staggered swimming 3D formations. More complex formations are studied in a physics-based simulator, providing new insights into the convergence and stability of formations given underwater inertial/drag conditions. Our findings lay the groundwork for future applications of underwater robot swarms in aquatic environments with minimal communication.", "published": "2024-10-31 04:00:00", "id": "ec623416-e32f-4976-9547-df32f4c09bba", "source": "arxiv", "section": "computerScience"}, {"title": "Why Fine-grained Labels in Pretraining Benefit Generalization?", "link": "https://arxiv.org/abs/2410.23129", "description": "arXiv:2410.23129v1 Announce Type: new \nAbstract: Recent studies show that pretraining a deep neural network with fine-grained labeled data, followed by fine-tuning on coarse-labeled data for downstream tasks, often yields better generalization than pretraining with coarse-labeled data. While there is ample empirical evidence supporting this, the theoretical justification remains an open problem. This paper addresses this gap by introducing a \"hierarchical multi-view\" structure to confine the input data distribution. Under this framework, we prove that: 1) coarse-grained pretraining only allows a neural network to learn the common features well, while 2) fine-grained pretraining helps the network learn the rare features in addition to the common ones, leading to improved accuracy on hard downstream test samples.", "published": "2024-10-31 04:00:00", "id": "54122470-2896-4ac3-8014-74da0b04440e", "source": "arxiv", "section": "computerScience"}, {"title": "Federated Learning under Periodic Client Participation and Heterogeneous Data: A New Communication-Efficient Algorithm and Analysis", "link": "https://arxiv.org/abs/2410.23131", "description": "arXiv:2410.23131v1 Announce Type: new \nAbstract: In federated learning, it is common to assume that clients are always available to participate in training, which may not be feasible with user devices in practice. Recent works analyze federated learning under more realistic participation patterns, such as cyclic client availability or arbitrary participation. However, all such works either require strong assumptions (e.g., all clients participate almost surely within a bounded window), do not achieve linear speedup and reduced communication rounds, or are not applicable in the general non-convex setting. In this work, we focus on nonconvex optimization and consider participation patterns in which the chance of participation over a fixed window of rounds is equal among all clients, which includes cyclic client availability as a special case. Under this setting, we propose a new algorithm, named Amplified SCAFFOLD, and prove that it achieves linear speedup, reduced communication, and resilience to data heterogeneity simultaneously. In particular, for cyclic participation, our algorithm is proved to enjoy $\\mathcal{O}(\\epsilon^{-2})$ communication rounds to find an $\\epsilon$-stationary point in the non-convex stochastic setting. In contrast, the prior work under the same setting requires $\\mathcal{O}(\\kappa^2 \\epsilon^{-4})$ communication rounds, where $\\kappa$ denotes the data heterogeneity. Therefore, our algorithm significantly reduces communication rounds due to better dependency in terms of $\\epsilon$ and $\\kappa$. Our analysis relies on a fine-grained treatment of the nested dependence between client participation and errors in the control variates, which results in tighter guarantees than previous work. We also provide experimental results with (1) synthetic data and (2) real-world data with a large number of clients $(N = 250)$, demonstrating the effectiveness of our algorithm under periodic client participation.", "published": "2024-10-31 04:00:00", "id": "59abf61e-af5b-4c61-8fc8-d12f1d0b85cd", "source": "arxiv", "section": "computerScience"}, {"title": "Revisiting MAE pre-training for 3D medical image segmentation", "link": "https://arxiv.org/abs/2410.23132", "description": "arXiv:2410.23132v1 Announce Type: new \nAbstract: Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the potential of vast, untapped clinical datasets, for various downstream applications that suffer from the scarcity of labeled data. While SSL has revolutionized fields like natural language processing and computer vision, their adoption in 3D medical image computing has been limited by three key pitfalls: Small pre-training dataset sizes, architectures inadequate for 3D medical image analysis, and insufficient evaluation practices. We address these issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and ii) using a Residual Encoder U-Net architecture within the state-of-the-art nnU-Net framework. iii) A robust development framework, incorporating 5 development and 8 testing brain MRI segmentation datasets, allowed performance-driven design decisions to optimize the simple concept of Masked Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses previous SSL methods but also outperforms the strong nnU-Net baseline by an average of approximately 3 Dice points. Furthermore, our model demonstrates exceptional stability, achieving the highest average rank of 2 out of 7 methods, compared to the second-best method's mean rank of 3.", "published": "2024-10-31 04:00:00", "id": "7f7490f8-36b7-4c0c-8951-580bb975b929", "source": "arxiv", "section": "computerScience"}, {"title": "Crowdsourcing Lexical Diversity", "link": "https://arxiv.org/abs/2410.23133", "description": "arXiv:2410.23133v1 Announce Type: new \nAbstract: Lexical-semantic resources (LSRs), such as online lexicons or wordnets, are fundamental for natural language processing applications. In many languages, however, such resources suffer from quality issues: incorrect entries, incompleteness, but also, the rarely addressed issue of bias towards the English language and Anglo-Saxon culture. Such bias manifests itself in the absence of concepts specific to the language or culture at hand, the presence of foreign (Anglo-Saxon) concepts, as well as in the lack of an explicit indication of untranslatability, also known as cross-lingual \\emph{lexical gaps}, when a term has no equivalent in another language. This paper proposes a novel crowdsourcing methodology for reducing bias in LSRs. Crowd workers compare lexemes from two languages, focusing on domains rich in lexical diversity, such as kinship or food. Our LingoGap crowdsourcing tool facilitates comparisons through microtasks identifying equivalent terms, language-specific terms, and lexical gaps across languages. We validated our method by applying it to two case studies focused on food-related terminology: (1) English and Arabic, and (2) Standard Indonesian and Banjarese. These experiments identified 2,140 lexical gaps in the first case study and 951 in the second. The success of these experiments confirmed the usability of our method and tool for future large-scale lexicon enrichment tasks.", "published": "2024-10-31 04:00:00", "id": "bf5e751b-a82f-4a38-91bb-4e250a64be37", "source": "arxiv", "section": "computerScience"}, {"title": "Real-Time Personalization for LLM-based Recommendation with Customized In-Context Learning", "link": "https://arxiv.org/abs/2410.23136", "description": "arXiv:2410.23136v1 Announce Type: new \nAbstract: Frequently updating Large Language Model (LLM)-based recommender systems to adapt to new user interests -- as done for traditional ones -- is impractical due to high training costs, even with acceleration methods. This work explores adapting to dynamic user interests without any model updates by leveraging In-Context Learning (ICL), which allows LLMs to learn new tasks from few-shot examples provided in the input. Using new-interest examples as the ICL few-shot examples, LLMs may learn real-time interest directly, avoiding the need for model updates. However, existing LLM-based recommenders often lose the in-context learning ability during recommendation tuning, while the original LLM's in-context learning lacks recommendation-specific focus. To address this, we propose RecICL, which customizes recommendation-specific in-context learning for real-time recommendations. RecICL organizes training examples in an in-context learning format, ensuring that in-context learning ability is preserved and aligned with the recommendation task during tuning.\n  Extensive experiments demonstrate RecICL's effectiveness in delivering real-time recommendations without requiring model updates. Our code is available at https://github.com/ym689/rec_icl.", "published": "2024-10-31 04:00:00", "id": "60ca64c6-dd64-4bcf-ad7d-a3fb6b50fb63", "source": "arxiv", "section": "computerScience"}, {"title": "Fair Division with Market Values", "link": "https://arxiv.org/abs/2410.23137", "description": "arXiv:2410.23137v1 Announce Type: new \nAbstract: We introduce a model of fair division with market values, where indivisible goods must be partitioned among agents with (additive) subjective valuations, and each good additionally has a market value. The market valuation can be viewed as a separate additive valuation that holds identically across all the agents. We seek allocations that are simultaneously fair with respect to the subjective valuations and with respect to the market valuation.\n  We show that an allocation that satisfies stochastically-dominant envy-freeness up to one good (SD-EF1) with respect to both the subjective valuations and the market valuation does not always exist, but the weaker guarantee of EF1 with respect to the subjective valuations along with SD-EF1 with respect to the market valuation can be guaranteed. We also study a number of other guarantees such as Pareto optimality, EFX, and MMS. In addition, we explore non-additive valuations and extend our model to cake-cutting. Along the way, we identify several tantalizing open questions.", "published": "2024-10-31 04:00:00", "id": "c96eb05c-6183-4b51-b473-af46fadd1b53", "source": "arxiv", "section": "computerScience"}, {"title": "FAIR-TAT: Improving Model Fairness Using Targeted Adversarial Training", "link": "https://arxiv.org/abs/2410.23142", "description": "arXiv:2410.23142v1 Announce Type: new \nAbstract: Deep neural networks are susceptible to adversarial attacks and common corruptions, which undermine their robustness. In order to enhance model resilience against such challenges, Adversarial Training (AT) has emerged as a prominent solution. Nevertheless, adversarial robustness is often attained at the expense of model fairness during AT, i.e., disparity in class-wise robustness of the model. While distinctive classes become more robust towards such adversaries, hard to detect classes suffer. Recently, research has focused on improving model fairness specifically for perturbed images, overlooking the accuracy of the most likely non-perturbed data. Additionally, despite their robustness against the adversaries encountered during model training, state-of-the-art adversarial trained models have difficulty maintaining robustness and fairness when confronted with diverse adversarial threats or common corruptions. In this work, we address the above concerns by introducing a novel approach called Fair Targeted Adversarial Training (FAIR-TAT). We show that using targeted adversarial attacks for adversarial training (instead of untargeted attacks) can allow for more favorable trade-offs with respect to adversarial fairness. Empirical results validate the efficacy of our approach.", "published": "2024-10-31 04:00:00", "id": "07eb838a-4146-499d-ad5f-b617f5d47e6f", "source": "arxiv", "section": "computerScience"}, {"title": "The Good, the Bad, and the Ugly: The Role of AI Quality Disclosure in Lie Detection", "link": "https://arxiv.org/abs/2410.23143", "description": "arXiv:2410.23143v1 Announce Type: new \nAbstract: We investigate how low-quality AI advisors, lacking quality disclosures, can help spread text-based lies while seeming to help people detect lies. Participants in our experiment discern truth from lies by evaluating transcripts from a game show that mimicked deceptive social media exchanges on topics with objective truths. We find that when relying on low-quality advisors without disclosures, participants' truth-detection rates fall below their own abilities, which recovered once the AI's true effectiveness was revealed. Conversely, high-quality advisor enhances truth detection, regardless of disclosure. We discover that participants' expectations about AI capabilities contribute to their undue reliance on opaque, low-quality advisors.", "published": "2024-10-31 04:00:00", "id": "a0139e53-c30f-487e-abe5-93dde881e4ba", "source": "arxiv", "section": "computerScience"}, {"title": "Public Domain 12M: A Highly Aesthetic Image-Text Dataset with Novel Governance Mechanisms", "link": "https://arxiv.org/abs/2410.23144", "description": "arXiv:2410.23144v1 Announce Type: new \nAbstract: We present Public Domain 12M (PD12M), a dataset of 12.4 million high-quality public domain and CC0-licensed images with synthetic captions, designed for training text-to-image models. PD12M is the largest public domain image-text dataset to date, with sufficient size to train foundation models while minimizing copyright concerns. Through the Source.Plus platform, we also introduce novel, community-driven dataset governance mechanisms that reduce harm and support reproducibility over time.", "published": "2024-10-31 04:00:00", "id": "c0b8479a-3982-434a-b8c6-59974bfc2774", "source": "arxiv", "section": "computerScience"}, {"title": "FoLDTree: A ULDA-Based Decision Tree Framework for Efficient Oblique Splits and Feature Selection", "link": "https://arxiv.org/abs/2410.23147", "description": "arXiv:2410.23147v1 Announce Type: new \nAbstract: Traditional decision trees are limited by axis-orthogonal splits, which can perform poorly when true decision boundaries are oblique. While oblique decision tree methods address this limitation, they often face high computational costs, difficulties with multi-class classification, and a lack of effective feature selection. In this paper, we introduce LDATree and FoLDTree, two novel frameworks that integrate Uncorrelated Linear Discriminant Analysis (ULDA) and Forward ULDA into a decision tree structure. These methods enable efficient oblique splits, handle missing values, support feature selection, and provide both class labels and probabilities as model outputs. Through evaluations on simulated and real-world datasets, LDATree and FoLDTree consistently outperform axis-orthogonal and other oblique decision tree methods, achieving accuracy levels comparable to the random forest. The results highlight the potential of these frameworks as robust alternatives to traditional single-tree methods.", "published": "2024-10-31 04:00:00", "id": "226ed20c-7669-4576-9dc5-cbf6bae2d481", "source": "arxiv", "section": "computerScience"}, {"title": "HiBO: Hierarchical Bayesian Optimization via Adaptive Search Space Partitioning", "link": "https://arxiv.org/abs/2410.23148", "description": "arXiv:2410.23148v1 Announce Type: new \nAbstract: Optimizing black-box functions in high-dimensional search spaces has been known to be challenging for traditional Bayesian Optimization (BO). In this paper, we introduce HiBO, a novel hierarchical algorithm integrating global-level search space partitioning information into the acquisition strategy of a local BO-based optimizer. HiBO employs a search-tree-based global-level navigator to adaptively split the search space into partitions with different sampling potential. The local optimizer then utilizes this global-level information to guide its acquisition strategy towards most promising regions within the search space. A comprehensive set of evaluations demonstrates that HiBO outperforms state-of-the-art methods in high-dimensional synthetic benchmarks and presents significant practical effectiveness in the real-world task of tuning configurations of database management systems (DBMSs).", "published": "2024-10-31 04:00:00", "id": "2e3392c9-ce84-427f-b504-851cfc727034", "source": "arxiv", "section": "computerScience"}, {"title": "QWO: Speeding Up Permutation-Based Causal Discovery in LiGAMs", "link": "https://arxiv.org/abs/2410.23155", "description": "arXiv:2410.23155v1 Announce Type: new \nAbstract: Causal discovery is essential for understanding relationships among variables of interest in many scientific domains. In this paper, we focus on permutation-based methods for learning causal graphs in Linear Gaussian Acyclic Models (LiGAMs), where the permutation encodes a causal ordering of the variables. Existing methods in this setting are not scalable due to their high computational complexity. These methods are comprised of two main components: (i) constructing a specific DAG, $\\mathcal{G}^\\pi$, for a given permutation $\\pi$, which represents the best structure that can be learned from the available data while adhering to $\\pi$, and (ii) searching over the space of permutations (i.e., causal orders) to minimize the number of edges in $\\mathcal{G}^\\pi$. We introduce QWO, a novel approach that significantly enhances the efficiency of computing $\\mathcal{G}^\\pi$ for a given permutation $\\pi$. QWO has a speed-up of $O(n^2)$ ($n$ is the number of variables) compared to the state-of-the-art BIC-based method, making it highly scalable. We show that our method is theoretically sound and can be integrated into existing search strategies such as GRASP and hill-climbing-based methods to improve their performance.", "published": "2024-10-31 04:00:00", "id": "53a48439-b952-4c5a-86dc-1fcbe7b01873", "source": "arxiv", "section": "computerScience"}, {"title": "VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning", "link": "https://arxiv.org/abs/2410.23156", "description": "arXiv:2410.23156v1 Announce Type: new \nAbstract: Broadly intelligent agents should form task-specific abstractions that selectively expose the essential elements of a task, while abstracting away the complexity of the raw sensorimotor space. In this work, we present Neuro-Symbolic Predicates, a first-order abstraction language that combines the strengths of symbolic and neural knowledge representations. We outline an online algorithm for inventing such predicates and learning abstract world models. We compare our approach to hierarchical reinforcement learning, vision-language model planning, and symbolic predicate invention approaches, on both in- and out-of-distribution tasks across five simulated robotic domains. Results show that our approach offers better sample complexity, stronger out-of-distribution generalization, and improved interpretability.", "published": "2024-10-31 04:00:00", "id": "5226c184-8c06-4001-9766-27a44ec7936a", "source": "arxiv", "section": "computerScience"}, {"title": "Directional anomaly detection", "link": "https://arxiv.org/abs/2410.23158", "description": "arXiv:2410.23158v1 Announce Type: new \nAbstract: Semi-supervised anomaly detection is based on the principle that potential anomalies are those records that look different from normal training data. However, in some cases we are specifically interested in anomalies that correspond to high attribute values (or low, but not both). We present two asymmetrical distance measures that take this directionality into account: ramp distance and signed distance. Through experiments on synthetic and real-life datasets we show that ramp distance performs as well or better than the absolute distance traditionally used in anomaly detection. While signed distance also performs well on synthetic data, it performs substantially poorer on real-life datasets. We argue that this reflects the fact that in practice, good scores on some attributes should not be allowed to compensate for bad scores on others.", "published": "2024-10-31 04:00:00", "id": "f69b732d-1f0b-40e2-8bb7-1c9b64fba83b", "source": "arxiv", "section": "computerScience"}, {"title": "Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting", "link": "https://arxiv.org/abs/2410.23159", "description": "arXiv:2410.23159v1 Announce Type: new \nAbstract: Deep learning approaches have been widely adopted for precipitation nowcasting in recent years. Previous studies mainly focus on proposing new model architectures to improve pixel-wise metrics. However, they frequently result in blurry predictions which provide limited utility to forecasting operations. In this work, we propose a new Fourier Amplitude and Correlation Loss (FACL) which consists of two novel loss terms: Fourier Amplitude Loss (FAL) and Fourier Correlation Loss (FCL). FAL regularizes the Fourier amplitude of the model prediction and FCL complements the missing phase information. The two loss terms work together to replace the traditional $L_2$ losses such as MSE and weighted MSE for the spatiotemporal prediction problem on signal-based data. Our method is generic, parameter-free and efficient. Extensive experiments using one synthetic dataset and three radar echo datasets demonstrate that our method improves perceptual metrics and meteorology skill scores, with a small trade-off to pixel-wise accuracy and structural similarity. Moreover, to improve the error margin in meteorological skill scores such as Critical Success Index (CSI) and Fractions Skill Score (FSS), we propose and adopt the Regional Histogram Divergence (RHD), a distance metric that considers the patch-wise similarity between signal-based imagery patterns with tolerance to local transforms. Code is available at https://github.com/argenycw/FACL", "published": "2024-10-31 04:00:00", "id": "64d8994c-0d65-4b94-bd50-cd7e924a07b1", "source": "arxiv", "section": "computerScience"}, {"title": "FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities", "link": "https://arxiv.org/abs/2410.23160", "description": "arXiv:2410.23160v1 Announce Type: new \nAbstract: Developing a foundation model for time series forecasting across diverse domains has attracted significant attention in recent years. Existing works typically assume regularly sampled, well-structured data, limiting their applicability to more generalized scenarios where time series often contain missing values, unequal sequence lengths, and irregular time intervals between measurements. To cover diverse domains and handle variable regularities, we propose FlexTSF, a universal time series forecasting model that possesses better generalization and natively support both regular and irregular time series. FlexTSF produces forecasts in an autoregressive manner and incorporates three novel designs: VT-Norm, a normalization strategy to ablate data domain barriers, IVP Patcher, a patching module to learn representations from flexibly structured time series, and LED attention, an attention mechanism to seamlessly integrate these two and propagate forecasts with awareness of domain and time information. Experiments on 12 datasets show that FlexTSF outperforms state-of-the-art forecasting models respectively designed for regular and irregular time series. Furthermore, after self-supervised pre-training, FlexTSF shows exceptional performance in both zero-shot and few-show settings for time series forecasting.", "published": "2024-10-31 04:00:00", "id": "81c91cc8-09a3-4483-8119-6e35b2310caf", "source": "arxiv", "section": "computerScience"}, {"title": "Energy-Efficient Intra-Domain Network Slicing for Multi-Layer Orchestration in Intelligent-Driven Distributed 6G Networks: Learning Generic Assignment Skills with Unsupervised Reinforcement Learning", "link": "https://arxiv.org/abs/2410.23161", "description": "arXiv:2410.23161v1 Announce Type: new \nAbstract: Since the 6th Generation (6G) of wireless networks is expected to provide a new level of network services and meet the emerging expectations of the future, it will be a complex and intricate networking system. 6Gs sophistication and robustness will be accompanied by complexities, which will require novel strategies to tackle them. This research work focuses on decentralized and multi-level system models for 6G networks and proposes an energy efficient automation strategy for edge domain management and Network Slicing (NS) with the main objective of reducing the networks complexity by leveraging scalability, efficiency, and generalization. Accordingly, we propose a pre-train phase to discover useful assignment skills in network edge domains by utilizing unsupervised Reinforcement Learning (unsupervised RL). The suggested technique does not depend on the domain specifications and thus is applicable to all the edge domains. Our proposed approach not only enables scalability and decentralization, but it also delivers efficiency by assisting domain controllers to provide various service types. We implemented the pre-training phase, and monitored that the discovered assignment skills span the entire interval of possible resource assignment portions for every service type.", "published": "2024-10-31 04:00:00", "id": "3f3d4443-7837-4698-8e66-61257fa1ac42", "source": "arxiv", "section": "computerScience"}, {"title": "SciPIP: An LLM-based Scientific Paper Idea Proposer", "link": "https://arxiv.org/abs/2410.23166", "description": "arXiv:2410.23166v1 Announce Type: new \nAbstract: The exponential growth of knowledge and the increasing complexity of interdisciplinary research pose significant challenges for researchers, including information overload and difficulties in exploring novel ideas. The advancements in large language models (LLMs), such as GPT-4, have shown great potential in enhancing idea proposals, but how to effectively utilize large models for reasonable idea proposal has not been thoroughly explored. This paper proposes a scientific paper idea proposer (SciPIP). Based on a user-provided research background, SciPIP retrieves helpful papers from a literature database while leveraging the capabilities of LLMs to generate more novel and feasible ideas. To this end, 1) we construct a literature retrieval database, extracting lots of papers' multi-dimension information for fast access. Then, a literature retrieval method based on semantics, entity, and citation co-occurrences is proposed to search relevant literature from multiple aspects based on the user-provided background. 2) After literature retrieval, we introduce dual-path idea proposal strategies, where one path infers solutions from the retrieved literature and the other path generates original ideas through model brainstorming. We then combine the two to achieve a good balance between feasibility and originality. Through extensive experiments on the natural language processing (NLP) field, we demonstrate that SciPIP can retrieve citations similar to those of existing top conference papers and generate many ideas consistent with them. Additionally, we evaluate the originality of other ideas generated by SciPIP using large language models, further validating the effectiveness of our proposed method. The code and the database are released at https://github.com/cheerss/SciPIP.", "published": "2024-10-31 04:00:00", "id": "10a0ee92-f670-427f-b88f-fbb341b9a6a0", "source": "arxiv", "section": "computerScience"}, {"title": "TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters", "link": "https://arxiv.org/abs/2410.23168", "description": "arXiv:2410.23168v1 Announce Type: new \nAbstract: Transformers have become the predominant architecture in foundation models due to their excellent performance across various domains. However, the substantial cost of scaling these models remains a significant concern. This problem arises primarily from their dependence on a fixed number of parameters within linear projections. When architectural modifications (e.g., channel dimensions) are introduced, the entire model typically requires retraining from scratch. As model sizes continue growing, this strategy results in increasingly high computational costs and becomes unsustainable. To overcome this problem, we introduce TokenFormer, a natively scalable architecture that leverages the attention mechanism not only for computations among input tokens but also for interactions between tokens and model parameters, thereby enhancing architectural flexibility. By treating model parameters as tokens, we replace all the linear projections in Transformers with our token-parameter attention layer, where input tokens act as queries and model parameters as keys and values. This reformulation allows for progressive and efficient scaling without necessitating retraining from scratch. Our model scales from 124M to 1.4B parameters by incrementally adding new key-value parameter pairs, achieving performance comparable to Transformers trained from scratch while greatly reducing training costs. Code and models are available at \\url{https://github.com/Haiyang-W/TokenFormer}.", "published": "2024-10-31 04:00:00", "id": "d66cbc80-bd7f-4f42-95a2-9f84327ed31e", "source": "arxiv", "section": "computerScience"}, {"title": "The Persistence of Neural Collapse Despite Low-Rank Bias: An Analytic Perspective Through Unconstrained Features", "link": "https://arxiv.org/abs/2410.23169", "description": "arXiv:2410.23169v1 Announce Type: new \nAbstract: Modern deep neural networks have been observed to exhibit a simple structure in their final layer features and weights, commonly referred to as neural collapse. This phenomenon has also been noted in layers beyond the final one, an extension known as deep neural collapse. Recent findings indicate that such a structure is generally not optimal in the deep unconstrained feature model, an approximation of an expressive network. This is attributed to a low-rank bias induced by regularization, which favors solutions with lower-rank than those typically associated with deep neural collapse. In this work, we extend these observations to the cross-entropy loss and analyze how the low-rank bias influences various solutions. Additionally, we explore how this bias induces specific structures in the singular values of the weights at global optima. Furthermore, we examine the loss surface of these models and provide evidence that the frequent observation of deep neural collapse in practice, despite its suboptimality, may result from its higher degeneracy on the loss surface.", "published": "2024-10-31 04:00:00", "id": "fd9ff8ec-1b76-4477-af27-643a7730babb", "source": "arxiv", "section": "computerScience"}, {"title": "Does equivariance matter at scale?", "link": "https://arxiv.org/abs/2410.23179", "description": "arXiv:2410.23179v1 Announce Type: new \nAbstract: Given large data sets and sufficient compute, is it beneficial to design neural architectures for the structure and symmetries of each problem? Or is it more efficient to learn them from data? We study empirically how equivariant and non-equivariant networks scale with compute and training samples. Focusing on a benchmark problem of rigid-body interactions and on general-purpose transformer architectures, we perform a series of experiments, varying the model size, training steps, and dataset size. We find evidence for three conclusions. First, equivariance improves data efficiency, but training non-equivariant models with data augmentation can close this gap given sufficient epochs. Second, scaling with compute follows a power law, with equivariant models outperforming non-equivariant ones at each tested compute budget. Finally, the optimal allocation of a compute budget onto model size and training duration differs between equivariant and non-equivariant models.", "published": "2024-10-31 04:00:00", "id": "feff973a-8bf8-4d7e-b098-3c05f3b9b2df", "source": "arxiv", "section": "computerScience"}, {"title": "ReasoningRec: Bridging Personalized Recommendations and Human-Interpretable Explanations through LLM Reasoning", "link": "https://arxiv.org/abs/2410.23180", "description": "arXiv:2410.23180v1 Announce Type: new \nAbstract: This paper presents ReasoningRec, a reasoning-based recommendation framework that leverages Large Language Models (LLMs) to bridge the gap between recommendations and human-interpretable explanations. In contrast to conventional recommendation systems that rely on implicit user-item interactions, ReasoningRec employs LLMs to model users and items, focusing on preferences, aversions, and explanatory reasoning. The framework utilizes a larger LLM to generate synthetic explanations for user preferences, subsequently used to fine-tune a smaller LLM for enhanced recommendation accuracy and human-interpretable explanation. Our experimental study investigates the impact of reasoning and contextual information on personalized recommendations, revealing that the quality of contextual and personalized data significantly influences the LLM's capacity to generate plausible explanations. Empirical evaluations demonstrate that ReasoningRec surpasses state-of-the-art methods by up to 12.5\\% in recommendation prediction while concurrently providing human-intelligible explanations. The code is available here: https://github.com/millenniumbismay/reasoningrec.", "published": "2024-10-31 04:00:00", "id": "5bd86da5-a772-48be-9419-154637b4aa8c", "source": "arxiv", "section": "computerScience"}, {"title": "ProTransformer: Robustify Transformers via Plug-and-Play Paradigm", "link": "https://arxiv.org/abs/2410.23182", "description": "arXiv:2410.23182v1 Announce Type: new \nAbstract: Transformer-based architectures have dominated various areas of machine learning in recent years. In this paper, we introduce a novel robust attention mechanism designed to enhance the resilience of transformer-based architectures. Crucially, this technique can be integrated into existing transformers as a plug-and-play layer, improving their robustness without the need for additional training or fine-tuning. Through comprehensive experiments and ablation studies, we demonstrate that our ProTransformer significantly enhances the robustness of transformer models across a variety of prediction tasks, attack mechanisms, backbone architectures, and data domains. Notably, without further fine-tuning, the ProTransformer consistently improves the performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT, ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler attack. Furthermore, ProTransformer shows promising resilience in large language models (LLMs) against prompting-based attacks, improving the performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the language domain, ProTransformer also demonstrates outstanding robustness in both vision and graph domains.", "published": "2024-10-31 04:00:00", "id": "e7db860e-3812-4e20-8f41-328b1ed0d307", "source": "arxiv", "section": "computerScience"}, {"title": "Reliability of Topic Modeling", "link": "https://arxiv.org/abs/2410.23186", "description": "arXiv:2410.23186v1 Announce Type: new \nAbstract: Topic models allow researchers to extract latent factors from text data and use those variables in downstream statistical analyses. However, these methodologies can vary significantly due to initialization differences, randomness in sampling procedures, or noisy data. Reliability of these methods is of particular concern as many researchers treat learned topic models as ground truth for subsequent analyses. In this work, we show that the standard practice for quantifying topic model reliability fails to capture essential aspects of the variation in two widely-used topic models. Drawing from a extensive literature on measurement theory, we provide empirical and theoretical analyses of three other metrics for evaluating the reliability of topic models. On synthetic and real-world data, we show that McDonald's $\\omega$ provides the best encapsulation of reliability. This metric provides an essential tool for validation of topic model methodologies that should be a standard component of any topic model-based research.", "published": "2024-10-31 04:00:00", "id": "0088e2cb-737b-47d9-acc8-df1c453cd51f", "source": "arxiv", "section": "computerScience"}, {"title": "Explorable Parity Automata", "link": "https://arxiv.org/abs/2410.23187", "description": "arXiv:2410.23187v1 Announce Type: new \nAbstract: We define the class of explorable automata on finite or infinite words. This is a generalization of History-Deterministic (HD) automata, where this time non-deterministic choices can be resolved by building finitely many simultaneous runs instead of just one. We show that recognizing HD parity automata of fixed index among explorable ones is in PTime, thereby giving a strong link between the two notions. We then show that recognizing explorable automata is ExpTime-complete, in the case of finite words or parity automata up to index [0, 2]. Additionally, we define the notion of {\\omega}-explorable automata on infinite words, where countably many runs can be used to resolve the non-deterministic choices. We show ExpTime-completeness for {\\omega}-explorability of automata on infinite words for the safety and coB\\\"uchi acceptance conditions. We finally characterize the expressivity of ({\\omega}-)explorable automata with respect to the parity index hierarchy.", "published": "2024-10-31 04:00:00", "id": "c1a97d79-c75d-4bdc-95fa-047e2206b8d3", "source": "arxiv", "section": "computerScience"}, {"title": "Continuous Spatio-Temporal Memory Networks for 4D Cardiac Cine MRI Segmentation", "link": "https://arxiv.org/abs/2410.23191", "description": "arXiv:2410.23191v1 Announce Type: new \nAbstract: Current cardiac cine magnetic resonance image (cMR) studies focus on the end diastole (ED) and end systole (ES) phases, while ignoring the abundant temporal information in the whole image sequence. This is because whole sequence segmentation is currently a tedious process and inaccurate. Conventional whole sequence segmentation approaches first estimate the motion field between frames, which is then used to propagate the mask along the temporal axis. However, the mask propagation results could be prone to error, especially for the basal and apex slices, where through-plane motion leads to significant morphology and structural change during the cardiac cycle. Inspired by recent advances in video object segmentation (VOS), based on spatio-temporal memory (STM) networks, we propose a continuous STM (CSTM) network for semi-supervised whole heart and whole sequence cMR segmentation. Our CSTM network takes full advantage of the spatial, scale, temporal and through-plane continuity prior of the underlying heart anatomy structures, to achieve accurate and fast 4D segmentation. Results of extensive experiments across multiple cMR datasets show that our method can improve the 4D cMR segmentation performance, especially for the hard-to-segment regions.", "published": "2024-10-31 04:00:00", "id": "1b0aa0e2-4e5f-4267-a661-93a1caa9c23c", "source": "arxiv", "section": "computerScience"}, {"title": "ReaWristic: Remote Touch Sensation to Fingers from a Wristband via Visually Augmented Electro-Tactile Feedback", "link": "https://arxiv.org/abs/2410.23193", "description": "arXiv:2410.23193v1 Announce Type: new \nAbstract: We present a technique for providing remote tactile feedback to the thumb and index finger via a wristband device. This enables haptics for touch and pinch interactions in mixed reality (MR) while keeping the hand entirely free. We achieve this through a novel cross-modal stimulation, which we term visually augmented electro-tactile feedback. This consists of (1) electrically stimulating the nerves that innervate the targeted fingers using our wristband device and (2) concurrently, visually augmenting the targeted finger in MR to steer the perceived sensation to the desired location. In our psychophysics study, we found that our approach provides tactile perception akin to tapping and, even from the wrist, it is capable of delivering the sensation to the targeted fingers with about 50% of sensation occurring in the thumb and about 40% of sensation occurring in the index finger. These results on localizability are unprecedented compared to electro-tactile feedback alone or any prior work for creating sensations in the hand with devices worn on the wrist/arm. Moreover, unlike conventional electro-tactile techniques, our wristband dispenses with gel electrodes. Instead, it incorporates custom-made elastomer-based dry electrodes and a stimulation waveform designed for the electrodes, ensuring the practicality of the device beyond laboratory settings. Lastly, we evaluated the haptic realism of our approach in mixed reality and elicited qualitative feedback from users. Participants preferred our approach to a baseline vibrotactile wrist-worn device.", "published": "2024-10-31 04:00:00", "id": "02604925-8e04-4a40-abe0-5ce88d051da6", "source": "arxiv", "section": "computerScience"}, {"title": "HEX: Hierarchical Emergence Exploitation in Self-Supervised Algorithms", "link": "https://arxiv.org/abs/2410.23200", "description": "arXiv:2410.23200v1 Announce Type: new \nAbstract: In this paper, we propose an algorithm that can be used on top of a wide variety of self-supervised (SSL) approaches to take advantage of hierarchical structures that emerge during training. SSL approaches typically work through some invariance term to ensure consistency between similar samples and a regularization term to prevent global dimensional collapse. Dimensional collapse refers to data representations spanning a lower-dimensional subspace. Recent work has demonstrated that the representation space of these algorithms gradually reflects a semantic hierarchical structure as training progresses. Data samples of the same hierarchical grouping tend to exhibit greater dimensional collapse locally compared to the dataset as a whole due to sharing features in common with each other. Ideally, SSL algorithms would take advantage of this hierarchical emergence to have an additional regularization term to account for this local dimensional collapse effect. However, the construction of existing SSL algorithms does not account for this property. To address this, we propose an adaptive algorithm that performs a weighted decomposition of the denominator of the InfoNCE loss into two terms: local hierarchical and global collapse regularization respectively. This decomposition is based on an adaptive threshold that gradually lowers to reflect the emerging hierarchical structure of the representation space throughout training. It is based on an analysis of the cosine similarity distribution of samples in a batch. We demonstrate that this hierarchical emergence exploitation (HEX) approach can be integrated across a wide variety of SSL algorithms. Empirically, we show performance improvements of up to 5.6% relative improvement over baseline SSL approaches on classification accuracy on Imagenet with 100 epochs of training.", "published": "2024-10-31 04:00:00", "id": "1c7b626d-4f01-44b5-bf3f-f0bb8679709a", "source": "arxiv", "section": "computerScience"}, {"title": "Resilient-By-Design: A Resiliency Framework for Future Wireless Networks", "link": "https://arxiv.org/abs/2410.23203", "description": "arXiv:2410.23203v1 Announce Type: new \nAbstract: Our future society will be increasingly digitalised, hyper-connected and globally data driven. The sixth generation (6G) and beyond 6G wireless networks are expected to bridge the digital and physical worlds by providing wireless connectivity as a service to different vertical sectors, including industries, smart cities, eHealth and autonomous transportation. Such far reaching integration will render the society increasingly reliant on wireless networks. While this has the potential to greatly enhance our quality and ease of life, any disruption to these networks would also have significant impact with overreaching consequences. Disruptions can happen due to a variety of reasons, including planned outages, failures due to the nature of wireless propagation, natural disasters, and deliberate cybersecurity attacks. Hence, 6G and beyond 6G networks should not only provide near instant and virtually unlimited connectivity, but also be resilient against internal and external disruptions. This paper proposes a resilient-by-design framework towards this end. First, we provide an overview of the disruption landscape. Thereafter, we comprehensively outline the main features of the proposed concept. Finally, we detail the four key steps of the framework, namely predict, preempt, protect and progress. A simple but illustrative preliminary simulation result is also presented to highlight the potential advantages and efficiency of the proposed approach in addressing outages.", "published": "2024-10-31 04:00:00", "id": "ac90ff03-9be3-4bd6-b1c6-63371ff497dd", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Autonomous Driving Safety Analysis with Generative AI: A Comparative Study on Automated Hazard and Risk Assessment", "link": "https://arxiv.org/abs/2410.23207", "description": "arXiv:2410.23207v1 Announce Type: new \nAbstract: The advent of autonomous driving technology has accentuated the need for comprehensive hazard analysis and risk assessment (HARA) to ensure the safety and reliability of vehicular systems. Traditional HARA processes, while meticulous, are inherently time-consuming and subject to human error, necessitating a transformative approach to fortify safety engineering. This paper presents an integrative application of generative artificial intelligence (AI) as a means to enhance HARA in autonomous driving safety analysis. Generative AI, renowned for its predictive modeling and data generation capabilities, is leveraged to automate the labor-intensive elements of HARA, thus expediting the process and augmenting the thoroughness of the safety analyses. Through empirical research, the study contrasts conventional HARA practices conducted by safety experts with those supplemented by generative AI tools. The benchmark comparisons focus on critical metrics such as analysis time, error rates, and scope of risk identification. By employing generative AI, the research demonstrates a significant upturn in efficiency, evidenced by reduced timeframes and expanded analytical coverage. The AI-augmented processes also deliver enhanced brainstorming support, stimulating creative problem-solving and identifying previously unrecognized risk factors.", "published": "2024-10-31 04:00:00", "id": "ae2d4628-5cd6-4398-b94f-7983c88b6cad", "source": "arxiv", "section": "computerScience"}, {"title": "Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks", "link": "https://arxiv.org/abs/2410.23208", "description": "arXiv:2410.23208v1 Announce Type: new \nAbstract: While large models trained with self-supervised learning on offline datasets have shown remarkable capabilities in text and image domains, achieving the same generalisation for agents that act in sequential decision problems remains an open challenge. In this work, we take a step towards this goal by procedurally generating tens of millions of 2D physics-based tasks and using these to train a general reinforcement learning (RL) agent for physical control. To this end, we introduce Kinetix: an open-ended space of physics-based RL environments that can represent tasks ranging from robotic locomotion and grasping to video games and classic RL environments, all within a unified framework. Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training. Our trained agent exhibits strong physical reasoning capabilities, being able to zero-shot solve unseen human-designed environments. Furthermore, fine-tuning this general agent on tasks of interest shows significantly stronger performance than training an RL agent *tabula rasa*. This includes solving some environments that standard RL training completely fails at. We believe this demonstrates the feasibility of large scale, mixed-quality pre-training for online RL and we hope that Kinetix will serve as a useful framework to investigate this further.", "published": "2024-10-31 04:00:00", "id": "837e05fc-ae63-43af-853b-29b9032c8d12", "source": "arxiv", "section": "computerScience"}, {"title": "ELMGS: Enhancing memory and computation scaLability through coMpression for 3D Gaussian Splatting", "link": "https://arxiv.org/abs/2410.23213", "description": "arXiv:2410.23213v1 Announce Type: new \nAbstract: 3D models have recently been popularized by the potentiality of end-to-end training offered first by Neural Radiance Fields and most recently by 3D Gaussian Splatting models. The latter has the big advantage of naturally providing fast training convergence and high editability. However, as the research around these is still in its infancy, there is still a gap in the literature regarding the model's scalability. In this work, we propose an approach enabling both memory and computation scalability of such models. More specifically, we propose an iterative pruning strategy that removes redundant information encoded in the model. We also enhance compressibility for the model by including in the optimization strategy a differentiable quantization and entropy coding estimator. Our results on popular benchmarks showcase the effectiveness of the proposed approach and open the road to the broad deployability of such a solution even on resource-constrained devices.", "published": "2024-10-31 04:00:00", "id": "94e16fa8-87d5-47bd-b55e-7957b27cd491", "source": "arxiv", "section": "computerScience"}, {"title": "Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval", "link": "https://arxiv.org/abs/2410.23214", "description": "arXiv:2410.23214v1 Announce Type: new \nAbstract: The hallucinations of large language models (LLMs) are increasingly mitigated by allowing LLMs to search for information and to ground their answers in real sources. Unfortunately, LLMs often struggle with posing the right search queries, especially when dealing with complex or otherwise indirect topics. Observing that LLMs can learn to search for relevant facts by $\\textit{trying}$ different queries and learning to up-weight queries that successfully produce relevant results, we introduce $\\underline{Le}$arning to $\\underline{Re}$trieve by $\\underline{T}$rying (LeReT), a reinforcement learning framework that explores search queries and uses preference-based optimization to improve their quality. \\methodclass can improve the absolute retrieval accuracy by up to 29\\% and the downstream generator evaluations by 17\\%. The simplicity and flexibility of LeReT allows it to be applied to arbitrary off-the-shelf retrievers and makes it a promising technique for improving general LLM pipelines. Project website: http://sherylhsu.com/LeReT/.", "published": "2024-10-31 04:00:00", "id": "e9b16469-953d-4182-a9ad-722ed6079f37", "source": "arxiv", "section": "computerScience"}, {"title": "Levels of explanation -- implementation and evaluation of what and when for different time-sensitive tasks", "link": "https://arxiv.org/abs/2410.23215", "description": "arXiv:2410.23215v1 Announce Type: new \nAbstract: In this work, we focused on constructing and evaluating levels of explanation(LOE) that address two basic aspect of HRI: 1. What information should be communicated to the user by the robot? 2. When should the robot communicate this information? For constructing the LOE, we defined two terms, verbosity and explanation patterns, each with two levels (verbosity -- high and low, explanation patterns -- dynamic and static). Based on these parameters, three different LOE (high, medium, and low) were constructed and evaluated in a user study with a telepresence robot. The user study was conducted for a simulated telerobotic healthcare task with two different conditions related to time sensitivity, as evaluated by two different user groups -- one that performed the task within a time limit and the other with no time limit. We found that the high LOE was preferred in terms of adequacy of explanation, number of collisions, number of incorrect movements, and number of clarifications when users performed the experiment in the without time limit condition. We also found that both high and medium LOE did not have significant differences in completion time, the fluency of HRI, and trust in the robot. When users performed the experiment in the with time limit condition, high and medium LOE had better task performances and were preferred to the low LOE in terms of completion time, fluency, adequacy of explanation, trust, number of collisions, number of incorrect movements and number of clarifications. Future directions for advancing LOE are discussed.", "published": "2024-10-31 04:00:00", "id": "58a363af-d7d1-49c9-b073-252ab7c10cc0", "source": "arxiv", "section": "computerScience"}, {"title": "OS-ATLAS: A Foundation Action Model for Generalist GUI Agents", "link": "https://arxiv.org/abs/2410.23218", "description": "arXiv:2410.23218v1 Announce Type: new \nAbstract: Existing efforts in building GUI agents heavily rely on the availability of robust commercial Vision-Language Models (VLMs) such as GPT-4o and GeminiProVision. Practitioners are often reluctant to use open-source VLMs due to their significant performance lag compared to their closed-source counterparts, particularly in GUI grounding and Out-Of-Distribution (OOD) scenarios. To facilitate future research in this area, we developed OS-Atlas - a foundational GUI action model that excels at GUI grounding and OOD agentic tasks through innovations in both data and modeling. We have invested significant engineering effort in developing an open-source toolkit for synthesizing GUI grounding data across multiple platforms, including Windows, Linux, MacOS, Android, and the web. Leveraging this toolkit, we are releasing the largest open-source cross-platform GUI grounding corpus to date, which contains over 13 million GUI elements. This dataset, combined with innovations in model training, provides a solid foundation for OS-Atlas to understand GUI screenshots and generalize to unseen interfaces. Through extensive evaluation across six benchmarks spanning three different platforms (mobile, desktop, and web), OS-Atlas demonstrates significant performance improvements over previous state-of-the-art models. Our evaluation also uncovers valuable insights into continuously improving and scaling the agentic capabilities of open-source VLMs.", "published": "2024-10-31 04:00:00", "id": "2bad0f60-0859-4284-b032-05ef0e456877", "source": "arxiv", "section": "computerScience"}, {"title": "DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET", "link": "https://arxiv.org/abs/2410.23219", "description": "arXiv:2410.23219v1 Announce Type: new \nAbstract: Diagnosing dementia, particularly for Alzheimer's Disease (AD) and frontotemporal dementia (FTD), is complex due to overlapping symptoms. While magnetic resonance imaging (MRI) and positron emission tomography (PET) data are critical for the diagnosis, integrating these modalities in deep learning faces challenges, often resulting in suboptimal performance compared to using single modalities. Moreover, the potential of multi-modal approaches in differential diagnosis, which holds significant clinical importance, remains largely unexplored. We propose a novel framework, DiaMond, to address these issues with vision Transformers to effectively integrate MRI and PET. DiaMond is equipped with self-attention and a novel bi-attention mechanism that synergistically combine MRI and PET, alongside a multi-modal normalization to reduce redundant dependency, thereby boosting the performance. DiaMond significantly outperforms existing multi-modal methods across various datasets, achieving a balanced accuracy of 92.4% in AD diagnosis, 65.2% for AD-MCI-CN classification, and 76.5% in differential diagnosis of AD and FTD. We also validated the robustness of DiaMond in a comprehensive ablation study. The code is available at https://github.com/ai-med/DiaMond.", "published": "2024-10-31 04:00:00", "id": "4f301c8c-7d16-46c6-962e-7aaa18293a28", "source": "arxiv", "section": "computerScience"}, {"title": "Partial Channel Dependence with Channel Masks for Time Series Foundation Models", "link": "https://arxiv.org/abs/2410.23222", "description": "arXiv:2410.23222v1 Announce Type: new \nAbstract: Recent advancements in foundation models have been successfully extended to the time series (TS) domain, facilitated by the emergence of large-scale TS datasets. However, previous efforts have primarily focused on designing model architectures to address explicit heterogeneity among datasets such as various numbers of channels, while often overlooking implicit heterogeneity such as varying dependencies between channels. In this work, we introduce the concept of partial channel dependence (PCD), which enables a more sophisticated adjustment of channel dependencies based on dataset-specific information. To achieve PCD, we propose a channel mask that captures the relationships between channels within a dataset using two key components: 1) a correlation matrix that encodes relative dependencies between channels, and 2) domain parameters that learn the absolute dependencies specific to each dataset, refining the correlation matrix. We validate the effectiveness of PCD across four tasks in TS including forecasting, classification, imputation, and anomaly detection, under diverse settings, including few-shot and zero-shot scenarios with both TS foundation models and single-task models. Code is available at https://github.com/seunghan96/CM.", "published": "2024-10-31 04:00:00", "id": "d2abd0a7-c49f-4fa6-a83b-9370837ff5f0", "source": "arxiv", "section": "computerScience"}, {"title": "COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences", "link": "https://arxiv.org/abs/2410.23223", "description": "arXiv:2410.23223v1 Announce Type: new \nAbstract: Many alignment methods, including reinforcement learning from human feedback (RLHF), rely on the Bradley-Terry reward assumption, which is insufficient to capture the full range of general human preferences. To achieve robust alignment with general preferences, we model the alignment problem as a two-player zero-sum game, where the Nash equilibrium policy guarantees a 50% win rate against any competing policy. However, previous algorithms for finding the Nash policy either diverge or converge to a Nash policy in a modified game, even in a simple synthetic setting, thereby failing to maintain the 50% win rate guarantee against all other policies. We propose a meta-algorithm, Convergent Meta Alignment Algorithm (COMAL), for language model alignment with general preferences, inspired by convergent algorithms in game theory. Theoretically, we prove that our meta-algorithm converges to an exact Nash policy in the last iterate. Additionally, our meta-algorithm is simple and can be integrated with many existing methods designed for RLHF and preference optimization with minimal changes. Experimental results demonstrate the effectiveness of the proposed framework when combined with existing preference policy optimization methods.", "published": "2024-10-31 04:00:00", "id": "4e67adea-5bf4-4183-bf45-adaa9547d6ae", "source": "arxiv", "section": "computerScience"}, {"title": "Deterministic counting from coupling independence", "link": "https://arxiv.org/abs/2410.23225", "description": "arXiv:2410.23225v1 Announce Type: new \nAbstract: We show that spin systems with bounded degrees and coupling independence admit fully polynomial time approximation schemes (FPTAS). We design a new recursive deterministic counting algorithm to achieve this. As applications, we give the first FPTASes for $q$-colourings on graphs of bounded maximum degree $\\Delta\\ge 3$, when $q\\ge (11/6-\\varepsilon_0)\\Delta$ for some small $\\varepsilon_0\\approx 10^{-5}$, or when $\\Delta\\ge 125$ and $q\\ge 1.809\\Delta$, and on graphs with sufficiently large (but constant) girth, when $q\\geq\\Delta+3$. These bounds match the current best randomised approximate counting algorithms by Chen, Delcourt, Moitra, Perarnau, and Postle (2019), Carlson and Vigoda (2024), and Chen, Liu, Mani, and Moitra (2023), respectively.", "published": "2024-10-31 04:00:00", "id": "3b76b4ee-e734-4443-97a3-714ecce3caef", "source": "arxiv", "section": "computerScience"}, {"title": "(FL)$^2$: Overcoming Few Labels in Federated Semi-Supervised Learning", "link": "https://arxiv.org/abs/2410.23227", "description": "arXiv:2410.23227v1 Announce Type: new \nAbstract: Federated Learning (FL) is a distributed machine learning framework that trains accurate global models while preserving clients' privacy-sensitive data. However, most FL approaches assume that clients possess labeled data, which is often not the case in practice. Federated Semi-Supervised Learning (FSSL) addresses this label deficiency problem, targeting situations where only the server has a small amount of labeled data while clients do not. However, a significant performance gap exists between Centralized Semi-Supervised Learning (SSL) and FSSL. This gap arises from confirmation bias, which is more pronounced in FSSL due to multiple local training epochs and the separation of labeled and unlabeled data. We propose $(FL)^2$, a robust training method for unlabeled clients using sharpness-aware consistency regularization. We show that regularizing the original pseudo-labeling loss is suboptimal, and hence we carefully select unlabeled samples for regularization. We further introduce client-specific adaptive thresholding and learning status-aware aggregation to adjust the training process based on the learning progress of each client. Our experiments on three benchmark datasets demonstrate that our approach significantly improves performance and bridges the gap with SSL, particularly in scenarios with scarce labeled data.", "published": "2024-10-31 04:00:00", "id": "b5e5cf9b-74ed-4205-be87-ee397eaf61da", "source": "arxiv", "section": "computerScience"}, {"title": "Emergence of meta-stable clustering in mean-field transformer models", "link": "https://arxiv.org/abs/2410.23228", "description": "arXiv:2410.23228v1 Announce Type: new \nAbstract: We model the evolution of tokens within a deep stack of Transformer layers as a continuous-time flow on the unit sphere, governed by a mean-field interacting particle system, building on the framework introduced in (Geshkovski et al., 2023). Studying the corresponding mean-field Partial Differential Equation (PDE), which can be interpreted as a Wasserstein gradient flow, in this paper we provide a mathematical investigation of the long-term behavior of this system, with a particular focus on the emergence and persistence of meta-stable phases and clustering phenomena, key elements in applications like next-token prediction. More specifically, we perform a perturbative analysis of the mean-field PDE around the iid uniform initialization and prove that, in the limit of large number of tokens, the model remains close to a meta-stable manifold of solutions with a given structure (e.g., periodicity). Further, the structure characterizing the meta-stable manifold is explicitly identified, as a function of the inverse temperature parameter of the model, by the index maximizing a certain rescaling of Gegenbauer polynomials.", "published": "2024-10-31 04:00:00", "id": "b1f6632d-3a44-4189-8920-18af76785597", "source": "arxiv", "section": "computerScience"}, {"title": "Aligning Audio-Visual Joint Representations with an Agentic Workflow", "link": "https://arxiv.org/abs/2410.23230", "description": "arXiv:2410.23230v1 Announce Type: new \nAbstract: Visual content and accompanied audio signals naturally formulate a joint representation to improve audio-visual (AV) related applications. While studies develop various AV representation learning frameworks, the importance of AV data alignment is usually undermined for achieving high-quality representation. We observe that an audio signal may contain background noise interference. Also, non-synchronization may appear between audio and video streams. These non-strict data alignment limits representation quality and downgrade application performance. In this paper, we propose to improve AV joint representations from a data-centric perspective by aligning audio signals to visual data. Our alignment is conducted in an agentic workflow controlled by an LLM-based assistant named AVAgent. For each input AV data pair, our AVAgent uses a multi-modal LLM to convert audio and visual data into language descriptions separately (i.e., tool use). Then, AVAgent reasons whether this paired data is aligned well and plans to edit the audio signal if needed (i.e., planning). The audio editing is executed by predefined actions that filter noise or augment data. Moreover, we use a VLM to evaluate how modified audio signals match the visual content and provide feedback to AVAgent (i.e., reflection). The tool use, planning, and reflection steps operate cyclically to become an agentic workflow where audio signals are gradually aligned to visual content. To this end, existing methods can directly leverage the aligned AV data via our agentic workflow to improve AV joint representations. The experimental results comprehensively demonstrate the state-of-the-art performance of the proposed approach against previous baselines in diverse downstream tasks.", "published": "2024-10-31 04:00:00", "id": "57a19439-5901-4242-b8d8-5fdca086467a", "source": "arxiv", "section": "computerScience"}, {"title": "LGU-SLAM: Learnable Gaussian Uncertainty Matching with Deformable Correlation Sampling for Deep Visual SLAM", "link": "https://arxiv.org/abs/2410.23231", "description": "arXiv:2410.23231v1 Announce Type: new \nAbstract: Deep visual Simultaneous Localization and Mapping (SLAM) techniques, e.g., DROID, have made significant advancements by leveraging deep visual odometry on dense flow fields. In general, they heavily rely on global visual similarity matching. However, the ambiguous similarity interference in uncertain regions could often lead to excessive noise in correspondences, ultimately misleading SLAM in geometric modeling. To address this issue, we propose a Learnable Gaussian Uncertainty (LGU) matching. It mainly focuses on precise correspondence construction. In our scheme, a learnable 2D Gaussian uncertainty model is designed to associate matching-frame pairs. It could generate input-dependent Gaussian distributions for each correspondence map. Additionally, a multi-scale deformable correlation sampling strategy is devised to adaptively fine-tune the sampling of each direction by a priori look-up ranges, enabling reliable correlation construction. Furthermore, a KAN-bias GRU component is adopted to improve a temporal iterative enhancement for accomplishing sophisticated spatio-temporal modeling with limited parameters. The extensive experiments on real-world and synthetic datasets are conducted to validate the effectiveness and superiority of our method.", "published": "2024-10-31 04:00:00", "id": "5f37b522-41de-4977-a96d-7688f9ce092a", "source": "arxiv", "section": "computerScience"}, {"title": "Attribute-to-Delete: Machine Unlearning via Datamodel Matching", "link": "https://arxiv.org/abs/2410.23232", "description": "arXiv:2410.23232v1 Announce Type: new \nAbstract: Machine unlearning -- efficiently removing the effect of a small \"forget set\" of training data on a pre-trained machine learning model -- has recently attracted significant research interest. Despite this interest, however, recent work shows that existing machine unlearning techniques do not hold up to thorough evaluation in non-convex settings. In this work, we introduce a new machine unlearning technique that exhibits strong empirical performance even in such challenging settings. Our starting point is the perspective that the goal of unlearning is to produce a model whose outputs are statistically indistinguishable from those of a model re-trained on all but the forget set. This perspective naturally suggests a reduction from the unlearning problem to that of data attribution, where the goal is to predict the effect of changing the training set on a model's outputs. Thus motivated, we propose the following meta-algorithm, which we call Datamodel Matching (DMM): given a trained model, we (a) use data attribution to predict the output of the model if it were re-trained on all but the forget set points; then (b) fine-tune the pre-trained model to match these predicted outputs. In a simple convex setting, we show how this approach provably outperforms a variety of iterative unlearning algorithms. Empirically, we use a combination of existing evaluations and a new metric based on the KL-divergence to show that even in non-convex settings, DMM achieves strong unlearning performance relative to existing algorithms. An added benefit of DMM is that it is a meta-algorithm, in the sense that future advances in data attribution translate directly into better unlearning algorithms, pointing to a clear direction for future progress in unlearning.", "published": "2024-10-31 04:00:00", "id": "b593d9e1-16bc-4419-b0d5-c381f2b50618", "source": "arxiv", "section": "computerScience"}, {"title": "EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning", "link": "https://arxiv.org/abs/2410.23234", "description": "arXiv:2410.23234v1 Announce Type: new \nAbstract: This paper introduces a framework, called EMOTION, for generating expressive motion sequences in humanoid robots, enhancing their ability to engage in humanlike non-verbal communication. Non-verbal cues such as facial expressions, gestures, and body movements play a crucial role in effective interpersonal interactions. Despite the advancements in robotic behaviors, existing methods often fall short in mimicking the diversity and subtlety of human non-verbal communication. To address this gap, our approach leverages the in-context learning capability of large language models (LLMs) to dynamically generate socially appropriate gesture motion sequences for human-robot interaction. We use this framework to generate 10 different expressive gestures and conduct online user studies comparing the naturalness and understandability of the motions generated by EMOTION and its human-feedback version, EMOTION++, against those by human operators. The results demonstrate that our approach either matches or surpasses human performance in generating understandable and natural robot motions under certain scenarios. We also provide design implications for future research to consider a set of variables when generating expressive robotic gestures.", "published": "2024-10-31 04:00:00", "id": "3c8c640e-cace-4de8-9d55-bfc56132d93c", "source": "arxiv", "section": "computerScience"}, {"title": "CRAFT@Large: Building Community Through Co-Making", "link": "https://arxiv.org/abs/2410.23239", "description": "arXiv:2410.23239v1 Announce Type: new \nAbstract: CRAFT@Large (C@L) is an initiative launched by the MakerLAB at Cornell Tech to create an inclusive environment for the intercultural and intergenerational exchange of ideas through making. With our approach, we challenge the traditional definition of community outreach performed by academic makerspaces. Existing academic makerspaces often perform community engagement by only offering hourly, one-time workshops or by having community members provide a problem that is then used by students as a project assignment. These approaches position community members as occasional visitors and non-equal contributors, which not only conflict with the core values of co-creation but also limit the makerspaces' impact on connecting the universities and the communities. C@L explored an alternative approach in which we invited community members as long-term and equal co-makers into the academic makerspaces. In this article, we showcase two sets of collaborations that illustrate the continuity of people through co-making. We present how academic makerspaces can function as a hub that connects community members and partner organizations with the campus community in a long-term relationship.", "published": "2024-10-31 04:00:00", "id": "fde5d140-46a0-4798-be59-f1b9d67b69c0", "source": "arxiv", "section": "computerScience"}, {"title": "A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment", "link": "https://arxiv.org/abs/2410.23242", "description": "arXiv:2410.23242v1 Announce Type: new \nAbstract: As general-purpose tools, Large Language Models (LLMs) must often reason about everyday physical environments. In a question-and-answer capacity, understanding the interactions of physical objects may be necessary to give appropriate responses. Moreover, LLMs are increasingly used as reasoning engines in agentic systems, designing and controlling their action sequences. The vast majority of research has tackled this issue using static benchmarks, comprised of text or image-based questions about the physical world. However, these benchmarks do not capture the complexity and nuance of real-life physical processes. Here we advocate for a second, relatively unexplored, approach: 'embodying' the LLMs by granting them control of an agent within a 3D environment. We present the first embodied and cognitively meaningful evaluation of physical common-sense reasoning in LLMs. Our framework allows direct comparison of LLMs with other embodied agents, such as those based on Deep Reinforcement Learning, and human and non-human animals. We employ the Animal-AI (AAI) environment, a simulated 3D virtual laboratory, to study physical common-sense reasoning in LLMs. For this, we use the AAI Testbed, a suite of experiments that replicate laboratory studies with non-human animals, to study physical reasoning capabilities including distance estimation, tracking out-of-sight objects, and tool use. We demonstrate that state-of-the-art multi-modal models with no finetuning can complete this style of task, allowing meaningful comparison to the entrants of the 2019 Animal-AI Olympics competition and to human children. Our results show that LLMs are currently outperformed by human children on these tasks. We argue that this approach allows the study of physical reasoning using ecologically valid experiments drawn directly from cognitive science, improving the predictability and reliability of LLMs.", "published": "2024-10-31 04:00:00", "id": "8d28c7ba-37dd-47bf-b71f-67ecb0fe6898", "source": "arxiv", "section": "computerScience"}, {"title": "Carrot and Stick: Eliciting Comparison Data and Beyond", "link": "https://arxiv.org/abs/2410.23243", "description": "arXiv:2410.23243v1 Announce Type: new \nAbstract: Comparison data elicited from people are fundamental to many machine learning tasks, including reinforcement learning from human feedback for large language models and estimating ranking models. They are typically subjective and not directly verifiable. How to truthfully elicit such comparison data from rational individuals? We design peer prediction mechanisms for eliciting comparison data using a bonus-penalty payment. Our design leverages on the strong stochastic transitivity for comparison data to create symmetrically strongly truthful mechanisms such that truth-telling 1) forms a strict Bayesian Nash equilibrium, and 2) yields the highest payment among all symmetric equilibria. Each individual only needs to evaluate one pair of items and report her comparison in our mechanism.\n  We further extend the bonus-penalty payment concept to eliciting networked data, designing a symmetrically strongly truthful mechanism when agents' private signals are sampled according to the Ising models. We provide the necessary and sufficient conditions for our bonus-penalty payment to have truth-telling as a strict Bayesian Nash equilibrium. Experiments on two real-world datasets further support our theoretical discoveries.", "published": "2024-10-31 04:00:00", "id": "1fc72d30-6884-4b31-99b5-db474b7989a1", "source": "arxiv", "section": "computerScience"}, {"title": "PointRecon: Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching", "link": "https://arxiv.org/abs/2410.23245", "description": "arXiv:2410.23245v1 Announce Type: new \nAbstract: We propose a novel online, point-based 3D reconstruction method from posed monocular RGB videos. Our model maintains a global point cloud representation of the scene, continuously updating the features and 3D locations of points as new images are observed. It expands the point cloud with newly detected points while carefully removing redundancies. The point cloud updates and depth predictions for new points are achieved through a novel ray-based 2D-3D feature matching technique, which is robust against errors in previous point position predictions. In contrast to offline methods, our approach processes infinite-length sequences and provides real-time updates. Additionally, the point cloud imposes no pre-defined resolution or scene size constraints, and its unified global representation ensures view consistency across perspectives. Experiments on the ScanNet dataset show that our method achieves state-of-the-art quality among online MVS approaches. Project page: https://arthurhero.github.io/projects/pointrecon", "published": "2024-10-31 04:00:00", "id": "77456872-3950-4d62-9844-5c373270b05e", "source": "arxiv", "section": "computerScience"}, {"title": "Evaluating Cultural and Social Awareness of LLM Web Agents", "link": "https://arxiv.org/abs/2410.23252", "description": "arXiv:2410.23252v1 Announce Type: new \nAbstract: As large language models (LLMs) expand into performing as agents for real-world applications beyond traditional NLP tasks, evaluating their robustness becomes increasingly important. However, existing benchmarks often overlook critical dimensions like cultural and social awareness. To address these, we introduce CASA, a benchmark designed to assess LLM agents' sensitivity to cultural and social norms across two web-based tasks: online shopping and social discussion forums. Our approach evaluates LLM agents' ability to detect and appropriately respond to norm-violating user queries and observations. Furthermore, we propose a comprehensive evaluation framework that measures awareness coverage, helpfulness in managing user queries, and the violation rate when facing misleading web content. Experiments show that current LLMs perform significantly better in non-agent than in web-based agent environments, with agents achieving less than 10% awareness coverage and over 40% violation rates. To improve performance, we explore two methods: prompting and fine-tuning, and find that combining both methods can offer complementary advantages -- fine-tuning on culture-specific datasets significantly enhances the agents' ability to generalize across different regions, while prompting boosts the agents' ability to navigate complex tasks. These findings highlight the importance of constantly benchmarking LLM agents' cultural and social awareness during the development cycle.", "published": "2024-10-31 04:00:00", "id": "1372adf1-d268-4482-b506-00449292f1b1", "source": "arxiv", "section": "computerScience"}, {"title": "Keypoint Abstraction using Large Models for Object-Relative Imitation Learning", "link": "https://arxiv.org/abs/2410.23254", "description": "arXiv:2410.23254v1 Announce Type: new \nAbstract: Generalization to novel object configurations and instances across diverse tasks and environments is a critical challenge in robotics. Keypoint-based representations have been proven effective as a succinct representation for capturing essential object features, and for establishing a reference frame in action prediction, enabling data-efficient learning of robot skills. However, their manual design nature and reliance on additional human labels limit their scalability. In this paper, we propose KALM, a framework that leverages large pre-trained vision-language models (LMs) to automatically generate task-relevant and cross-instance consistent keypoints. KALM distills robust and consistent keypoints across views and objects by generating proposals using LMs and verifies them against a small set of robot demonstration data. Based on the generated keypoints, we can train keypoint-conditioned policy models that predict actions in keypoint-centric frames, enabling robots to generalize effectively across varying object poses, camera views, and object instances with similar functional shapes. Our method demonstrates strong performance in the real world, adapting to different tasks and environments from only a handful of demonstrations while requiring no additional labels. Website: https://kalm-il.github.io/", "published": "2024-10-31 04:00:00", "id": "0fe2c77a-8f74-405b-8f90-541d46957116", "source": "arxiv", "section": "computerScience"}, {"title": "EMMA: End-to-End Multimodal Model for Autonomous Driving", "link": "https://arxiv.org/abs/2410.23262", "description": "arXiv:2410.23262v1 Announce Type: new \nAbstract: We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving. Built on a multi-modal large language model foundation, EMMA directly maps raw camera sensor data into various driving-specific outputs, including planner trajectories, perception objects, and road graph elements. EMMA maximizes the utility of world knowledge from the pre-trained large language models, by representing all non-sensor inputs (e.g. navigation instructions and ego vehicle status) and outputs (e.g. trajectories and 3D locations) as natural language text. This approach allows EMMA to jointly process various driving tasks in a unified language space, and generate the outputs for each task using task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by achieving state-of-the-art performance in motion planning on nuScenes as well as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also yields competitive results for camera-primary 3D object detection on the Waymo Open Dataset (WOD). We show that co-training EMMA with planner trajectories, object detection, and road graph tasks yields improvements across all three domains, highlighting EMMA's potential as a generalist model for autonomous driving applications. However, EMMA also exhibits certain limitations: it can process only a small amount of image frames, does not incorporate accurate 3D sensing modalities like LiDAR or radar and is computationally expensive. We hope that our results will inspire further research to mitigate these issues and to further evolve the state of the art in autonomous driving model architectures.", "published": "2024-10-31 04:00:00", "id": "bc9eeb24-a488-4266-a549-35b9e2c3fd9b", "source": "arxiv", "section": "computerScience"}, {"title": "TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models", "link": "https://arxiv.org/abs/2410.23266", "description": "arXiv:2410.23266v1 Announce Type: new \nAbstract: Existing benchmarks often highlight the remarkable performance achieved by state-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporal context for video understanding. However, how well do the models truly perform visual temporal reasoning? Our study of existing benchmarks shows that this capability of MFMs is likely overestimated as many questions can be solved by using a single, few, or out-of-order frames. To systematically examine current visual temporal reasoning tasks, we propose three principles with corresponding metrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) Frame Information Disparity. Following these principles, we introduce TOMATO, Temporal Reasoning Multimodal Evaluation, a novel benchmark crafted to rigorously assess MFMs' temporal reasoning capabilities in video understanding. TOMATO comprises 1,484 carefully curated, human-annotated questions spanning six tasks (i.e., action count, direction, rotation, shape & trend, velocity & frequency, and visual cues), applied to 1,417 videos, including 805 self-recorded and -generated videos, that encompass human-centric, real-world, and simulated scenarios. Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model. Moreover, our in-depth analysis uncovers more fundamental limitations beyond this gap in current MFMs. While they can accurately recognize events in isolated frames, they fail to interpret these frames as a continuous sequence. We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending human world dynamics through the video modality.", "published": "2024-10-31 04:00:00", "id": "1b0a1219-b028-4130-a34d-b68c95f360b3", "source": "arxiv", "section": "computerScience"}, {"title": "Commit: Online Groups with Participation Commitments", "link": "https://arxiv.org/abs/2410.23267", "description": "arXiv:2410.23267v1 Announce Type: new \nAbstract: In spite of efforts to increase participation, many online groups struggle to survive past the initial days, as members leave and activity atrophies. We argue that a main assumption of online group design -- that groups ask nothing of their members beyond lurking -- may be preventing many of these groups from sustaining a critical mass of participation. In this paper, we explore an alternative commitment design for online groups, which requires that all members commit at regular intervals to participating, as a condition of remaining in the group. We instantiate this approach in a mobile group chat platform called Commit, and perform a field study comparing commitment against a control condition of social psychological nudges with N=57 participants over three weeks. Commitment doubled the number of contributions versus the control condition, and resulted in 87% (vs. 19%) of participants remaining active by the third week. Participants reported that commitment provided safe cover for them to post even when they were nervous. Through this work, we argue that more effortful, not less effortful, membership may support many online groups.", "published": "2024-10-31 04:00:00", "id": "a9e4d5c5-34d7-49e4-acb4-a13c3b134fa0", "source": "arxiv", "section": "computerScience"}, {"title": "A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction", "link": "https://arxiv.org/abs/2410.23272", "description": "arXiv:2410.23272v1 Announce Type: new \nAbstract: Probabilistic prediction of sequences from images and other high-dimensional data is a key challenge, particularly in risk-sensitive applications. In these settings, it is often desirable to quantify the uncertainty associated with the prediction (instead of just determining the most likely sequence, as in language modeling). In this paper, we propose a Monte Carlo framework to estimate probabilities and confidence intervals associated with the distribution of a discrete sequence. Our framework uses a Monte Carlo simulator, implemented as an autoregressively trained neural network, to sample sequences conditioned on an image input. We then use these samples to estimate the probabilities and confidence intervals. Experiments on synthetic and real data show that the framework produces accurate discriminative predictions, but can suffer from miscalibration. In order to address this shortcoming, we propose a time-dependent regularization method, which is shown to produce calibrated predictions.", "published": "2024-10-31 04:00:00", "id": "b6df5cbd-9e05-418e-95c7-5374dc76701b", "source": "arxiv", "section": "computerScience"}, {"title": "Proportional Fairness in Non-Centroid Clustering", "link": "https://arxiv.org/abs/2410.23273", "description": "arXiv:2410.23273v1 Announce Type: new \nAbstract: We revisit the recently developed framework of proportionally fair clustering, where the goal is to provide group fairness guarantees that become stronger for groups of data points (agents) that are large and cohesive. Prior work applies this framework to centroid clustering, where the loss of an agent is its distance to the centroid assigned to its cluster. We expand the framework to non-centroid clustering, where the loss of an agent is a function of the other agents in its cluster, by adapting two proportional fairness criteria -- the core and its relaxation, fully justified representation (FJR) -- to this setting.\n  We show that the core can be approximated only under structured loss functions, and even then, the best approximation we are able to establish, using an adaptation of the GreedyCapture algorithm developed for centroid clustering [Chen et al., 2019; Micha and Shah, 2020], is unappealing for a natural loss function. In contrast, we design a new (inefficient) algorithm, GreedyCohesiveClustering, which achieves the relaxation FJR exactly under arbitrary loss functions, and show that the efficient GreedyCapture algorithm achieves a constant approximation of FJR. We also design an efficient auditing algorithm, which estimates the FJR approximation of any given clustering solution up to a constant factor. Our experiments on real data suggest that traditional clustering algorithms are highly unfair, whereas GreedyCapture is considerably fairer and incurs only a modest loss in common clustering objectives.", "published": "2024-10-31 04:00:00", "id": "80333e68-ea38-4e74-8c76-716442ba15ba", "source": "arxiv", "section": "computerScience"}, {"title": "Multi-student Diffusion Distillation for Better One-step Generators", "link": "https://arxiv.org/abs/2410.23274", "description": "arXiv:2410.23274v1 Announce Type: new \nAbstract: Diffusion models achieve high-quality sample generation at the cost of a lengthy multistep inference procedure. To overcome this, diffusion distillation techniques produce student generators capable of matching or surpassing the teacher in a single step. However, the student model's inference speed is limited by the size of the teacher architecture, preventing real-time generation for computationally heavy applications. In this work, we introduce Multi-Student Distillation (MSD), a framework to distill a conditional teacher diffusion model into multiple single-step generators. Each student generator is responsible for a subset of the conditioning data, thereby obtaining higher generation quality for the same capacity. MSD trains multiple distilled students, allowing smaller sizes and, therefore, faster inference. Also, MSD offers a lightweight quality boost over single-student distillation with the same architecture. We demonstrate MSD is effective by training multiple same-sized or smaller students on single-step distillation using distribution matching and adversarial distillation techniques. With smaller students, MSD gets competitive results with faster inference for single-step generation. Using 4 same-sized students, MSD sets a new state-of-the-art for one-step image generation: FID 1.20 on ImageNet-64x64 and 8.20 on zero-shot COCO2014.", "published": "2024-10-31 04:00:00", "id": "159421f5-c704-4256-afd9-1cf1f0de6ae1", "source": "arxiv", "section": "computerScience"}, {"title": "SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation", "link": "https://arxiv.org/abs/2410.23277", "description": "arXiv:2410.23277v1 Announce Type: new \nAbstract: Human beings are endowed with a complementary learning system, which bridges the slow learning of general world dynamics with fast storage of episodic memory from a new experience. Previous video generation models, however, primarily focus on slow learning by pre-training on vast amounts of data, overlooking the fast learning phase crucial for episodic memory storage. This oversight leads to inconsistencies across temporally distant frames when generating longer videos, as these frames fall beyond the model's context window. To this end, we introduce SlowFast-VGen, a novel dual-speed learning system for action-driven long video generation. Our approach incorporates a masked conditional video diffusion model for the slow learning of world dynamics, alongside an inference-time fast learning strategy based on a temporal LoRA module. Specifically, the fast learning process updates its temporal LoRA parameters based on local inputs and outputs, thereby efficiently storing episodic memory in its parameters. We further propose a slow-fast learning loop algorithm that seamlessly integrates the inner fast learning loop into the outer slow learning loop, enabling the recall of prior multi-episode experiences for context-aware skill learning. To facilitate the slow learning of an approximate world model, we collect a large-scale dataset of 200k videos with language action annotations, covering a wide range of scenarios. Extensive experiments show that SlowFast-VGen outperforms baselines across various metrics for action-driven video generation, achieving an FVD score of 514 compared to 782, and maintaining consistency in longer videos, with an average of 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithm significantly enhances performances on long-horizon planning tasks as well. Project Website: https://slowfast-vgen.github.io", "published": "2024-10-31 04:00:00", "id": "0986c0c5-6a2e-42ba-9cb6-b5bde4762eca", "source": "arxiv", "section": "computerScience"}, {"title": "OpenSatMap: A Fine-grained High-resolution Satellite Dataset for Large-scale Map Construction", "link": "https://arxiv.org/abs/2410.23278", "description": "arXiv:2410.23278v1 Announce Type: new \nAbstract: In this paper, we propose OpenSatMap, a fine-grained, high-resolution satellite dataset for large-scale map construction. Map construction is one of the foundations of the transportation industry, such as navigation and autonomous driving. Extracting road structures from satellite images is an efficient way to construct large-scale maps. However, existing satellite datasets provide only coarse semantic-level labels with a relatively low resolution (up to level 19), impeding the advancement of this field. In contrast, the proposed OpenSatMap (1) has fine-grained instance-level annotations; (2) consists of high-resolution images (level 20); (3) is currently the largest one of its kind; (4) collects data with high diversity. Moreover, OpenSatMap covers and aligns with the popular nuScenes dataset and Argoverse 2 dataset to potentially advance autonomous driving technologies. By publishing and maintaining the dataset, we provide a high-quality benchmark for satellite-based map construction and downstream tasks like autonomous driving.", "published": "2024-10-31 04:00:00", "id": "ab198835-4348-4278-8ccc-f2d9bc7124dd", "source": "arxiv", "section": "computerScience"}, {"title": "A Neural Transformer Framework for Simultaneous Tasks of Segmentation, Classification, and Caller Identification of Marmoset Vocalization", "link": "https://arxiv.org/abs/2410.23279", "description": "arXiv:2410.23279v1 Announce Type: new \nAbstract: Marmoset, a highly vocalized primate, has become a popular animal model for studying social-communicative behavior and its underlying mechanism. In the study of vocal communication, it is vital to know the caller identities, call contents, and vocal exchanges. Previous work of a CNN has achieved a joint model for call segmentation, classification, and caller identification for marmoset vocalizations. However, the CNN has limitations in modeling long-range acoustic patterns; the Transformer architecture that has been shown to outperform CNNs, utilizes the self-attention mechanism that efficiently segregates information parallelly over long distances and captures the global structure of marmoset vocalization. We propose using the Transformer to jointly segment and classify the marmoset calls and identify the callers for each vocalization.", "published": "2024-10-31 04:00:00", "id": "913c960e-d189-4252-b96f-1ac4b5e57e10", "source": "arxiv", "section": "computerScience"}, {"title": "RelationBooth: Towards Relation-Aware Customized Object Generation", "link": "https://arxiv.org/abs/2410.23280", "description": "arXiv:2410.23280v1 Announce Type: new \nAbstract: Customized image generation is crucial for delivering personalized content based on user-provided image prompts, aligning large-scale text-to-image diffusion models with individual needs. However, existing models often overlook the relationships between customized objects in generated images. Instead, this work addresses that gap by focusing on relation-aware customized image generation, which aims to preserve the identities from image prompts while maintaining the predicate relations described in text prompts. Specifically, we introduce RelationBooth, a framework that disentangles identity and relation learning through a well-curated dataset. Our training data consists of relation-specific images, independent object images containing identity information, and text prompts to guide relation generation. Then, we propose two key modules to tackle the two main challenges: generating accurate and natural relations, especially when significant pose adjustments are required, and avoiding object confusion in cases of overlap. First, we introduce a keypoint matching loss that effectively guides the model in adjusting object poses closely tied to their relationships. Second, we incorporate local features from the image prompts to better distinguish between objects, preventing confusion in overlapping cases. Extensive results on three benchmarks demonstrate the superiority of RelationBooth in generating precise relations while preserving object identities across a diverse set of objects and relations. The source code and trained models will be made available to the public.", "published": "2024-10-31 04:00:00", "id": "33338219-7f90-4aa1-818d-4ae510a37243", "source": "arxiv", "section": "computerScience"}, {"title": "DisCo: Distributed Contact-Rich Trajectory Optimization for Forceful Multi-Robot Collaboration", "link": "https://arxiv.org/abs/2410.23283", "description": "arXiv:2410.23283v1 Announce Type: new \nAbstract: We present DisCo, a distributed algorithm for contact-rich, multi-robot tasks. DisCo is a distributed contact-implicit trajectory optimization algorithm, which allows a group of robots to optimize a time sequence of forces to objects and to their environment to accomplish tasks such as collaborative manipulation, robot team sports, and modular robot locomotion. We build our algorithm on a variant of the Alternating Direction Method of Multipliers (ADMM), where each robot computes its own contact forces and contact-switching events from a smaller single-robot, contact-implicit trajectory optimization problem, while cooperating with other robots through dual variables, enforcing constraints between robots. Each robot iterates between solving its local problem, and communicating over a wireless mesh network to enforce these consistency constraints with its neighbors, ultimately converging to a coordinated plan for the group. The local problems solved by each robot are significantly less challenging than a centralized problem with all robots' contact forces and switching events, improving the computational efficiency, while also preserving the privacy of some aspects of each robot's operation. We demonstrate the effectiveness of our algorithm in simulations of collaborative manipulation, multi-robot team sports scenarios, and in modular robot locomotion, where DisCo achieves $3$x higher success rates with a 2.5x to 5x faster computation time. Further, we provide results of hardware experiments on a modular truss robot, with three collaborating truss nodes planning individually while working together to produce a punctuated rolling-gate motion of the composite structure. Videos are available on the project page: https://disco-opt.github.io.", "published": "2024-10-31 04:00:00", "id": "0d39e430-1aec-43d4-b12a-341c4ac9486a", "source": "arxiv", "section": "computerScience"}, {"title": "Provable acceleration for diffusion models under minimal assumptions", "link": "https://arxiv.org/abs/2410.23285", "description": "arXiv:2410.23285v1 Announce Type: new \nAbstract: While score-based diffusion models have achieved exceptional sampling quality, their sampling speeds are often limited by the high computational burden of score function evaluations. Despite the recent remarkable empirical advances in speeding up the score-based samplers, theoretical understanding of acceleration techniques remains largely limited. To bridge this gap, we propose a novel training-free acceleration scheme for stochastic samplers. Under minimal assumptions -- namely, $L^2$-accurate score estimates and a finite second-moment condition on the target distribution -- our accelerated sampler provably achieves $\\varepsilon$-accuracy in total variation within $\\widetilde{O}(d^{5/4}/\\sqrt{\\varepsilon})$ iterations, thereby significantly improving upon the $\\widetilde{O}(d/\\varepsilon)$ iteration complexity of standard score-based samplers. Notably, our convergence theory does not rely on restrictive assumptions on the target distribution or higher-order score estimation guarantees.", "published": "2024-10-31 04:00:00", "id": "90802dfd-3dbf-4712-ba4b-83a751e8cbcb", "source": "arxiv", "section": "computerScience"}, {"title": "ReferEverything: Towards Segmenting Everything We Can Speak of in Videos", "link": "https://arxiv.org/abs/2410.23287", "description": "arXiv:2410.23287v1 Announce Type: new \nAbstract: We present REM, a framework for segmenting a wide range of concepts in video that can be described through natural language. Our method capitalizes on visual-language representations learned by video diffusion models on Internet-scale datasets. A key insight of our approach is preserving as much of the generative model's original representation as possible, while fine-tuning it on narrow-domain Referral Object Segmentation datasets. As a result, our framework can accurately segment and track rare and unseen objects, despite being trained on object masks from a limited set of categories. Additionally, it can generalize to non-object dynamic concepts, such as waves crashing in the ocean, as demonstrated in our newly introduced benchmark for Referral Video Process Segmentation (Ref-VPS). Our experiments show that REM performs on par with state-of-the-art approaches on in-domain datasets, like Ref-DAVIS, while outperforming them by up to twelve points in terms of region similarity on out-of-domain data, leveraging the power of Internet-scale pre-training.", "published": "2024-10-31 04:00:00", "id": "b557f268-cd64-4478-adb3-8ea090de80f1", "source": "arxiv", "section": "computerScience"}, {"title": "Computing the bridge length: the key ingredient in a continuous isometry classification of periodic point sets", "link": "https://arxiv.org/abs/2410.23288", "description": "arXiv:2410.23288v1 Announce Type: new \nAbstract: The fundamental model of any periodic crystal is a periodic set of points at all atomic centres. Since crystal structures are determined in a rigid form, their strongest equivalence is rigid motion (composition of translations and rotations) or isometry (also including reflections). The recent isometry classification of periodic point sets used a complete invariant isoset whose size essentially depends on the bridge length, defined as the minimum `jump' that suffices to connect any points in the given set.\n  We propose a practical algorithm to compute the bridge length of any periodic point set given by a motif of points in a periodically translated unit cell. The algorithm has been tested on a large crystal dataset and is required for an efficient continuous classification of all periodic crystals. The exact computation of the bridge length is a key step to realising the inverse design of materials from new invariant values.", "published": "2024-10-31 04:00:00", "id": "f4af4711-1963-4af8-963c-5f24eede8983", "source": "arxiv", "section": "computerScience"}, {"title": "Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards", "link": "https://arxiv.org/abs/2410.23289", "description": "arXiv:2410.23289v1 Announce Type: new \nAbstract: Training robots directly from human videos is an emerging area in robotics and computer vision. While there has been notable progress with two-fingered grippers, learning autonomous tasks for multi-fingered robot hands in this way remains challenging. A key reason for this difficulty is that a policy trained on human hands may not directly transfer to a robot hand due to morphology differences. In this work, we present HuDOR, a technique that enables online fine-tuning of policies by directly computing rewards from human videos. Importantly, this reward function is built using object-oriented trajectories derived from off-the-shelf point trackers, providing meaningful learning signals despite the morphology gap and visual differences between human and robot hands. Given a single video of a human solving a task, such as gently opening a music box, HuDOR enables our four-fingered Allegro hand to learn the task with just an hour of online interaction. Our experiments across four tasks show that HuDOR achieves a 4x improvement over baselines. Code and videos are available on our website, https://object-rewards.github.io.", "published": "2024-10-31 04:00:00", "id": "a7927d52-9d68-44ea-a672-ffcd1f8d7b14", "source": "arxiv", "section": "computerScience"}, {"title": "The SPORT-C Intervention: An Integration of Sports, Case-Based Pedagogy and Systems Thinking Learning", "link": "https://arxiv.org/abs/2307.11755", "description": "arXiv:2307.11755v1 Announce Type: cross \nAbstract: The STEM field is unrepresentative of the population it serves. Due to a lack of cultural relevance in STEM courses, there is a dissociation between the lived experience of students from underrepresented racial groups (URG) and STEM course material. The SPORT-C intervention is a framework that combines sports, systems thinking learning, and a case-based pedagogy into an activity that can be used in any STEM course. A pilot study was conducted to determine the viability of the SPORT-C intervention in a classroom setting and determine if it was worth further investigating and if any impact differed by racial identity. The findings from this study implicate that the SPORT-C intervention has an impact on the motivation levels of students to participate in STEM courses.", "published": "2024-10-31 04:00:00", "id": "3f680013-ed70-4681-a4c0-c42deffb5da9", "source": "arxiv", "section": "computerScience"}, {"title": "Robot Policy Learning with Temporal Optimal Transport Reward", "link": "https://arxiv.org/abs/2410.21795", "description": "arXiv:2410.21795v1 Announce Type: cross \nAbstract: Reward specification is one of the most tricky problems in Reinforcement Learning, which usually requires tedious hand engineering in practice.\n  One promising approach to tackle this challenge is to adopt existing expert video demonstrations for policy learning.\n  Some recent work investigates how to learn robot policies from only a single/few expert video demonstrations.\n  For example, reward labeling via Optimal Transport (OT) has been shown to be an effective strategy to generate a proxy reward by measuring the alignment between the robot trajectory and the expert demonstrations.\n  However, previous work mostly overlooks that the OT reward is invariant to temporal order information, which could bring extra noise to the reward signal.\n  To address this issue, in this paper, we introduce the Temporal Optimal Transport (TemporalOT) reward to incorporate temporal order information for learning a more accurate OT-based proxy reward.\n  Extensive experiments on the Meta-world benchmark tasks validate the efficacy of the proposed method.\n  Code is available at: https://github.com/fuyw/TemporalOT", "published": "2024-10-31 04:00:00", "id": "36413613-75a0-430d-8024-31a81bf30e6a", "source": "arxiv", "section": "computerScience"}, {"title": "Sing it, Narrate it: Quality Musical Lyrics Translation", "link": "https://arxiv.org/abs/2410.22066", "description": "arXiv:2410.22066v1 Announce Type: cross \nAbstract: Translating lyrics for musicals presents unique challenges due to the need to ensure high translation quality while adhering to singability requirements such as length and rhyme. Existing song translation approaches often prioritize these singability constraints at the expense of translation quality, which is crucial for musicals. This paper aims to enhance translation quality while maintaining key singability features. Our method consists of three main components. First, we create a dataset to train reward models for the automatic evaluation of translation quality. Second, to enhance both singability and translation quality, we implement a two-stage training process with filtering techniques. Finally, we introduce an inference-time optimization framework for translating entire songs. Extensive experiments, including both automatic and human evaluations, demonstrate significant improvements over baseline methods and validate the effectiveness of each component in our approach.", "published": "2024-10-31 04:00:00", "id": "5db774db-c74d-4751-8579-75cc94071b8d", "source": "arxiv", "section": "computerScience"}, {"title": "MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation", "link": "https://arxiv.org/abs/2410.22223", "description": "arXiv:2410.22223v1 Announce Type: cross \nAbstract: Medical image segmentation is pivotal in healthcare, enhancing diagnostic accuracy, informing treatment strategies, and tracking disease progression. This process allows clinicians to extract critical information from visual data, enabling personalized patient care. However, developing neural networks for segmentation remains challenging, especially when preserving image resolution, which is essential in detecting subtle details that influence diagnoses. Moreover, the lack of transparency in these deep learning models has slowed their adoption in clinical practice. Efforts in model interpretability are increasingly focused on making these models' decision-making processes more transparent. In this paper, we introduce MAPUNetR, a novel architecture that synergizes the strengths of transformer models with the proven U-Net framework for medical image segmentation. Our model addresses the resolution preservation challenge and incorporates attention maps highlighting segmented regions, increasing accuracy and interpretability. Evaluated on the BraTS 2020 dataset, MAPUNetR achieved a dice score of 0.88 and a dice coefficient of 0.92 on the ISIC 2018 dataset. Our experiments show that the model maintains stable performance and potential as a powerful tool for medical image segmentation in clinical practice.", "published": "2024-10-31 04:00:00", "id": "e9a40009-d7e6-48ad-aab6-451995d26920", "source": "arxiv", "section": "computerScience"}, {"title": "The $s$-Energy and Its Applications", "link": "https://arxiv.org/abs/2410.22341", "description": "arXiv:2410.22341v1 Announce Type: cross \nAbstract: Averaging dynamics drives countless processes in physics, biology, engineering, and the social sciences. In recent years, the $s$-energy has emerged as a useful tool for bounding the convergence rates of time-varying averaging systems. We derive new bounds on the $s$-energy, which we use to resolve a number of open questions in the areas of bird flocking, opinion dynamics, and distributed motion coordination. We also use our results to provide a theoretical validation for the idea of the \"Overton Window\" as an attracting manifold of viable group opinions. Our new bounds on the $s$-energy highlight its dependency on the connectivity of the underlying networks. In this vein, we use the $s$-energy to explain the exponential gap in the convergence rates of stationary and time-varying consensus systems.", "published": "2024-10-31 04:00:00", "id": "b2ac6695-fcfe-4e2e-853d-3de316b75bba", "source": "arxiv", "section": "computerScience"}, {"title": "Representation Learning for Regime detection in Block Hierarchical Financial Markets", "link": "https://arxiv.org/abs/2410.22346", "description": "arXiv:2410.22346v1 Announce Type: cross \nAbstract: We consider financial market regime detection from the perspective of deep representation learning of the causal information geometry underpinning traded asset systems using a hierarchical correlation structure to characterise market evolution. We assess the robustness of three toy models: SPDNet, SPD-NetBN and U-SPDNet whose architectures respect the underlying Riemannian manifold of input block hierarchical SPD correlation matrices. Market phase detection for each model is carried out using three data configurations: randomised JSE Top 60 data, synthetically-generated block hierarchical SPD matrices and block-resampled chronology-preserving JSE Top 60 data. We show that using a singular performance metric is misleading in our financial market investment use cases where deep learning models overfit in learning spatio-temporal correlation dynamics.", "published": "2024-10-31 04:00:00", "id": "2f30ab94-f9a4-4c09-8093-f7ae3df203e4", "source": "arxiv", "section": "computerScience"}, {"title": "Solve Mismatch Problem in Compressed Sensing", "link": "https://arxiv.org/abs/2410.22354", "description": "arXiv:2410.22354v1 Announce Type: cross \nAbstract: This article proposes a novel algorithm for solving mismatch problem in compressed sensing. Its core is to transform mismatch problem into matched by constructing a new measurement matrix to match measurement value under unknown measurement matrix. Therefore, we propose mismatch equation and establish two types of algorithm based on it, which are matched solution of unknown measurement matrix and calibration of unknown measurement matrix. Experiments have shown that when under low gaussian noise levels, the constructed measurement matrix can transform the mismatch problem into matched and recover original images. The code is available: https://github.com/yanglebupt/mismatch-solution", "published": "2024-10-31 04:00:00", "id": "32ff7d3e-2cf4-4c84-8163-8367321712fb", "source": "arxiv", "section": "computerScience"}, {"title": "Low regularity symplectic schemes for stochastic NLS", "link": "https://arxiv.org/abs/2410.22359", "description": "arXiv:2410.22359v1 Announce Type: cross \nAbstract: We introduce a class of symplectic resonance based schemes for Schr\\\"odinger's equation in dimension one, building on the work in [1] wherein resonance based numerical schemes were developed in the context of dispersive PDE driven by time dependent, or space-time dependent, coloured noise. We work primarily with a cubic nonlinearity, advancing the approach introduced in [15] for deriving symplectic schemes in the deterministic setting. As an example of such a scheme we derive the resonance based midpoint rule for the Stochastic NLS and analyse its convergence properties.", "published": "2024-10-31 04:00:00", "id": "b300c202-af27-4a52-aab4-9c3b0fc5abab", "source": "arxiv", "section": "computerScience"}, {"title": "MMM-RS: A Multi-modal, Multi-GSD, Multi-scene Remote Sensing Dataset and Benchmark for Text-to-Image Generation", "link": "https://arxiv.org/abs/2410.22362", "description": "arXiv:2410.22362v1 Announce Type: cross \nAbstract: Recently, the diffusion-based generative paradigm has achieved impressive general image generation capabilities with text prompts due to its accurate distribution modeling and stable training process. However, generating diverse remote sensing (RS) images that are tremendously different from general images in terms of scale and perspective remains a formidable challenge due to the lack of a comprehensive remote sensing image generation dataset with various modalities, ground sample distances (GSD), and scenes. In this paper, we propose a Multi-modal, Multi-GSD, Multi-scene Remote Sensing (MMM-RS) dataset and benchmark for text-to-image generation in diverse remote sensing scenarios. Specifically, we first collect nine publicly available RS datasets and conduct standardization for all samples. To bridge RS images to textual semantic information, we utilize a large-scale pretrained vision-language model to automatically output text prompts and perform hand-crafted rectification, resulting in information-rich text-image pairs (including multi-modal images). In particular, we design some methods to obtain the images with different GSD and various environments (e.g., low-light, foggy) in a single sample. With extensive manual screening and refining annotations, we ultimately obtain a MMM-RS dataset that comprises approximately 2.1 million text-image pairs. Extensive experimental results verify that our proposed MMM-RS dataset allows off-the-shelf diffusion models to generate diverse RS images across various modalities, scenes, weather conditions, and GSD. The dataset is available at https://github.com/ljl5261/MMM-RS.", "published": "2024-10-31 04:00:00", "id": "4bec9bd9-b1f0-4731-a406-106eda1a283c", "source": "arxiv", "section": "computerScience"}, {"title": "Branch-and-bound algorithm for efficient reliability analysis of general coherent systems", "link": "https://arxiv.org/abs/2410.22363", "description": "arXiv:2410.22363v1 Announce Type: cross \nAbstract: Branch and bound algorithms have been developed for reliability analysis of coherent systems. They exhibit a set of advantages; in particular, they can find a computationally efficient representation of a system failure or survival event, which can be re-used when the input probability distributions change over time or when new data is available. However, existing branch-and-bound algorithms can handle only a limited set of system performance functions, mostly network connectivity and maximum flow. Furthermore, they run redundant analyses on component vector states whose system state can be inferred from previous analysis results. This study addresses these limitations by proposing branch and bound for reliability analysis of general coherent systems} (BRC) algorithm: an algorithm that automatically finds minimal representations of failure/survival events of general coherent systems. Computational efficiency is attained by dynamically inferring importance of component events from hitherto obtained results. We demonstrate advantages of the BRC method as a real-time risk management tool by application to the Eastern Massachusetts highway benchmark network.", "published": "2024-10-31 04:00:00", "id": "9233f4e1-23e6-4092-b80e-c2f77004ecb4", "source": "arxiv", "section": "computerScience"}, {"title": "Vascular Segmentation of Functional Ultrasound Images using Deep Learning", "link": "https://arxiv.org/abs/2410.22365", "description": "arXiv:2410.22365v1 Announce Type: cross \nAbstract: Segmentation of medical images is a fundamental task with numerous applications. While MRI, CT, and PET modalities have significantly benefited from deep learning segmentation techniques, more recent modalities, like functional ultrasound (fUS), have seen limited progress. fUS is a non invasive imaging method that measures changes in cerebral blood volume (CBV) with high spatio-temporal resolution. However, distinguishing arterioles from venules in fUS is challenging due to opposing blood flow directions within the same pixel. Ultrasound localization microscopy (ULM) can enhance resolution by tracking microbubble contrast agents but is invasive, and lacks dynamic CBV quantification. In this paper, we introduce the first deep learning-based segmentation tool for fUS images, capable of differentiating signals from different vascular compartments, based on ULM automatic annotation and enabling dynamic CBV quantification. We evaluate various UNet architectures on fUS images of rat brains, achieving competitive segmentation performance, with 90% accuracy, a 71% F1 score, and an IoU of 0.59, using only 100 temporal frames from a fUS stack. These results are comparable to those from tubular structure segmentation in other imaging modalities. Additionally, models trained on resting-state data generalize well to images captured during visual stimulation, highlighting robustness. This work offers a non-invasive, cost-effective alternative to ULM, enhancing fUS data interpretation and improving understanding of vessel function. Our pipeline shows high linear correlation coefficients between signals from predicted and actual compartments in both cortical and deeperregions, showcasing its ability to accurately capture blood flow dynamics.", "published": "2024-10-31 04:00:00", "id": "6b8b01fa-ff03-477d-ab21-59d4f900a655", "source": "arxiv", "section": "computerScience"}, {"title": "MAMMAL -- Molecular Aligned Multi-Modal Architecture and Language", "link": "https://arxiv.org/abs/2410.22367", "description": "arXiv:2410.22367v1 Announce Type: cross \nAbstract: Drug discovery typically consists of multiple steps, including identifying a target protein key to a disease's etiology, validating that interacting with this target could prevent symptoms or cure the disease, discovering a small molecule or biologic therapeutic to interact with it, and optimizing the candidate molecule through a complex landscape of required properties. Drug discovery related tasks often involve prediction and generation while considering multiple entities that potentially interact, which poses a challenge for typical AI models. For this purpose we present MAMMAL - Molecular Aligned Multi-Modal Architecture and Language - a method that we applied to create a versatile multi-task foundation model ibm/biomed.omics.bl.sm.ma-ted-458m that learns from large-scale biological datasets (2 billion samples) across diverse modalities, including proteins, small molecules, and genes. We introduce a prompt syntax that supports a wide range of classification, regression, and generation tasks. It allows combining different modalities and entity types as inputs and/or outputs. Our model handles combinations of tokens and scalars and enables the generation of small molecules and proteins, property prediction, and transcriptomic lab test predictions. We evaluated the model on 11 diverse downstream tasks spanning different steps within a typical drug discovery pipeline, where it reaches new SOTA in 9 tasks and is comparable to SOTA in 2 tasks. This performance is achieved while using a unified architecture serving all tasks, in contrast to the original SOTA performance achieved using tailored architectures.\n  The model code and pretrained weights are publicly available at https://github.com/BiomedSciAI/biomed-multi-alignment and https://huggingface.co/ibm/biomed.omics.bl.sm.ma-ted-458m.", "published": "2024-10-31 04:00:00", "id": "7ebd2c73-2889-4dfa-85ad-fe94fd86c112", "source": "arxiv", "section": "computerScience"}, {"title": "Debiasing Alternative Data for Credit Underwriting Using Causal Inference", "link": "https://arxiv.org/abs/2410.22382", "description": "arXiv:2410.22382v1 Announce Type: cross \nAbstract: Alternative data provides valuable insights for lenders to evaluate a borrower's creditworthiness, which could help expand credit access to underserved groups and lower costs for borrowers. But some forms of alternative data have historically been excluded from credit underwriting because it could act as an illegal proxy for a protected class like race or gender, causing redlining. We propose a method for applying causal inference to a supervised machine learning model to debias alternative data so that it might be used for credit underwriting. We demonstrate how our algorithm can be used against a public credit dataset to improve model accuracy across different racial groups, while providing theoretically robust nondiscrimination guarantees.", "published": "2024-10-31 04:00:00", "id": "22adfe98-8698-45b8-8b47-236eff9b36c4", "source": "arxiv", "section": "computerScience"}, {"title": "ET-Flow: Equivariant Flow-Matching for Molecular Conformer Generation", "link": "https://arxiv.org/abs/2410.22388", "description": "arXiv:2410.22388v1 Announce Type: cross \nAbstract: Predicting low-energy molecular conformations given a molecular graph is an important but challenging task in computational drug discovery. Existing state-of-the-art approaches either resort to large scale transformer-based models that diffuse over conformer fields, or use computationally expensive methods to generate initial structures and diffuse over torsion angles. In this work, we introduce Equivariant Transformer Flow (ET-Flow). We showcase that a well-designed flow matching approach with equivariance and harmonic prior alleviates the need for complex internal geometry calculations and large architectures, contrary to the prevailing methods in the field. Our approach results in a straightforward and scalable method that directly operates on all-atom coordinates with minimal assumptions. With the advantages of equivariance and flow matching, ET-Flow significantly increases the precision and physical validity of the generated conformers, while being a lighter model and faster at inference. Code is available https://github.com/shenoynikhil/ETFlow.", "published": "2024-10-31 04:00:00", "id": "6a45bcd6-a496-4881-928b-3e63574e4c92", "source": "arxiv", "section": "computerScience"}, {"title": "EfficientNet with Hybrid Attention Mechanisms for Enhanced Breast Histopathology Classification: A Comprehensive Approach", "link": "https://arxiv.org/abs/2410.22392", "description": "arXiv:2410.22392v1 Announce Type: cross \nAbstract: Breast cancer histopathology image classification is crucial for early cancer detection, offering the potential to reduce mortality rates through timely diagnosis. This paper introduces a novel approach integrating Hybrid EfficientNet models with advanced attention mechanisms, including Convolutional Block Attention Module (CBAM), Self-Attention, and Deformable Attention, to enhance feature extraction and focus on critical image regions. We evaluate the performance of our models across multiple magnification scales using publicly available histopathological datasets. Our method achieves significant improvements, with accuracy reaching 98.42% at 400X magnification, surpassing several state-of-the-art models, including VGG and ResNet architectures. The results are validated using metrics such as accuracy, F1-score, precision, and recall, demonstrating the clinical potential of our model in improving diagnostic accuracy. Furthermore, the proposed method shows increased computational efficiency, making it suitable for integration into real-time diagnostic workflows.", "published": "2024-10-31 04:00:00", "id": "cc11d89e-b60c-47c3-917d-3b4c3b069e99", "source": "arxiv", "section": "computerScience"}, {"title": "A Closer Look at Neural Codec Resynthesis: Bridging the Gap between Codec and Waveform Generation", "link": "https://arxiv.org/abs/2410.22448", "description": "arXiv:2410.22448v1 Announce Type: cross \nAbstract: Neural Audio Codecs, initially designed as a compression technique, have gained more attention recently for speech generation. Codec models represent each audio frame as a sequence of tokens, i.e., discrete embeddings. The discrete and low-frequency nature of neural codecs introduced a new way to generate speech with token-based models. As these tokens encode information at various levels of granularity, from coarse to fine, most existing works focus on how to better generate the coarse tokens. In this paper, we focus on an equally important but often overlooked question: How can we better resynthesize the waveform from coarse tokens? We point out that both the choice of learning target and resynthesis approach have a dramatic impact on the generated audio quality. Specifically, we study two different strategies based on token prediction and regression, and introduce a new method based on Schr\\\"odinger Bridge. We examine how different design choices affect machine and human perception.", "published": "2024-10-31 04:00:00", "id": "75509f27-ab1b-47da-8894-f396384f6010", "source": "arxiv", "section": "computerScience"}, {"title": "Explainable convolutional neural network model provides an alternative genome-wide association perspective on mutations in SARS-CoV-2", "link": "https://arxiv.org/abs/2410.22452", "description": "arXiv:2410.22452v1 Announce Type: cross \nAbstract: Identifying mutations of SARS-CoV-2 strains associated with their phenotypic changes is critical for pandemic prediction and prevention. We compared an explainable convolutional neural network (CNN) and the traditional genome-wide association study (GWAS) on the mutations associated with WHO labels of SARS-CoV-2, a proxy for virulence phenotypes. We trained a CNN classification model that can predict genomic sequences into Variants of Concern (VOCs), and then applied Shapley Additive explanations (SHAP) model to identify mutations that are important for the correct predictions. For comparison, we performed traditional GWAS to identify mutations associated with VOCs. Comparison of the two approaches shows that the explainable neural network approach can more effectively reveal known nucleotide substitutions associated with VOCs, such as those in the spike gene regions. Our results suggest that explainable neural networks for genomic sequences offer a promising alternative to the traditional genome wide analysis approaches.", "published": "2024-10-31 04:00:00", "id": "1616dc7d-7622-4ede-ada3-b47bcc8c1df6", "source": "arxiv", "section": "computerScience"}, {"title": "Ethical Statistical Practice and Ethical AI", "link": "https://arxiv.org/abs/2410.22475", "description": "arXiv:2410.22475v1 Announce Type: cross \nAbstract: Artificial Intelligence (AI) is a field that utilizes computing and often, data and statistics, intensively together to solve problems or make predictions. AI has been evolving with literally unbelievable speed over the past few years, and this has led to an increase in social, cultural, industrial, scientific, and governmental concerns about the ethical development and use of AI systems worldwide. The ASA has issued a statement on ethical statistical practice and AI (ASA, 2024), which echoes similar statements from other groups. Here we discuss the support for ethical statistical practice and ethical AI that has been established in long-standing human rights law and ethical practice standards for computing and statistics. There are multiple sources of support for ethical statistical practice and ethical AI deriving from these source documents, which are critical for strengthening the operationalization of the \"Statement on Ethical AI for Statistics Practitioners\". These resources are explicated for interested readers to utilize to guide their development and use of AI in, and through, their statistical practice.", "published": "2024-10-31 04:00:00", "id": "2809d327-4564-4e81-a856-7170d4f0ac9b", "source": "arxiv", "section": "computerScience"}, {"title": "Bayesian Counterfactual Prediction Models for HIV Care Retention with Incomplete Outcome and Covariate Information", "link": "https://arxiv.org/abs/2410.22481", "description": "arXiv:2410.22481v1 Announce Type: cross \nAbstract: Like many chronic diseases, human immunodeficiency virus (HIV) is managed over time at regular clinic visits. At each visit, patient features are assessed, treatments are prescribed, and a subsequent visit is scheduled. There is a need for data-driven methods for both predicting retention and recommending scheduling decisions that optimize retention. Prediction models can be useful for estimating retention rates across a range of scheduling options. However, training such models with electronic health records (EHR) involves several complexities. First, formal causal inference methods are needed to adjust for observed confounding when estimating retention rates under counterfactual scheduling decisions. Second, competing events such as death preclude retention, while censoring events render retention missing. Third, inconsistent monitoring of features such as viral load and CD4 count lead to covariate missingness. This paper presents an all-in-one approach for both predicting HIV retention and optimizing scheduling while accounting for these complexities. We formulate and identify causal retention estimands in terms of potential return-time under a hypothetical scheduling decision. Flexible Bayesian approaches are used to model the observed return-time distribution while accounting for competing and censoring events and form posterior point and uncertainty estimates for these estimands. We address the urgent need for data-driven decision support in HIV care by applying our method to EHR from the Academic Model Providing Access to Healthcare (AMPATH) - a consortium of clinics that treat HIV in Western Kenya.", "published": "2024-10-31 04:00:00", "id": "d029e53f-2066-4012-ad3e-77a71cadeb8b", "source": "arxiv", "section": "computerScience"}, {"title": "Privacy-Preserving Dynamic Assortment Selection", "link": "https://arxiv.org/abs/2410.22488", "description": "arXiv:2410.22488v1 Announce Type: cross \nAbstract: With the growing demand for personalized assortment recommendations, concerns over data privacy have intensified, highlighting the urgent need for effective privacy-preserving strategies. This paper presents a novel framework for privacy-preserving dynamic assortment selection using the multinomial logit (MNL) bandits model. Our approach employs a perturbed upper confidence bound method, integrating calibrated noise into user utility estimates to balance between exploration and exploitation while ensuring robust privacy protection. We rigorously prove that our policy satisfies Joint Differential Privacy (JDP), which better suits dynamic environments than traditional differential privacy, effectively mitigating inference attack risks. This analysis is built upon a novel objective perturbation technique tailored for MNL bandits, which is also of independent interest. Theoretically, we derive a near-optimal regret bound of $\\tilde{O}(\\sqrt{T})$ for our policy and explicitly quantify how privacy protection impacts regret. Through extensive simulations and an application to the Expedia hotel dataset, we demonstrate substantial performance enhancements over the benchmark method.", "published": "2024-10-31 04:00:00", "id": "a2863e40-2d83-4b62-af26-073ef9f35a59", "source": "arxiv", "section": "computerScience"}, {"title": "On Dialectica and Differentiation, via Categories", "link": "https://arxiv.org/abs/2410.22494", "description": "arXiv:2410.22494v1 Announce Type: cross \nAbstract: Godel's Dialectica has been introduced and developed as a logical transformation. Only recently has it been related with the, a priori unrelated, notion of differentiation: we can now read it as a differentiable program transformation. Building on that, we formulate the relation between these two notions categorically, in the framework of differential categories. Moreover, we study the relation between differential categories and Dialectica categories. We do this by taking the point of view of fibrations and (dependent) lenses, which allows us to keep a geometrical intuition in mind by considering reverse tangent categories. The viewpoint we propose opens many interesting further developments.", "published": "2024-10-31 04:00:00", "id": "5d290fb5-62cf-4a3d-a171-c85be7864a0e", "source": "arxiv", "section": "computerScience"}, {"title": "Evaluating utility in synthetic banking microdata applications", "link": "https://arxiv.org/abs/2410.22519", "description": "arXiv:2410.22519v1 Announce Type: cross \nAbstract: Financial regulators such as central banks collect vast amounts of data, but access to the resulting fine-grained banking microdata is severely restricted by banking secrecy laws. Recent developments have resulted in mechanisms that generate faithful synthetic data, but current evaluation frameworks lack a focus on the specific challenges of banking institutions and microdata. We develop a framework that considers the utility and privacy requirements of regulators, and apply this to financial usage indices, term deposit yield curves, and credit card transition matrices. Using the Central Bank of Paraguay's data, we provide the first implementation of synthetic banking microdata using a central bank's collected information, with the resulting synthetic datasets for all three domain applications being publicly available and featuring information not yet released in statistical disclosure. We find that applications less susceptible to post-processing information loss, which are based on frequency tables, are particularly suited for this approach, and that marginal-based inference mechanisms to outperform generative adversarial network models for these applications. Our results demonstrate that synthetic data generation is a promising privacy-enhancing technology for financial regulators seeking to complement their statistical disclosure, while highlighting the crucial role of evaluating such endeavors in terms of utility and privacy requirements.", "published": "2024-10-31 04:00:00", "id": "ade1c6d4-c605-4043-b866-476881fdf079", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Neural-Network-based optical temperature sensing of Semiconductor Membrane External Cavity Laser", "link": "https://arxiv.org/abs/2410.22528", "description": "arXiv:2410.22528v1 Announce Type: cross \nAbstract: A machine-learning non-contact method to determine the temperature of a laser gain medium via its laser emission with a trained few-layer neural net model is presented. The training of the feed-forward Neural Network (NN) enables the prediction of the device's properties solely from spectral data, here recorded by visible-/nearinfrared-light compact micro-spectrometers for both a diode pump laser and optically-pumped gain membrane of a semiconductor disk laser. Fiber spectrometers are used for the acquisition of large quantities of labelled intensity data, which can afterwards be used for the prediction process. Such pretrained deep NNs enable a fast, reliable and easy way to infer the temperature of a laser system such as our Membrane External Cavity Laser, at a later monitoring stage without the need of additional optical diagnostics or read-out temperature sensors. With the miniature mobile spectrometer and the remote detection ability, the temperature inference capability can be adapted for various laser diodes using transfer learning methods with pretrained models. Here, mean-square-error values for the temperature inference corresponding to sub-percent accuracy of our sensor scheme are reached, while computational cost can be saved by reducing the network depth at the here displayed cost of accuracy, as appropriate for different application scenarios.", "published": "2024-10-31 04:00:00", "id": "f41c114d-886a-49b1-9f32-dc6fba37da9e", "source": "arxiv", "section": "computerScience"}, {"title": "Adaptive Aggregation Weights for Federated Segmentation of Pancreas MRI", "link": "https://arxiv.org/abs/2410.22530", "description": "arXiv:2410.22530v1 Announce Type: cross \nAbstract: Federated learning (FL) enables collaborative model training across institutions without sharing sensitive data, making it an attractive solution for medical imaging tasks. However, traditional FL methods, such as Federated Averaging (FedAvg), face difficulties in generalizing across domains due to variations in imaging protocols and patient demographics across institutions. This challenge is particularly evident in pancreas MRI segmentation, where anatomical variability and imaging artifacts significantly impact performance. In this paper, we conduct a comprehensive evaluation of FL algorithms for pancreas MRI segmentation and introduce a novel approach that incorporates adaptive aggregation weights. By dynamically adjusting the contribution of each client during model aggregation, our method accounts for domain-specific differences and improves generalization across heterogeneous datasets. Experimental results demonstrate that our approach enhances segmentation accuracy and reduces the impact of domain shift compared to conventional FL methods while maintaining privacy-preserving capabilities. Significant performance improvements are observed across multiple hospitals (centers).", "published": "2024-10-31 04:00:00", "id": "1245c092-37d1-4c9a-ba10-20c66fad5a64", "source": "arxiv", "section": "computerScience"}, {"title": "Deep Priors for Video Quality Prediction", "link": "https://arxiv.org/abs/2410.22566", "description": "arXiv:2410.22566v1 Announce Type: cross \nAbstract: In this work, we designed a completely blind video quality assessment algorithm using the deep video prior. This work mainly explores the utility of deep video prior in estimating the visual quality of the video. In our work, we have used a single distorted video and a reference video pair to learn the deep video prior. At inference time, the learned deep prior is used to restore the original videos from the distorted videos. The ability of learned deep video prior to restore the original video from the distorted video is measured to quantify distortion in the video. Our hypothesis is that the learned deep video prior fails in restoring the highly distorted videos. The restoring ability of deep video prior is proportional to the distortion present in the video. Therefore, we propose to use the distance between the distorted video and the restored video as the perceptual quality of the video. Our algorithm is trained using a single video pair and it does not need any labelled data. We show that our proposed algorithm outperforms the existing unsupervised video quality assessment algorithms in terms of LCC and SROCC on a synthetically distorted video quality assessment dataset.", "published": "2024-10-31 04:00:00", "id": "67da8ce1-aea5-4479-80ca-fd32a035268a", "source": "arxiv", "section": "computerScience"}, {"title": "Fast Deep Hedging with Second-Order Optimization", "link": "https://arxiv.org/abs/2410.22568", "description": "arXiv:2410.22568v1 Announce Type: cross \nAbstract: Hedging exotic options in presence of market frictions is an important risk management task. Deep hedging can solve such hedging problems by training neural network policies in realistic simulated markets. Training these neural networks may be delicate and suffer from slow convergence, particularly for options with long maturities and complex sensitivities to market parameters. To address this, we propose a second-order optimization scheme for deep hedging. We leverage pathwise differentiability to construct a curvature matrix, which we approximate as block-diagonal and Kronecker-factored to efficiently precondition gradients. We evaluate our method on a challenging and practically important problem: hedging a cliquet option on a stock with stochastic volatility by trading in the spot and vanilla options. We find that our second-order scheme can optimize the policy in 1/4 of the number of steps that standard adaptive moment-based optimization takes.", "published": "2024-10-31 04:00:00", "id": "2545c437-d48b-4399-932b-8b432361bccf", "source": "arxiv", "section": "computerScience"}, {"title": "Orb: A Fast, Scalable Neural Network Potential", "link": "https://arxiv.org/abs/2410.22570", "description": "arXiv:2410.22570v1 Announce Type: cross \nAbstract: We introduce Orb, a family of universal interatomic potentials for atomistic modelling of materials. Orb models are 3-6 times faster than existing universal potentials, stable under simulation for a range of out of distribution materials and, upon release, represented a 31% reduction in error over other methods on the Matbench Discovery benchmark. We explore several aspects of foundation model development for materials, with a focus on diffusion pretraining. We evaluate Orb as a model for geometry optimization, Monte Carlo and molecular dynamics simulations.", "published": "2024-10-31 04:00:00", "id": "28f6dc6f-f457-4bc8-9157-ca6d7dc41f10", "source": "arxiv", "section": "computerScience"}, {"title": "Continuous-Time Line-of-Sight Constrained Trajectory Planning for 6-Degree of Freedom Systems", "link": "https://arxiv.org/abs/2410.22596", "description": "arXiv:2410.22596v1 Announce Type: cross \nAbstract: Perception algorithms are ubiquitous in modern autonomy stacks, providing necessary environmental information to operate in the real world. Many of these algorithms depend on the visibility of keypoints, which must remain within the robot's line-of-sight (LoS), for reliable operation. This paper tackles the challenge of maintaining LoS on such keypoints during robot movement. We propose a novel method that addresses these issues by ensuring applicability to various sensor footprints, adaptability to arbitrary nonlinear dynamics, and constant enforcement of LoS throughout the robot's path. Through our experiments, we show that the proposed approach achieves significantly reduced LoS violation and runtime compared to existing state-of-the-art methods in several representative and challenging scenarios.", "published": "2024-10-31 04:00:00", "id": "cd3ecd07-b654-440f-8356-68c6cb218c08", "source": "arxiv", "section": "computerScience"}, {"title": "Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse", "link": "https://arxiv.org/abs/2410.22598", "description": "arXiv:2410.22598v1 Announce Type: cross \nAbstract: Machine learning models are often used to automate or support decisions in applications such as lending and hiring. In such settings, consumer protection rules mandate that we provide a list of \"principal reasons\" to consumers who receive adverse decisions. In practice, lenders and employers identify principal reasons by returning the top-scoring features from a feature attribution method. In this work, we study how such practices align with one of the underlying goals of consumer protection - recourse - i.e., educating individuals on how they can attain a desired outcome. We show that standard attribution methods can mislead individuals by highlighting reasons without recourse - i.e., by presenting consumers with features that cannot be changed to achieve recourse. We propose to address these issues by scoring features on the basis of responsiveness - i.e., the probability that an individual can attain a desired outcome by changing a specific feature. We develop efficient methods to compute responsiveness scores for any model and any dataset under complex actionability constraints. We present an extensive empirical study on the responsiveness of explanations in lending and demonstrate how responsiveness scores can be used to construct feature-highlighting explanations that lead to recourse and mitigate harm by flagging instances with fixed predictions.", "published": "2024-10-31 04:00:00", "id": "21b58f16-f99f-40a0-a4d4-39aacb637548", "source": "arxiv", "section": "computerScience"}, {"title": "A physics-aware data-driven surrogate approach for fast atmospheric radiative transfer inversion", "link": "https://arxiv.org/abs/2410.22609", "description": "arXiv:2410.22609v1 Announce Type: cross \nAbstract: FORUM (Far-infrared Outgoing Radiation Understanding and Monitoring) was selected in 2019 as the ninth Earth Explorer mission by the European Space Agency (ESA). Its primary objective is to collect interferometric measurements in the Far-InfraRed (FIR) spectral range, which accounts for 50\\% of Earth's outgoing longwave radiation emitted into space, and will be observed from space for the first time. Accurate measurements of the FIR at the top of the atmosphere are crucial for improving climate models. Current instruments are insufficient, necessitating the development of advanced computational techniques. To ensure the quality of the mission data, an End-to-End Simulator (E2ES) was developed to simulate the measurement process and evaluate the effects of instrument characteristics and environmental factors. The core challenge of the mission is solving the retrieval problem, which involves estimating atmospheric properties from the radiance spectra observed by the satellite. This problem is ill-posed and regularization techniques are necessary. In this work, we present a novel and fast data-driven approach to approximate the inverse mapping. In the first phase, we generate an initial approximation of the inverse mapping using only simulated FORUM data. In the second phase, we improve this approximation by introducing climatological data as a priori information and using a neural network to estimate the optimal regularization parameters. While our approach does not match the precision of full-physics retrieval methods, its key advantage is the ability to deliver results almost instantaneously, making it highly suitable for real-time applications. Furthermore, the proposed method can provide more accurate a priori estimates for full-physics methods, thereby improving the overall accuracy of the retrieved atmospheric profiles.", "published": "2024-10-31 04:00:00", "id": "45a63c18-7f86-4526-ae84-1bb4698fae6a", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection", "link": "https://arxiv.org/abs/2410.22619", "description": "arXiv:2410.22619v1 Announce Type: cross \nAbstract: Uncontrolled cell division in the brain is what gives rise to brain tumors. If the tumor size increases by more than half, there is little hope for the patient's recovery. This emphasizes the need of rapid and precise brain tumor diagnosis. When it comes to analyzing, diagnosing, and planning therapy for brain tumors, MRI imaging plays a crucial role. A brain tumor's development history is crucial information for doctors to have. When it comes to distinguishing between human soft tissues, MRI scans are superior. In order to get reliable classification results from MRI scans quickly, deep learning is one of the most practical methods. Early human illness diagnosis has been demonstrated to be more accurate when deep learning methods are used. In the case of diagnosing a brain tumor, when even a little misdiagnosis might have serious consequences, accuracy is especially important. Disclosure of brain tumors in medical images is still a difficult task. Brain MRIs are notoriously imprecise in revealing the presence or absence of tumors. Using MRI scans of the brain, a Convolutional Neural Network (CNN) was trained to identify the presence of a tumor in this research. Results from the CNN model showed an accuracy of 99.17%. The CNN model's characteristics were also retrieved. In order to evaluate the CNN model's capability for processing images, we applied the features via the following machine learning models: KNN, Logistic regression, SVM, Random Forest, Naive Bayes, and Perception. CNN and machine learning models were also evaluated using the standard metrics of Precision, Recall, Specificity, and F1 score. The significance of the doctor's diagnosis enhanced the accuracy of the CNN model's assistance in identifying the existence of tumor and treating the patient.", "published": "2024-10-31 04:00:00", "id": "4c2c60f8-816d-41da-9af0-5e0596a5b3a4", "source": "arxiv", "section": "computerScience"}, {"title": "SleepNetZero: Zero-Burden Zero-Shot Reliable Sleep Staging With Neural Networks Based on Ballistocardiograms", "link": "https://arxiv.org/abs/2410.22646", "description": "arXiv:2410.22646v1 Announce Type: cross \nAbstract: Sleep monitoring plays a crucial role in maintaining good health, with sleep staging serving as an essential metric in the monitoring process. Traditional methods, utilizing medical sensors like EEG and ECG, can be effective but often present challenges such as unnatural user experience, complex deployment, and high costs. Ballistocardiography~(BCG), a type of piezoelectric sensor signal, offers a non-invasive, user-friendly, and easily deployable alternative for long-term home monitoring. However, reliable BCG-based sleep staging is challenging due to the limited sleep monitoring data available for BCG. A restricted training dataset prevents the model from generalization across populations. Additionally, transferring to BCG faces difficulty ensuring model robustness when migrating from other data sources. To address these issues, we introduce SleepNetZero, a zero-shot learning based approach for sleep staging. To tackle the generalization challenge, we propose a series of BCG feature extraction methods that align BCG components with corresponding respiratory, cardiac, and movement channels in PSG. This allows models to be trained on large-scale PSG datasets that are diverse in population. For the migration challenge, we employ data augmentation techniques, significantly enhancing generalizability. We conducted extensive training and testing on large datasets~(12393 records from 9637 different subjects), achieving an accuracy of 0.803 and a Cohen's Kappa of 0.718. ZeroSleepNet was also deployed in real prototype~(monitoring pads) and tested in actual hospital settings~(265 users), demonstrating an accuracy of 0.697 and a Cohen's Kappa of 0.589. To the best of our knowledge, this work represents the first known reliable BCG-based sleep staging effort and marks a significant step towards in-home health monitoring.", "published": "2024-10-31 04:00:00", "id": "d8da97e8-d3c7-4ef7-b7da-cc3714ab56c3", "source": "arxiv", "section": "computerScience"}, {"title": "Property Estimation in Geotechnical Databases Using Labeled Random Finite Sets", "link": "https://arxiv.org/abs/2410.22659", "description": "arXiv:2410.22659v1 Announce Type: cross \nAbstract: The sufficiency of accurate data is a core element in data-centric geotechnics. However, geotechnical datasets are essentially uncertain, whereupon engineers have difficulty with obtaining precise information for making decisions. This challenge is more apparent when the performance of data-driven technologies solely relies on imperfect databases or even when it is sometimes difficult to investigate sites physically. This paper introduces geotechnical property estimation from noisy and incomplete data within the labeled random finite set (LRFS) framework. We leverage the ability of the generalized labeled multi-Bernoulli (GLMB) filter, a fundamental solution for multi-object estimation, to deal with measurement uncertainties from a Bayesian perspective. In particular, this work focuses on the similarity between LRFSs and big indirect data (BID) in geotechnics as those characteristics resemble each other, which enables GLMB filtering to be exploited potentially for data-centric geotechnical engineering. Experiments for numerical study are conducted to evaluate the proposed method using a public clay database.", "published": "2024-10-31 04:00:00", "id": "141bc86a-ab0c-4516-a8df-0e6f16d5ddaa", "source": "arxiv", "section": "computerScience"}, {"title": "Dynamic PET Image Prediction Using a Network Combining Reversible and Irreversible Modules", "link": "https://arxiv.org/abs/2410.22674", "description": "arXiv:2410.22674v1 Announce Type: cross \nAbstract: Dynamic positron emission tomography (PET) images can reveal the distribution of tracers in the organism and the dynamic processes involved in biochemical reactions, and it is widely used in clinical practice. Despite the high effectiveness of dynamic PET imaging in studying the kinetics and metabolic processes of radiotracers. Pro-longed scan times can cause discomfort for both patients and medical personnel. This study proposes a dynamic frame prediction method for dynamic PET imaging, reduc-ing dynamic PET scanning time by applying a multi-module deep learning framework composed of reversible and irreversible modules. The network can predict kinetic parameter images based on the early frames of dynamic PET images, and then generate complete dynamic PET images. In validation experiments with simulated data, our network demonstrated good predictive performance for kinetic parameters and was able to reconstruct high-quality dynamic PET images. Additionally, in clinical data experiments, the network exhibited good generalization performance and attached that the proposed method has promising clinical application prospects.", "published": "2024-10-31 04:00:00", "id": "5782be01-4fbc-4398-b62e-96c6d0277c1a", "source": "arxiv", "section": "computerScience"}, {"title": "Inexact Augmented Lagrangian Methods for Conic Programs: Quadratic Growth and Linear Convergence", "link": "https://arxiv.org/abs/2410.22683", "description": "arXiv:2410.22683v1 Announce Type: cross \nAbstract: Augmented Lagrangian Methods (ALMs) are widely employed in solving constrained optimizations, and some efficient solvers are developed based on this framework. Under the quadratic growth assumption, it is known that the dual iterates and the Karush-Kuhn-Tucker (KKT) residuals of ALMs applied to semidefinite programs (SDPs) converge linearly. In contrast, the convergence rate of the primal iterates has remained elusive. In this paper, we resolve this challenge by establishing new $\\textit{quadratic growth}$ and $\\textit{error bound}$ properties for primal and dual SDPs under the strict complementarity condition. Our main results reveal that both primal and dual iterates of the ALMs converge linearly contingent solely upon the assumption of strict complementarity and a bounded solution set. This finding provides a positive answer to an open question regarding the asymptotically linear convergence of the primal iterates of ALMs applied to semidefinite optimization.", "published": "2024-10-31 04:00:00", "id": "17abd58a-6aa2-494b-bd59-403dff42ef20", "source": "arxiv", "section": "computerScience"}, {"title": "Amplitude Expansion Phase Field Crystal (APFC) Modeling based Efficient Dislocation Simulations using Fourier Pseudospectral Method", "link": "https://arxiv.org/abs/2410.22720", "description": "arXiv:2410.22720v1 Announce Type: cross \nAbstract: Crystalline defects play a critical role in determining the properties of crystalline solids, underscoring the need for accurate computational methods to study them. Lattice deformation in dislocation simulations, which involves changes in atomic positions, can be described either microscopically by specific atomic configurations or macroscopically by continuum elasticity, each with inherent limitations. The complex amplitude expansion of the phase field crystal (APFC) model provides a mesoscopic approach that bridges these scales. In this paper, we introduce a Fourier pseudospectral method for efficiently solving the APFC model in the context of crystalline defect simulations. This study marks the first application of the Fourier pseudospectral method to the APFC model. The method fully exploits the system's periodicity and facilitates the implementation of periodic boundary conditions, thanks to its high accuracy and computational efficiency. Numerical experiments conducted on two-dimensional triangular lattices and three-dimensional body-centered cubic lattices for edge dislocation geometry optimization have produced strain field images that align well with by continuum elasticity predictions. The findings demonstrate the potential of the APFC model to accurately capture the complex strain fields associated with dislocations at the mesoscopic scales, a key step toward modeling more intricate crystalline defect structures and dynamics.", "published": "2024-10-31 04:00:00", "id": "bd9be787-a79b-4928-822c-37b0acf250a5", "source": "arxiv", "section": "computerScience"}, {"title": "Identifying Drift, Diffusion, and Causal Structure from Temporal Snapshots", "link": "https://arxiv.org/abs/2410.22729", "description": "arXiv:2410.22729v1 Announce Type: cross \nAbstract: Stochastic differential equations (SDEs) are a fundamental tool for modelling dynamic processes, including gene regulatory networks (GRNs), contaminant transport, financial markets, and image generation. However, learning the underlying SDE from observational data is a challenging task, especially when individual trajectories are not observable. Motivated by burgeoning research in single-cell datasets, we present the first comprehensive approach for jointly estimating the drift and diffusion of an SDE from its temporal marginals. Assuming linear drift and additive diffusion, we prove that these parameters are identifiable from marginals if and only if the initial distribution is not invariant to a class of generalized rotations, a condition that is satisfied by most distributions. We further prove that the causal graph of any SDE with additive diffusion can be recovered from the SDE parameters. To complement this theory, we adapt entropy-regularized optimal transport to handle anisotropic diffusion, and introduce APPEX (Alternating Projection Parameter Estimation from $X_0$), an iterative algorithm designed to estimate the drift, diffusion, and causal graph of an additive noise SDE, solely from temporal marginals. We show that each of these steps are asymptotically optimal with respect to the Kullback-Leibler divergence, and demonstrate APPEX's effectiveness on simulated data from linear additive noise SDEs.", "published": "2024-10-31 04:00:00", "id": "78261515-7750-44d2-913f-4c00dfecd8cb", "source": "arxiv", "section": "computerScience"}, {"title": "st-DTPM: Spatial-Temporal Guided Diffusion Transformer Probabilistic Model for Delayed Scan PET Image Prediction", "link": "https://arxiv.org/abs/2410.22732", "description": "arXiv:2410.22732v1 Announce Type: cross \nAbstract: PET imaging is widely employed for observing biological metabolic activities within the human body. However, numerous benign conditions can cause increased uptake of radiopharmaceuticals, confounding differentiation from malignant tumors. Several studies have indicated that dual-time PET imaging holds promise in distinguishing between malignant and benign tumor processes. Nevertheless, the hour-long distribution period of radiopharmaceuticals post-injection complicates the determination of optimal timing for the second scan, presenting challenges in both practical applications and research. Notably, we have identified that delay time PET imaging can be framed as an image-to-image conversion problem. Motivated by this insight, we propose a novel spatial-temporal guided diffusion transformer probabilistic model (st-DTPM) to solve dual-time PET imaging prediction problem. Specifically, this architecture leverages the U-net framework that integrates patch-wise features of CNN and pixel-wise relevance of Transformer to obtain local and global information. And then employs a conditional DDPM model for image synthesis. Furthermore, on spatial condition, we concatenate early scan PET images and noisy PET images on every denoising step to guide the spatial distribution of denoising sampling. On temporal condition, we convert diffusion time steps and delay time to a universal time vector, then embed it to each layer of model architecture to further improve the accuracy of predictions. Experimental results demonstrated the superiority of our method over alternative approaches in preserving image quality and structural information, thereby affirming its efficacy in predictive task.", "published": "2024-10-31 04:00:00", "id": "97bb3f20-6fab-47be-a37b-ae68495ac675", "source": "arxiv", "section": "computerScience"}, {"title": "An Overview of Causal Inference using Kernel Embeddings", "link": "https://arxiv.org/abs/2410.22754", "description": "arXiv:2410.22754v1 Announce Type: cross \nAbstract: Kernel embeddings have emerged as a powerful tool for representing probability measures in a variety of statistical inference problems. By mapping probability measures into a reproducing kernel Hilbert space (RKHS), kernel embeddings enable flexible representations of complex relationships between variables. They serve as a mechanism for efficiently transferring the representation of a distribution downstream to other tasks, such as hypothesis testing or causal effect estimation. In the context of causal inference, the main challenges include identifying causal associations and estimating the average treatment effect from observational data, where confounding variables may obscure direct cause-and-effect relationships. Kernel embeddings provide a robust nonparametric framework for addressing these challenges. They allow for the representations of distributions of observational data and their seamless transformation into representations of interventional distributions to estimate relevant causal quantities. We overview recent research that leverages the expressiveness of kernel embeddings in tandem with causal inference.", "published": "2024-10-31 04:00:00", "id": "410fb9f4-f6b3-4a1b-ba38-be47d5bfd23e", "source": "arxiv", "section": "computerScience"}, {"title": "Unfolding Target Detection with State Space Model", "link": "https://arxiv.org/abs/2410.22774", "description": "arXiv:2410.22774v1 Announce Type: cross \nAbstract: Target detection is a fundamental task in radar sensing, serving as the precursor to any further processing for various applications. Numerous detection algorithms have been proposed. Classical methods based on signal processing, e.g., the most widely used CFAR, are challenging to tune and sensitive to environmental conditions. Deep learning-based methods can be more accurate and robust, yet usually lack interpretability and physical relevance. In this paper, we introduce a novel method that combines signal processing and deep learning by unfolding the CFAR detector with a state space model architecture. By reserving the CFAR pipeline yet turning its sophisticated configurations into trainable parameters, our method achieves high detection performance without manual parameter tuning, while preserving model interpretability. We implement a lightweight model of only 260K parameters and conduct real-world experiments for human target detection using FMCW radars. The results highlight the remarkable performance of the proposed method, outperforming CFAR and its variants by 10X in detection rate and false alarm rate. Our code is open-sourced here: https://github.com/aiot-lab/NeuroDet.", "published": "2024-10-31 04:00:00", "id": "7f001cb0-e29f-4805-91c9-a4b3fdecf4ad", "source": "arxiv", "section": "computerScience"}, {"title": "Machine Learning Nonadiabatic Dynamics: Eliminating Phase Freedom of Nonadiabatic Couplings with the State-Intraction State-Averaged Spin-Restricted Ensemble-Referenced Kohn-Sham Approach", "link": "https://arxiv.org/abs/2410.22801", "description": "arXiv:2410.22801v1 Announce Type: cross \nAbstract: Excited-state molecular dynamics (ESMD) simulations near conical intersections (CIs) pose significant challenges when using machine learning potentials (MLPs). Although MLPs have gained recognition for their integration into mixed quantum-classical (MQC) methods, such as trajectory surface hopping (TSH), and their capacity to model correlated electron-nuclear dynamics efficiently, difficulties persist in managing nonadiabatic dynamics. Specifically, singularities at CIs and double-valued coupling elements result in discontinuities that disrupt the smoothness of predictive functions. Partial solutions have been provided by learning diabatic Hamiltonians with phaseless loss functions to these challenges. However, a definitive method for addressing the discontinuities caused by CIs and double-valued coupling elements has yet to be developed. Here, we introduce the phaseless coupling term, $\\Delta^2$, derived from the square of the off-diagonal elements of the diabatic Hamiltonian in the SSR(2,2) formalism. This approach improves the stability and accuracy of the MLP model by addressing the issues arising from CI singularities and double-valued coupling functions. We apply this method to the penta-2,4-dieniminium cation (PSB3), demonstrating its effectiveness in improving MLP training for ML-based nonadiabatic dynamics. Our results show that the $\\Delta^2$ based ML-ESMD method can reproduce ab initio ESMD simulations, underscoring its potential and efficiency for broader applications, particularly in large-scale and long-timescale ESMD simulations.", "published": "2024-10-31 04:00:00", "id": "9e0b10e9-ad29-4f54-8019-c88be089274a", "source": "arxiv", "section": "computerScience"}, {"title": "APCodec+: A Spectrum-Coding-Based High-Fidelity and High-Compression-Rate Neural Audio Codec with Staged Training Paradigm", "link": "https://arxiv.org/abs/2410.22807", "description": "arXiv:2410.22807v1 Announce Type: cross \nAbstract: This paper proposes a novel neural audio codec, named APCodec+, which is an improved version of APCodec. The APCodec+ takes the audio amplitude and phase spectra as the coding object, and employs an adversarial training strategy. Innovatively, we propose a two-stage joint-individual training paradigm for APCodec+. In the joint training stage, the encoder, quantizer, decoder and discriminator are jointly trained with complete spectral loss, quantization loss, and adversarial loss. In the individual training stage, the encoder and quantizer fix their parameters and provide high-quality training data for the decoder and discriminator. The decoder and discriminator are individually trained from scratch without the quantization loss. The purpose of introducing individual training is to reduce the learning difficulty of the decoder, thereby further improving the fidelity of the decoded audio. Experimental results confirm that our proposed APCodec+ at low bitrates achieves comparable performance with baseline codecs at higher bitrates, thanks to the proposed staged training paradigm.", "published": "2024-10-31 04:00:00", "id": "eb01277b-ea12-42c9-bfef-ae851dfc2a0b", "source": "arxiv", "section": "computerScience"}, {"title": "Latent Diffusion, Implicit Amplification: Efficient Continuous-Scale Super-Resolution for Remote Sensing Images", "link": "https://arxiv.org/abs/2410.22830", "description": "arXiv:2410.22830v1 Announce Type: cross \nAbstract: Recent advancements in diffusion models have significantly improved performance in super-resolution (SR) tasks. However, previous research often overlooks the fundamental differences between SR and general image generation. General image generation involves creating images from scratch, while SR focuses specifically on enhancing existing low-resolution (LR) images by adding typically missing high-frequency details. This oversight not only increases the training difficulty but also limits their inference efficiency. Furthermore, previous diffusion-based SR methods are typically trained and inferred at fixed integer scale factors, lacking flexibility to meet the needs of up-sampling with non-integer scale factors. To address these issues, this paper proposes an efficient and elastic diffusion-based SR model (E$^2$DiffSR), specially designed for continuous-scale SR in remote sensing imagery. E$^2$DiffSR employs a two-stage latent diffusion paradigm. During the first stage, an autoencoder is trained to capture the differential priors between high-resolution (HR) and LR images. The encoder intentionally ignores the existing LR content to alleviate the encoding burden, while the decoder introduces an SR branch equipped with a continuous scale upsampling module to accomplish the reconstruction under the guidance of the differential prior. In the second stage, a conditional diffusion model is learned within the latent space to predict the true differential prior encoding. Experimental results demonstrate that E$^2$DiffSR achieves superior objective metrics and visual quality compared to the state-of-the-art SR methods. Additionally, it reduces the inference time of diffusion-based SR methods to a level comparable to that of non-diffusion methods.", "published": "2024-10-31 04:00:00", "id": "1faf3f58-ec34-4437-9728-d24973ab4089", "source": "arxiv", "section": "computerScience"}, {"title": "Erd\\H{o}s-Gy\\'arf\\'as conjecture on graphs without long induced paths", "link": "https://arxiv.org/abs/2410.22842", "description": "arXiv:2410.22842v1 Announce Type: cross \nAbstract: In 1994, Erd\\H{o}s and Gy\\'arf\\'as conjectured that every graph with minimum degree at least 3 has a cycle of length a power of 2. In 2022, Gao and Shan (Graphs and Combinatorics) proved that the conjecture is true for $P_8$-free graphs, i.e., graphs without any induced copies of a path on 8 vertices. In 2024, Hu and Shen (Discrete Mathematics) improved this result by proving that the conjecture is true for $P_{10}$-free graphs. With the aid of a computer search, we improve this further by proving that the conjecture is true for $P_{13}$-free graphs.", "published": "2024-10-31 04:00:00", "id": "588996f2-1114-4769-9009-c78d0c837e00", "source": "arxiv", "section": "computerScience"}, {"title": "Dataset of polarimetric images of mechanically generated water surface waves coupled with surface elevation records by wave gauges linear array", "link": "https://arxiv.org/abs/2410.22849", "description": "arXiv:2410.22849v1 Announce Type: cross \nAbstract: Effective spatio-temporal measurements of water surface elevation (water waves) in laboratory experiments are essential for scientific and engineering research. Existing techniques are often cumbersome, computationally heavy and generally suffer from limited wavenumber/frequency response. To address these challenges a novel method was developed, using polarization filter equipped camera as the main sensor and Machine Learning (ML) algorithms for data processing [1,2]. The developed method training and evaluation was based on in-house made supervised dataset. Here we present this supervised dataset of polarimetric images of the water surface coupled with the water surface elevation measurements made by a linear array of resistance-type wave gauges (WG). The water waves were mechanically generated in a laboratory waves basin, and the polarimetric images were captured under an artificial light source. Meticulous camera and WGs calibration and instruments synchronization supported high spatio-temporal resolution. The data set covers several wavefield conditions, from simple monochromatic wave trains of various steepness, to irregular wavefield of JONSWAP prescribed spectral shape and several wave breaking scenarios. The dataset contains measurements repeated in several camera positions relative to the wave field propagation direction.", "published": "2024-10-31 04:00:00", "id": "6e6dc89f-ba1d-4881-8d60-a3d33ce944de", "source": "arxiv", "section": "computerScience"}, {"title": "Hyperparameter Optimization in Machine Learning", "link": "https://arxiv.org/abs/2410.22854", "description": "arXiv:2410.22854v1 Announce Type: cross \nAbstract: Hyperparameters are configuration variables controlling the behavior of machine learning algorithms. They are ubiquitous in machine learning and artificial intelligence and the choice of their values determine the effectiveness of systems based on these technologies. Manual hyperparameter search is often unsatisfactory and becomes unfeasible when the number of hyperparameters is large. Automating the search is an important step towards automating machine learning, freeing researchers and practitioners alike from the burden of finding a good set of hyperparameters by trial and error. In this survey, we present a unified treatment of hyperparameter optimization, providing the reader with examples and insights into the state-of-the-art. We cover the main families of techniques to automate hyperparameter search, often referred to as hyperparameter optimization or tuning, including random and quasi-random search, bandit-, model- and gradient- based approaches. We further discuss extensions, including online, constrained, and multi-objective formulations, touch upon connections with other fields such as meta-learning and neural architecture search, and conclude with open questions and future research directions.", "published": "2024-10-31 04:00:00", "id": "c9623f84-11c0-4d21-87ac-2fc11c2e9ef2", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Population Scale Testis Volume Segmentation in DIXON MRI", "link": "https://arxiv.org/abs/2410.22866", "description": "arXiv:2410.22866v1 Announce Type: cross \nAbstract: Testis size is known to be one of the main predictors of male fertility, usually assessed in clinical workup via palpation or imaging. Despite its potential, population-level evaluation of testicular volume using imaging remains underexplored. Previous studies, limited by small and biased datasets, have demonstrated the feasibility of machine learning for testis volume segmentation. This paper presents an evaluation of segmentation methods for testicular volume using Magnet Resonance Imaging data from the UKBiobank. The best model achieves a median dice score of $0.87$, compared to median dice score of $0.83$ for human interrater reliability on the same dataset, enabling large-scale annotation on a population scale for the first time. Our overall aim is to provide a trained model, comparative baseline methods, and annotated training data to enhance accessibility and reproducibility in testis MRI segmentation research.", "published": "2024-10-31 04:00:00", "id": "82e7af10-cc45-4ad6-b5fc-6bafbb66483e", "source": "arxiv", "section": "computerScience"}, {"title": "Generalization Bounds via Conditional $f$-Information", "link": "https://arxiv.org/abs/2410.22887", "description": "arXiv:2410.22887v1 Announce Type: cross \nAbstract: In this work, we introduce novel information-theoretic generalization bounds using the conditional $f$-information framework, an extension of the traditional conditional mutual information (MI) framework. We provide a generic approach to derive generalization bounds via $f$-information in the supersample setting, applicable to both bounded and unbounded loss functions. Unlike previous MI-based bounds, our proof strategy does not rely on upper bounding the cumulant-generating function (CGF) in the variational formula of MI. Instead, we set the CGF or its upper bound to zero by carefully selecting the measurable function invoked in the variational formula. Although some of our techniques are partially inspired by recent advances in the coin-betting framework (e.g., Jang et al. (2023)), our results are independent of any previous findings from regret guarantees of online gambling algorithms. Additionally, our newly derived MI-based bound recovers many previous results and improves our understanding of their potential limitations. Finally, we empirically compare various $f$-information measures for generalization, demonstrating the improvement of our new bounds over the previous bounds.", "published": "2024-10-31 04:00:00", "id": "b7429269-f58d-48d3-b41c-15387ceeab22", "source": "arxiv", "section": "computerScience"}, {"title": "Augmenting Polish Automatic Speech Recognition System With Synthetic Data", "link": "https://arxiv.org/abs/2410.22903", "description": "arXiv:2410.22903v1 Announce Type: cross \nAbstract: This paper presents a system developed for submission to Poleval 2024, Task 3: Polish Automatic Speech Recognition Challenge. We describe Voicebox-based speech synthesis pipeline and utilize it to augment Conformer and Whisper speech recognition models with synthetic data. We show that addition of synthetic speech to training improves achieved results significantly. We also present final results achieved by our models in the competition.", "published": "2024-10-31 04:00:00", "id": "63c98e12-95f4-4687-b50e-675ec9fe6821", "source": "arxiv", "section": "computerScience"}, {"title": "Deduction, Constrained Zero Forcing, and Constrained Searching", "link": "https://arxiv.org/abs/2410.22962", "description": "arXiv:2410.22962v1 Announce Type: cross \nAbstract: Deduction is a recently introduced graph searching process in which searchers clear the vertex set of a graph with one move each, with each searcher's movement determined by which of its neighbors are protected by other searchers. In this paper, we show that the minimum number of searchers required to clear the graph is the same in deduction as in constrained versions of other previously studied graph processes, namely zero forcing and fast-mixed search. We give a structural characterization, new bounds and a spectrum result on the number of searchers required. We consider the complexity of computing this parameter, giving an NP-completeness result for arbitrary graphs, and exhibiting families of graphs for which the parameter can be computed in polynomial time. We also describe properties of the deduction process related to the timing of searcher movement and the success of terminal layouts.", "published": "2024-10-31 04:00:00", "id": "b92a07ab-8d2c-4f3b-8b6d-1c658825fe05", "source": "arxiv", "section": "computerScience"}, {"title": "Graph Integration for Diffusion-Based Manifold Alignment", "link": "https://arxiv.org/abs/2410.22978", "description": "arXiv:2410.22978v1 Announce Type: cross \nAbstract: Data from individual observations can originate from various sources or modalities but are often intrinsically linked. Multimodal data integration can enrich information content compared to single-source data. Manifold alignment is a form of data integration that seeks a shared, underlying low-dimensional representation of multiple data sources that emphasizes similarities between alternative representations of the same entities. Semi-supervised manifold alignment relies on partially known correspondences between domains, either through shared features or through other known associations. In this paper, we introduce two semi-supervised manifold alignment methods. The first method, Shortest Paths on the Union of Domains (SPUD), forms a unified graph structure using known correspondences to establish graph edges. By learning inter-domain geodesic distances, SPUD creates a global, multi-domain structure. The second method, MASH (Manifold Alignment via Stochastic Hopping), learns local geometry within each domain and forms a joint diffusion operator using known correspondences to iteratively learn new inter-domain correspondences through a random-walk approach. Through the diffusion process, MASH forms a coupling matrix that links heterogeneous domains into a unified structure. We compare SPUD and MASH with existing semi-supervised manifold alignment methods and show that they outperform competing methods in aligning true correspondences and cross-domain classification. In addition, we show how these methods can be applied to transfer label information between domains.", "published": "2024-10-31 04:00:00", "id": "907396cb-3926-4452-b73c-4c2a43e58711", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient Routing on Quantum Networks using Adaptive Clustering", "link": "https://arxiv.org/abs/2410.23007", "description": "arXiv:2410.23007v1 Announce Type: cross \nAbstract: We introduce QuARC, Quantum Adaptive Routing using Clusters, a novel clustering-based entanglement routing protocol that leverages redundant, multi-path routing through multi-particle projective quantum measurements to enable high-throughput, low-overhead, starvation-free entanglement distribution. At its core, QuARC periodically reconfigures the underlying quantum network into clusters of different sizes, where each cluster acts as a small network that distributes entanglement across itself, and the end-to-end entanglement is established by further distributing between clusters. QuARC does not require a-priori knowledge of any physical parameters, and is able to adapt the network configuration using static topology information, and using local (within-cluster) measurements only. We present a comprehensive simulation-based evaluation that shows QuARC is robust against changes to physical network parameters, and maintains high throughput without starvation even as network sizes scale and physical parameters degrade.", "published": "2024-10-31 04:00:00", "id": "7a95ea63-0a15-42e5-bf03-a0b14822fe51", "source": "arxiv", "section": "computerScience"}, {"title": "Audiovisual angle and voice incongruence do not affect audiovisual verbal short-term memory in virtual reality", "link": "https://arxiv.org/abs/2410.23015", "description": "arXiv:2410.23015v1 Announce Type: cross \nAbstract: Virtual reality (VR) environments are frequently used in auditory and cognitive research to imitate real-life scenarios, presumably enhancing state-of-the-art approaches with traditional computer screens. However, the effects of different display technologies on audiovisual processing remain underexplored. This study investigated how VR displayed with an head-mounted display (HMD) affects serial recall performance compared to traditional computer monitors, focusing on their effects on audiovisual processing in cognitive tasks. For that matter, we conducted two experiments with both an HMD and a computer monitor as display devices and two types of audiovisual incongruences: angle (Exp. 1) and voice (Exp. 2) incongruence. To quantify cognitive performance an audiovisual verbal serial recall (avVSR) task was developed where an embodied conversational agent (ECA) was animated to speak the target digit sequence. Even though subjective evaluations showed a higher sense of presence in the HMD condition, we found no effect of the display device on the proportion of correctly recalled digits. For the extreme conditions of angle incongruence in the computer monitor presentation the proportion of correctly recalled digits increased marginally, presumably due to raised attention, but the effect is likely too small to be meaningful. Response times were not affected by incongruences in either display device across both experiments. These findings suggest that the avVSR task is robust against angular and voice audiovisual incongruences, irrespective of the display device, at least for the conditions studied here. Hence, the study introduces the avVSR task in VR and contributes to the understanding of audiovisual integration.", "published": "2024-10-31 04:00:00", "id": "7d4c0f4a-aed7-4d72-97d0-327a5e8a181d", "source": "arxiv", "section": "computerScience"}, {"title": "Beyond hypergraph acyclicity: limits of tractability for pseudo-Boolean optimization", "link": "https://arxiv.org/abs/2410.23045", "description": "arXiv:2410.23045v1 Announce Type: cross \nAbstract: In this paper, we study the problem of minimizing a polynomial function with literals over all binary points, often referred to as pseudo-Boolean optimization. We investigate the fundamental limits of computation for this problem by providing new necessary conditions and sufficient conditions for tractability. On one hand, we obtain the first intractability results for pseudo-Boolean optimization problems on signed hypergraphs with bounded rank, in terms of the treewidth of the intersection graph. On the other hand, we introduce the nest-set gap, a new hypergraph-theoretic notion that enables us to move beyond hypergraph acyclicity, and obtain a polynomial-size extended formulation for the pseudo-Boolean polytope of a class of signed hypergraphs whose underlying hypergraphs contain beta-cycles.", "published": "2024-10-31 04:00:00", "id": "6c7d8e10-c882-4661-892e-ddc03607b078", "source": "arxiv", "section": "computerScience"}, {"title": "AI-assisted prostate cancer detection and localisation on biparametric MR by classifying radiologist-positives", "link": "https://arxiv.org/abs/2410.23084", "description": "arXiv:2410.23084v1 Announce Type: cross \nAbstract: Prostate cancer diagnosis through MR imaging have currently relied on radiologists' interpretation, whilst modern AI-based methods have been developed to detect clinically significant cancers independent of radiologists. In this study, we propose to develop deep learning models that improve the overall cancer diagnostic accuracy, by classifying radiologist-identified patients or lesions (i.e. radiologist-positives), as opposed to the existing models that are trained to discriminate over all patients. We develop a single voxel-level classification model, with a simple percentage threshold to determine positive cases, at levels of lesions, Barzell-zones and patients. Based on the presented experiments from two clinical data sets, consisting of histopathology-labelled MR images from more than 800 and 500 patients in the respective UCLA and UCL PROMIS studies, we show that the proposed strategy can improve the diagnostic accuracy, by augmenting the radiologist reading of the MR imaging. Among varying definition of clinical significance, the proposed strategy, for example, achieved a specificity of 44.1% (with AI assistance) from 36.3% (by radiologists alone), at a controlled sensitivity of 80.0% on the publicly available UCLA data set. This provides measurable clinical values in a range of applications such as reducing unnecessary biopsies, lowering cost in cancer screening and quantifying risk in therapies.", "published": "2024-10-31 04:00:00", "id": "4daeb6a3-f1f8-45b5-895e-4c11dd8ceea8", "source": "arxiv", "section": "computerScience"}, {"title": "A proof of a conjecture on trivariate permutations", "link": "https://arxiv.org/abs/2410.23097", "description": "arXiv:2410.23097v1 Announce Type: cross \nAbstract: In this note we show (for a large enough dimension of the underlying field) a conjecture of [C. Beierle, C. Carlet, G. Leander, L. Perrin, {\\em A further study of quadratic APN permutations in dimension nine}, Finite Fields Appl. 81 (2022), 102049] on a trivariate permutation. This function is a global representation of two new sporadic quadratic APN permutations in dimension $9$ found by [C. Beierle, G. Leander, {\\em New instances of quadratic APN functions}, IEEE Trans. Inf. Theory 68(1) (2022), 670--678].", "published": "2024-10-31 04:00:00", "id": "276379c4-dfda-4660-b89f-a8408fb28ca4", "source": "arxiv", "section": "computerScience"}, {"title": "Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes", "link": "https://arxiv.org/abs/2410.23126", "description": "arXiv:2410.23126v1 Announce Type: cross \nAbstract: We study the optimal memorization capacity of modern Hopfield models and Kernelized Hopfield Models (KHMs), a transformer-compatible class of Dense Associative Memories. We present a tight analysis by establishing a connection between the memory configuration of KHMs and spherical codes from information theory. Specifically, we treat the stored memory set as a specialized spherical code. This enables us to cast the memorization problem in KHMs into a point arrangement problem on a hypersphere. We show that the optimal capacity of KHMs occurs when the feature space allows memories to form an optimal spherical code. This unique perspective leads to: (i) An analysis of how KHMs achieve optimal memory capacity, and identify corresponding necessary conditions. Importantly, we establish an upper capacity bound that matches the well-known exponential lower bound in the literature. This provides the first tight and optimal asymptotic memory capacity for modern Hopfield models. (ii) A sub-linear time algorithm $\\mathtt{U}\\text{-}\\mathtt{Hop}$+ to reach KHMs' optimal capacity. (iii) An analysis of the scaling behavior of the required feature dimension relative to the number of stored memories. These efforts improve both the retrieval capability of KHMs and the representation learning of corresponding transformers. Experimentally, we provide thorough numerical results to back up theoretical findings.", "published": "2024-10-31 04:00:00", "id": "b9414aad-0d66-4997-a305-503711b6f9f7", "source": "arxiv", "section": "computerScience"}, {"title": "Compositional Segmentation of Cardiac Images Leveraging Metadata", "link": "https://arxiv.org/abs/2410.23130", "description": "arXiv:2410.23130v1 Announce Type: cross \nAbstract: Cardiac image segmentation is essential for automated cardiac function assessment and monitoring of changes in cardiac structures over time. Inspired by coarse-to-fine approaches in image analysis, we propose a novel multitask compositional segmentation approach that can simultaneously localize the heart in a cardiac image and perform part-based segmentation of different regions of interest. We demonstrate that this compositional approach achieves better results than direct segmentation of the anatomies. Further, we propose a novel Cross-Modal Feature Integration (CMFI) module to leverage the metadata related to cardiac imaging collected during image acquisition. We perform experiments on two different modalities, MRI and ultrasound, using public datasets, Multi-disease, Multi-View, and Multi-Centre (M&amp;Ms-2) and Multi-structure Ultrasound Segmentation (CAMUS) data, to showcase the efficiency of the proposed compositional segmentation method and Cross-Modal Feature Integration module incorporating metadata within the proposed compositional segmentation network. The source code is available: https://github.com/kabbas570/CompSeg-MetaData.", "published": "2024-10-31 04:00:00", "id": "7dcfe973-616d-477d-9e58-64bcfb8c234e", "source": "arxiv", "section": "computerScience"}, {"title": "When can classical neural networks represent quantum states?", "link": "https://arxiv.org/abs/2410.23152", "description": "arXiv:2410.23152v1 Announce Type: cross \nAbstract: A naive classical representation of an n-qubit state requires specifying exponentially many amplitudes in the computational basis. Past works have demonstrated that classical neural networks can succinctly express these amplitudes for many physically relevant states, leading to computationally powerful representations known as neural quantum states. What underpins the efficacy of such representations? We show that conditional correlations present in the measurement distribution of quantum states control the performance of their neural representations. Such conditional correlations are basis dependent, arise due to measurement-induced entanglement, and reveal features not accessible through conventional few-body correlations often examined in studies of phases of matter. By combining theoretical and numerical analysis, we demonstrate how the state's entanglement and sign structure, along with the choice of measurement basis, give rise to distinct patterns of short- or long-range conditional correlations. Our findings provide a rigorous framework for exploring the expressive power of neural quantum states.", "published": "2024-10-31 04:00:00", "id": "4e2fe14c-19b6-4d13-b0a6-6a438324020a", "source": "arxiv", "section": "computerScience"}, {"title": "Nested ResNet: A Vision-Based Method for Detecting the Sensing Area of a Drop-in Gamma Probe", "link": "https://arxiv.org/abs/2410.23154", "description": "arXiv:2410.23154v1 Announce Type: cross \nAbstract: Purpose: Drop-in gamma probes are widely used in robotic-assisted minimally invasive surgery (RAMIS) for lymph node detection. However, these devices only provide audio feedback on signal intensity, lacking the visual feedback necessary for precise localisation. Previous work attempted to predict the sensing area location using laparoscopic images, but the prediction accuracy was unsatisfactory. Improvements are needed in the deep learning-based regression approach.\n  Methods: We introduce a three-branch deep learning framework to predict the sensing area of the probe. Specifically, we utilise the stereo laparoscopic images as input for the main branch and develop a Nested ResNet architecture. The framework also incorporates depth estimation via transfer learning and orientation guidance through probe axis sampling. The combined features from each branch enhanced the accuracy of the prediction.\n  Results: Our approach has been evaluated on a publicly available dataset, demonstrating superior performance over previous methods. In particular, our method resulted in a 22.10\\% decrease in 2D mean error and a 41.67\\% reduction in 3D mean error. Additionally, qualitative comparisons further demonstrated the improved precision of our approach.\n  Conclusion: With extensive evaluation, our solution significantly enhances the accuracy and reliability of sensing area predictions. This advancement enables visual feedback during the use of the drop-in gamma probe in surgery, providing surgeons with more accurate and reliable localisation.}", "published": "2024-10-31 04:00:00", "id": "e63d5edb-deee-47fe-9d50-003895ea65b8", "source": "arxiv", "section": "computerScience"}, {"title": "Functional Gradient Flows for Constrained Sampling", "link": "https://arxiv.org/abs/2410.23170", "description": "arXiv:2410.23170v1 Announce Type: cross \nAbstract: Recently, through a unified gradient flow perspective of Markov chain Monte Carlo (MCMC) and variational inference (VI), particle-based variational inference methods (ParVIs) have been proposed that tend to combine the best of both worlds. While typical ParVIs such as Stein Variational Gradient Descent (SVGD) approximate the gradient flow within a reproducing kernel Hilbert space (RKHS), many attempts have been made recently to replace RKHS with more expressive function spaces, such as neural networks. While successful, these methods are mainly designed for sampling from unconstrained domains. In this paper, we offer a general solution to constrained sampling by introducing a boundary condition for the gradient flow which would confine the particles within the specific domain. This allows us to propose a new functional gradient ParVI method for constrained sampling, called constrained functional gradient flow (CFG), with provable continuous-time convergence in total variation (TV). We also present novel numerical strategies to handle the boundary integral term arising from the domain constraints. Our theory and experiments demonstrate the effectiveness of the proposed framework.", "published": "2024-10-31 04:00:00", "id": "57d873c6-e4a8-4b42-ab64-920bc4ef5b03", "source": "arxiv", "section": "computerScience"}, {"title": "Far-right party influence on polarization dynamics in electoral campaign", "link": "https://arxiv.org/abs/2410.23177", "description": "arXiv:2410.23177v1 Announce Type: cross \nAbstract: Political polarization has attracted increasing attention in recent years, driven by the rise of social media and the global emergence of far-right populist movements. This study investigates the dynamics of structural polarization during electoral campaigns in multi-party systems, with a particular focus on the presence of far-right actors and their influence on polarization patterns and hate speech. Using retweet networks as a measure of structural polarization, we analyze two case studies in Spain: the 2022 Andalusia regional elections, where the far-right party Vox was a significant contender, and the 2019 Barcelona city council elections, where the party had no representation. Our results reveal that the presence of a far-right party intensifies polarization, leading to the formation of two distinct ideological blocks aligned along left-right ideological axes, as observed in Andalusia. In contrast, the Catalan independence movement in Barcelona diluted the alignment of voters, resulting in a more complex, multi-axis polarization landscape. We also explore the relationship between polarization and hate speech, finding an anti-correlation between them in both cases. Our findings underscore the significant role of far-right movements in driving political polarization and the nuanced effects of different political contexts on polarization dynamics.", "published": "2024-10-31 04:00:00", "id": "3398c5c8-16ea-45cb-a4e2-884d7dd18c1e", "source": "arxiv", "section": "computerScience"}, {"title": "Uncertainty quantification for fast reconstruction methods using augmented equivariant bootstrap: Application to radio interferometry", "link": "https://arxiv.org/abs/2410.23178", "description": "arXiv:2410.23178v1 Announce Type: cross \nAbstract: The advent of next-generation radio interferometers like the Square Kilometer Array promises to revolutionise our radio astronomy observational capabilities. The unprecedented volume of data these devices generate requires fast and accurate image reconstruction algorithms to solve the ill-posed radio interferometric imaging problem. Most state-of-the-art reconstruction methods lack trustworthy and scalable uncertainty quantification, which is critical for the rigorous scientific interpretation of radio observations. We propose an unsupervised technique based on a conformalized version of a radio-augmented equivariant bootstrapping method, which allows us to quantify uncertainties for fast reconstruction methods. Noticeably, we rely on reconstructions from ultra-fast unrolled algorithms. The proposed method brings more reliable uncertainty estimations to our problem than existing alternatives.", "published": "2024-10-31 04:00:00", "id": "2015ed8e-bd85-4911-8a7f-6e81fdd60a3f", "source": "arxiv", "section": "computerScience"}, {"title": "Generalized cryptographic semi-regular sequences: A variant of Fr\\\"{o}berg conjecture and a simple complexity estimation for Gr\\\"{o}bner basis computation", "link": "https://arxiv.org/abs/2410.23211", "description": "arXiv:2410.23211v1 Announce Type: cross \nAbstract: In this paper, we study generalized cryptographic semi-regular sequences, which are expected to generic in the space of homogeneous polynomial sequences on which the coordinate rings have Krull dimension one. We provide an upper-bound on the complexity of the Gr\\\"{o}bner basis computation for such a sequence.", "published": "2024-10-31 04:00:00", "id": "0b93c630-8c06-4472-9572-4912cf504af2", "source": "arxiv", "section": "computerScience"}, {"title": "Improved convergence rate of kNN graph Laplacians", "link": "https://arxiv.org/abs/2410.23212", "description": "arXiv:2410.23212v1 Announce Type: cross \nAbstract: In graph-based data analysis, $k$-nearest neighbor ($k$NN) graphs are widely used due to their adaptivity to local data densities. Allowing weighted edges in the graph, the kernelized graph affinity provides a more general type of $k$NN graph where the $k$NN distance is used to set the kernel bandwidth adaptively. In this work, we consider a general class of $k$NN graph where the graph affinity is $W_{ij} = \\epsilon^{-d/2} \\; k_0 ( \\| x_i - x_j \\|^2 / \\epsilon \\phi( \\widehat{\\rho}(x_i), \\widehat{\\rho}(x_j) )^2 ) $, with $\\widehat{\\rho}(x)$ being the (rescaled) $k$NN distance at the point $x$, $\\phi$ a symmetric bi-variate function, and $k_0$ a non-negative function on $[0,\\infty)$. Under the manifold data setting, where $N$ i.i.d. samples $x_i$ are drawn from a density $p$ on a $d$-dimensional unknown manifold embedded in a high dimensional Euclidean space, we prove the point-wise convergence of the $k$NN graph Laplacian to the limiting manifold operator (depending on $p$) at the rate of $O(N^{-2/(d+6)}\\,)$, up to a log factor, when $k_0$ and $\\phi$ have $C^3$ regularity and satisfy other technical conditions. This fast rate is obtained when $\\epsilon \\sim N^{-2/(d+6)}\\,$ and $k \\sim N^{6/(d+6)}\\,$, both at the optimal order to balance the theoretical bias and variance errors. When $k_0$ and $\\phi$ have lower regularities, including when $k_0$ is a compactly supported function as in the standard $k$NN graph, the convergence rate degenerates to $O(N^{-1/(d+4)}\\,)$. Our improved convergence rate is based on a refined analysis of the $k$NN estimator, which can be of independent interest. We validate our theory by numerical experiments on simulated data.", "published": "2024-10-31 04:00:00", "id": "48524477-9df6-40e8-a099-be77ee72e959", "source": "arxiv", "section": "computerScience"}, {"title": "Crosstalk Attack Resilient RNS Quantum Addition", "link": "https://arxiv.org/abs/2410.23217", "description": "arXiv:2410.23217v1 Announce Type: cross \nAbstract: As quantum computers scale, the rise of multi-user and cloud-based quantum platforms can lead to new security challenges. Attacks within shared execution environments become increasingly feasible due to the crosstalk noise that, in combination with quantum computer's hardware specifications, can be exploited in form of crosstalk attack. Our work pursues crosstalk attack implementation in ion-trap quantum computers. We propose three novel quantum crosstalk attacks designed for ion trap qubits: (i) Alternate CNOT attack (ii) Superposition Alternate CNOT (SAC) attack (iii) Alternate Phase Change (APC) attack. We demonstrate the effectiveness of proposed attacks by conducting noise-based simulations on a commercial 20-qubit ion-trap quantum computer. The proposed attacks achieve an impressive reduction of up to 42.2% in output probability for Quantum Full Adders (QFA) having 6 to 9-qubit output. Finally, we investigate the possibility of mitigating crosstalk attacks by using Residue Number System (RNS) based Parallel Quantum Addition (PQA). We determine that PQA achieves higher attack resilience against crosstalk attacks in the form of 24.3% to 133.5% improvement in output probability against existing Non Parallel Quantum Addition (NPQA). Through our systematic methodology, we demonstrate how quantum properties such as superposition and phase transition can lead to crosstalk attacks and also how parallel quantum computing can help secure against these attacks.", "published": "2024-10-31 04:00:00", "id": "28465d62-71ff-4f97-938a-6eb0db92c595", "source": "arxiv", "section": "computerScience"}, {"title": "Full-waveform earthquake source inversion using simulation-based inference", "link": "https://arxiv.org/abs/2410.23238", "description": "arXiv:2410.23238v1 Announce Type: cross \nAbstract: This paper presents a novel framework for full-waveform seismic source inversion using simulation-based inference (SBI). Traditional probabilistic approaches often rely on simplifying assumptions about data errors, which we show can lead to inaccurate uncertainty quantification. SBI addresses this limitation by building an empirical probabilistic model of the data errors using machine learning models, known as neural density estimators, which can then be integrated into the Bayesian inference framework. We apply the SBI framework to point-source moment tensor inversions as well as joint moment tensor and time-location inversions. We construct a range of synthetic examples to explore the quality of the SBI solutions, as well as to compare the SBI results with standard Gaussian likelihood-based Bayesian inversions. We then demonstrate that under real seismic noise, common Gaussian likelihood assumptions for treating full-waveform data yield overconfident posterior distributions that underestimate the moment tensor component uncertainties by up to a factor of 3. We contrast this with SBI, which produces well-calibrated posteriors that generally agree with the true seismic source parameters, and offers an order-of-magnitude reduction in the number of simulations required to perform inference compared to standard Monte Carlo techniques. Finally, we apply our methodology to a pair of moderate magnitude earthquakes in the North Atlantic. We utilise seismic waveforms recorded by the recent UPFLOW ocean bottom seismometer array as well as by regional land stations in the Azores, comparing full moment tensor and source-time location posteriors between SBI and a Gaussian likelihood approach. We find that our adaptation of SBI can be directly applied to real earthquake sources to efficiently produce high quality posterior distributions that significantly improve upon Gaussian likelihood approaches.", "published": "2024-10-31 04:00:00", "id": "af1604b9-7c66-4704-ba4a-9303dace852b", "source": "arxiv", "section": "computerScience"}, {"title": "Very fast Bayesian Additive Regression Trees on GPU", "link": "https://arxiv.org/abs/2410.23244", "description": "arXiv:2410.23244v1 Announce Type: cross \nAbstract: Bayesian Additive Regression Trees (BART) is a nonparametric Bayesian regression technique based on an ensemble of decision trees. It is part of the toolbox of many statisticians. The overall statistical quality of the regression is typically higher than other generic alternatives, and it requires less manual tuning, making it a good default choice. However, it is a niche method compared to its natural competitor XGBoost, due to the longer running time, making sample sizes above 10,000-100,000 a nuisance. I present a GPU-enabled implementation of BART, faster by up to 200x relative to a single CPU core, making BART competitive in running time with XGBoost. This implementation is available in the Python package bartz.", "published": "2024-10-31 04:00:00", "id": "a8e8a12f-650a-47c6-8e9d-b536bbaad1db", "source": "arxiv", "section": "computerScience"}, {"title": "bit2bit: 1-bit quanta video reconstruction via self-supervised photon prediction", "link": "https://arxiv.org/abs/2410.23247", "description": "arXiv:2410.23247v1 Announce Type: cross \nAbstract: Quanta image sensors, such as SPAD arrays, are an emerging sensor technology, producing 1-bit arrays representing photon detection events over exposures as short as a few nanoseconds. In practice, raw data are post-processed using heavy spatiotemporal binning to create more useful and interpretable images at the cost of degrading spatiotemporal resolution. In this work, we propose bit2bit, a new method for reconstructing high-quality image stacks at the original spatiotemporal resolution from sparse binary quanta image data. Inspired by recent work on Poisson denoising, we developed an algorithm that creates a dense image sequence from sparse binary photon data by predicting the photon arrival location probability distribution. However, due to the binary nature of the data, we show that the assumption of a Poisson distribution is inadequate. Instead, we model the process with a Bernoulli lattice process from the truncated Poisson. This leads to the proposal of a novel self-supervised solution based on a masked loss function. We evaluate our method using both simulated and real data. On simulated data from a conventional video, we achieve 34.35 mean PSNR with extremely photon-sparse binary input (<0.06 photons per pixel per frame). We also present a novel dataset containing a wide range of real SPAD high-speed videos under various challenging imaging conditions. The scenes cover strong/weak ambient light, strong motion, ultra-fast events, etc., which will be made available to the community, on which we demonstrate the promise of our approach. Both reconstruction quality and throughput substantially surpass the state-of-the-art methods (e.g., Quanta Burst Photography (QBP)). Our approach significantly enhances the visualization and usability of the data, enabling the application of existing analysis techniques.", "published": "2024-10-31 04:00:00", "id": "47b3ca26-55ec-4601-bb5a-1142e32daa76", "source": "arxiv", "section": "computerScience"}, {"title": "Generalized Short Path Algorithms: Towards Super-Quadratic Speedup over Markov Chain Search for Combinatorial Optimization", "link": "https://arxiv.org/abs/2410.23270", "description": "arXiv:2410.23270v1 Announce Type: cross \nAbstract: We analyze generalizations of algorithms based on the short-path framework first proposed by Hastings [Quantum 2, 78 (2018)], which has been extended and shown by Dalzell et al. [STOC '22] to achieve super-Grover speedups for certain binary optimization problems. We demonstrate that, under some commonly satisfied technical conditions, an appropriate generalization can achieve super-quadratic speedups not only over unstructured search but also over a classical optimization algorithm that searches for the optimum by drawing samples from the stationary distribution of a Markov Chain. We employ this framework to obtain algorithms for problems including variants of Max-Bisection, Max Independent Set, the Ising Model, and the Sherrington Kirkpatrick Model, whose runtimes are asymptotically faster than those obtainable from previous short path techniques. For random regular graphs of sufficiently high degree, our algorithm is super-quadratically faster than the best rigorously proven classical runtimes for regular graphs. Our results also shed light on the quantum nature of short path algorithms, by identifying a setting where our algorithm is super-quadratically faster than any polynomial time Gibbs sampler, unless NP = RP. We conclude the paper with a numerical analysis that guides the choice of parameters for short path algorithms and raises the possibility of super-quadratic speedups in settings that are currently beyond our theoretical analysis.", "published": "2024-10-31 04:00:00", "id": "52722a5f-27a0-4a0d-91d3-e2955af8678f", "source": "arxiv", "section": "computerScience"}, {"title": "Conditional Forecasting of Margin Calls using Dynamic Graph Neural Networks", "link": "https://arxiv.org/abs/2410.23275", "description": "arXiv:2410.23275v1 Announce Type: cross \nAbstract: We introduce a novel Dynamic Graph Neural Network (DGNN) architecture for solving conditional $m$-steps ahead forecasting problems in temporal financial networks. The proposed DGNN is validated on simulated data from a temporal financial network model capturing stylized features of Interest Rate Swaps (IRSs) transaction networks, where financial entities trade swap contracts dynamically and the network topology evolves conditionally on a reference rate. The proposed model is able to produce accurate conditional forecasts of net variation margins up to a $21$-day horizon by leveraging conditional information under pre-determined stress test scenarios. Our work shows that the network dynamics can be successfully incorporated into stress-testing practices, thus providing regulators and policymakers with a crucial tool for systemic risk monitoring.", "published": "2024-10-31 04:00:00", "id": "c3d0bc51-990d-42cd-abd9-624cf6d54b62", "source": "arxiv", "section": "computerScience"}, {"title": "3D Crowd Counting via Geometric Attention-guided Multi-View Fusion", "link": "https://arxiv.org/abs/2003.08162", "description": "arXiv:2003.08162v2 Announce Type: replace \nAbstract: Recently multi-view crowd counting using deep neural networks has been proposed to enable counting in large and wide scenes using multiple cameras. The current methods project the camera-view features to the average-height plane of the 3D world, and then fuse the projected multi-view features to predict a 2D scene-level density map on the ground (i.e., birds-eye view). Unlike the previous research, we consider the variable height of the people in the 3D world and propose to solve the multi-view crowd counting task through 3D feature fusion with 3D scene-level density maps, instead of the 2D density map on the ground plane. Compared to 2D fusion, the 3D fusion extracts more information of the people along the z-dimension (height), which helps to address the scale variations across multiple views. The 3D density maps still preserve the 2D density maps property that the sum is the count, while also providing 3D information about the crowd density. Furthermore, instead of using the standard method of copying the features along the view ray in the 2D-to-3D projection, we propose an attention module based on a height estimation network, which forces each 2D pixel to be projected to one 3D voxel along the view ray. We also explore the projection consistency among the 3D prediction and the ground truth in the 2D views to further enhance the counting performance. The proposed method is tested on the synthetic and real-world multiview counting datasets and achieves better or comparable counting performance to the state-of-the-art.", "published": "2024-10-31 04:00:00", "id": "7bf66bb4-25d0-4ce5-af03-e6c957ba41e1", "source": "arxiv", "section": "computerScience"}, {"title": "A Strong Baseline for Semi-Supervised Incremental Few-Shot Learning", "link": "https://arxiv.org/abs/2110.11128", "description": "arXiv:2110.11128v3 Announce Type: replace \nAbstract: Few-shot learning (FSL) aims to learn models that generalize to novel classes with limited training samples. Recent works advance FSL towards a scenario where unlabeled examples are also available and propose semi-supervised FSL methods. Another line of methods also cares about the performance of base classes in addition to the novel ones and thus establishes the incremental FSL scenario. In this paper, we generalize the above two under a more realistic yet complex setting, named by Semi-Supervised Incremental Few-Shot Learning (S2 I-FSL). To tackle the task, we propose a novel paradigm containing two parts: (1) a well-designed meta-training algorithm for mitigating ambiguity between base and novel classes caused by unreliable pseudo labels and (2) a model adaptation mechanism to learn discriminative features for novel classes while preserving base knowledge using few labeled and all the unlabeled data. Extensive experiments on standard FSL, semi-supervised FSL, incremental FSL, and the firstly built S2 I-FSL benchmarks demonstrate the effectiveness of our proposed method.", "published": "2024-10-31 04:00:00", "id": "be4536f5-eaf9-4b10-a26a-cf7c81a03557", "source": "arxiv", "section": "computerScience"}, {"title": "Scientific and Technological Information Oriented Semantics-adversarial and Media-adversarial Cross-media Retrieval", "link": "https://arxiv.org/abs/2203.08615", "description": "arXiv:2203.08615v3 Announce Type: replace \nAbstract: Cross-media retrieval of scientific and technological information is one of the important tasks in the cross-media study. Cross-media scientific and technological information retrieval obtain target information from massive multi-source and heterogeneous scientific and technological resources, which helps to design applications that meet users' needs, including scientific and technological information recommendation, personalized scientific and technological information retrieval, etc. The core of cross-media retrieval is to learn a common subspace, so that data from different media can be directly compared with each other after being mapped into this subspace. In subspace learning, existing methods often focus on modeling the discrimination of intra-media data and the invariance of inter-media data after mapping; however, they ignore the semantic consistency of inter-media data before and after mapping and media discrimination of intra-semantics data, which limit the result of cross-media retrieval. In light of this, we propose a scientific and technological information oriented Semantics-adversarial and Media-adversarial Cross-media Retrieval method (SMCR) to find an effective common subspace. Specifically, SMCR minimizes the loss of inter-media semantic consistency in addition to modeling intra-media semantic discrimination, to preserve semantic similarity before and after mapping. Furthermore, SMCR constructs a basic feature mapping network and a refined feature mapping network to jointly minimize the media discriminative loss within semantics, so as to enhance the feature mapping network's ability to confuse the media discriminant network. Experimental results on two datasets demonstrate that the proposed SMCR outperforms state-of-the-art methods in cross-media retrieval.", "published": "2024-10-31 04:00:00", "id": "8b433af2-cbad-4fc1-a260-59cc18e13da6", "source": "arxiv", "section": "computerScience"}, {"title": "Metric Based Few-Shot Graph Classification", "link": "https://arxiv.org/abs/2206.03695", "description": "arXiv:2206.03695v3 Announce Type: replace \nAbstract: Many modern deep-learning techniques do not work without enormous datasets. At the same time, several fields demand methods working in scarcity of data. This problem is even more complex when the samples have varying structures, as in the case of graphs. Graph representation learning techniques have recently proven successful in a variety of domains. Nevertheless, the employed architectures perform miserably when faced with data scarcity. On the other hand, few-shot learning allows employing modern deep learning models in scarce data regimes without waiving their effectiveness. In this work, we tackle the problem of few-shot graph classification, showing that equipping a simple distance metric learning baseline with a state-of-the-art graph embedder allows to obtain competitive results on the task. While the simplicity of the architecture is enough to outperform more complex ones, it also allows straightforward additions. To this end, we show that additional improvements may be obtained by encouraging a task-conditioned embedding space. Finally, we propose a MixUp-based online data augmentation technique acting in the latent space and show its effectiveness on the task.", "published": "2024-10-31 04:00:00", "id": "44b9bfbf-1b41-448e-b8b4-f387a9c07d68", "source": "arxiv", "section": "computerScience"}, {"title": "No imputation without representation", "link": "https://arxiv.org/abs/2206.14254", "description": "arXiv:2206.14254v4 Announce Type: replace \nAbstract: By filling in missing values in datasets, imputation allows these datasets to be used with algorithms that cannot handle missing values by themselves. However, missing values may in principle contribute useful information that is lost through imputation. The missing-indicator approach can be used in combination with imputation to instead represent this information as a part of the dataset. There are several theoretical considerations why missing-indicators may or may not be beneficial, but there has not been any large-scale practical experiment on real-life datasets to test this question for machine learning predictions. We perform this experiment for three imputation strategies and a range of different classification algorithms, on the basis of twenty real-life datasets. In a follow-up experiment, we determine attribute-specific missingness thresholds for each classifier above which missing-indicators are more likely than not to increase classification performance. And in a second follow-up experiment, we evaluate numerical imputation of one-hot encoded categorical attributes. We reach the following conclusions. Firstly, missing-indicators generally increase classification performance. Secondly, with missing-indicators, nearest neighbour and iterative imputation do not lead to better performance than simple mean/mode imputation. Thirdly, for decision trees, pruning is necessary to prevent overfitting. Fourthly, the thresholds above which missing-indicators are more likely than not to improve performance are lower for categorical attributes than for numerical attributes. Lastly, mean imputation of numerical attributes preserves some of the information from missing values. Consequently, when not using missing-indicators it can be advantageous to apply mean imputation to one-hot encoded categorical attributes instead of mode imputation.", "published": "2024-10-31 04:00:00", "id": "c4f011dd-cda6-4f23-a410-d11d5612eecd", "source": "arxiv", "section": "computerScience"}, {"title": "MPPI-IPDDP: Hybrid Method of Collision-Free Smooth Trajectory Generation for Autonomous Robots", "link": "https://arxiv.org/abs/2208.02439", "description": "arXiv:2208.02439v2 Announce Type: replace \nAbstract: This paper presents a hybrid trajectory optimization method designed to generate collision-free, smooth trajectories for autonomous mobile robots. By combining sampling-based Model Predictive Path Integral (MPPI) control with gradient-based Interior-Point Differential Dynamic Programming (IPDDP), we leverage their respective strengths in exploration and smoothing. The proposed method, MPPI-IPDDP, involves three steps: First, MPPI control is used to generate a coarse trajectory. Second, a collision-free convex corridor is constructed. Third, IPDDP is applied to smooth the coarse trajectory, utilizing the collision-free corridor from the second step. To demonstrate the effectiveness of our approach, we apply the proposed algorithm to trajectory optimization for differential-drive wheeled mobile robots and point-mass quadrotors. In comparisons with other MPPI variants and continuous optimization-based solvers, our method shows superior performance in terms of computational robustness and trajectory smoothness.\n  Code: https://github.com/i-ASL/mppi-ipddp Video: https://youtu.be/-oUAt5sd9Bk", "published": "2024-10-31 04:00:00", "id": "9199018e-3609-426e-8253-9f7fb1a47857", "source": "arxiv", "section": "computerScience"}, {"title": "BeGin: Extensive Benchmark Scenarios and An Easy-to-use Framework for Graph Continual Learning", "link": "https://arxiv.org/abs/2211.14568", "description": "arXiv:2211.14568v5 Announce Type: replace \nAbstract: Continual Learning (CL) is the process of learning ceaselessly a sequence of tasks. Most existing CL methods deal with independent data (e.g., images and text) for which many benchmark frameworks and results under standard experimental settings are available. Compared to them, however, CL methods for graph data (graph CL) are relatively underexplored because of (a) the lack of standard experimental settings, especially regarding how to deal with the dependency between instances, (b) the lack of benchmark datasets and scenarios, and (c) high complexity in implementation and evaluation due to the dependency. In this paper, regarding (a) we define four standard incremental settings (task-, class-, domain-, and time-incremental) for node-, link-, and graph-level problems, extending the previously explored scope. Regarding (b), we provide 35 benchmark scenarios based on 24 real-world graphs. Regarding (c), we develop BeGin, an easy and fool-proof framework for graph CL. BeGin is easily extended since it is modularized with reusable modules for data processing, algorithm design, and evaluation. Especially, the evaluation module is completely separated from user code to eliminate potential mistakes. Regarding benchmark results, we cover 3x more combinations of incremental settings and levels of problems than the latest benchmark. All assets for the benchmark framework are publicly available at https://github.com/ShinhwanKang/BeGin.", "published": "2024-10-31 04:00:00", "id": "57b5135f-ec21-4043-937c-48153a9813d9", "source": "arxiv", "section": "computerScience"}, {"title": "AugTriever: Unsupervised Dense Retrieval and Domain Adaptation by Scalable Data Augmentation", "link": "https://arxiv.org/abs/2212.08841", "description": "arXiv:2212.08841v4 Announce Type: replace \nAbstract: Dense retrievers have made significant strides in text retrieval and open-domain question answering. However, most of these achievements have relied heavily on extensive human-annotated supervision. In this study, we aim to develop unsupervised methods for improving dense retrieval models. We propose two approaches that enable annotation-free and scalable training by creating pseudo querydocument pairs: query extraction and transferred query generation. The query extraction method involves selecting salient spans from the original document to generate pseudo queries. On the other hand, the transferred query generation method utilizes generation models trained for other NLP tasks, such as summarization, to produce pseudo queries. Through extensive experimentation, we demonstrate that models trained using these augmentation methods can achieve comparable, if not better, performance than multiple strong dense baselines. Moreover, combining these strategies leads to further improvements, resulting in superior performance of unsupervised dense retrieval, unsupervised domain adaptation and supervised finetuning, benchmarked on both BEIR and ODQA datasets. Code and datasets are publicly available at https://github.com/salesforce/AugTriever.", "published": "2024-10-31 04:00:00", "id": "c620e67b-2ea6-4eea-939c-25d9c96301ab", "source": "arxiv", "section": "computerScience"}, {"title": "Neural Networks with Sparse Activation Induced by Large Bias: Tighter Analysis with Bias-Generalized NTK", "link": "https://arxiv.org/abs/2301.00327", "description": "arXiv:2301.00327v3 Announce Type: replace \nAbstract: We study training one-hidden-layer ReLU networks in the neural tangent kernel (NTK) regime, where the networks' biases are initialized to some constant rather than zero. We prove that under such initialization, the neural network will have sparse activation throughout the entire training process, which enables fast training procedures via some sophisticated computational methods. With such initialization, we show that the neural networks possess a different limiting kernel which we call \\textit{bias-generalized NTK}, and we study various properties of the neural networks with this new kernel. We first characterize the gradient descent dynamics. In particular, we show that the network in this case can achieve as fast convergence as the dense network, as opposed to the previous work suggesting that the sparse networks converge slower. In addition, our result improves the previous required width to ensure convergence. Secondly, we study the networks' generalization: we show a width-sparsity dependence, which yields a sparsity-dependent Rademacher complexity and generalization bound. To our knowledge, this is the first sparsity-dependent generalization result via Rademacher complexity. Lastly, we study the smallest eigenvalue of this new kernel. We identify a data-dependent region where we can derive a much sharper lower bound on the NTK's smallest eigenvalue than the worst-case bound previously known. This can lead to improvement in the generalization bound.", "published": "2024-10-31 04:00:00", "id": "de819259-24ce-4823-97c0-363d4dc4af96", "source": "arxiv", "section": "computerScience"}, {"title": "Cognitive Load-based Affective Workload Allocation for Multi-human Multi-robot Teams", "link": "https://arxiv.org/abs/2303.10465", "description": "arXiv:2303.10465v2 Announce Type: replace \nAbstract: The interaction and collaboration between humans and multiple robots represent a novel field of research known as human multi-robot systems. Adequately designed systems within this field allow teams composed of both humans and robots to work together effectively on tasks such as monitoring, exploration, and search and rescue operations. This paper presents a deep reinforcement learning-based affective workload allocation controller specifically for multi-human multi-robot teams. The proposed controller can dynamically reallocate workloads based on the performance of the operators during collaborative missions with multi-robot systems. The operators' performances are evaluated through the scores of a self-reported questionnaire (i.e., subjective measurement) and the results of a deep learning-based cognitive workload prediction algorithm that uses physiological and behavioral data (i.e., objective measurement). To evaluate the effectiveness of the proposed controller, we use a multi-human multi-robot CCTV monitoring task as an example and carry out comprehensive real-world experiments with 32 human subjects for both quantitative measurement and qualitative analysis. Our results demonstrate the performance and effectiveness of the proposed controller and highlight the importance of incorporating both subjective and objective measurements of the operators' cognitive workload as well as seeking consent for workload transitions, to enhance the performance of multi-human multi-robot teams.", "published": "2024-10-31 04:00:00", "id": "4b377fae-3104-4ad0-8cff-c26060144346", "source": "arxiv", "section": "computerScience"}, {"title": "Combining Robust Control and Machine Learning for Uncertain Nonlinear Systems Subject to Persistent Disturbances", "link": "https://arxiv.org/abs/2303.11890", "description": "arXiv:2303.11890v2 Announce Type: replace \nAbstract: This paper proposes a control strategy consisting of a robust controller and an Echo State Network (ESN) based control law for stabilizing a class of uncertain nonlinear discrete-time systems subject to persistent disturbances. Firstly, the robust controller is designed to ensure that the closed-loop system is Input-to-State Stable (ISS) with a guaranteed stability region regardless of the ESN control action and exogenous disturbances. Then, the ESN based controller is trained in order to mitigate the effects of disturbances on the system output. A numerical example demonstrates the potentials of the proposed control design method.", "published": "2024-10-31 04:00:00", "id": "760b8f00-488c-4063-95de-d2421ceb89d7", "source": "arxiv", "section": "computerScience"}, {"title": "Efficient distributed representations with linear-time attention scores normalization", "link": "https://arxiv.org/abs/2303.17475", "description": "arXiv:2303.17475v3 Announce Type: replace \nAbstract: The attention score matrix ${\\rm SoftMax}(XY^T)$ encodes relational similarity patterns between objects and is extremely popular in machine learning. However, the complexity required to calculate it runs quadratically with the problem size, making it a computationally heavy solution. In this article, we propose a linear-time approximation of the attention score normalization constants for embedding vectors with bounded norms. We show on several pre-trained embeddings that the accuracy of our estimation formula surpasses competing kernel methods by even orders of magnitude. From this result, we design a linear-time and task-agnostic embedding algorithm based on the optimization of the attention scores. The proposed algorithm is highly interpretable and easily adapted to an arbitrary embedding problem. We consider a few use-cases and observe similar or higher performances and a lower computational time with respect to comparable embedding algorithms.", "published": "2024-10-31 04:00:00", "id": "e5b59a0b-816f-47a5-9566-67ba78a162d8", "source": "arxiv", "section": "computerScience"}, {"title": "Integrating One-Shot View Planning with a Single Next-Best View via Long-Tail Multiview Sampling", "link": "https://arxiv.org/abs/2304.00910", "description": "arXiv:2304.00910v4 Announce Type: replace \nAbstract: Existing view planning systems either adopt an iterative paradigm using next-best views (NBV) or a one-shot pipeline relying on the set-covering view-planning (SCVP) network. However, neither of these methods can concurrently guarantee both high-quality and high-efficiency reconstruction of 3D unknown objects. To tackle this challenge, we introduce a crucial hypothesis: with the availability of more information about the unknown object, the prediction quality of the SCVP network improves. There are two ways to provide extra information: (1) leveraging perception data obtained from NBVs, and (2) training on an expanded dataset of multiview inputs. In this work, we introduce a novel combined pipeline that incorporates a single NBV before activating the proposed multiview-activated (MA-)SCVP network. The MA-SCVP is trained on a multiview dataset generated by our long-tail sampling method, which addresses the issue of unbalanced multiview inputs and enhances the network performance. Extensive simulated experiments substantiate that our system demonstrates a significant surface coverage increase and a substantial 45% reduction in movement cost compared to state-of-the-art systems. Real-world experiments justify the capability of our system for generalization and deployment.", "published": "2024-10-31 04:00:00", "id": "3c3244cb-46c6-4ecf-a37f-1649df4934dd", "source": "arxiv", "section": "computerScience"}, {"title": "Selective Reincarnation: Offline-to-Online Multi-Agent Reinforcement Learning", "link": "https://arxiv.org/abs/2304.00977", "description": "arXiv:2304.00977v2 Announce Type: replace \nAbstract: 'Reincarnation' in reinforcement learning has been proposed as a formalisation of reusing prior computation from past experiments when training an agent in an environment. In this paper, we present a brief foray into the paradigm of reincarnation in the multi-agent (MA) context. We consider the case where only some agents are reincarnated, whereas the others are trained from scratch -- selective reincarnation. In the fully-cooperative MA setting with heterogeneous agents, we demonstrate that selective reincarnation can lead to higher returns than training fully from scratch, and faster convergence than training with full reincarnation. However, the choice of which agents to reincarnate in a heterogeneous system is vitally important to the outcome of the training -- in fact, a poor choice can lead to considerably worse results than the alternatives. We argue that a rich field of work exists here, and we hope that our effort catalyses further energy in bringing the topic of reincarnation to the multi-agent realm.", "published": "2024-10-31 04:00:00", "id": "d65d980c-d900-4938-9a50-b49ec765f69b", "source": "arxiv", "section": "computerScience"}, {"title": "Investigations into Proof Structures", "link": "https://arxiv.org/abs/2304.12827", "description": "arXiv:2304.12827v3 Announce Type: replace \nAbstract: We introduce and elaborate a novel formalism for the manipulation and analysis of proofs as objects in a global manner. In this first approach the formalism is restricted to first-order problems characterized by condensed detachment. It is applied in an exemplary manner to a coherent and comprehensive formal reconstruction and analysis of historical proofs of a widely-studied problem due to {\\L}ukasiewicz. The underlying approach opens the door towards new systematic ways of generating lemmas in the course of proof search to the effects of reducing the search effort and finding shorter proofs. Among the numerous reported experiments along this line, a proof of {\\L}ukasiewicz's problem was automatically discovered that is much shorter than any proof found before by man or machine.", "published": "2024-10-31 04:00:00", "id": "1dcb4ee2-e365-4d67-8300-dc096e6b45fa", "source": "arxiv", "section": "computerScience"}, {"title": "Adding Reconfiguration to Zielonka's Asynchronous Automata", "link": "https://arxiv.org/abs/2305.01425", "description": "arXiv:2305.01425v2 Announce Type: replace \nAbstract: We study an extension of Zielonka's (fixed) asynchronous automata called reconfigurable asynchronous automata where processes can dynamically change who they communicate with. We show that reconfigurable asynchronous automata are not more expressive than fixed asynchronous automata by giving translations from one to the other.  However, going from reconfigurable to fixed comes at the cost of disseminating communication (and knowledge) to all processes in the system. We then show that this is unavoidable by describing a language accepted by a reconfigurable automaton such that in every equivalent fixed automaton, every process must either be aware of all communication or be irrelevant.", "published": "2024-10-31 04:00:00", "id": "dfbd3292-45f0-4ec3-9933-38b0387d24fc", "source": "arxiv", "section": "computerScience"}, {"title": "Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations", "link": "https://arxiv.org/abs/2305.12715", "description": "arXiv:2305.12715v4 Announce Type: replace \nAbstract: Learning with reduced labeling standards, such as noisy label, partial label, and multiple label candidates, which we generically refer to as \\textit{imprecise} labels, is a commonplace challenge in machine learning tasks. Previous methods tend to propose specific designs for every emerging imprecise label configuration, which is usually unsustainable when multiple configurations of imprecision coexist. In this paper, we introduce imprecise label learning (ILL), a framework for the unification of learning with various imprecise label configurations. ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information. We demonstrate that ILL can seamlessly adapt to partial label learning, semi-supervised learning, noisy label learning, and, more importantly, a mixture of these settings. Notably, ILL surpasses the existing specified techniques for handling imprecise labels, marking the first unified framework with robust and effective performance across various challenging settings. We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.", "published": "2024-10-31 04:00:00", "id": "66cb6a5e-9cff-4acf-8de1-49bfa4eaf8d5", "source": "arxiv", "section": "computerScience"}, {"title": "Interpretable Mesomorphic Networks for Tabular Data", "link": "https://arxiv.org/abs/2305.13072", "description": "arXiv:2305.13072v2 Announce Type: replace \nAbstract: Even though neural networks have been long deployed in applications involving tabular data, still existing neural architectures are not explainable by design. In this paper, we propose a new class of interpretable neural networks for tabular data that are both deep and linear at the same time (i.e. mesomorphic). We optimize deep hypernetworks to generate explainable linear models on a per-instance basis. As a result, our models retain the accuracy of black-box deep networks while offering free-lunch explainability for tabular data by design. Through extensive experiments, we demonstrate that our explainable deep networks have comparable performance to state-of-the-art classifiers on tabular data and outperform current existing methods that are explainable by design.", "published": "2024-10-31 04:00:00", "id": "3c739ba8-e2c2-405b-9afb-2d02c5087c4e", "source": "arxiv", "section": "computerScience"}, {"title": "Domain-Expanded ASTE: Rethinking Generalization in Aspect Sentiment Triplet Extraction", "link": "https://arxiv.org/abs/2305.14434", "description": "arXiv:2305.14434v2 Announce Type: replace \nAbstract: Aspect Sentiment Triplet Extraction (ASTE) is a challenging task in sentiment analysis, aiming to provide fine-grained insights into human sentiments. However, existing benchmarks are limited to two domains and do not evaluate model performance on unseen domains, raising concerns about the generalization of proposed methods. Furthermore, it remains unclear if large language models (LLMs) can effectively handle complex sentiment tasks like ASTE. In this work, we address the issue of generalization in ASTE from both a benchmarking and modeling perspective. We introduce a domain-expanded benchmark by annotating samples from diverse domains, enabling evaluation of models in both in-domain and out-of-domain settings. Additionally, we propose CASE, a simple and effective decoding strategy that enhances trustworthiness and performance of LLMs in ASTE. Through comprehensive experiments involving multiple tasks, settings, and models, we demonstrate that CASE can serve as a general decoding strategy for complex sentiment tasks. By expanding the scope of evaluation and providing a more reliable decoding strategy, we aim to inspire the research community to reevaluate the generalizability of benchmarks and models for ASTE. Our code, data, and models are available at https://github.com/DAMO-NLP-SG/domain-expanded-aste.", "published": "2024-10-31 04:00:00", "id": "fc1a7e85-af39-4e96-960f-910df4399b87", "source": "arxiv", "section": "computerScience"}, {"title": "Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of Language Model", "link": "https://arxiv.org/abs/2305.15265", "description": "arXiv:2305.15265v3 Announce Type: replace \nAbstract: With the rapid growth in model size, fine-tuning the large pre-trained language model has become increasingly difficult due to its extensive memory usage. Previous works usually focus on reducing the number of trainable parameters in the network. While the model parameters do contribute to memory usage, the primary memory bottleneck during training arises from storing feature maps, also known as activations, as they are crucial for gradient calculation. Notably, neural networks are usually trained using stochastic gradient descent. We argue that in stochastic optimization, models can handle noisy gradients as long as the gradient estimator is unbiased with reasonable variance. Following this motivation, we propose a new family of unbiased estimators called WTA-CRS, for matrix production with reduced variance, which only requires storing the sub-sampled activations for calculating the gradient. Our work provides both theoretical and experimental evidence that, in the context of tuning transformers, our proposed estimators exhibit lower variance compared to existing ones. By replacing the linear operation with our approximated one in transformers, we can achieve up to 2.7$\\times$ peak memory reduction with almost no accuracy drop and enables up to $6.4\\times$ larger batch size. Under the same hardware, WTA-CRS enables better down-streaming task performance by applying larger models and/or faster training speed with larger batch sizes.", "published": "2024-10-31 04:00:00", "id": "ed832608-2b15-4e8d-93c6-2e53323acfbf", "source": "arxiv", "section": "computerScience"}, {"title": "Set-based Neural Network Encoding Without Weight Tying", "link": "https://arxiv.org/abs/2305.16625", "description": "arXiv:2305.16625v2 Announce Type: replace \nAbstract: We propose a neural network weight encoding method for network property prediction that utilizes set-to-set and set-to-vector functions to efficiently encode neural network parameters. Our approach is capable of encoding neural networks in a model zoo of mixed architecture and different parameter sizes as opposed to previous approaches that require custom encoding models for different architectures. Furthermore, our \\textbf{S}et-based \\textbf{N}eural network \\textbf{E}ncoder (SNE) takes into consideration the hierarchical computational structure of neural networks. To respect symmetries inherent in network weight space, we utilize Logit Invariance to learn the required minimal invariance properties. Additionally, we introduce a \\textit{pad-chunk-encode} pipeline to efficiently encode neural network layers that is adjustable to computational and memory constraints. We also introduce two new tasks for neural network property prediction: cross-dataset and cross-architecture. In cross-dataset property prediction, we evaluate how well property predictors generalize across model zoos trained on different datasets but of the same architecture. In cross-architecture property prediction, we evaluate how well property predictors transfer to model zoos of different architecture not seen during training. We show that SNE outperforms the relevant baselines on standard benchmarks.", "published": "2024-10-31 04:00:00", "id": "d652fc49-e9d9-4642-8b39-304097104bad", "source": "arxiv", "section": "computerScience"}, {"title": "Computation of a Unified Graph-Based Rate Optimization Problem", "link": "https://arxiv.org/abs/2306.04981", "description": "arXiv:2306.04981v3 Announce Type: replace \nAbstract: We define a graph-based rate optimization problem and consider its computation, which provides a unified approach to the computation of various theoretical limits, including the (conditional) graph entropy, rate-distortion functions and capacity-cost functions with side information. Compared with their classical counterparts, theoretical limits with side information are much more difficult to compute since their characterizations as optimization problems have larger and more complex feasible regions. Following the unified approach, we develop effective methods to resolve the difficulty. On the theoretical side, we derive graph characterizations for rate-distortion and capacity-cost functions with side information and simplify the characterizations in special cases by reducing the number of decision variables. On the computational side, we design an efficient alternating minimization algorithm for the graph-based problem, which deals with the inequality constraint by a flexible multiplier update strategy. Moreover, simplified graph characterizations are exploited and deflation techniques are introduced, so that the computing time is greatly reduced. Theoretical analysis shows that the algorithm converges to an optimal solution. By numerical experiments, the accuracy and efficiency of the algorithm are illustrated and its significant advantage over existing methods is demonstrated.", "published": "2024-10-31 04:00:00", "id": "672273fa-c331-4556-9879-aac85f04203f", "source": "arxiv", "section": "computerScience"}, {"title": "CoTran: An LLM-based Code Translator using Reinforcement Learning with Feedback from Compiler and Symbolic Execution", "link": "https://arxiv.org/abs/2306.06755", "description": "arXiv:2306.06755v4 Announce Type: replace \nAbstract: In this paper, we present an LLM-based code translation method and an associated tool called CoTran, that translates whole-programs from one high-level programming language to another. Existing LLM-based code translation methods lack training to ensure that the translated code reliably compiles or bears substantial functional equivalence to the input code. In our work, we fine-tune an LLM using reinforcement learning, incorporating compiler feedback, and symbolic execution (symexec)-based testing feedback to assess functional equivalence between the input and output programs. The idea is to guide an LLM during fine-tuning, via compiler and symexec-based testing feedback, by letting it know how far it is from producing perfect translations. We conduct extensive experiments comparing CoTran with 14 other code translation tools, including human-written transpilers, LLM-based translation tools, and ChatGPT. Using a benchmark of over \\num{57000} code pairs in Java and Python, we demonstrate that CoTran outperforms the other tools on relevant metrics such as compilation accuracy (CompAcc) and functional equivalence accuracy (FEqAcc). For example, in Python-to-Java translation, CoTran achieves 48.68% FEqAcc and 76.98% CompAcc, whereas the nearest competing tool (PLBART-base) gets 38.26% and 75.77% respectively. Additionally, CoTran, built on top of CodeT5, improves FEqAcc by +14.89% and CompAcc by +8.14% for Python-to-Java (resp., +12.94% and +4.30% for Java-to-Python).", "published": "2024-10-31 04:00:00", "id": "b87393b7-d1d6-4031-b4f3-728f93b1b0cc", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Heterogeneous Long-tailed Learning: Benchmarking, Metrics, and Toolbox", "link": "https://arxiv.org/abs/2307.08235", "description": "arXiv:2307.08235v2 Announce Type: replace \nAbstract: Long-tailed data distributions pose challenges for a variety of domains like e-commerce, finance, biomedical science, and cyber security, where the performance of machine learning models is often dominated by head categories while tail categories are inadequately learned. This work aims to provide a systematic view of long-tailed learning with regard to three pivotal angles: (A1) the characterization of data long-tailedness, (A2) the data complexity of various domains, and (A3) the heterogeneity of emerging tasks. We develop HeroLT, a comprehensive long-tailed learning benchmark integrating 18 state-of-the-art algorithms, 10 evaluation metrics, and 17 real-world datasets across 6 tasks and 4 data modalities. HeroLT with novel angles and extensive experiments (315 in total) enables effective and fair evaluation of newly proposed methods compared with existing baselines on varying dataset types. Finally, we conclude by highlighting the significant applications of long-tailed learning and identifying several promising future directions. For accessibility and reproducibility, we open-source our benchmark HeroLT and corresponding results at https://github.com/SSSKJ/HeroLT.", "published": "2024-10-31 04:00:00", "id": "50db559e-3394-4a98-9dea-11e489355a60", "source": "arxiv", "section": "computerScience"}, {"title": "Integration of Large Language Models and Federated Learning", "link": "https://arxiv.org/abs/2307.08925", "description": "arXiv:2307.08925v3 Announce Type: replace \nAbstract: As the parameter size of Large Language Models (LLMs) continues to expand, there is an urgent need to address the scarcity of high-quality data. In response, existing research has attempted to make a breakthrough by incorporating Federated Learning (FL) into LLMs. Conversely, considering the outstanding performance of LLMs in task generalization, researchers have also tried applying LLMs within FL to tackle challenges in relevant domains. The complementarity between LLMs and FL has already ignited widespread research interest. In this paper, we aim to deeply explore the integration of LLMs and FL. We propose a research framework, dividing the fusion of LLMs and FL into three parts: the combination of LLM sub-technologies with FL, the integration of FL sub-technologies with LLMs, and the overall merger of LLMs and FL. We first provide a comprehensive review of the current state of research in the domain of LLMs combined with FL, including their typical applications, integration advantages, challenges faced, and future directions for resolution. Subsequently, we discuss the practical applications of the combination of LLMs and FL in critical scenarios such as healthcare, finance, and education, and provide new perspectives and insights into future research directions for LLMs and FL.", "published": "2024-10-31 04:00:00", "id": "a1911c14-e533-4a3f-bb95-2f1256d5c5ec", "source": "arxiv", "section": "computerScience"}, {"title": "Fairness in Ranking under Disparate Uncertainty", "link": "https://arxiv.org/abs/2309.01610", "description": "arXiv:2309.01610v4 Announce Type: replace \nAbstract: Ranking is a ubiquitous method for focusing the attention of human evaluators on a manageable subset of options. Its use as part of human decision-making processes ranges from surfacing potentially relevant products on an e-commerce site to prioritizing college applications for human review. While ranking can make human evaluation more effective by focusing attention on the most promising options, we argue that it can introduce unfairness if the uncertainty of the underlying relevance model differs between groups of options. Unfortunately, such disparity in uncertainty appears widespread, often to the detriment of minority groups for which relevance estimates can have higher uncertainty due to a lack of data or appropriate features. To address this fairness issue, we propose Equal-Opportunity Ranking (EOR) as a new fairness criterion for ranking and show that it corresponds to a group-wise fair lottery among the relevant options even in the presence of disparate uncertainty. EOR optimizes for an even cost burden on all groups, unlike the conventional Probability Ranking Principle, and is fundamentally different from existing notions of fairness in rankings, such as demographic parity and proportional Rooney rule constraints that are motivated by proportional representation relative to group size. To make EOR ranking practical, we present an efficient algorithm for computing it in time $O(n \\log(n))$ and prove its close approximation guarantee to the globally optimal solution. In a comprehensive empirical evaluation on synthetic data, a US Census dataset, and a real-world audit of Amazon search queries, we find that the algorithm reliably guarantees EOR fairness while providing effective rankings.", "published": "2024-10-31 04:00:00", "id": "f61d08f0-b6a3-49d8-a0c3-b6ed141a00d0", "source": "arxiv", "section": "computerScience"}, {"title": "StyleAdapter: A Unified Stylized Image Generation Model", "link": "https://arxiv.org/abs/2309.01770", "description": "arXiv:2309.01770v2 Announce Type: replace \nAbstract: This work focuses on generating high-quality images with specific style of reference images and content of provided textual descriptions. Current leading algorithms, i.e., DreamBooth and LoRA, require fine-tuning for each style, leading to time-consuming and computationally expensive processes. In this work, we propose StyleAdapter, a unified stylized image generation model capable of producing a variety of stylized images that match both the content of a given prompt and the style of reference images, without the need for per-style fine-tuning. It introduces a two-path cross-attention (TPCA) module to separately process style information and textual prompt, which cooperate with a semantic suppressing vision model (SSVM) to suppress the semantic content of style images. In this way, it can ensure that the prompt maintains control over the content of the generated images, while also mitigating the negative impact of semantic information in style references. This results in the content of the generated image adhering to the prompt, and its style aligning with the style references. Besides, our StyleAdapter can be integrated with existing controllable synthesis methods, such as T2I-adapter and ControlNet, to attain a more controllable and stable generation process. Extensive experiments demonstrate the superiority of our method over previous works.", "published": "2024-10-31 04:00:00", "id": "fb3c15a1-4f5d-4281-b1ed-2542f5715523", "source": "arxiv", "section": "computerScience"}, {"title": "Solving Quadratic Systems with Full-Rank Matrices Using Sparse or Generative Priors", "link": "https://arxiv.org/abs/2309.09032", "description": "arXiv:2309.09032v2 Announce Type: replace \nAbstract: The problem of recovering a signal $\\boldsymbol x\\in \\mathbb{R}^n$ from a quadratic system $\\{y_i=\\boldsymbol x^\\top\\boldsymbol A_i\\boldsymbol x,\\ i=1,\\ldots,m\\}$ with full-rank matrices $\\boldsymbol A_i$ frequently arises in applications such as unassigned distance geometry and sub-wavelength imaging. With i.i.d. standard Gaussian matrices $\\boldsymbol A_i$, this paper addresses the high-dimensional case where $m\\ll n$ by incorporating prior knowledge of $\\boldsymbol x$. First, we consider a $k$-sparse $\\boldsymbol x$ and introduce the thresholded Wirtinger flow (TWF) algorithm that does not require the sparsity level $k$. TWF comprises two steps: the spectral initialization that identifies a point sufficiently close to $\\boldsymbol x$ (up to a sign flip) when $m=O(k^2\\log n)$, and the thresholded gradient descent which, when provided a good initialization, produces a sequence linearly converging to $\\boldsymbol x$ with $m=O(k\\log n)$ measurements. Second, we explore the generative prior, assuming that $x$ lies in the range of an $L$-Lipschitz continuous generative model with $k$-dimensional inputs in an $\\ell_2$-ball of radius $r$. With an estimate correlated with the signal, we develop the projected gradient descent (PGD) algorithm that also comprises two steps: the projected power method that provides an initial vector with $O\\big(\\sqrt{\\frac{k \\log L}{m}}\\big)$ $\\ell_2$-error given $m=O(k\\log(Lnr))$ measurements, and the projected gradient descent that refines the $\\ell_2$-error to $O(\\delta)$ at a geometric rate when $m=O(k\\log\\frac{Lrn}{\\delta^2})$. Experimental results corroborate our theoretical findings and show that: (i) our approach for the sparse case notably outperforms the existing provable algorithm sparse power factorization; (ii) leveraging the generative prior allows for precise image recovery in the MNIST dataset from a small number of quadratic measurements.", "published": "2024-10-31 04:00:00", "id": "c1a1dde5-1f9a-426e-9395-2c87dd94d1ff", "source": "arxiv", "section": "computerScience"}, {"title": "Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks", "link": "https://arxiv.org/abs/2309.12927", "description": "arXiv:2309.12927v3 Announce Type: replace \nAbstract: Recurrent neural networks (RNNs) in the brain and in silico excel at solving tasks with intricate temporal dependencies. Long timescales required for solving such tasks can arise from properties of individual neurons (single-neuron timescale, $\\tau$, e.g., membrane time constant in biological neurons) or recurrent interactions among them (network-mediated timescale). However, the contribution of each mechanism for optimally solving memory-dependent tasks remains poorly understood. Here, we train RNNs to solve $N$-parity and $N$-delayed match-to-sample tasks with increasing memory requirements controlled by $N$ by simultaneously optimizing recurrent weights and $\\tau$s. We find that for both tasks RNNs develop longer timescales with increasing $N$, but depending on the learning objective, they use different mechanisms. Two distinct curricula define learning objectives: sequential learning of a single-$N$ (single-head) or simultaneous learning of multiple $N$s (multi-head). Single-head networks increase their $\\tau$ with $N$ and are able to solve tasks for large $N$, but they suffer from catastrophic forgetting. However, multi-head networks, which are explicitly required to hold multiple concurrent memories, keep $\\tau$ constant and develop longer timescales through recurrent connectivity. Moreover, we show that the multi-head curriculum increases training speed and network stability to ablations and perturbations, and allows RNNs to generalize better to tasks beyond their training regime. This curriculum also significantly improves training GRUs and LSTMs for large-$N$ tasks. Our results suggest that adapting timescales to task requirements via recurrent interactions allows learning more complex objectives and improves the RNN's performance.", "published": "2024-10-31 04:00:00", "id": "1ac2af8f-4c02-47c4-927e-fd5e9f9ecfd9", "source": "arxiv", "section": "computerScience"}, {"title": "Zero-Shot Reinforcement Learning from Low Quality Data", "link": "https://arxiv.org/abs/2309.15178", "description": "arXiv:2309.15178v3 Announce Type: replace \nAbstract: Zero-shot reinforcement learning (RL) promises to provide agents that can perform any task in an environment after an offline, reward-free pre-training phase. Methods leveraging successor measures and successor features have shown strong performance in this setting, but require access to large heterogenous datasets for pre-training which cannot be expected for most real problems. Here, we explore how the performance of zero-shot RL methods degrades when trained on small homogeneous datasets, and propose fixes inspired by conservatism, a well-established feature of performant single-task offline RL algorithms. We evaluate our proposals across various datasets, domains and tasks, and show that conservative zero-shot RL algorithms outperform their non-conservative counterparts on low quality datasets, and perform no worse on high quality datasets. Somewhat surprisingly, our proposals also outperform baselines that get to see the task during training. Our code is available via https://enjeeneer.io/projects/zero-shot-rl/ .", "published": "2024-10-31 04:00:00", "id": "76c58125-9e22-4e14-9707-b78620c50007", "source": "arxiv", "section": "computerScience"}, {"title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs", "link": "https://arxiv.org/abs/2310.01801", "description": "arXiv:2310.01801v4 Announce Type: replace \nAbstract: In this study, we introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs). Different from the conventional KV cache that retains key and value vectors for all context tokens, we conduct targeted profiling to discern the intrinsic structure of attention modules. Based on the recognized structure, we then construct the KV cache in an adaptive manner: evicting long-range contexts on attention heads emphasizing local contexts, discarding non-special tokens on attention heads centered on special tokens, and only employing the standard KV cache for attention heads that broadly attend to all tokens. Moreover, with the lightweight attention profiling used to guide the construction of the adaptive KV cache, FastGen can be deployed without resource-intensive fine-tuning or re-training. In our experiments across various asks, FastGen demonstrates substantial reduction on GPU memory consumption with negligible generation quality loss. We will release our code and the compatible CUDA kernel for reproducibility.", "published": "2024-10-31 04:00:00", "id": "5bf490c2-8355-4ba0-b85e-3dfb8af0fc29", "source": "arxiv", "section": "computerScience"}, {"title": "Mapping the DeFi Crime Landscape: An Evidence-based Picture", "link": "https://arxiv.org/abs/2310.04356", "description": "arXiv:2310.04356v2 Announce Type: replace \nAbstract: Decentralized finance (DeFi) has been the target of numerous profit-driven crimes, but the prevalence and cumulative impact of these crimes have not yet been assessed. This study provides a comprehensive assessment of profit-driven crimes targeting the DeFi sector. We collected data on 1153 crime events from 2017 to 2022. Of these, 1,048 were related to DeFi (the main focus of this study) and 105 to centralized finance (CeFi). The findings show that the entire cryptoasset industry has suffered a minimum loss of US$30B, with two thirds related to CeFi and one third to DeFi. Focusing on DeFi, a taxonomy was developed to clarify the similarities and differences among these crimes. All events were mapped onto the DeFi stack to assess the impacted technical layers, and the financial damages were quantified to gauge their scale. The results highlight that during an attack, a DeFi actor (an entity developing a DeFi technology) can serve as a direct target (due to technical vulnerabilities or exploitation of human risks), as a perpetrator (through malicious uses of contracts or market manipulations), or as an intermediary (by being imitated through, for example, phishing scams). The findings also show that DeFi actors are the first victims of crimes targeting the DeFi industry: 52.2% of events targeted them, primarily due to technical vulnerabilities at the protocol layer, and these events accounted for 83% of all financial damages. Alternatively, in 40.7% of events, DeFi actors were themselves malicious perpetrators, predominantly misusing contracts at the cryptoasset layer (e.g., rug pull scams). However, these events accounted for only 17% of all financial damages. The study offers a preliminary assessment of the size and scope of crime events within the DeFi sector and highlights the vulnerable position of DeFi actors in the ecosystem.", "published": "2024-10-31 04:00:00", "id": "4fd78df9-00c4-44df-8875-767b4c1d69d8", "source": "arxiv", "section": "computerScience"}, {"title": "Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational Knowledge Graph Construction", "link": "https://arxiv.org/abs/2310.05185", "description": "arXiv:2310.05185v3 Announce Type: replace \nAbstract: Beyond traditional binary relational facts, n-ary relational knowledge graphs (NKGs) are comprised of n-ary relational facts containing more than two entities, which are closer to real-world facts with broader applications. However, the construction of NKGs remains at a coarse-grained level, which is always in a single schema, ignoring the order and variable arity of entities. To address these restrictions, we propose Text2NKG, a novel fine-grained n-ary relation extraction framework for n-ary relational knowledge graph construction. We introduce a span-tuple classification approach with hetero-ordered merging and output merging to accomplish fine-grained n-ary relation extraction in different arity. Furthermore, Text2NKG supports four typical NKG schemas: hyper-relational schema, event-based schema, role-based schema, and hypergraph-based schema, with high flexibility and practicality. The experimental results demonstrate that Text2NKG achieves state-of-the-art performance in F1 scores on the fine-grained n-ary relation extraction benchmark. Our code and datasets are publicly available.", "published": "2024-10-31 04:00:00", "id": "3512fd5f-5b9c-41ca-b7a2-52031b755aaf", "source": "arxiv", "section": "computerScience"}, {"title": "Predictive auxiliary objectives in deep RL mimic learning in the brain", "link": "https://arxiv.org/abs/2310.06089", "description": "arXiv:2310.06089v3 Announce Type: replace \nAbstract: The ability to predict upcoming events has been hypothesized to comprise a key aspect of natural and machine cognition. This is supported by trends in deep reinforcement learning (RL), where self-supervised auxiliary objectives such as prediction are widely used to support representation learning and improve task performance. Here, we study the effects predictive auxiliary objectives have on representation learning across different modules of an RL system and how these mimic representational changes observed in the brain. We find that predictive objectives improve and stabilize learning particularly in resource-limited architectures, and we identify settings where longer predictive horizons better support representational transfer. Furthermore, we find that representational changes in this RL system bear a striking resemblance to changes in neural activity observed in the brain across various experiments. Specifically, we draw a connection between the auxiliary predictive model of the RL system and hippocampus, an area thought to learn a predictive model to support memory-guided behavior. We also connect the encoder network and the value learning network of the RL system to visual cortex and striatum in the brain, respectively. This work demonstrates how representation learning in deep RL systems can provide an interpretable framework for modeling multi-region interactions in the brain. The deep RL perspective taken here also suggests an additional role of the hippocampus in the brain -- that of an auxiliary learning system that benefits representation learning in other regions.", "published": "2024-10-31 04:00:00", "id": "25b17e98-c8e2-4061-b0f7-634f6a138cd4", "source": "arxiv", "section": "computerScience"}, {"title": "IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training", "link": "https://arxiv.org/abs/2310.07355", "description": "arXiv:2310.07355v5 Announce Type: replace \nAbstract: In the field of medical Vision-Language Pre-training (VLP), significant efforts have been devoted to deriving text and image features from both clinical reports and associated medical images. However, most existing methods may have overlooked the opportunity in leveraging the inherent hierarchical structure of clinical reports, which are generally split into `findings' for descriptive content and `impressions' for conclusive observation. Instead of utilizing this rich, structured format, current medical VLP approaches often simplify the report into either a unified entity or fragmented tokens. In this work, we propose a novel clinical prior guided VLP framework named IMITATE to learn the structure information from medical reports with hierarchical vision-language alignment. The framework derives multi-level visual features from the chest X-ray (CXR) images and separately aligns these features with the descriptive and the conclusive text encoded in the hierarchical medical report. Furthermore, a new clinical-informed contrastive loss is introduced for cross-modal learning, which accounts for clinical prior knowledge in formulating sample correlations in contrastive learning. The proposed model, IMITATE, outperforms baseline VLP methods across six different datasets, spanning five medical imaging downstream tasks. Comprehensive experimental results highlight the advantages of integrating the hierarchical structure of medical reports for vision-language alignment. The code related to this paper is available at https://github.com/cheliu-computation/IMITATE-TMI2024.", "published": "2024-10-31 04:00:00", "id": "cf427c53-d14d-4bb6-87f5-964001f52f13", "source": "arxiv", "section": "computerScience"}, {"title": "Optimal Linear Decay Learning Rate Schedules and Further Refinements", "link": "https://arxiv.org/abs/2310.07831", "description": "arXiv:2310.07831v2 Announce Type: replace \nAbstract: Learning rate schedules used in practice bear little resemblance to those recommended by theory. We close much of this theory/practice gap, and as a consequence are able to derive new problem-adaptive learning rate schedules. Our main technical contribution is a refined analysis of learning rate schedules for a wide class of optimization algorithms (including SGD). When considering only worst-case analysis, our theory predicts that the optimal choice is the linear decay schedule where the step-size is set proportional to 1 - t/T, where t is the current iteration and T is the total number of steps. To go beyond this worst-case analysis, we use the observed gradient norms to derive schedules refined for any particular task. These refined schedules exhibit learning rate warm-up and rapid learning rate annealing near the end of training. Ours is the first systematic approach to automatically yield both of these properties. We perform the most comprehensive evaluation of learning rate schedules to date, evaluating across 10 diverse deep learning problems, a series of LLMs, and a suite of logistic regression problems. We validate that overall, the linear-decay schedule outperforms all commonly used default schedules including cosine annealing. Our adaptive schedule refinement method gives further improvements.", "published": "2024-10-31 04:00:00", "id": "a720e603-5acd-4ffe-b23b-9d88323c71c4", "source": "arxiv", "section": "computerScience"}, {"title": "Yuga: Automatically Detecting Lifetime Annotation Bugs in the Rust Language", "link": "https://arxiv.org/abs/2310.08507", "description": "arXiv:2310.08507v2 Announce Type: replace \nAbstract: The Rust programming language is becoming increasingly popular among systems programmers due to its efficient performance and robust memory safety guarantees. Rust employs an ownership model to ensure this guarantee by allowing each value to be owned by only one identifier at a time. Additionally, it introduces the concept of borrowing and lifetimes to enable other variables to borrow the values under certain conditions temporarily. Despite its benefits, security vulnerabilities have been reported in Rust projects, often attributed to the use of \"unsafe\" Rust code. These vulnerabilities, in part, arise from incorrect lifetime annotations on function signatures. However, existing tools fail to detect these bugs, primarily because such bugs are rare, challenging to detect through dynamic analysis, and require explicit memory models. To overcome these limitations, first, we characterize incorrect lifetime annotations as a source of memory safety bugs and leverage this understanding to devise a novel static analysis tool, Yuga, to detect potential lifetime annotation bugs. Yuga uses a multi-phase analysis approach, starting with a quick pattern-matching algorithm to identify potential buggy components and then conducting a flow and field-sensitive alias analysis to confirm the bugs. We also curate new datasets of lifetime annotation bugs. Yuga successfully detects bugs with good precision on these datasets, and we make the code and datasets publicly available for review.", "published": "2024-10-31 04:00:00", "id": "a521443c-f944-4319-95ba-082bec2f1330", "source": "arxiv", "section": "computerScience"}, {"title": "ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models", "link": "https://arxiv.org/abs/2310.08975", "description": "arXiv:2310.08975v3 Announce Type: replace \nAbstract: Knowledge Base Question Answering (KBQA) aims to answer natural language questions over large-scale knowledge bases (KBs), which can be summarized into two crucial steps: knowledge retrieval and semantic parsing. However, three core challenges remain: inefficient knowledge retrieval, mistakes of retrieval adversely impacting semantic parsing, and the complexity of previous KBQA methods. To tackle these challenges, we introduce ChatKBQA, a novel and simple generate-then-retrieve KBQA framework, which proposes first generating the logical form with fine-tuned LLMs, then retrieving and replacing entities and relations with an unsupervised retrieval method, to improve both generation and retrieval more directly. Experimental results show that ChatKBQA achieves new state-of-the-art performance on standard KBQA datasets, WebQSP, and CWQ. This work can also be regarded as a new paradigm for combining LLMs with knowledge graphs (KGs) for interpretable and knowledge-required question answering. Our code is publicly available.", "published": "2024-10-31 04:00:00", "id": "1bc730fb-eacf-4b9c-87c0-0ec07bf1f003", "source": "arxiv", "section": "computerScience"}, {"title": "Masked Hard-Attention Transformers Recognize Exactly the Star-Free Languages", "link": "https://arxiv.org/abs/2310.13897", "description": "arXiv:2310.13897v4 Announce Type: replace \nAbstract: The expressive power of transformers over inputs of unbounded size can be studied through their ability to recognize classes of formal languages. In this paper, we establish exact characterizations of transformers with hard attention (in which all attention is focused on exactly one position) and attention masking (in which each position only attends to positions on one side). With strict masking (each position cannot attend to itself) and without position embeddings, these transformers are expressively equivalent to linear temporal logic (LTL), which defines exactly the star-free languages. A key technique is the use of Boolean RASP as a convenient intermediate language between transformers and LTL. We then take numerous results known for LTL and apply them to transformers, showing how position embeddings, strict masking, and depth all increase expressive power.", "published": "2024-10-31 04:00:00", "id": "dc3e7408-7873-4cd9-a7f2-c0cc45d6d37d", "source": "arxiv", "section": "computerScience"}, {"title": "On Unsupervised Partial Shape Correspondence", "link": "https://arxiv.org/abs/2310.14692", "description": "arXiv:2310.14692v3 Announce Type: replace \nAbstract: While dealing with matching shapes to their parts, we often apply a tool known as functional maps. The idea is to translate the shape matching problem into \"convenient\" spaces by which matching is performed algebraically by solving a least squares problem. Here, we argue that such formulations, though popular in this field, introduce errors in the estimated match when partiality is invoked. Such errors are unavoidable even for advanced feature extraction networks, and they can be shown to escalate with increasing degrees of shape partiality, adversely affecting the learning capability of such systems. To circumvent these limitations, we propose a novel approach for partial shape matching. Our study of functional maps led us to a novel method that establishes direct correspondence between partial and full shapes through feature matching bypassing the need for functional map intermediate spaces. The Gromov Distance between metric spaces leads to the construction of the first part of our loss functions. For regularization we use two options: a term based on the area preserving property of the mapping, and a relaxed version that avoids the need to resort to functional maps. The proposed approach shows superior performance on the SHREC'16 dataset, outperforming existing unsupervised methods for partial shape matching.Notably, it achieves state-of-the-art results on the SHREC'16 HOLES benchmark, superior also compared to supervised methods. We demonstrate the benefits of the proposed unsupervised method when applied to a new dataset PFAUST for part-to-full shape correspondence.", "published": "2024-10-31 04:00:00", "id": "26dd59e8-4561-49a0-b133-f50b4fc1831d", "source": "arxiv", "section": "computerScience"}, {"title": "Sui Lutris: A Blockchain Combining Broadcast and Consensus", "link": "https://arxiv.org/abs/2310.18042", "description": "arXiv:2310.18042v5 Announce Type: replace \nAbstract: Sui Lutris is the first smart-contract platform to sustainably achieve sub-second finality. It achieves this significant decrease by employing consensusless agreement not only for simple payments but for a large variety of transactions. Unlike prior work, Sui Lutris neither compromises expressiveness nor throughput and can run perpetually without restarts. Sui Lutris achieves this by safely integrating consensuless agreement with a high-throughput consensus protocol that is invoked out of the critical finality path but ensures that when a transaction is at risk of inconsistent concurrent accesses, its settlement is delayed until the total ordering is resolved. Building such a hybrid architecture is especially delicate during reconfiguration events, where the system needs to preserve the safety of the consensusless path without compromising the long-term liveness of potentially misconfigured clients. We thus develop a novel reconfiguration protocol, the first to provably show the safe and efficient reconfiguration of a consensusless blockchain. Sui Lutris is currently running in production and underpins the Sui smart-contract platform. Combined with the use of Objects instead of accounts it enables the safe execution of smart contracts that expose objects as a first-class resource. In our experiments Sui Lutris achieves latency lower than 0.5 seconds for throughput up to 5,000 certificates per second (150k ops/s with transaction blocks), compared to the state-of-the-art real-world consensus latencies of 3 seconds. Furthermore, it gracefully handles validators crash-recovery and does not suffer visible performance degradation during reconfiguration.", "published": "2024-10-31 04:00:00", "id": "be978509-b831-41de-b470-f471d79cd3bf", "source": "arxiv", "section": "computerScience"}, {"title": "FLIP: Fine-grained Alignment between ID-based Models and Pretrained Language Models for CTR Prediction", "link": "https://arxiv.org/abs/2310.19453", "description": "arXiv:2310.19453v4 Announce Type: replace \nAbstract: Click-through rate (CTR) prediction plays as a core function module in various personalized online services. The traditional ID-based models for CTR prediction take as inputs the one-hot encoded ID features of tabular modality, which capture the collaborative signals via feature interaction modeling. But the one-hot encoding discards the semantic information included in the textual features. Recently, the emergence of Pretrained Language Models(PLMs) has given rise to another paradigm, which takes as inputs the sentences of textual modality obtained by hard prompt templates and adopts PLMs to extract the semantic knowledge. However, PLMs often face challenges in capturing field-wise collaborative signals and distinguishing features with subtle textual differences. In this paper, to leverage the benefits of both paradigms and meanwhile overcome their limitations, we propose to conduct Fine-grained feature-level ALignment between ID-based Models and Pretrained Language Models(FLIP) for CTR prediction. Unlike most methods that solely rely on global views through instance-level contrastive learning, we design a novel jointly masked tabular/language modeling task to learn fine-grained alignment between tabular IDs and word tokens. Specifically, the masked data of one modality (IDs and tokens) has to be recovered with the help of the other modality, which establishes the feature-level interaction and alignment via sufficient mutual information extraction between dual modalities. Moreover, we propose to jointly finetune the ID-based model and PLM by adaptively combining the output of both models, thus achieving superior performance in downstream CTR prediction tasks. Extensive experiments on three real-world datasets demonstrate that FLIP outperforms SOTA baselines, and is highly compatible with various ID-based models and PLMs. The code is at \\url{https://github.com/justarter/FLIP}.", "published": "2024-10-31 04:00:00", "id": "0d86825b-a22f-4976-80a5-b85c52cff993", "source": "arxiv", "section": "computerScience"}, {"title": "Orion: A Fully Homomorphic Encryption Framework for Deep Learning", "link": "https://arxiv.org/abs/2311.03470", "description": "arXiv:2311.03470v2 Announce Type: replace \nAbstract: Fully Homomorphic Encryption (FHE) has the potential to substantially improve privacy and security by enabling computation directly on encrypted data. This is especially true with deep learning, as today, many popular user services are powered by neural networks in the cloud. One of the major challenges facing wide-scale deployment of FHE-secured neural inference is effectively mapping these networks to FHE primitives. FHE poses many programming challenges including packing large vectors, automatically managing noise via bootstrapping, and translating arbitrary and general-purpose programs to the limited instruction set provided by FHE. These challenges make building large FHE neural networks intractable using the tools available today.\n  In this paper we address these challenges with Orion, a fully-automated framework for private neural inference in FHE. Orion accepts deep neural networks written in PyTorch and translates them into efficient FHE programs. We achieve this by proposing a novel single-shot multiplexed packing strategy for arbitrary convolutions and through a new, efficient technique to automate bootstrap placement. We evaluate Orion on common benchmarks used by the FHE deep learning community and outperform state-of-the-art by $2.38 \\times$ on ResNet-20, the largest network they report. Orion extends naturally to larger networks. We demonstrate this by evaluating ResNet-50 on ImageNet and present the first high-resolution homomorphic object detection experiments using a YOLO-v1 model with 139 million parameters. Finally, we open-source our framework Orion at the following repository: https://github.com/baahl-nyu/orion", "published": "2024-10-31 04:00:00", "id": "511b832f-6a5f-4af3-9a51-d061cf29f7ba", "source": "arxiv", "section": "computerScience"}, {"title": "Structure and inference in hypergraphs with node attributes", "link": "https://arxiv.org/abs/2311.03857", "description": "arXiv:2311.03857v2 Announce Type: replace \nAbstract: Many networked datasets with units interacting in groups of two or more, encoded with hypergraphs, are accompanied by extra information about nodes, such as the role of an individual in a workplace. Here we show how these node attributes can be used to improve our understanding of the structure resulting from higher-order interactions. We consider the problem of community detection in hypergraphs and develop a principled model that combines higher-order interactions and node attributes to better represent the observed interactions and to detect communities more accurately than using either of these types of information alone. The method learns automatically from the input data the extent to which structure and attributes contribute to explain the data, down weighing or discarding attributes if not informative. Our algorithmic implementation is efficient and scales to large hypergraphs and interactions of large numbers of units. We apply our method to a variety of systems, showing strong performance in hyperedge prediction tasks and in selecting community divisions that correlate with attributes when these are informative, but discarding them otherwise. Our approach illustrates the advantage of using informative node attributes when available with higher-order data.", "published": "2024-10-31 04:00:00", "id": "8bfbc35a-5818-49d3-8351-35d25c2d4b1b", "source": "arxiv", "section": "computerScience"}, {"title": "Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning", "link": "https://arxiv.org/abs/2311.08110", "description": "arXiv:2311.08110v3 Announce Type: replace \nAbstract: Hateful memes have emerged as a significant concern on the Internet. Detecting hateful memes requires the system to jointly understand the visual and textual modalities. Our investigation reveals that the embedding space of existing CLIP-based systems lacks sensitivity to subtle differences in memes that are vital for correct hatefulness classification. We propose constructing a hatefulness-aware embedding space through retrieval-guided contrastive training. Our approach achieves state-of-the-art performance on the HatefulMemes dataset with an AUROC of 87.0, outperforming much larger fine-tuned large multimodal models. We demonstrate a retrieval-based hateful memes detection system, which is capable of identifying hatefulness based on data unseen in training. This allows developers to update the hateful memes detection system by simply adding new examples without retraining, a desirable feature for real services in the constantly evolving landscape of hateful memes on the Internet.", "published": "2024-10-31 04:00:00", "id": "e81053ca-57a3-484a-b503-6b34d82315a7", "source": "arxiv", "section": "computerScience"}, {"title": "Summarization-Based Document IDs for Generative Retrieval with Language Models", "link": "https://arxiv.org/abs/2311.08593", "description": "arXiv:2311.08593v2 Announce Type: replace \nAbstract: Generative retrieval (Wang et al., 2022; Tay et al., 2022) is a popular approach for end-to-end document retrieval that directly generates document identifiers given an input query. We introduce summarization-based document IDs, in which each document's ID is composed of an extractive summary or abstractive keyphrases generated by a language model, rather than an integer ID sequence or bags of n-grams as proposed in past work. We find that abstractive, content-based IDs (ACID) and an ID based on the first 30 tokens are very effective in direct comparisons with previous approaches to ID creation. We show that using ACID improves top-10 and top-20 recall by 15.6% and 14.4% (relative) respectively versus the cluster-based integer ID baseline on the MSMARCO 100k retrieval task, and 9.8% and 9.9% respectively on the Wikipedia-based NQ 100k retrieval task. Our results demonstrate the effectiveness of human-readable, natural-language IDs created through summarization for generative retrieval. We also observed that extractive IDs outperformed abstractive IDs on Wikipedia articles in NQ but not the snippets in MSMARCO, which suggests that document characteristics affect generative retrieval performance.", "published": "2024-10-31 04:00:00", "id": "3c5bf008-ca58-4b67-80b1-054a0442497f", "source": "arxiv", "section": "computerScience"}, {"title": "Learning Dynamic Selection and Pricing of Out-of-Home Deliveries", "link": "https://arxiv.org/abs/2311.13983", "description": "arXiv:2311.13983v3 Announce Type: replace \nAbstract: Home delivery failures, traffic congestion, and relatively large handling times have a negative impact on the profitability of last-mile logistics. A potential solution is the delivery to parcel lockers or parcel shops, denoted by out-of-home (OOH) delivery. In the academic literature, models for OOH delivery were so far limited to static settings, contrasting with the sequential nature of the problem. We model the sequential decision-making problem of which OOH location to offer against what incentive for each incoming customer, taking into account future customer arrivals and choices. We propose Dynamic Selection and Pricing of OOH (DSPO), an algorithmic pipeline that uses a novel spatial-temporal state encoding as input to a convolutional neural network. We demonstrate the performance of our method by benchmarking it against two state-of-the-art approaches. Our extensive numerical study, guided by real-world data, reveals that DSPO can save 19.9%pt in costs compared to a situation without OOH locations, 7%pt compared to a static selection and pricing policy, and 3.8%pt compared to a state-of-the-art demand management benchmark. We provide comprehensive insights into the complex interplay between OOH delivery dynamics and customer behavior influenced by pricing strategies. The implications of our findings suggest practitioners to adopt dynamic selection and pricing policies.", "published": "2024-10-31 04:00:00", "id": "28d9efae-15bd-4cdf-94d6-876d5dd330bb", "source": "arxiv", "section": "computerScience"}, {"title": "The Adoption and Efficacy of Large Language Models: Evidence From Consumer Complaints in the Financial Industry", "link": "https://arxiv.org/abs/2311.16466", "description": "arXiv:2311.16466v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) are reshaping consumer decision-making, particularly in communication with firms, yet our understanding of their impact remains limited. This research explores the effect of LLMs on consumer complaints submitted to the Consumer Financial Protection Bureau from 2015 to 2024, documenting the adoption of LLMs for drafting complaints and evaluating the likelihood of obtaining relief from financial firms. Utilizing a leading AI detection tool, we analyzed over 1 million complaints and identified a significant increase in LLM usage following the release of ChatGPT. We establish a causal relationship between LLM usage and an increased likelihood of obtaining relief by employing instrumental variables to address endogeneity in LLM adoption. Experimental data further support this link, demonstrating that LLMs enhance the clarity and persuasiveness of consumer narratives. Our findings suggest that facilitating access to LLMs can help firms better understand consumer concerns and level the playing field among consumers. This underscores the importance of policies promoting technological accessibility, enabling all consumers to effectively voice their concerns.", "published": "2024-10-31 04:00:00", "id": "708277e0-2127-41ed-bbe1-69f3a07936fe", "source": "arxiv", "section": "computerScience"}, {"title": "Tight Bounds for The Price of Fairness", "link": "https://arxiv.org/abs/2311.18339", "description": "arXiv:2311.18339v2 Announce Type: replace \nAbstract: A central decision maker (CDM), who seeks an efficient allocation of scarce resources among a finite number of players, often has to incorporate fairness criteria to avoid unfair outcomes. Indeed, the Price of Fairness (POF), a term coined in the seminal work by Bertsimas et al. (2011), refers to the efficiency loss due to the incorporation of fairness criteria into the allocation method. Quantifying the POF would help the CDM strike an appropriate balance between efficiency and fairness. In this paper we improve upon existing results in the literature, by providing tight bounds for the POF for the proportional fairness criterion for any $n$, when the maximum achievable utilities of the players are equal or are not equal. Further, while Bertsimas et al. (2011) have already derived a tight bound for the max-min fairness criterion for the case that all players have equal maximum achievable utilities, we also provide a tight bound in scenarios where these utilities are not equal. For both criteria, we characterize the conditions where the POF reaches its peak and provide the supremum bounds of our bounds over all maximum achievable utility vectors, which are shown to be asymptotically strictly smaller than the supremum of the Bertsimas et al. (2011) bounds. Finally, we investigate the sensitivity of our bounds and the bounds in Bertsimas et al. (2011) for the POF to the variability of the maximum achievable utilities.", "published": "2024-10-31 04:00:00", "id": "d9667f7e-a871-4df1-b789-bdab1c04f40d", "source": "arxiv", "section": "computerScience"}, {"title": "Numerical approximation of Dynkin games with asymmetric information", "link": "https://arxiv.org/abs/2312.01847", "description": "arXiv:2312.01847v2 Announce Type: replace \nAbstract: We propose an implementable, neural network-based structure preserving probabilistic numerical approximation for a generalized obstacle problem describing the value of a zero-sum differential game of optimal stopping with asymmetric information. The target solution depends on three variables: the time, the spatial (or state) variable, and a variable from a standard $(I-1)$-simplex which represents the probabilities with which the $I$ possible configurations of the game are played. The proposed numerical approximation preserves the convexity of the continuous solution as well as the lower and upper obstacle bounds. We show convergence of the fully-discrete scheme to the unique viscosity solution of the continuous problem and present a range of numerical studies to demonstrate its applicability.", "published": "2024-10-31 04:00:00", "id": "e8f4ca12-1ff7-4d95-982b-b4849571a400", "source": "arxiv", "section": "computerScience"}, {"title": "Anti-symmetric and Positivity Preserving Formulation of a Spectral Method for Vlasov-Poisson Equations", "link": "https://arxiv.org/abs/2312.05439", "description": "arXiv:2312.05439v3 Announce Type: replace \nAbstract: We analyze the anti-symmetric properties of a spectral discretization for the one-dimensional Vlasov-Poisson equations. The discretization is based on a spectral expansion in velocity with the symmetrically weighted Hermite basis functions, central finite differencing in space, and an implicit Runge Kutta integrator in time. The proposed discretization preserves the anti-symmetric structure of the advection operator in the Vlasov equation, resulting in a stable numerical method. We apply such discretization to two formulations: the canonical Vlasov-Poisson equations and their continuously transformed square-root representation. The latter preserves the positivity of the particle distribution function. We derive analytically the conservation properties of both formulations, including particle number, momentum, and energy, which are verified numerically on the following benchmark problems: manufactured solution, linear and nonlinear Landau damping, two-stream instability, bump-on-tail instability, and ion-acoustic wave.", "published": "2024-10-31 04:00:00", "id": "6813b066-7e62-42bd-b9bf-a8f1174a641c", "source": "arxiv", "section": "computerScience"}, {"title": "Banyan: Fast Rotating Leader BFT", "link": "https://arxiv.org/abs/2312.05869", "description": "arXiv:2312.05869v2 Announce Type: replace \nAbstract: This paper presents Banyan, the first rotating leader state machine replication (SMR) protocol that allows transactions to be confirmed in just a single round-trip time in the Byzantine fault tolerance (BFT) setting. Based on minimal alterations to the Internet Computer Consensus (ICC) protocol and with negligible communication overhead, we introduce a novel dual mode mechanism that enables optimal block finalization latency in the fast path. Crucially, the modes of operation are integrated, such that even if the fast path is not effective, no penalties are incurred. Moreover, our algorithm maintains the core attributes of the ICC protocol it is based on, including optimistic responsiveness and rotating leaders without the necessity for a view-change protocol. We prove the correctness of our protocol and provide an open-source implementation of it. Banyan is compared to its predecessor ICC, as well as other well known BFT protocols, in a globally distributed wide-area network. Our evaluation reveals that Banyan reduces latency by up to 30% compared to state-of-the-art protocols, without requiring additional security assumptions.", "published": "2024-10-31 04:00:00", "id": "cdc65dcb-efe3-43c8-ba4e-2fd45c03de77", "source": "arxiv", "section": "computerScience"}, {"title": "Successive Bayesian Reconstructor for Channel Estimation in Fluid Antenna Systems", "link": "https://arxiv.org/abs/2312.06551", "description": "arXiv:2312.06551v4 Announce Type: replace \nAbstract: Fluid antenna systems (FASs) can reconfigure their antenna locations freely within a spatially continuous space. To keep favorable antenna positions, the channel state information (CSI) acquisition for FASs is essential. While some techniques have been proposed, most existing FAS channel estimators require several channel assumptions, such as slow variation and angular-domain sparsity. When these assumptions are not reasonable, the model mismatch may lead to unpredictable performance losses. In this paper, we propose the successive Bayesian reconstructor (S-BAR) as a general solution to estimate FAS channels. Unlike model-based estimators, the proposed S-BAR is prior-aided, which builds the experiential kernel for CSI acquisition. Inspired by Bayesian regression, the key idea of S-BAR is to model the FAS channels as a stochastic process, whose uncertainty can be successively eliminated by kernel-based sampling and regression. In this way, the predictive mean of the regressed stochastic process can be viewed as a Bayesian channel estimator. Simulation results verify that, in both model-mismatched and model-matched cases, the proposed S-BAR can achieve higher estimation accuracy than the existing schemes.", "published": "2024-10-31 04:00:00", "id": "06a21281-3e05-45b5-a1cb-00e231f9abd0", "source": "arxiv", "section": "computerScience"}, {"title": "Certified Minimax Unlearning with Generalization Rates and Deletion Capacity", "link": "https://arxiv.org/abs/2312.10336", "description": "arXiv:2312.10336v2 Announce Type: replace \nAbstract: We study the problem of $(\\epsilon,\\delta)$-certified machine unlearning for minimax models. Most of the existing works focus on unlearning from standard statistical learning models that have a single variable and their unlearning steps hinge on the direct Hessian-based conventional Newton update. We develop a new $(\\epsilon,\\delta)$-certified machine unlearning algorithm for minimax models. It proposes a minimax unlearning step consisting of a total-Hessian-based complete Newton update and the Gaussian mechanism borrowed from differential privacy. To obtain the unlearning certification, our method injects calibrated Gaussian noises by carefully analyzing the \"sensitivity\" of the minimax unlearning step (i.e., the closeness between the minimax unlearning variables and the retraining-from-scratch variables). We derive the generalization rates in terms of population strong and weak primal-dual risk for three different cases of loss functions, i.e., (strongly-)convex-(strongly-)concave losses. We also provide the deletion capacity to guarantee that a desired population risk can be maintained as long as the number of deleted samples does not exceed the derived amount. With training samples $n$ and model dimension $d$, it yields the order $\\mathcal O(n/d^{1/4})$, which shows a strict gap over the baseline method of differentially private minimax learning that has $\\mathcal O(n/d^{1/2})$. In addition, our rates of generalization and deletion capacity match the state-of-the-art rates derived previously for standard statistical learning models.", "published": "2024-10-31 04:00:00", "id": "352eac60-d035-43e7-9e8d-5f251db04c68", "source": "arxiv", "section": "computerScience"}, {"title": "A Concentration Bound for TD(0) with Function Approximation", "link": "https://arxiv.org/abs/2312.10424", "description": "arXiv:2312.10424v2 Announce Type: replace \nAbstract: We derive a concentration bound of the type `for all $n \\geq n_0$ for some $n_0$' for TD(0) with linear function approximation. We work with online TD learning with samples from a single sample path of the underlying Markov chain. This makes our analysis significantly different from offline TD learning or TD learning with access to independent samples from the stationary distribution of the Markov chain. We treat TD(0) as a contractive stochastic approximation algorithm, with both martingale and Markov noises. Markov noise is handled using the Poisson equation and the lack of almost sure guarantees on boundedness of iterates is handled using the concept of relaxed concentration inequalities.", "published": "2024-10-31 04:00:00", "id": "0dfa799c-8f15-46ff-9532-7bfe3ff9ef03", "source": "arxiv", "section": "computerScience"}, {"title": "MetaSegNet: Metadata-collaborative Vision-Language Representation Learning for Semantic Segmentation of Remote Sensing Images", "link": "https://arxiv.org/abs/2312.12735", "description": "arXiv:2312.12735v3 Announce Type: replace \nAbstract: Semantic segmentation of remote sensing images plays a vital role in a wide range of Earth Observation applications, such as land use land cover mapping, environment monitoring, and sustainable development. Driven by rapid developments in artificial intelligence, deep learning (DL) has emerged as the mainstream for semantic segmentation and has achieved many breakthroughs in the field of remote sensing. However, most DL-based methods focus on unimodal visual data while ignoring rich multimodal information involved in the real world. Non-visual data, such as text, can gather extra knowledge from the real world, which can strengthen the interpretability, reliability, and generalization of visual models. Inspired by this, we propose a novel metadata-collaborative segmentation network (MetaSegNet) that applies vision-language representation learning for semantic segmentation of remote sensing images. Unlike the common model structure that only uses unimodal visual data, we extract the key characteristic (e.g. the climate zone) from freely available remote sensing image metadata and transfer it into geographic text prompts via the generic ChatGPT. Then, we construct an image encoder, a text encoder, and a crossmodal attention fusion subnetwork to extract the image and text feature and apply image-text interaction. Benefiting from such a design, the proposed MetaSegNet not only demonstrates superior generalization in zero-shot testing but also achieves competitive accuracy with the state-of-the-art semantic segmentation methods on the large-scale OpenEarthMap dataset (70.4% mIoU) and the Potsdam dataset (93.3% mean F1 score) as well as the LoveDA dataset (52.0% mIoU).", "published": "2024-10-31 04:00:00", "id": "cb263c40-802c-4cb6-b5ce-fd9570fc5823", "source": "arxiv", "section": "computerScience"}, {"title": "Algebraic Positional Encodings", "link": "https://arxiv.org/abs/2312.16045", "description": "arXiv:2312.16045v2 Announce Type: replace \nAbstract: We introduce a novel positional encoding strategy for Transformer-style models, addressing the shortcomings of existing, often ad hoc, approaches. Our framework provides a flexible mapping from the algebraic specification of a domain to an interpretation as orthogonal operators. This design preserves the algebraic characteristics of the source domain, ensuring that the model upholds its desired structural properties. Our scheme can accommodate various structures, ncluding sequences, grids and trees, as well as their compositions. We conduct a series of experiments to demonstrate the practical applicability of our approach. Results suggest performance on par with or surpassing the current state-of-the-art, without hyper-parameter optimizations or \"task search\" of any kind. Code is available at https://github.com/konstantinosKokos/ape.", "published": "2024-10-31 04:00:00", "id": "fab145ec-33e3-44a8-81b7-2a2e2f94f148", "source": "arxiv", "section": "computerScience"}, {"title": "Robust Control Barrier Functions using Uncertainty Estimation with Application to Mobile Robots", "link": "https://arxiv.org/abs/2401.01881", "description": "arXiv:2401.01881v2 Announce Type: replace \nAbstract: This paper proposes a safety-critical control design approach for nonlinear control affine systems in the presence of matched and unmatched uncertainties. Our constructive framework couples control barrier function (CBF) theory with a new uncertainty estimator to ensure robust safety. The estimated uncertainty with a derived upper bound on the estimation error is used for synthesizing CBFs and safety-critical controllers via a quadratic program-based feedback control law that rigorously ensures robust safety while improving disturbance rejection performance. The method is extended to higher-order CBFs (HOCBFs) to achieve safety under unmatched uncertainty, which may cause relative degree differences with respect to control input and disturbances. We assume the relative degree difference is at most one, resulting in a second-order cone constraint. The proposed robust HOCBF method is demonstrated via a simulation of an uncertain elastic actuator control problem. Finally, we experimentally demonstrated the efficacy of our robust CBF framework on a tracked robot with slope-induced matched and unmatched perturbations.", "published": "2024-10-31 04:00:00", "id": "7eab2522-624f-4bfd-a105-d6d17ae36226", "source": "arxiv", "section": "computerScience"}, {"title": "A Survey Analyzing Generalization in Deep Reinforcement Learning", "link": "https://arxiv.org/abs/2401.02349", "description": "arXiv:2401.02349v2 Announce Type: replace \nAbstract: Reinforcement learning research obtained significant success and attention with the utilization of deep neural networks to solve problems in high dimensional state or action spaces. While deep reinforcement learning policies are currently being deployed in many different fields from medical applications to large language models, there are still ongoing questions the field is trying to answer on the generalization capabilities of deep reinforcement learning policies. In this paper, we will formalize and analyze generalization in deep reinforcement learning. We will explain the fundamental reasons why deep reinforcement learning policies encounter overfitting problems that limit their generalization capabilities. Furthermore, we will categorize and explain the manifold solution approaches to increase generalization, and overcome overfitting in deep reinforcement learning policies. From exploration to adversarial analysis and from regularization to robustness our paper provides an analysis on a wide range of subfields within deep reinforcement learning with a broad scope and in-depth view. We believe our study can provide a compact guideline for the current advancements in deep reinforcement learning, and help to construct robust deep neural policies with higher generalization skills.", "published": "2024-10-31 04:00:00", "id": "82b97c75-02eb-4d6b-907b-a727e7391b62", "source": "arxiv", "section": "computerScience"}, {"title": "ChatQA: Surpassing GPT-4 on Conversational QA and RAG", "link": "https://arxiv.org/abs/2401.10225", "description": "arXiv:2401.10225v5 Announce Type: replace \nAbstract: In this work, we introduce ChatQA, a suite of models that outperform GPT-4 on retrieval-augmented generation (RAG) and conversational question answering (QA). To enhance generation, we propose a two-stage instruction tuning method that significantly boosts the performance of RAG. For effective retrieval, we introduce a dense retriever optimized for conversational QA, which yields results comparable to the alternative state-of-the-art query rewriting models, while substantially reducing deployment costs. We also present the ChatRAG Bench, which encompasses ten datasets covering comprehensive evaluations on RAG, table-related QA, arithmetic calculations, and scenarios involving unanswerable questions. Our ChatQA-1.0-70B (score: 54.14), built on Llama2, a weaker foundation model than GPT-4, can slightly outperform GPT-4-0613 (score: 53.90) and GPT-4-Turbo-2024-04-09 (score: 54.03) on the ChatRAG Bench, without relying on any synthetic data from OpenAI GPT models. Notably, the Llama3-ChatQA-1.5-70B model surpasses the accuracy of GPT-4-Turbo-2024-04-09, achieving a 4.4% improvement. To advance research in this field, we open-sourced the model weights, instruction tuning data, ChatRAG Bench, and retriever for the community: https://chatqa-project.github.io/.", "published": "2024-10-31 04:00:00", "id": "97e6bbf9-4c81-4f06-a130-da2e45dd5cec", "source": "arxiv", "section": "computerScience"}, {"title": "HyperSense: Hyperdimensional Intelligent Sensing for Energy-Efficient Sparse Data Processing", "link": "https://arxiv.org/abs/2401.10267", "description": "arXiv:2401.10267v4 Announce Type: replace \nAbstract: Introducing HyperSense, our co-designed hardware and software system efficiently controls Analog-to-Digital Converter (ADC) modules' data generation rate based on object presence predictions in sensor data. Addressing challenges posed by escalating sensor quantities and data rates, HyperSense reduces redundant digital data using energy-efficient low-precision ADC, diminishing machine learning system costs. Leveraging neurally-inspired HyperDimensional Computing (HDC), HyperSense analyzes real-time raw low-precision sensor data, offering advantages in handling noise, memory-centricity, and real-time learning. Our proposed HyperSense model combines high-performance software for object detection with real-time hardware prediction, introducing the novel concept of Intelligent Sensor Control. Comprehensive software and hardware evaluations demonstrate our solution's superior performance, evidenced by the highest Area Under the Curve (AUC) and sharpest Receiver Operating Characteristic (ROC) curve among lightweight models. Hardware-wise, our FPGA-based domain-specific accelerator tailored for HyperSense achieves a 5.6x speedup compared to YOLOv4 on NVIDIA Jetson Orin while showing up to 92.1% energy saving compared to the conventional system. These results underscore HyperSense's effectiveness and efficiency, positioning it as a promising solution for intelligent sensing and real-time data processing across diverse applications.", "published": "2024-10-31 04:00:00", "id": "966b9041-510a-474e-a13a-a85d1fe2fbff", "source": "arxiv", "section": "computerScience"}, {"title": "AI, insurance, discrimination and unfair differentiation. An overview and research agenda", "link": "https://arxiv.org/abs/2401.11892", "description": "arXiv:2401.11892v3 Announce Type: replace \nAbstract: Insurers underwrite risks: they calculate risks and decide on the insurance premium. Insurers seem captivated by two trends enabled by Artificial Intelligence (AI). (i) First, insurers could use AI for analysing more and new types of data to assess risks more precisely: data-intensive underwriting. (ii) Second, insurers could use AI to monitor the behaviour of individual consumers in real-time: behaviour-based insurance. For example, some car insurers offer a discount if the consumer agrees to being tracked by the insurer and drives safely. While the two trends bring many advantages, they may also have discriminatory effects on society. This paper focuses on the following question. Which effects related to discrimination and unfair differentiation may occur if insurers follow data-intensive underwriting and behaviour-based insurance? Researchers and policymakers working in other sectors may also find the paper useful, as the insurance sector has decades of experience with statistics and forms of AI. Moreover, some questions that arise in the insurance sector are important in other sectors too.", "published": "2024-10-31 04:00:00", "id": "f4624547-f16a-45e5-9a09-0a9af96be855", "source": "arxiv", "section": "computerScience"}, {"title": "Out-of-Distribution Detection & Applications With Ablated Learned Temperature Energy", "link": "https://arxiv.org/abs/2401.12129", "description": "arXiv:2401.12129v2 Announce Type: replace \nAbstract: As deep neural networks become adopted in high-stakes domains, it is crucial to identify when inference inputs are Out-of-Distribution (OOD) so that users can be alerted of likely drops in performance and calibration despite high confidence -- ultimately to know when networks' decisions (and their uncertainty in those decisions) should be trusted. In this paper we introduce Ablated Learned Temperature Energy (or \"AbeT\" for short), an OOD detection method which lowers the False Positive Rate at 95\\% True Positive Rate (FPR@95) by $43.43\\%$ in classification compared to state of the art without training networks in multiple stages or requiring hyperparameters or test-time backward passes. We additionally provide empirical insights as to why our model learns to distinguish between In-Distribution (ID) and OOD samples while only being explicitly trained on ID samples via exposure to misclassified ID examples at training time. Lastly, we show the efficacy of our method in identifying predicted bounding boxes and pixels corresponding to OOD objects in object detection and semantic segmentation, respectively -- with an AUROC increase of $5.15\\%$ in object detection and both a decrease in FPR@95 of $41.48\\%$ and an increase in AUPRC of $34.20\\%$ in semantic segmentation compared to previous state of the art.", "published": "2024-10-31 04:00:00", "id": "4b3be8d0-cfa7-4fe4-869a-ab2261eb6a89", "source": "arxiv", "section": "computerScience"}, {"title": "Incorporating Test-Time Optimization into Training with Dual Networks for Human Mesh Recovery", "link": "https://arxiv.org/abs/2401.14121", "description": "arXiv:2401.14121v2 Announce Type: replace \nAbstract: Human Mesh Recovery (HMR) is the task of estimating a parameterized 3D human mesh from an image. There is a kind of methods first training a regression model for this problem, then further optimizing the pretrained regression model for any specific sample individually at test time. However, the pretrained model may not provide an ideal optimization starting point for the test-time optimization. Inspired by meta-learning, we incorporate the test-time optimization into training, performing a step of test-time optimization for each sample in the training batch before really conducting the training optimization over all the training samples. In this way, we obtain a meta-model, the meta-parameter of which is friendly to the test-time optimization. At test time, after several test-time optimization steps starting from the meta-parameter, we obtain much higher HMR accuracy than the test-time optimization starting from the simply pretrained regression model. Furthermore, we find test-time HMR objectives are different from training-time objectives, which reduces the effectiveness of the learning of the meta-model. To solve this problem, we propose a dual-network architecture that unifies the training-time and test-time objectives. Our method, armed with meta-learning and the dual networks, outperforms state-of-the-art regression-based and optimization-based HMR approaches, as validated by the extensive experiments. The codes are available at https://github.com/fmx789/Meta-HMR.", "published": "2024-10-31 04:00:00", "id": "e004b938-6675-47ed-a7f4-5196683124a4", "source": "arxiv", "section": "computerScience"}, {"title": "Stochastic Amortization: A Unified Approach to Accelerate Feature and Data Attribution", "link": "https://arxiv.org/abs/2401.15866", "description": "arXiv:2401.15866v2 Announce Type: replace \nAbstract: Many tasks in explainable machine learning, such as data valuation and feature attribution, perform expensive computation for each data point and are intractable for large datasets. These methods require efficient approximations, and although amortizing the process by learning a network to directly predict the desired output is a promising solution, training such models with exact labels is often infeasible. We therefore explore training amortized models with noisy labels, and we find that this is inexpensive and surprisingly effective. Through theoretical analysis of the label noise and experiments with various models and datasets, we show that this approach tolerates high noise levels and significantly accelerates several feature attribution and data valuation methods, often yielding an order of magnitude speedup over existing approaches.", "published": "2024-10-31 04:00:00", "id": "ecb69412-a5f9-4181-982d-5b234d35a78c", "source": "arxiv", "section": "computerScience"}, {"title": "Recent Advances in Hate Speech Moderation: Multimodality and the Role of Large Models", "link": "https://arxiv.org/abs/2401.16727", "description": "arXiv:2401.16727v4 Announce Type: replace \nAbstract: In the evolving landscape of online communication, moderating hate speech (HS) presents an intricate challenge, compounded by the multimodal nature of digital content. This comprehensive survey delves into the recent strides in HS moderation, spotlighting the burgeoning role of large language models (LLMs) and large multimodal models (LMMs). Our exploration begins with a thorough analysis of current literature, revealing the nuanced interplay between textual, visual, and auditory elements in propagating HS. We uncover a notable trend towards integrating these modalities, primarily due to the complexity and subtlety with which HS is disseminated. A significant emphasis is placed on the advances facilitated by LLMs and LMMs, which have begun to redefine the boundaries of detection and moderation capabilities. We identify existing gaps in research, particularly in the context of underrepresented languages and cultures, and the need for solutions to handle low-resource settings. The survey concludes with a forward-looking perspective, outlining potential avenues for future research, including the exploration of novel AI methodologies, the ethical governance of AI in moderation, and the development of more nuanced, context-aware systems. This comprehensive overview aims to catalyze further research and foster a collaborative effort towards more sophisticated, responsible, and human-centric approaches to HS moderation in the digital era. WARNING: This paper contains offensive examples.", "published": "2024-10-31 04:00:00", "id": "0cdde199-288b-4a67-865c-7f69ec13f04a", "source": "arxiv", "section": "computerScience"}, {"title": "Comparing Template-based and Template-free Language Model Probing", "link": "https://arxiv.org/abs/2402.00123", "description": "arXiv:2402.00123v2 Announce Type: replace \nAbstract: The differences between cloze-task language model (LM) probing with 1) expert-made templates and 2) naturally-occurring text have often been overlooked. Here, we evaluate 16 different LMs on 10 probing English datasets -- 4 template-based and 6 template-free -- in general and biomedical domains to answer the following research questions: (RQ1) Do model rankings differ between the two approaches? (RQ2) Do models' absolute scores differ between the two approaches? (RQ3) Do the answers to RQ1 and RQ2 differ between general and domain-specific models? Our findings are: 1) Template-free and template-based approaches often rank models differently, except for the top domain-specific models. 2) Scores decrease by up to 42% Acc@1 when comparing parallel template-free and template-based prompts. 3) Perplexity is negatively correlated with accuracy in the template-free approach, but, counter-intuitively, they are positively correlated for template-based probing. 4) Models tend to predict the same answers frequently across prompts for template-based probing, which is less common when employing template-free techniques.", "published": "2024-10-31 04:00:00", "id": "0e17cbfb-3232-41b7-ab69-28ae7dd04978", "source": "arxiv", "section": "computerScience"}, {"title": "Human Expertise in Algorithmic Prediction", "link": "https://arxiv.org/abs/2402.00793", "description": "arXiv:2402.00793v3 Announce Type: replace \nAbstract: We introduce a novel framework for incorporating human expertise into algorithmic predictions. Our approach leverages human judgment to distinguish inputs which are algorithmically indistinguishable, or \"look the same\" to predictive algorithms. We argue that this framing clarifies the problem of human-AI collaboration in prediction tasks, as experts often form judgments by drawing on information which is not encoded in an algorithm's training data. Algorithmic indistinguishability yields a natural test for assessing whether experts incorporate this kind of \"side information\", and further provides a simple but principled method for selectively incorporating human feedback into algorithmic predictions. We show that this method provably improves the performance of any feasible algorithmic predictor and precisely quantify this improvement. We find empirically that although algorithms often outperform their human counterparts on average, human judgment can improve algorithmic predictions on specific instances (which can be identified ex-ante). In an X-ray classification task, we find that this subset constitutes nearly $30\\%$ of the patient population. Our approach provides a natural way of uncovering this heterogeneity and thus enabling effective human-AI collaboration.", "published": "2024-10-31 04:00:00", "id": "4290b48c-412e-4ed2-82a2-9114c3a977f3", "source": "arxiv", "section": "computerScience"}, {"title": "Score-based Causal Representation Learning: Linear and General Transformations", "link": "https://arxiv.org/abs/2402.00849", "description": "arXiv:2402.00849v3 Announce Type: replace \nAbstract: This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on general transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does not need to know which pair of interventional environments have the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.", "published": "2024-10-31 04:00:00", "id": "1b6e9c2c-4199-4a3c-8a11-eb42ed8aea50", "source": "arxiv", "section": "computerScience"}, {"title": "Learning General Parameterized Policies for Infinite Horizon Average Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm", "link": "https://arxiv.org/abs/2402.02042", "description": "arXiv:2402.02042v3 Announce Type: replace \nAbstract: This paper explores the realm of infinite horizon average reward Constrained Markov Decision Processes (CMDPs). To the best of our knowledge, this work is the first to delve into the regret and constraint violation analysis of average reward CMDPs with a general policy parametrization. To address this challenge, we propose a primal dual-based policy gradient algorithm that adeptly manages the constraints while ensuring a low regret guarantee toward achieving a global optimal policy. In particular, our proposed algorithm achieves $\\tilde{\\mathcal{O}}({T}^{4/5})$ objective regret and $\\tilde{\\mathcal{O}}({T}^{4/5})$ constraint violation bounds.", "published": "2024-10-31 04:00:00", "id": "85a7f15d-75bc-4427-b48a-8b02c1931858", "source": "arxiv", "section": "computerScience"}, {"title": "Learning Structure-Aware Representations of Dependent Types", "link": "https://arxiv.org/abs/2402.02104", "description": "arXiv:2402.02104v2 Announce Type: replace \nAbstract: Agda is a dependently-typed programming language and a proof assistant, pivotal in proof formalization and programming language theory. This paper extends the Agda ecosystem into machine learning territory, and, vice versa, makes Agda-related resources available to machine learning practitioners. We introduce and release a novel dataset of Agda program-proofs that is elaborate and extensive enough to support various machine learning applications -- the first of its kind. Leveraging the dataset's ultra-high resolution, which details proof states at the sub-type level, we propose a novel neural architecture targeted at faithfully representing dependently-typed programs on the basis of structural rather than nominal principles. We instantiate and evaluate our architecture in a premise selection setup, where it achieves promising initial results, surpassing strong baselines.", "published": "2024-10-31 04:00:00", "id": "bc0a92f5-df00-415d-a090-e260cac00351", "source": "arxiv", "section": "computerScience"}, {"title": "Online Feature Updates Improve Online (Generalized) Label Shift Adaptation", "link": "https://arxiv.org/abs/2402.03545", "description": "arXiv:2402.03545v2 Announce Type: replace \nAbstract: This paper addresses the prevalent issue of label shift in an online setting with missing labels, where data distributions change over time and obtaining timely labels is challenging. While existing methods primarily focus on adjusting or updating the final layer of a pre-trained classifier, we explore the untapped potential of enhancing feature representations using unlabeled data at test-time. Our novel method, Online Label Shift adaptation with Online Feature Updates (OLS-OFU), leverages self-supervised learning to refine the feature extraction process, thereby improving the prediction model. By carefully designing the algorithm, theoretically OLS-OFU maintains the similar online regret convergence to the results in the literature while taking the improved features into account. Empirically, it achieves substantial improvements over existing methods, which is as significant as the gains existing methods have over the baseline (i.e., without distribution shift adaptations).", "published": "2024-10-31 04:00:00", "id": "8f69ddde-9992-4b1a-b3e4-a0e4852957b4", "source": "arxiv", "section": "computerScience"}, {"title": "Block Sparse Bayesian Learning: A Diversified Scheme", "link": "https://arxiv.org/abs/2402.04646", "description": "arXiv:2402.04646v2 Announce Type: replace \nAbstract: This paper introduces a novel prior called Diversified Block Sparse Prior to characterize the widespread block sparsity phenomenon in real-world data. By allowing diversification on intra-block variance and inter-block correlation matrices, we effectively address the sensitivity issue of existing block sparse learning methods to pre-defined block information, which enables adaptive block estimation while mitigating the risk of overfitting. Based on this, a diversified block sparse Bayesian learning method (DivSBL) is proposed, utilizing EM algorithm and dual ascent method for hyperparameter estimation. Moreover, we establish the global and local optimality theory of our model. Experiments validate the advantages of DivSBL over existing algorithms.", "published": "2024-10-31 04:00:00", "id": "93f3dd15-55af-4b5b-95f9-d1d5875d88e3", "source": "arxiv", "section": "computerScience"}, {"title": "Noise Contrastive Alignment of Language Models with Explicit Rewards", "link": "https://arxiv.org/abs/2402.05369", "description": "arXiv:2402.05369v3 Announce Type: replace \nAbstract: User intentions are typically formalized as evaluation rewards to be maximized when fine-tuning language models (LMs). Existing alignment methods, such as Direct Preference Optimization (DPO), are mainly tailored for pairwise preference data where rewards are implicitly defined rather than explicitly given. In this paper, we introduce a general framework for LM alignment, leveraging Noise Contrastive Estimation (NCE) to bridge the gap in handling reward datasets explicitly annotated with scalar evaluations. Our framework comprises two parallel algorithms, NCA and InfoNCA, both enabling the direct extraction of an LM policy from reward data as well as preference data. Notably, we show that the DPO loss is a special case of our proposed InfoNCA objective under pairwise preference settings, thereby integrating and extending current alignment theories. By comparing NCA and InfoNCA, we demonstrate that the well-observed decreasing-likelihood trend of DPO/InfoNCA is caused by their focus on adjusting relative likelihood across different responses. In contrast, NCA optimizes the absolute likelihood for each response, thereby effectively preventing the chosen likelihood from decreasing. We evaluate our methods in both reward and preference settings with Mistral-8*7B and 7B models. Experiments suggest that InfoNCA/NCA surpasses various preference baselines when reward datasets are available. We also find NCA significantly outperforms DPO in complex reasoning tasks like math and coding.", "published": "2024-10-31 04:00:00", "id": "0f884873-8d12-4c0a-9446-42cf2251887e", "source": "arxiv", "section": "computerScience"}, {"title": "Trade-Offs of Diagonal Fisher Information Matrix Estimators", "link": "https://arxiv.org/abs/2402.05379", "description": "arXiv:2402.05379v3 Announce Type: replace \nAbstract: The Fisher information matrix can be used to characterize the local geometry of the parameter space of neural networks. It elucidates insightful theories and useful tools to understand and optimize neural networks. Given its high computational cost, practitioners often use random estimators and evaluate only the diagonal entries. We examine two popular estimators whose accuracy and sample complexity depend on their associated variances. We derive bounds of the variances and instantiate them in neural networks for regression and classification. We navigate trade-offs for both estimators based on analytical and numerical studies. We find that the variance quantities depend on the non-linearity wrt different parameter groups and should not be neglected when estimating the Fisher information.", "published": "2024-10-31 04:00:00", "id": "a2326b25-1e18-4910-9649-86b06ec6d6b2", "source": "arxiv", "section": "computerScience"}, {"title": "How to split a tera-polynomial", "link": "https://arxiv.org/abs/2402.06083", "description": "arXiv:2402.06083v2 Announce Type: replace \nAbstract: This article presents a new algorithm to compute all the roots of two families of polynomials that are of interest for the Mandelbrot set $\\mathcal{M}$ : the roots of those polynomials are respectively the parameters $c\\in\\mathcal{M}$ associated with periodic critical dynamics for $f_c(z)=z^2+c$ (hyperbolic centers) or with pre-periodic dynamics (Misiurewicz-Thurston parameters). The algorithm is based on the computation of discrete level lines that provide excellent starting points for the Newton method. In practice, we observe that these polynomials can be split in linear time of the degree. This article is paired with a code library [Mandel] that implements this algorithm. Using this library and about 723 000 core-hours on the HPC center Rom\\'eo (Reims), we have successfully found all hyperbolic centers of period $\\leq 41$ and all Misiurewicz-Thurston parameters whose period and pre-period sum to $\\leq 35$. Concretely, this task involves splitting a tera-polynomial, i.e. a polynomial of degree $\\sim10^{12}$, which is orders of magnitude ahead of the previous state of the art. It also involves dealing with the certifiability of our numerical results, which is an issue that we address in detail, both mathematically and along the production chain. The certified database is available to the scientific community. For the smaller periods that can be represented using only hardware arithmetic (floating points FP80), the implementation of our algorithm can split the corresponding polynomials of degree $\\sim10^{9}$ in less than one day-core. We complement these benchmarks with a statistical analysis of the separation of the roots, which confirms that no other polynomial in these families can be split without using higher precision arithmetic.", "published": "2024-10-31 04:00:00", "id": "dd441b70-151a-4913-a4dc-d3aa65beabe6", "source": "arxiv", "section": "computerScience"}, {"title": "Copycats: the many lives of a publicly available medical imaging dataset", "link": "https://arxiv.org/abs/2402.06353", "description": "arXiv:2402.06353v3 Announce Type: replace \nAbstract: Medical Imaging (MI) datasets are fundamental to artificial intelligence in healthcare. The accuracy, robustness, and fairness of diagnostic algorithms depend on the data (and its quality) used to train and evaluate the models. MI datasets used to be proprietary, but have become increasingly available to the public, including on community-contributed platforms (CCPs) like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data's public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper, we conduct an analysis of publicly available machine learning datasets on CCPs, discussing datasets' context, and identifying limitations and gaps in the current CCP landscape. We highlight differences between MI and computer vision datasets, particularly in the potentially harmful downstream effects from poor adoption of recommended dataset management practices. We compare the analyzed datasets across several dimensions, including data sharing, data documentation, and maintenance. We find vague licenses, lack of persistent identifiers and storage, duplicates, and missing metadata, with differences between the platforms. Our research contributes to efforts in responsible data curation and AI algorithms for healthcare.", "published": "2024-10-31 04:00:00", "id": "f2d7eeec-0dd1-4467-9723-557185e41c80", "source": "arxiv", "section": "computerScience"}, {"title": "Transductive Learning Is Compact", "link": "https://arxiv.org/abs/2402.10360", "description": "arXiv:2402.10360v3 Announce Type: replace \nAbstract: We demonstrate a compactness result holding broadly across supervised learning with a general class of loss functions: Any hypothesis class $H$ is learnable with transductive sample complexity $m$ precisely when all of its finite projections are learnable with sample complexity $m$. We prove that this exact form of compactness holds for realizable and agnostic learning with respect to any proper metric loss function (e.g., any norm on $\\mathbb{R}^d$) and any continuous loss on a compact space (e.g., cross-entropy, squared loss). For realizable learning with improper metric losses, we show that exact compactness of sample complexity can fail, and provide matching upper and lower bounds of a factor of 2 on the extent to which such sample complexities can differ. We conjecture that larger gaps are possible for the agnostic case. Furthermore, invoking the equivalence between sample complexities in the PAC and transductive models (up to lower order factors, in the realizable case) permits us to directly port our results to the PAC model, revealing an almost-exact form of compactness holding broadly in PAC learning.", "published": "2024-10-31 04:00:00", "id": "44225776-c649-447d-8e27-8ba4430a79c3", "source": "arxiv", "section": "computerScience"}, {"title": "UnlearnCanvas: Stylized Image Dataset for Enhanced Machine Unlearning Evaluation in Diffusion Models", "link": "https://arxiv.org/abs/2402.11846", "description": "arXiv:2402.11846v4 Announce Type: replace \nAbstract: The technological advancements in diffusion models (DMs) have demonstrated unprecedented capabilities in text-to-image generation and are widely used in diverse applications. However, they have also raised significant societal concerns, such as the generation of harmful content and copyright disputes. Machine unlearning (MU) has emerged as a promising solution, capable of removing undesired generative capabilities from DMs. However, existing MU evaluation systems present several key challenges that can result in incomplete and inaccurate assessments. To address these issues, we propose UnlearnCanvas, a comprehensive high-resolution stylized image dataset that facilitates the evaluation of the unlearning of artistic styles and associated objects. This dataset enables the establishment of a standardized, automated evaluation framework with 7 quantitative metrics assessing various aspects of the unlearning performance for DMs. Through extensive experiments, we benchmark 9 state-of-the-art MU methods for DMs, revealing novel insights into their strengths, weaknesses, and underlying mechanisms. Additionally, we explore challenging unlearning scenarios for DMs to evaluate worst-case performance against adversarial prompts, the unlearning of finer-scale concepts, and sequential unlearning. We hope that this study can pave the way for developing more effective, accurate, and robust DM unlearning methods, ensuring safer and more ethical applications of DMs in the future. The dataset, benchmark, and codes are publicly available at https://unlearn-canvas.netlify.app/.", "published": "2024-10-31 04:00:00", "id": "b53a7848-44ee-4664-9e97-8c74cc446225", "source": "arxiv", "section": "computerScience"}, {"title": "Are Fact-Checking Tools Helpful? An Exploration of the Usability of Google Fact Check", "link": "https://arxiv.org/abs/2402.13244", "description": "arXiv:2402.13244v5 Announce Type: replace \nAbstract: Fact-checking-specific search tools such as Google Fact Check are a promising way to combat misinformation on social media, especially during events bringing significant social influence, such as the COVID-19 pandemic and the U.S. presidential elections. However, the usability of such an approach has not been thoroughly studied. We evaluated the performance of Google Fact Check by analyzing the retrieved fact-checking results regarding 1,000 COVID-19-related false claims and found it able to retrieve the fact-checking results for 15.8% of the input claims, and the rendered results are relatively reliable. We also found that the false claims receiving different fact-checking verdicts (i.e., \"False,\" \"Partly False,\" \"True,\" and \"Unratable\") tend to reflect diverse emotional tones, and fact-checking sources tend to check the claims in different lengths and using dictionary words to various extents. Claim variations addressing the same issue yet described differently are likely to retrieve distinct fact-checking results. We suggest that the quantities of the retrieved fact-checking results could be optimized and that slightly adjusting input wording may be the best practice for users to retrieve more useful information. This study aims to contribute to the understanding of state-of-the-art fact-checking tools and information integrity.", "published": "2024-10-31 04:00:00", "id": "07daf740-cb2b-4b3c-bb4a-986ca9273d36", "source": "arxiv", "section": "computerScience"}, {"title": "Retention Induced Biases in a Recommendation System with Heterogeneous Users", "link": "https://arxiv.org/abs/2402.13959", "description": "arXiv:2402.13959v3 Announce Type: replace \nAbstract: I examine a conceptual model of a recommendation system (RS) with user inflow and churn dynamics. When inflow and churn balance out, the user distribution reaches a steady state. Changing the recommendation algorithm alters the steady state and creates a transition period. During this period, the RS behaves differently from its new steady state. In particular, A/B experiment metrics obtained in transition periods are biased indicators of the RS's long-term performance. Scholars and practitioners, however, often conduct A/B tests shortly after introducing new algorithms to validate their effectiveness. This A/B experiment paradigm, widely regarded as the gold standard for assessing RS improvements, may consequently yield false conclusions. I also briefly touch on the data bias caused by the user retention dynamics.", "published": "2024-10-31 04:00:00", "id": "cd8d6794-dc02-4334-b04e-b18d5cff4689", "source": "arxiv", "section": "computerScience"}, {"title": "Linear Transformers are Versatile In-Context Learners", "link": "https://arxiv.org/abs/2402.14180", "description": "arXiv:2402.14180v2 Announce Type: replace \nAbstract: Recent research has demonstrated that transformers, particularly linear attention models, implicitly execute gradient-descent-like algorithms on data provided in-context during their forward inference step. However, their capability in handling more complex problems remains unexplored. In this paper, we prove that each layer of a linear transformer maintains a weight vector for an implicit linear regression problem and can be interpreted as performing a variant of preconditioned gradient descent. We also investigate the use of linear transformers in a challenging scenario where the training data is corrupted with different levels of noise. Remarkably, we demonstrate that for this problem linear transformers discover an intricate and highly effective optimization algorithm, surpassing or matching in performance many reasonable baselines. We analyze this algorithm and show that it is a novel approach incorporating momentum and adaptive rescaling based on noise levels. Our findings show that even linear transformers possess the surprising ability to discover sophisticated optimization strategies.", "published": "2024-10-31 04:00:00", "id": "bacff8bd-acd1-454f-ad1b-30fc9e13917d", "source": "arxiv", "section": "computerScience"}, {"title": "Attention-Enhanced Prioritized Proximal Policy Optimization for Adaptive Edge Caching", "link": "https://arxiv.org/abs/2402.14576", "description": "arXiv:2402.14576v3 Announce Type: replace \nAbstract: This paper tackles the growing issue of excessive data transmission in networks. With increasing traffic, backhaul links and core networks are under significant traffic, leading to the investigation of caching solutions at edge routers. Many existing studies utilize Markov Decision Processes (MDP) to tackle caching problems, often assuming decision points at fixed intervals; however, real-world environments are characterized by random request arrivals. Additionally, critical file attributes such as lifetime, size, and priority significantly impact the effectiveness of caching policies, yet existing research fails to integrate all these attributes in policy design. In this work, we model the caching problem using a Semi-Markov Decision Process (SMDP) to better capture the continuous-time nature of real-world applications, enabling caching decisions to be triggered by random file requests. We then introduce a Proximal Policy Optimization (PPO)--based caching strategy that fully considers file attributes like lifetime, size, and priority. Simulations show that our method outperforms a recent Deep Reinforcement Learning-based technique. To further advance our research, we improved the convergence rate of PPO by prioritizing transitions within the replay buffer through an attention mechanism. This mechanism evaluates the similarity between the current state and all stored transitions, assigning higher priorities to transitions that exhibit greater similarity.", "published": "2024-10-31 04:00:00", "id": "0d1014f1-22fd-4cc1-95a0-c73fc3840470", "source": "arxiv", "section": "computerScience"}, {"title": "NeuralSolver: Learning Algorithms For Consistent and Efficient Extrapolation Across General Tasks", "link": "https://arxiv.org/abs/2402.15393", "description": "arXiv:2402.15393v3 Announce Type: replace \nAbstract: We contribute NeuralSolver, a novel recurrent solver that can efficiently and consistently extrapolate, i.e., learn algorithms from smaller problems (in terms of observation size) and execute those algorithms in large problems. Contrary to previous recurrent solvers, NeuralSolver can be naturally applied in both same-size problems, where the input and output sizes are the same, and in different-size problems, where the size of the input and output differ. To allow for this versatility, we design NeuralSolver with three main components: a recurrent module, that iteratively processes input information at different scales, a processing module, responsible for aggregating the previously processed information, and a curriculum-based training scheme, that improves the extrapolation performance of the method. To evaluate our method we introduce a set of novel different-size tasks and we show that NeuralSolver consistently outperforms the prior state-of-the-art recurrent solvers in extrapolating to larger problems, considering smaller training problems and requiring less parameters than other approaches.", "published": "2024-10-31 04:00:00", "id": "190b0099-3176-4200-88a3-02bc2a0e143a", "source": "arxiv", "section": "computerScience"}, {"title": "Minions: Accelerating Large Language Model Inference with Aggregated Speculative Execution", "link": "https://arxiv.org/abs/2402.15678", "description": "arXiv:2402.15678v2 Announce Type: replace \nAbstract: Large language models (LLM) have recently attracted surging interest due to their outstanding capabilities across various domains. However, enabling efficient LLM inference is challenging due to its autoregressive decoding that generates tokens only one at a time. Although research works apply pruning or quantization to speed up LLM inference, they typically require fine-tuning the LLM, incurring significant time and economic costs. Meanwhile, speculative decoding has been proposed to use small speculative models (SSMs) to accelerate the inference of LLM. However, the low acceptance rate of SSM and the high verification cost of LLM prohibit further performance improvement of inference. In this paper, we propose Minions, an LLM inference system that accelerates LLM inference with a collective and adaptive speculative generation. Specifically, Minions proposes a majority-voted mechanism to leverage multiple SSMs to jointly speculate the outputs of LLM, which improves the inference performance without introducing prohibitive computation costs for LLM. To better trade off the number of tokens speculated from SSM and the verification cost of LLM, Minions proposes an adaptive mechanism to dynamically determine the optimal speculation length of SSM, which can achieve better inference performance across different models, datasets, and hyper-parameters. In addition, Minions decouples the SSM decoding and LLM verification efficiently and adopts a pipelined execution mechanism to further improve the inference performance of LLM. By comparing with the state-of-the-art LLM inference systems, we demonstrate that Minions can achieve higher inference throughput and lower inference time.", "published": "2024-10-31 04:00:00", "id": "be17de92-9f7f-4815-bc91-faa0215778e8", "source": "arxiv", "section": "computerScience"}, {"title": "Anchor-free Clustering based on Anchor Graph Factorization", "link": "https://arxiv.org/abs/2402.15688", "description": "arXiv:2402.15688v2 Announce Type: replace \nAbstract: Anchor-based methods are a pivotal approach in handling clustering of large-scale data. However, these methods typically entail two distinct stages: selecting anchor points and constructing an anchor graph. This bifurcation, along with the initialization of anchor points, significantly influences the overall performance of the algorithm. To mitigate these issues, we introduce a novel method termed Anchor-free Clustering based on Anchor Graph Factorization (AFCAGF). AFCAGF innovates in learning the anchor graph, requiring only the computation of pairwise distances between samples. This process, achievable through straightforward optimization, circumvents the necessity for explicit selection of anchor points. More concretely, our approach enhances the Fuzzy k-means clustering algorithm (FKM), introducing a new manifold learning technique that obviates the need for initializing cluster centers. Additionally, we evolve the concept of the membership matrix between cluster centers and samples in FKM into an anchor graph encompassing multiple anchor points and samples. Employing Non-negative Matrix Factorization (NMF) on this anchor graph allows for the direct derivation of cluster labels, thereby eliminating the requirement for further post-processing steps. To solve the method proposed, we implement an alternating optimization algorithm that ensures convergence. Empirical evaluations on various real-world datasets underscore the superior efficacy of our algorithm compared to traditional approaches.", "published": "2024-10-31 04:00:00", "id": "1948a18c-ce06-4a00-abf7-682535e2ada2", "source": "arxiv", "section": "computerScience"}, {"title": "Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue", "link": "https://arxiv.org/abs/2402.17262", "description": "arXiv:2402.17262v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have been demonstrated to generate illegal or unethical responses, particularly when subjected to \"jailbreak.\" Research on jailbreak has highlighted the safety issues of LLMs. However, prior studies have predominantly focused on single-turn dialogue, ignoring the potential complexities and risks presented by multi-turn dialogue, a crucial mode through which humans derive information from LLMs. In this paper, we argue that humans could exploit multi-turn dialogue to induce LLMs into generating harmful information. LLMs may not intend to reject cautionary or borderline unsafe queries, even if each turn is closely served for one malicious purpose in a multi-turn dialogue. Therefore, by decomposing an unsafe query into several sub-queries for multi-turn dialogue, we induced LLMs to answer harmful sub-questions incrementally, culminating in an overall harmful response. Our experiments, conducted across a wide range of LLMs, indicate current inadequacies in the safety mechanisms of LLMs in multi-turn dialogue. Our findings expose vulnerabilities of LLMs in complex scenarios involving multi-turn dialogue, presenting new challenges for the safety of LLMs.", "published": "2024-10-31 04:00:00", "id": "271946b6-94e1-406a-b2dc-e8cc17967321", "source": "arxiv", "section": "computerScience"}, {"title": "Detection of Micromobility Vehicles in Urban Traffic Videos", "link": "https://arxiv.org/abs/2402.18503", "description": "arXiv:2402.18503v2 Announce Type: replace \nAbstract: Urban traffic environments present unique challenges for object detection, particularly with the increasing presence of micromobility vehicles like e-scooters and bikes. To address this object detection problem, this work introduces an adapted detection model that combines the accuracy and speed of single-frame object detection with the richer features offered by video object detection frameworks. This is done by applying aggregated feature maps from consecutive frames processed through motion flow to the YOLOX architecture. This fusion brings a temporal perspective to YOLOX detection abilities, allowing for a better understanding of urban mobility patterns and substantially improving detection reliability. Tested on a custom dataset curated for urban micromobility scenarios, our model showcases substantial improvement over existing state-of-the-art methods, demonstrating the need to consider spatio-temporal information for detecting such small and thin objects. Our approach enhances detection in challenging conditions, including occlusions, ensuring temporal consistency, and effectively mitigating motion blur.", "published": "2024-10-31 04:00:00", "id": "139a03ec-e2bf-4292-99ee-50378da58978", "source": "arxiv", "section": "computerScience"}, {"title": "Derivative-enhanced Deep Operator Network", "link": "https://arxiv.org/abs/2402.19242", "description": "arXiv:2402.19242v2 Announce Type: replace \nAbstract: The deep operator networks (DeepONet), a class of neural operators that learn mappings between function spaces, have recently been developed as surrogate models for parametric partial differential equations (PDEs). In this work we propose a derivative-enhanced deep operator network (DE-DeepONet), which leverages derivative information to enhance the solution prediction accuracy and provides a more accurate approximation of solution-to-parameter derivatives, especially when training data are limited. DE-DeepONet explicitly incorporates linear dimension reduction of high dimensional parameter input into DeepONet to reduce training cost and adds derivative loss in the loss function to reduce the number of required parameter-solution pairs. We further demonstrate that the use of derivative loss can be extended to enhance other neural operators, such as the Fourier neural operator (FNO). Numerical experiments validate the effectiveness of our approach.", "published": "2024-10-31 04:00:00", "id": "52b4c899-ecc3-44a5-a882-a2b65376d3c7", "source": "arxiv", "section": "computerScience"}, {"title": "LLMs for Targeted Sentiment in News Headlines: Exploring the Descriptive-Prescriptive Dilemma", "link": "https://arxiv.org/abs/2403.00418", "description": "arXiv:2403.00418v3 Announce Type: replace \nAbstract: News headlines often evoke sentiment by intentionally portraying entities in particular ways, making targeted sentiment analysis (TSA) of headlines a worthwhile but difficult task. Due to its subjectivity, creating TSA datasets can involve various annotation paradigms, from descriptive to prescriptive, either encouraging or limiting subjectivity. LLMs are a good fit for TSA due to their broad linguistic and world knowledge and in-context learning abilities, yet their performance depends on prompt design. In this paper, we compare the accuracy of state-of-the-art LLMs and fine-tuned encoder models for TSA of news headlines using descriptive and prescriptive datasets across several languages. Exploring the descriptive--prescriptive continuum, we analyze how performance is affected by prompt prescriptiveness, ranging from plain zero-shot to elaborate few-shot prompts. Finally, we evaluate the ability of LLMs to quantify uncertainty via calibration error and comparison to human label variation. We find that LLMs outperform fine-tuned encoders on descriptive datasets, while calibration and F1-score generally improve with increased prescriptiveness, yet the optimal level varies.", "published": "2024-10-31 04:00:00", "id": "cd58da54-0207-48f0-b705-ba94a1687326", "source": "arxiv", "section": "computerScience"}, {"title": "CIDGMed: Causal Inference-Driven Medication Recommendation with Enhanced Dual-Granularity Learning", "link": "https://arxiv.org/abs/2403.00880", "description": "arXiv:2403.00880v2 Announce Type: replace \nAbstract: Medication recommendation aims to integrate patients' long-term health records to provide accurate and safe medication combinations for specific health states. Existing methods often fail to deeply explore the true causal relationships between diseases/procedures and medications, resulting in biased recommendations. Additionally, in medication representation learning, the relationships between information at different granularities of medications, coarse-grained (medication itself) and fine-grained (molecular level), are not effectively integrated, leading to biases in representation learning. To address these limitations, we propose the Causal Inference-driven Dual-Granularity Medication Recommendation method (CIDGMed). Our approach leverages causal inference to uncover the relationships between diseases/procedures and medications, thereby enhancing the rationality and interpretability of recommendations. By integrating coarse-grained medication effects with fine-grained molecular structure information, CIDGMed provides a comprehensive representation of medications. Additionally, we employ a bias correction model during the prediction phase to further refine recommendations, ensuring both accuracy and safety. Through extensive experiments, CIDGMed significantly outperforms current state-of-the-art models across multiple metrics, achieving a 2.54% increase in accuracy, a 3.65% reduction in side effects, and a 39.42% improvement in time efficiency. Additionally, we demonstrate the rationale of CIDGMed through a case study.", "published": "2024-10-31 04:00:00", "id": "640816cd-4df8-47c2-b296-4d7ad339258d", "source": "arxiv", "section": "computerScience"}, {"title": "GuardT2I: Defending Text-to-Image Models from Adversarial Prompts", "link": "https://arxiv.org/abs/2403.01446", "description": "arXiv:2403.01446v2 Announce Type: replace \nAbstract: Recent advancements in Text-to-Image (T2I) models have raised significant safety concerns about their potential misuse for generating inappropriate or Not-Safe-For-Work (NSFW) contents, despite existing countermeasures such as NSFW classifiers or model fine-tuning for inappropriate concept removal. Addressing this challenge, our study unveils GuardT2I, a novel moderation framework that adopts a generative approach to enhance T2I models' robustness against adversarial prompts. Instead of making a binary classification, GuardT2I utilizes a Large Language Model (LLM) to conditionally transform text guidance embeddings within the T2I models into natural language for effective adversarial prompt detection, without compromising the models' inherent performance. Our extensive experiments reveal that GuardT2I outperforms leading commercial solutions like OpenAI-Moderation and Microsoft Azure Moderator by a significant margin across diverse adversarial scenarios. Our framework is available at https://github.com/cure-lab/GuardT2I.", "published": "2024-10-31 04:00:00", "id": "42ce68ab-4370-42b5-8bca-ddcd61e51923", "source": "arxiv", "section": "computerScience"}, {"title": "Active Learning of Mealy Machines with Timers", "link": "https://arxiv.org/abs/2403.02019", "description": "arXiv:2403.02019v2 Announce Type: replace \nAbstract: We present the first algorithm for query learning of a class of Mealy machines with timers in a black-box context. Our algorithm is an extension of the L# algorithm of Vaandrager et al. to a timed setting. We rely on symbolic queries which empower us to reason on untimed executions while learning. Similarly to the algorithm for learning timed automata of Waga, these symbolic queries can be implemented using finitely many concrete queries. Experiments with a prototype implementation, written in Rust, show that our algorithm is able to efficiently learn realistic benchmarks.", "published": "2024-10-31 04:00:00", "id": "ad6ec339-0086-4c35-9bfa-24f00e04f3a2", "source": "arxiv", "section": "computerScience"}, {"title": "Differentially Private Representation Learning via Image Captioning", "link": "https://arxiv.org/abs/2403.02506", "description": "arXiv:2403.02506v2 Announce Type: replace \nAbstract: Differentially private (DP) machine learning is considered the gold-standard solution for training a model from sensitive data while still preserving privacy. However, a major barrier to achieving this ideal is its sub-optimal privacy-accuracy trade-off, which is particularly visible in DP representation learning. Specifically, it has been shown that under modest privacy budgets, most models learn representations that are not significantly better than hand-crafted features. In this work, we show that effective DP representation learning can be done via image captioning and scaling up to internet-scale multimodal datasets. Through a series of engineering tricks, we successfully train a DP image captioner (DP-Cap) on a 233M subset of LAION-2B from scratch using a reasonable amount of computation, and obtaining unprecedented high-quality image features that can be used in a variety of downstream vision and vision-language tasks. For example, under a privacy budget of $\\varepsilon=8$ for the LAION dataset, a linear classifier trained on top of learned DP-Cap features attains $65.8\\%$ accuracy on ImageNet-1K, considerably improving the previous SOTA of $56.5\\%$.", "published": "2024-10-31 04:00:00", "id": "15dfad64-fa8e-4945-81ba-d9242d1fa8b8", "source": "arxiv", "section": "computerScience"}, {"title": "CURATRON: Complete and Robust Preference Data for Rigorous Alignment of Large Language Models", "link": "https://arxiv.org/abs/2403.02745", "description": "arXiv:2403.02745v2 Announce Type: replace \nAbstract: This paper addresses the challenges of aligning large language models (LLMs) with human values via preference learning (PL), focusing on incomplete and corrupted data in preference datasets. We propose a novel method for robustly and completely recalibrating values within these datasets to enhance LLMs' resilience against the issues. In particular, we devise a guaranteed polynomial time ranking algorithm that robustifies several existing models, such as the classic Bradley-Terry-Luce (BTL) (Bradley and Terry, 1952) model and certain generalizations of it. To the best of our knowledge, our present work is the first to propose an algorithm that provably recovers an $\\epsilon$-optimal ranking with high probability while allowing as large as $O(n)$ perturbed pairwise comparison results per model response. Furthermore, we show robust recovery results in the partially observed setting. Our experiments confirm that our algorithms handle adversarial noise and unobserved comparisons well in both general and LLM preference dataset settings. This work contributes to the development and scaling of more reliable and ethically aligned AI models by equipping the dataset curation pipeline with the ability to handle missing and maliciously manipulated inputs.", "published": "2024-10-31 04:00:00", "id": "755436d2-5bd8-4092-b6a9-446ec93e7ff5", "source": "arxiv", "section": "computerScience"}, {"title": "Accelerating the convergence of Newton's method for nonlinear elliptic PDEs using Fourier neural operators", "link": "https://arxiv.org/abs/2403.03021", "description": "arXiv:2403.03021v2 Announce Type: replace \nAbstract: It is well known that Newton's method can have trouble converging if the initial guess is too far from the solution. Such a problem particularly occurs when this method is used to solve nonlinear elliptic partial differential equations (PDEs) discretized via finite differences. This work focuses on accelerating Newton's method convergence in this context. We seek to construct a mapping from the parameters of the nonlinear PDE to an approximation of its discrete solution, independently of the mesh resolution. This approximation is then used as an initial guess for Newton's method. To achieve these objectives, we elect to use a Fourier neural operator (FNO). The loss function is the sum of a data term (i.e., the comparison between known solutions and outputs of the FNO) and a physical term (i.e., the residual of the PDE discretization). Numerical results, in one and two dimensions, show that the proposed initial guess accelerates the convergence of Newton's method by a large margin compared to a naive initial guess, especially for highly nonlinear and anisotropic problems, with larger gains on coarse grids.", "published": "2024-10-31 04:00:00", "id": "d4e9af1f-1e26-4c24-9e5b-ae5a42175b82", "source": "arxiv", "section": "computerScience"}, {"title": "MamMIL: Multiple Instance Learning for Whole Slide Images with State Space Models", "link": "https://arxiv.org/abs/2403.05160", "description": "arXiv:2403.05160v3 Announce Type: replace \nAbstract: Recently, pathological diagnosis has achieved superior performance by combining deep learning models with the multiple instance learning (MIL) framework using whole slide images (WSIs). However, the giga-pixeled nature of WSIs poses a great challenge for efficient MIL. Existing studies either do not consider global dependencies among instances, or use approximations such as linear attentions to model the pair-to-pair instance interactions, which inevitably brings performance bottlenecks. To tackle this challenge, we propose a framework named MamMIL for WSI analysis by cooperating the selective structured state space model (i.e., Mamba) with MIL, enabling the modeling of global instance dependencies while maintaining linear complexity. Specifically, considering the irregularity of the tissue regions in WSIs, we represent each WSI as an undirected graph. To address the problem that Mamba can only process 1D sequences, we further propose a topology-aware scanning mechanism to serialize the WSI graphs while preserving the topological relationships among the instances. Finally, in order to further perceive the topological structures among the instances and incorporate short-range feature interactions, we propose an instance aggregation block based on graph neural networks. Experiments show that MamMIL can achieve advanced performance than the state-of-the-art frameworks. The code can be accessed at https://github.com/Vison307/MamMIL.", "published": "2024-10-31 04:00:00", "id": "27324785-6e1a-49f6-b067-5674f474e0fa", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Full Automation of Geometry Extraction for Biomechanical Analysis of Abdominal Aortic Aneurysm; Neural Network-Based versus Classical Methodologies", "link": "https://arxiv.org/abs/2403.07238", "description": "arXiv:2403.07238v2 Announce Type: replace \nAbstract: In this study, we investigated the impact of image segmentation methods on the results of stress computation in the wall of abdominal aortic aneurysms (AAAs). We compared wall stress distributions and magnitudes calculated from geometry models obtained from classical semi-automated segmentation versus automated neural network-based segmentation. 16 different AAA contrast-enhanced computed tomography (CT) images were semi-automatically segmented by an analyst, taking between 15 and 40 minutes of human effort per patient, depending on image quality. The same images were automatically segmented using PRAEVAorta commercial software by NUREA (https://www.nurea-soft.com/), developed based on artificial intelligence (AI) algorithms, and automatically post-processed with an in-house MATLAB code, requiring only 1-2 minutes of computer time per patient. Aneurysm wall stress calculations, automatically performed using the BioPARR software (https://bioparr.mech.uwa.edu.au/), revealed that, compared to the classical semi-automated segmentation, the automatic neural network-based segmentation leads to equivalent stress distributions, and slightly higher peak and 99th percentile maximum principal stress values. This difference is due to consistently larger lumen surface areas in automatically segmented models as compared to classical semi-automated segmentations, resulting in greater total pressure load on the wall. However, our statistical analysis indicated that the differences in AAA wall stress obtained using the two segmentation methods are not statistically significant and fall within the typical range of inter-analyst and intra-analyst variability, justifying the use of AI-based automatic segmentation in a fully automated AAA stress computation pipeline.", "published": "2024-10-31 04:00:00", "id": "c3b1f96b-2720-495e-97df-5085b28f6e55", "source": "arxiv", "section": "computerScience"}, {"title": "Solving Partial Differential Equations Using Artificial Neural Networks", "link": "https://arxiv.org/abs/2403.09001", "description": "arXiv:2403.09001v2 Announce Type: replace \nAbstract: Partial differential equations have a wide range of applications in modeling multiple physical, biological, or social phenomena. Therefore, we need to approximate the solutions of these equations in computationally feasible terms. Nowadays, among the most popular numerical methods for solving partial differential equations in engineering, we encounter the finite difference and finite element methods. An alternative numerical method that has recently gained popularity for numerically solving partial differential equations is the use of artificial neural networks.\n  Artificial neural networks, or neural networks for short, are mathematical structures with universal approximation properties. In addition, thanks to the extraordinary computational development of the last decade, neural networks have become accessible and powerful numerical methods for engineers and researchers. For example, imaging and language processing are applications of neural networks today that show sublime performance inconceivable years ago.\n  This dissertation contributes to the numerical solution of partial differential equations using neural networks with the following two-fold objective: investigate the behavior of neural networks as approximators of solutions of partial differential equations and propose neural-network-based methods for frameworks that are hardly addressable via traditional numerical methods.\n  As novel neural-network-based proposals, we first present a method inspired by the finite element method when applying mesh refinements to solve parametric problems. Secondly, we propose a general residual minimization scheme based on a generalized version of the Ritz method. Finally, we develop a memory-based strategy to overcome a usual numerical integration limitation when using neural networks to solve partial differential equations.", "published": "2024-10-31 04:00:00", "id": "4723e334-88fb-4951-abdf-5dc615ab0970", "source": "arxiv", "section": "computerScience"}, {"title": "Robustness of data-driven approaches in limited angle tomography", "link": "https://arxiv.org/abs/2403.11350", "description": "arXiv:2403.11350v2 Announce Type: replace \nAbstract: The limited angle Radon transform is notoriously difficult to invert due to its ill-posedness. In this work, we give a mathematical explanation that data-driven approaches can stably reconstruct more information compared to traditional methods like filtered backprojection. In addition, we use experiments based on the U-Net neural network to validate our theory.", "published": "2024-10-31 04:00:00", "id": "6e990a18-fb07-4b7a-9dfb-08153f40e874", "source": "arxiv", "section": "computerScience"}, {"title": "First-order factors of linear Mahler operators", "link": "https://arxiv.org/abs/2403.11545", "description": "arXiv:2403.11545v2 Announce Type: replace \nAbstract: We develop and compare two algorithms for computing first-order right-hand factors in the ring of linear Mahler operators$\\ell_r M^r + \\dots + \\ell_1 M + \\ell_0$where $\\ell_0, \\dots, \\ell_r$ are polynomials in~$x$ and $Mx = x^b M$ for some integer $b \\geq 2$. In other words, we give algorithms for finding all formal infinite product solutions of linear functional equations$\\ell_r(x) f(x^{b^r}) + \\dots + \\ell_1(x) f(x^b) + \\ell_0(x) f(x) = 0$. The first of our algorithms is adapted from Petkov\\v{s}ek's classical algorithm forthe analogous problem in the case of linear recurrences. The second one proceeds by computing a basis of generalized power series solutions of the functional equation and by using Hermite-Pad{\\'e} approximants to detect those linear combinations of the solutions that correspond to first-order factors. We present implementations of both algorithms and discuss their use in combination with criteria from the literature to prove the differential transcendence of power series solutions of Mahler equations.", "published": "2024-10-31 04:00:00", "id": "0c50bcf4-5916-437e-94ac-a67f2a289f38", "source": "arxiv", "section": "computerScience"}, {"title": "SpatialPIN: Enhancing Spatial Reasoning Capabilities of Vision-Language Models through Prompting and Interacting 3D Priors", "link": "https://arxiv.org/abs/2403.13438", "description": "arXiv:2403.13438v5 Announce Type: replace \nAbstract: Current state-of-the-art spatial reasoning-enhanced VLMs are trained to excel at spatial visual question answering (VQA). However, we believe that higher-level 3D-aware tasks, such as articulating dynamic scene changes and motion planning, require a fundamental and explicit 3D understanding beyond current spatial VQA datasets. In this work, we present SpatialPIN, a framework designed to enhance the spatial reasoning capabilities of VLMs through prompting and interacting with priors from multiple 3D foundation models in a zero-shot, training-free manner. Extensive experiments demonstrate that our spatial reasoning-imbued VLM performs well on various forms of spatial VQA and can extend to help in various downstream robotics tasks such as pick and stack and trajectory planning.", "published": "2024-10-31 04:00:00", "id": "b4ec5fb3-e67d-48e6-b698-1791c215b415", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Neural Network Representations with Prior Knowledge-Based Normalization", "link": "https://arxiv.org/abs/2403.16798", "description": "arXiv:2403.16798v3 Announce Type: replace \nAbstract: Deep learning models face persistent challenges in training, particularly due to internal covariate shift and label shift. While single-mode normalization methods like Batch Normalization partially address these issues, they are constrained by batch size dependencies and limiting distributional assumptions. Multi-mode normalization techniques mitigate these limitations but struggle with computational demands when handling diverse Gaussian distributions. In this paper, we introduce a new approach to multi-mode normalization that leverages prior knowledge to improve neural network representations. Our method organizes data into predefined structures, or \"contexts\", prior to training and normalizes based on these contexts, with two variants: Context Normalization (CN) and Context Normalization - Extended (CN-X). When contexts are unavailable, we introduce Adaptive Context Normalization (ACN), which dynamically builds contexts in the latent space during training. Across tasks in image classification, domain adaptation, and image generation, our methods demonstrate superior convergence and performance.", "published": "2024-10-31 04:00:00", "id": "aed9c233-fc5a-476d-83bc-c318e4b6a499", "source": "arxiv", "section": "computerScience"}, {"title": "Is Your LiDAR Placement Optimized for 3D Scene Understanding?", "link": "https://arxiv.org/abs/2403.17009", "description": "arXiv:2403.17009v2 Announce Type: replace \nAbstract: The reliability of driving perception systems under unprecedented conditions is crucial for practical usage. Latest advancements have prompted increasing interest in multi-LiDAR perception. However, prevailing driving datasets predominantly utilize single-LiDAR systems and collect data devoid of adverse conditions, failing to capture the complexities of real-world environments accurately. Addressing these gaps, we proposed Place3D, a full-cycle pipeline that encompasses LiDAR placement optimization, data generation, and downstream evaluations. Our framework makes three appealing contributions. 1) To identify the most effective configurations for multi-LiDAR systems, we introduce the Surrogate Metric of the Semantic Occupancy Grids (M-SOG) to evaluate LiDAR placement quality. 2) Leveraging the M-SOG metric, we propose a novel optimization strategy to refine multi-LiDAR placements. 3) Centered around the theme of multi-condition multi-LiDAR perception, we collect a 280,000-frame dataset from both clean and adverse conditions. Extensive experiments demonstrate that LiDAR placements optimized using our approach outperform various baselines. We showcase exceptional results in both LiDAR semantic segmentation and 3D object detection tasks, under diverse weather and sensor failure conditions.", "published": "2024-10-31 04:00:00", "id": "7ac53805-f6c1-445e-9ba6-423f95bcc9a2", "source": "arxiv", "section": "computerScience"}, {"title": "Evolution-based Feature Selection for Predicting Dissolved Oxygen Concentrations in Lakes", "link": "https://arxiv.org/abs/2403.18923", "description": "arXiv:2403.18923v2 Announce Type: replace \nAbstract: Accurate prediction of dissolved oxygen (DO) concentrations in lakes requires a comprehensive study of phenological patterns across ecosystems, highlighting the need for precise selection of interactions amongst external factors and internal physical-chemical-biological variables. This paper presents the Multi-population Cognitive Evolutionary Search (MCES), a novel evolutionary algorithm for complex feature interaction selection problems. MCES allows models within every population to evolve adaptively, selecting relevant feature interactions for different lake types and tasks. Evaluated on diverse lakes in the Midwestern USA, MCES not only consistently produces accurate predictions with few observed labels but also, through gene maps of models, reveals sophisticated phenological patterns of different lake types, embodying the innovative concept of \"AI from nature, for nature\".", "published": "2024-10-31 04:00:00", "id": "78cc4d8a-7975-4457-8f85-daa0d67d6cf4", "source": "arxiv", "section": "computerScience"}, {"title": "Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods", "link": "https://arxiv.org/abs/2404.00282", "description": "arXiv:2404.00282v3 Announce Type: replace \nAbstract: With extensive pre-trained knowledge and high-level general capabilities, large language models (LLMs) emerge as a promising avenue to augment reinforcement learning (RL) in aspects such as multi-task learning, sample efficiency, and high-level task planning. In this survey, we provide a comprehensive review of the existing literature in LLM-enhanced RL and summarize its characteristics compared to conventional RL methods, aiming to clarify the research scope and directions for future studies. Utilizing the classical agent-environment interaction paradigm, we propose a structured taxonomy to systematically categorize LLMs' functionalities in RL, including four roles: information processor, reward designer, decision-maker, and generator. For each role, we summarize the methodologies, analyze the specific RL challenges that are mitigated, and provide insights into future directions. Lastly, a comparative analysis of each role, potential applications, prospective opportunities, and challenges of the LLM-enhanced RL are discussed. By proposing this taxonomy, we aim to provide a framework for researchers to effectively leverage LLMs in the RL field, potentially accelerating RL applications in complex applications such as robotics, autonomous driving, and energy systems.", "published": "2024-10-31 04:00:00", "id": "b9c0de05-be17-4d8b-8609-5e33a595f21a", "source": "arxiv", "section": "computerScience"}, {"title": "Interpretable Multi-View Clustering Based on Anchor Graph Tensor Factorization", "link": "https://arxiv.org/abs/2404.00883", "description": "arXiv:2404.00883v2 Announce Type: replace \nAbstract: The clustering method based on the anchor graph has gained significant attention due to its exceptional clustering performance and ability to process large-scale data. One common approach is to learn bipartite graphs with K-connected components, helping avoid the need for post-processing. However, this method has strict parameter requirements and may not always get K-connected components. To address this issue, an alternative approach is to directly obtain the cluster label matrix by performing non-negative matrix factorization (NMF) on the anchor graph. Nevertheless, existing multi-view clustering methods based on anchor graph factorization lack adequate cluster interpretability for the decomposed matrix and often overlook the inter-view information. We address this limitation by using non-negative tensor factorization to decompose an anchor graph tensor that combines anchor graphs from multiple views. This approach allows us to consider inter-view information comprehensively. The decomposed tensors, namely the sample indicator tensor and the anchor indicator tensor, enhance the interpretability of the factorization. Extensive experiments validate the effectiveness of this method.", "published": "2024-10-31 04:00:00", "id": "214ff36a-0c23-41a9-9870-a15030676f97", "source": "arxiv", "section": "computerScience"}, {"title": "A novel seamless magnetic-based actuating mechanism for end-effector-based robotic rehabilitation platforms", "link": "https://arxiv.org/abs/2404.01441", "description": "arXiv:2404.01441v2 Announce Type: replace \nAbstract: Rehabilitation robotics continues to confront substantial challenges, particularly in achieving smooth, safe, and intuitive human-robot interactions for upper limb motor training. Many current systems depend on complex mechanical designs, direct physical contact, and multiple sensors, which not only elevate costs but also reduce accessibility. Additionally, delivering seamless weight compensation and precise motion tracking remains a highly complex undertaking. To overcome these obstacles, we have developed a novel magnetic-based actuation mechanism for end-effector robotic rehabilitation. This innovative approach enables smooth, non-contact force transmission, significantly enhancing patient safety and comfort during upper limb training. To ensure consistent performance, we integrated an Extended Kalman Filter (EKF) alongside a controller for real-time position tracking, allowing the system to maintain high accuracy or recover even in the event of sensor malfunction or failure. In a user study with 12 participants, 75% rated the system highly for its smoothness, while 66.7% commended its safety and effective weight compensation. The EKF demonstrated precise tracking performance, with root mean square error (RMSE) values remaining within acceptable limits (under 2 cm). By combining magnetic actuation with advanced closed-loop control algorithms, this system marks a significant advancement in the field of upper limb rehabilitation robotics.", "published": "2024-10-31 04:00:00", "id": "86836b90-5ffa-4968-bc7c-c4a07e02a10b", "source": "arxiv", "section": "computerScience"}, {"title": "Spectral Graph Pruning Against Over-Squashing and Over-Smoothing", "link": "https://arxiv.org/abs/2404.04612", "description": "arXiv:2404.04612v2 Announce Type: replace \nAbstract: Message Passing Graph Neural Networks are known to suffer from two problems that are sometimes believed to be diametrically opposed: over-squashing and over-smoothing. The former results from topological bottlenecks that hamper the information flow from distant nodes and are mitigated by spectral gap maximization, primarily, by means of edge additions. However, such additions often promote over-smoothing that renders nodes of different classes less distinguishable. Inspired by the Braess phenomenon, we argue that deleting edges can address over-squashing and over-smoothing simultaneously. This insight explains how edge deletions can improve generalization, thus connecting spectral gap optimization to a seemingly disconnected objective of reducing computational resources by pruning graphs for lottery tickets. To this end, we propose a more effective spectral gap optimization framework to add or delete edges and demonstrate its effectiveness on large heterophilic datasets.", "published": "2024-10-31 04:00:00", "id": "172a646b-6f8c-4001-ae69-7916c46685d1", "source": "arxiv", "section": "computerScience"}, {"title": "Computation and Critical Transitions of Rate-Distortion-Perception Functions With Wasserstein Barycenter", "link": "https://arxiv.org/abs/2404.04681", "description": "arXiv:2404.04681v3 Announce Type: replace \nAbstract: The information rate-distortion-perception (RDP) function characterizes the three-way trade-off between description rate, average distortion, and perceptual quality measured by discrepancy between probability distributions and has been applied to emerging areas in communications empowered by generative modeling. We study several variants of the RDP functions through the lens of optimal transport to characterize their critical transitions. By transforming the information RDP function into a Wasserstein Barycenter problem, we identify the critical transitions when one of the constraints becomes inactive. Further, the non-strictly convexity brought by the perceptual constraint can be regularized by an entropy regularization term. We prove that the entropy regularized model converges to the original problem and propose an alternating iteration method based on the Sinkhorn algorithm to numerically solve the regularized optimization problem. In many practical scenarios, the computation of the Distortion-Rate-Perception (DRP) function offers a solution to minimize distortion and perceptual discrepancy under rate constraints. However, the interchange of the rate objective and the distortion constraint significantly amplifies the complexity. The proposed method effectively addresses this complexity, providing an efficient solution for DRP functions. Using our numerical method, we propose a reverse data hiding scheme that imperceptibly embeds a secret message into an image, ensuring perceptual fidelity and achieving a significant improvement in the perceptual quality of the stego image compared to traditional methods under the same embedding rate. Our theoretical results and numerical method lay an attractive foundation for steganographic communications with perceptual quality constraints.", "published": "2024-10-31 04:00:00", "id": "47f9c824-7cec-40e0-80eb-f7e65f457156", "source": "arxiv", "section": "computerScience"}, {"title": "A Lightweight Measure of Classification Difficulty from Application Dataset Characteristics", "link": "https://arxiv.org/abs/2404.05981", "description": "arXiv:2404.05981v2 Announce Type: replace \nAbstract: Although accuracy and computation benchmarks are widely available to help choose among neural network models, these are usually trained on datasets with many classes, and do not give a good idea of performance for few (< 10) classes. The conventional procedure to predict performance involves repeated training and testing on the different models and dataset variations. We propose an efficient cosine similarity-based classification difficulty measure S that is calculated from the number of classes and intra- and inter-class similarity metrics of the dataset. After a single stage of training and testing per model family, relative performance for different datasets and models of the same family can be predicted by comparing difficulty measures - without further training and testing. Our proposed method is verified by extensive experiments on 8 CNN and ViT models and 7 datasets. Results show that S is highly correlated to model accuracy with correlation coefficient |r| = 0.796, outperforming the baseline Euclidean distance at |r| = 0.66. We show how a practitioner can use this measure to help select an efficient model 6 to 29x faster than through repeated training and testing. We also describe using the measure for an industrial application in which options are identified to select a model 42% smaller than the baseline YOLOv5-nano model, and if class merging from 3 to 2 classes meets requirements, 85% smaller.", "published": "2024-10-31 04:00:00", "id": "164e6dcd-5cce-43b0-bf1f-693d0cae97c2", "source": "arxiv", "section": "computerScience"}, {"title": "Late Breaking Results: Fast System Technology Co-Optimization Framework for Emerging Technology Based on Graph Neural Networks", "link": "https://arxiv.org/abs/2404.06939", "description": "arXiv:2404.06939v4 Announce Type: replace \nAbstract: This paper proposes a fast system technology co-optimization (STCO) framework that optimizes power, performance, and area (PPA) for next-generation IC design, addressing the challenges and opportunities presented by novel materials and device architectures. We focus on accelerating the technology level of STCO using AI techniques, by employing graph neural network (GNN)-based approaches for both TCAD simulation and cell library characterization, which are interconnected through a unified compact model, collectively achieving over a 100X speedup over traditional methods. These advancements enable comprehensive STCO iterations with runtime speedups ranging from 1.9X to 14.1X and supports both emerging and traditional technologies.", "published": "2024-10-31 04:00:00", "id": "de4d1016-d2bc-47c1-85a3-d59a93d52eff", "source": "arxiv", "section": "computerScience"}, {"title": "OTTER: Effortless Label Distribution Adaptation of Zero-shot Models", "link": "https://arxiv.org/abs/2404.08461", "description": "arXiv:2404.08461v2 Announce Type: replace \nAbstract: Popular zero-shot models suffer due to artifacts inherited from pretraining. One particularly detrimental issue, caused by unbalanced web-scale pretraining data, is mismatched label distribution. Existing approaches that seek to repair the label distribution are not suitable in zero-shot settings, as they have mismatching requirements, such as needing access to labeled downstream task data or knowledge of the true label balance in the pretraining distribution. We sidestep these challenges and introduce a simple and lightweight approach to adjust pretrained model predictions via optimal transport. Our technique requires only an estimate of the label distribution of a downstream task. Theoretically, we characterize the improvement produced by our procedure under certain mild conditions and provide bounds on the error caused by misspecification. Empirically, we validate our method in a wide array of zero-shot image and text classification tasks, improving accuracy by 4.8% and 15.9% on average, and beating baselines like prior matching -- often by significant margins -- in 17 out of 21 datasets.", "published": "2024-10-31 04:00:00", "id": "ffc82b2a-c452-456d-9173-cce4c284ff4c", "source": "arxiv", "section": "computerScience"}, {"title": "FusionPortableV2: A Unified Multi-Sensor Dataset for Generalized SLAM Across Diverse Platforms and Scalable Environments", "link": "https://arxiv.org/abs/2404.08563", "description": "arXiv:2404.08563v2 Announce Type: replace \nAbstract: Simultaneous Localization and Mapping (SLAM) technology has been widely applied in various robotic scenarios, from rescue operations to autonomous driving. However, the generalization of SLAM algorithms remains a significant challenge, as current datasets often lack scalability in terms of platforms and environments. To address this limitation, we present FusionPortableV2, a multi-sensor SLAM dataset featuring sensor diversity, varied motion patterns, and a wide range of environmental scenarios. Our dataset comprises $27$ sequences, spanning over $2.5$ hours and collected from four distinct platforms: a handheld suite, a legged robots, a unmanned ground vehicle (UGV), and a vehicle. These sequences cover diverse settings, including buildings, campuses, and urban areas, with a total length of $38.7km$. Additionally, the dataset includes ground-truth (GT) trajectories and RGB point cloud maps covering approximately $0.3km^2$. To validate the utility of our dataset in advancing SLAM research, we assess several state-of-the-art (SOTA) SLAM algorithms. Furthermore, we demonstrate the dataset's broad application beyond traditional SLAM tasks by investigating its potential for monocular depth estimation. The complete dataset, including sensor data, GT, and calibration details, is accessible at https://fusionportable.github.io/dataset/fusionportable_v2.", "published": "2024-10-31 04:00:00", "id": "9942b19f-bd31-488d-8f3a-950864875f5d", "source": "arxiv", "section": "computerScience"}, {"title": "Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers", "link": "https://arxiv.org/abs/2404.09326", "description": "arXiv:2404.09326v3 Announce Type: replace \nAbstract: Few-shot knowledge distillation recently emerged as a viable approach to harness the knowledge of large-scale pre-trained models, using limited data and computational resources. In this paper, we propose a novel few-shot feature distillation approach for vision transformers. Our approach is based on two key steps. Leveraging the fact that vision transformers have a consistent depth-wise structure, we first copy the weights from intermittent layers of existing pre-trained vision transformers (teachers) into shallower architectures (students), where the intermittence factor controls the complexity of the student transformer with respect to its teacher. Next, we employ an enhanced version of Low-Rank Adaptation (LoRA) to distill knowledge into the student in a few-shot scenario, aiming to recover the information processing carried out by the skipped teacher layers. We present comprehensive experiments with supervised and self-supervised transformers as teachers, on six data sets from various domains (natural, medical and satellite images) and tasks (classification and segmentation). The empirical results confirm the superiority of our approach over state-of-the-art competitors. Moreover, the ablation results demonstrate the usefulness of each component of the proposed pipeline. We release our code at https://github.com/dianagrigore/WeCoLoRA.", "published": "2024-10-31 04:00:00", "id": "97e09be4-86c7-41f4-a703-f6d947e97c60", "source": "arxiv", "section": "computerScience"}, {"title": "Exploring the Role of Token in Transformer-based Time Series Forecasting", "link": "https://arxiv.org/abs/2404.10337", "description": "arXiv:2404.10337v3 Announce Type: replace \nAbstract: Transformer-based methods are a mainstream approach for solving time series forecasting (TSF). These methods use temporal or variable tokens from observable data to make predictions. However, most focus on optimizing the model structure, with few studies paying attention to the role of tokens for predictions. The role is crucial since a model that distinguishes useful tokens from useless ones will predict more effectively. In this paper, we explore this issue. Through theoretical analyses, we find that the gradients mainly depend on tokens that contribute to the predicted series, called positive tokens. Based on this finding, we explore what helps models select these positive tokens. Through a series of experiments, we obtain three observations: i) positional encoding (PE) helps the model identify positive tokens; ii) as the network depth increases, the PE information gradually weakens, affecting the model's ability to identify positive tokens in deeper layers; iii) both enhancing PE in the deeper layers and using semantic-based PE can improve the model's ability to identify positive tokens, thus boosting performance. Inspired by these findings, we design temporal positional encoding (T-PE) for temporal tokens and variable positional encoding (V-PE) for variable tokens. To utilize T-PE and V-PE, we propose T2B-PE, a Transformer-based dual-branch framework. Extensive experiments demonstrate that T2B-PE has superior robustness and effectiveness.", "published": "2024-10-31 04:00:00", "id": "c9ebea9d-a89c-4b56-81c0-4044c3543e4f", "source": "arxiv", "section": "computerScience"}, {"title": "Non-Invasive Suicide Risk Prediction Through Speech Analysis", "link": "https://arxiv.org/abs/2404.12132", "description": "arXiv:2404.12132v3 Announce Type: replace \nAbstract: The delayed access to specialized psychiatric assessments and care for patients at risk of suicidal tendencies in emergency departments creates a notable gap in timely intervention, hindering the provision of adequate mental health support during critical situations. To address this, we present a non-invasive, speech-based approach for automatic suicide risk assessment. For our study, we collected a novel speech recording dataset from $20$ patients. We extract three sets of features, including wav2vec, interpretable speech and acoustic features, and deep learning-based spectral representations. We proceed by conducting a binary classification to assess suicide risk in a leave-one-subject-out fashion. Our most effective speech model achieves a balanced accuracy of $66.2\\,\\%$. Moreover, we show that integrating our speech model with a series of patients' metadata, such as the history of suicide attempts or access to firearms, improves the overall result. The metadata integration yields a balanced accuracy of $94.4\\,\\%$, marking an absolute improvement of $28.2\\,\\%$, demonstrating the efficacy of our proposed approaches for automatic suicide risk assessment in emergency medicine.", "published": "2024-10-31 04:00:00", "id": "5e9010d7-3b86-45a1-9671-e1c995231aa6", "source": "arxiv", "section": "computerScience"}, {"title": "High-fidelity Endoscopic Image Synthesis by Utilizing Depth-guided Neural Surfaces", "link": "https://arxiv.org/abs/2404.13437", "description": "arXiv:2404.13437v2 Announce Type: replace \nAbstract: In surgical oncology, screening colonoscopy plays a pivotal role in providing diagnostic assistance, such as biopsy, and facilitating surgical navigation, particularly in polyp detection. Computer-assisted endoscopic surgery has recently gained attention and amalgamated various 3D computer vision techniques, including camera localization, depth estimation, surface reconstruction, etc. Neural Radiance Fields (NeRFs) and Neural Implicit Surfaces (NeuS) have emerged as promising methodologies for deriving accurate 3D surface models from sets of registered images, addressing the limitations of existing colon reconstruction approaches stemming from constrained camera movement.\n  However, the inadequate tissue texture representation and confused scale problem in monocular colonoscopic image reconstruction still impede the progress of the final rendering results. In this paper, we introduce a novel method for colon section reconstruction by leveraging NeuS applied to endoscopic images, supplemented by a single frame of depth map. Notably, we pioneered the exploration of utilizing only one frame depth map in photorealistic reconstruction and neural rendering applications while this single depth map can be easily obtainable from other monocular depth estimation networks with an object scale. Through rigorous experimentation and validation on phantom imagery, our approach demonstrates exceptional accuracy in completely rendering colon sections, even capturing unseen portions of the surface. This breakthrough opens avenues for achieving stable and consistently scaled reconstructions, promising enhanced quality in cancer screening procedures and treatment interventions.", "published": "2024-10-31 04:00:00", "id": "1492a789-deba-4ca0-9718-f6f43b74ca29", "source": "arxiv", "section": "computerScience"}, {"title": "MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making", "link": "https://arxiv.org/abs/2404.15155", "description": "arXiv:2404.15155v3 Announce Type: replace \nAbstract: Foundation models are becoming valuable tools in medicine. Yet despite their promise, the best way to leverage Large Language Models (LLMs) in complex medical tasks remains an open question. We introduce a novel multi-agent framework, named Medical Decision-making Agents (MDAgents) that helps address this gap by automatically assigning a collaboration structure to a team of LLMs. The assigned solo or group collaboration structure is tailored to the medical task at hand, emulating real-world medical decision-making processes adapted to tasks of varying complexities. We evaluate our framework and baseline methods using state-of-the-art LLMs across a suite of real-world medical knowledge and medical diagnosis benchmarks, including a comparison of LLMs' medical complexity classification against human physicians. MDAgents achieved the best performance in seven out of ten benchmarks on tasks requiring an understanding of medical knowledge and multi-modal reasoning, showing a significant improvement of up to 4.2% (p < 0.05) compared to previous methods' best performances. Ablation studies reveal that MDAgents effectively determines medical complexity to optimize for efficiency and accuracy across diverse medical tasks. Notably, the combination of moderator review and external medical knowledge in group collaboration resulted in an average accuracy improvement of 11.8%. Our code can be found at https://github.com/mitmedialab/MDAgents.", "published": "2024-10-31 04:00:00", "id": "d7f916a6-379d-444f-b9a5-74aa1f4c913b", "source": "arxiv", "section": "computerScience"}, {"title": "Point-JEPA: A Joint Embedding Predictive Architecture for Self-Supervised Learning on Point Cloud", "link": "https://arxiv.org/abs/2404.16432", "description": "arXiv:2404.16432v4 Announce Type: replace \nAbstract: Recent advancements in self-supervised learning in the point cloud domain have demonstrated significant potential. However, these methods often suffer from drawbacks, including lengthy pre-training time, the necessity of reconstruction in the input space, or the necessity of additional modalities. In order to address these issues, we introduce Point-JEPA, a joint embedding predictive architecture designed specifically for point cloud data. To this end, we introduce a sequencer that orders point cloud tokens to efficiently compute and utilize tokens proximity based on their indices during target and context selection. The sequencer also allows shared computations of the tokens proximity between context and target selection, further improving the efficiency. Experimentally, our method achieves competitive results with state-of-the-art methods while avoiding the reconstruction in the input space or additional modality.", "published": "2024-10-31 04:00:00", "id": "10739b35-ebef-4c03-b2ab-f735232f024e", "source": "arxiv", "section": "computerScience"}, {"title": "Dynamical Mode Recognition of Coupled Flame Oscillators by Supervised and Unsupervised Learning Approaches", "link": "https://arxiv.org/abs/2404.17801", "description": "arXiv:2404.17801v2 Announce Type: replace \nAbstract: Combustion instability in gas turbines and rocket engines, as one of the most challenging problems in combustion research, arises from the complex interactions among flames, which are also influenced by chemical reactions, heat and mass transfer, and acoustics. Identifying and understanding combustion instability is essential to ensure the safe and reliable operation of many combustion systems, where exploring and classifying the dynamical behaviors of complex flame systems is a core take. To facilitate fundamental studies, the present work concerns dynamical mode recognition of coupled flame oscillators made of flickering buoyant diffusion flames, which have gained increasing attention in recent years but are not sufficiently understood. The time series data of flame oscillators are generated by fully validated reacting flow simulations. Due to limitations of expertise-based models, a data-driven approach is adopted. In this study, a nonlinear dimensional reduction model of variational autoencoder (VAE) is used to project the simulation data onto a 2-dimensional latent space. Based on the phase trajectories in latent space, both supervised and unsupervised classifiers are proposed for datasets with well known labeling and without, respectively. For labeled datasets, we establish the Wasserstein-distance-based classifier (WDC) for mode recognition; for unlabeled datasets, we develop a novel unsupervised classifier (GMM-DTWC) combining dynamic time warping (DTW) and Gaussian mixture model (GMM). Through comparing with conventional approaches for dimensionality reduction and classification, the proposed supervised and unsupervised VAE-based approaches exhibit a prominent performance for distinguishing dynamical modes, implying their potential extension to dynamical mode recognition of complex combustion problems.", "published": "2024-10-31 04:00:00", "id": "377c6e56-c7c3-4b4b-977d-b1f508e6eafa", "source": "arxiv", "section": "computerScience"}, {"title": "Estimation of uncertainties in the density driven flow in fractured porous media using MLMC", "link": "https://arxiv.org/abs/2404.18003", "description": "arXiv:2404.18003v3 Announce Type: replace \nAbstract: We use the Multi Level Monte Carlo method to estimate uncertainties in a Henry-like salt water intrusion problem with a fracture. The flow is induced by the variation of the density of the fluid phase, which depends on the mass fraction of salt. We assume that the fracture has a known fixed location but an uncertain aperture. Other input uncertainties are the porosity and permeability fields and the recharge. In our setting, porosity and permeability vary spatially and recharge is time-dependent. For each realisation of these uncertain parameters, the evolution of the mass fraction and pressure fields is modelled by a system of non-linear and time-dependent PDEs with a jump of the solution at the fracture. The uncertainties propagate into the distribution of the salt concentration, which is an important characteristic of the quality of water resources. We show that the multilevel Monte Carlo (MLMC) method is able to reduce the overall computational cost compared to classical Monte Carlo methods. This is achieved by balancing discretisation and statistical errors. Multiple scenarios are evaluated at different spatial and temporal mesh levels. The deterministic solver ug4 is run in parallel to calculate all stochastic scenarios.", "published": "2024-10-31 04:00:00", "id": "66535c48-9075-4926-b5bd-d6d41040114b", "source": "arxiv", "section": "computerScience"}, {"title": "Long-Term Human Trajectory Prediction using 3D Dynamic Scene Graphs", "link": "https://arxiv.org/abs/2405.00552", "description": "arXiv:2405.00552v4 Announce Type: replace \nAbstract: We present a novel approach for long-term human trajectory prediction in indoor human-centric environments, which is essential for long-horizon robot planning in these environments. State-of-the-art human trajectory prediction methods are limited by their focus on collision avoidance and short-term planning, and their inability to model complex interactions of humans with the environment. In contrast, our approach overcomes these limitations by predicting sequences of human interactions with the environment and using this information to guide trajectory predictions over a horizon of up to 60s. We leverage Large Language Models (LLMs) to predict interactions with the environment by conditioning the LLM prediction on rich contextual information about the scene. This information is given as a 3D Dynamic Scene Graph that encodes the geometry, semantics, and traversability of the environment into a hierarchical representation. We then ground these interaction sequences into multi-modal spatio-temporal distributions over human positions using a probabilistic approach based on continuous-time Markov Chains. To evaluate our approach, we introduce a new semi-synthetic dataset of long-term human trajectories in complex indoor environments, which also includes annotations of human-object interactions. We show in thorough experimental evaluations that our approach achieves a 54% lower average negative log-likelihood and a 26.5% lower Best-of-20 displacement error compared to the best non-privileged (i.e., evaluated in a zero-shot fashion on the dataset) baselines for a time horizon of 60s.", "published": "2024-10-31 04:00:00", "id": "0d1b96fd-5ab7-42fb-9f1c-b4580248932c", "source": "arxiv", "section": "computerScience"}, {"title": "SHED: Shapley-Based Automated Dataset Refinement for Instruction Fine-Tuning", "link": "https://arxiv.org/abs/2405.00705", "description": "arXiv:2405.00705v2 Announce Type: replace \nAbstract: The pre-trained Large Language Models (LLMs) can be adapted for many downstream tasks and tailored to align with human preferences through fine-tuning. Recent studies have discovered that LLMs can achieve desirable performance with only a small amount of high-quality data, suggesting that a large amount of the data in these extensive datasets is redundant or even harmful. Identifying high-quality data from vast datasets to curate small yet effective datasets has emerged as a critical challenge. In this paper, we introduce SHED, an automated dataset refinement framework based on Shapley value for instruction fine-tuning. SHED eliminates the need for human intervention or the use of commercial LLMs. Moreover, the datasets curated through SHED exhibit transferability, indicating they can be reused across different LLMs with consistently high performance. We conduct extensive experiments to evaluate the datasets curated by SHED. The results demonstrate SHED's superiority over state-of-the-art methods across various tasks and LLMs; notably, datasets comprising only 10% of the original data selected by SHED achieve performance comparable to or surpassing that of the full datasets.", "published": "2024-10-31 04:00:00", "id": "072561ee-9169-445c-a587-3c4062cf9315", "source": "arxiv", "section": "computerScience"}, {"title": "Designing Algorithmic Recommendations to Achieve Human-AI Complementarity", "link": "https://arxiv.org/abs/2405.01484", "description": "arXiv:2405.01484v2 Announce Type: replace \nAbstract: Algorithms frequently assist, rather than replace, human decision-makers. However, the design and analysis of algorithms often focus on predicting outcomes and do not explicitly model their effect on human decisions. This discrepancy between the design and role of algorithmic assistants becomes particularly concerning in light of empirical evidence that suggests that algorithmic assistants again and again fail to improve human decisions. In this article, we formalize the design of recommendation algorithms that assist human decision-makers without making restrictive ex-ante assumptions about how recommendations affect decisions. We formulate an algorithmic-design problem that leverages the potential-outcomes framework from causal inference to model the effect of recommendations on a human decision-maker's binary treatment choice. Within this model, we introduce a monotonicity assumption that leads to an intuitive classification of human responses to the algorithm. Under this assumption, we can express the human's response to algorithmic recommendations in terms of their compliance with the algorithm and the active decision they would take if the algorithm sends no recommendation. We showcase the utility of our framework using an online experiment that simulates a hiring task. We argue that our approach can make sense of the relative performance of different recommendation algorithms in the experiment and can help design solutions that realize human-AI complementarity. Finally, we leverage our approach to derive minimax optimal recommendation algorithms that can be implemented with machine learning using limited training data.", "published": "2024-10-31 04:00:00", "id": "9d689220-031f-4b25-9c38-33ab68610268", "source": "arxiv", "section": "computerScience"}, {"title": "Advanced Detection of Source Code Clones via an Ensemble of Unsupervised Similarity Measures", "link": "https://arxiv.org/abs/2405.02095", "description": "arXiv:2405.02095v2 Announce Type: replace \nAbstract: The capability of accurately determining code similarity is crucial in many tasks related to software development. For example, it might be essential to identify code duplicates for performing software maintenance. This research introduces a novel ensemble learning approach for code similarity assessment, combining the strengths of multiple unsupervised similarity measures. The key idea is that the strengths of a diverse set of similarity measures can complement each other and mitigate individual weaknesses, leading to improved performance. Preliminary results show that while Transformers-based CodeBERT and its variant GraphCodeBERT are undoubtedly the best option in the presence of abundant training data, in the case of specific small datasets (up to 500 samples), our ensemble achieves similar results, without prejudice to the interpretability of the resulting solution, and with a much lower associated carbon footprint due to training. The source code of this novel approach can be downloaded from https://github.com/jorge-martinez-gil/ensemble-codesim.", "published": "2024-10-31 04:00:00", "id": "ddf2bc8c-7ff9-4a2d-9a6f-6437ff3efc06", "source": "arxiv", "section": "computerScience"}, {"title": "U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers", "link": "https://arxiv.org/abs/2405.02730", "description": "arXiv:2405.02730v3 Announce Type: replace \nAbstract: Diffusion Transformers (DiTs) introduce the transformer architecture to diffusion tasks for latent-space image generation. With an isotropic architecture that chains a series of transformer blocks, DiTs demonstrate competitive performance and good scalability; but meanwhile, the abandonment of U-Net by DiTs and their following improvements is worth rethinking. To this end, we conduct a simple toy experiment by comparing a U-Net architectured DiT with an isotropic one. It turns out that the U-Net architecture only gain a slight advantage amid the U-Net inductive bias, indicating potential redundancies within the U-Net-style DiT. Inspired by the discovery that U-Net backbone features are low-frequency-dominated, we perform token downsampling on the query-key-value tuple for self-attention that bring further improvements despite a considerable amount of reduction in computation. Based on self-attention with downsampled tokens, we propose a series of U-shaped DiTs (U-DiTs) in the paper and conduct extensive experiments to demonstrate the extraordinary performance of U-DiT models. The proposed U-DiT could outperform DiT-XL/2 with only 1/6 of its computation cost. Codes are available at https://github.com/YuchuanTian/U-DiT.", "published": "2024-10-31 04:00:00", "id": "966dc28b-cd2d-4c22-bf1b-17724e6ee2a0", "source": "arxiv", "section": "computerScience"}, {"title": "On the Influence of Data Resampling for Deep Learning-Based Log Anomaly Detection: Insights and Recommendations", "link": "https://arxiv.org/abs/2405.03489", "description": "arXiv:2405.03489v3 Announce Type: replace \nAbstract: Numerous Deep Learning (DL)-based approaches have gained attention in software Log Anomaly Detection (LAD), yet class imbalance in training data remains a challenge, with anomalies often comprising less than 1% of datasets like Thunderbird. Existing DLLAD methods may underperform in severely imbalanced datasets. Although data resampling has proven effective in other software engineering tasks, it has not been explored in LAD. This study aims to fill this gap by providing an in-depth analysis of the impact of diverse data resampling methods on existing DLLAD approaches from two distinct perspectives. Firstly, we assess the performance of these DLLAD approaches across four datasets with different levels of class imbalance, and we explore the impact of resampling ratios of normal to abnormal data on DLLAD approaches. Secondly, we evaluate the effectiveness of the data resampling methods when utilizing optimal resampling ratios of normal to abnormal data. Our findings indicate that oversampling methods generally outperform undersampling and hybrid sampling methods. Data resampling on raw data yields superior results compared to data resampling in the feature space. These improvements are attributed to the increased attention given to important tokens. By exploring the resampling ratio of normal to abnormal data, we suggest generating more data for minority classes through oversampling while removing less data from majority classes through undersampling. In conclusion, our study provides valuable insights into the intricate relationship between data resampling methods and DLLAD. By addressing the challenge of class imbalance, researchers and practitioners can enhance DLLAD performance.", "published": "2024-10-31 04:00:00", "id": "4b7404b1-0e3c-49ac-8f10-1da0c70e95ea", "source": "arxiv", "section": "computerScience"}, {"title": "Aequitas Flow: Streamlining Fair ML Experimentation", "link": "https://arxiv.org/abs/2405.05809", "description": "arXiv:2405.05809v2 Announce Type: replace \nAbstract: Aequitas Flow is an open-source framework and toolkit for end-to-end Fair Machine Learning (ML) experimentation, and benchmarking in Python. This package fills integration gaps that exist in other fair ML packages. In addition to the existing audit capabilities in Aequitas, the Aequitas Flow module provides a pipeline for fairness-aware model training, hyperparameter optimization, and evaluation, enabling easy-to-use and rapid experiments and analysis of results. Aimed at ML practitioners and researchers, the framework offers implementations of methods, datasets, metrics, and standard interfaces for these components to improve extensibility. By facilitating the development of fair ML practices, Aequitas Flow hopes to enhance the incorporation of fairness concepts in AI systems making AI systems more robust and fair.", "published": "2024-10-31 04:00:00", "id": "cacc6f97-f86d-480a-ab20-04b024fc9de0", "source": "arxiv", "section": "computerScience"}, {"title": "PyZoBot: A Platform for Conversational Information Extraction and Synthesis from Curated Zotero Reference Libraries through Advanced Retrieval-Augmented Generation", "link": "https://arxiv.org/abs/2405.07963", "description": "arXiv:2405.07963v2 Announce Type: replace \nAbstract: The exponential growth of scientific literature has resulted in information overload, challenging researchers to effectively synthesize relevant publications. This paper explores the integration of traditional reference management software with advanced computational techniques, including Large Language Models and Retrieval-Augmented Generation. We introduce PyZoBot, an AI-driven platform developed in Python, incorporating Zoteros reference management with OpenAIs sophisticated LLMs. PyZoBot streamlines knowledge extraction and synthesis from extensive human-curated scientific literature databases. It demonstrates proficiency in handling complex natural language queries, integrating data from multiple sources, and meticulously presenting references to uphold research integrity and facilitate further exploration. By leveraging LLMs, RAG, and human expertise through a curated library, PyZoBot offers an effective solution to manage information overload and keep pace with rapid scientific advancements. The development of such AI-enhanced tools promises significant improvements in research efficiency and effectiveness across various disciplines.", "published": "2024-10-31 04:00:00", "id": "ce72f277-6b55-455a-9215-78df737b455a", "source": "arxiv", "section": "computerScience"}, {"title": "Compositional imprecise probability", "link": "https://arxiv.org/abs/2405.09391", "description": "arXiv:2405.09391v2 Announce Type: replace \nAbstract: Imprecise probability is concerned with uncertainty about which probability distributions to use. It has applications in robust statistics and machine learning.\n  We look at programming language models for imprecise probability. Our desiderata are that we would like our model to support all kinds of composition, categorical and monoidal; in other words, guided by dataflow diagrams. Another equivalent perspective is that we would like a model of synthetic probability in the sense of Markov categories.\n  Imprecise probability can be modelled in various ways, with the leading monad-based approach using convex sets of probability distributions. This model is not fully compositional because the monad involved is not commutative, meaning it does not have a proper monoidal structure. In this work, we provide a new fully compositional account. The key idea is to name the non-deterministic choices. To manage the renamings and disjointness of names, we use graded monads. We show that the resulting compositional model is maximal and relate it with the earlier monadic approach, proving that we obtain tighter bounds on the uncertainty.", "published": "2024-10-31 04:00:00", "id": "7ef868cd-eaa9-482b-9e0b-42eb9d64ff10", "source": "arxiv", "section": "computerScience"}, {"title": "A Theory of Synaptic Neural Balance: From Local to Global Order", "link": "https://arxiv.org/abs/2405.09688", "description": "arXiv:2405.09688v3 Announce Type: replace \nAbstract: We develop a general theory of synaptic neural balance and how it can emerge or be enforced in neural networks. For a given regularizer, a neuron is said to be in balance if the total cost of its input weights is equal to the total cost of its output weights. The basic example is provided by feedforward networks of ReLU units trained with $L_2$ regularizers, which exhibit balance after proper training. The theory explains this phenomenon and extends it in several directions. The first direction is the extension to bilinear and other activation functions. The second direction is the extension to more general regularizers, including all $L_p$ regularizers. The third direction is the extension to non-layered architectures, recurrent architectures, convolutional architectures, as well as architectures with mixed activation functions. Gradient descent on the error function alone does not converge in general to a balanced state, where every neuron is in balance, even when starting from a balanced state. However, gradient descent on the regularized error function ought to converge to a balanced state, and thus network balance can be used to assess learning progress. The theory is based on two local neuronal operations: scaling which is commutative, and balancing which is not commutative. Given any initial set of weights, when local balancing operations are applied to each neuron in a stochastic manner, global order always emerges through the convergence of the stochastic balancing algorithm to the same unique set of balanced weights. The reason for this is the existence of an underlying strictly convex optimization problem where the relevant variables are constrained to a linear, only architecture-dependent, manifold. Simulations show that balancing neurons prior to learning, or during learning in alternation with gradient descent steps, can improve learning speed and final performance.", "published": "2024-10-31 04:00:00", "id": "92b4c540-15bb-4e60-8b25-71213940de66", "source": "arxiv", "section": "computerScience"}, {"title": "Reward Centering", "link": "https://arxiv.org/abs/2405.09999", "description": "arXiv:2405.09999v2 Announce Type: replace \nAbstract: We show that discounted methods for solving continuing reinforcement learning problems can perform significantly better if they center their rewards by subtracting out the rewards' empirical average. The improvement is substantial at commonly used discount factors and increases further as the discount factor approaches one. In addition, we show that if a problem's rewards are shifted by a constant, then standard methods perform much worse, whereas methods with reward centering are unaffected. Estimating the average reward is straightforward in the on-policy setting; we propose a slightly more sophisticated method for the off-policy setting. Reward centering is a general idea, so we expect almost every reinforcement-learning algorithm to benefit by the addition of reward centering.", "published": "2024-10-31 04:00:00", "id": "f24e9eb6-e11d-40b7-973e-f1a0c8d16303", "source": "arxiv", "section": "computerScience"}, {"title": "Jumping Automata Must Pay", "link": "https://arxiv.org/abs/2405.11849", "description": "arXiv:2405.11849v2 Announce Type: replace \nAbstract: Jumping automata are finite automata that read their input in a non-sequential manner, by allowing a reading head to \"jump\" between positions on the input, consuming a permutation of the input word. We argue that allowing the head to jump should incur some cost. To this end, we propose three quantitative semantics for jumping automata, whereby the jumps of the head in an accepting run define the cost of the run. The three semantics correspond to different interpretations of jumps: the absolute distance semantics counts the distance the head jumps, the reversal semantics counts the number of times the head changes direction, and the Hamming distance measures the number of letter-swaps the run makes.\n  We study these measures, with the main focus being the boundedness problem: given a jumping automaton, decide whether its (quantitative) languages is bounded by some given number k. We establish the decidability and complexity for this problem under several variants.", "published": "2024-10-31 04:00:00", "id": "fcb22e84-17ce-40b2-9ed6-c96c2696c460", "source": "arxiv", "section": "computerScience"}, {"title": "Diffusion for World Modeling: Visual Details Matter in Atari", "link": "https://arxiv.org/abs/2405.12399", "description": "arXiv:2405.12399v2 Announce Type: replace \nAbstract: World models constitute a promising approach for training reinforcement learning agents in a safe and sample-efficient manner. Recent world models predominantly operate on sequences of discrete latent variables to model environment dynamics. However, this compression into a compact discrete representation may ignore visual details that are important for reinforcement learning. Concurrently, diffusion models have become a dominant approach for image generation, challenging well-established methods modeling discrete latents. Motivated by this paradigm shift, we introduce DIAMOND (DIffusion As a Model Of eNvironment Dreams), a reinforcement learning agent trained in a diffusion world model. We analyze the key design choices that are required to make diffusion suitable for world modeling, and demonstrate how improved visual details can lead to improved agent performance. DIAMOND achieves a mean human normalized score of 1.46 on the competitive Atari 100k benchmark; a new best for agents trained entirely within a world model. We further demonstrate that DIAMOND's diffusion world model can stand alone as an interactive neural game engine by training on static Counter-Strike: Global Offensive gameplay. To foster future research on diffusion for world modeling, we release our code, agents, videos and playable world models at https://diamond-wm.github.io.", "published": "2024-10-31 04:00:00", "id": "832126bf-5465-47cc-b697-bb1a80e7198b", "source": "arxiv", "section": "computerScience"}, {"title": "Detecting and Mitigating Bias in Algorithms Used to Disseminate Information in Social Networks", "link": "https://arxiv.org/abs/2405.12764", "description": "arXiv:2405.12764v2 Announce Type: replace \nAbstract: Social connections are conduits through which individuals communicate, information propagates, and diseases spread. Identifying individuals who are more likely to adopt ideas and spread them is essential in order to develop effective information campaigns, maximize the reach of resources, and fight epidemics. Influence maximization algorithms are used to identify sets of influencers. Based on extensive computer simulations on synthetic and ten diverse real-world social networks we show that seeding information using these methods creates information gaps. Our results show that these algorithms select influencers who do not disseminate information equitably, threatening to create an increasingly unequal society. To overcome this issue we devise a multi-objective algorithm which maximizes influence and information equity. Our results demonstrate it is possible to reduce vulnerability at a relatively low trade-off with respect to spread. This highlights that in our search for maximizing information we do not need to compromise on information equality.", "published": "2024-10-31 04:00:00", "id": "d996f1df-6bbb-4f0f-a40d-1a064c248109", "source": "arxiv", "section": "computerScience"}, {"title": "Implicit-ARAP: Efficient Handle-Guided Deformation of High-Resolution Meshes and Neural Fields via Local Patch Meshing", "link": "https://arxiv.org/abs/2405.12895", "description": "arXiv:2405.12895v2 Announce Type: replace \nAbstract: In this work, we present the local patch mesh representation for neural signed distance fields. This technique allows to discretize local regions of the level sets of an input SDF by projecting and deforming flat patch meshes onto the level set surface, using exclusively the SDF information and its gradient. Our analysis reveals this method to be more accurate than the standard marching cubes algorithm for approximating the implicit surface. Then, we apply this representation in the setting of handle-guided deformation: we introduce two distinct pipelines, which make use of 3D neural fields to compute As-Rigid-As-Possible deformations of both high-resolution meshes and neural fields under a given set of constraints. We run a comprehensive evaluation of our method and various baselines for neural field and mesh deformation which show both pipelines achieve impressive efficiency and notable improvements in terms of quality of results and robustness. With our novel pipeline, we introduce a scalable approach to solve a well-established geometry processing problem on high-resolution meshes, and pave the way for extending other geometric tasks to the domain of implicit surfaces via local patch meshing.", "published": "2024-10-31 04:00:00", "id": "461866ab-91d6-49b2-b1d5-0ec70612ea58", "source": "arxiv", "section": "computerScience"}, {"title": "On the stability of gradient descent with second order dynamics for time-varying cost functions", "link": "https://arxiv.org/abs/2405.13765", "description": "arXiv:2405.13765v2 Announce Type: replace \nAbstract: Gradient based optimization algorithms deployed in Machine Learning (ML) applications are often analyzed and compared by their convergence rates or regret bounds. While these rates and bounds convey valuable information they don't always directly translate to stability guarantees. Stability and similar concepts, like robustness, will become ever more important as we move towards deploying models in real-time and safety critical systems. In this work we build upon the results in Gaudio et al. 2021 and Moreu & Annaswamy 2022 for gradient descent with second order dynamics when applied to explicitly time varying cost functions and provide more general stability guarantees. These more general results can aid in the design and certification of these optimization schemes so as to help ensure safe and reliable deployment for real-time learning applications. We also hope that the techniques provided here will stimulate and cross-fertilize the analysis that occurs on the same algorithms from the online learning and stochastic optimization communities.", "published": "2024-10-31 04:00:00", "id": "6d143fcd-b210-4281-b098-028d7df092f6", "source": "arxiv", "section": "computerScience"}, {"title": "LookHere: Vision Transformers with Directed Attention Generalize and Extrapolate", "link": "https://arxiv.org/abs/2405.13985", "description": "arXiv:2405.13985v2 Announce Type: replace \nAbstract: High-resolution images offer more information about scenes that can improve model accuracy. However, the dominant model architecture in computer vision, the vision transformer (ViT), cannot effectively leverage larger images without finetuning -- ViTs poorly extrapolate to more patches at test time, although transformers offer sequence length flexibility. We attribute this shortcoming to the current patch position encoding methods, which create a distribution shift when extrapolating.\n  We propose a drop-in replacement for the position encoding of plain ViTs that restricts attention heads to fixed fields of view, pointed in different directions, using 2D attention masks. Our novel method, called LookHere, provides translation-equivariance, ensures attention head diversity, and limits the distribution shift that attention heads face when extrapolating. We demonstrate that LookHere improves performance on classification (avg. 1.6%), against adversarial attack (avg. 5.4%), and decreases calibration error (avg. 1.5%) -- on ImageNet without extrapolation. With extrapolation, LookHere outperforms the current SoTA position encoding method, 2D-RoPE, by 21.7% on ImageNet when trained at $224^2$ px and tested at $1024^2$ px. Additionally, we release a high-resolution test set to improve the evaluation of high-resolution image classifiers, called ImageNet-HR.", "published": "2024-10-31 04:00:00", "id": "984515f9-a567-4884-8ce2-aac2c2292870", "source": "arxiv", "section": "computerScience"}, {"title": "Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning", "link": "https://arxiv.org/abs/2405.14039", "description": "arXiv:2405.14039v2 Announce Type: replace \nAbstract: Real-world data deviating from the independent and identically distributed (i.i.d.) assumption of in-distribution training data poses security threats to deep networks, thus advancing out-of-distribution (OOD) detection algorithms. Detection methods in generative language models (GLMs) mainly focus on uncertainty estimation and embedding distance measurement, with the latter proven to be most effective in traditional linguistic tasks like summarization and translation. However, another complex generative scenario mathematical reasoning poses significant challenges to embedding-based methods due to its high-density feature of output spaces, but this feature causes larger discrepancies in the embedding shift trajectory between different samples in latent spaces. Hence, we propose a trajectory-based method TV score, which uses trajectory volatility for OOD detection in mathematical reasoning. Experiments show that our method outperforms all traditional algorithms on GLMs under mathematical reasoning scenarios and can be extended to more applications with high-density features in output spaces, such as multiple-choice questions.", "published": "2024-10-31 04:00:00", "id": "1a9584c9-e7cc-485a-9714-4731940d09e5", "source": "arxiv", "section": "computerScience"}, {"title": "SpGesture: Source-Free Domain-adaptive sEMG-based Gesture Recognition with Jaccard Attentive Spiking Neural Network", "link": "https://arxiv.org/abs/2405.14398", "description": "arXiv:2405.14398v3 Announce Type: replace \nAbstract: Surface electromyography (sEMG) based gesture recognition offers a natural and intuitive interaction modality for wearable devices. Despite significant advancements in sEMG-based gesture-recognition models, existing methods often suffer from high computational latency and increased energy consumption. Additionally, the inherent instability of sEMG signals, combined with their sensitivity to distribution shifts in real-world settings, compromises model robustness. To tackle these challenges, we propose a novel SpGesture framework based on Spiking Neural Networks, which possesses several unique merits compared with existing methods: (1) Robustness: By utilizing membrane potential as a memory list, we pioneer the introduction of Source-Free Domain Adaptation into SNN for the first time. This enables SpGesture to mitigate the accuracy degradation caused by distribution shifts. (2) High Accuracy: With a novel Spiking Jaccard Attention, SpGesture enhances the SNNs' ability to represent sEMG features, leading to a notable rise in system accuracy. To validate SpGesture's performance, we collected a new sEMG gesture dataset which has different forearm postures, where SpGesture achieved the highest accuracy among the baselines ($89.26\\%$). Moreover, the actual deployment on the CPU demonstrated a system latency below 100ms, well within real-time requirements. This impressive performance showcases SpGesture's potential to enhance the applicability of sEMG in real-world scenarios. The code is available at https://github.com/guoweiyu/SpGesture/.", "published": "2024-10-31 04:00:00", "id": "4af34deb-c415-4566-996a-4aad51a624a0", "source": "arxiv", "section": "computerScience"}, {"title": "YOLOv10: Real-Time End-to-End Object Detection", "link": "https://arxiv.org/abs/2405.14458", "description": "arXiv:2405.14458v2 Announce Type: replace \nAbstract: Over the past years, YOLOs have emerged as the predominant paradigm in the field of real-time object detection owing to their effective balance between computational cost and detection performance. Researchers have explored the architectural designs, optimization objectives, data augmentation strategies, and others for YOLOs, achieving notable progress. However, the reliance on the non-maximum suppression (NMS) for post-processing hampers the end-to-end deployment of YOLOs and adversely impacts the inference latency. Besides, the design of various components in YOLOs lacks the comprehensive and thorough inspection, resulting in noticeable computational redundancy and limiting the model's capability. It renders the suboptimal efficiency, along with considerable potential for performance improvements. In this work, we aim to further advance the performance-efficiency boundary of YOLOs from both the post-processing and model architecture. To this end, we first present the consistent dual assignments for NMS-free training of YOLOs, which brings competitive performance and low inference latency simultaneously. Moreover, we introduce the holistic efficiency-accuracy driven model design strategy for YOLOs. We comprehensively optimize various components of YOLOs from both efficiency and accuracy perspectives, which greatly reduces the computational overhead and enhances the capability. The outcome of our effort is a new generation of YOLO series for real-time end-to-end object detection, dubbed YOLOv10. Extensive experiments show that YOLOv10 achieves state-of-the-art performance and efficiency across various model scales. For example, our YOLOv10-S is 1.8$\\times$ faster than RT-DETR-R18 under the similar AP on COCO, meanwhile enjoying 2.8$\\times$ smaller number of parameters and FLOPs. Compared with YOLOv9-C, YOLOv10-B has 46\\% less latency and 25\\% fewer parameters for the same performance.", "published": "2024-10-31 04:00:00", "id": "ba81a26c-9a4f-4750-8493-858f6868fc0d", "source": "arxiv", "section": "computerScience"}, {"title": "Vortex-capturing multiscale spaces for the Ginzburg-Landau equation", "link": "https://arxiv.org/abs/2405.14772", "description": "arXiv:2405.14772v3 Announce Type: replace \nAbstract: This paper considers minimizers of the Ginzburg-Landau energy functional in particular multiscale spaces that are based on finite elements. The spaces are constructed by localized orthogonal decomposition techniques and their usage for solving the Ginzburg-Landau equation was first suggested in [D\\\"orich, Henning, SINUM 2024]. In this work we further explore their approximation properties and give an analytical explanation for why vortex structures of energy minimizers can be captured more accurately in these spaces. We quantify the necessary mesh resolution in terms of the Ginzburg-Landau parameter $\\kappa$ and a stabilization parameter $\\beta \\ge 0$ that is used in the construction of the multiscale spaces. Furthermore, we analyze how $\\kappa$ affects the necessary locality of the multiscale basis functions and we prove that the choice $\\beta=0$ yields typically the highest accuracy. Our findings are supported by numerical experiments.", "published": "2024-10-31 04:00:00", "id": "600641f2-b7a2-46bc-b8d4-c2245a001004", "source": "arxiv", "section": "computerScience"}, {"title": "DisC-GS: Discontinuity-aware Gaussian Splatting", "link": "https://arxiv.org/abs/2405.15196", "description": "arXiv:2405.15196v2 Announce Type: replace \nAbstract: Recently, Gaussian Splatting, a method that represents a 3D scene as a collection of Gaussian distributions, has gained significant attention in addressing the task of novel view synthesis. In this paper, we highlight a fundamental limitation of Gaussian Splatting: its inability to accurately render discontinuities and boundaries in images due to the continuous nature of Gaussian distributions. To address this issue, we propose a novel framework enabling Gaussian Splatting to perform discontinuity-aware image rendering. Additionally, we introduce a B\\'ezier-boundary gradient approximation strategy within our framework to keep the \"differentiability\" of the proposed discontinuity-aware rendering process. Extensive experiments demonstrate the efficacy of our framework.", "published": "2024-10-31 04:00:00", "id": "918b260e-dd7d-43b0-b37f-3e6c269e2671", "source": "arxiv", "section": "computerScience"}, {"title": "Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search", "link": "https://arxiv.org/abs/2405.15383", "description": "arXiv:2405.15383v2 Announce Type: replace \nAbstract: In this work we consider Code World Models, world models generated by a Large Language Model (LLM) in the form of Python code for model-based Reinforcement Learning (RL). Calling code instead of LLMs for planning has potential to be more precise, reliable, interpretable, and extremely efficient. However, writing appropriate Code World Models requires the ability to understand complex instructions, to generate exact code with non-trivial logic and to self-debug a long program with feedback from unit tests and environment trajectories. To address these challenges, we propose Generate, Improve and Fix with Monte Carlo Tree Search (GIF-MCTS), a new code generation strategy for LLMs. To test our approach in an offline RL setting, we introduce the Code World Models Benchmark (CWMB), a suite of program synthesis and planning tasks comprised of 18 diverse RL environments paired with corresponding textual descriptions and curated trajectories. GIF-MCTS surpasses all baselines on the CWMB and two other benchmarks, and we show that the Code World Models synthesized with it can be successfully used for planning, resulting in model-based RL agents with greatly improved sample efficiency and inference speed.", "published": "2024-10-31 04:00:00", "id": "99537547-4168-43a6-a170-be9878167e99", "source": "arxiv", "section": "computerScience"}, {"title": "Kronecker-Factored Approximate Curvature for Physics-Informed Neural Networks", "link": "https://arxiv.org/abs/2405.15603", "description": "arXiv:2405.15603v3 Announce Type: replace \nAbstract: Physics-informed neural networks (PINNs) are infamous for being hard to train. Recently, second-order methods based on natural gradient and Gauss-Newton methods have shown promising performance, improving the accuracy achieved by first-order methods by several orders of magnitude. While promising, the proposed methods only scale to networks with a few thousand parameters due to the high computational cost to evaluate, store, and invert the curvature matrix. We propose Kronecker-factored approximate curvature (KFAC) for PINN losses that greatly reduces the computational cost and allows scaling to much larger networks. Our approach goes beyond the established KFAC for traditional deep learning problems as it captures contributions from a PDE's differential operator that are crucial for optimization. To establish KFAC for such losses, we use Taylor-mode automatic differentiation to describe the differential operator's computation graph as a forward network with shared weights. This allows us to apply KFAC thanks to a recently-developed general formulation for networks with weight sharing. Empirically, we find that our KFAC-based optimizers are competitive with expensive second-order methods on small problems, scale more favorably to higher-dimensional neural networks and PDEs, and consistently outperform first-order methods and LBFGS.", "published": "2024-10-31 04:00:00", "id": "3e56d622-d652-41a0-a858-5feb0b80eece", "source": "arxiv", "section": "computerScience"}, {"title": "The Road Less Scheduled", "link": "https://arxiv.org/abs/2405.15682", "description": "arXiv:2405.15682v4 Announce Type: replace \nAbstract: Existing learning rate schedules that do not require specification of the optimization stopping step T are greatly out-performed by learning rate schedules that depend on T. We propose an approach that avoids the need for this stopping time by eschewing the use of schedules entirely, while exhibiting state-of-the-art performance compared to schedules across a wide family of problems ranging from convex problems to large-scale deep learning problems. Our Schedule-Free approach introduces no additional hyper-parameters over standard optimizers with momentum. Our method is a direct consequence of a new theory we develop that unifies scheduling and iterate averaging. An open source implementation of our method is available at https://github.com/facebookresearch/schedule_free. Schedule-Free AdamW is the core algorithm behind our winning entry to the MLCommons 2024 AlgoPerf Algorithmic Efficiency Challenge Self-Tuning track.", "published": "2024-10-31 04:00:00", "id": "a8f07e65-42a2-4c18-a20f-90a98ec36b31", "source": "arxiv", "section": "computerScience"}, {"title": "Improved Particle Approximation Error for Mean Field Neural Networks", "link": "https://arxiv.org/abs/2405.15767", "description": "arXiv:2405.15767v3 Announce Type: replace \nAbstract: Mean-field Langevin dynamics (MFLD) minimizes an entropy-regularized nonlinear convex functional defined over the space of probability distributions. MFLD has gained attention due to its connection with noisy gradient descent for mean-field two-layer neural networks. Unlike standard Langevin dynamics, the nonlinearity of the objective functional induces particle interactions, necessitating multiple particles to approximate the dynamics in a finite-particle setting. Recent works (Chen et al., 2022; Suzuki et al., 2023b) have demonstrated the uniform-in-time propagation of chaos for MFLD, showing that the gap between the particle system and its mean-field limit uniformly shrinks over time as the number of particles increases. In this work, we improve the dependence on logarithmic Sobolev inequality (LSI) constants in their particle approximation errors, which can exponentially deteriorate with the regularization coefficient. Specifically, we establish an LSI-constant-free particle approximation error concerning the objective gap by leveraging the problem structure in risk minimization. As the application, we demonstrate improved convergence of MFLD, sampling guarantee for the mean-field stationary distribution, and uniform-in-time Wasserstein propagation of chaos in terms of particle complexity.", "published": "2024-10-31 04:00:00", "id": "dce020cd-6024-421e-abea-fba0c4b1a6b9", "source": "arxiv", "section": "computerScience"}, {"title": "Accelerating Transformers with Spectrum-Preserving Token Merging", "link": "https://arxiv.org/abs/2405.16148", "description": "arXiv:2405.16148v2 Announce Type: replace \nAbstract: Increasing the throughput of the Transformer architecture, a foundational component used in numerous state-of-the-art models for vision and language tasks (e.g., GPT, LLaVa), is an important problem in machine learning. One recent and effective strategy is to merge token representations within Transformer models, aiming to reduce computational and memory requirements while maintaining accuracy. Prior works have proposed algorithms based on Bipartite Soft Matching (BSM), which divides tokens into distinct sets and merges the top k similar tokens. However, these methods have significant drawbacks, such as sensitivity to token-splitting strategies and damage to informative tokens in later layers. This paper presents a novel paradigm called PiToMe, which prioritizes the preservation of informative tokens using an additional metric termed the energy score. This score identifies large clusters of similar tokens as high-energy, indicating potential candidates for merging, while smaller (unique and isolated) clusters are considered as low-energy and preserved. Experimental findings demonstrate that PiToMe saved from 40-60\\% FLOPs of the base models while exhibiting superior off-the-shelf performance on image classification (0.5\\% average performance drop of ViT-MAE-H compared to 2.6\\% as baselines), image-text retrieval (0.3\\% average performance drop of CLIP on Flickr30k compared to 4.5\\% as others), and analogously in visual questions answering with LLaVa-7B. Furthermore, PiToMe is theoretically shown to preserve intrinsic spectral properties of the original token space under mild conditions", "published": "2024-10-31 04:00:00", "id": "ef4ac021-5ee8-4f68-a588-16272c348a12", "source": "arxiv", "section": "computerScience"}, {"title": "Flow Snapshot Neurons in Action: Deep Neural Networks Generalize to Biological Motion Perception", "link": "https://arxiv.org/abs/2405.16493", "description": "arXiv:2405.16493v2 Announce Type: replace \nAbstract: Biological motion perception (BMP) refers to humans' ability to perceive and recognize the actions of living beings solely from their motion patterns, sometimes as minimal as those depicted on point-light displays. While humans excel at these tasks without any prior training, current AI models struggle with poor generalization performance. To close this research gap, we propose the Motion Perceiver (MP). MP solely relies on patch-level optical flows from video clips as inputs. During training, it learns prototypical flow snapshots through a competitive binding mechanism and integrates invariant motion representations to predict action labels for the given video. During inference, we evaluate the generalization ability of all AI models and humans on 62,656 video stimuli spanning 24 BMP conditions using point-light displays in neuroscience. Remarkably, MP outperforms all existing AI models with a maximum improvement of 29% in top-1 action recognition accuracy on these conditions. Moreover, we benchmark all AI models in point-light displays of two standard video datasets in computer vision. MP also demonstrates superior performance in these cases. More interestingly, via psychophysics experiments, we found that MP recognizes biological movements in a way that aligns with human behaviors. Our data and code are available at https://github.com/ZhangLab-DeepNeuroCogLab/MotionPerceiver.", "published": "2024-10-31 04:00:00", "id": "9a19cdd2-270f-4acd-9833-9579551a01b6", "source": "arxiv", "section": "computerScience"}, {"title": "Fast TRAC: A Parameter-Free Optimizer for Lifelong Reinforcement Learning", "link": "https://arxiv.org/abs/2405.16642", "description": "arXiv:2405.16642v3 Announce Type: replace \nAbstract: A key challenge in lifelong reinforcement learning (RL) is the loss of plasticity, where previous learning progress hinders an agent's adaptation to new tasks. While regularization and resetting can help, they require precise hyperparameter selection at the outset and environment-dependent adjustments. Building on the principled theory of online convex optimization, we present a parameter-free optimizer for lifelong RL, called TRAC, which requires no tuning or prior knowledge about the distribution shifts. Extensive experiments on Procgen, Atari, and Gym Control environments show that TRAC works surprisingly well-mitigating loss of plasticity and rapidly adapting to challenging distribution shifts-despite the underlying optimization problem being nonconvex and nonstationary.", "published": "2024-10-31 04:00:00", "id": "330a9545-77d1-4b4c-a21e-636541b0aa61", "source": "arxiv", "section": "computerScience"}, {"title": "Code Repair with LLMs gives an Exploration-Exploitation Tradeoff", "link": "https://arxiv.org/abs/2405.17503", "description": "arXiv:2405.17503v3 Announce Type: replace \nAbstract: Iteratively improving and repairing source code with large language models (LLMs), known as refinement, has emerged as a popular way of generating programs that would be too complex to construct in one shot. Given a bank of test cases, together with a candidate program, an LLM can improve that program by being prompted with failed test cases. But it remains an open question how to best iteratively refine code, with prior work employing simple greedy or breadth-first strategies. We show here that refinement exposes an explore-exploit tradeoff: exploit by refining the program that passes the most test cases, or explore by refining a lesser considered program. We frame this as an arm-acquiring bandit problem, which we solve with Thompson Sampling. The resulting LLM-based program synthesis algorithm is broadly applicable: Across loop invariant synthesis, visual reasoning puzzles, and competition programming problems, we find that our new method can solve more problems using fewer language model calls.", "published": "2024-10-31 04:00:00", "id": "a72e9647-f452-44bb-8685-414974ab70b1", "source": "arxiv", "section": "computerScience"}, {"title": "Mixed Dynamics In Linear Networks: Unifying the Lazy and Active Regimes", "link": "https://arxiv.org/abs/2405.17580", "description": "arXiv:2405.17580v2 Announce Type: replace \nAbstract: The training dynamics of linear networks are well studied in two distinct setups: the lazy regime and balanced/active regime, depending on the initialization and width of the network. We provide a surprisingly simple unifying formula for the evolution of the learned matrix that contains as special cases both lazy and balanced regimes but also a mixed regime in between the two. In the mixed regime, a part of the network is lazy while the other is balanced. More precisely the network is lazy along singular values that are below a certain threshold and balanced along those that are above the same threshold. At initialization, all singular values are lazy, allowing for the network to align itself with the task, so that later in time, when some of the singular value cross the threshold and become active they will converge rapidly (convergence in the balanced regime is notoriously difficult in the absence of alignment). The mixed regime is the `best of both worlds': it converges from any random initialization (in contrast to balanced dynamics which require special initialization), and has a low rank bias (absent in the lazy dynamics). This allows us to prove an almost complete phase diagram of training behavior as a function of the variance at initialization and the width, for a MSE training task.", "published": "2024-10-31 04:00:00", "id": "edc1fb9e-41c3-4f22-94bc-1d7c75173410", "source": "arxiv", "section": "computerScience"}, {"title": "Bias Detection Via Signaling", "link": "https://arxiv.org/abs/2405.17694", "description": "arXiv:2405.17694v2 Announce Type: replace \nAbstract: We introduce and study the problem of detecting whether an agent is updating their prior beliefs given new evidence in an optimal way that is Bayesian, or whether they are biased towards their own prior. In our model, biased agents form posterior beliefs that are a convex combination of their prior and the Bayesian posterior, where the more biased an agent is, the closer their posterior is to the prior. Since we often cannot observe the agent's beliefs directly, we take an approach inspired by information design. Specifically, we measure an agent's bias by designing a signaling scheme and observing the actions they take in response to different signals, assuming that they are maximizing their own expected utility; our goal is to detect bias with a minimum number of signals. Our main results include a characterization of scenarios where a single signal suffices and a computationally efficient algorithm to compute optimal signaling schemes.", "published": "2024-10-31 04:00:00", "id": "268a1c47-6284-4d51-9f90-38167d376116", "source": "arxiv", "section": "computerScience"}, {"title": "Enabling Generative Design Tools with LLM Agents for Mechanical Computation Devices: A Case Study", "link": "https://arxiv.org/abs/2405.17837", "description": "arXiv:2405.17837v3 Announce Type: replace \nAbstract: In the field of Human-Computer Interaction (HCI), interactive devices with embedded mechanical computation are gaining attention. The rise of these cutting-edge devices has created a need for specialized design tools that democratize the prototyping process. While current tools streamline prototyping through parametric design and simulation, they often come with a steep learning curve and may not fully support creative ideation. In this study, we use fluidic computation interfaces as a case study to explore how design tools for such devices can be augmented by Large Language Model agents (LLMs). Integrated with LLMs, the Generative Design Tool (GDT) better understands the capabilities and limitations of new technologies, proposes diverse and practical applications, and suggests designs that are technically and contextually appropriate. Additionally, it generates design parameters for visualizing results and producing fabrication-ready support files. This paper details the GDT's framework, implementation, and performance while addressing its potential and challenges.", "published": "2024-10-31 04:00:00", "id": "de010945-fe73-45b9-8d8e-3bf0919cdf16", "source": "arxiv", "section": "computerScience"}, {"title": "$C^2M^3$: Cycle-Consistent Multi-Model Merging", "link": "https://arxiv.org/abs/2405.17897", "description": "arXiv:2405.17897v2 Announce Type: replace \nAbstract: In this paper, we present a novel data-free method for merging neural networks in weight space. Differently from most existing works, our method optimizes for the permutations of network neurons globally across all layers. This allows us to enforce cycle consistency of the permutations when merging $N \\geq 3$ models, allowing circular compositions of permutations to be computed without accumulating error along the path. We qualitatively and quantitatively motivate the need for such a constraint, showing its benefits when merging sets of models in scenarios spanning varying architectures and datasets. We finally show that, when coupled with activation renormalization, our approach yields the best results in the task.", "published": "2024-10-31 04:00:00", "id": "aa44f1df-5108-428b-8029-c5db313ebdf8", "source": "arxiv", "section": "computerScience"}, {"title": "Adam with model exponential moving average is effective for nonconvex optimization", "link": "https://arxiv.org/abs/2405.18199", "description": "arXiv:2405.18199v2 Announce Type: replace \nAbstract: In this work, we offer a theoretical analysis of two modern optimization techniques for training large and complex models: (i) adaptive optimization algorithms, such as Adam, and (ii) the model exponential moving average (EMA). Specifically, we demonstrate that a clipped version of Adam with model EMA achieves the optimal convergence rates in various nonconvex optimization settings, both smooth and nonsmooth. Moreover, when the scale varies significantly across different coordinates, we demonstrate that the coordinate-wise adaptivity of Adam is provably advantageous. Notably, unlike previous analyses of Adam, our analysis crucially relies on its core elements -- momentum and discounting factors -- as well as model EMA, motivating their wide applications in practice.", "published": "2024-10-31 04:00:00", "id": "1ccf1f21-f120-40e9-85c6-27e5196f0054", "source": "arxiv", "section": "computerScience"}, {"title": "Continuous Product Graph Neural Networks", "link": "https://arxiv.org/abs/2405.18877", "description": "arXiv:2405.18877v2 Announce Type: replace \nAbstract: Processing multidomain data defined on multiple graphs holds significant potential in various practical applications in computer science. However, current methods are mostly limited to discrete graph filtering operations. Tensorial partial differential equations on graphs (TPDEGs) provide a principled framework for modeling structured data across multiple interacting graphs, addressing the limitations of the existing discrete methodologies. In this paper, we introduce Continuous Product Graph Neural Networks (CITRUS) that emerge as a natural solution to the TPDEG. CITRUS leverages the separability of continuous heat kernels from Cartesian graph products to efficiently implement graph spectral decomposition. We conduct thorough theoretical analyses of the stability and over-smoothing properties of CITRUS in response to domain-specific graph perturbations and graph spectra effects on the performance. We evaluate CITRUS on well-known traffic and weather spatiotemporal forecasting datasets, demonstrating superior performance over existing approaches. The implementation codes are available at https://github.com/ArefEinizade2/CITRUS.", "published": "2024-10-31 04:00:00", "id": "4528972e-8361-4c66-aa50-2dadaa5afaec", "source": "arxiv", "section": "computerScience"}, {"title": "Neural Isometries: Taming Transformations for Equivariant ML", "link": "https://arxiv.org/abs/2405.19296", "description": "arXiv:2405.19296v2 Announce Type: replace \nAbstract: Real-world geometry and 3D vision tasks are replete with challenging symmetries that defy tractable analytical expression. In this paper, we introduce Neural Isometries, an autoencoder framework which learns to map the observation space to a general-purpose latent space wherein encodings are related by isometries whenever their corresponding observations are geometrically related in world space. Specifically, we regularize the latent space such that maps between encodings preserve a learned inner product and commute with a learned functional operator, in the same manner as rigid-body transformations commute with the Laplacian. This approach forms an effective backbone for self-supervised representation learning, and we demonstrate that a simple off-the-shelf equivariant network operating in the pre-trained latent space can achieve results on par with meticulously-engineered, handcrafted networks designed to handle complex, nonlinear symmetries. Furthermore, isometric maps capture information about the respective transformations in world space, and we show that this allows us to regress camera poses directly from the coefficients of the maps between encodings of adjacent views of a scene.", "published": "2024-10-31 04:00:00", "id": "9316349b-6d68-4f0c-b67b-2af99f532d9f", "source": "arxiv", "section": "computerScience"}, {"title": "MemControl: Mitigating Memorization in Diffusion Models via Automated Parameter Selection", "link": "https://arxiv.org/abs/2405.19458", "description": "arXiv:2405.19458v2 Announce Type: replace \nAbstract: Diffusion models excel in generating images that closely resemble their training data but are also susceptible to data memorization, raising privacy, ethical, and legal concerns, particularly in sensitive domains such as medical imaging. We hypothesize that this memorization stems from the overparameterization of deep models and propose that regularizing model capacity during fine-tuning can mitigate this issue. Firstly, we empirically show that regulating the model capacity via Parameter-efficient fine-tuning (PEFT) mitigates memorization to some extent, however, it further requires the identification of the exact parameter subsets to be fine-tuned for high-quality generation. To identify these subsets, we introduce a bi-level optimization framework, MemControl, that automates parameter selection using memorization and generation quality metrics as rewards during fine-tuning. The parameter subsets discovered through MemControl achieve a superior tradeoff between generation quality and memorization. For the task of medical image generation, our approach outperforms existing state-of-the-art memorization mitigation strategies by fine-tuning as few as 0.019% of model parameters. Moreover, we demonstrate that the discovered parameter subsets are transferable to non-medical domains. Our framework is scalable to large datasets, agnostic to reward functions, and can be integrated with existing approaches for further memorization mitigation. To the best of our knowledge, this is the first study to empirically evaluate memorization in medical images and propose a targeted yet universal mitigation strategy. The code is available at https://github.com/Raman1121/Diffusion_Memorization_HPO", "published": "2024-10-31 04:00:00", "id": "074a3f75-eeea-44c9-968b-eb727bca6f61", "source": "arxiv", "section": "computerScience"}, {"title": "Source Code Foundation Models are Transferable Binary Analysis Knowledge Bases", "link": "https://arxiv.org/abs/2405.19581", "description": "arXiv:2405.19581v2 Announce Type: replace \nAbstract: Human-Oriented Binary Reverse Engineering (HOBRE) lies at the intersection of binary and source code, aiming to lift binary code to human-readable content relevant to source code, thereby bridging the binary-source semantic gap. Recent advancements in uni-modal code model pre-training, particularly in generative Source Code Foundation Models (SCFMs) and binary understanding models, have laid the groundwork for transfer learning applicable to HOBRE. However, existing approaches for HOBRE rely heavily on uni-modal models like SCFMs for supervised fine-tuning or general LLMs for prompting, resulting in sub-optimal performance. Inspired by recent progress in large multi-modal models, we propose that it is possible to harness the strengths of uni-modal code models from both sides to bridge the semantic gap effectively. In this paper, we introduce a novel probe-and-recover framework that incorporates a binary-source encoder-decoder model and black-box LLMs for binary analysis. Our approach leverages the pre-trained knowledge within SCFMs to synthesize relevant, symbol-rich code fragments as context. This additional context enables black-box LLMs to enhance recovery accuracy. We demonstrate significant improvements in zero-shot binary summarization and binary function name recovery, with a 10.3% relative gain in CHRF and a 16.7% relative gain in a GPT4-based metric for summarization, as well as a 6.7% and 7.4% absolute increase in token-level precision and recall for name recovery, respectively. These results highlight the effectiveness of our approach in automating and improving binary code analysis.", "published": "2024-10-31 04:00:00", "id": "3a32cb39-19b1-40ed-93e5-e723e53ea447", "source": "arxiv", "section": "computerScience"}, {"title": "SWIFT: A Monotonic, Flux-Form Semi-Lagrangian Tracer Transport Scheme for Flow with Large Courant Numbers", "link": "https://arxiv.org/abs/2405.20006", "description": "arXiv:2405.20006v3 Announce Type: replace \nAbstract: Local conservation of mass and entropy are becoming increasingly desirable properties for modern numerical weather and climate models. This work presents a Flux-Form Semi-Lagrangian (FFSL) transport scheme, called SWIFT, that facilitates this conservation for tracer variables, whilst maintaining other vital properties such as preservation of a constant, monotonicity and positivity. Importantly, these properties all hold for large Courant numbers and multi-dimensional flow, making the scheme appropriate for use within a dynamical core which takes large time steps.\n  The SWIFT scheme presented here can be seen as an evolution of the FFSL methods of Leonard et al and Lin and Rood. Two-dimensional and three-dimensional schemes consist of a splitting into a sequence of one-dimensional calculations. The new SWIFT splitting presented here allows monotonic and positivity properties from the one-dimensional calculations to be inherited by the multi-dimensional scheme. These one-dimensional calculations involve separating the mass flux into terms that correspond to integer and fractional parts of the Courant number. Key to achieving conservation is coupling the transport of tracers to the transport of the fluid density, through re-use of the discrete mass flux that was calculated from the fluid density in the transport of the tracers. This work also describes how these properties can still be attained when the tracer is vertically-staggered from the density in a Charney-Phillips grid.", "published": "2024-10-31 04:00:00", "id": "d1037b1f-fe7b-4e1a-9277-080f15f25a57", "source": "arxiv", "section": "computerScience"}, {"title": "Segment, Shuffle, and Stitch: A Simple Layer for Improving Time-Series Representations", "link": "https://arxiv.org/abs/2405.20082", "description": "arXiv:2405.20082v3 Announce Type: replace \nAbstract: Existing approaches for learning representations of time-series keep the temporal arrangement of the time-steps intact with the presumption that the original order is the most optimal for learning. However, non-adjacent sections of real-world time-series may have strong dependencies. Accordingly, we raise the question: Is there an alternative arrangement for time-series which could enable more effective representation learning? To address this, we propose a simple plug-and-play neural network layer called Segment, Shuffle, and Stitch (S3) designed to improve representation learning in time-series models. S3 works by creating non-overlapping segments from the original sequence and shuffling them in a learned manner that is optimal for the task at hand. It then re-attaches the shuffled segments back together and performs a learned weighted sum with the original input to capture both the newly shuffled sequence along with the original sequence. S3 is modular and can be stacked to achieve different levels of granularity, and can be added to many forms of neural architectures including CNNs or Transformers with negligible computation overhead. Through extensive experiments on several datasets and state-of-the-art baselines, we show that incorporating S3 results in significant improvements for the tasks of time-series classification, forecasting, and anomaly detection, improving performance on certain datasets by up to 68\\%. We also show that S3 makes the learning more stable with a smoother training loss curve and loss landscape compared to the original baseline. The code is available at https://github.com/shivam-grover/S3-TimeSeries.", "published": "2024-10-31 04:00:00", "id": "65e3483f-032a-448d-b6ec-10f81f2dc01b", "source": "arxiv", "section": "computerScience"}, {"title": "OpenDAS: Open-Vocabulary Domain Adaptation for 2D and 3D Segmentation", "link": "https://arxiv.org/abs/2405.20141", "description": "arXiv:2405.20141v4 Announce Type: replace \nAbstract: Recently, Vision-Language Models (VLMs) have advanced segmentation techniques by shifting from the traditional segmentation of a closed-set of predefined object classes to open-vocabulary segmentation (OVS), allowing users to segment novel classes and concepts unseen during training of the segmentation model. However, this flexibility comes with a trade-off: fully-supervised closed-set methods still outperform OVS methods on base classes, that is on classes on which they have been explicitly trained. This is due to the lack of pixel-aligned training masks for VLMs (which are trained on image-caption pairs), and the absence of domain-specific knowledge, such as autonomous driving. Therefore, we propose the task of open-vocabulary domain adaptation to infuse domain-specific knowledge into VLMs while preserving their open-vocabulary nature. By doing so, we achieve improved performance in base and novel classes. Existing VLM adaptation methods improve performance on base (training) queries, but fail to fully preserve the open-set capabilities of VLMs on novel queries. To address this shortcoming, we combine parameter-efficient prompt tuning with a triplet-loss-based training strategy that uses auxiliary negative queries. Notably, our approach is the only parameter-efficient method that consistently surpasses the original VLM on novel classes. Our adapted VLMs can seamlessly be integrated into existing OVS pipelines, e.g., improving OVSeg by +6.0% mIoU on ADE20K for open-vocabulary 2D segmentation, and OpenMask3D by +4.1% AP on ScanNet++ Offices for open-vocabulary 3D instance segmentation without other changes. The project page is available at https://open-das.github.io/.", "published": "2024-10-31 04:00:00", "id": "b7bea778-f143-4690-81c9-d9354306a6c0", "source": "arxiv", "section": "computerScience"}, {"title": "SECURE: Benchmarking Large Language Models for Cybersecurity", "link": "https://arxiv.org/abs/2405.20441", "description": "arXiv:2405.20441v4 Announce Type: replace \nAbstract: Large Language Models (LLMs) have demonstrated potential in cybersecurity applications but have also caused lower confidence due to problems like hallucinations and a lack of truthfulness. Existing benchmarks provide general evaluations but do not sufficiently address the practical and applied aspects of LLM performance in cybersecurity-specific tasks. To address this gap, we introduce the SECURE (Security Extraction, Understanding \\& Reasoning Evaluation), a benchmark designed to assess LLMs performance in realistic cybersecurity scenarios. SECURE includes six datasets focussed on the Industrial Control System sector to evaluate knowledge extraction, understanding, and reasoning based on industry-standard sources. Our study evaluates seven state-of-the-art models on these tasks, providing insights into their strengths and weaknesses in cybersecurity contexts, and offer recommendations for improving LLMs reliability as cyber advisory tools.", "published": "2024-10-31 04:00:00", "id": "dac4fb67-a672-4f6b-b4a6-861179493e8a", "source": "arxiv", "section": "computerScience"}, {"title": "Slight Corruption in Pre-training Data Makes Better Diffusion Models", "link": "https://arxiv.org/abs/2405.20494", "description": "arXiv:2405.20494v2 Announce Type: replace \nAbstract: Diffusion models (DMs) have shown remarkable capabilities in generating realistic high-quality images, audios, and videos. They benefit significantly from extensive pre-training on large-scale datasets, including web-crawled data with paired data and conditions, such as image-text and image-class pairs. Despite rigorous filtering, these pre-training datasets often inevitably contain corrupted pairs where conditions do not accurately describe the data. This paper presents the first comprehensive study on the impact of such corruption in pre-training data of DMs. We synthetically corrupt ImageNet-1K and CC3M to pre-train and evaluate over 50 conditional DMs. Our empirical findings reveal that various types of slight corruption in pre-training can significantly enhance the quality, diversity, and fidelity of the generated images across different DMs, both during pre-training and downstream adaptation stages. Theoretically, we consider a Gaussian mixture model and prove that slight corruption in the condition leads to higher entropy and a reduced 2-Wasserstein distance to the ground truth of the data distribution generated by the corruptly trained DMs. Inspired by our analysis, we propose a simple method to improve the training of DMs on practical datasets by adding condition embedding perturbations (CEP). CEP significantly improves the performance of various DMs in both pre-training and downstream tasks. We hope that our study provides new insights into understanding the data and pre-training processes of DMs and all models are released at https://huggingface.co/DiffusionNoise.", "published": "2024-10-31 04:00:00", "id": "f09e8305-d01f-4cbd-875b-5a1336c3dbd8", "source": "arxiv", "section": "computerScience"}, {"title": "Position Coupling: Improving Length Generalization of Arithmetic Transformers Using Task Structure", "link": "https://arxiv.org/abs/2405.20671", "description": "arXiv:2405.20671v2 Announce Type: replace \nAbstract: Even for simple arithmetic tasks like integer addition, it is challenging for Transformers to generalize to longer sequences than those encountered during training. To tackle this problem, we propose position coupling, a simple yet effective method that directly embeds the structure of the tasks into the positional encoding of a (decoder-only) Transformer. Taking a departure from the vanilla absolute position mechanism assigning unique position IDs to each of the tokens, we assign the same position IDs to two or more \"relevant\" tokens; for integer addition tasks, we regard digits of the same significance as in the same position. On the empirical side, we show that with the proposed position coupling, our models trained on 1 to 30-digit additions can generalize up to 200-digit additions (6.67x of the trained length). On the theoretical side, we prove that a 1-layer Transformer with coupled positions can solve the addition task involving exponentially many digits, whereas any 1-layer Transformer without positional information cannot entirely solve it. We also demonstrate that position coupling can be applied to other algorithmic tasks such as Nx2 multiplication and a two-dimensional task.", "published": "2024-10-31 04:00:00", "id": "0a0da206-0e3f-4e41-8a95-22116b31f9dd", "source": "arxiv", "section": "computerScience"}, {"title": "Improving Generalization and Convergence by Enhancing Implicit Regularization", "link": "https://arxiv.org/abs/2405.20763", "description": "arXiv:2405.20763v3 Announce Type: replace \nAbstract: In this work, we propose an Implicit Regularization Enhancement (IRE) framework to accelerate the discovery of flat solutions in deep learning, thereby improving generalization and convergence. Specifically, IRE decouples the dynamics of flat and sharp directions, which boosts the sharpness reduction along flat directions while maintaining the training stability in sharp directions. We show that IRE can be practically incorporated with {\\em generic base optimizers} without introducing significant computational overload. Experiments show that IRE consistently improves the generalization performance for image classification tasks across a variety of benchmark datasets (CIFAR-10/100, ImageNet) and models (ResNets and ViTs). Surprisingly, IRE also achieves a $2\\times$ {\\em speed-up} compared to AdamW in the pre-training of Llama models (of sizes ranging from 60M to 229M) on datasets including Wikitext-103, Minipile, and Openwebtext. Moreover, we provide theoretical guarantees, showing that IRE can substantially accelerate the convergence towards flat minima in Sharpness-aware Minimization (SAM).", "published": "2024-10-31 04:00:00", "id": "9ef8e423-f327-4702-87c0-d8dc07dcc2a3", "source": "arxiv", "section": "computerScience"}, {"title": "einspace: Searching for Neural Architectures from Fundamental Operations", "link": "https://arxiv.org/abs/2405.20838", "description": "arXiv:2405.20838v2 Announce Type: replace \nAbstract: Neural architecture search (NAS) finds high performing networks for a given task. Yet the results of NAS are fairly prosaic; they did not e.g. create a shift from convolutional structures to transformers. This is not least because the search spaces in NAS often aren't diverse enough to include such transformations a priori. Instead, for NAS to provide greater potential for fundamental design shifts, we need a novel expressive search space design which is built from more fundamental operations. To this end, we introduce einspace, a search space based on a parameterised probabilistic context-free grammar. Our space is versatile, supporting architectures of various sizes and complexities, while also containing diverse network operations which allow it to model convolutions, attention components and more. It contains many existing competitive architectures, and provides flexibility for discovering new ones. Using this search space, we perform experiments to find novel architectures as well as improvements on existing ones on the diverse Unseen NAS datasets. We show that competitive architectures can be obtained by searching from scratch, and we consistently find large improvements when initialising the search with strong baselines. We believe that this work is an important advancement towards a transformative NAS paradigm where search space expressivity and strategic search initialisation play key roles.", "published": "2024-10-31 04:00:00", "id": "940bf9c3-5664-47c7-8354-07bd7e39c912", "source": "arxiv", "section": "computerScience"}, {"title": "Equivariant Machine Learning on Graphs with Nonlinear Spectral Filters", "link": "https://arxiv.org/abs/2406.01249", "description": "arXiv:2406.01249v2 Announce Type: replace \nAbstract: Equivariant machine learning is an approach for designing deep learning models that respect the symmetries of the problem, with the aim of reducing model complexity and improving generalization. In this paper, we focus on an extension of shift equivariance, which is the basis of convolution networks on images, to general graphs. Unlike images, graphs do not have a natural notion of domain translation. Therefore, we consider the graph functional shifts as the symmetry group: the unitary operators that commute with the graph shift operator. Notably, such symmetries operate in the signal space rather than directly in the spatial space. We remark that each linear filter layer of a standard spectral graph neural network (GNN) commutes with graph functional shifts, but the activation function breaks this symmetry. Instead, we propose nonlinear spectral filters (NLSFs) that are fully equivariant to graph functional shifts and show that they have universal approximation properties. The proposed NLSFs are based on a new form of spectral domain that is transferable between graphs. We demonstrate the superior performance of NLSFs over existing spectral GNNs in node and graph classification benchmarks.", "published": "2024-10-31 04:00:00", "id": "e1117092-abb3-41c6-ae23-347cdc0d2f1e", "source": "arxiv", "section": "computerScience"}, {"title": "Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses", "link": "https://arxiv.org/abs/2406.01288", "description": "arXiv:2406.01288v2 Announce Type: replace \nAbstract: Recently, Anil et al. (2024) show that many-shot (up to hundreds of) demonstrations can jailbreak state-of-the-art LLMs by exploiting their long-context capability. Nevertheless, is it possible to use few-shot demonstrations to efficiently jailbreak LLMs within limited context sizes? While the vanilla few-shot jailbreaking may be inefficient, we propose improved techniques such as injecting special system tokens like [/INST] and employing demo-level random search from a collected demo pool. These simple techniques result in surprisingly effective jailbreaking against aligned LLMs (even with advanced defenses). For examples, our method achieves >80% (mostly >95%) ASRs on Llama-2-7B and Llama-3-8B without multiple restarts, even if the models are enhanced by strong defenses such as perplexity detection and/or SmoothLLM, which is challenging for suffix-based jailbreaking. In addition, we conduct comprehensive and elaborate (e.g., making sure to use correct system prompts) evaluations against other aligned LLMs and advanced defenses, where our method consistently achieves nearly 100% ASRs. Our code is available at https://github.com/sail-sg/I-FSJ.", "published": "2024-10-31 04:00:00", "id": "bc6f45ba-3bdf-47d4-9bb5-7d47112d79a7", "source": "arxiv", "section": "computerScience"}, {"title": "REvolve: Reward Evolution with Large Language Models using Human Feedback", "link": "https://arxiv.org/abs/2406.01309", "description": "arXiv:2406.01309v2 Announce Type: replace \nAbstract: Designing effective reward functions is crucial to training reinforcement learning (RL) algorithms. However, this design is non-trivial, even for domain experts, due to the subjective nature of certain tasks that are hard to quantify explicitly. In recent works, large language models (LLMs) have been used for reward generation from natural language task descriptions, leveraging their extensive instruction tuning and commonsense understanding of human behavior. In this work, we hypothesize that LLMs, guided by human feedback, can be used to formulate reward functions that reflect human implicit knowledge. We study this in three challenging settings -- autonomous driving, humanoid locomotion, and dexterous manipulation -- wherein notions of ``good\" behavior are tacit and hard to quantify. To this end, we introduce REvolve, a truly evolutionary framework that uses LLMs for reward design in RL. REvolve generates and refines reward functions by utilizing human feedback to guide the evolution process, effectively translating implicit human knowledge into explicit reward functions for training (deep) RL agents. Experimentally, we demonstrate that agents trained on REvolve-designed rewards outperform other state-of-the-art baselines.", "published": "2024-10-31 04:00:00", "id": "210e8d43-3687-4f3b-b529-9fd027b91038", "source": "arxiv", "section": "computerScience"}, {"title": "TE-NeXt: A LiDAR-Based 3D Sparse Convolutional Network for Traversability Estimation", "link": "https://arxiv.org/abs/2406.01395", "description": "arXiv:2406.01395v2 Announce Type: replace \nAbstract: This paper presents TE-NeXt, a novel and efficient architecture for Traversability Estimation (TE) from sparse LiDAR point clouds based on a residual convolution block. TE-NeXt block fuses notions of current trends such as attention mechanisms and 3D sparse convolutions. TE-NeXt aims to demonstrate high capacity for generalisation in a variety of urban and natural environments, using well-known and accessible datasets such as SemanticKITTI, Rellis-3D and SemanticUSL. Thus, the designed architecture ouperforms state-of-the-art methods in the problem of semantic segmentation, demonstrating better results in unstructured environments and maintaining high reliability and robustness in urbans environments, which leads to better abstraction. Implementation is available in a open repository to the scientific community with the aim of ensuring the reproducibility of results.", "published": "2024-10-31 04:00:00", "id": "6bb0ca23-fd51-4e09-b219-6e7d352d8e02", "source": "arxiv", "section": "computerScience"}, {"title": "Charting the Landscape of Nefarious Uses of Generative Artificial Intelligence for Online Election Interference", "link": "https://arxiv.org/abs/2406.01862", "description": "arXiv:2406.01862v4 Announce Type: replace \nAbstract: Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) pose significant risks, particularly in the realm of online election interference. This paper explores the nefarious applications of GenAI, highlighting their potential to disrupt democratic processes through deepfakes, botnets, targeted misinformation campaigns, and synthetic identities. By examining recent case studies and public incidents, we illustrate how malicious actors exploit these technologies to try influencing voter behavior, spread disinformation, and undermine public trust in electoral systems. The paper also discusses the societal implications of these threats, emphasizing the urgent need for robust mitigation strategies and international cooperation to safeguard democratic integrity.", "published": "2024-10-31 04:00:00", "id": "dafb4afb-d02a-4e59-9075-55a4a8f625c6", "source": "arxiv", "section": "computerScience"}, {"title": "Image contrast enhancement based on the Schr\\\"odinger operator spectrum", "link": "https://arxiv.org/abs/2406.02264", "description": "arXiv:2406.02264v2 Announce Type: replace \nAbstract: In this study, we propose a novel image contrast enhancement method based on projecting images onto the squared eigenfunctions of the two-dimensional Schr\\\"odinger operator. This projection relies on a design parameter, $\\gamma$, which controls pixel intensity during image reconstruction. The method's performance is evaluated using color images. The selection of $\\gamma$ values is guided by priors based on fuzzy logic and clustering, preserving the spatial adjacency information of the image. Additionally, multi-objective optimization using the Non-dominated Sorting Genetic Algorithm II (NSGA-II) is employed to determine the optimal values of $\\gamma$ and the semi-classical parameter, $h$, from the 2D-SCSA. Results demonstrate that the proposed method effectively enhances image contrast while preserving the inherent characteristics of the original image, producing the desired enhancement with minimal artifacts.", "published": "2024-10-31 04:00:00", "id": "2a2852d4-fa68-443c-8b4e-c15e530ebd32", "source": "arxiv", "section": "computerScience"}, {"title": "Are Your Models Still Fair? Fairness Attacks on Graph Neural Networks via Node Injections", "link": "https://arxiv.org/abs/2406.03052", "description": "arXiv:2406.03052v2 Announce Type: replace \nAbstract: Despite the remarkable capabilities demonstrated by Graph Neural Networks (GNNs) in graph-related tasks, recent research has revealed the fairness vulnerabilities in GNNs when facing malicious adversarial attacks. However, all existing fairness attacks require manipulating the connectivity between existing nodes, which may be prohibited in reality. To this end, we introduce a Node Injection-based Fairness Attack (NIFA), exploring the vulnerabilities of GNN fairness in such a more realistic setting. In detail, NIFA first designs two insightful principles for node injection operations, namely the uncertainty-maximization principle and homophily-increase principle, and then optimizes injected nodes' feature matrix to further ensure the effectiveness of fairness attacks. Comprehensive experiments on three real-world datasets consistently demonstrate that NIFA can significantly undermine the fairness of mainstream GNNs, even including fairness-aware GNNs, by injecting merely 1% of nodes. We sincerely hope that our work can stimulate increasing attention from researchers on the vulnerability of GNN fairness, and encourage the development of corresponding defense mechanisms. Our code and data are released at: https://github.com/CGCL-codes/NIFA.", "published": "2024-10-31 04:00:00", "id": "3bbea3fe-7b6a-4569-8f31-e2da73f7060c", "source": "arxiv", "section": "computerScience"}, {"title": "Noise-Aware Algorithm for Heterogeneous Differentially Private Federated Learning", "link": "https://arxiv.org/abs/2406.03519", "description": "arXiv:2406.03519v3 Announce Type: replace \nAbstract: High utility and rigorous data privacy are of the main goals of a federated learning (FL) system, which learns a model from the data distributed among some clients. The latter has been tried to achieve by using differential privacy in FL (DPFL). There is often heterogeneity in clients privacy requirements, and existing DPFL works either assume uniform privacy requirements for clients or are not applicable when server is not fully trusted (our setting). Furthermore, there is often heterogeneity in batch and/or dataset size of clients, which as shown, results in extra variation in the DP noise level across clients model updates. With these sources of heterogeneity, straightforward aggregation strategies, e.g., assigning clients aggregation weights proportional to their privacy parameters will lead to lower utility. We propose Robust-HDP, which efficiently estimates the true noise level in clients model updates and reduces the noise-level in the aggregated model updates considerably. Robust-HDP improves utility and convergence speed, while being safe to the clients that may maliciously send falsified privacy parameter to server. Extensive experimental results on multiple datasets and our theoretical analysis confirm the effectiveness of Robust-HDP. Our code can be found here.", "published": "2024-10-31 04:00:00", "id": "4bf87dec-f869-4ce4-b8bd-5277da9a0871", "source": "arxiv", "section": "computerScience"}, {"title": "Certified Robustness to Data Poisoning in Gradient-Based Training", "link": "https://arxiv.org/abs/2406.05670", "description": "arXiv:2406.05670v2 Announce Type: replace \nAbstract: Modern machine learning pipelines leverage large amounts of public data, making it infeasible to guarantee data quality and leaving models open to poisoning and backdoor attacks. Provably bounding model behavior under such attacks remains an open problem. In this work, we address this challenge by developing the first framework providing provable guarantees on the behavior of models trained with potentially manipulated data without modifying the model or learning algorithm. In particular, our framework certifies robustness against untargeted and targeted poisoning, as well as backdoor attacks, for bounded and unbounded manipulations of the training inputs and labels. Our method leverages convex relaxations to over-approximate the set of all possible parameter updates for a given poisoning threat model, allowing us to bound the set of all reachable parameters for any gradient-based learning algorithm. Given this set of parameters, we provide bounds on worst-case behavior, including model performance and backdoor success rate. We demonstrate our approach on multiple real-world datasets from applications including energy consumption, medical imaging, and autonomous driving.", "published": "2024-10-31 04:00:00", "id": "c3df56fb-c005-4c33-9edc-76f2444565c3", "source": "arxiv", "section": "computerScience"}, {"title": "TLCM: Training-efficient Latent Consistency Model for Image Generation with 2-8 Steps", "link": "https://arxiv.org/abs/2406.05768", "description": "arXiv:2406.05768v4 Announce Type: replace \nAbstract: Distilling latent diffusion models (LDMs) into ones that are fast to sample from is attracting growing research interest. However, the majority of existing methods face two critical challenges: (1) They hinge on long training using a huge volume of real data. (2) They routinely lead to quality degradation for generation, especially in text-image alignment. This paper proposes a novel training-efficient Latent Consistency Model (TLCM) to overcome these challenges. Our method first accelerates LDMs via data-free multistep latent consistency distillation (MLCD), and then data-free latent consistency distillation is proposed to efficiently guarantee the inter-segment consistency in MLCD. Furthermore, we introduce bags of techniques, e.g., distribution matching, adversarial learning, and preference learning, to enhance TLCM's performance at few-step inference without any real data. TLCM demonstrates a high level of flexibility by enabling adjustment of sampling steps within the range of 2 to 8 while still producing competitive outputs compared to full-step approaches. Notably, TLCM enjoys the data-free merit by employing synthetic data from the teacher for distillation. With just 70 training hours on an A100 GPU, a 3-step TLCM distilled from SDXL achieves an impressive CLIP Score of 33.68 and an Aesthetic Score of 5.97 on the MSCOCO-2017 5K benchmark, surpassing various accelerated models and even outperforming the teacher model in human preference metrics. We also demonstrate the versatility of TLCMs in applications including image style transfer, controllable generation, and Chinese-to-image generation.", "published": "2024-10-31 04:00:00", "id": "7488f9ca-f4f8-460d-93d0-4e1a280bb608", "source": "arxiv", "section": "computerScience"}, {"title": "VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction", "link": "https://arxiv.org/abs/2406.05774", "description": "arXiv:2406.05774v2 Announce Type: replace \nAbstract: Although 3D Gaussian Splatting has been widely studied because of its realistic and efficient novel-view synthesis, it is still challenging to extract a high-quality surface from the point-based representation. Previous works improve the surface by incorporating geometric priors from the off-the-shelf normal estimator. However, there are two main limitations: 1) Supervising normals rendered from 3D Gaussians effectively updates the rotation parameter but is less effective for other geometric parameters; 2) The inconsistency of predicted normal maps across multiple views may lead to severe reconstruction artifacts. In this paper, we propose a Depth-Normal regularizer that directly couples normal with other geometric parameters, leading to full updates of the geometric parameters from normal regularization. We further propose a confidence term to mitigate inconsistencies of normal predictions across multiple views. Moreover, we also introduce a densification and splitting strategy to regularize the size and distribution of 3D Gaussians for more accurate surface modeling. Compared with Gaussian-based baselines, experiments show that our approach obtains better reconstruction quality and maintains competitive appearance quality at faster training speed and 100+ FPS rendering.", "published": "2024-10-31 04:00:00", "id": "8da0f17c-24aa-4184-98f8-a2d993ff71a0", "source": "arxiv", "section": "computerScience"}, {"title": "CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models", "link": "https://arxiv.org/abs/2406.06007", "description": "arXiv:2406.06007v2 Announce Type: replace \nAbstract: Artificial intelligence has significantly impacted medical applications, particularly with the advent of Medical Large Vision Language Models (Med-LVLMs), sparking optimism for the future of automated and personalized healthcare. However, the trustworthiness of Med-LVLMs remains unverified, posing significant risks for future model deployment. In this paper, we introduce CARES and aim to comprehensively evaluate the Trustworthiness of Med-LVLMs across the medical domain. We assess the trustworthiness of Med-LVLMs across five dimensions, including trustfulness, fairness, safety, privacy, and robustness. CARES comprises about 41K question-answer pairs in both closed and open-ended formats, covering 16 medical image modalities and 27 anatomical regions. Our analysis reveals that the models consistently exhibit concerns regarding trustworthiness, often displaying factual inaccuracies and failing to maintain fairness across different demographic groups. Furthermore, they are vulnerable to attacks and demonstrate a lack of privacy awareness. We publicly release our benchmark and code in https://cares-ai.github.io/.", "published": "2024-10-31 04:00:00", "id": "63548029-9fb9-4ded-8f54-12dfa88560f1", "source": "arxiv", "section": "computerScience"}, {"title": "Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text", "link": "https://arxiv.org/abs/2406.06056", "description": "arXiv:2406.06056v2 Announce Type: replace \nAbstract: Social and behavioral determinants of health (SBDH) play a crucial role in health outcomes and are frequently documented in clinical text. Automatically extracting SBDH information from clinical text relies on publicly available good-quality datasets. However, existing SBDH datasets exhibit substantial limitations in their availability and coverage. In this study, we introduce Synth-SBDH, a novel synthetic dataset with detailed SBDH annotations, encompassing status, temporal information, and rationale across 15 SBDH categories. We showcase the utility of Synth-SBDH on three tasks using real-world clinical datasets from two distinct hospital settings, highlighting its versatility, generalizability, and distillation capabilities. Models trained on Synth-SBDH consistently outperform counterparts with no Synth-SBDH training, achieving up to 63.75% macro-F improvements. Additionally, Synth-SBDH proves effective for rare SBDH categories and under-resource constraints while being substantially cheaper than expert-annotated real-world data. Human evaluation reveals a 71.06% Human-LLM alignment and uncovers areas for future refinements.", "published": "2024-10-31 04:00:00", "id": "936e4e1c-3565-4e0d-b0eb-9cbc8e2ee8c3", "source": "arxiv", "section": "computerScience"}, {"title": "VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs", "link": "https://arxiv.org/abs/2406.07476", "description": "arXiv:2406.07476v3 Announce Type: replace \nAbstract: In this paper, we present the VideoLLaMA 2, a set of Video Large Language Models (Video-LLMs) designed to enhance spatial-temporal modeling and audio understanding in video and audio-oriented tasks. Building upon its predecessor, VideoLLaMA 2 incorporates a tailor-made Spatial-Temporal Convolution (STC) connector, which effectively captures the intricate spatial and temporal dynamics of video data. Additionally, we integrate an Audio Branch into the model through joint training, thereby enriching the multimodal understanding capabilities of the model by seamlessly incorporating audio cues. Comprehensive evaluations on multiple-choice video question answering (MC-VQA), open-ended video question answering (OE-VQA), and video captioning (VC) tasks demonstrate that VideoLLaMA 2 consistently achieves competitive results among open-source models and even gets close to some proprietary models on several benchmarks. Furthermore, VideoLLaMA 2 exhibits reasonable improvements in audio-only and audio-video question-answering (AQA & OE-AVQA) benchmarks over existing models. These advancements underline VideoLLaMA 2's superior performance in multimodal comprehension, setting a new standard for intelligent video analysis systems. All models are public to facilitate further research.", "published": "2024-10-31 04:00:00", "id": "6e17fe5f-c990-40f2-8281-e468a19d704c", "source": "arxiv", "section": "computerScience"}, {"title": "Diff-A-Riff: Musical Accompaniment Co-creation via Latent Diffusion Models", "link": "https://arxiv.org/abs/2406.08384", "description": "arXiv:2406.08384v2 Announce Type: replace \nAbstract: Recent advancements in deep generative models present new opportunities for music production but also pose challenges, such as high computational demands and limited audio quality. Moreover, current systems frequently rely solely on text input and typically focus on producing complete musical pieces, which is incompatible with existing workflows in music production. To address these issues, we introduce \"Diff-A-Riff,\" a Latent Diffusion Model designed to generate high-quality instrumental accompaniments adaptable to any musical context. This model offers control through either audio references, text prompts, or both, and produces 48kHz pseudo-stereo audio while significantly reducing inference time and memory usage. We demonstrate the model's capabilities through objective metrics and subjective listening tests, with extensive examples available on the accompanying website: sonycslparis.github.io/diffariff-companion/", "published": "2024-10-31 04:00:00", "id": "a6733e4d-4a93-482a-bf04-86985cb362fa", "source": "arxiv", "section": "computerScience"}, {"title": "Scaling Laws in Linear Regression: Compute, Parameters, and Data", "link": "https://arxiv.org/abs/2406.08466", "description": "arXiv:2406.08466v2 Announce Type: replace \nAbstract: Empirically, large-scale deep learning models often satisfy a neural scaling law: the test error of the trained model improves polynomially as the model size and data size grow. However, conventional wisdom suggests the test error consists of approximation, bias, and variance errors, where the variance error increases with model size. This disagrees with the general form of neural scaling laws, which predict that increasing model size monotonically improves performance.\n  We study the theory of scaling laws in an infinite dimensional linear regression setup. Specifically, we consider a model with $M$ parameters as a linear function of sketched covariates. The model is trained by one-pass stochastic gradient descent (SGD) using $N$ data. Assuming the optimal parameter satisfies a Gaussian prior and the data covariance matrix has a power-law spectrum of degree $a>1$, we show that the reducible part of the test error is $\\Theta(M^{-(a-1)} + N^{-(a-1)/a})$. The variance error, which increases with $M$, is dominated by the other errors due to the implicit regularization of SGD, thus disappearing from the bound. Our theory is consistent with the empirical neural scaling laws and verified by numerical simulation.", "published": "2024-10-31 04:00:00", "id": "0ef28783-32db-4a6c-beae-c28740cbe150", "source": "arxiv", "section": "computerScience"}, {"title": "Time-MMD: A New Multi-Domain Multimodal Dataset for Time Series Analysis", "link": "https://arxiv.org/abs/2406.08627", "description": "arXiv:2406.08627v2 Announce Type: replace \nAbstract: Time series data are ubiquitous across a wide range of real-world domains. While real-world time series analysis (TSA) requires human experts to integrate numerical series data with multimodal domain-specific knowledge, most existing TSA models rely solely on numerical data, overlooking the significance of information beyond numerical series. This oversight is due to the untapped potential of textual series data and the absence of a comprehensive, high-quality multimodal dataset. To overcome this obstacle, we introduce Time-MMD, the first multi-domain, multimodal time series dataset covering 9 primary data domains. Time-MMD ensures fine-grained modality alignment, eliminates data contamination, and provides high usability. Additionally, we develop MM-TSFlib, the first multimodal time-series forecasting (TSF) library, seamlessly pipelining multimodal TSF evaluations based on Time-MMD for in-depth analyses. Extensive experiments conducted on Time-MMD through MM-TSFlib demonstrate significant performance enhancements by extending unimodal TSF to multimodality, evidenced by over 15% mean squared error reduction in general, and up to 40% in domains with rich textual data. More importantly, our datasets and library revolutionize broader applications, impacts, research topics to advance TSA. The dataset and library are available at https://github.com/AdityaLab/Time-MMD and https://github.com/AdityaLab/MM-TSFlib.", "published": "2024-10-31 04:00:00", "id": "b212c11e-a7fb-4a37-a5b7-cfedd8486adf", "source": "arxiv", "section": "computerScience"}, {"title": "DenoiseRep: Denoising Model for Representation Learning", "link": "https://arxiv.org/abs/2406.08773", "description": "arXiv:2406.08773v2 Announce Type: replace \nAbstract: The denoising model has been proven a powerful generative model but has little exploration of discriminative tasks. Representation learning is important in discriminative tasks, which is defined as \"learning representations (or features) of the data that make it easier to extract useful information when building classifiers or other predictors\". In this paper, we propose a novel Denoising Model for Representation Learning (DenoiseRep) to improve feature discrimination with joint feature extraction and denoising. DenoiseRep views each embedding layer in a backbone as a denoising layer, processing the cascaded embedding layers as if we are recursively denoise features step-by-step. This unifies the frameworks of feature extraction and denoising, where the former progressively embeds features from low-level to high-level, and the latter recursively denoises features step-by-step. After that, DenoiseRep fuses the parameters of feature extraction and denoising layers, and theoretically demonstrates its equivalence before and after the fusion, thus making feature denoising computation-free. DenoiseRep is a label-free algorithm that incrementally improves features but also complementary to the label if available. Experimental results on various discriminative vision tasks, including re-identification (Market-1501, DukeMTMC-reID, MSMT17, CUHK-03, vehicleID), image classification (ImageNet, UB200, Oxford-Pet, Flowers), object detection (COCO), image segmentation (ADE20K) show stability and impressive improvements. We also validate its effectiveness on the CNN (ResNet) and Transformer (ViT, Swin, Vmamda) architectures.", "published": "2024-10-31 04:00:00", "id": "bf8a62e2-005f-4e96-a7b6-5a669068fa6d", "source": "arxiv", "section": "computerScience"}, {"title": "Schur's Positive-Definite Network: Deep Learning in the SPD cone with structure", "link": "https://arxiv.org/abs/2406.09023", "description": "arXiv:2406.09023v3 Announce Type: replace \nAbstract: Estimating matrices in the symmetric positive-definite (SPD) cone is of interest for many applications ranging from computer vision to graph learning. While there exist various convex optimization-based estimators, they remain limited in expressivity due to their model-based approach. The success of deep learning motivates the use of learning-based approaches to estimate SPD matrices with neural networks in a data-driven fashion. However, designing effective neural architectures for SPD learning is challenging, particularly when the task requires additional structural constraints, such as element-wise sparsity. Current approaches either do not ensure that the output meets all desired properties or lack expressivity. In this paper, we introduce SpodNet, a novel and generic learning module that guarantees SPD outputs and supports additional structural constraints. Notably, it solves the challenging task of learning jointly SPD and sparse matrices. Our experiments illustrate the versatility and relevance of SpodNet layers for such applications.", "published": "2024-10-31 04:00:00", "id": "3c4a4a57-f117-4d8a-8fe1-4090e04cdfdc", "source": "arxiv", "section": "computerScience"}, {"title": "Dispelling the Mirage of Progress in Offline MARL through Standardised Baselines and Evaluation", "link": "https://arxiv.org/abs/2406.09068", "description": "arXiv:2406.09068v3 Announce Type: replace \nAbstract: Offline multi-agent reinforcement learning (MARL) is an emerging field with great promise for real-world applications. Unfortunately, the current state of research in offline MARL is plagued by inconsistencies in baselines and evaluation protocols, which ultimately makes it difficult to accurately assess progress, trust newly proposed innovations, and allow researchers to easily build upon prior work. In this paper, we firstly identify significant shortcomings in existing methodologies for measuring the performance of novel algorithms through a representative study of published offline MARL work. Secondly, by directly comparing to this prior work, we demonstrate that simple, well-implemented baselines can achieve state-of-the-art (SOTA) results across a wide range of tasks. Specifically, we show that on 35 out of 47 datasets used in prior work (almost 75% of cases), we match or surpass the performance of the current purported SOTA. Strikingly, our baselines often substantially outperform these more sophisticated algorithms. Finally, we correct for the shortcomings highlighted from this prior work by introducing a straightforward standardised methodology for evaluation and by providing our baseline implementations with statistically robust results across several scenarios, useful for comparisons in future work. Our proposal includes simple and sensible steps that are easy to adopt, which in combination with solid baselines and comparative results, could substantially improve the overall rigour of empirical science in offline MARL moving forward.", "published": "2024-10-31 04:00:00", "id": "740674b9-752c-4cdf-bb64-5d2c6a08b631", "source": "arxiv", "section": "computerScience"}, {"title": "On the Worst Prompt Performance of Large Language Models", "link": "https://arxiv.org/abs/2406.10248", "description": "arXiv:2406.10248v4 Announce Type: replace \nAbstract: The performance of large language models (LLMs) is acutely sensitive to the phrasing of prompts, which raises significant concerns about their reliability in real-world scenarios. Existing studies often divide prompts into task-level instructions and case-level inputs and primarily focus on evaluating and improving robustness against variations in tasks-level instructions. However, this setup fails to fully address the diversity of real-world user queries and assumes the existence of task-specific datasets. To address these limitations, we introduce RobustAlpacaEval, a new benchmark that consists of semantically equivalent case-level queries and emphasizes the importance of using the worst prompt performance to gauge the lower bound of model performance. Extensive experiments on RobustAlpacaEval with ChatGPT and six open-source LLMs from the Llama, Mistral, and Gemma families uncover substantial variability in model performance; for instance, a difference of 45.48% between the worst and best performance for the Llama-2-70B-chat model, with its worst performance dipping as low as 9.38%. We further illustrate the difficulty in identifying the worst prompt from both model-agnostic and model-dependent perspectives, emphasizing the absence of a shortcut to characterize the worst prompt. We also attempt to enhance the worst prompt performance using existing prompt engineering and prompt consistency methods, but find that their impact is limited. These findings underscore the need to create more resilient LLMs that can maintain high performance across diverse prompts. Data and code are available at https://github.com/cbwbuaa/On-the-Worst-Prompt- Performance-of-LLMs.", "published": "2024-10-31 04:00:00", "id": "550ab5ae-e6e3-4500-aa40-a138c89a145a", "source": "arxiv", "section": "computerScience"}, {"title": "Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences", "link": "https://arxiv.org/abs/2406.10427", "description": "arXiv:2406.10427v2 Announce Type: replace \nAbstract: We propose Adaptive Randomized Smoothing (ARS) to certify the predictions of our test-time adaptive models against adversarial examples. ARS extends the analysis of randomized smoothing using $f$-Differential Privacy to certify the adaptive composition of multiple steps. For the first time, our theory covers the sound adaptive composition of general and high-dimensional functions of noisy inputs. We instantiate ARS on deep image classification to certify predictions against adversarial examples of bounded $L_{\\infty}$ norm. In the $L_{\\infty}$ threat model, ARS enables flexible adaptation through high-dimensional input-dependent masking. We design adaptivity benchmarks, based on CIFAR-10 and CelebA, and show that ARS improves standard test accuracy by $1$ to $15\\%$ points. On ImageNet, ARS improves certified test accuracy by up to $1.6\\%$ points over standard RS without adaptivity. Our code is available at https://github.com/ubc-systopia/adaptive-randomized-smoothing .", "published": "2024-10-31 04:00:00", "id": "04844ab8-e2e9-4653-8c37-23749a609c28", "source": "arxiv", "section": "computerScience"}, {"title": "Exploring Parent-Child Perceptions on Safety in Generative AI: Concerns, Mitigation Strategies, and Design Implications", "link": "https://arxiv.org/abs/2406.10461", "description": "arXiv:2406.10461v2 Announce Type: replace \nAbstract: The widespread use of Generative Artificial Intelligence (GAI) among teenagers has led to significant misuse and safety concerns. To identify risks and understand parental controls challenges, we conducted a content analysis on Reddit and interviewed 20 participants (seven teenagers and 13 parents). Our study reveals a significant gap in parental awareness of the extensive ways children use GAI, such as interacting with character-based chatbots for emotional support or engaging in virtual relationships. Parents and children report differing perceptions of risks associated with GAI. Parents primarily express concerns about data collection, misinformation, and exposure to inappropriate content. In contrast, teenagers are more concerned about becoming addicted to virtual relationships with GAI, the potential misuse of GAI to spread harmful content in social groups, and the invasion of privacy due to unauthorized use of their personal data in GAI applications. The absence of parental control features on GAI platforms forces parents to rely on system-built controls, manually check histories, share accounts, and engage in active mediation. Despite these efforts, parents struggle to grasp the full spectrum of GAI-related risks and to perform effective real-time monitoring, mediation, and education. We provide design recommendations to improve parent-child communication and enhance the safety of GAI use.", "published": "2024-10-31 04:00:00", "id": "dfd4a7a3-f416-4faf-b4c9-4dbba89342e9", "source": "arxiv", "section": "computerScience"}, {"title": "CoLoR-Filter: Conditional Loss Reduction Filtering for Targeted Language Model Pre-training", "link": "https://arxiv.org/abs/2406.10670", "description": "arXiv:2406.10670v3 Announce Type: replace \nAbstract: Selecting high-quality data for pre-training is crucial in shaping the downstream task performance of language models. A major challenge lies in identifying this optimal subset, a problem generally considered intractable, thus necessitating scalable and effective heuristics. In this work, we propose a data selection method, CoLoR-Filter (Conditional Loss Reduction Filtering), which leverages an empirical Bayes-inspired approach to derive a simple and computationally efficient selection criterion based on the relative loss values of two auxiliary models.\n  In addition to the modeling rationale, we evaluate CoLoR-Filter empirically on two language modeling tasks: (1) selecting data from C4 for domain adaptation to evaluation on Books and (2) selecting data from C4 for a suite of downstream multiple-choice question answering tasks. We demonstrate favorable scaling both as we subselect more aggressively and using small auxiliary models to select data for large target models. As one headline result, CoLoR-Filter data selected using a pair of 150m parameter auxiliary models can train a 1.2b parameter target model to match a 1.2b parameter model trained on 25b randomly selected tokens with 25x less data for Books and 11x less data for the downstream tasks.\n  Code: https://github.com/davidbrandfonbrener/color-filter-olmo\n  Filtered data: https://huggingface.co/datasets/davidbrandfonbrener/color-filtered-c4", "published": "2024-10-31 04:00:00", "id": "ebee90ad-712d-4d37-9228-0879a2c4e189", "source": "arxiv", "section": "computerScience"}, {"title": "Scale Equivariant Graph Metanetworks", "link": "https://arxiv.org/abs/2406.10685", "description": "arXiv:2406.10685v2 Announce Type: replace \nAbstract: This paper pertains to an emerging machine learning paradigm: learning higher-order functions, i.e. functions whose inputs are functions themselves, $\\textit{particularly when these inputs are Neural Networks (NNs)}$. With the growing interest in architectures that process NNs, a recurring design principle has permeated the field: adhering to the permutation symmetries arising from the connectionist structure of NNs. $\\textit{However, are these the sole symmetries present in NN parameterizations}$? Zooming into most practical activation functions (e.g. sine, ReLU, tanh) answers this question negatively and gives rise to intriguing new symmetries, which we collectively refer to as $\\textit{scaling symmetries}$, that is, non-zero scalar multiplications and divisions of weights and biases. In this work, we propose $\\textit{Scale Equivariant Graph MetaNetworks - ScaleGMNs}$, a framework that adapts the Graph Metanetwork (message-passing) paradigm by incorporating scaling symmetries and thus rendering neuron and edge representations equivariant to valid scalings. We introduce novel building blocks, of independent technical interest, that allow for equivariance or invariance with respect to individual scalar multipliers or their product and use them in all components of ScaleGMN. Furthermore, we prove that, under certain expressivity conditions, ScaleGMN can simulate the forward and backward pass of any input feedforward neural network. Experimental results demonstrate that our method advances the state-of-the-art performance for several datasets and activation functions, highlighting the power of scaling symmetries as an inductive bias for NN processing. The source code is publicly available at https://github.com/jkalogero/scalegmn.", "published": "2024-10-31 04:00:00", "id": "a27711e8-2e94-421c-b12a-43d6a60a569c", "source": "arxiv", "section": "computerScience"}, {"title": "BSRBF-KAN: A combination of B-splines and Radial Basis Functions in Kolmogorov-Arnold Networks", "link": "https://arxiv.org/abs/2406.11173", "description": "arXiv:2406.11173v5 Announce Type: replace \nAbstract: In this paper, we introduce BSRBF-KAN, a Kolmogorov Arnold Network (KAN) that combines B-splines and radial basis functions (RBFs) to fit input vectors during data training. We perform experiments with BSRBF-KAN, multi-layer perception (MLP), and other popular KANs, including EfficientKAN, FastKAN, FasterKAN, and GottliebKAN over the MNIST and Fashion-MNIST datasets. BSRBF-KAN shows stability in 5 training runs with a competitive average accuracy of 97.55% on MNIST and 89.33% on Fashion-MNIST and obtains convergence better than other networks. We expect BSRBF-KAN to open many combinations of mathematical functions to design KANs. Our repo is publicly available at: https://github.com/hoangthangta/BSRBF_KAN.", "published": "2024-10-31 04:00:00", "id": "12f9d0d3-32a1-4c4e-9092-e49f9926af46", "source": "arxiv", "section": "computerScience"}, {"title": "QTIP: Quantization with Trellises and Incoherence Processing", "link": "https://arxiv.org/abs/2406.11235", "description": "arXiv:2406.11235v3 Announce Type: replace \nAbstract: Post-training quantization (PTQ) reduces the memory footprint of LLMs by quantizing weights to low-precision datatypes. Since LLM inference is usually memory-bound, PTQ methods can improve inference throughput. Recent state-of-the-art PTQ approaches use vector quantization (VQ) to quantize multiple weights at once, which improves information utilization through better shaping. However, VQ requires a codebook with size exponential in the dimension. This limits current VQ-based PTQ works to low VQ dimensions ($\\le 8$) that in turn limit quantization quality. Here, we introduce QTIP, which instead uses trellis coded quantization (TCQ) to achieve ultra-high-dimensional quantization. TCQ uses a stateful decoder that separates the codebook size from the bitrate and effective dimension. QTIP introduces a spectrum of lookup-only to computed lookup-free trellis codes designed for a hardware-efficient \"bitshift\" trellis structure; these codes achieve state-of-the-art results in both quantization quality and inference speed.", "published": "2024-10-31 04:00:00", "id": "eb647181-6bb0-4dfa-9206-51d5f64a5bd2", "source": "arxiv", "section": "computerScience"}, {"title": "BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models", "link": "https://arxiv.org/abs/2406.11675", "description": "arXiv:2406.11675v4 Announce Type: replace \nAbstract: Large Language Models (LLMs) often suffer from overconfidence during inference, particularly when adapted to downstream domain-specific tasks with limited data. Previous work addresses this issue by employing approximate Bayesian estimation after the LLMs are trained, enabling them to quantify uncertainty. However, such post-training approaches' performance is severely limited by the parameters learned during training. In this paper, we go beyond post-training Bayesianization and propose Bayesian Low-Rank Adaptation by Backpropagation (BLoB), an algorithm that continuously and jointly adjusts both the mean and covariance of LLM parameters throughout the whole fine-tuning process. Our empirical results verify the effectiveness of BLoB in terms of generalization and uncertainty estimation, when evaluated on both in-distribution and out-of-distribution data.", "published": "2024-10-31 04:00:00", "id": "67495734-6a70-4b04-9d33-77b3d2e246e3", "source": "arxiv", "section": "computerScience"}, {"title": "How Do Large Language Models Acquire Factual Knowledge During Pretraining?", "link": "https://arxiv.org/abs/2406.11813", "description": "arXiv:2406.11813v2 Announce Type: replace \nAbstract: Despite the recent observation that large language models (LLMs) can store substantial factual knowledge, there is a limited understanding of the mechanisms of how they acquire factual knowledge through pretraining. This work addresses this gap by studying how LLMs acquire factual knowledge during pretraining. The findings reveal several important insights into the dynamics of factual knowledge acquisition during pretraining. First, counterintuitively, we observe that pretraining on more data shows no significant improvement in the model's capability to acquire and maintain factual knowledge. Next, there is a power-law relationship between training steps and forgetting of memorization and generalization of factual knowledge, and LLMs trained with duplicated training data exhibit faster forgetting. Third, training LLMs with larger batch sizes can enhance the models' robustness to forgetting. Overall, our observations suggest that factual knowledge acquisition in LLM pretraining occurs by progressively increasing the probability of factual knowledge presented in the pretraining data at each step. However, this increase is diluted by subsequent forgetting. Based on this interpretation, we demonstrate that we can provide plausible explanations for recently observed behaviors of LLMs, such as the poor performance of LLMs on long-tail knowledge and the benefits of deduplicating the pretraining corpus.", "published": "2024-10-31 04:00:00", "id": "7e4b9d37-f158-4bfe-928f-82f02381738c", "source": "arxiv", "section": "computerScience"}, {"title": "The EarlyBird Gets the WORM: Heuristically Accelerating EarlyBird Convergence", "link": "https://arxiv.org/abs/2406.11872", "description": "arXiv:2406.11872v2 Announce Type: replace \nAbstract: The Lottery Ticket hypothesis proposes that ideal, sparse subnetworks, called lottery tickets, exist in untrained dense neural networks. The Early Bird hypothesis proposes an efficient algorithm to find these winning lottery tickets in convolutional neural networks, using the novel concept of distance between subnetworks to detect convergence in the subnetworks of a model. However, this approach overlooks unchanging groups of unimportant neurons near the search's end. We proposes WORM, a method that exploits these static groups by truncating their gradients, forcing the model to rely on other neurons. Experiments show WORM achieves faster ticket identification during training on convolutional neural networks, despite the additional computational overhead, when compared to EarlyBird search. Additionally, WORM-pruned models lose less accuracy during pruning and recover accuracy faster, improving the robustness of a given model. Furthermore, WORM is also able to generalize the Early Bird hypothesis reasonably well to larger models, such as transformers, displaying its flexibility to adapt to more complex architectures.", "published": "2024-10-31 04:00:00", "id": "dc8e9725-daee-4b83-b5f0-7489f1f16bb5", "source": "arxiv", "section": "computerScience"}, {"title": "Unleashing the Potential of Open-set Noisy Samples Against Label Noise for Medical Image Classification", "link": "https://arxiv.org/abs/2406.12293", "description": "arXiv:2406.12293v2 Announce Type: replace \nAbstract: Addressing mixed closed-set and open-set label noise in medical image classification remains a largely unexplored challenge. Unlike natural image classification, which often separates and processes closed-set and open-set noisy samples from clean ones, medical image classification contends with high inter-class similarity, complicating the identification of open-set noisy samples. Additionally, existing methods often fail to fully utilize open-set noisy samples for label noise mitigation, leading to their exclusion or the application of uniform soft labels. To address these challenges, we propose the Extended Noise-robust Contrastive and Open-set Feature Augmentation framework for medical image classification tasks. This framework incorporates the Extended Noise-robust Supervised Contrastive Loss, which helps differentiate features among both in-distribution and out-of-distribution classes. This loss treats open-set noisy samples as an extended class, improving label noise mitigation by weighting contrastive pairs according to label reliability. Additionally, we develop the Open-set Feature Augmentation module that enriches open-set samples at the feature level and then assigns them dynamic class labels, thereby leveraging the model's capacity and reducing overfitting to noisy data. We evaluated the proposed framework on both a synthetic noisy dataset and a real-world noisy dataset. The results indicate the superiority of our framework over four existing methods and the effectiveness of leveraging open-set noisy samples to combat label noise.", "published": "2024-10-31 04:00:00", "id": "b41c3d0c-0087-4b99-a4af-7e45b908ca8b", "source": "arxiv", "section": "computerScience"}, {"title": "Mixture of Scales: Memory-Efficient Token-Adaptive Binarization for Large Language Models", "link": "https://arxiv.org/abs/2406.12311", "description": "arXiv:2406.12311v2 Announce Type: replace \nAbstract: Binarization, which converts weight parameters to binary values, has emerged as an effective strategy to reduce the size of large language models (LLMs). However, typical binarization techniques significantly diminish linguistic effectiveness of LLMs. To address this issue, we introduce a novel binarization technique called Mixture of Scales (BinaryMoS). Unlike conventional methods, BinaryMoS employs multiple scaling experts for binary weights, dynamically merging these experts for each token to adaptively generate scaling factors. This token-adaptive approach boosts the representational power of binarized LLMs by enabling contextual adjustments to the values of binary weights. Moreover, because this adaptive process only involves the scaling factors rather than the entire weight matrix, BinaryMoS maintains compression efficiency similar to traditional static binarization methods. Our experimental results reveal that BinaryMoS surpasses conventional binarization techniques in various natural language processing tasks and even outperforms 2-bit quantization methods, all while maintaining similar model size to static binarization techniques.", "published": "2024-10-31 04:00:00", "id": "5be1691f-e8d8-4559-9d54-337d19ca0fc4", "source": "arxiv", "section": "computerScience"}, {"title": "From Instance Training to Instruction Learning: Task Adapters Generation from Instructions", "link": "https://arxiv.org/abs/2406.12382", "description": "arXiv:2406.12382v2 Announce Type: replace \nAbstract: Large language models (LLMs) have acquired the ability to solve general tasks by utilizing instruction finetuning (IFT). However, IFT still relies heavily on instance training of extensive task data, which greatly limits the adaptability of LLMs to real-world scenarios where labeled task instances are scarce and broader task generalization becomes paramount. Contrary to LLMs, humans acquire skills and complete tasks not merely through repeated practice but also by understanding and following instructional guidelines. This paper is dedicated to simulating human learning to address the shortcomings of instance training, focusing on instruction learning to enhance cross-task generalization. Within this context, we introduce Task Adapters Generation from Instructions (TAGI), which automatically constructs the task-specific model in a parameter generation manner based on the given task instructions without retraining for unseen tasks. Specifically, we utilize knowledge distillation to enhance the consistency between TAGI developed through Learning with Instruction and task-specific models developed through Training with Instance, by aligning the labels, output logits, and adapter parameters between them. TAGI is endowed with cross-task generalization capabilities through a two-stage training process that includes hypernetwork pretraining and finetuning. We evaluate TAGI on the Super-Natural Instructions and P3 datasets. The experimental results demonstrate that TAGI can match or even outperform traditional meta-trained models and other hypernetwork models, while significantly reducing computational requirements.", "published": "2024-10-31 04:00:00", "id": "508a10b3-229a-40f3-858b-1ce04770e874", "source": "arxiv", "section": "computerScience"}, {"title": "HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors", "link": "https://arxiv.org/abs/2406.12459", "description": "arXiv:2406.12459v2 Announce Type: replace \nAbstract: Despite recent advancements in high-fidelity human reconstruction techniques, the requirements for densely captured images or time-consuming per-instance optimization significantly hinder their applications in broader scenarios. To tackle these issues, we present HumanSplat which predicts the 3D Gaussian Splatting properties of any human from a single input image in a generalizable manner. In particular, HumanSplat comprises a 2D multi-view diffusion model and a latent reconstruction transformer with human structure priors that adeptly integrate geometric priors and semantic features within a unified framework. A hierarchical loss that incorporates human semantic information is further designed to achieve high-fidelity texture modeling and better constrain the estimated multiple views. Comprehensive experiments on standard benchmarks and in-the-wild images demonstrate that HumanSplat surpasses existing state-of-the-art methods in achieving photorealistic novel-view synthesis.", "published": "2024-10-31 04:00:00", "id": "10e41c4a-f26e-47de-9d9f-070f89633e6a", "source": "arxiv", "section": "computerScience"}, {"title": "Stealth edits to large language models", "link": "https://arxiv.org/abs/2406.12670", "description": "arXiv:2406.12670v2 Announce Type: replace \nAbstract: We reveal the theoretical foundations of techniques for editing large language models, and present new methods which can do so without requiring retraining. Our theoretical insights show that a single metric (a measure of the intrinsic dimension of the model's features) can be used to assess a model's editability and reveals its previously unrecognised susceptibility to malicious stealth attacks. This metric is fundamental to predicting the success of a variety of editing approaches, and reveals new bridges between disparate families of editing methods. We collectively refer to these as stealth editing methods, because they directly update a model's weights to specify its response to specific known hallucinating prompts without affecting other model behaviour. By carefully applying our theoretical insights, we are able to introduce a new jet-pack network block which is optimised for highly selective model editing, uses only standard network operations, and can be inserted into existing networks. We also reveal the vulnerability of language models to stealth attacks: a small change to a model's weights which fixes its response to a single attacker-chosen prompt. Stealth attacks are computationally simple, do not require access to or knowledge of the model's training data, and therefore represent a potent yet previously unrecognised threat to redistributed foundation models. Extensive experimental results illustrate and support our methods and their theoretical underpinnings. Demos and source code are available at https://github.com/qinghua-zhou/stealth-edits.", "published": "2024-10-31 04:00:00", "id": "64254139-88bd-449c-a622-0e1e1d97229e", "source": "arxiv", "section": "computerScience"}, {"title": "Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation", "link": "https://arxiv.org/abs/2406.12849", "description": "arXiv:2406.12849v2 Announce Type: replace \nAbstract: Accurately estimating depth in 360-degree imagery is crucial for virtual reality, autonomous navigation, and immersive media applications. Existing depth estimation methods designed for perspective-view imagery fail when applied to 360-degree images due to different camera projections and distortions, whereas 360-degree methods perform inferior due to the lack of labeled data pairs. We propose a new depth estimation framework that utilizes unlabeled 360-degree data effectively. Our approach uses state-of-the-art perspective depth estimation models as teacher models to generate pseudo labels through a six-face cube projection technique, enabling efficient labeling of depth in 360-degree images. This method leverages the increasing availability of large datasets. Our approach includes two main stages: offline mask generation for invalid regions and an online semi-supervised joint training regime. We tested our approach on benchmark datasets such as Matterport3D and Stanford2D3D, showing significant improvements in depth estimation accuracy, particularly in zero-shot scenarios. Our proposed training pipeline can enhance any 360 monocular depth estimator and demonstrates effective knowledge transfer across different camera projections and data types. See our project page for results: https://albert100121.github.io/Depth-Anywhere/", "published": "2024-10-31 04:00:00", "id": "25db7ede-7679-4e3a-b1fd-d4dfe1736535", "source": "arxiv", "section": "computerScience"}, {"title": "LIVE: Learnable In-Context Vector for Visual Question Answering", "link": "https://arxiv.org/abs/2406.13185", "description": "arXiv:2406.13185v2 Announce Type: replace \nAbstract: As language models continue to scale, Large Language Models (LLMs) have exhibited emerging capabilities in In-Context Learning (ICL), enabling them to solve language tasks by prefixing a few in-context demonstrations (ICDs) as context. Inspired by these advancements, researchers have extended these techniques to develop Large Multimodal Models (LMMs) with ICL capabilities. However, applying ICL usually faces two major challenges: 1) using more ICDs will largely increase the inference time and 2) the performance is sensitive to the selection of ICDs. These challenges are further exacerbated in LMMs due to the integration of multiple data types and the combinational complexity of multimodal ICDs. Recently, to address these challenges, some NLP studies introduce non-learnable In-Context Vectors (ICVs) which extract useful task information from ICDs into a single vector and then insert it into the LLM to help solve the corresponding task. However, although useful in simple NLP tasks, these non-learnable methods fail to handle complex multimodal tasks like Visual Question Answering (VQA). In this study, we propose \\underline{\\textbf{L}}earnable \\underline{\\textbf{I}}n-Context \\underline{\\textbf{Ve}}ctor (LIVE) to distill essential task information from demonstrations, improving ICL performance in LMMs. Experiments show that LIVE can significantly reduce computational costs while enhancing accuracy in VQA tasks compared to traditional ICL and other non-learnable ICV methods. The code is available at \\url{https://github.com/ForJadeForest/LIVE-Learnable-In-Context-Vector}.", "published": "2024-10-31 04:00:00", "id": "6f6a3d5e-c497-4ab1-9bcb-695ee386813b", "source": "arxiv", "section": "computerScience"}, {"title": "MC-MKE: A Fine-Grained Multimodal Knowledge Editing Benchmark Emphasizing Modality Consistency", "link": "https://arxiv.org/abs/2406.13219", "description": "arXiv:2406.13219v2 Announce Type: replace \nAbstract: Multimodal large language models (MLLMs) are prone to non-factual or outdated knowledge issues, which can manifest as misreading and misrecognition errors due to the complexity of multimodal knowledge. Previous benchmarks have not systematically analyzed the performance of editing methods in correcting these two error types. To better represent and correct these errors, we decompose multimodal knowledge into its visual and textual components. Different error types correspond to different editing formats, which edit distinct parts of the multimodal knowledge. We present MC-MKE, a fine-grained Multimodal Knowledge Editing benchmark emphasizing Modality Consistency. Our benchmark facilitates independent correction of misreading and misrecognition errors by editing the corresponding knowledge component. We evaluate four multimodal knowledge editing methods on MC-MKE, revealing their limitations, particularly in terms of modality consistency. Our work highlights the challenges posed by multimodal knowledge editing and motivates further research in developing effective techniques for this task.", "published": "2024-10-31 04:00:00", "id": "ac74cb11-8815-47d0-bf59-3352e98f2b37", "source": "arxiv", "section": "computerScience"}, {"title": "Data Contamination Can Cross Language Barriers", "link": "https://arxiv.org/abs/2406.13236", "description": "arXiv:2406.13236v2 Announce Type: replace \nAbstract: The opacity in developing large language models (LLMs) is raising growing concerns about the potential contamination of public benchmarks in the pre-training data. Existing contamination detection methods are typically based on the text overlap between training and evaluation data, which can be too superficial to reflect deeper forms of contamination. In this paper, we first present a cross-lingual form of contamination that inflates LLMs' performance while evading current detection methods, deliberately injected by overfitting LLMs on the translated versions of benchmark test sets. Then, we propose generalization-based approaches to unmask such deeply concealed contamination. Specifically, we examine the LLM's performance change after modifying the original benchmark by replacing the false answer choices with correct ones from other questions. Contaminated models can hardly generalize to such easier situations, where the false choices can be \\emph{not even wrong}, as all choices are correct in their memorization. Experimental results demonstrate that cross-lingual contamination can easily fool existing detection methods, but not ours. In addition, we discuss the potential utilization of cross-lingual contamination in interpreting LLMs' working mechanisms and in post-training LLMs for enhanced multilingual capabilities. The code and dataset we use can be obtained from \\url{https://github.com/ShangDataLab/Deep-Contam}.", "published": "2024-10-31 04:00:00", "id": "7b353acf-197b-4fa3-9bad-0f2c37f23f53", "source": "arxiv", "section": "computerScience"}, {"title": "R^2AG: Incorporating Retrieval Information into Retrieval Augmented Generation", "link": "https://arxiv.org/abs/2406.13249", "description": "arXiv:2406.13249v2 Announce Type: replace \nAbstract: Retrieval augmented generation (RAG) has been applied in many scenarios to augment large language models (LLMs) with external documents provided by retrievers. However, a semantic gap exists between LLMs and retrievers due to differences in their training objectives and architectures. This misalignment forces LLMs to passively accept the documents provided by the retrievers, leading to incomprehension in the generation process, where the LLMs are burdened with the task of distinguishing these documents using their inherent knowledge. This paper proposes R$^2$AG, a novel enhanced RAG framework to fill this gap by incorporating Retrieval information into Retrieval Augmented Generation. Specifically, R$^2$AG utilizes the nuanced features from the retrievers and employs a R$^2$-Former to capture retrieval information. Then, a retrieval-aware prompting strategy is designed to integrate retrieval information into LLMs' generation. Notably, R$^2$AG suits low-source scenarios where LLMs and retrievers are frozen. Extensive experiments across five datasets validate the effectiveness, robustness, and efficiency of R$^2$AG. Our analysis reveals that retrieval information serves as an anchor to aid LLMs in the generation process, thereby filling the semantic gap.", "published": "2024-10-31 04:00:00", "id": "3defc6bc-4896-4bf8-a984-3eda2048cf01", "source": "arxiv", "section": "computerScience"}, {"title": "Certification for Differentially Private Prediction in Gradient-Based Training", "link": "https://arxiv.org/abs/2406.13433", "description": "arXiv:2406.13433v2 Announce Type: replace \nAbstract: Differential privacy upper-bounds the information leakage of machine learning models, yet providing meaningful privacy guarantees has proven to be challenging in practice. The private prediction setting where model outputs are privatized is being investigated as an alternate way to provide formal guarantees at prediction time. Most current private prediction algorithms, however, rely on global sensitivity for noise calibration, which often results in large amounts of noise being added to the predictions. Data-specific noise calibration, such as smooth sensitivity, could significantly reduce the amount of noise added, but were so far infeasible to compute exactly for modern machine learning models. In this work we provide a novel and practical approach based on convex relaxation and bound propagation to compute a provable upper-bound for the local and smooth sensitivity of a prediction. This bound allows us to reduce the magnitude of noise added or improve privacy accounting in the private prediction setting. We validate our framework on datasets from financial services, medical image classification, and natural language processing and across models and find our approach to reduce the noise added by up to order of magnitude.", "published": "2024-10-31 04:00:00", "id": "9c3adf8a-ce5b-4740-9348-0b299e979672", "source": "arxiv", "section": "computerScience"}, {"title": "Optimal deep learning of holomorphic operators between Banach spaces", "link": "https://arxiv.org/abs/2406.13928", "description": "arXiv:2406.13928v2 Announce Type: replace \nAbstract: Operator learning problems arise in many key areas of scientific computing where Partial Differential Equations (PDEs) are used to model physical systems. In such scenarios, the operators map between Banach or Hilbert spaces. In this work, we tackle the problem of learning operators between Banach spaces, in contrast to the vast majority of past works considering only Hilbert spaces. We focus on learning holomorphic operators - an important class of problems with many applications. We combine arbitrary approximate encoders and decoders with standard feedforward Deep Neural Network (DNN) architectures - specifically, those with constant width exceeding the depth - under standard $\\ell^2$-loss minimization. We first identify a family of DNNs such that the resulting Deep Learning (DL) procedure achieves optimal generalization bounds for such operators. For standard fully-connected architectures, we then show that there are uncountably many minimizers of the training problem that yield equivalent optimal performance. The DNN architectures we consider are `problem agnostic', with width and depth only depending on the amount of training data $m$ and not on regularity assumptions of the target operator. Next, we show that DL is optimal for this problem: no recovery procedure can surpass these generalization bounds up to log terms. Finally, we present numerical results demonstrating the practical performance on challenging problems including the parametric diffusion, Navier-Stokes-Brinkman and Boussinesq PDEs.", "published": "2024-10-31 04:00:00", "id": "4cf2fd1d-7cb0-4338-802a-5090d35362d6", "source": "arxiv", "section": "computerScience"}, {"title": "MR-Ben: A Meta-Reasoning Benchmark for Evaluating System-2 Thinking in LLMs", "link": "https://arxiv.org/abs/2406.13975", "description": "arXiv:2406.13975v2 Announce Type: replace \nAbstract: Large language models (LLMs) have shown increasing capability in problem-solving and decision-making, largely based on the step-by-step chain-of-thought reasoning processes. However, evaluating these reasoning abilities has become increasingly challenging. Existing outcome-based benchmarks are beginning to saturate, becoming less effective in tracking meaningful progress. To address this, we present a process-based benchmark MR-Ben that demands a meta-reasoning skill, where LMs are asked to locate and analyse potential errors in automatically generated reasoning steps. Our meta-reasoning paradigm is especially suited for system-2 slow thinking, mirroring the human cognitive process of carefully examining assumptions, conditions, calculations, and logic to identify mistakes. MR-Ben comprises 5,975 questions curated by human experts across a wide range of subjects, including physics, chemistry, logic, coding, and more. Through our designed metrics for assessing meta-reasoning on this benchmark, we identify interesting limitations and weaknesses of current LLMs (open-source and closed-source models). For example, with models like the o1 series from OpenAI demonstrating strong performance by effectively scrutinizing the solution space, many other state-of-the-art models fall significantly behind on MR-Ben, exposing potential shortcomings in their training strategies and inference methodologies.", "published": "2024-10-31 04:00:00", "id": "3c2040a0-9d8d-4f72-b9af-fe024dc6067c", "source": "arxiv", "section": "computerScience"}, {"title": "Control when confidence is costly", "link": "https://arxiv.org/abs/2406.14427", "description": "arXiv:2406.14427v2 Announce Type: replace \nAbstract: We develop a version of stochastic control that accounts for computational costs of inference. Past studies identified efficient coding without control, or efficient control that neglects the cost of synthesizing information. Here we combine these concepts into a framework where agents rationally approximate inference for efficient control. Specifically, we study Linear Quadratic Gaussian (LQG) control with an added internal cost on the relative precision of the posterior probability over the world state. This creates a trade-off: an agent can obtain more utility overall by sacrificing some task performance, if doing so saves enough bits during inference. We discover that the rational strategy that solves the joint inference and control problem goes through phase transitions depending on the task demands, switching from a costly but optimal inference to a family of suboptimal inferences related by rotation transformations, each misestimate the stability of the world. In all cases, the agent moves more to think less. This work provides a foundation for a new type of rational computations that could be used by both brains and machines for efficient but computationally constrained control.", "published": "2024-10-31 04:00:00", "id": "f37e0161-efe9-422d-9a8f-cf0d40dd976e", "source": "arxiv", "section": "computerScience"}, {"title": "Fusion of Movement and Naive Predictions for Point Forecasting in Univariate Random Walks", "link": "https://arxiv.org/abs/2406.14469", "description": "arXiv:2406.14469v5 Announce Type: replace \nAbstract: Point forecasting in univariate random walks is an important yet challenging research topic. Many attempts at this task often fail to surpass the na\\\"ive baseline because of the randomness of the data and the improper utilization of exogenous variables as features. In view of the limitations of existing random walk forecasting methods, this study introduces a variant definition of random walks, proposing that point forecasting can be improved beyond the na\\\"ive baseline through the fusion of movement and na\\\"ive predictions (FMNP). FMNP naturally bridges movement prediction and point forecasting. It employs an exogenous variable to provide a consistent movement prediction for the target variable and uses a linear regression to combine movement and na\\\"ive predictions. In forecasting five financial time series in the U.S. market with the FTSE opening price as the exogenous variable, FMNP consistently outperforms na\\\"ive baselines and is superior to baseline models such as ARIMA, MA, MLP, DNN, LSTM, and CNN-LSTM. FMNP is particularly advantageous when accurate point predictions are challenging but accurate movement predictions are attainable, translating movement predictions into point forecasts in random walk contexts.", "published": "2024-10-31 04:00:00", "id": "2965bd33-1139-4e06-bffe-87a4f7f875b3", "source": "arxiv", "section": "computerScience"}, {"title": "MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding", "link": "https://arxiv.org/abs/2406.14515", "description": "arXiv:2406.14515v3 Announce Type: replace \nAbstract: The advent of large vision-language models (LVLMs) has spurred research into their applications in multi-modal contexts, particularly in video understanding. Traditional VideoQA benchmarks, despite providing quantitative metrics, often fail to encompass the full spectrum of video content and inadequately assess models' temporal comprehension. To address these limitations, we introduce MMBench-Video, a quantitative benchmark designed to rigorously evaluate LVLMs' proficiency in video understanding. MMBench-Video incorporates lengthy videos from YouTube and employs free-form questions, mirroring practical use cases. The benchmark is meticulously crafted to probe the models' temporal reasoning skills, with all questions human-annotated according to a carefully constructed ability taxonomy. We employ GPT-4 for automated assessment, demonstrating superior accuracy and robustness over earlier LLM-based evaluations. Utilizing MMBench-Video, we have conducted comprehensive evaluations that include both proprietary and open-source LVLMs for images and videos. MMBench-Video stands as a valuable resource for the research community, facilitating improved evaluation of LVLMs and catalyzing progress in the field of video understanding. The evalutation code of MMBench-Video will be integrated into VLMEvalKit: https://github.com/open-compass/VLMEvalKit.", "published": "2024-10-31 04:00:00", "id": "a3212de4-b904-4242-929e-bba0de0ca871", "source": "arxiv", "section": "computerScience"}, {"title": "CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics", "link": "https://arxiv.org/abs/2406.14558", "description": "arXiv:2406.14558v3 Announce Type: replace \nAbstract: Enabling humanoid robots to clean rooms has long been a pursued dream within humanoid research communities. However, many tasks require multi-humanoid collaboration, such as carrying large and heavy furniture together. Given the scarcity of motion capture data on multi-humanoid collaboration and the efficiency challenges associated with multi-agent learning, these tasks cannot be straightforwardly addressed using training paradigms designed for single-agent scenarios. In this paper, we introduce Cooperative Human-Object Interaction (CooHOI), a framework designed to tackle the challenge of multi-humanoid object transportation problem through a two-phase learning paradigm: individual skill learning and subsequent policy transfer. First, a single humanoid character learns to interact with objects through imitation learning from human motion priors. Then, the humanoid learns to collaborate with others by considering the shared dynamics of the manipulated object using centralized training and decentralized execution (CTDE) multi-agent RL algorithms. When one agent interacts with the object, resulting in specific object dynamics changes, the other agents learn to respond appropriately, thereby achieving implicit communication and coordination between teammates. Unlike previous approaches that relied on tracking-based methods for multi-humanoid HOI, CooHOI is inherently efficient, does not depend on motion capture data of multi-humanoid interactions, and can be seamlessly extended to include more participants and a wide range of object types.", "published": "2024-10-31 04:00:00", "id": "b7ced865-007b-466a-af6f-04516a594452", "source": "arxiv", "section": "computerScience"}, {"title": "Can LLMs Learn by Teaching for Better Reasoning? A Preliminary Study", "link": "https://arxiv.org/abs/2406.14629", "description": "arXiv:2406.14629v2 Announce Type: replace \nAbstract: Teaching to improve student models (e.g., knowledge distillation) is an extensively studied methodology in LLMs. However, for humans, teaching improves not only students but also teachers, by fostering more rigorous and clear reasoning as well as knowledge building. We ask: Can LLMs also learn by teaching (LbT) for better reasoning? If the answer is yes, we can potentially unlock the possibility of continuously advancing the models without solely relying on human-produced data or stronger models. In this paper, we provide a preliminary exploration on this question. We show that LbT ideas can be incorporated into existing LLM training/prompting pipelines and bring improvements. Specifically, we design three methods, each mimicking one of the three levels of LbT: observing students' feedback, learning from the feedback, and learning iteratively, with the goals of improving answer accuracy without training or improving models' inherent capability with fine-tuning. We reveal some findings: (1) Teaching materials that make it easier for students to learn have clearer and more accurate logic when using in-context learning as the student's \"learning\" method; (2) Weak-to-strong generalization: LbT might help improve strong models by teaching weak models; (3) Diversity in students might help: teaching multiple students could be better than teaching one student or the teacher itself. We hope that our exploration can inspire future research on LbT and more broadly adopting the advanced techniques in education to improve LLMs. The code and website are at https://github.com/imagination-research/lbt and https://sites.google.com/view/llm-learning-by-teaching.", "published": "2024-10-31 04:00:00", "id": "0e8d07eb-f6e4-4c4d-8a79-ec1d6c95f4f9", "source": "arxiv", "section": "computerScience"}, {"title": "Exploring Design Choices for Building Language-Specific LLMs", "link": "https://arxiv.org/abs/2406.14670", "description": "arXiv:2406.14670v2 Announce Type: replace \nAbstract: Despite rapid progress in large language models (LLMs), their performance on a vast majority of languages remains unsatisfactory. In this paper, we study building language-specific LLMs by adapting monolingual and multilingual LLMs. We conduct systematic experiments on how design choices (base model selection, vocabulary extension, and continued pretraining) impact the adapted LLM, both in terms of efficiency (how many tokens are needed to encode the same amount of information) and end task performance. We find that (1) the initial performance of LLM does not always correlate with the final performance after the adaptation. Adapting an English-centric models can yield better results than adapting multilingual models despite their worse initial performance on low-resource languages. (2) Efficiency can easily improved with simple vocabulary extension and continued pretraining in most LLMs we study, and (3) The optimal adaptation method (choice of the base model, new vocabulary size, training data, initialization strategy) is highly language-dependent, and the simplest embedding initialization works well across various experimental settings. Together, our work lays foundations on efficiently building language-specific LLMs by adapting existing LLMs.", "published": "2024-10-31 04:00:00", "id": "c8f86ec4-b65e-47a0-96d6-22958d716fb1", "source": "arxiv", "section": "computerScience"}, {"title": "Benchmarking Uncertainty Quantification Methods for Large Language Models with LM-Polygraph", "link": "https://arxiv.org/abs/2406.15627", "description": "arXiv:2406.15627v2 Announce Type: replace \nAbstract: Uncertainty quantification (UQ) is a critical component of machine learning (ML) applications. The rapid proliferation of large language models (LLMs) has stimulated researchers to seek efficient and effective approaches to UQ for text generation. As with other ML models, LLMs are prone to making incorrect predictions, in the form of ``hallucinations'' whereby claims are fabricated or low-quality outputs are generated for a given input. UQ is a key element in dealing with these challenges. However, research to date on UQ methods for LLMs has been fragmented, in terms of the literature on UQ techniques and evaluation methods. In this work, we tackle this issue by introducing a novel benchmark that implements a collection of state-of-the-art UQ baselines, and provides an environment for controllable and consistent evaluation of novel UQ techniques over various text generation tasks. Our benchmark also supports the assessment of confidence normalization methods in terms of their ability to provide interpretable scores. Using our benchmark, we conduct a large-scale empirical investigation of UQ and normalization techniques across nine tasks, and identify the most promising approaches.\n  Code: https://github.com/IINemo/lm-polygraph", "published": "2024-10-31 04:00:00", "id": "0124e621-5012-4e1f-915a-2c17cbe355e8", "source": "arxiv", "section": "computerScience"}, {"title": "Bandits with Preference Feedback: A Stackelberg Game Perspective", "link": "https://arxiv.org/abs/2406.16745", "description": "arXiv:2406.16745v2 Announce Type: replace \nAbstract: Bandits with preference feedback present a powerful tool for optimizing unknown target functions when only pairwise comparisons are allowed instead of direct value queries. This model allows for incorporating human feedback into online inference and optimization and has been employed in systems for fine-tuning large language models. The problem is well understood in simplified settings with linear target functions or over finite small domains that limit practical interest. Taking the next step, we consider infinite domains and nonlinear (kernelized) rewards. In this setting, selecting a pair of actions is quite challenging and requires balancing exploration and exploitation at two levels: within the pair, and along the iterations of the algorithm. We propose MAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, and chooses action pairs that are informative and yield favorable rewards. MAXMINLCB consistently outperforms existing algorithms and satisfies an anytime-valid rate-optimal regret guarantee. This is due to our novel preference-based confidence sequences for kernelized logistic estimators.", "published": "2024-10-31 04:00:00", "id": "4221e618-2721-41cd-9e82-1e1307a6acf3", "source": "arxiv", "section": "computerScience"}, {"title": "Training-Free Exponential Context Extension via Cascading KV Cache", "link": "https://arxiv.org/abs/2406.17808", "description": "arXiv:2406.17808v2 Announce Type: replace \nAbstract: The transformer's context window is vital for tasks such as few-shot learning and conditional generation as it preserves previous tokens for active memory. However, as the context lengths increase, the computational costs grow quadratically, hindering the deployment of large language models (LLMs) in real-world, long sequence scenarios. Although some recent key-value caching (KV Cache) methods offer linear inference complexity, they naively manage the stored context, prematurely evicting tokens and losing valuable information. Moreover, they lack an optimized prefill/prompt stage strategy, resulting in higher latency than even quadratic attention for realistic context sizes. In response, we introduce a novel mechanism that leverages cascading sub-cache buffers to selectively retain the most relevant tokens, enabling the model to maintain longer context histories without increasing the cache size. Our approach outperforms linear caching baselines across key benchmarks, including streaming perplexity, question answering, book summarization, and passkey retrieval, where it retains better retrieval accuracy at 1M tokens after four doublings of the cache size of 65K. Additionally, our method reduces prefill stage latency by a factor of 6.8 when compared to flash attention on 1M tokens. These innovations not only enhance the computational efficiency of LLMs but also pave the way for their effective deployment in resource-constrained environments, enabling large-scale, real-time applications with significantly reduced latency.", "published": "2024-10-31 04:00:00", "id": "2938c360-63a8-447d-973f-1801b79e36b8", "source": "arxiv", "section": "computerScience"}, {"title": "Gaussian process-based online health monitoring and fault analysis of lithium-ion battery systems from field data", "link": "https://arxiv.org/abs/2406.19015", "description": "arXiv:2406.19015v3 Announce Type: replace \nAbstract: Health monitoring, fault analysis, and detection are critical for the safe and sustainable operation of battery systems. We apply Gaussian process resistance models on lithium iron phosphate battery field data to effectively separate the time-dependent and operating point-dependent resistance. The data set contains 29 battery systems returned to the manufacturer for warranty, each with eight cells in series, totaling 232 cells and 131 million data rows. We develop probabilistic fault detection rules using recursive spatiotemporal Gaussian processes. These processes allow the quick processing of over a million data points, enabling advanced online monitoring and furthering the understanding of battery pack failure in the field. The analysis underlines that often, only a single cell shows abnormal behavior or a knee point, consistent with weakest-link failure for cells connected in series, amplified by local resistive heating. The results further the understanding of how batteries degrade and fail in the field and demonstrate the potential of efficient online monitoring based on data. We open-source the code and publish the large data set upon completion of the review of this article.", "published": "2024-10-31 04:00:00", "id": "c93cf6b7-f9d6-489d-a41d-c1cd20a2e70f", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Universal Mesh Movement Networks", "link": "https://arxiv.org/abs/2407.00382", "description": "arXiv:2407.00382v3 Announce Type: replace \nAbstract: Solving complex Partial Differential Equations (PDEs) accurately and efficiently is an essential and challenging problem in all scientific and engineering disciplines. Mesh movement methods provide the capability to improve the accuracy of the numerical solution without increasing the overall mesh degree of freedom count. Conventional sophisticated mesh movement methods are extremely expensive and struggle to handle scenarios with complex boundary geometries. However, existing learning-based methods require re-training from scratch given a different PDE type or boundary geometry, which limits their applicability, and also often suffer from robustness issues in the form of inverted elements. In this paper, we introduce the Universal Mesh Movement Network (UM2N), which -- once trained -- can be applied in a non-intrusive, zero-shot manner to move meshes with different size distributions and structures, for solvers applicable to different PDE types and boundary geometries. UM2N consists of a Graph Transformer (GT) encoder for extracting features and a Graph Attention Network (GAT) based decoder for moving the mesh. We evaluate our method on advection and Navier-Stokes based examples, as well as a real-world tsunami simulation case. Our method outperforms existing learning-based mesh movement methods in terms of the benchmarks described above. In comparison to the conventional sophisticated Monge-Amp\\`ere PDE-solver based method, our approach not only significantly accelerates mesh movement, but also proves effective in scenarios where the conventional method fails. Our project page is at https://erizmr.github.io/UM2N/.", "published": "2024-10-31 04:00:00", "id": "074c82eb-54ef-4ce7-a09d-9759c7520e2a", "source": "arxiv", "section": "computerScience"}, {"title": "Towards optimal hierarchical training of neural networks", "link": "https://arxiv.org/abs/2407.02242", "description": "arXiv:2407.02242v2 Announce Type: replace \nAbstract: We propose a hierarchical training algorithm for standard feed-forward neural networks that adaptively extends the network architecture as soon as the optimization reaches a stationary point. By solving small (low-dimensional) optimization problems, the extended network provably escapes any local minimum or stationary point. Under some assumptions on the approximability of the data with stable neural networks, we show that the algorithm achieves an optimal convergence rate s in the sense that loss is bounded by the number of parameters to the -s. As a byproduct, we obtain computable indicators which judge the optimality of the training state of a given network and derive a new notion of generalization error.", "published": "2024-10-31 04:00:00", "id": "33e4a7cc-e62f-4ec3-93cc-82a603c01cfc", "source": "arxiv", "section": "computerScience"}, {"title": "Soft Language Prompts for Language Transfer", "link": "https://arxiv.org/abs/2407.02317", "description": "arXiv:2407.02317v2 Announce Type: replace \nAbstract: Cross-lingual knowledge transfer, especially between high- and low-resource languages, remains challenging in natural language processing (NLP). This study offers insights for improving cross-lingual NLP applications through the combination of parameter-efficient fine-tuning methods. We systematically explore strategies for enhancing cross-lingual transfer through the incorporation of language-specific and task-specific adapters and soft prompts. We present a detailed investigation of various combinations of these methods, exploring their efficiency across 16 languages, focusing on 10 mid- and low-resource languages. We further present to our knowledge the first use of soft prompts for language transfer, a technique we call soft language prompts. Our findings demonstrate that in contrast to claims of previous work, a combination of language and task adapters does not always work best; instead, combining a soft language prompt with a task adapter outperforms most configurations in many cases.", "published": "2024-10-31 04:00:00", "id": "60105939-0def-4fe5-a3ff-22cdd939059d", "source": "arxiv", "section": "computerScience"}, {"title": "Generative Large Language Models in Automated Fact-Checking: A Survey", "link": "https://arxiv.org/abs/2407.02351", "description": "arXiv:2407.02351v2 Announce Type: replace \nAbstract: The dissemination of false information on online platforms presents a serious societal challenge. While manual fact-checking remains crucial, Large Language Models (LLMs) offer promising opportunities to support fact-checkers with their vast knowledge and advanced reasoning capabilities. This survey explores the application of generative LLMs in fact-checking, highlighting various approaches and techniques for prompting or fine-tuning these models. By providing an overview of existing methods and their limitations, the survey aims to enhance the understanding of how LLMs can be used in fact-checking and to facilitate further progress in their integration into the fact-checking process.", "published": "2024-10-31 04:00:00", "id": "051c9945-a237-4d23-bfa1-24f0123d9b8a", "source": "arxiv", "section": "computerScience"}, {"title": "MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention", "link": "https://arxiv.org/abs/2407.02490", "description": "arXiv:2407.02490v2 Announce Type: replace \nAbstract: The computational challenges of Large Language Model (LLM) inference remain a significant barrier to their widespread deployment, especially as prompt lengths continue to increase. Due to the quadratic complexity of the attention computation, it takes 30 minutes for an 8B LLM to process a prompt of 1M tokens (i.e., the pre-filling stage) on a single A100 GPU. Existing methods for speeding up prefilling often fail to maintain acceptable accuracy or efficiency when applied to long-context LLMs. To address this gap, we introduce MInference (Milliontokens Inference), a sparse calculation method designed to accelerate pre-filling of long-sequence processing. Specifically, we identify three unique patterns in long-context attention matrices-the A-shape, Vertical-Slash, and Block-Sparsethat can be leveraged for efficient sparse computation on GPUs. We determine the optimal pattern for each attention head offline and dynamically build sparse indices based on the assigned pattern during inference. With the pattern and sparse indices, we perform efficient sparse attention calculations via our optimized GPU kernels to significantly reduce the latency in the pre-filling stage of long-context LLMs. Our proposed technique can be directly applied to existing LLMs without any modifications to the pre-training setup or additional fine-tuning. By evaluating on a wide range of downstream tasks, including InfiniteBench, RULER, PG-19, and Needle In A Haystack, and models including LLaMA-3-1M, GLM4-1M, Yi-200K, Phi-3-128K, and Qwen2-128K, we demonstrate that MInference effectively reduces inference latency by up to 10x for pre-filling on an A100, while maintaining accuracy. Our code is available at https://aka.ms/MInference.", "published": "2024-10-31 04:00:00", "id": "8637c4c6-304d-4cab-9bdf-2cf45b40c6be", "source": "arxiv", "section": "computerScience"}, {"title": "Breach By A Thousand Leaks: Unsafe Information Leakage in `Safe' AI Responses", "link": "https://arxiv.org/abs/2407.02551", "description": "arXiv:2407.02551v2 Announce Type: replace \nAbstract: Vulnerability of Frontier language models to misuse and jailbreaks has prompted the development of safety measures like filters and alignment training in an effort to ensure safety through robustness to adversarially crafted prompts. We assert that robustness is fundamentally insufficient for ensuring safety goals, and current defenses and evaluation methods fail to account for risks of dual-intent queries and their composition for malicious goals. To quantify these risks, we introduce a new safety evaluation framework based on impermissible information leakage of model outputs and demonstrate how our proposed question-decomposition attack can extract dangerous knowledge from a censored LLM more effectively than traditional jailbreaking. Underlying our proposed evaluation method is a novel information-theoretic threat model of inferential adversaries, distinguished from security adversaries, such as jailbreaks, in that success is measured by inferring impermissible knowledge from victim outputs as opposed to forcing explicitly impermissible outputs from the victim. Through our information-theoretic framework, we show that to ensure safety against inferential adversaries, defense mechanisms must ensure information censorship, bounding the leakage of impermissible information. However, we prove that such defenses inevitably incur a safety-utility trade-off.", "published": "2024-10-31 04:00:00", "id": "d719f4f6-50fb-4439-b467-dc31f9e1ec53", "source": "arxiv", "section": "computerScience"}, {"title": "Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning", "link": "https://arxiv.org/abs/2407.06120", "description": "arXiv:2407.06120v2 Announce Type: replace \nAbstract: We revisit data selection in a modern context of finetuning from a fundamental perspective. Extending the classical wisdom of variance minimization in low dimensions to high-dimensional finetuning, our generalization analysis unveils the importance of additionally reducing bias induced by low-rank approximation. Inspired by the variance-bias tradeoff in high dimensions from the theory, we introduce Sketchy Moment Matching (SkMM), a scalable data selection scheme with two stages. (i) First, the bias is controlled using gradient sketching that explores the finetuning parameter space for an informative low-dimensional subspace $\\mathcal{S}$; (ii) then the variance is reduced over $\\mathcal{S}$ via moment matching between the original and selected datasets. Theoretically, we show that gradient sketching is fast and provably accurate: selecting $n$ samples by reducing variance over $\\mathcal{S}$ preserves the fast-rate generalization $O(\\dim(\\mathcal{S})/n)$, independent of the parameter dimension. Empirically, we concretize the variance-bias balance via synthetic experiments and demonstrate the effectiveness of SkMM for finetuning in real vision tasks.", "published": "2024-10-31 04:00:00", "id": "231bccc1-5ba0-4ba8-9407-f43ec81222b2", "source": "arxiv", "section": "computerScience"}, {"title": "DiffPhyCon: A Generative Approach to Control Complex Physical Systems", "link": "https://arxiv.org/abs/2407.06494", "description": "arXiv:2407.06494v4 Announce Type: replace \nAbstract: Controlling the evolution of complex physical systems is a fundamental task across science and engineering. Classical techniques suffer from limited applicability or huge computational costs. On the other hand, recent deep learning and reinforcement learning-based approaches often struggle to optimize long-term control sequences under the constraints of system dynamics. In this work, we introduce Diffusion Physical systems Control (DiffPhyCon), a new class of method to address the physical systems control problem. DiffPhyCon excels by simultaneously minimizing both the learned generative energy function and the predefined control objectives across the entire trajectory and control sequence. Thus, it can explore globally and plan near-optimal control sequences. Moreover, we enhance DiffPhyCon with prior reweighting, enabling the discovery of control sequences that significantly deviate from the training distribution. We test our method on three tasks: 1D Burgers' equation, 2D jellyfish movement control, and 2D high-dimensional smoke control, where our generated jellyfish dataset is released as a benchmark for complex physical system control research. Our method outperforms widely applied classical approaches and state-of-the-art deep learning and reinforcement learning methods. Notably, DiffPhyCon unveils an intriguing fast-close-slow-open pattern observed in the jellyfish, aligning with established findings in the field of fluid dynamics. The project website, jellyfish dataset, and code can be found at https://github.com/AI4Science-WestlakeU/diffphycon.", "published": "2024-10-31 04:00:00", "id": "ccf4291d-3845-48f6-a33a-81c0ddffeab0", "source": "arxiv", "section": "computerScience"}, {"title": "It's Our Loss: No Privacy Amplification for Hidden State DP-SGD With Non-Convex Loss", "link": "https://arxiv.org/abs/2407.06496", "description": "arXiv:2407.06496v3 Announce Type: replace \nAbstract: Differentially Private Stochastic Gradient Descent (DP-SGD) is a popular iterative algorithm used to train machine learning models while formally guaranteeing the privacy of users. However, the privacy analysis of DP-SGD makes the unrealistic assumption that all intermediate iterates (aka internal state) of the algorithm are released since, in practice, only the final trained model, i.e., the final iterate of the algorithm is released. In this hidden state setting, prior work has provided tighter analyses, albeit only when the loss function is constrained, e.g., strongly convex and smooth or linear. On the other hand, the privacy leakage observed empirically from hidden state DP-SGD, even when using non-convex loss functions, suggests that there is in fact a gap between the theoretical privacy analysis and the privacy guarantees achieved in practice. Therefore, it remains an open question whether hidden state privacy amplification for DP-SGD is possible for all (possibly non-convex) loss functions in general.\n  In this work, we design a counter-example and show, both theoretically and empirically, that a hidden state privacy amplification result for DP-SGD for all loss functions in general is not possible. By carefully constructing a loss function for DP-SGD, we show that for specific loss functions, the final iterate of DP-SGD alone leaks as much information as the sequence of all iterates combined. Furthermore, we empirically verify this result by evaluating the privacy leakage from the final iterate of DP-SGD with our loss function and show that this exactly matches the theoretical upper bound guaranteed by DP. Therefore, we show that the current privacy analysis for DP-SGD is tight for general loss functions and conclude that no privacy amplification is possible for DP-SGD in general for all (possibly non-convex) loss functions.", "published": "2024-10-31 04:00:00", "id": "488896fd-3a44-4b5f-9d1c-accd0b50440d", "source": "arxiv", "section": "computerScience"}, {"title": "Aligning Diffusion Behaviors with Q-functions for Efficient Continuous Control", "link": "https://arxiv.org/abs/2407.09024", "description": "arXiv:2407.09024v2 Announce Type: replace \nAbstract: Drawing upon recent advances in language model alignment, we formulate offline Reinforcement Learning as a two-stage optimization problem: First pretraining expressive generative policies on reward-free behavior datasets, then fine-tuning these policies to align with task-specific annotations like Q-values. This strategy allows us to leverage abundant and diverse behavior data to enhance generalization and enable rapid adaptation to downstream tasks using minimal annotations. In particular, we introduce Efficient Diffusion Alignment (EDA) for solving continuous control problems. EDA utilizes diffusion models for behavior modeling. However, unlike previous approaches, we represent diffusion policies as the derivative of a scalar neural network with respect to action inputs. This representation is critical because it enables direct density calculation for diffusion models, making them compatible with existing LLM alignment theories. During policy fine-tuning, we extend preference-based alignment methods like Direct Preference Optimization (DPO) to align diffusion behaviors with continuous Q-functions. Our evaluation on the D4RL benchmark shows that EDA exceeds all baseline methods in overall performance. Notably, EDA maintains about 95\\% of performance and still outperforms several baselines given only 1\\% of Q-labelled data during fine-tuning.", "published": "2024-10-31 04:00:00", "id": "e2e91e15-3556-46ce-bea7-5e0823095e14", "source": "arxiv", "section": "computerScience"}, {"title": "Image captioning in different languages", "link": "https://arxiv.org/abs/2407.09495", "description": "arXiv:2407.09495v2 Announce Type: replace \nAbstract: This short position paper provides a manually curated list of non-English image captioning datasets (as of May 2024). Through this list, we can observe the dearth of datasets in different languages: only 23 different languages are represented. With the addition of the Crossmodal-3600 dataset (Thapliyal et al., 2022, 36 languages) this number increases somewhat, but still this number is small compared to the +/-500 institutional languages that are out there. This paper closes with some open questions for the field of Vision & Language.", "published": "2024-10-31 04:00:00", "id": "64729d59-8f8d-4885-8bfb-c75a765165af", "source": "arxiv", "section": "computerScience"}, {"title": "PARE-Net: Position-Aware Rotation-Equivariant Networks for Robust Point Cloud Registration", "link": "https://arxiv.org/abs/2407.10142", "description": "arXiv:2407.10142v2 Announce Type: replace \nAbstract: Learning rotation-invariant distinctive features is a fundamental requirement for point cloud registration. Existing methods often use rotation-sensitive networks to extract features, while employing rotation augmentation to learn an approximate invariant mapping rudely. This makes networks fragile to rotations, overweight, and hinders the distinctiveness of features. To tackle these problems, we propose a novel position-aware rotation-equivariant network, for efficient, light-weighted, and robust registration. The network can provide a strong model inductive bias to learn rotation-equivariant/invariant features, thus addressing the aforementioned limitations. To further improve the distinctiveness of descriptors, we propose a position-aware convolution, which can better learn spatial information of local structures. Moreover, we also propose a feature-based hypothesis proposer. It leverages rotation-equivariant features that encode fine-grained structure orientations to generate reliable model hypotheses. Each correspondence can generate a hypothesis, thus it is more efficient than classic estimators that require multiple reliable correspondences. Accordingly, a contrastive rotation loss is presented to enhance the robustness of rotation-equivariant features against data degradation. Extensive experiments on indoor and outdoor datasets demonstrate that our method significantly outperforms the SOTA methods in terms of registration recall while being lightweight and keeping a fast speed. Moreover, experiments on rotated datasets demonstrate its robustness against rotation variations. Code is available at https://github.com/yaorz97/PARENet.", "published": "2024-10-31 04:00:00", "id": "776b14d2-7094-4b48-a928-41f76cb778c9", "source": "arxiv", "section": "computerScience"}, {"title": "Enabling MCTS Explainability for Sequential Planning Through Computation Tree Logic", "link": "https://arxiv.org/abs/2407.10820", "description": "arXiv:2407.10820v3 Announce Type: replace \nAbstract: Monte Carlo tree search (MCTS) is one of the most capable online search algorithms for sequential planning tasks, with significant applications in areas such as resource allocation and transit planning. Despite its strong performance in real-world deployment, the inherent complexity of MCTS makes it challenging to understand for users without technical background. This paper considers the use of MCTS in transportation routing services, where the algorithm is integrated to develop optimized route plans. These plans are required to meet a range of constraints and requirements simultaneously, further complicating the task of explaining the algorithm's operation in real-world contexts. To address this critical research gap, we introduce a novel computation tree logic-based explainer for MCTS. Our framework begins by taking user-defined requirements and translating them into rigorous logic specifications through the use of language templates. Then, our explainer incorporates a logic verification and quantitative evaluation module that validates the states and actions traversed by the MCTS algorithm. The outcomes of this analysis are then rendered into human-readable descriptive text using a second set of language templates. The user satisfaction of our approach was assessed through a survey with 82 participants. The results indicated that our explanatory approach significantly outperforms other baselines in user preference.", "published": "2024-10-31 04:00:00", "id": "b1dda110-c28f-461c-ad74-0afbf25c4c5d", "source": "arxiv", "section": "computerScience"}, {"title": "Make-An-Agent: A Generalizable Policy Network Generator with Behavior-Prompted Diffusion", "link": "https://arxiv.org/abs/2407.10973", "description": "arXiv:2407.10973v2 Announce Type: replace \nAbstract: Can we generate a control policy for an agent using just one demonstration of desired behaviors as a prompt, as effortlessly as creating an image from a textual description? In this paper, we present Make-An-Agent, a novel policy parameter generator that leverages the power of conditional diffusion models for behavior-to-policy generation. Guided by behavior embeddings that encode trajectory information, our policy generator synthesizes latent parameter representations, which can then be decoded into policy networks. Trained on policy network checkpoints and their corresponding trajectories, our generation model demonstrates remarkable versatility and scalability on multiple tasks and has a strong generalization ability on unseen tasks to output well-performed policies with only few-shot demonstrations as inputs. We showcase its efficacy and efficiency on various domains and tasks, including varying objectives, behaviors, and even across different robot manipulators. Beyond simulation, we directly deploy policies generated by Make-An-Agent onto real-world robots on locomotion tasks. Project page: https://cheryyunl.github.io/make-an-agent/", "published": "2024-10-31 04:00:00", "id": "ec1a0be1-f773-4785-81ac-23755a8404a4", "source": "arxiv", "section": "computerScience"}, {"title": "Empowering Persian LLMs for Instruction Following: A Novel Dataset and Training Approach", "link": "https://arxiv.org/abs/2407.11186", "description": "arXiv:2407.11186v3 Announce Type: replace \nAbstract: Instruction-tuned large language models have demonstrated remarkable capabilities in following human instructions across various domains. However, their proficiency remains notably deficient in many low-resource languages. To address this challenge, we begin by introducing FarsInstruct a comprehensive instruction dataset designed to enhance the instruction following ability of large language models specifically for the Persian language a significant yet underrepresented language globally. FarsInstruct encompasses a wide range of task types and datasets, each containing a mix of straightforward to complex manual written instructions, as well as translations from the Public Pool of Prompts, ensuring a rich linguistic and cultural representation. Furthermore, we introduce Co-CoLA, a framework designed to enhance the multi-task adaptability of LoRA-tuned models. Through extensive experimental analyses, our study showcases the effectiveness of the FarsInstruct dataset coupled with training by the Co-CoLA framework, in improving the performance of large language models within the Persian context. As of the current writing, FarsInstruct comprises 197 templates across 21 distinct datasets, and we intend to update it consistently, thus augmenting its applicability.", "published": "2024-10-31 04:00:00", "id": "51803326-b0b3-4e67-aeb2-30f5f3490e42", "source": "arxiv", "section": "computerScience"}, {"title": "Questionable practices in machine learning", "link": "https://arxiv.org/abs/2407.12220", "description": "arXiv:2407.12220v2 Announce Type: replace \nAbstract: Evaluating modern ML models is hard. The strong incentive for researchers and companies to report a state-of-the-art result on some metric often leads to questionable research practices (QRPs): bad practices which fall short of outright research fraud. We describe 44 such practices which can undermine reported results, giving examples where possible. Our list emphasises the evaluation of large language models (LLMs) on public benchmarks. We also discuss \"irreproducible research practices\", i.e. decisions that make it difficult or impossible for other researchers to reproduce, build on or audit previous research.", "published": "2024-10-31 04:00:00", "id": "d7dc7b18-bad7-478b-934d-49cc114edede", "source": "arxiv", "section": "computerScience"}, {"title": "InterpBench: Semi-Synthetic Transformers for Evaluating Mechanistic Interpretability Techniques", "link": "https://arxiv.org/abs/2407.14494", "description": "arXiv:2407.14494v2 Announce Type: replace \nAbstract: Mechanistic interpretability methods aim to identify the algorithm a neural network implements, but it is difficult to validate such methods when the true algorithm is unknown. This work presents InterpBench, a collection of semi-synthetic yet realistic transformers with known circuits for evaluating these techniques. We train simple neural networks using a stricter version of Interchange Intervention Training (IIT) which we call Strict IIT (SIIT). Like the original, SIIT trains neural networks by aligning their internal computation with a desired high-level causal model, but it also prevents non-circuit nodes from affecting the model's output. We evaluate SIIT on sparse transformers produced by the Tracr tool and find that SIIT models maintain Tracr's original circuit while being more realistic. SIIT can also train transformers with larger circuits, like Indirect Object Identification (IOI). Finally, we use our benchmark to evaluate existing circuit discovery techniques.", "published": "2024-10-31 04:00:00", "id": "bfe21585-fc35-4ee6-ba82-690cac5f28b7", "source": "arxiv", "section": "computerScience"}, {"title": "u-$\\mu$P: The Unit-Scaled Maximal Update Parametrization", "link": "https://arxiv.org/abs/2407.17465", "description": "arXiv:2407.17465v2 Announce Type: replace \nAbstract: The Maximal Update Parametrization ($\\mu$P) aims to make the optimal hyperparameters (HPs) of a model independent of its size, allowing them to be swept using a cheap proxy model rather than the full-size target model. We present a new scheme, u-$\\mu$P, which improves upon $\\mu$P by combining it with Unit Scaling, a method for designing models that makes them easy to train in low-precision. The two techniques have a natural affinity: $\\mu$P ensures that the scale of activations is independent of model size, and Unit Scaling ensures that activations, weights and gradients begin training with a scale of one. This synthesis opens the door to a simpler scheme, whose default values are near-optimal. This in turn facilitates a more efficient sweeping strategy, with u-$\\mu$P models reaching a loss that is equal to or lower than comparable $\\mu$P models and working out-of-the-box in FP8.", "published": "2024-10-31 04:00:00", "id": "51830160-76f6-4c70-9de4-a1cc0ee241a5", "source": "arxiv", "section": "computerScience"}, {"title": "Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models", "link": "https://arxiv.org/abs/2408.00113", "description": "arXiv:2408.00113v2 Announce Type: replace \nAbstract: What latent features are encoded in language model (LM) representations? Recent work on training sparse autoencoders (SAEs) to disentangle interpretable features in LM representations has shown significant promise. However, evaluating the quality of these SAEs is difficult because we lack a ground-truth collection of interpretable features that we expect good SAEs to recover. We thus propose to measure progress in interpretable dictionary learning by working in the setting of LMs trained on chess and Othello transcripts. These settings carry natural collections of interpretable features -- for example, \"there is a knight on F3\" -- which we leverage into $\\textit{supervised}$ metrics for SAE quality. To guide progress in interpretable dictionary learning, we introduce a new SAE training technique, $\\textit{p-annealing}$, which improves performance on prior unsupervised metrics as well as our new metrics.", "published": "2024-10-31 04:00:00", "id": "8e0d1e8c-358f-48b5-841e-ca7f7726aa19", "source": "arxiv", "section": "computerScience"}, {"title": "Data Poisoning in LLMs: Jailbreak-Tuning and Scaling Laws", "link": "https://arxiv.org/abs/2408.02946", "description": "arXiv:2408.02946v4 Announce Type: replace \nAbstract: LLMs produce harmful and undesirable behavior when trained on poisoned datasets that contain a small fraction of corrupted or harmful data. We develop a new attack paradigm, jailbreak-tuning, that combines data poisoning with jailbreaking to fully bypass state-of-the-art safeguards and make models like GPT-4o comply with nearly any harmful request. Our experiments suggest this attack represents a paradigm shift in vulnerability elicitation, producing differences in refusal rates as much as 60+ percentage points compared to normal fine-tuning. Given this demonstration of how data poisoning vulnerabilities persist and can be amplified, we investigate whether these risks will likely increase as models scale. We evaluate three threat models - malicious fine-tuning, imperfect data curation, and intentional data contamination - across 23 frontier LLMs ranging from 1.5 to 72 billion parameters. Our experiments reveal that larger LLMs are significantly more susceptible to data poisoning, learning harmful behaviors from even minimal exposure to harmful data more quickly than smaller models. These findings underscore the need for leading AI companies to thoroughly red team fine-tuning APIs before public release and to develop more robust safeguards against data poisoning, particularly as models continue to scale in size and capability.", "published": "2024-10-31 04:00:00", "id": "3142cae4-ecb0-470b-9a99-f49771375bc9", "source": "arxiv", "section": "computerScience"}, {"title": "Certifiably Robust Policies for Uncertain Parametric Environments", "link": "https://arxiv.org/abs/2408.03093", "description": "arXiv:2408.03093v3 Announce Type: replace \nAbstract: We present a data-driven approach for producing policies that are provably robust across unknown stochastic environments. Existing approaches can learn models of a single environment as an interval Markov decision processes (IMDP) and produce a robust policy with a probably approximately correct (PAC) guarantee on its performance. However these are unable to reason about the impact of environmental parameters underlying the uncertainty. We propose a framework based on parametric Markov decision processes (MDPs) with unknown distributions over parameters. We learn and analyse IMDPs for a set of unknown sample environments induced by parameters. The key challenge is then to produce meaningful performance guarantees that combine the two layers of uncertainty: (1) multiple environments induced by parameters with an unknown distribution; (2) unknown induced environments which are approximated by IMDPs. We present a novel approach based on scenario optimisation that yields a single PAC guarantee quantifying the risk level for which a specified performance level can be assured in unseen environments, plus a means to trade-off risk and performance. We implement and evaluate our framework using multiple robust policy generation methods on a range of benchmarks. We show that our approach produces tight bounds on a policy's performance with high confidence.", "published": "2024-10-31 04:00:00", "id": "58bf29ed-45e3-4030-abc2-d6f23646b6da", "source": "arxiv", "section": "computerScience"}, {"title": "Modular assurance of an Autonomous Ferry using Contract-Based Design and Simulation-based Verification Principles", "link": "https://arxiv.org/abs/2408.03244", "description": "arXiv:2408.03244v2 Announce Type: replace \nAbstract: With the introduction of autonomous technology into our society, e.g. autonomous shipping, it is important to assess and assure the safety of autonomous systems in a real-world context. Simulation-based testing is a common approach to attempt to verify performance of autonomous systems, but assurance also requires formal evidence. This paper introduces the Assurance of Digital Assets (ADA) framework, a structured method for the assurance of digital assets, i.e. novel, complex, or intelligent systems enabled by digital technologies, using contract-based design. Results are shown for an autonomous ferry assurance case, focusing on collision avoidance during the ferry's transit. Further, we discuss the role of simulation-based testing in verifying compliance to contract specifications, to build the necessary evidence for an assurance case.", "published": "2024-10-31 04:00:00", "id": "1070d066-1f44-47f9-80ca-98c89d0b06de", "source": "arxiv", "section": "computerScience"}, {"title": "Electricity Market-Clearing With Extreme Events", "link": "https://arxiv.org/abs/2408.03409", "description": "arXiv:2408.03409v2 Announce Type: replace \nAbstract: Extreme events jeopardize power network operations, causing beyond-design failures and massive supply interruptions. Existing market designs fail to internalize and systematically assess the risk of extreme and rare events. Efficiently maintaining the reliability of renewable-dominant power systems during extreme weather events requires co-optimizing system resources, while differentiating between large/rare and small/frequent deviations from forecast conditions. To address this gap in both research and practice, we propose managing the uncertainties associated with extreme weather events through an additional reserve service, termed extreme reserve. The procurement of extreme reserve is co-optimized with energy and regular reserve using a large deviation theory chance-constrained (LDT-CC) model, where LDT offers a mathematical framework to quantify the increased uncertainty during extreme events. To mitigate the high additional costs associated with reserve scheduling under the LDT-CC model, we also propose an LDT model based on weighted chance constraints (LDT-WCC). This model prepares the power system for extreme events at a lower cost, making it a less conservative alternative to the LDT-CC model. The proposed market design leads to a competitive equilibrium while ensuring cost recovery. Numerical experiments on an illustrative system and a modified 8-zone ISO New England system highlight the advantages of the proposed market design.", "published": "2024-10-31 04:00:00", "id": "04a1efb2-8c97-4a66-a5d0-b45aac151fcf", "source": "arxiv", "section": "computerScience"}, {"title": "2D-OOB: Attributing Data Contribution Through Joint Valuation Framework", "link": "https://arxiv.org/abs/2408.03572", "description": "arXiv:2408.03572v2 Announce Type: replace \nAbstract: Data valuation has emerged as a powerful framework for quantifying each datum's contribution to the training of a machine learning model. However, it is crucial to recognize that the quality of cells within a single data point can vary greatly in practice. For example, even in the case of an abnormal data point, not all cells are necessarily noisy. The single scalar score assigned by existing data valuation methods blurs the distinction between noisy and clean cells of a data point, making it challenging to interpret the data values. In this paper, we propose 2D-OOB, an out-of-bag estimation framework for jointly determining helpful (or detrimental) samples as well as the particular cells that drive them. Our comprehensive experiments demonstrate that 2D-OOB achieves state-of-the-art performance across multiple use cases while being exponentially faster. Specifically, 2D-OOB shows promising results in detecting and rectifying fine-grained outliers at the cell level, and localizing backdoor triggers in data poisoning attacks.", "published": "2024-10-31 04:00:00", "id": "b5c2a836-9736-494d-a9c4-a8c3f97a40db", "source": "arxiv", "section": "computerScience"}, {"title": "MMSummary: Multimodal Summary Generation for Fetal Ultrasound Video", "link": "https://arxiv.org/abs/2408.03761", "description": "arXiv:2408.03761v2 Announce Type: replace \nAbstract: We present the first automated multimodal summary generation system, MMSummary, for medical imaging video, particularly with a focus on fetal ultrasound analysis. Imitating the examination process performed by a human sonographer, MMSummary is designed as a three-stage pipeline, progressing from keyframe detection to keyframe captioning and finally anatomy segmentation and measurement. In the keyframe detection stage, an innovative automated workflow is proposed to progressively select a concise set of keyframes, preserving sufficient video information without redundancy. Subsequently, we adapt a large language model to generate meaningful captions for fetal ultrasound keyframes in the keyframe captioning stage. If a keyframe is captioned as fetal biometry, the segmentation and measurement stage estimates biometric parameters by segmenting the region of interest according to the textual prior. The MMSummary system provides comprehensive summaries for fetal ultrasound examinations and based on reported experiments is estimated to reduce scanning time by approximately 31.5%, thereby suggesting the potential to enhance clinical workflow efficiency.", "published": "2024-10-31 04:00:00", "id": "a35cdf4f-ee22-40de-9718-45dcf381b9d2", "source": "arxiv", "section": "computerScience"}, {"title": "LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description", "link": "https://arxiv.org/abs/2408.04957", "description": "arXiv:2408.04957v4 Announce Type: replace \nAbstract: Visual Spatial Description (VSD) aims to generate texts that describe the spatial relationships between objects within images. Traditional visual spatial relationship classification (VSRC) methods typically output the spatial relationship between two objects in an image, often neglecting world knowledge and lacking general language capabilities. In this paper, we propose a Large Language-and-Vision Assistant for Visual Spatial Description, named LLaVA-VSD, which is designed for the classification, description, and open-ended description of visual spatial relationships. Specifically, the model first constructs a VSD instruction-following dataset using given figure-caption pairs for the three tasks. It then employs LoRA to fine-tune a Large Language and Vision Assistant for VSD, which has 13 billion parameters and supports high-resolution images. Finally, a large language model (Qwen-2) is used to refine the generated sentences, enhancing their diversity and accuracy. LLaVA-VSD demonstrates excellent multimodal conversational capabilities and can follow open-ended instructions to assist with inquiries about object relationships in images.", "published": "2024-10-31 04:00:00", "id": "0c6d4ad6-02c2-41b0-a5f0-1d3cf0605865", "source": "arxiv", "section": "computerScience"}, {"title": "Learning a robust shape parameter for RBF approximation", "link": "https://arxiv.org/abs/2408.05081", "description": "arXiv:2408.05081v2 Announce Type: replace \nAbstract: Radial basis functions (RBFs) play an important role in function interpolation, in particular in an arbitrary set of interpolation nodes. The accuracy of the interpolation depends on a parameter called the shape parameter. There are many approaches in literature on how to appropriately choose it as to increase the accuracy of interpolation while avoiding instability issues. However, finding the optimal shape parameter value in general remains a challenge. In this work, we present a novel approach to determine the shape parameter in RBFs. First, we construct an optimisation problem to obtain a shape parameter that leads to an interpolation matrix with bounded condition number, then, we introduce a data-driven method that controls the condition of the interpolation matrix to avoid numerically unstable interpolations, while keeping a very good accuracy. In addition, a fall-back procedure is proposed to enforce a strict upper bound on the condition number, as well as a learning strategy to improve the performance of the data-driven method by learning from previously run simulations. We present numerical test cases to assess the performance of the proposed methods in interpolation tasks and in a RBF based finite difference (RBF-FD) method, in one and two-space dimensions.", "published": "2024-10-31 04:00:00", "id": "f1045ddc-273b-42e9-aa23-e62fb94b4ad9", "source": "arxiv", "section": "computerScience"}, {"title": "Impacts of floating-point non-associativity on reproducibility for HPC and deep learning applications", "link": "https://arxiv.org/abs/2408.05148", "description": "arXiv:2408.05148v3 Announce Type: replace \nAbstract: Run to run variability in parallel programs caused by floating-point non-associativity has been known to significantly affect reproducibility in iterative algorithms, due to accumulating errors. Non-reproducibility can critically affect the efficiency and effectiveness of correctness testing for stochastic programs. Recently, the sensitivity of deep learning training and inference pipelines to floating-point non-associativity has been found to sometimes be extreme. It can prevent certification for commercial applications, accurate assessment of robustness and sensitivity, and bug detection. New approaches in scientific computing applications have coupled deep learning models with high-performance computing, leading to an aggravation of debugging and testing challenges. Here we perform an investigation of the statistical properties of floating-point non-associativity within modern parallel programming models, and analyze performance and productivity impacts of replacing atomic operations with deterministic alternatives on GPUs. We examine the recently-added deterministic options in PyTorch within the context of GPU deployment for deep learning, uncovering and quantifying the impacts of input parameters triggering run to run variability and reporting on the reliability and completeness of the documentation. Finally, we evaluate the strategy of exploiting automatic determinism that could be provided by deterministic hardware, using the Groq accelerator for inference portions of the deep learning pipeline. We demonstrate the benefits that a hardware-based strategy can provide within reproducibility and correctness efforts.", "published": "2024-10-31 04:00:00", "id": "d1b5d067-70ca-4b4f-a016-002208c53634", "source": "arxiv", "section": "computerScience"}, {"title": "Evaluating LLMs on Entity Disambiguation in Tables", "link": "https://arxiv.org/abs/2408.06423", "description": "arXiv:2408.06423v2 Announce Type: replace \nAbstract: Tables are crucial containers of information, but understanding their meaning may be challenging. Over the years, there has been a surge in interest in data-driven approaches based on deep learning that have increasingly been combined with heuristic-based ones. In the last period, the advent of \\acf{llms} has led to a new category of approaches for table annotation. However, these approaches have not been consistently evaluated on a common ground, making evaluation and comparison difficult. This work proposes an extensive evaluation of four STI SOTA approaches: Alligator (formerly s-elbat), Dagobah, TURL, and TableLlama; the first two belong to the family of heuristic-based algorithms, while the others are respectively encoder-only and decoder-only Large Language Models (LLMs). We also include in the evaluation both GPT-4o and GPT-4o-mini, since they excel in various public benchmarks. The primary objective is to measure the ability of these approaches to solve the entity disambiguation task with respect to both the performance achieved on a common-ground evaluation setting and the computational and cost requirements involved, with the ultimate aim of charting new research paths in the field.", "published": "2024-10-31 04:00:00", "id": "75461dab-f053-4fcd-a4e0-c51ebf99261a", "source": "arxiv", "section": "computerScience"}, {"title": "Hybrid SD: Edge-Cloud Collaborative Inference for Stable Diffusion Models", "link": "https://arxiv.org/abs/2408.06646", "description": "arXiv:2408.06646v2 Announce Type: replace \nAbstract: Stable Diffusion Models (SDMs) have shown remarkable proficiency in image synthesis. However, their broad application is impeded by their large model sizes and intensive computational requirements, which typically require expensive cloud servers for deployment. On the flip side, while there are many compact models tailored for edge devices that can reduce these demands, they often compromise on semantic integrity and visual quality when compared to full-sized SDMs. To bridge this gap, we introduce Hybrid SD, an innovative, training-free SDMs inference framework designed for edge-cloud collaborative inference. Hybrid SD distributes the early steps of the diffusion process to the large models deployed on cloud servers, enhancing semantic planning. Furthermore, small efficient models deployed on edge devices can be integrated for refining visual details in the later stages. Acknowledging the diversity of edge devices with differing computational and storage capacities, we employ structural pruning to the SDMs U-Net and train a lightweight VAE. Empirical evaluations demonstrate that our compressed models achieve state-of-the-art parameter efficiency (225.8M) on edge devices with competitive image quality. Additionally, Hybrid SD reduces the cloud cost by 66% with edge-cloud collaborative inference.", "published": "2024-10-31 04:00:00", "id": "2ceb753a-a3ef-4189-b1dc-6f82effbff81", "source": "arxiv", "section": "computerScience"}, {"title": "Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models", "link": "https://arxiv.org/abs/2408.09053", "description": "arXiv:2408.09053v2 Announce Type: replace \nAbstract: Parameter-efficient fine-tuning (PEFT) methods are increasingly used with pre-trained language models (PLMs) for continual learning (CL). These methods typically involve training a PEFT module for each new task and employing similarity-based selection to route modules during inference. However, they face two major limitations: 1) interference during module training with already learned modules and 2) suboptimal routing when composing modules. In this paper, we present L2R, a method that isolates the training of new PEFT modules to ensure their task specialization. L2R then learns to compose the learned modules by training a network of routers that leverages a small memory containing examples of previously seen tasks. We evaluate our method in two CL setups using various benchmarks. Our results demonstrate that L2R provides an effective composition of PEFT modules, leading to improved generalization and performance compared to other methods.", "published": "2024-10-31 04:00:00", "id": "229bf711-382b-4b7a-886d-77fbe645abf3", "source": "arxiv", "section": "computerScience"}, {"title": "Reward Difference Optimization For Sample Reweighting In Offline RLHF", "link": "https://arxiv.org/abs/2408.09385", "description": "arXiv:2408.09385v2 Announce Type: replace \nAbstract: With the rapid advances in Large Language Models (LLMs), aligning LLMs with human preferences become increasingly important. Although Reinforcement Learning with Human Feedback (RLHF) proves effective, it is complicated and highly resource-intensive. As such, offline RLHF has been introduced as an alternative solution, which directly optimizes LLMs with ranking losses on a fixed preference dataset. Current offline RLHF only captures the \"ordinal relationship\" between responses, overlooking the crucial aspect of how much one is preferred over the others. To address this issue, we propose a simple yet effective solution called Reward Difference Optimization, shorted as RDO. Specifically, we introduce reward difference coefficients to reweigh sample pairs in offline RLHF. We then develop a difference model which captures rich interactions between a pair of responses for predicting these difference coefficients. Experiments with 7B LLMs on the HH and TL;DR datasets substantiate the effectiveness of our method in both automatic metrics and human evaluation, thereby highlighting its potential for aligning LLMs with human intent and values", "published": "2024-10-31 04:00:00", "id": "89be8d73-58fc-43c0-8cfb-2b64bddefd92", "source": "arxiv", "section": "computerScience"}, {"title": "A Benchmark for AI-based Weather Data Assimilation", "link": "https://arxiv.org/abs/2408.11438", "description": "arXiv:2408.11438v2 Announce Type: replace \nAbstract: Recent advancements in Artificial Intelligence (AI) have led to the development of several Large Weather Models (LWMs) that rival State-Of-The-Art (SOTA) Numerical Weather Prediction (NWP) systems. Until now, these models have still relied on traditional NWP-generated analysis fields as input and are far from autonomous. Currently, scientists are increasingly focusing on developing data-driven data assimilation (DA) models for LWMs. To expedite advancements in this field and facilitate the operationalization of data-driven end-to-end weather forecasting systems, we propose DABench, a benchmark constructed by simulated observations, real-world observations, and ERA5 reanalysis. DABench contributes four standard features: (1) sparse and noisy observations provided for both simulated and real-world experiments; (2) a Skillful pre-trained Transformer-based weather prediction model, Sformer, designed to generate background fields while rigorously assessing the impact of assimilation outcomes on predictions; (3) standardized evaluation metrics for the model comparison; (4) a strong DA baseline, 4DVarFormerV2. Our experimental results demonstrate that the end-to-end weather forecasting system, integrating 4DVarFormerV2 and Sformer, can assimilate real-world observations, thereby facilitating a stable DA cycle lasting one year and achieving a skillful forecasting lead time of up to 7 days. The proposed DABench will significantly advance research in AI-based DA, AI-based weather forecasting, and related domains.", "published": "2024-10-31 04:00:00", "id": "e7f152a6-973b-424f-bd89-c01ac19cbb79", "source": "arxiv", "section": "computerScience"}, {"title": "Mutagenesis screen to map the functions of parameters of Large Language Models", "link": "https://arxiv.org/abs/2408.11494", "description": "arXiv:2408.11494v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have significantly advanced artificial intelligence, excelling in numerous tasks. Although the functionality of a model is inherently tied to its parameters, a systematic method for exploring the connections between the parameters and the functionality are lacking. Models sharing similar structure and parameter counts exhibit significant performance disparities across various tasks, prompting investigations into the varying patterns that govern their performance. We adopted a mutagenesis screen approach inspired by the methods used in biological studies, to investigate Llama2-7b and Zephyr. This technique involved mutating elements within the models' matrices to their maximum or minimum values to examine the relationship between model parameters and their functionalities. Our research uncovered multiple levels of fine structures within both models. Many matrices showed a mixture of maximum and minimum mutations following mutagenesis, but others were predominantly sensitive to one type. Notably, mutations that produced phenotypes, especially those with severe outcomes, tended to cluster along axes. Additionally, the location of maximum and minimum mutations often displayed a complementary pattern on matrix in both models, with the Gate matrix showing a unique two-dimensional asymmetry after rearrangement. In Zephyr, certain mutations consistently resulted in poetic or conversational rather than descriptive outputs. These \"writer\" mutations grouped according to the high-frequency initial word of the output, with a marked tendency to share the row coordinate even when they are in different matrices. Our findings affirm that the mutagenesis screen is an effective tool for deciphering the complexities of large language models and identifying unexpected ways to expand their potential, providing deeper insights into the foundational aspects of AI systems.", "published": "2024-10-31 04:00:00", "id": "c46cd600-ae71-4992-b658-ff7c87cc6d2e", "source": "arxiv", "section": "computerScience"}, {"title": "On the Credibility of Backdoor Attacks Against Object Detectors in the Physical World", "link": "https://arxiv.org/abs/2408.12122", "description": "arXiv:2408.12122v2 Announce Type: replace \nAbstract: Object detectors are vulnerable to backdoor attacks. In contrast to classifiers, detectors possess unique characteristics, architecturally and in task execution; often operating in challenging conditions, for instance, detecting traffic signs in autonomous cars. But, our knowledge dominates attacks against classifiers and tests in the \"digital domain\".\n  To address this critical gap, we conducted an extensive empirical study targeting multiple detector architectures and two challenging detection tasks in real-world settings: traffic signs and vehicles. Using the diverse, methodically collected videos captured from driving cars and flying drones, incorporating physical object trigger deployments in authentic scenes, we investigated the viability of physical object-triggered backdoor attacks in application settings.\n  Our findings revealed 8 key insights. Importantly, the prevalent \"digital\" data poisoning method for injecting backdoors into models does not lead to effective attacks against detectors in the real world, although proven effective in classification tasks. We construct a new, cost-efficient attack method, dubbed MORPHING, incorporating the unique nature of detection tasks; ours is remarkably successful in injecting physical object-triggered backdoors, even capable of poisoning triggers with clean label annotations or invisible triggers without diminishing the success of physical object triggered backdoors. We discovered that the defenses curated are ill-equipped to safeguard detectors against such attacks. To underscore the severity of the threat and foster further research, we, for the first time, release an extensive video test set of real-world backdoor attacks. Our study not only establishes the credibility and seriousness of this threat but also serves as a clarion call to the research community to advance backdoor defenses in the context of object detection.", "published": "2024-10-31 04:00:00", "id": "da62a54c-ba42-4476-9eb9-750ce6f8090e", "source": "arxiv", "section": "computerScience"}, {"title": "The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities", "link": "https://arxiv.org/abs/2408.13296", "description": "arXiv:2408.13296v3 Announce Type: replace \nAbstract: This report examines the fine-tuning of Large Language Models (LLMs), integrating theoretical insights with practical applications. It outlines the historical evolution of LLMs from traditional Natural Language Processing (NLP) models to their pivotal role in AI. A comparison of fine-tuning methodologies, including supervised, unsupervised, and instruction-based approaches, highlights their applicability to different tasks. The report introduces a structured seven-stage pipeline for fine-tuning LLMs, spanning data preparation, model initialization, hyperparameter tuning, and model deployment. Emphasis is placed on managing imbalanced datasets and optimization techniques. Parameter-efficient methods like Low-Rank Adaptation (LoRA) and Half Fine-Tuning are explored for balancing computational efficiency with performance. Advanced techniques such as memory fine-tuning, Mixture of Experts (MoE), and Mixture of Agents (MoA) are discussed for leveraging specialized networks and multi-agent collaboration. The report also examines novel approaches like Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO), which align LLMs with human preferences, alongside pruning and routing optimizations to improve efficiency. Further sections cover validation frameworks, post-deployment monitoring, and inference optimization, with attention to deploying LLMs on distributed and cloud-based platforms. Emerging areas such as multimodal LLMs, fine-tuning for audio and speech, and challenges related to scalability, privacy, and accountability are also addressed. This report offers actionable insights for researchers and practitioners navigating LLM fine-tuning in an evolving landscape.", "published": "2024-10-31 04:00:00", "id": "c9a853a5-172c-4d25-acee-046f93415335", "source": "arxiv", "section": "computerScience"}, {"title": "Investigating Language-Specific Calibration For Pruning Multilingual Large Language Models", "link": "https://arxiv.org/abs/2408.14398", "description": "arXiv:2408.14398v3 Announce Type: replace \nAbstract: Recent advances in large language model (LLM) pruning have shown state-of-the-art (SotA) compression results in post-training and retraining-free settings while maintaining high predictive performance. However, previous research mainly considered calibrating based on English text, despite the multilingual nature of modern LLMs and their frequent use in non-English languages. In this paper, we set out to investigate calibrating the pruning of multilingual language models for monolingual applications. We present the first comprehensive empirical study, comparing different calibration languages for pruning multilingual models across diverse languages, tasks, models, and SotA pruning techniques. Our results offer practical suggestions, for example, calibrating in the target language can efficiently retain the language modeling capability but does not necessarily benefit downstream tasks. Through further analysis of latent subspaces, pruning masks, and individual neurons within pruned models, we find that while pruning generally preserves strong language-specific features, it may fail to retain language-specific neuron activation patterns and subtle, language-agnostic features associated with knowledge and reasoning that are needed for complex tasks.", "published": "2024-10-31 04:00:00", "id": "2161eb95-7793-4e1b-9c4c-d1a2da270897", "source": "arxiv", "section": "computerScience"}, {"title": "No Regrets: Investigating and Improving Regret Approximations for Curriculum Discovery", "link": "https://arxiv.org/abs/2408.15099", "description": "arXiv:2408.15099v3 Announce Type: replace \nAbstract: What data or environments to use for training to improve downstream performance is a longstanding and very topical question in reinforcement learning. In particular, Unsupervised Environment Design (UED) methods have gained recent attention as their adaptive curricula promise to enable agents to be robust to in- and out-of-distribution tasks. This work investigates how existing UED methods select training environments, focusing on task prioritisation metrics. Surprisingly, despite methods aiming to maximise regret in theory, the practical approximations do not correlate with regret but with success rate. As a result, a significant portion of an agent's experience comes from environments it has already mastered, offering little to no contribution toward enhancing its abilities. Put differently, current methods fail to predict intuitive measures of ``learnability.'' Specifically, they are unable to consistently identify those scenarios that the agent can sometimes solve, but not always. Based on our analysis, we develop a method that directly trains on scenarios with high learnability. This simple and intuitive approach outperforms existing UED methods in several binary-outcome environments, including the standard domain of Minigrid and a novel setting closely inspired by a real-world robotics problem. We further introduce a new adversarial evaluation procedure for directly measuring robustness, closely mirroring the conditional value at risk (CVaR). We open-source all our code and present visualisations of final policies here: https://github.com/amacrutherford/sampling-for-learnability.", "published": "2024-10-31 04:00:00", "id": "e22b1bc3-0a88-452c-975a-76eedc1699b5", "source": "arxiv", "section": "computerScience"}, {"title": "Unifying Model Execution and Deductive Verification with Interaction Trees in Isabelle/HOL", "link": "https://arxiv.org/abs/2408.15817", "description": "arXiv:2408.15817v2 Announce Type: replace \nAbstract: Model execution allows us to prototype and analyse software engineering models by stepping through their possible behaviours, using techniques like animation and simulation. On the other hand, deductive verification allows us to construct formal proofs demonstrating satisfaction of certain critical properties in support of high-assurance software engineering. To ensure coherent results between execution and proof, we need unifying semantics and automation. In this paper, we mechanise Interaction Trees (ITrees) in Isabelle/HOL to produce an execution and verification framework. ITrees are coinductive structures that allow us to encode infinite labelled transition systems, yet they are inherently executable. We use ITrees to create verification tools for stateful imperative programs, concurrent programs with message passing in the form of the CSP and \\Circus languages, and abstract system models in the style of the Z and B methods. We demonstrate how ITrees can account for diverse semantic presentations, such as structural operational semantics, a relational program model, and CSP's failures-divergences trace model. Finally, we demonstrate how ITrees can be executed using the Isabelle code generator to support the animation of models.", "published": "2024-10-31 04:00:00", "id": "4aaea70b-1d8f-4626-9b1d-2e1ca097aa0f", "source": "arxiv", "section": "computerScience"}, {"title": "Robust Statistical Scaling of Outlier Scores: Improving the Quality of Outlier Probabilities for Outliers (Extended Version)", "link": "https://arxiv.org/abs/2408.15874", "description": "arXiv:2408.15874v3 Announce Type: replace \nAbstract: Outlier detection algorithms typically assign an outlier score to each observation in a dataset, indicating the degree to which an observation is an outlier. However, these scores are often not comparable across algorithms and can be difficult for humans to interpret. Statistical scaling addresses this problem by transforming outlier scores into outlier probabilities without using ground-truth labels, thereby improving interpretability and comparability across algorithms. However, the quality of this transformation can be different for outliers and inliers. Missing outliers in scenarios where they are of particular interest - such as healthcare, finance, or engineering - can be costly or dangerous. Thus, ensuring good probabilities for outliers is essential. This paper argues that statistical scaling, as commonly used in the literature, does not produce equally good probabilities for outliers as for inliers. Therefore, we propose robust statistical scaling, which uses robust estimators to improve the probabilities for outliers. We evaluate several variants of our method against other outlier score transformations for real-world datasets and outlier detection algorithms, where it can improve the probabilities for outliers.", "published": "2024-10-31 04:00:00", "id": "8714ae4a-705a-419d-97de-e029ca947b67", "source": "arxiv", "section": "computerScience"}, {"title": "The Sample-Communication Complexity Trade-off in Federated Q-Learning", "link": "https://arxiv.org/abs/2408.16981", "description": "arXiv:2408.16981v2 Announce Type: replace \nAbstract: We consider the problem of federated Q-learning, where $M$ agents aim to collaboratively learn the optimal Q-function of an unknown infinite-horizon Markov decision process with finite state and action spaces. We investigate the trade-off between sample and communication complexities for the widely used class of intermittent communication algorithms. We first establish the converse result, where it is shown that a federated Q-learning algorithm that offers any speedup with respect to the number of agents in the per-agent sample complexity needs to incur a communication cost of at least an order of $\\frac{1}{1-\\gamma}$ up to logarithmic factors, where $\\gamma$ is the discount factor. We also propose a new algorithm, called Fed-DVR-Q, which is the first federated Q-learning algorithm to simultaneously achieve order-optimal sample and communication complexities. Thus, together these results provide a complete characterization of the sample-communication complexity trade-off in federated Q-learning.", "published": "2024-10-31 04:00:00", "id": "00bf9b9e-6819-4081-9070-2f8574c3353d", "source": "arxiv", "section": "computerScience"}, {"title": "Unlocking the Wisdom of Large Language Models: An Introduction to The Path to Artificial General Intelligence", "link": "https://arxiv.org/abs/2409.01007", "description": "arXiv:2409.01007v2 Announce Type: replace \nAbstract: This booklet, \"Unlocking the Wisdom of LLM Collaborative Intelligence,\" introduces the comprehensive work \"The Path to Artificial General Intelligence.\" Through ten aphorisms, it distills the core principles of LLM Collaborative Intelligence (LCI) as a promising framework toward achieving AGI. The booklet also offers titles, abstracts, and introductions from the main chapters, along with the first two chapters in full. The second edition, released this week, includes significant enhancements to Chapters 6 to 9 and a revised preface addressing Yann LeCun's skepticism about AGI. LeCun argues that LLMs lack memory, planning, and grounding, but we propose that LCI's collaborative architecture, involving multimodal LLMs with executive, legislative, and judicial roles, overcomes these limitations. Chapters on SocraSynth, EVINCE, consciousness modeling, and behavior modeling demonstrate that collaborative LLMs with checks and balances can achieve intelligence beyond any single model's capability. By combining complementary strengths, such as world modeling and advanced sensory capabilities, LCI enables models to work together and perceive reality beyond human limitations. As with human institutions, progress depends on cooperation, not isolation. Collaborative LLMs may unlock new levels of intelligence, paving the way toward AGI.", "published": "2024-10-31 04:00:00", "id": "c96ec853-c229-48ee-9b7a-11d5c486ad06", "source": "arxiv", "section": "computerScience"}, {"title": "Real-Time Recurrent Learning using Trace Units in Reinforcement Learning", "link": "https://arxiv.org/abs/2409.01449", "description": "arXiv:2409.01449v2 Announce Type: replace \nAbstract: Recurrent Neural Networks (RNNs) are used to learn representations in partially observable environments. For agents that learn online and continually interact with the environment, it is desirable to train RNNs with real-time recurrent learning (RTRL); unfortunately, RTRL is prohibitively expensive for standard RNNs. A promising direction is to use linear recurrent architectures (LRUs), where dense recurrent weights are replaced with a complex-valued diagonal, making RTRL efficient. In this work, we build on these insights to provide a lightweight but effective approach for training RNNs in online RL. We introduce Recurrent Trace Units (RTUs), a small modification on LRUs that we nonetheless find to have significant performance benefits over LRUs when trained with RTRL. We find RTUs significantly outperform other recurrent architectures across several partially observable environments while using significantly less computation.", "published": "2024-10-31 04:00:00", "id": "2e0e62f4-df13-4a61-96d8-9d7d12d728ee", "source": "arxiv", "section": "computerScience"}, {"title": "Improving Apple Object Detection with Occlusion-Enhanced Distillation", "link": "https://arxiv.org/abs/2409.01573", "description": "arXiv:2409.01573v2 Announce Type: replace \nAbstract: Apples growing in natural environments often face severe visual obstructions from leaves and branches. This significantly increases the risk of false detections in object detection tasks, thereby escalating the challenge. Addressing this issue, we introduce a technique called \"Occlusion-Enhanced Distillation\" (OED). This approach utilizes occlusion information to regularize the learning of semantically aligned features on occluded datasets and employs Exponential Moving Average (EMA) to enhance training stability. Specifically, we first design an occlusion-enhanced dataset that integrates Grounding DINO and SAM methods to extract occluding elements such as leaves and branches from each sample, creating occlusion examples that reflect the natural growth state of fruits. Additionally, we propose a multi-scale knowledge distillation strategy, where the student network uses images with increased occlusions as inputs, while the teacher network employs images without natural occlusions. Through this setup, the strategy guides the student network to learn from the teacher across scales of semantic and local features alignment, effectively narrowing the feature distance between occluded and non-occluded targets and enhancing the robustness of object detection. Lastly, to improve the stability of the student network, we introduce the EMA strategy, which aids the student network in learning more generalized feature expressions that are less affected by the noise of individual image occlusions. Our method significantly outperforms current state-of-the-art techniques through extensive comparative experiments.", "published": "2024-10-31 04:00:00", "id": "a68c9de2-50f7-4d4c-910c-fe56aaae489e", "source": "arxiv", "section": "computerScience"}, {"title": "The Prevalence of Neural Collapse in Neural Multivariate Regression", "link": "https://arxiv.org/abs/2409.04180", "description": "arXiv:2409.04180v2 Announce Type: replace \nAbstract: Recently it has been observed that neural networks exhibit Neural Collapse (NC) during the final stage of training for the classification problem. We empirically show that multivariate regression, as employed in imitation learning and other applications, exhibits Neural Regression Collapse (NRC), a new form of neural collapse: (NRC1) The last-layer feature vectors collapse to the subspace spanned by the $n$ principal components of the feature vectors, where $n$ is the dimension of the targets (for univariate regression, $n=1$); (NRC2) The last-layer feature vectors also collapse to the subspace spanned by the last-layer weight vectors; (NRC3) The Gram matrix for the weight vectors converges to a specific functional form that depends on the covariance matrix of the targets. After empirically establishing the prevalence of (NRC1)-(NRC3) for a variety of datasets and network architectures, we provide an explanation of these phenomena by modeling the regression task in the context of the Unconstrained Feature Model (UFM), in which the last layer feature vectors are treated as free variables when minimizing the loss function. We show that when the regularization parameters in the UFM model are strictly positive, then (NRC1)-(NRC3) also emerge as solutions in the UFM optimization problem. We also show that if the regularization parameters are equal to zero, then there is no collapse. To our knowledge, this is the first empirical and theoretical study of neural collapse in the context of regression. This extension is significant not only because it broadens the applicability of neural collapse to a new category of problems but also because it suggests that the phenomena of neural collapse could be a universal behavior in deep learning.", "published": "2024-10-31 04:00:00", "id": "45b09bf2-8687-4e10-ade1-517ba39406bc", "source": "arxiv", "section": "computerScience"}, {"title": "DFabric: Scaling Out Data Parallel Applications with CXL-Ethernet Hybrid Interconnects", "link": "https://arxiv.org/abs/2409.05404", "description": "arXiv:2409.05404v2 Announce Type: replace \nAbstract: Emerging interconnects, such as CXL and NVLink, have been integrated into the intra-host topology to scale more accelerators and facilitate efficient communication between them, such as GPUs. To keep pace with the accelerator's growing computing throughput, the interconnect has seen substantial enhancement in link bandwidth, e.g., 256GBps for CXL 3.0 links, which surpasses Ethernet and InfiniBand network links by an order of magnitude or more. Consequently, when data-intensive jobs, such as LLM training, scale across multiple hosts beyond the reach limit of the interconnect, the performance is significantly hindered by the limiting bandwidth of the network infrastructure. We address the problem by proposing DFabric, a two-tier interconnect architecture. We address the problem by proposing DFabric, a two-tier interconnect architecture. First, DFabric disaggregates rack's computing units with an interconnect fabric, i.e., CXL fabric, which scales at rack-level, so that they can enjoy intra-rack efficient interconnecting. Second, DFabric disaggregates NICs from hosts, and consolidates them to form a NIC pool with CXL fabric. By providing sufficient aggregated capacity comparable to interconnect bandwidth, the NIC pool bridges efficient communication across racks or beyond the reach limit of interconnect fabric. However, the local memory accessing becomes the bottleneck when enabling each host to utilize the NIC pool efficiently. To the end, DFabric builds a memory pool with sufficient bandwidth by disaggregating host local memory and adding more memory devices. We have implemented a prototype of DFabric that can run applications transparently. We validated its performance gain by running various microbenchmarks and compute-intensive applications such as DNN and graph.", "published": "2024-10-31 04:00:00", "id": "5436fe85-716b-4a5b-bb32-6ffa9fc3b8ff", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Preference-based Linear Bandits via Human Response Time", "link": "https://arxiv.org/abs/2409.05798", "description": "arXiv:2409.05798v3 Announce Type: replace \nAbstract: Interactive preference learning systems present humans with queries as pairs of options; humans then select their preferred choice, allowing the system to infer preferences from these binary choices. While binary choice feedback is simple and widely used, it offers limited information about preference strength. To address this, we leverage human response times, which inversely correlate with preference strength, as complementary information. We introduce a computationally efficient method based on the EZ-diffusion model, combining choices and response times to estimate the underlying human utility function. Theoretical and empirical comparisons with traditional choice-only estimators show that for queries where humans have strong preferences (i.e., \"easy\" queries), response times provide valuable complementary information and enhance utility estimates. We integrate this estimator into preference-based linear bandits for fixed-budget best-arm identification. Simulations on three real-world datasets demonstrate that incorporating response times significantly accelerates preference learning.", "published": "2024-10-31 04:00:00", "id": "6b60da6e-b4a7-443b-9ae6-bf5e7c92840a", "source": "arxiv", "section": "computerScience"}, {"title": "Geometric-Averaged Preference Optimization for Soft Preference Labels", "link": "https://arxiv.org/abs/2409.06691", "description": "arXiv:2409.06691v2 Announce Type: replace \nAbstract: Many algorithms for aligning LLMs with human preferences assume that human preferences are binary and deterministic. However, human preferences can vary across individuals, and therefore should be represented distributionally. In this work, we introduce the distributional soft preference labels and improve Direct Preference Optimization (DPO) with a weighted geometric average of the LLM output likelihood in the loss function. This approach adjusts the scale of learning loss based on the soft labels such that the loss would approach zero when the responses are closer to equally preferred. This simple modification can be easily applied to any DPO-based methods and mitigate over-optimization and objective mismatch, which prior works suffer from. Our experiments simulate the soft preference labels with AI feedback from LLMs and demonstrate that geometric averaging consistently improves performance on standard benchmarks for alignment research. In particular, we observe more preferable responses than binary labels and significant improvements where modestly-confident labels are in the majority.", "published": "2024-10-31 04:00:00", "id": "f27fe37b-974f-474a-b584-2d04e808bed6", "source": "arxiv", "section": "computerScience"}, {"title": "Recent Trends of Multimodal Affective Computing: A Survey from NLP Perspective", "link": "https://arxiv.org/abs/2409.07388", "description": "arXiv:2409.07388v2 Announce Type: replace \nAbstract: Multimodal affective computing (MAC) has garnered increasing attention due to its broad applications in analyzing human behaviors and intentions, especially in text-dominated multimodal affective computing field. This survey presents the recent trends of multimodal affective computing from NLP perspective through four hot tasks: multimodal sentiment analysis, multimodal emotion recognition in conversation, multimodal aspect-based sentiment analysis and multimodal multi-label emotion recognition. The goal of this survey is to explore the current landscape of multimodal affective research, identify development trends, and highlight the similarities and differences across various tasks, offering a comprehensive report on the recent progress in multimodal affective computing from an NLP perspective. This survey covers the formalization of tasks, provides an overview of relevant works, describes benchmark datasets, and details the evaluation metrics for each task. Additionally, it briefly discusses research in multimodal affective computing involving facial expressions, acoustic signals, physiological signals, and emotion causes. Additionally, we discuss the technical approaches, challenges, and future directions in multimodal affective computing. To support further research, we released a repository that compiles related works in multimodal affective computing, providing detailed resources and references for the community.", "published": "2024-10-31 04:00:00", "id": "864e18cb-b3fa-44ef-b605-b1d71d42389e", "source": "arxiv", "section": "computerScience"}, {"title": "Still More Shades of Null: An Evaluation Suite for Responsible Missing Value Imputation", "link": "https://arxiv.org/abs/2409.07510", "description": "arXiv:2409.07510v2 Announce Type: replace \nAbstract: Data missingness is a practical challenge of sustained interest to the scientific community. In this paper, we present Shades-of-Null, an evaluation suite for responsible missing value imputation. Our work is novel in two ways (i) we model realistic and socially-salient missingness scenarios that go beyond Rubin's classic Missing Completely at Random (MCAR), Missing At Random (MAR) and Missing Not At Random (MNAR) settings, to include multi-mechanism missingness (when different missingness patterns co-exist in the data) and missingness shift (when the missingness mechanism changes between training and test) (ii) we evaluate imputers holistically, based on imputation quality, as well as on the predictive performance, fairness and stability of the models that are trained and tested on the data post-imputation.\n  We use Shades-of-Null to conduct a large-scale empirical study involving 23,940 experimental pipelines, and find that while there is no single best-performing imputation approach for all missingness types, interesting trade-offs arise between predictive performance, fairness and stability, based on the combination of missingness scenario, imputer choice, and the architecture of the predictive model. We make Shades-of-Null publicly available, to enable researchers to rigorously evaluate missing value imputation methods on a wide range of metrics in plausible and socially meaningful scenarios.", "published": "2024-10-31 04:00:00", "id": "c9cca6c8-8b28-4667-ba2b-65ae60d30b2e", "source": "arxiv", "section": "computerScience"}, {"title": "L3Cube-IndicQuest: A Benchmark Question Answering Dataset for Evaluating Knowledge of LLMs in Indic Context", "link": "https://arxiv.org/abs/2409.08706", "description": "arXiv:2409.08706v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have made significant progress in incorporating Indic languages within multilingual models. However, it is crucial to quantitatively assess whether these languages perform comparably to globally dominant ones, such as English. Currently, there is a lack of benchmark datasets specifically designed to evaluate the regional knowledge of LLMs in various Indic languages. In this paper, we present the L3Cube-IndicQuest, a gold-standard factual question-answering benchmark dataset designed to evaluate how well multilingual LLMs capture regional knowledge across various Indic languages. The dataset contains 200 question-answer pairs, each for English and 19 Indic languages, covering five domains specific to the Indic region. We aim for this dataset to serve as a benchmark, providing ground truth for evaluating the performance of LLMs in understanding and representing knowledge relevant to the Indian context. The IndicQuest can be used for both reference-based evaluation and LLM-as-a-judge evaluation. The dataset is shared publicly at https://github.com/l3cube-pune/indic-nlp .", "published": "2024-10-31 04:00:00", "id": "29e537af-f4b6-4fe3-9507-f734d30028c8", "source": "arxiv", "section": "computerScience"}, {"title": "Instigating Cooperation among LLM Agents Using Adaptive Information Modulation", "link": "https://arxiv.org/abs/2409.10372", "description": "arXiv:2409.10372v3 Announce Type: replace \nAbstract: This paper introduces a novel framework combining LLM agents as proxies for human strategic behavior with reinforcement learning (RL) to engage these agents in evolving strategic interactions within team environments. Our approach extends traditional agent-based simulations by using strategic LLM agents (SLA) and introducing dynamic and adaptive governance through a pro-social promoting RL agent (PPA) that modulates information access across agents in a network, optimizing social welfare and promoting pro-social behavior. Through validation in iterative games, including the prisoner dilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations. The PPA agent effectively learns to adjust information transparency, resulting in enhanced cooperation rates. This framework offers significant insights into AI-mediated social dynamics, contributing to the deployment of AI in real-world team settings.", "published": "2024-10-31 04:00:00", "id": "5b03f37d-9971-4bf0-8dfd-7816ebca4418", "source": "arxiv", "section": "computerScience"}, {"title": "Implicit Reasoning in Deep Time Series Forecasting", "link": "https://arxiv.org/abs/2409.10840", "description": "arXiv:2409.10840v3 Announce Type: replace \nAbstract: Recently, time series foundation models have shown promising zero-shot forecasting performance on time series from a wide range of domains. However, it remains unclear whether their success stems from a true understanding of temporal dynamics or simply from memorizing the training data. While implicit reasoning in language models has been studied, similar evaluations for time series models have been largely unexplored. This work takes an initial step toward assessing the reasoning abilities of deep time series forecasting models. We find that certain linear, MLP-based, and patch-based Transformer models generalize effectively in systematically orchestrated out-of-distribution scenarios, suggesting underexplored reasoning capabilities beyond simple pattern memorization.", "published": "2024-10-31 04:00:00", "id": "c11f8ad8-8749-447d-afd3-1426cbe33d49", "source": "arxiv", "section": "computerScience"}, {"title": "GStex: Per-Primitive Texturing of 2D Gaussian Splatting for Decoupled Appearance and Geometry Modeling", "link": "https://arxiv.org/abs/2409.12954", "description": "arXiv:2409.12954v2 Announce Type: replace \nAbstract: Gaussian splatting has demonstrated excellent performance for view synthesis and scene reconstruction. The representation achieves photorealistic quality by optimizing the position, scale, color, and opacity of thousands to millions of 2D or 3D Gaussian primitives within a scene. However, since each Gaussian primitive encodes both appearance and geometry, these attributes are strongly coupled--thus, high-fidelity appearance modeling requires a large number of Gaussian primitives, even when the scene geometry is simple (e.g., for a textured planar surface). We propose to texture each 2D Gaussian primitive so that even a single Gaussian can be used to capture appearance details. By employing per-primitive texturing, our appearance representation is agnostic to the topology and complexity of the scene's geometry. We show that our approach, GStex, yields improved visual quality over prior work in texturing Gaussian splats. Furthermore, we demonstrate that our decoupling enables improved novel view synthesis performance compared to 2D Gaussian splatting when reducing the number of Gaussian primitives, and that GStex can be used for scene appearance editing and re-texturing.", "published": "2024-10-31 04:00:00", "id": "4815a480-e846-4886-8c10-3820624f6337", "source": "arxiv", "section": "computerScience"}, {"title": "Knowledge in Triples for LLMs: Enhancing Table QA Accuracy with Semantic Extraction", "link": "https://arxiv.org/abs/2409.14192", "description": "arXiv:2409.14192v2 Announce Type: replace \nAbstract: Integrating structured knowledge from tabular formats poses significant challenges within natural language processing (NLP), mainly when dealing with complex, semi-structured tables like those found in the FeTaQA dataset. These tables require advanced methods to interpret and generate meaningful responses accurately. Traditional approaches, such as SQL and SPARQL, often fail to fully capture the semantics of such data, especially in the presence of irregular table structures like web tables. This paper addresses these challenges by proposing a novel approach that extracts triples straightforward from tabular data and integrates it with a retrieval-augmented generation (RAG) model to enhance the accuracy, coherence, and contextual richness of responses generated by a fine-tuned GPT-3.5-turbo-0125 model. Our approach significantly outperforms existing baselines on the FeTaQA dataset, particularly excelling in Sacre-BLEU and ROUGE metrics. It effectively generates contextually accurate and detailed long-form answers from tables, showcasing its strength in complex data interpretation.", "published": "2024-10-31 04:00:00", "id": "747cfc7a-1e0e-4b0b-8892-21042b8c63f6", "source": "arxiv", "section": "computerScience"}, {"title": "Uncovering Coordinated Cross-Platform Information Operations Threatening the Integrity of the 2024 U.S. Presidential Election Online Discussion", "link": "https://arxiv.org/abs/2409.15402", "description": "arXiv:2409.15402v2 Announce Type: replace \nAbstract: Information Operations (IOs) pose a significant threat to the integrity of democratic processes, with the potential to influence election-related online discourse. In anticipation of the 2024 U.S. presidential election, we present a study aimed at uncovering the digital traces of coordinated IOs on $\\mathbb{X}$ (formerly Twitter). Using our machine learning framework for detecting online coordination, we analyze a dataset comprising election-related conversations on $\\mathbb{X}$ from May 2024. This reveals a network of coordinated inauthentic actors, displaying notable similarities in their link-sharing behaviors. Our analysis shows concerted efforts by these accounts to disseminate misleading, redundant, and biased information across the Web through a coordinated cross-platform information operation: The links shared by this network frequently direct users to other social media platforms or suspicious websites featuring low-quality political content and, in turn, promoting the same $\\mathbb{X}$ and YouTube accounts. Members of this network also shared deceptive images generated by AI, accompanied by language attacking political figures and symbolic imagery intended to convey power and dominance. While $\\mathbb{X}$ has suspended a subset of these accounts, more than 75% of the coordinated network remains active. Our findings underscore the critical role of developing computational models to scale up the detection of threats on large social media platforms, and emphasize the broader implications of these techniques to detect IOs across the wider Web.", "published": "2024-10-31 04:00:00", "id": "803b3aa6-ee94-4702-a15e-af68d80dab0d", "source": "arxiv", "section": "computerScience"}, {"title": "M$^2$PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning", "link": "https://arxiv.org/abs/2409.15657", "description": "arXiv:2409.15657v4 Announce Type: replace \nAbstract: Multimodal Large Language Models (MLLMs) demonstrate remarkable performance across a wide range of domains, with increasing emphasis on enhancing their zero-shot generalization capabilities for unseen tasks across various modalities. Instruction tuning has emerged as an effective strategy for achieving zero-shot generalization by finetuning pretrained models on diverse multimodal tasks. As the scale of MLLMs continues to grow, parameter-efficient finetuning becomes increasingly critical. However, most existing parameter-efficient approaches focus only on single modalities and often overlook the multimodal characteristics during finetuning. In this work, we introduce a novel Multimodal Prompt Tuning (M$^2$PT) approach for efficient instruction tuning of MLLMs. M$^2$PT effectively integrates visual and textual prompts into the vision encoder and language processor respectively during finetuning, facilitating the extraction and alignment of features across modalities. Empirical results on various multimodal evaluation datasets demonstrate the superior performance of our approach compared to several state-of-the-art baselines. A comprehensive set of ablation studies validates the effectiveness of our prompt design and the efficiency of our approach.", "published": "2024-10-31 04:00:00", "id": "0f87b754-b3c0-44dd-a676-f754d46a42e3", "source": "arxiv", "section": "computerScience"}, {"title": "Self-Supervised Graph Embedding Clustering", "link": "https://arxiv.org/abs/2409.15887", "description": "arXiv:2409.15887v2 Announce Type: replace \nAbstract: The K-means one-step dimensionality reduction clustering method has made some progress in addressing the curse of dimensionality in clustering tasks. However, it combines the K-means clustering and dimensionality reduction processes for optimization, leading to limitations in the clustering effect due to the introduced hyperparameters and the initialization of clustering centers. Moreover, maintaining class balance during clustering remains challenging. To overcome these issues, we propose a unified framework that integrates manifold learning with K-means, resulting in the self-supervised graph embedding framework. Specifically, we establish a connection between K-means and the manifold structure, allowing us to perform K-means without explicitly defining centroids. Additionally, we use this centroid-free K-means to generate labels in low-dimensional space and subsequently utilize the label information to determine the similarity between samples. This approach ensures consistency between the manifold structure and the labels. Our model effectively achieves one-step clustering without the need for redundant balancing hyperparameters. Notably, we have discovered that maximizing the $\\ell_{2,1}$-norm naturally maintains class balance during clustering, a result that we have theoretically proven. Finally, experiments on multiple datasets demonstrate that the clustering results of Our-LPP and Our-MFA exhibit excellent and reliable performance.", "published": "2024-10-31 04:00:00", "id": "1c0295e2-07c1-4eaf-841d-7f3773dfff44", "source": "arxiv", "section": "computerScience"}, {"title": "From News to Forecast: Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection", "link": "https://arxiv.org/abs/2409.17515", "description": "arXiv:2409.17515v3 Announce Type: replace \nAbstract: This paper introduces a novel approach that leverages Large Language Models (LLMs) and Generative Agents to enhance time series forecasting by reasoning across both text and time series data. With language as a medium, our method adaptively integrates social events into forecasting models, aligning news content with time series fluctuations to provide richer insights. Specifically, we utilize LLM-based agents to iteratively filter out irrelevant news and employ human-like reasoning to evaluate predictions. This enables the model to analyze complex events, such as unexpected incidents and shifts in social behavior, and continuously refine the selection logic of news and the robustness of the agent's output. By integrating selected news events with time series data, we fine-tune a pre-trained LLM to predict sequences of digits in time series. The results demonstrate significant improvements in forecasting accuracy, suggesting a potential paradigm shift in time series forecasting through the effective utilization of unstructured news data.", "published": "2024-10-31 04:00:00", "id": "2a3ce37b-bf67-4907-9d8b-9e9ca098ad28", "source": "arxiv", "section": "computerScience"}, {"title": "ZALM3: Zero-Shot Enhancement of Vision-Language Alignment via In-Context Information in Multi-Turn Multimodal Medical Dialogue", "link": "https://arxiv.org/abs/2409.17610", "description": "arXiv:2409.17610v2 Announce Type: replace \nAbstract: The rocketing prosperity of large language models (LLMs) in recent years has boosted the prevalence of vision-language models (VLMs) in the medical sector. In our online medical consultation scenario, a doctor responds to the texts and images provided by a patient in multiple rounds to diagnose her/his health condition, forming a multi-turn multimodal medical dialogue format. Unlike high-quality images captured by professional equipment in traditional medical visual question answering (Med-VQA), the images in our case are taken by patients' mobile phones. These images have poor quality control, with issues such as excessive background elements and the lesion area being significantly off-center, leading to degradation of vision-language alignment in the model training phase. In this paper, we propose ZALM3, a Zero-shot strategy to improve vision-language ALignment in Multi-turn Multimodal Medical dialogue. Since we observe that the preceding text conversations before an image can infer the regions of interest (RoIs) in the image, ZALM3 employs an LLM to summarize the keywords from the preceding context and a visual grounding model to extract the RoIs. The updated images eliminate unnecessary background noise and provide more effective vision-language alignment. To better evaluate our proposed method, we design a new subjective assessment metric for multi-turn unimodal/multimodal medical dialogue to provide a fine-grained performance comparison. Our experiments across three different clinical departments remarkably demonstrate the efficacy of ZALM3 with statistical significance.", "published": "2024-10-31 04:00:00", "id": "e7aeb778-5967-43f0-8bf0-612e18a2be7c", "source": "arxiv", "section": "computerScience"}, {"title": "Intrinsic Robustness of Prophet Inequality to Strategic Reward Signaling", "link": "https://arxiv.org/abs/2409.18269", "description": "arXiv:2409.18269v2 Announce Type: replace \nAbstract: Prophet inequality concerns a basic optimal stopping problem and states that simple threshold stopping policies -- i.e., accepting the first reward larger than a certain threshold -- can achieve tight $\\frac{1}{2}$-approximation to the optimal prophet value. Motivated by its economic applications, this paper studies the robustness of this approximation to natural strategic manipulations in which each random reward is associated with a self-interested player who may selectively reveal his realized reward to the searcher in order to maximize his probability of being selected.\n  We say a threshold policy is $\\alpha$(-strategically)-robust if it (a) achieves the $\\alpha$-approximation to the prophet value for strategic players; and (b) meanwhile remains a $\\frac{1}{2}$-approximation in the standard non-strategic setting. Starting with a characterization of each player's optimal information revealing strategy, we demonstrate the intrinsic robustness of prophet inequalities to strategic reward signaling through the following results: (1) for arbitrary reward distributions, there is a threshold policy that is $\\frac{1-\\frac{1}{e}}{2}$-robust, and this ratio is tight; (2) for i.i.d. reward distributions, there is a threshold policy that is $\\frac{1}{2}$-robust, which is tight for the setting; and (3) for log-concave (but non-identical) reward distributions, the $\\frac{1}{2}$-robustness can also be achieved under certain regularity assumptions.", "published": "2024-10-31 04:00:00", "id": "d19b30c6-2c7e-41ef-bbfa-55df5c5d6d19", "source": "arxiv", "section": "computerScience"}, {"title": "Localizing Memorization in SSL Vision Encoders", "link": "https://arxiv.org/abs/2409.19069", "description": "arXiv:2409.19069v2 Announce Type: replace \nAbstract: Recent work on studying memorization in self-supervised learning (SSL) suggests that even though SSL encoders are trained on millions of images, they still memorize individual data points. While effort has been put into characterizing the memorized data and linking encoder memorization to downstream utility, little is known about where the memorization happens inside SSL encoders. To close this gap, we propose two metrics for localizing memorization in SSL encoders on a per-layer (layermem) and per-unit basis (unitmem). Our localization methods are independent of the downstream task, do not require any label information, and can be performed in a forward pass. By localizing memorization in various encoder architectures (convolutional and transformer-based) trained on diverse datasets with contrastive and non-contrastive SSL frameworks, we find that (1) while SSL memorization increases with layer depth, highly memorizing units are distributed across the entire encoder, (2) a significant fraction of units in SSL encoders experiences surprisingly high memorization of individual data points, which is in contrast to models trained under supervision, (3) atypical (or outlier) data points cause much higher layer and unit memorization than standard data points, and (4) in vision transformers, most memorization happens in the fully-connected layers. Finally, we show that localizing memorization in SSL has the potential to improve fine-tuning and to inform pruning strategies.", "published": "2024-10-31 04:00:00", "id": "7a209327-ac3a-42bd-ab4e-93a6aa43b8ae", "source": "arxiv", "section": "computerScience"}, {"title": "Causal Deciphering and Inpainting in Spatio-Temporal Dynamics via Diffusion Model", "link": "https://arxiv.org/abs/2409.19608", "description": "arXiv:2409.19608v2 Announce Type: replace \nAbstract: Spatio-temporal (ST) prediction has garnered a De facto attention in earth sciences, such as meteorological prediction, human mobility perception. However, the scarcity of data coupled with the high expenses involved in sensor deployment results in notable data imbalances. Furthermore, models that are excessively customized and devoid of causal connections further undermine the generalizability and interpretability. To this end, we establish a causal framework for ST predictions, termed CaPaint, which targets to identify causal regions in data and endow model with causal reasoning ability in a two-stage process. Going beyond this process, we utilize the back-door adjustment to specifically address the sub-regions identified as non-causal in the upstream phase. Specifically, we employ a novel image inpainting technique. By using a fine-tuned unconditional Diffusion Probabilistic Model (DDPM) as the generative prior, we in-fill the masks defined as environmental parts, offering the possibility of reliable extrapolation for potential data distributions. CaPaint overcomes the high complexity dilemma of optimal ST causal discovery models by reducing the data generation complexity from exponential to quasi-linear levels. Extensive experiments conducted on five real-world ST benchmarks demonstrate that integrating the CaPaint concept allows models to achieve improvements ranging from 4.3% to 77.3%. Moreover, compared to traditional mainstream ST augmenters, CaPaint underscores the potential of diffusion models in ST enhancement, offering a novel paradigm for this field. Our project is available at https://anonymous.4open.science/r/12345-DFCC.", "published": "2024-10-31 04:00:00", "id": "93aea601-04e1-42da-996a-eefd94d854b1", "source": "arxiv", "section": "computerScience"}, {"title": "Balancing Cost and Effectiveness of Synthetic Data Generation Strategies for LLMs", "link": "https://arxiv.org/abs/2409.19759", "description": "arXiv:2409.19759v3 Announce Type: replace \nAbstract: As large language models (LLMs) are applied to more use cases, creating high quality, task-specific datasets for fine-tuning becomes a bottleneck for model improvement. Using high quality human data has been the most common approach to unlock model performance, but is prohibitively expensive in many scenarios. Several alternative methods have also emerged, such as generating synthetic or hybrid data, but the effectiveness of these approaches remain unclear, especially in resource-constrained scenarios and tasks that are not easily verified. To investigate this, we group various synthetic data generation strategies into three representative categories -- Answer Augmentation, Question Rephrase and New Question -- and study the performance of student LLMs trained under various constraints, namely seed instruction set size and query budget. We demonstrate that these strategies are not equally effective across settings. Notably, the optimal data generation strategy depends strongly on the ratio between the available teacher query budget and the size of the seed instruction set. When this ratio is low, generating new answers to existing questions proves most effective, but as this ratio increases, generating new questions becomes optimal. Across all tasks, we find that choice of augmentation method and other design choices matter substantially more in low to mid data regimes than in high data regimes. We provide a practical framework for selecting the appropriate augmentation method across settings, taking into account additional factors such as the scalability of each method, the importance of verifying synthetic data, and the use of different LLMs for synthetic data generation.", "published": "2024-10-31 04:00:00", "id": "e0fb2343-3f39-4642-bd4d-7e85177d3738", "source": "arxiv", "section": "computerScience"}, {"title": "CycleCrash: A Dataset of Bicycle Collision Videos for Collision Prediction and Analysis", "link": "https://arxiv.org/abs/2409.19942", "description": "arXiv:2409.19942v2 Announce Type: replace \nAbstract: Self-driving research often underrepresents cyclist collisions and safety. To address this, we present CycleCrash, a novel dataset consisting of 3,000 dashcam videos with 436,347 frames that capture cyclists in a range of critical situations, from collisions to safe interactions. This dataset enables 9 different cyclist collision prediction and classification tasks focusing on potentially hazardous conditions for cyclists and is annotated with collision-related, cyclist-related, and scene-related labels. Next, we propose VidNeXt, a novel method that leverages a ConvNeXt spatial encoder and a non-stationary transformer to capture the temporal dynamics of videos for the tasks defined in our dataset. To demonstrate the effectiveness of our method and create additional baselines on CycleCrash, we apply and compare 7 models along with a detailed ablation. We release the dataset and code at https://github.com/DeSinister/CycleCrash/ .", "published": "2024-10-31 04:00:00", "id": "8cbed29e-edd2-419e-9f7b-60c85791d874", "source": "arxiv", "section": "computerScience"}, {"title": "LexEval: A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models", "link": "https://arxiv.org/abs/2409.20288", "description": "arXiv:2409.20288v3 Announce Type: replace \nAbstract: Large language models (LLMs) have made significant progress in natural language processing tasks and demonstrate considerable potential in the legal domain. However, legal applications demand high standards of accuracy, reliability, and fairness. Applying existing LLMs to legal systems without careful evaluation of their potential and limitations could pose significant risks in legal practice. To this end, we introduce a standardized comprehensive Chinese legal benchmark LexEval. This benchmark is notable in the following three aspects: (1) Ability Modeling: We propose a new taxonomy of legal cognitive abilities to organize different tasks. (2) Scale: To our knowledge, LexEval is currently the largest Chinese legal evaluation dataset, comprising 23 tasks and 14,150 questions. (3) Data: we utilize formatted existing datasets, exam datasets and newly annotated datasets by legal experts to comprehensively evaluate the various capabilities of LLMs. LexEval not only focuses on the ability of LLMs to apply fundamental legal knowledge but also dedicates efforts to examining the ethical issues involved in their application. We evaluated 38 open-source and commercial LLMs and obtained some interesting findings. The experiments and findings offer valuable insights into the challenges and potential solutions for developing Chinese legal systems and LLM evaluation pipelines. The LexEval dataset and leaderboard are publicly available at \\url{https://github.com/CSHaitao/LexEval} and will be continuously updated.", "published": "2024-10-31 04:00:00", "id": "6efaf4f1-36b2-4615-bfdd-e8e0ea4adcb6", "source": "arxiv", "section": "computerScience"}, {"title": "Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach", "link": "https://arxiv.org/abs/2410.00025", "description": "arXiv:2410.00025v2 Announce Type: replace \nAbstract: Recent progress in Spoken Language Modeling has shown that learning language directly from speech is feasible. Generating speech through a pipeline that operates at the text level typically loses nuances, intonations, and non-verbal vocalizations. Modeling directly from speech opens up the path to more natural and expressive systems. On the other hand, speech-only systems require up to three orders of magnitude more data to catch up to their text-based counterparts in terms of their semantic abilities. We show that fine-tuning speech representation models on phoneme classification leads to more context-invariant representations, and language models trained on these units achieve comparable lexical comprehension to ones trained on hundred times more data.", "published": "2024-10-31 04:00:00", "id": "2deb0752-6f62-42f9-b10d-ce084f8557d3", "source": "arxiv", "section": "computerScience"}, {"title": "A Hitchhikers Guide to Fine-Grained Face Forgery Detection Using Common Sense Reasoning", "link": "https://arxiv.org/abs/2410.00485", "description": "arXiv:2410.00485v2 Announce Type: replace \nAbstract: Explainability in artificial intelligence is crucial for restoring trust, particularly in areas like face forgery detection, where viewers often struggle to distinguish between real and fabricated content. Vision and Large Language Models (VLLM) bridge computer vision and natural language, offering numerous applications driven by strong common-sense reasoning. Despite their success in various tasks, the potential of vision and language remains underexplored in face forgery detection, where they hold promise for enhancing explainability by leveraging the intrinsic reasoning capabilities of language to analyse fine-grained manipulation areas. As such, there is a need for a methodology that converts face forgery detection to a Visual Question Answering (VQA) task to systematically and fairly evaluate these capabilities. Previous efforts for unified benchmarks in deepfake detection have focused on the simpler binary task, overlooking evaluation protocols for fine-grained detection and text-generative models. We propose a multi-staged approach that diverges from the traditional binary decision paradigm to address this gap. In the first stage, we assess the models' performance on the binary task and their sensitivity to given instructions using several prompts. In the second stage, we delve deeper into fine-grained detection by identifying areas of manipulation in a multiple-choice VQA setting. In the third stage, we convert the fine-grained detection to an open-ended question and compare several matching strategies for the multi-label classification task. Finally, we qualitatively evaluate the fine-grained responses of the VLLMs included in the benchmark. We apply our benchmark to several popular models, providing a detailed comparison of binary, multiple-choice, and open-ended VQA evaluation across seven datasets. \\url{https://nickyfot.github.io/hitchhickersguide.github.io/}", "published": "2024-10-31 04:00:00", "id": "1043ab7d-ed46-47fc-bd97-98e878fcd2d1", "source": "arxiv", "section": "computerScience"}, {"title": "EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis", "link": "https://arxiv.org/abs/2410.01804", "description": "arXiv:2410.01804v5 Announce Type: replace \nAbstract: We present Exact Volumetric Ellipsoid Rendering (EVER), a method for real-time differentiable emission-only volume rendering. Unlike recent rasterization based approach by 3D Gaussian Splatting (3DGS), our primitive based representation allows for exact volume rendering, rather than alpha compositing 3D Gaussian billboards. As such, unlike 3DGS our formulation does not suffer from popping artifacts and view dependent density, but still achieves frame rates of $\\sim\\!30$ FPS at 720p on an NVIDIA RTX4090. Since our approach is built upon ray tracing it enables effects such as defocus blur and camera distortion (e.g. such as from fisheye cameras), which are difficult to achieve by rasterization. We show that our method is more accurate with fewer blending issues than 3DGS and follow-up work on view-consistent rendering, especially on the challenging large-scale scenes from the Zip-NeRF dataset where it achieves sharpest results among real-time techniques.", "published": "2024-10-31 04:00:00", "id": "c210f4b4-d541-4415-a5ea-f66871518d13", "source": "arxiv", "section": "computerScience"}, {"title": "Comparison of Autoencoder Encodings for ECG Representation in Downstream Prediction Tasks", "link": "https://arxiv.org/abs/2410.02937", "description": "arXiv:2410.02937v2 Announce Type: replace \nAbstract: The electrocardiogram (ECG) is an inexpensive and widely available tool for cardiovascular assessment. Despite its standardized format and small file size, the high complexity and inter-individual variability of ECG signals (typically a 60,000-size vector) make it challenging to use in deep learning models, especially when only small datasets are available. This study addresses these challenges by exploring feature generation methods from representative beat ECGs, focusing on Principal Component Analysis (PCA) and Autoencoders to reduce data complexity. We introduce three novel Variational Autoencoder (VAE) variants: Stochastic Autoencoder (SAE), Annealed beta-VAE (Abeta-VAE), and cyclical beta-VAE (Cbeta-VAE), and compare their effectiveness in maintaining signal fidelity and enhancing downstream prediction tasks. The Abeta-VAE achieved superior signal reconstruction, reducing the mean absolute error (MAE) to 15.7 plus-minus 3.2 microvolts, which is at the level of signal noise. Moreover, the SAE encodings, when combined with ECG summary features, improved the prediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an area under the receiver operating characteristic curve (AUROC) of 0.901. This performance nearly matches the 0.910 AUROC of state-of-the-art CNN models but requires significantly less data and computational resources. Our findings demonstrate that these VAE encodings are not only effective in simplifying ECG data but also provide a practical solution for applying deep learning in contexts with limited-scale labeled training data.", "published": "2024-10-31 04:00:00", "id": "50cf41fd-0006-4038-becb-917ec0cffba8", "source": "arxiv", "section": "computerScience"}, {"title": "Resource-aware Mixed-precision Quantization for Enhancing Deployability of Transformers for Time-series Forecasting on Embedded FPGAs", "link": "https://arxiv.org/abs/2410.03294", "description": "arXiv:2410.03294v3 Announce Type: replace \nAbstract: This study addresses the deployment challenges of integer-only quantized Transformers on resource-constrained embedded FPGAs (Xilinx Spartan-7 XC7S15). We enhanced the flexibility of our VHDL template by introducing a selectable resource type for storing intermediate results across model layers, thereby breaking the deployment bottleneck by utilizing BRAM efficiently. Moreover, we developed a resource-aware mixed-precision quantization approach that enables researchers to explore hardware-level quantization strategies without requiring extensive expertise in Neural Architecture Search. This method provides accurate resource utilization estimates with a precision discrepancy as low as 3%, compared to actual deployment metrics. Compared to previous work, our approach has successfully facilitated the deployment of model configurations utilizing mixed-precision quantization, thus overcoming the limitations inherent in five previously non-deployable configurations with uniform quantization bitwidths. Consequently, this research enhances the applicability of Transformers in embedded systems, facilitating a broader range of Transformer-powered applications on edge devices.", "published": "2024-10-31 04:00:00", "id": "417d6a12-39a4-43d2-8ef6-b21de22c6343", "source": "arxiv", "section": "computerScience"}, {"title": "PRF: Parallel Resonate and Fire Neuron for Long Sequence Learning in Spiking Neural Networks", "link": "https://arxiv.org/abs/2410.03530", "description": "arXiv:2410.03530v2 Announce Type: replace \nAbstract: Recently, there is growing demand for effective and efficient long sequence modeling, with State Space Models (SSMs) proving to be effective for long sequence tasks. To further reduce energy consumption, SSMs can be adapted to Spiking Neural Networks (SNNs) using spiking functions. However, current spiking-formalized SSMs approaches still rely on float-point matrix-vector multiplication during inference, undermining SNNs' energy advantage. In this work, we address the efficiency and performance challenges of long sequence learning in SNNs simultaneously. First, we propose a decoupled reset method for parallel spiking neuron training, reducing the typical Leaky Integrate-and-Fire (LIF) model's training time from $O(L^2)$ to $O(L\\log L)$, effectively speeding up the training by $6.57 \\times$ to $16.50 \\times$ on sequence lengths $1,024$ to $32,768$. To our best knowledge, this is the first time that parallel computation with a reset mechanism is implemented achieving equivalence to its sequential counterpart. Secondly, to capture long-range dependencies, we propose a Parallel Resonate and Fire (PRF) neuron, which leverages an oscillating membrane potential driven by a resonate mechanism from a differentiable reset function in the complex domain. The PRF enables efficient long sequence learning while maintaining parallel training. Finally, we demonstrate that the proposed spike-driven architecture using PRF achieves performance comparable to Structured SSMs (S4), with two orders of magnitude reduction in energy consumption, outperforming Transformer on Long Range Arena tasks.", "published": "2024-10-31 04:00:00", "id": "64e6bb87-154a-4251-a8b4-b59dae0d3c2e", "source": "arxiv", "section": "computerScience"}, {"title": "AraSync: Precision Time Synchronization in Rural Wireless Living Lab", "link": "https://arxiv.org/abs/2410.03583", "description": "arXiv:2410.03583v2 Announce Type: replace \nAbstract: Time synchronization is a critical component in network operation and management, and it is also required by Ultra-Reliable, Low-Latency Communications (URLLC) in next-generation wireless systems such as those of 5G, 6G, and Open RAN. In this context, we design and implement AraSync as an end-to-end time synchronization system in the ARA wireless living lab to enable advanced wireless experiments and applications involving stringent time constraints. We make use of Precision Time Protocol (PTP) at different levels to achieve synchronization accuracy in the order of nanoseconds. Along with fiber networks, AraSync enables time synchronization across the AraHaul wireless x-haul network consisting of long-range, high-capacity mmWave and microwave links. In this paper, we present the detailed design and implementation of AraSync, including its hardware and software components and the PTP network topology. Further, we experimentally characterize the performance of AraSync from spatial and temporal dimensions. Our measurement and analysis of the clock offset and mean path delay show the impact of the wireless channel and weather conditions on the PTP synchronization accuracy.", "published": "2024-10-31 04:00:00", "id": "7cdaf595-0409-4f7f-a810-6190a3698454", "source": "arxiv", "section": "computerScience"}, {"title": "System 2 Reasoning Capabilities Are Nigh", "link": "https://arxiv.org/abs/2410.03662", "description": "arXiv:2410.03662v2 Announce Type: replace \nAbstract: In recent years, machine learning models have made strides towards human-like reasoning capabilities from several directions. In this work, we review the current state of the literature and describe the remaining steps to achieve a neural model which can perform System~2 reasoning analogous to a human. We argue that if current models are insufficient to be classed as performing reasoning, there remains very little additional progress needed to attain that goal.", "published": "2024-10-31 04:00:00", "id": "d63f3ed2-a649-4269-9ca2-c1853ce82213", "source": "arxiv", "section": "computerScience"}, {"title": "The $Z$-Curve as an $n$-Dimensional Hypersphere: Properties and Analysis", "link": "https://arxiv.org/abs/2410.04611", "description": "arXiv:2410.04611v2 Announce Type: replace \nAbstract: In this research, we introduce an algorithm that produces what appears to be a new mathematical object as a consequence of projecting the \\( n \\)-dimensional \\( Z \\)-curve onto an \\( n \\)-dimensional sphere. The first part presents the algorithm that enables this transformation, and the second part focuses on studying its properties.", "published": "2024-10-31 04:00:00", "id": "04879379-e699-4532-8d43-3191764e8076", "source": "arxiv", "section": "computerScience"}, {"title": "Disruption Risk Evaluation on Large-scale Production Network with Establishments and Products", "link": "https://arxiv.org/abs/2410.05595", "description": "arXiv:2410.05595v2 Announce Type: replace \nAbstract: We constructed an establishment-level production network where each establishment inputs and outputs multiple products, using data that includes the firm-level production network and establishments covering nearly all Japanese entities. The network represents the manufacturing sector with 183,951 establishments across 157,537 firms and 919,982 inter-establishment linkages. A probabilistic model of supply chain disruptions was applied to this network. The key findings are as follows: (1) The establishment-level network exhibits greater shock propagation compared to the firm-level network. (2) Incorporating actual product information leads to a larger impact on propagation compared to using industry-level information. (3) Regional shock simulations reveal that while the firm-level network shows greater shock propagation when the shock originates in Tokyo, no such difference is observed in the establishment-level network.", "published": "2024-10-31 04:00:00", "id": "02fe6bd6-1716-4ea5-8222-ee2cea4c678a", "source": "arxiv", "section": "computerScience"}, {"title": "LeanAgent: Lifelong Learning for Formal Theorem Proving", "link": "https://arxiv.org/abs/2410.06209", "description": "arXiv:2410.06209v5 Announce Type: replace \nAbstract: Large Language Models (LLMs) have been successful in mathematical reasoning tasks such as formal theorem proving when integrated with interactive proof assistants like Lean. Existing approaches involve training or fine-tuning an LLM on a specific dataset to perform well on particular domains, such as undergraduate-level mathematics. These methods struggle with generalizability to advanced mathematics. A fundamental limitation is that these approaches operate on static domains, failing to capture how mathematicians often work across multiple domains and projects simultaneously or cyclically. We present LeanAgent, a novel lifelong learning framework for theorem proving that continuously generalizes to and improves on ever-expanding mathematical knowledge without forgetting previously learned knowledge. LeanAgent introduces several key innovations, including a curriculum learning strategy that optimizes the learning trajectory in terms of mathematical difficulty, a dynamic database for efficient management of evolving mathematical knowledge, and progressive training to balance stability and plasticity. LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics. It performs significantly better than the static LLM baseline, proving challenging theorems in domains like abstract algebra and algebraic topology while showcasing a clear progression of learning from basic concepts to advanced topics. In addition, we analyze LeanAgent's superior performance on key lifelong learning metrics. LeanAgent achieves exceptional scores in stability and backward transfer, where learning new tasks improves performance on previously learned tasks. This emphasizes LeanAgent's continuous generalizability and improvement, explaining its superior theorem-proving performance.", "published": "2024-10-31 04:00:00", "id": "a1d12d97-979d-404e-ba82-9e4ae7791d15", "source": "arxiv", "section": "computerScience"}, {"title": "ES-Gaussian: Gaussian Splatting Mapping via Error Space-Based Gaussian Completion", "link": "https://arxiv.org/abs/2410.06613", "description": "arXiv:2410.06613v2 Announce Type: replace \nAbstract: Accurate and affordable indoor 3D reconstruction is critical for effective robot navigation and interaction. Traditional LiDAR-based mapping provides high precision but is costly, heavy, and power-intensive, with limited ability for novel view rendering. Vision-based mapping, while cost-effective and capable of capturing visual data, often struggles with high-quality 3D reconstruction due to sparse point clouds. We propose ES-Gaussian, an end-to-end system using a low-altitude camera and single-line LiDAR for high-quality 3D indoor reconstruction. Our system features Visual Error Construction (VEC) to enhance sparse point clouds by identifying and correcting areas with insufficient geometric detail from 2D error maps. Additionally, we introduce a novel 3DGS initialization method guided by single-line LiDAR, overcoming the limitations of traditional multi-view setups and enabling effective reconstruction in resource-constrained environments. Extensive experimental results on our new Dreame-SR dataset and a publicly available dataset demonstrate that ES-Gaussian outperforms existing methods, particularly in challenging scenarios. The project page is available at https://chenlu-china.github.io/ES-Gaussian/.", "published": "2024-10-31 04:00:00", "id": "3410fb8c-9c45-4052-a3e3-6ae67680c83a", "source": "arxiv", "section": "computerScience"}, {"title": "Continual Learning in the Frequency Domain", "link": "https://arxiv.org/abs/2410.06645", "description": "arXiv:2410.06645v3 Announce Type: replace \nAbstract: Continual learning (CL) is designed to learn new tasks while preserving existing knowledge. Replaying samples from earlier tasks has proven to be an effective method to mitigate the forgetting of previously acquired knowledge. However, the current research on the training efficiency of rehearsal-based methods is insufficient, which limits the practical application of CL systems in resource-limited scenarios. The human visual system (HVS) exhibits varying sensitivities to different frequency components, enabling the efficient elimination of visually redundant information. Inspired by HVS, we propose a novel framework called Continual Learning in the Frequency Domain (CLFD). To our knowledge, this is the first study to utilize frequency domain features to enhance the performance and efficiency of CL training on edge devices. For the input features of the feature extractor, CLFD employs wavelet transform to map the original input image into the frequency domain, thereby effectively reducing the size of input feature maps. Regarding the output features of the feature extractor, CLFD selectively utilizes output features for distinct classes for classification, thereby balancing the reusability and interference of output features based on the frequency domain similarity of the classes across various tasks. Optimizing only the input and output features of the feature extractor allows for seamless integration of CLFD with various rehearsal-based methods. Extensive experiments conducted in both cloud and edge environments demonstrate that CLFD consistently improves the performance of state-of-the-art (SOTA) methods in both precision and training efficiency. Specifically, CLFD can increase the accuracy of the SOTA CL method by up to 6.83% and reduce the training time by 2.6$\\times$.", "published": "2024-10-31 04:00:00", "id": "04a16f75-7545-477e-820f-94c64c8d1ccb", "source": "arxiv", "section": "computerScience"}, {"title": "Benchmarking Agentic Workflow Generation", "link": "https://arxiv.org/abs/2410.07869", "description": "arXiv:2410.07869v2 Announce Type: replace \nAbstract: Large Language Models (LLMs), with their exceptional ability to handle a wide range of tasks, have driven significant advancements in tackling reasoning and planning tasks, wherein decomposing complex problems into executable workflows is a crucial step in this process. Existing workflow evaluation frameworks either focus solely on holistic performance or suffer from limitations such as restricted scenario coverage, simplistic workflow structures, and lax evaluation standards. To this end, we introduce WorFBench, a unified workflow generation benchmark with multi-faceted scenarios and intricate graph workflow structures. Additionally, we present WorFEval, a systemic evaluation protocol utilizing subsequence and subgraph matching algorithms to accurately quantify the LLM agent's workflow generation capabilities. Through comprehensive evaluations across different types of LLMs, we discover distinct gaps between the sequence planning capabilities and graph planning capabilities of LLM agents, with even GPT-4 exhibiting a gap of around 15%. We also train two open-source models and evaluate their generalization abilities on held-out tasks. Furthermore, we observe that the generated workflows can enhance downstream tasks, enabling them to achieve superior performance with less time during inference. Code and dataset are available at https://github.com/zjunlp/WorFBench.", "published": "2024-10-31 04:00:00", "id": "4f136f60-c798-4e89-a3ac-038f29de6b0e", "source": "arxiv", "section": "computerScience"}, {"title": "Lambda-Skip Connections: the architectural component that prevents Rank Collapse", "link": "https://arxiv.org/abs/2410.10609", "description": "arXiv:2410.10609v2 Announce Type: replace \nAbstract: Rank collapse, a phenomenon where embedding vectors in sequence models rapidly converge to a uniform token or equilibrium state, has recently gained attention in the deep learning literature. This phenomenon leads to reduced expressivity and potential training instabilities due to vanishing gradients. Empirical evidence suggests that architectural components like skip connections, LayerNorm, and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse. While this issue is well-documented for transformers, alternative sequence models, such as State Space Models (SSMs), which have recently gained prominence, have not been thoroughly examined for similar vulnerabilities. This paper extends the theory of rank collapse from transformers to SSMs using a unifying framework that captures both architectures. We study how a parametrized version of the classic skip connection component, which we call \\emph{lambda-skip connections}, provides guarantees for rank collapse prevention. Through analytical results, we present a sufficient condition to guarantee prevention of rank collapse across all the aforementioned architectures. We also study the necessity of this condition via ablation studies and analytical examples. To our knowledge, this is the first study that provides a general guarantee to prevent rank collapse, and that investigates rank collapse in the context of SSMs, offering valuable understanding for both theoreticians and practitioners. Finally, we validate our findings with experiments demonstrating the crucial role of architectural components such as skip connections and gating mechanisms in preventing rank collapse.", "published": "2024-10-31 04:00:00", "id": "e7925b95-00d6-4c91-be1b-2ed142fabbc5", "source": "arxiv", "section": "computerScience"}, {"title": "Dynamical loss functions shape landscape topography and improve learning in artificial neural networks", "link": "https://arxiv.org/abs/2410.10690", "description": "arXiv:2410.10690v2 Announce Type: replace \nAbstract: Dynamical loss functions are derived from standard loss functions used in supervised classification tasks, but they are modified such that the contribution from each class periodically increases and decreases. These oscillations globally alter the loss landscape without affecting the global minima. In this paper, we demonstrate how to transform cross-entropy and mean squared error into dynamical loss functions. We begin by discussing the impact of increasing the size of the neural network or the learning rate on the learning process. Building on this intuition, we propose several versions of dynamical loss functions and show how they significantly improve validation accuracy for networks of varying sizes. Finally, we explore how the landscape of these dynamical loss functions evolves during training, highlighting the emergence of instabilities that may be linked to edge-of-instability minimization.", "published": "2024-10-31 04:00:00", "id": "36a56358-bfc9-433e-9146-caf50a6e9bab", "source": "arxiv", "section": "computerScience"}, {"title": "Fair Interest Rates Are Impossible for Lending Pools: Results from Options Pricing", "link": "https://arxiv.org/abs/2410.11053", "description": "arXiv:2410.11053v2 Announce Type: replace \nAbstract: Cryptocurrency lending pools are services that allow lenders to pool together assets in one cryptocurrency and loan it out to borrowers who provide collateral worth more (than the loan) in a separate cryptocurrency. Borrowers can repay their loans to reclaim their collateral unless their loan was liquidated, which happens when the value of the collateral dips significantly. Interest rates for these pools are currently set via supply and demand heuristics, which have several downsides, including inefficiency, inflexibility, and being vulnerable to manipulation. Here, we reduce lending pools to options, and then use ideas from options pricing to search for fair interest rates for lending pools. In a simplified model where the loans have a fixed duration and can only be repaid at the end of the term, we obtain analytical pricing results. We then consider a more realistic model, where loans can be repaid dynamically and without expiry. Our main theoretical contribution is to show that fair interest rates do not exist in this setting. We then show that impossibility results generalize even to models of lending pools which have no obvious reduction to options. To address these negative results, we introduce a model of lending pools with fixed fees, and model the ability of borrowers to top-up their loans to reduce the risk of liquidation. As a proof of concept, we use simulations to show how our model's predicted interest rates compare to interest rates in practice.", "published": "2024-10-31 04:00:00", "id": "5d3c5de5-de8f-4cae-b110-f784db38680a", "source": "arxiv", "section": "computerScience"}, {"title": "DreamSteerer: Enhancing Source Image Conditioned Editability using Personalized Diffusion Models", "link": "https://arxiv.org/abs/2410.11208", "description": "arXiv:2410.11208v2 Announce Type: replace \nAbstract: Recent text-to-image personalization methods have shown great promise in teaching a diffusion model user-specified concepts given a few images for reusing the acquired concepts in a novel context. With massive efforts being dedicated to personalized generation, a promising extension is personalized editing, namely to edit an image using personalized concepts, which can provide a more precise guidance signal than traditional textual guidance. To address this, a straightforward solution is to incorporate a personalized diffusion model with a text-driven editing framework. However, such a solution often shows unsatisfactory editability on the source image. To address this, we propose DreamSteerer, a plug-in method for augmenting existing T2I personalization methods. Specifically, we enhance the source image conditioned editability of a personalized diffusion model via a novel Editability Driven Score Distillation (EDSD) objective. Moreover, we identify a mode trapping issue with EDSD, and propose a mode shifting regularization with spatial feature guided sampling to avoid such an issue. We further employ two key modifications to the Delta Denoising Score framework that enable high-fidelity local editing with personalized concepts. Extensive experiments validate that DreamSteerer can significantly improve the editability of several T2I personalization baselines while being computationally efficient.", "published": "2024-10-31 04:00:00", "id": "7bf2a3d7-0d23-4053-afc7-e3d7570d6380", "source": "arxiv", "section": "computerScience"}, {"title": "LLM2Swarm: Robot Swarms that Responsively Reason, Plan, and Collaborate through LLMs", "link": "https://arxiv.org/abs/2410.11387", "description": "arXiv:2410.11387v3 Announce Type: replace \nAbstract: Robot swarms are composed of many simple robots that communicate and collaborate to fulfill complex tasks. Robot controllers usually need to be specified by experts on a case-by-case basis via programming code. This process is time-consuming, prone to errors, and unable to take into account all situations that may be encountered during deployment. On the other hand, recent Large Language Models (LLMs) have demonstrated reasoning and planning capabilities, introduced new ways to interact with and program machines, and incorporate both domain-specific and commonsense knowledge. Hence, we propose to address the aforementioned challenges by integrating LLMs with robot swarms and show the potential in proofs of concept (showcases). For this integration, we explore two approaches. The first approach is 'indirect integration,' where LLMs are used to synthesize and validate the robot controllers. This approach may reduce development time and human error before deployment. Moreover, during deployment, it could be used for on-the-fly creation of new robot behaviors. The second approach is 'direct integration,' where each robot locally executes a separate LLM instance during deployment for robot-robot collaboration and human-swarm interaction. These local LLM instances enable each robot to reason, plan, and collaborate using natural language, as demonstrated in our showcases where the robots are able to detect a variety of anomalies, without prior information about the nature of these anomalies. To enable further research on our mainly conceptual contribution, we release the software and videos for our LLM2Swarm system: https://github.com/Pold87/LLM2Swarm.", "published": "2024-10-31 04:00:00", "id": "8ef3d4fb-32c1-47a1-ad1b-dcaad203f2b9", "source": "arxiv", "section": "computerScience"}, {"title": "Are High-Degree Representations Really Unnecessary in Equivariant Graph Neural Networks?", "link": "https://arxiv.org/abs/2410.11443", "description": "arXiv:2410.11443v3 Announce Type: replace \nAbstract: Equivariant Graph Neural Networks (GNNs) that incorporate E(3) symmetry have achieved significant success in various scientific applications. As one of the most successful models, EGNN leverages a simple scalarization technique to perform equivariant message passing over only Cartesian vectors (i.e., 1st-degree steerable vectors), enjoying greater efficiency and efficacy compared to equivariant GNNs using higher-degree steerable vectors. This success suggests that higher-degree representations might be unnecessary. In this paper, we disprove this hypothesis by exploring the expressivity of equivariant GNNs on symmetric structures, including $k$-fold rotations and regular polyhedra. We theoretically demonstrate that equivariant GNNs will always degenerate to a zero function if the degree of the output representations is fixed to 1 or other specific values. Based on this theoretical insight, we propose HEGNN, a high-degree version of EGNN to increase the expressivity by incorporating high-degree steerable vectors while maintaining EGNN's efficiency through the scalarization trick. Our extensive experiments demonstrate that HEGNN not only aligns with our theoretical analyses on toy datasets consisting of symmetric structures, but also shows substantial improvements on more complicated datasets such as $N$-body and MD17. Our theoretical findings and empirical results potentially open up new possibilities for the research of equivariant GNNs.", "published": "2024-10-31 04:00:00", "id": "6481b17d-bd9f-4626-89e8-9a40521ade78", "source": "arxiv", "section": "computerScience"}, {"title": "Degradation Oriented and Regularized Network for Real-World Depth Super-Resolution", "link": "https://arxiv.org/abs/2410.11666", "description": "arXiv:2410.11666v2 Announce Type: replace \nAbstract: Recent RGB-guided depth super-resolution methods have achieved impressive performance under the assumption of fixed and known degradation (e.g., bicubic downsampling). However, in real-world scenarios, captured depth data often suffer from unconventional and unknown degradation due to sensor limitations and complex imaging environments (e.g., low reflective surfaces, varying illumination). Consequently, the performance of these methods significantly declines when real-world degradation deviate from their assumptions. In this paper, we propose the Degradation Oriented and Regularized Network (DORNet), a novel framework designed to adaptively address unknown degradation in real-world scenes through implicit degradation representations. Our approach begins with the development of a self-supervised degradation learning strategy, which models the degradation representations of low-resolution depth data using routing selection-based degradation regularization. To facilitate effective RGB-D fusion, we further introduce a degradation-oriented feature transformation module that selectively propagates RGB content into the depth data based on the learned degradation priors. Extensive experimental results on both real and synthetic datasets demonstrate the superiority of our DORNet. The code is available at https://github.com/yanzq95/DORNet.", "published": "2024-10-31 04:00:00", "id": "2d69dfe4-293f-4f4d-9afd-e2332990d1c9", "source": "arxiv", "section": "computerScience"}, {"title": "PromptExp: Multi-granularity Prompt Explanation of Large Language Models", "link": "https://arxiv.org/abs/2410.13073", "description": "arXiv:2410.13073v3 Announce Type: replace \nAbstract: Large Language Models excel in tasks like natural language understanding and text generation. Prompt engineering plays a critical role in leveraging LLM effectively. However, LLMs black-box nature hinders its interpretability and effective prompting engineering. A wide range of model explanation approaches have been developed for deep learning models, However, these local explanations are designed for single-output tasks like classification and regression,and cannot be directly applied to LLMs, which generate sequences of tokens. Recent efforts in LLM explanation focus on natural language explanations, but they are prone to hallucinations and inaccuracies. To address this, we introduce PromptExp , a framework for multi-granularity prompt explanations by aggregating token-level insights. PromptExp introduces two token-level explanation approaches: 1. an aggregation-based approach combining local explanation techniques, and 2. a perturbation-based approach with novel techniques to evaluate token masking impact. PromptExp supports both white-box and black-box explanations and extends explanations to higher granularity levels, enabling flexible analysis. We evaluate PromptExp in case studies such as sentiment analysis, showing the perturbation-based approach performs best using semantic similarity to assess perturbation impact. Furthermore, we conducted a user study to confirm PromptExp's accuracy and practical value, and demonstrate its potential to enhance LLM interpretability.", "published": "2024-10-31 04:00:00", "id": "c10a9ffc-1ec3-4ea9-ad66-cdb1ebe77e75", "source": "arxiv", "section": "computerScience"}, {"title": "Utilizing Large Language Models in an iterative paradigm with Domain feedback for Zero-shot Molecule optimization", "link": "https://arxiv.org/abs/2410.13147", "description": "arXiv:2410.13147v4 Announce Type: replace \nAbstract: Molecule optimization is a critical task in drug discovery to optimize desired properties of a given molecule through chemical modification. Despite Large Language Models (LLMs) holding the potential to efficiently simulate this task by using natural language to direct the optimization, straightforwardly utilizing shows limited performance. In this work, we facilitate utilizing LLMs in an iterative paradigm by proposing a simple yet highly effective domain feedback provider, namely $\\text{Re}^3$DF. In detail, $\\text{Re}^3$DF harnesses an external toolkit, RDKit, to handle the molecule hallucination, if the modified molecule is chemically invalid. Otherwise, its desired properties are computed and compared to the original one, establishing reliable domain feedback with correct direction and distance towards the objective, followed by a retrieved example, to explicitly guide the LLM to refine the modified molecule. We conduct experiments across both single- and multi-property objectives with 2 thresholds, where $\\text{Re}^3$DF shows significant improvements. Particularly, for 20 single-property objectives, $\\text{Re}^3$DF enhances Hit ratio by 16.95% and 20.76% under loose and strict thresholds, respectively. For 32 multi-property objectives, $\\text{Re}^3$DF enhances Hit ratio by 6.04% and 5.25%.", "published": "2024-10-31 04:00:00", "id": "7f6d9eb0-9ba4-45eb-99cb-8402a10f655e", "source": "arxiv", "section": "computerScience"}, {"title": "Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents", "link": "https://arxiv.org/abs/2410.13185", "description": "arXiv:2410.13185v5 Announce Type: replace \nAbstract: Effective research ideation is a critical step for scientific research. However, the exponential increase in scientific literature makes it challenging for researchers to stay current with recent advances and identify meaningful research directions. Recent developments in large language models~(LLMs) suggest a promising avenue for automating the generation of novel research ideas. However, existing methods for idea generation either trivially prompt LLMs or directly expose LLMs to extensive literature without indicating useful information. Inspired by the research process of human researchers, we propose a Chain-of-Ideas~(CoI) agent, an LLM-based agent that organizes relevant literature in a chain structure to effectively mirror the progressive development in a research domain. This organization facilitates LLMs to capture the current advancements in research, thereby enhancing their ideation capabilities. Furthermore, we propose Idea Arena, an evaluation protocol that can comprehensively evaluate idea generation methods from different perspectives, aligning closely with the preferences of human researchers. Experimental results indicate that the CoI agent consistently outperforms other methods and shows comparable quality as humans in research idea generation. Moreover, our CoI agent is budget-friendly, with a minimum cost of \\$0.50 to generate a candidate idea and its corresponding experimental design.", "published": "2024-10-31 04:00:00", "id": "74d3cf8e-e62b-4f1e-b472-da89b956e02e", "source": "arxiv", "section": "computerScience"}, {"title": "aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Completion", "link": "https://arxiv.org/abs/2410.13187", "description": "arXiv:2410.13187v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have been widely used in code completion, and researchers are focusing on scaling up LLMs to improve their accuracy. However, larger LLMs will increase the response time of code completion and decrease the developers' productivity. In this paper, we propose a lightweight and effective LLM for code completion named aiXcoder-7B. Compared to existing LLMs, aiXcoder-7B achieves higher code completion accuracy while having smaller scales (i.e., 7 billion parameters). We attribute the superiority of aiXcoder-7B to three key factors: (1) Multi-objective training. We employ three training objectives, one of which is our proposed Structured Fill-In-the-Middle (SFIM). SFIM considers the syntax structures in code and effectively improves the performance of LLMs for code. (2) Diverse data sampling strategies. They consider inter-file relationships and enhance the capability of LLMs in understanding cross-file contexts. (3) Extensive high-quality data. We establish a rigorous data collection pipeline and consume a total of 1.2 trillion unique tokens for training aiXcoder-7B. This vast volume of data enables aiXcoder-7B to learn a broad distribution of code. We evaluate aiXcoder-7B in five popular code completion benchmarks and a new benchmark collected by this paper. The results show that aiXcoder-7B outperforms the latest six LLMs with similar sizes and even surpasses four larger LLMs (e.g., StarCoder2-15B and CodeLlama-34B), positioning aiXcoder-7B as a lightweight and effective LLM for academia and industry. Finally, we summarize three valuable insights for helping practitioners train the next generations of LLMs for code. aiXcoder-7B has been open-souced and gained significant attention. As of the submission date, aiXcoder-7B has received 2,193 GitHub Stars.", "published": "2024-10-31 04:00:00", "id": "72172a54-32e4-42bc-8629-c165797be81c", "source": "arxiv", "section": "computerScience"}, {"title": "Dynamic Input Mapping Inversion for Algebraic Loop-Free Control in Hydraulic Actuators", "link": "https://arxiv.org/abs/2410.13389", "description": "arXiv:2410.13389v2 Announce Type: replace \nAbstract: The application of nonlinear control schemes to electro-hydraulic actuators often requires several alterations in the design of the controllers during their implementation. This is to overcome the challenges that frequently arise from the inherent complexity of such control algorithms owning to model nonlinearities. Moreover, advanced control solutions for this type of systems often introduce input algebraic loops and chatter, which considerably degrade the tracking performance. This study presents a nonlinear control architecture for hydraulic actuators that comprises low-complexity modules, based on well-established designs that facilitate robust high performance in tracking without introducing the aforementioned limitations. Specifically, the proposed solution consists of two variants of a position controller for the hydraulic cylinder and a dynamic input-mapping inversion module to avoid algebraic loops in the control input. The stability of the closed-loop system is analysed using arguments from Lyapunov theory for cascaded non-autonomous nonlinear systems. The effectiveness of the proposed solution is evaluated on a high-fidelity simulator of a wind turbine pitch system. Appropriate quantitative metrics are finally defined to evaluate the closed-loop system performance in comparison to state-of-the-art nonlinear design.", "published": "2024-10-31 04:00:00", "id": "1350cb5e-80cf-4aa9-a4f2-7bcffe3b38e9", "source": "arxiv", "section": "computerScience"}, {"title": "Graph Neural Flows for Unveiling Systemic Interactions Among Irregularly Sampled Time Series", "link": "https://arxiv.org/abs/2410.14030", "description": "arXiv:2410.14030v2 Announce Type: replace \nAbstract: Interacting systems are prevalent in nature. It is challenging to accurately predict the dynamics of the system if its constituent components are analyzed independently. We develop a graph-based model that unveils the systemic interactions of time series observed at irregular time points, by using a directed acyclic graph to model the conditional dependencies (a form of causal notation) of the system components and learning this graph in tandem with a continuous-time model that parameterizes the solution curves of ordinary differential equations (ODEs). Our technique, a graph neural flow, leads to substantial enhancements over non-graph-based methods, as well as graph-based methods without the modeling of conditional dependencies. We validate our approach on several tasks, including time series classification and forecasting, to demonstrate its efficacy.", "published": "2024-10-31 04:00:00", "id": "b49233ac-33c8-4a3a-9940-ed073d26a5b6", "source": "arxiv", "section": "computerScience"}, {"title": "Do LLMs \"know\" internally when they follow instructions?", "link": "https://arxiv.org/abs/2410.14516", "description": "arXiv:2410.14516v4 Announce Type: replace \nAbstract: Instruction-following is crucial for building AI agents with large language models (LLMs), as these models must adhere strictly to user-provided constraints and guidelines. However, LLMs often fail to follow even simple and clear instructions. To improve instruction-following behavior and prevent undesirable outputs, a deeper understanding of how LLMs' internal states relate to these outcomes is required. Our analysis of LLM internal states reveal a dimension in the input embedding space linked to successful instruction-following. We demonstrate that modifying representations along this dimension improves instruction-following success rates compared to random changes, without compromising response quality. Further investigation reveals that this dimension is more closely related to the phrasing of prompts rather than the inherent difficulty of the task or instructions. This discovery also suggests explanations for why LLMs sometimes fail to follow clear instructions and why prompt engineering is often effective, even when the content remains largely unchanged. This work provides insight into the internal workings of LLMs' instruction-following, paving the way for reliable LLM agents.", "published": "2024-10-31 04:00:00", "id": "988c8936-bdb4-40bc-8eb2-3698ac1c50e5", "source": "arxiv", "section": "computerScience"}, {"title": "SEA: State-Exchange Attention for High-Fidelity Physics Based Transformers", "link": "https://arxiv.org/abs/2410.15495", "description": "arXiv:2410.15495v2 Announce Type: replace \nAbstract: Current approaches using sequential networks have shown promise in estimating field variables for dynamical systems, but they are often limited by high rollout errors. The unresolved issue of rollout error accumulation results in unreliable estimations as the network predicts further into the future, with each step's error compounding and leading to an increase in inaccuracy. Here, we introduce the State-Exchange Attention (SEA) module, a novel transformer-based module enabling information exchange between encoded fields through multi-head cross-attention. The cross-field multidirectional information exchange design enables all state variables in the system to exchange information with one another, capturing physical relationships and symmetries between fields. Additionally, we introduce an efficient ViT-like mesh autoencoder to generate spatially coherent mesh embeddings for a large number of meshing cells. The SEA integrated transformer demonstrates the state-of-the-art rollout error compared to other competitive baselines. Specifically, we outperform PbGMR-GMUS Transformer-RealNVP and GMR-GMUS Transformer, with a reduction in error of 88% and 91%, respectively. Furthermore, we demonstrate that the SEA module alone can reduce errors by 97% for state variables that are highly dependent on other states of the system. The repository for this work is available at: https://github.com/ParsaEsmati/SEA", "published": "2024-10-31 04:00:00", "id": "4229448b-806f-45be-ac05-c3e962ccad06", "source": "arxiv", "section": "computerScience"}, {"title": "Intrinsic Finite Element Error Analysis on Manifolds with Regge Metrics, with Applications to Calculating Connection Forms", "link": "https://arxiv.org/abs/2410.15579", "description": "arXiv:2410.15579v2 Announce Type: replace \nAbstract: We present some aspects of the theory of finite element exterior calculus as applied to partial differential equations on manifolds, especially manifolds endowed with an approximate metric called a Regge metric. Our treatment is intrinsic, avoiding wherever possible the use of preferred coordinates or a preferred embedding into an ambient space, which presents some challenges but also conceptual and possibly computational advantages. As an application, we analyze and implement a method for computing an approximate Levi-Civita connection form for a disc whose metric is itself approximate.", "published": "2024-10-31 04:00:00", "id": "58e40ba3-a74e-4ef6-94e3-00badd6fe55f", "source": "arxiv", "section": "computerScience"}, {"title": "Erasing Undesirable Concepts in Diffusion Models with Adversarial Preservation", "link": "https://arxiv.org/abs/2410.15618", "description": "arXiv:2410.15618v2 Announce Type: replace \nAbstract: Diffusion models excel at generating visually striking content from text but can inadvertently produce undesirable or harmful content when trained on unfiltered internet data. A practical solution is to selectively removing target concepts from the model, but this may impact the remaining concepts. Prior approaches have tried to balance this by introducing a loss term to preserve neutral content or a regularization term to minimize changes in the model parameters, yet resolving this trade-off remains challenging. In this work, we propose to identify and preserving concepts most affected by parameter changes, termed as \\textit{adversarial concepts}. This approach ensures stable erasure with minimal impact on the other concepts. We demonstrate the effectiveness of our method using the Stable Diffusion model, showing that it outperforms state-of-the-art erasure methods in eliminating unwanted content while maintaining the integrity of other unrelated elements. Our code is available at \\url{https://github.com/tuananhbui89/Erasing-Adversarial-Preservation}.", "published": "2024-10-31 04:00:00", "id": "1d74c6ba-b464-41ad-ae77-6c44bbb0fadb", "source": "arxiv", "section": "computerScience"}, {"title": "Opportunities and Challenges of Generative-AI in Finance", "link": "https://arxiv.org/abs/2410.15653", "description": "arXiv:2410.15653v2 Announce Type: replace \nAbstract: Gen-AI techniques are able to improve understanding of context and nuances in language modeling, translation between languages, handle large volumes of data, provide fast, low-latency responses and can be fine-tuned for various tasks and domains.\n  In this manuscript, we present a comprehensive overview of the applications of Gen-AI techniques in the finance domain. In particular, we present the opportunities and challenges associated with the usage of Gen-AI techniques. We also illustrate the various methodologies which can be used to train Gen-AI techniques and present the various application areas of Gen-AI technologies in the finance ecosystem.\n  To the best of our knowledge, this work represents the most comprehensive summarization of Gen-AI techniques within the financial domain. The analysis is designed for a deep overview of areas marked for substantial advancement while simultaneously pin-point those warranting future prioritization. We also hope that this work would serve as a conduit between finance and other domains, thus fostering the cross-pollination of innovative concepts and practices.", "published": "2024-10-31 04:00:00", "id": "27c01499-faaa-45ed-90e7-41e04360a6b1", "source": "arxiv", "section": "computerScience"}, {"title": "TreeBoN: Enhancing Inference-Time Alignment with Speculative Tree-Search and Best-of-N Sampling", "link": "https://arxiv.org/abs/2410.16033", "description": "arXiv:2410.16033v3 Announce Type: replace \nAbstract: Inference-time alignment enhances the performance of large language models without requiring additional training or fine-tuning but presents challenges due to balancing computational efficiency with high-quality output. Best-of-N (BoN) sampling, as a simple yet powerful approach, generates multiple responses and selects the best one, achieving improved performance but with a high computational cost. We propose TreeBoN, a novel framework that integrates a speculative tree-search strategy into Best-of-N (BoN) Sampling. TreeBoN maintains a set of parent nodes, iteratively branching and pruning low-quality responses, thereby reducing computational overhead while maintaining high output quality. Our approach also leverages token-level rewards from Direct Preference Optimization (DPO) to guide tree expansion and prune low-quality paths. We evaluate TreeBoN using AlpacaFarm, HH-RLHF, UltraFeedback, GSM8K, and TutorEval datasets, demonstrating consistent improvements. Specifically, TreeBoN achieves the highest win rate of 65% on TutorEval and around 60% win rates across other different datasets, outperforming standard BoN with the same computational cost and showcasing its scalability and alignment efficacy.", "published": "2024-10-31 04:00:00", "id": "21412681-b855-434b-9293-203b77192aee", "source": "arxiv", "section": "computerScience"}, {"title": "Can Knowledge Editing Really Correct Hallucinations?", "link": "https://arxiv.org/abs/2410.16251", "description": "arXiv:2410.16251v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) suffer from hallucinations, referring to the non-factual information in generated content, despite their superior capacities across tasks. Meanwhile, knowledge editing has been developed as a new popular paradigm to correct the erroneous factual knowledge encoded in LLMs with the advantage of avoiding retraining from scratch. However, one common issue of existing evaluation datasets for knowledge editing is that they do not ensure LLMs actually generate hallucinated answers to the evaluation questions before editing. When LLMs are evaluated on such datasets after being edited by different techniques, it is hard to directly adopt the performance to assess the effectiveness of different knowledge editing methods in correcting hallucinations. Thus, the fundamental question remains insufficiently validated: Can knowledge editing really correct hallucinations in LLMs? We proposed HalluEditBench to holistically benchmark knowledge editing methods in correcting real-world hallucinations. First, we rigorously construct a massive hallucination dataset with 9 domains, 26 topics and more than 6,000 hallucinations. Then, we assess the performance of knowledge editing methods in a holistic way on five dimensions including Efficacy, Generalization, Portability, Locality, and Robustness. Through HalluEditBench, we have provided new insights into the potentials and limitations of different knowledge editing methods in correcting hallucinations, which could inspire future improvements and facilitate the progress in the field of knowledge editing.", "published": "2024-10-31 04:00:00", "id": "f4396508-1398-4bf3-9f9c-70eb37bbcf57", "source": "arxiv", "section": "computerScience"}, {"title": "Hardware-Software Co-optimised Fast and Accurate Deep Reconfigurable Spiking Inference Accelerator Architecture Design Methodology", "link": "https://arxiv.org/abs/2410.16298", "description": "arXiv:2410.16298v2 Announce Type: replace \nAbstract: Spiking Neural Networks (SNNs) have emerged as a promising approach to improve the energy efficiency of machine learning models, as they naturally implement event-driven computations while avoiding expensive multiplication operations. In this paper, we develop a hardware-software co-optimisation strategy to port software-trained deep neural networks (DNN) to reduced-precision spiking models demonstrating fast and accurate inference in a novel event-driven CMOS reconfigurable spiking inference accelerator. Experimental results show that a reduced-precision Resnet-18 and VGG-11 SNN models achieves classification accuracy within 1% of the baseline full-precision DNN model within 8 spike timesteps. We also demonstrate an FPGA prototype implementation of the spiking inference accelerator with a throughput of 38.4 giga operations per second (GOPS) consuming 1.54 Watts on PYNQ-Z2 FPGA. This corresponds to 0.6 GOPS per processing element and 2.25,GOPS/DSP slice, which is 2x and 4.5x higher utilisation efficiency respectively compared to the state-of-the-art. Our co-optimisation strategy can be employed to develop deep reduced precision SNN models and port them to resource-efficient event-driven hardware accelerators for edge applications.", "published": "2024-10-31 04:00:00", "id": "747f115b-ee7b-48ac-b41d-b96c9e83f184", "source": "arxiv", "section": "computerScience"}, {"title": "Fair Bilevel Neural Network (FairBiNN): On Balancing fairness and accuracy via Stackelberg Equilibrium", "link": "https://arxiv.org/abs/2410.16432", "description": "arXiv:2410.16432v2 Announce Type: replace \nAbstract: The persistent challenge of bias in machine learning models necessitates robust solutions to ensure parity and equal treatment across diverse groups, particularly in classification tasks. Current methods for mitigating bias often result in information loss and an inadequate balance between accuracy and fairness. To address this, we propose a novel methodology grounded in bilevel optimization principles. Our deep learning-based approach concurrently optimizes for both accuracy and fairness objectives, and under certain assumptions, achieving proven Pareto optimal solutions while mitigating bias in the trained model. Theoretical analysis indicates that the upper bound on the loss incurred by this method is less than or equal to the loss of the Lagrangian approach, which involves adding a regularization term to the loss function. We demonstrate the efficacy of our model primarily on tabular datasets such as UCI Adult and Heritage Health. When benchmarked against state-of-the-art fairness methods, our model exhibits superior performance, advancing fairness-aware machine learning solutions and bridging the accuracy-fairness gap. The implementation of FairBiNN is available on https://github.com/yazdanimehdi/FairBiNN.", "published": "2024-10-31 04:00:00", "id": "7fd6db1e-a1c1-4e7c-b8ba-29d8c69cc56d", "source": "arxiv", "section": "computerScience"}, {"title": "SINGAPO: Single Image Controlled Generation of Articulated Parts in Objects", "link": "https://arxiv.org/abs/2410.16499", "description": "arXiv:2410.16499v2 Announce Type: replace \nAbstract: We address the challenge of creating 3D assets for household articulated objects from a single image. Prior work on articulated object creation either requires multi-view multi-state input, or only allows coarse control over the generation process. These limitations hinder the scalability and practicality for articulated object modeling. In this work, we propose a method to generate articulated objects from a single image. Observing the object in resting state from an arbitrary view, our method generates an articulated object that is visually consistent with the input image. To capture the ambiguity in part shape and motion posed by a single view of the object, we design a diffusion model that learns the plausible variations of objects in terms of geometry and kinematics. To tackle the complexity of generating structured data with attributes in multiple domains, we design a pipeline that produces articulated objects from high-level structure to geometric details in a coarse-to-fine manner, where we use a part connectivity graph and part abstraction as proxies. Our experiments show that our method outperforms the state-of-the-art in articulated object creation by a large margin in terms of the generated object realism, resemblance to the input image, and reconstruction quality.", "published": "2024-10-31 04:00:00", "id": "093fb328-2671-46df-b47e-8f4d127b41dc", "source": "arxiv", "section": "computerScience"}, {"title": "Improving Causal Reasoning in Large Language Models: A Survey", "link": "https://arxiv.org/abs/2410.16676", "description": "arXiv:2410.16676v2 Announce Type: replace \nAbstract: Causal reasoning (CR) is a crucial aspect of intelligence, essential for problem-solving, decision-making, and understanding the world. While large language models (LLMs) can generate rationales for their outputs, their ability to reliably perform causal reasoning remains uncertain, often falling short in tasks requiring a deep understanding of causality. In this survey, we provide a comprehensive review of research aimed at enhancing LLMs for causal reasoning. We categorize existing methods based on the role of LLMs: either as reasoning engines or as helpers providing knowledge or data to traditional CR methods, followed by a detailed discussion of the methodologies in each category. We then evaluate the performance of LLMs on various causal reasoning tasks, providing key findings and in-depth analysis. Finally, we provide insights from current studies and highlight promising directions for future research. We aim for this work to serve as a comprehensive resource, fostering further advancements in causal reasoning with LLMs. Resources are available at https://github.com/chendl02/Awesome-LLM-causal-reasoning.", "published": "2024-10-31 04:00:00", "id": "6fe4d8c0-17ed-460d-8f21-e326ecace380", "source": "arxiv", "section": "computerScience"}, {"title": "MiniPLM: Knowledge Distillation for Pre-Training Language Models", "link": "https://arxiv.org/abs/2410.17215", "description": "arXiv:2410.17215v2 Announce Type: replace \nAbstract: Knowledge distillation (KD) is widely used to train small, high-performing student language models (LMs) using large teacher LMs. While effective in fine-tuning, KD during pre-training faces challenges in efficiency, flexibility, and effectiveness. Existing methods either incur high computational costs due to online teacher inference, require tokenization matching between teacher and student LMs, or risk losing the difficulty and diversity of the teacher-generated training data. To address these issues, we propose MiniPLM, a KD framework for pre-training LMs by refining the training data distribution with the teacher's knowledge. For efficiency, MiniPLM performs offline teacher LM inference, allowing KD for multiple student LMs without adding training-time costs. For flexibility, MiniPLM operates solely on the training corpus, enabling KD across model families. For effectiveness, MiniPLM leverages the differences between large and small LMs to enhance the difficulty and diversity of the training data, helping student LMs acquire versatile and sophisticated knowledge. Extensive experiments demonstrate that MiniPLM boosts the student LMs' performance on 9 widely used downstream tasks, improves the language modeling capabilities, and reduces pre-training computation. The benefit of MiniPLM extends to large pre-training scales, evidenced by the extrapolation of the scaling curves. Further analysis reveals that MiniPLM supports KD across model families and enhances the utilization of pre-training data. Our model, code, and data are available at https://github.com/thu-coai/MiniPLM.", "published": "2024-10-31 04:00:00", "id": "7134cb4e-163b-48bb-8cb6-04e7aa9866a9", "source": "arxiv", "section": "computerScience"}, {"title": "AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents", "link": "https://arxiv.org/abs/2410.17401", "description": "arXiv:2410.17401v2 Announce Type: replace \nAbstract: Vision Language Models (VLMs) have revolutionized the creation of generalist web agents, empowering them to autonomously complete diverse tasks on real-world websites, thereby boosting human efficiency and productivity. However, despite their remarkable capabilities, the safety and security of these agents against malicious attacks remain critically underexplored, raising significant concerns about their safe deployment. To uncover and exploit such vulnerabilities in web agents, we provide AdvWeb, a novel black-box attack framework designed against web agents. AdvWeb trains an adversarial prompter model that generates and injects adversarial prompts into web pages, misleading web agents into executing targeted adversarial actions such as inappropriate stock purchases or incorrect bank transactions, actions that could lead to severe real-world consequences. With only black-box access to the web agent, we train and optimize the adversarial prompter model using DPO, leveraging both successful and failed attack strings against the target agent. Unlike prior approaches, our adversarial string injection maintains stealth and control: (1) the appearance of the website remains unchanged before and after the attack, making it nearly impossible for users to detect tampering, and (2) attackers can modify specific substrings within the generated adversarial string to seamlessly change the attack objective (e.g., purchasing stocks from a different company), enhancing attack flexibility and efficiency. We conduct extensive evaluations, demonstrating that AdvWeb achieves high success rates in attacking SOTA GPT-4V-based VLM agent across various web tasks. Our findings expose critical vulnerabilities in current LLM/VLM-based agents, emphasizing the urgent need for developing more reliable web agents and effective defenses. Our code and data are available at https://ai-secure.github.io/AdvWeb/ .", "published": "2024-10-31 04:00:00", "id": "dc09d5bf-972b-4d78-b329-f35a1e6cb91c", "source": "arxiv", "section": "computerScience"}, {"title": "A Kernel Perspective on Distillation-based Collaborative Learning", "link": "https://arxiv.org/abs/2410.17592", "description": "arXiv:2410.17592v2 Announce Type: replace \nAbstract: Over the past decade, there is a growing interest in collaborative learning that can enhance AI models of multiple parties. However, it is still challenging to enhance performance them without sharing private data and models from individual parties. One recent promising approach is to develop distillation-based algorithms that exploit unlabeled public data but the results are still unsatisfactory in both theory and practice. To tackle this problem, we rigorously analyze a representative distillation-based algorithm in the view of kernel regression. This work provides the first theoretical results to prove the (nearly) minimax optimality of the nonparametric collaborative learning algorithm that does not directly share local data or models in massively distributed statistically heterogeneous environments. Inspired by our theoretical results, we also propose a practical distillation-based collaborative learning algorithm based on neural network architecture. Our algorithm successfully bridges the gap between our theoretical assumptions and practical settings with neural networks through feature kernel matching. We simulate various regression tasks to verify our theory and demonstrate the practical feasibility of our proposed algorithm.", "published": "2024-10-31 04:00:00", "id": "b8a6f9da-bcd0-4d06-90b4-9aa4e4600b89", "source": "arxiv", "section": "computerScience"}, {"title": "VISAGE: Video Synthesis using Action Graphs for Surgery", "link": "https://arxiv.org/abs/2410.17751", "description": "arXiv:2410.17751v2 Announce Type: replace \nAbstract: Surgical data science (SDS) is a field that analyzes patient data before, during, and after surgery to improve surgical outcomes and skills. However, surgical data is scarce, heterogeneous, and complex, which limits the applicability of existing machine learning methods. In this work, we introduce the novel task of future video generation in laparoscopic surgery. This task can augment and enrich the existing surgical data and enable various applications, such as simulation, analysis, and robot-aided surgery. Ultimately, it involves not only understanding the current state of the operation but also accurately predicting the dynamic and often unpredictable nature of surgical procedures. Our proposed method, VISAGE (VIdeo Synthesis using Action Graphs for Surgery), leverages the power of action scene graphs to capture the sequential nature of laparoscopic procedures and utilizes diffusion models to synthesize temporally coherent video sequences. VISAGE predicts the future frames given only a single initial frame, and the action graph triplets. By incorporating domain-specific knowledge through the action graph, VISAGE ensures the generated videos adhere to the expected visual and motion patterns observed in real laparoscopic procedures. The results of our experiments demonstrate high-fidelity video generation for laparoscopy procedures, which enables various applications in SDS.", "published": "2024-10-31 04:00:00", "id": "806e9dff-be71-4249-a64e-487b9bd07dc6", "source": "arxiv", "section": "computerScience"}, {"title": "Scalable Ranked Preference Optimization for Text-to-Image Generation", "link": "https://arxiv.org/abs/2410.18013", "description": "arXiv:2410.18013v2 Announce Type: replace \nAbstract: Direct Preference Optimization (DPO) has emerged as a powerful approach to align text-to-image (T2I) models with human feedback. Unfortunately, successful application of DPO to T2I models requires a huge amount of resources to collect and label large-scale datasets, e.g., millions of generated paired images annotated with human preferences. In addition, these human preference datasets can get outdated quickly as the rapid improvements of T2I models lead to higher quality images. In this work, we investigate a scalable approach for collecting large-scale and fully synthetic datasets for DPO training. Specifically, the preferences for paired images are generated using a pre-trained reward function, eliminating the need for involving humans in the annotation process, greatly improving the dataset collection efficiency. Moreover, we demonstrate that such datasets allow averaging predictions across multiple models and collecting ranked preferences as opposed to pairwise preferences. Furthermore, we introduce RankDPO to enhance DPO-based methods using the ranking feedback. Applying RankDPO on SDXL and SD3-Medium models with our synthetically generated preference dataset \"Syn-Pic\" improves both prompt-following (on benchmarks like T2I-Compbench, GenEval, and DPG-Bench) and visual quality (through user studies). This pipeline presents a practical and scalable solution to develop better preference datasets to enhance the performance of text-to-image models.", "published": "2024-10-31 04:00:00", "id": "4592b8e9-8d4f-4bc5-909e-708be5025a9a", "source": "arxiv", "section": "computerScience"}, {"title": "A Systematic Survey on Instructional Text: From Representation Formats to Downstream NLP Tasks", "link": "https://arxiv.org/abs/2410.18529", "description": "arXiv:2410.18529v2 Announce Type: replace \nAbstract: Recent advances in large language models have demonstrated promising capabilities in following simple instructions through instruction tuning. However, real-world tasks often involve complex, multi-step instructions that remain challenging for current NLP systems. Despite growing interest in this area, there lacks a comprehensive survey that systematically analyzes the landscape of complex instruction understanding and processing. Through a systematic review of the literature, we analyze available resources, representation schemes, and downstream tasks related to instructional text. Our study examines 177 papers, identifying trends, challenges, and opportunities in this emerging field. We provide AI/NLP researchers with essential background knowledge and a unified view of various approaches to complex instruction understanding, bridging gaps between different research directions and highlighting future research opportunities.", "published": "2024-10-31 04:00:00", "id": "6958f14b-c299-40d1-81f2-df2cc12e8c2e", "source": "arxiv", "section": "computerScience"}, {"title": "Denoising diffusion probabilistic models are optimally adaptive to unknown low dimensionality", "link": "https://arxiv.org/abs/2410.18784", "description": "arXiv:2410.18784v2 Announce Type: replace \nAbstract: The denoising diffusion probabilistic model (DDPM) has emerged as a mainstream generative model in generative AI. While sharp convergence guarantees have been established for the DDPM, the iteration complexity is, in general, proportional to the ambient data dimension, resulting in overly conservative theory that fails to explain its practical efficiency. This has motivated the recent work Li and Yan (2024a) to investigate how the DDPM can achieve sampling speed-ups through automatic exploitation of intrinsic low dimensionality of data. We strengthen this line of work by demonstrating, in some sense, optimal adaptivity to unknown low dimensionality. For a broad class of data distributions with intrinsic dimension $k$, we prove that the iteration complexity of the DDPM scales nearly linearly with $k$, which is optimal when using KL divergence to measure distributional discrepancy. Notably, our work is closely aligned with the independent concurrent work Potaptchik et al. (2024) -- posted two weeks prior to ours -- in establishing nearly linear-$k$ convergence guarantees for the DDPM.", "published": "2024-10-31 04:00:00", "id": "c5880e16-5767-4653-bad6-9f66fe764820", "source": "arxiv", "section": "computerScience"}, {"title": "Dynamic Vocabulary Pruning in Early-Exit LLMs", "link": "https://arxiv.org/abs/2410.18952", "description": "arXiv:2410.18952v2 Announce Type: replace \nAbstract: Increasing the size of large language models (LLMs) has been shown to lead to better performance. However, this comes at the cost of slower and more expensive inference. Early-exiting is a promising approach for improving the efficiency of LLM inference by enabling next token prediction at intermediate layers. Yet, the large vocabulary size in modern LLMs makes the confidence estimation required for exit decisions computationally expensive, diminishing the efficiency gains. To address this, we propose dynamically pruning the vocabulary at test time for each token. Specifically, the vocabulary is pruned at one of the initial layers, and the smaller vocabulary is then used throughout the rest of the forward pass. Our experiments demonstrate that such post-hoc dynamic vocabulary pruning improves the efficiency of confidence estimation in early-exit LLMs while maintaining competitive performance.", "published": "2024-10-31 04:00:00", "id": "17fcd94c-97bd-4bf6-b389-c82fe1226d53", "source": "arxiv", "section": "computerScience"}, {"title": "Unbounded: A Generative Infinite Game of Character Life Simulation", "link": "https://arxiv.org/abs/2410.18975", "description": "arXiv:2410.18975v2 Announce Type: replace \nAbstract: We introduce the concept of a generative infinite game, a video game that transcends the traditional boundaries of finite, hard-coded systems by using generative models. Inspired by James P. Carse's distinction between finite and infinite games, we leverage recent advances in generative AI to create Unbounded: a game of character life simulation that is fully encapsulated in generative models. Specifically, Unbounded draws inspiration from sandbox life simulations and allows you to interact with your autonomous virtual character in a virtual world by feeding, playing with and guiding it - with open-ended mechanics generated by an LLM, some of which can be emergent. In order to develop Unbounded, we propose technical innovations in both the LLM and visual generation domains. Specifically, we present: (1) a specialized, distilled large language model (LLM) that dynamically generates game mechanics, narratives, and character interactions in real-time, and (2) a new dynamic regional image prompt Adapter (IP-Adapter) for vision models that ensures consistent yet flexible visual generation of a character across multiple environments. We evaluate our system through both qualitative and quantitative analysis, showing significant improvements in character life simulation, user instruction following, narrative coherence, and visual consistency for both characters and the environments compared to traditional related approaches.", "published": "2024-10-31 04:00:00", "id": "01c70d3a-320a-4832-977f-e826fd4c712c", "source": "arxiv", "section": "computerScience"}, {"title": "On a Geometric Interpretation Of the Subset Sum Problem", "link": "https://arxiv.org/abs/2410.19024", "description": "arXiv:2410.19024v2 Announce Type: replace \nAbstract: For $S \\in \\mathbb{N}^n$ and $T \\in \\mathbb{N}$, the Subset Sum Problem (SSP) $\\exists^? x \\in \\{0,1\\}^n $ such that $S^T\\cdot x = T$ can be interpreted as the problem of deciding whether the intersection of the positive unit hypercube $Q_n = [0,1]^n$ with the hyperplane $S^T\\cdot \\left(x - \\frac{S}{\\|S\\|^2 }\\cdot T \\right) = 0$ contains at least a vertex. In this paper, we give an algorithm of complexity $\\mathcal{O}\\left( \\frac{1}{\\epsilon}\\cdot n^b \\right)$, for some absolute constant $b$, which either proves that there are no vertices in a slab of thickness $\\epsilon$ either finds a vertex in the slab of thickness $4\\cdot \\epsilon$. It is shown that any vertex $P$ in a slab of thickness $\\epsilon$ meets $\\left| \\frac{S^T\\cdot P}{T} - 1 \\right| \\leq \\epsilon$, therefore making the proposed algorithm a FPTAS for the SSP. The results are then applied to the study of the so called Simultaneous Subset-Sum Problem (SSSP).", "published": "2024-10-31 04:00:00", "id": "cda5e797-9101-4d6b-92b5-f5fa774b9ac3", "source": "arxiv", "section": "computerScience"}, {"title": "Mirror Matrix on the Wall: coding and vector notation as tools for introspection", "link": "https://arxiv.org/abs/2410.19549", "description": "arXiv:2410.19549v2 Announce Type: replace \nAbstract: The vector notation adopted by GNU Octave plays a significant role as a tool for introspection, aligning itself with the vision of Kenneth E. Iverson. He believed that, just like mathematics, a programming language should be an effective thinking tool for representing and reasoning about problems we wish to address. This work aims to explore the use of vector notation in GNU Octave through the analysis of operators and functions, providing a closer alignment with mathematical notation and enhancing code efficiency. We will delve into fundamental concepts such as indexing, broadcasting, and function handles, and present case studies for a deeper understanding of these concepts. By adopting vector notation, GNU Octave becomes a powerful tool for mathematicians, scientists and engineers, enabling them to express and solve complex problems more effectively and intuitively.", "published": "2024-10-31 04:00:00", "id": "1522bc87-d29b-4db5-9ff0-6a390d0c3f32", "source": "arxiv", "section": "computerScience"}, {"title": "ChunkRAG: Novel LLM-Chunk Filtering Method for RAG Systems", "link": "https://arxiv.org/abs/2410.19572", "description": "arXiv:2410.19572v3 Announce Type: replace \nAbstract: Retrieval-Augmented Generation (RAG) systems using large language models (LLMs) often generate inaccurate responses due to the retrieval of irrelevant or loosely related information. Existing methods, which operate at the document level, fail to effectively filter out such content. We propose LLM-driven chunk filtering, ChunkRAG, a framework that enhances RAG systems by evaluating and filtering retrieved information at the chunk level. Our approach employs semantic chunking to divide documents into coherent sections and utilizes LLM-based relevance scoring to assess each chunk's alignment with the user's query. By filtering out less pertinent chunks before the generation phase, we significantly reduce hallucinations and improve factual accuracy. Experiments show that our method outperforms existing RAG models, achieving higher accuracy on tasks requiring precise information retrieval. This advancement enhances the reliability of RAG systems, making them particularly beneficial for applications like fact-checking and multi-hop reasoning.", "published": "2024-10-31 04:00:00", "id": "6b76423f-9579-412b-b3d9-642eacba480a", "source": "arxiv", "section": "computerScience"}, {"title": "DiffGS: Functional Gaussian Splatting Diffusion", "link": "https://arxiv.org/abs/2410.19657", "description": "arXiv:2410.19657v2 Announce Type: replace \nAbstract: 3D Gaussian Splatting (3DGS) has shown convincing performance in rendering speed and fidelity, yet the generation of Gaussian Splatting remains a challenge due to its discreteness and unstructured nature. In this work, we propose DiffGS, a general Gaussian generator based on latent diffusion models. DiffGS is a powerful and efficient 3D generative model which is capable of generating Gaussian primitives at arbitrary numbers for high-fidelity rendering with rasterization. The key insight is to represent Gaussian Splatting in a disentangled manner via three novel functions to model Gaussian probabilities, colors and transforms. Through the novel disentanglement of 3DGS, we represent the discrete and unstructured 3DGS with continuous Gaussian Splatting functions, where we then train a latent diffusion model with the target of generating these Gaussian Splatting functions both unconditionally and conditionally. Meanwhile, we introduce a discretization algorithm to extract Gaussians at arbitrary numbers from the generated functions via octree-guided sampling and optimization. We explore DiffGS for various tasks, including unconditional generation, conditional generation from text, image, and partial 3DGS, as well as Point-to-Gaussian generation. We believe that DiffGS provides a new direction for flexibly modeling and generating Gaussian Splatting.", "published": "2024-10-31 04:00:00", "id": "90085625-1151-42b8-a1c1-cdb774b4a418", "source": "arxiv", "section": "computerScience"}, {"title": "Super Gradient Descent: Global Optimization requires Global Gradient", "link": "https://arxiv.org/abs/2410.19706", "description": "arXiv:2410.19706v2 Announce Type: replace \nAbstract: Global minimization is a fundamental challenge in optimization, especially in machine learning, where finding the global minimum of a function directly impacts model performance and convergence. This article introduces a novel optimization method that we called Super Gradient Descent, designed specifically for one-dimensional functions, guaranteeing convergence to the global minimum for any k-Lipschitz function defined on a closed interval [a, b]. Our approach addresses the limitations of traditional optimization algorithms, which often get trapped in local minima. In particular, we introduce the concept of global gradient which offers a robust solution for precise and well-guided global optimization. By focusing on the global minimization problem, this work bridges a critical gap in optimization theory, offering new insights and practical advancements in different optimization problems in particular Machine Learning problems like line search.", "published": "2024-10-31 04:00:00", "id": "fb983b02-fb38-4e2a-b493-45e625277977", "source": "arxiv", "section": "computerScience"}, {"title": "Learning to Adopt Generative AI", "link": "https://arxiv.org/abs/2410.19806", "description": "arXiv:2410.19806v2 Announce Type: replace \nAbstract: Recent advancements in generative AI, exemplified by ChatGPT, have dramatically transformed how people access information. Despite its powerful capabilities, the benefits it provides may not be equally distributed among individuals - a phenomenon referred to as the digital divide. Building upon prior literature, we propose two forms of digital divide in the generative AI adoption process: (i) the learning divide, capturing individuals' heterogeneous abilities to update their perceived utility of ChatGPT; and (ii) the utility divide, representing differences in individuals' actual utility derived from per use of ChatGPT. To evaluate these two divides, we develop a Bayesian learning model that incorporates demographic heterogeneities in both the utility and signal functions. Leveraging a six-month clickstream dataset, we estimate the model and find significant learning and utility divides across various demographic attributes. Interestingly, lower-educated and non-white individuals derive higher utility gains from ChatGPT but learn about its utility at a slower rate. Furthermore, males, younger individuals, and those with an IT background not only derive higher utility per use from ChatGPT but also learn about its utility more rapidly. Besides, we document a phenomenon termed the belief trap, wherein users underestimate ChatGPT's utility, opt not to use the tool, and consequently lack new experiences to update their perceptions, leading to continued underutilization. Our simulation further demonstrates that the learning divide can significantly affect the probability of falling into the belief trap, another form of the digital divide in adoption outcomes (i.e., outcome divide); however, offering training programs can alleviate the belief trap and mitigate the divide.", "published": "2024-10-31 04:00:00", "id": "ce0597c9-731f-4990-a031-d7154c80fe28", "source": "arxiv", "section": "computerScience"}, {"title": "Residual Random Neural Networks", "link": "https://arxiv.org/abs/2410.19987", "description": "arXiv:2410.19987v2 Announce Type: replace \nAbstract: The single-layer feedforward neural network with random weights is a recurring motif in the neural networks literature. The advantage of these networks is their simplified training, which reduces to solving a ridge-regression problem. However, a general assumption is that these networks require a large number of hidden neurons relative to the dimensionality of the data samples, in order to achieve good classification accuracy. Contrary to this assumption, here we show that one can obtain good classification results even if the number of hidden neurons has the same order of magnitude as the dimensionality of the data samples, if this dimensionality is reasonably high. We also develop an efficient iterative residual training method for such random neural networks, which significantly improves their classification accuracy. Moreover, we also describe an encryption (obfuscation) method which can be used to protect both the data and the neural network model.", "published": "2024-10-31 04:00:00", "id": "c851a79d-8e99-41b2-a208-1bc770de2299", "source": "arxiv", "section": "computerScience"}, {"title": "Generative linguistics contribution to artificial intelligence: Where this contribution lies?", "link": "https://arxiv.org/abs/2410.20221", "description": "arXiv:2410.20221v2 Announce Type: replace \nAbstract: This article aims to characterize Generative linguistics (GL) contribution to artificial intelligence (AI), alluding to the debate among linguists and AI scientists on whether linguistics belongs to humanities or science. In this article, I will try not to be biased as a linguist, studying the phenomenon from an independent scientific perspective. The article walks the researcher/reader through the scientific theorems and rationales involved in AI which belong from GL, specifically the Chomsky School. It, thus, provides good evidence from syntax, semantics, language faculty, Universal Grammar, computational system of human language, language acquisition, human brain, programming languages (e.g. Python), Large Language Models, and unbiased AI scientists that this contribution is huge, and that this contribution cannot be denied. It concludes that however the huge GL contribution to AI, there are still points of divergence including the nature and type of language input.", "published": "2024-10-31 04:00:00", "id": "be357c24-dc05-4328-b1b9-86a47fe64605", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing CNN Classification with Lamarckian Memetic Algorithms and Local Search", "link": "https://arxiv.org/abs/2410.20234", "description": "arXiv:2410.20234v2 Announce Type: replace \nAbstract: Optimization is critical for optimal performance in deep neural networks (DNNs). Traditional gradient-based methods often face challenges like local minima entrapment. This paper explores population-based metaheuristic optimization algorithms for image classification networks. We propose a novel approach integrating a two-stage training technique with population-based optimization algorithms incorporating local search capabilities. Our experiments demonstrate that the proposed method outperforms state-of-the-art gradient-based techniques, such as ADAM, in accuracy and computational efficiency, particularly with high computational complexity and numerous trainable parameters. The results suggest that our approach offers a robust alternative to traditional methods for weight optimization in convolutional neural networks (CNNs). Future work will explore integrating adaptive mechanisms for parameter tuning and applying the proposed method to other types of neural networks and real-time applications.", "published": "2024-10-31 04:00:00", "id": "1aba1ab0-09ac-465d-9b95-68c7f2d4d2a0", "source": "arxiv", "section": "computerScience"}, {"title": "SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement", "link": "https://arxiv.org/abs/2410.20285", "description": "arXiv:2410.20285v2 Announce Type: replace \nAbstract: Software engineers operating in complex and dynamic environments must continuously adapt to evolving requirements, learn iteratively from experience, and reconsider their approaches based on new insights. However, current large language model (LLM)-based software agents often rely on rigid processes and tend to repeat ineffective actions without the capacity to evaluate their performance or adapt their strategies over time. To address these challenges, we propose SWE-Search, a multi-agent framework that integrates Monte Carlo Tree Search (MCTS) with a self-improvement mechanism to enhance software agents' performance on repository-level software tasks. SWE-Search extends traditional MCTS by incorporating a hybrid value function that leverages LLMs for both numerical value estimation and qualitative evaluation. This enables self-feedback loops where agents iteratively refine their strategies based on both quantitative numerical evaluations and qualitative natural language assessments of pursued trajectories. The framework includes a SWE-Agent for adaptive exploration, a Value Agent for iterative feedback, and a Discriminator Agent that facilitates multi-agent debate for collaborative decision-making. Applied to the SWE-bench benchmark, our approach demonstrates a 23% relative improvement in performance across five models compared to standard open-source agents without MCTS. Our analysis reveals how performance scales with increased search depth and identifies key factors that facilitate effective self-evaluation in software agents. This work highlights the potential of self-evaluation driven search techniques to enhance agent reasoning and planning in complex, dynamic software engineering environments.", "published": "2024-10-31 04:00:00", "id": "83a56a7a-eb7b-4404-99fe-9668ff898c9b", "source": "arxiv", "section": "computerScience"}, {"title": "YourSkatingCoach: A Figure Skating Video Benchmark for Fine-Grained Element Analysis", "link": "https://arxiv.org/abs/2410.20427", "description": "arXiv:2410.20427v2 Announce Type: replace \nAbstract: Combining sports and machine learning involves leveraging ML algorithms and techniques to extract insight from sports-related data such as player statistics, game footage, and other relevant information. However, datasets related to figure skating in the literature focus primarily on element classification and are currently unavailable or exhibit only limited access, which greatly raise the entry barrier to developing visual sports technology for it. Moreover, when using such data to help athletes improve their skills, we find they are very coarse-grained: they work for learning what an element is, but they are poorly suited to learning whether the element is good or bad. Here we propose air time detection, a novel motion analysis task, the goal of which is to accurately detect the duration of the air time of a jump. We present YourSkatingCoach, a large, novel figure skating dataset which contains 454 videos of jump elements, the detected skater skeletons in each video, along with the gold labels of the start and ending frames of each jump, together as a video benchmark for figure skating. In addition, although this type of task is often viewed as classification, we cast it as a sequential labeling problem and propose a Transformer-based model to calculate the duration. Experimental results show that the proposed model yields a favorable results for a strong baseline. To further verify the generalizability of the fine-grained labels, we apply the same process to other sports as cross-sports tasks but for coarse-grained task action classification. Here we fine-tune the classification to demonstrate that figure skating, as it contains the essential body movements, constitutes a strong foundation for adaptation to other sports.", "published": "2024-10-31 04:00:00", "id": "43dd833c-78e6-443e-b577-baca112bb897", "source": "arxiv", "section": "computerScience"}, {"title": "Guiding Through Complexity: What Makes Good Supervision for Hard Reasoning Tasks?", "link": "https://arxiv.org/abs/2410.20533", "description": "arXiv:2410.20533v2 Announce Type: replace \nAbstract: How can \"weak teacher models\" such as average human annotators or existing AI systems, effectively supervise LLMs to improve performance on hard reasoning tasks, especially those that challenge and requires expertise or daily practice from the teacher models? In this paper, we seek for empirical answers to this question by investigating various data-driven strategies that offer supervision data at different quality levels upon tasks of varying complexity. Two intuitive strategies emerge for teacher models to provide supervision during alignment training: 1) using lower-quality supervision from complete tasks that match the difficulty of the target reasoning tasks, and 2) leveraging higher-quality supervision from easier subtasks that are less challenging. Interestingly, we find that even when the outcome error rate for hard task supervision is high (e.g., 90\\%), training on such data can outperform perfectly correct supervision on easier subtasks on multiple hard math benchmarks. We further identify a more critical factor influencing training performance: step-wise error rates, which indicate the severity of errors in solutions. Specifically, training on hard task supervision with the same outcome error rates but disparate step-wise error rates can lead to a 30\\% accuracy gap on MATH benchmark. Our results also reveal that supplementing hard task supervision with the corresponding subtask supervision can yield notable performance improvements than simply combining rephrased hard full task supervision, suggesting new avenues for data augmentation. Data and code are released at \\url{https://github.com/hexuan21/Weak-to-Strong}.", "published": "2024-10-31 04:00:00", "id": "3f6954e0-4cf3-4800-974c-5c1173eb5d41", "source": "arxiv", "section": "computerScience"}, {"title": "Gender Bias in LLM-generated Interview Responses", "link": "https://arxiv.org/abs/2410.20739", "description": "arXiv:2410.20739v2 Announce Type: replace \nAbstract: LLMs have emerged as a promising tool for assisting individuals in diverse text-generation tasks, including job-related texts. However, LLM-generated answers have been increasingly found to exhibit gender bias. This study evaluates three LLMs (GPT-3.5, GPT-4, Claude) to conduct a multifaceted audit of LLM-generated interview responses across models, question types, and jobs, and their alignment with two gender stereotypes. Our findings reveal that gender bias is consistent, and closely aligned with gender stereotypes and the dominance of jobs. Overall, this study contributes to the systematic examination of gender bias in LLM-generated interview responses, highlighting the need for a mindful approach to mitigate such biases in related applications.", "published": "2024-10-31 04:00:00", "id": "5397aa38-afda-49e5-8cbe-9eb94d943f31", "source": "arxiv", "section": "computerScience"}, {"title": "History-Matching of Imbibition Flow in Multiscale Fractured Porous Media Using Physics-Informed Neural Networks (PINNs)", "link": "https://arxiv.org/abs/2410.20801", "description": "arXiv:2410.20801v2 Announce Type: replace \nAbstract: We propose a workflow based on physics-informed neural networks (PINNs) to model multiphase fluid flow in fractured porous media. After validating the workflow in forward and inverse modeling of a synthetic problem of flow in fractured porous media, we applied it to a real experimental dataset in which brine is injected at a constant pressure drop into a CO2 saturated naturally fractured shale core plug. The exact spatial positions of natural fractures and the dynamic in-situ distribution of fluids were imaged using a CT-scan setup. To model the targeted system, we followed a domain decomposition approach for matrix and fractures and a multi-network architecture for the separate calculation of water saturation and pressure. The flow equations in the matrix, fractures and interplay between them were solved during training. Prior to fully-coupled simulations, we proposed pre-training the model. This aided in a more efficient and successful training of the coupled system. Both for the synthetic and experimental inverse problems, we determined flow parameters within the matrix and the fractures. Multiple random initializations of network and system parameters were performed to assess the uncertainty and uniqueness of the results. The results confirmed the precision of the inverse calculated parameters in retrieving the main flow characteristics of the system. The consideration of multiscale matrix-fracture impacts is commonly overlooked in existing workflows. Accounting for them led to several orders of magnitude variations in the calculated flow properties compared to not accounting for them. To the best of our knowledge, the proposed PINNs-based workflow is the first to offer a reliable and computationally efficient solution for inverse modeling of multiphase flow in fractured porous media, achieved through history-matching noisy and multi-fidelity experimental measurements.", "published": "2024-10-31 04:00:00", "id": "45e933c7-d465-4803-846c-94ee294876c1", "source": "arxiv", "section": "computerScience"}, {"title": "Transformer-Based Tooth Alignment Prediction With Occlusion And Collision Constraints", "link": "https://arxiv.org/abs/2410.20806", "description": "arXiv:2410.20806v2 Announce Type: replace \nAbstract: The planning of digital orthodontic treatment requires providing tooth alignment, which not only consumes a lot of time and labor to determine manually but also relays clinical experiences heavily. In this work, we proposed a lightweight tooth alignment neural network based on Swin-transformer. We first re-organized 3D point clouds based on virtual arch lines and converted them into order-sorted multi-channel textures, which improves the accuracy and efficiency simultaneously. We then designed two new occlusal loss functions that quantitatively evaluate the occlusal relationship between the upper and lower jaws. They are important clinical constraints, first introduced to the best of our knowledge, and lead to cutting-edge prediction accuracy. To train our network, we collected a large digital orthodontic dataset that has 591 clinical cases, including various complex clinical cases. This dataset will benefit the community after its release since there is no open dataset so far. Furthermore, we also proposed two new orthodontic dataset augmentation methods considering tooth spatial distribution and occlusion. We evaluated our method with this dataset and extensive experiments, including comparisons with STAT methods and ablation studies, and demonstrate the high prediction accuracy of our method.", "published": "2024-10-31 04:00:00", "id": "699cd3d7-ade8-4972-9e76-b36b561ede5d", "source": "arxiv", "section": "computerScience"}, {"title": "BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference", "link": "https://arxiv.org/abs/2410.21262", "description": "arXiv:2410.21262v2 Announce Type: replace \nAbstract: Large-scale foundation models have demonstrated exceptional performance in language and vision tasks. However, the numerous dense matrix-vector operations involved in these large networks pose significant computational challenges during inference. To address these challenges, we introduce the Block-Level Adaptive STructured (BLAST) matrix, designed to learn and leverage efficient structures prevalent in the weight matrices of linear layers within deep learning models. Compared to existing structured matrices, the BLAST matrix offers substantial flexibility, as it can represent various types of structures that are either learned from data or computed from pre-existing weight matrices. We demonstrate the efficiency of using the BLAST matrix for compressing both language and vision tasks, showing that (i) for medium-sized models such as ViT and GPT-2, training with BLAST weights boosts performance while reducing complexity by 70% and 40%, respectively; and (ii) for large foundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x compression while exhibiting the lowest performance degradation among all tested structured matrices. Our code is available at https://github.com/changwoolee/BLAST.", "published": "2024-10-31 04:00:00", "id": "f9d50761-e372-4277-8d7d-399029dee74c", "source": "arxiv", "section": "computerScience"}, {"title": "Bayesian Collaborative Bandits with Thompson Sampling for Improved Outreach in Maternal Health Program", "link": "https://arxiv.org/abs/2410.21405", "description": "arXiv:2410.21405v2 Announce Type: replace \nAbstract: Mobile health (mHealth) programs face a critical challenge in optimizing the timing of automated health information calls to beneficiaries. This challenge has been formulated as a collaborative multi-armed bandit problem, requiring online learning of a low-rank reward matrix. Existing solutions often rely on heuristic combinations of offline matrix completion and exploration strategies. In this work, we propose a principled Bayesian approach using Thompson Sampling for this collaborative bandit problem. Our method leverages prior information through efficient Gibbs sampling for posterior inference over the low-rank matrix factors, enabling faster convergence. We demonstrate significant improvements over state-of-the-art baselines on a real-world dataset from the world's largest maternal mHealth program. Our approach achieves a $16\\%$ reduction in the number of calls compared to existing methods and a $47$\\% reduction compared to the deployed random policy. This efficiency gain translates to a potential increase in program capacity by $0.5-1.4$ million beneficiaries, granting them access to vital ante-natal and post-natal care information. Furthermore, we observe a $7\\%$ and $29\\%$ improvement in beneficiary retention (an extremely hard metric to impact) compared to state-of-the-art and deployed baselines, respectively. Synthetic simulations further demonstrate the superiority of our approach, particularly in low-data regimes and in effectively utilizing prior information. We also provide a theoretical analysis of our algorithm in a special setting using Eluder dimension.", "published": "2024-10-31 04:00:00", "id": "cbe147b8-9b78-4ef6-9836-edbcfe4f792a", "source": "arxiv", "section": "computerScience"}, {"title": "Carbon-Aware Computing for Data Centers with Probabilistic Performance Guarantees", "link": "https://arxiv.org/abs/2410.21510", "description": "arXiv:2410.21510v2 Announce Type: replace \nAbstract: Data centers are significant contributors to carbon emissions and can strain power systems due to their high electricity consumption. To mitigate this impact and to participate in demand response programs, cloud computing companies strive to balance and optimize operations across their global fleets by making strategic decisions about when and where to place compute jobs for execution. In this paper, we introduce a load shaping scheme which reacts to time-varying grid signals by leveraging both temporal and spatial flexibility of compute jobs to provide risk-aware management guidelines and job placement with provable performance guarantees based on distributionally robust optimization. Our approach divides the problem into two key components: (i) day-ahead planning, which generates an optimal scheduling strategy based on historical load data, and (ii) real-time job placement and (time) scheduling, which dynamically tracks the optimal strategy generated in (i). We validate our method in simulation using normalized load profiles from randomly selected Google clusters, incorporating time-varying grid signals. We can demonstrate significant reductions in carbon cost and peak power with our approach compared to myopic greedy policies, while maintaining computational efficiency and abiding to system constraints.", "published": "2024-10-31 04:00:00", "id": "668b44a7-62cf-48bb-b599-075f0e75a84e", "source": "arxiv", "section": "computerScience"}, {"title": "Intelligent Environmental Empathy (IEE): A new power and platform to fostering green obligation for climate peace and justice", "link": "https://arxiv.org/abs/2410.21536", "description": "arXiv:2410.21536v2 Announce Type: replace \nAbstract: In this paper, we propose Intelligent Environmental Empathy (IEE) as a new driver for climate peace and justice, as an emerging issue in the age of big data. We first show that the authoritarian top-down intergovernmental cooperation, through international organizations (e.g., UNEP) for climate justice, could not overcome environmental issues and crevices so far. We elaborate on four grounds of climate injustice (i.e., teleological origin, axiological origin, formation cause, and social epistemic cause), and explain how the lack of empathy and environmental motivation on a global scale causes the failure of all the authoritarian top-down intergovernmental cooperation. Addressing all these issues requires a new button-up approach to climate peace and justice. Secondly, focusing on the intersection of AI, environmental empathy, and climate justice, we propose a model of Intelligent Environmental Empathy (IEE) for climate peace and justice at the operational level. IEE is empowered by the new power of environmental empathy (as a driver of green obligation for climate justice) and putative decentralized platform of AI (as an operative system against free riders), which Initially, impact citizens and some middle-class decision makers, such as city planners and local administrators, but will eventually affect global decision-makers as well.", "published": "2024-10-31 04:00:00", "id": "6348e135-83cc-4c77-81b9-3b4e4f6dbb5a", "source": "arxiv", "section": "computerScience"}, {"title": "Information diffusion assumptions can distort our understanding of social network dynamics", "link": "https://arxiv.org/abs/2410.21554", "description": "arXiv:2410.21554v2 Announce Type: replace \nAbstract: To analyze the flow of information online, experts often rely on platform-provided data from social media companies, which typically attribute all resharing actions to an original poster. This obscures the true dynamics of how information spreads online, as users can be exposed to content in various ways. While most researchers analyze data as it is provided by the platform and overlook this issue, some attempt to infer the structure of these information cascades. However, the absence of ground truth about actual diffusion cascades makes verifying the efficacy of these efforts impossible. This study investigates the implications of the common practice of ignoring reconstruction all together. Two case studies involving data from Twitter and Bluesky reveal that reconstructing cascades significantly alters the identification of influential users, therefore affecting downstream analyses in general. We also propose a novel reconstruction approach that allows us to evaluate the effects of different assumptions made during the cascade inference procedure. Analysis of the diffusion of over 40,000 true and false news stories on Twitter reveals that the assumptions made during the reconstruction procedure drastically distort both microscopic and macroscopic properties of cascade networks. This work highlights the challenges of studying information spreading processes on complex networks and has significant implications for the broader study of digital platforms.", "published": "2024-10-31 04:00:00", "id": "0bca34ef-16d0-4865-9023-7a9ad8b7b3e1", "source": "arxiv", "section": "computerScience"}, {"title": "Super-resolution in disordered media using neural networks", "link": "https://arxiv.org/abs/2410.21556", "description": "arXiv:2410.21556v2 Announce Type: replace \nAbstract: We propose a methodology that exploits large and diverse data sets to accurately estimate the ambient medium's Green's functions in strongly scattering media. Given these estimates, obtained with and without the use of neural networks, excellent imaging results are achieved, with a resolution that is better than that of a homogeneous medium. This phenomenon, also known as super-resolution, occurs because the ambient scattering medium effectively enhances the physical imaging aperture.", "published": "2024-10-31 04:00:00", "id": "a26a899a-16e9-4c73-9c97-54870895f7b3", "source": "arxiv", "section": "computerScience"}, {"title": "A Novel Score-CAM based Denoiser for Spectrographic Signature Extraction without Ground Truth", "link": "https://arxiv.org/abs/2410.21557", "description": "arXiv:2410.21557v2 Announce Type: replace \nAbstract: Sonar based audio classification techniques are a growing area of research in the field of underwater acoustics. Usually, underwater noise picked up by passive sonar transducers contains all types of signals that travel through the ocean and is transformed into spectrographic images. As a result, the corresponding spectrograms intended to display the temporal-frequency data of a certain object often include the tonal regions of abundant extraneous noise that can effectively interfere with a 'contact'. So, a majority of spectrographic samples extracted from underwater audio signals are rendered unusable due to their clutter and lack the required indistinguishability between different objects. With limited clean true data for supervised training, creating classification models for these audio signals is severely bottlenecked.\n  This paper derives several new techniques to combat this problem by developing a novel Score-CAM based denoiser to extract an object's signature from noisy spectrographic data without being given any ground truth data. In particular, this paper proposes a novel generative adversarial network architecture for learning and producing spectrographic training data in similar distributions to low-feature spectrogram inputs. In addition, this paper also a generalizable class activation mapping based denoiser for different distributions of acoustic data, even real-world data distributions. Utilizing these novel architectures and proposed denoising techniques, these experiments demonstrate state-of-the-art noise reduction accuracy and improved classification accuracy than current audio classification standards. As such, this approach has applications not only to audio data but for countless data distributions used all around the world for machine learning.", "published": "2024-10-31 04:00:00", "id": "3a835afc-16f6-4e98-b6b0-fd427503b47a", "source": "arxiv", "section": "computerScience"}, {"title": "Thank You, Stingray: Multilingual Large Language Models Can Not (Yet) Disambiguate Cross-Lingual Word Sense", "link": "https://arxiv.org/abs/2410.21573", "description": "arXiv:2410.21573v2 Announce Type: replace \nAbstract: Multilingual large language models (LLMs) have gained prominence, but concerns arise regarding their reliability beyond English. This study addresses the gap in cross-lingual semantic evaluation by introducing a novel benchmark for cross-lingual sense disambiguation, StingrayBench. In this paper, we demonstrate using false friends -- words that are orthographically similar but have completely different meanings in two languages -- as a possible approach to pinpoint the limitation of cross-lingual sense disambiguation in LLMs. We collect false friends in four language pairs, namely Indonesian-Malay, Indonesian-Tagalog, Chinese-Japanese, and English-German; and challenge LLMs to distinguish the use of them in context. In our analysis of various models, we observe they tend to be biased toward higher-resource languages. We also propose new metrics for quantifying the cross-lingual sense bias and comprehension based on our benchmark. Our work contributes to developing more diverse and inclusive language modeling, promoting fairer access for the wider multilingual community.", "published": "2024-10-31 04:00:00", "id": "e2268e29-c214-4692-8de9-fcca44f37e94", "source": "arxiv", "section": "computerScience"}, {"title": "On filter design in deep convolutional neural network", "link": "https://arxiv.org/abs/2410.21644", "description": "arXiv:2410.21644v2 Announce Type: replace \nAbstract: The deep convolutional neural network (DCNN) in computer vision has given promising results. It is widely applied in many areas, from medicine, agriculture, self-driving car, biometric system, and almost all computer vision-based applications. Filters or weights are the critical elements responsible for learning in DCNN. Backpropagation has been the primary learning algorithm for DCNN and provides promising results, but the size and numbers of the filters remain hyper-parameters. Various studies have been done in the last decade on semi-supervised, self-supervised, and unsupervised methods and their properties. The effects of filter initialization, size-shape selection, and the number of filters on learning and optimization have not been investigated in a separate publication to collate all the options. Such attributes are often treated as hyper-parameters and lack mathematical understanding. Computer vision algorithms have many limitations in real-life applications, and understanding the learning process is essential to have some significant improvement. To the best of our knowledge, no separate investigation has been published discussing the filters; this is our primary motivation. This study focuses on arguments for choosing specific physical parameters of filters, initialization, and learning technic over scattered methods. The promising unsupervised approaches have been evaluated. Additionally, the limitations, current challenges, and future scope have been discussed in this paper.", "published": "2024-10-31 04:00:00", "id": "f56dcc10-7867-422d-bcc3-1504e0a7a5c6", "source": "arxiv", "section": "computerScience"}, {"title": "Impact of Code Transformation on Detection of Smart Contract Vulnerabilities", "link": "https://arxiv.org/abs/2410.21685", "description": "arXiv:2410.21685v2 Announce Type: replace \nAbstract: While smart contracts are foundational elements of blockchain applications, their inherent susceptibility to security vulnerabilities poses a significant challenge. Existing training datasets employed for vulnerability detection tools may be limited, potentially compromising their efficacy. This paper presents a method for improving the quantity and quality of smart contract vulnerability datasets and evaluates current detection methods. The approach centers around semantic-preserving code transformation, a technique that modifies the source code structure without altering its semantic meaning. The transformed code snippets are inserted into all potential locations within benign smart contract code, creating new vulnerable contract versions. This method aims to generate a wider variety of vulnerable codes, including those that can bypass detection by current analysis tools. The paper experiments evaluate the method's effectiveness using tools like Slither, Mythril, and CrossFuzz, focusing on metrics like the number of generated vulnerable samples and the false negative rate in detecting these vulnerabilities. The improved results show that many newly created vulnerabilities can bypass tools and the false reporting rate goes up to 100% and increases dataset size minimum by 2.5X.", "published": "2024-10-31 04:00:00", "id": "404e0cd4-b0c7-4c81-9fd9-4d82abf85380", "source": "arxiv", "section": "computerScience"}, {"title": "Enhancing Safety and Robustness of Vision-Based Controllers via Reachability Analysis", "link": "https://arxiv.org/abs/2410.21736", "description": "arXiv:2410.21736v2 Announce Type: replace \nAbstract: Autonomous systems, such as self-driving cars and drones, have made significant strides in recent years by leveraging visual inputs and machine learning for decision-making and control. Despite their impressive performance, these vision-based controllers can make erroneous predictions when faced with novel or out-of-distribution inputs. Such errors can cascade into catastrophic system failures and compromise system safety. In this work, we compute Neural Reachable Tubes, which act as parameterized approximations of Backward Reachable Tubes to stress-test the vision-based controllers and mine their failure modes. The identified failures are then used to enhance the system safety through both offline and online methods. The online approach involves training a classifier as a run-time failure monitor to detect closed-loop, system-level failures, subsequently triggering a fallback controller that robustly handles these detected failures to preserve system safety. For the offline approach, we improve the original controller via incremental training using a carefully augmented failure dataset, resulting in a more robust controller that is resistant to the known failure modes. In either approach, the system is safeguarded against shortcomings that transcend the vision-based controller and pertain to the closed-loop safety of the overall system. We validate the proposed approaches on an autonomous aircraft taxiing task that involves using a vision-based controller to guide the aircraft towards the centerline of the runway. Our results show the efficacy of the proposed algorithms in identifying and handling system-level failures, outperforming methods that rely on controller prediction error or uncertainty quantification for identifying system failures.", "published": "2024-10-31 04:00:00", "id": "d8544320-1588-4373-afc7-52dfd63ddf41", "source": "arxiv", "section": "computerScience"}, {"title": "IntLoRA: Integral Low-rank Adaptation of Quantized Diffusion Models", "link": "https://arxiv.org/abs/2410.21759", "description": "arXiv:2410.21759v2 Announce Type: replace \nAbstract: Fine-tuning large-scale text-to-image diffusion models for various downstream tasks has yielded impressive results. However, the heavy computational burdens of tuning large models prevent personal customization. Recent advances have attempted to employ parameter-efficient fine-tuning (PEFT) techniques to adapt the floating-point (FP) or quantized pre-trained weights. Nonetheless, the adaptation parameters in existing works are still restricted to FP arithmetic, hindering hardware-friendly acceleration. In this work, we propose IntLoRA, to further push the efficiency limits by using integer type (INT) low-rank parameters to adapt the quantized diffusion models. By working in the integer arithmetic, our IntLoRA offers three key advantages: (i) for fine-tuning, the pre-trained weights are quantized, reducing memory usage; (ii) for storage, both pre-trained and low-rank weights are in INT which consumes less disk space; (iii) for inference, IntLoRA weights can be naturally merged into quantized pre-trained weights through efficient integer multiplication or bit-shifting, eliminating additional post-training quantization. Extensive experiments demonstrate that IntLoRA can achieve performance on par with or even superior to the vanilla LoRA, accompanied by significant efficiency improvements. Code is available at \\url{https://github.com/csguoh/IntLoRA}.", "published": "2024-10-31 04:00:00", "id": "e0a581ac-fab2-4a01-9024-c12f4f3206fe", "source": "arxiv", "section": "computerScience"}, {"title": "Text-Guided Attention is All You Need for Zero-Shot Robustness in Vision-Language Models", "link": "https://arxiv.org/abs/2410.21802", "description": "arXiv:2410.21802v2 Announce Type: replace \nAbstract: Due to the impressive zero-shot capabilities, pre-trained vision-language models (e.g. CLIP), have attracted widespread attention and adoption across various domains. Nonetheless, CLIP has been observed to be susceptible to adversarial examples. Through experimental analysis, we have observed a phenomenon wherein adversarial perturbations induce shifts in text-guided attention. Building upon this observation, we propose a simple yet effective strategy: Text-Guided Attention for Zero-Shot Robustness (TGA-ZSR). This framework incorporates two components: the Attention Refinement module and the Attention-based Model Constraint module. Our goal is to maintain the generalization of the CLIP model and enhance its adversarial robustness: The Attention Refinement module aligns the text-guided attention obtained from the target model via adversarial examples with the text-guided attention acquired from the original model via clean examples. This alignment enhances the model's robustness. Additionally, the Attention-based Model Constraint module acquires text-guided attention from both the target and original models using clean examples. Its objective is to maintain model performance on clean samples while enhancing overall robustness. The experiments validate that our method yields a 9.58% enhancement in zero-shot robust accuracy over the current state-of-the-art techniques across 16 datasets. Our code is available at https://github.com/zhyblue424/TGA-ZSR.", "published": "2024-10-31 04:00:00", "id": "bf7af0b2-4dec-4877-b63f-16b88a2b89d7", "source": "arxiv", "section": "computerScience"}, {"title": "Large Language Models Based JSON Parser Fuzzing for Bug Discovery and Behavioral Analysis", "link": "https://arxiv.org/abs/2410.21806", "description": "arXiv:2410.21806v2 Announce Type: replace \nAbstract: Fuzzing has been incredibly successful in uncovering bugs and vulnerabilities across diverse software systems. JSON parsers play a vital role in modern software development, and ensuring their reliability is of great importance. This research project focuses on leveraging Large Language Models (LLMs) to enhance JSON parser testing. The primary objectives are to generate test cases and mutants using LLMs for the discovery of potential bugs in open-source JSON parsers and the identification of behavioral diversities among them. We aim to uncover underlying bugs, plus discovering (and overcoming) behavioral diversities.", "published": "2024-10-31 04:00:00", "id": "2ebf393d-9775-4c16-a805-288738a37a7e", "source": "arxiv", "section": "computerScience"}, {"title": "A Fresh Look at Generalized Category Discovery through Non-negative Matrix Factorization", "link": "https://arxiv.org/abs/2410.21807", "description": "arXiv:2410.21807v2 Announce Type: replace \nAbstract: Generalized Category Discovery (GCD) aims to classify both base and novel images using labeled base data. However, current approaches inadequately address the intrinsic optimization of the co-occurrence matrix $\\bar{A}$ based on cosine similarity, failing to achieve zero base-novel regions and adequate sparsity in base and novel domains. To address these deficiencies, we propose a Non-Negative Generalized Category Discovery (NN-GCD) framework. It employs Symmetric Non-negative Matrix Factorization (SNMF) as a mathematical medium to prove the equivalence of optimal K-means with optimal SNMF, and the equivalence of SNMF solver with non-negative contrastive learning (NCL) optimization. Utilizing these theoretical equivalences, it reframes the optimization of $\\bar{A}$ and K-means clustering as an NCL optimization problem. Moreover, to satisfy the non-negative constraints and make a GCD model converge to a near-optimal region, we propose a GELU activation function and an NMF NCE loss. To transition $\\bar{A}$ from a suboptimal state to the desired $\\bar{A}^*$, we introduce a hybrid sparse regularization approach to impose sparsity constraints. Experimental results show NN-GCD outperforms state-of-the-art methods on GCD benchmarks, achieving an average accuracy of 66.1\\% on the Semantic Shift Benchmark, surpassing prior counterparts by 4.7\\%.", "published": "2024-10-31 04:00:00", "id": "7cc3b06a-0031-4974-8b25-47cafcb169d5", "source": "arxiv", "section": "computerScience"}, {"title": "Feature distribution Adaptation Network for Speech Emotion Recognition", "link": "https://arxiv.org/abs/2410.22023", "description": "arXiv:2410.22023v2 Announce Type: replace \nAbstract: In this paper, we propose a novel deep inductive transfer learning framework, named feature distribution adaptation network, to tackle the challenging multi-modal speech emotion recognition problem. Our method aims to use deep transfer learning strategies to align visual and audio feature distributions to obtain consistent representation of emotion, thereby improving the performance of speech emotion recognition. In our model, the pre-trained ResNet-34 is utilized for feature extraction for facial expression images and acoustic Mel spectrograms, respectively. Then, the cross-attention mechanism is introduced to model the intrinsic similarity relationships of multi-modal features. Finally, the multi-modal feature distribution adaptation is performed efficiently with feed-forward network, which is extended using the local maximum mean discrepancy loss. Experiments are carried out on two benchmark datasets, and the results demonstrate that our model can achieve excellent performance compared with existing ones.", "published": "2024-10-31 04:00:00", "id": "45264c86-93a5-4e60-83dd-9c29bfcfd8b9", "source": "arxiv", "section": "computerScience"}, {"title": "PC-Gym: Benchmark Environments For Process Control Problems", "link": "https://arxiv.org/abs/2410.22093", "description": "arXiv:2410.22093v2 Announce Type: replace \nAbstract: PC-Gym is an open-source tool designed to facilitate the development and evaluation of reinforcement learning (RL) algorithms for chemical process control problems. It provides a suite of environments that model a range of chemical processes, incorporating nonlinear dynamics, process disturbances, and constraints. Key features include flexible constraint handling mechanisms, customizable disturbance generation, and modular reward function design. The framework enables benchmarking state-of-the-art RL algorithms against a nonlinear Model Predictive Control (NMPC) oracle across various process control scenarios. Case studies demonstrate PC-Gym's effectiveness in evaluating RL approaches for the control of various chemical engineering systems such as a continuously stirred tank reactor, multistage extraction process, and crystallization reactor. The framework's ability to incorporate realistic disturbances and constraints allows for robust testing of control strategies. Results highlight the performance gaps between RL algorithms and NMPC oracles, demonstrating the utility of PC-Gym for algorithm benchmarking and suggesting areas for improvement in RL-based process control. By offering a standardized platform for developing and assessing RL-based control strategies, PC-Gym aims to accelerate research at the intersection of machine learning and process systems engineering. It bridges the gap between theoretical advancements in RL and practical applications in industrial process control, providing researchers and practitioners with a valuable tool for exploring data-driven control solutions for complex chemical processes.", "published": "2024-10-31 04:00:00", "id": "0dce617c-e3ec-495e-a2cb-80be81617656", "source": "arxiv", "section": "computerScience"}, {"title": "Training LLMs for Generating IEC 61131-3 Structured Text with Online Feedback", "link": "https://arxiv.org/abs/2410.22159", "description": "arXiv:2410.22159v2 Announce Type: replace \nAbstract: The advent of large language models (LLMs), such as GPT-4, has enabled significant advancements in generating code across various domains. However, these models face unique challenges when generating IEC 61131-3 Structured Text (ST) code due to limited data in public training datasets and the complexity of ST language syntax. This paper proposes a novel approach to training LLMs that emphasizes improving the quality of learning data through an online process involving compiler feedback and evaluation from a secondary LLM. In this framework, the primary LLM generates new training samples, which are subsequently evaluated by a compiler for syntactical correctness and by a specialized LLM that excels at assessing semantic accuracy, though it is not optimized for code generation itself. Through iterative refinement of the training data, this approach results in marked improvements for the trained LLM, leading to higher compilation success rates and better semantic precision. As a result, the framework proves highly suitable for industrial automation applications and outperforms state-of-the-art models.", "published": "2024-10-31 04:00:00", "id": "3ed70168-f9e6-474f-87bd-8ff74bb77e1b", "source": "arxiv", "section": "computerScience"}, {"title": "Towards Unifying Understanding and Generation in the Era of Vision Foundation Models: A Survey from the Autoregression Perspective", "link": "https://arxiv.org/abs/2410.22217", "description": "arXiv:2410.22217v2 Announce Type: replace \nAbstract: Autoregression in large language models (LLMs) has shown impressive scalability by unifying all language tasks into the next token prediction paradigm. Recently, there is a growing interest in extending this success to vision foundation models. In this survey, we review the recent advances and discuss future directions for autoregressive vision foundation models. First, we present the trend for next generation of vision foundation models, i.e., unifying both understanding and generation in vision tasks. We then analyze the limitations of existing vision foundation models, and present a formal definition of autoregression with its advantages. Later, we categorize autoregressive vision foundation models from their vision tokenizers and autoregression backbones. Finally, we discuss several promising research challenges and directions. To the best of our knowledge, this is the first survey to comprehensively summarize autoregressive vision foundation models under the trend of unifying understanding and generation. A collection of related resources is available at https://github.com/EmmaSRH/ARVFM.", "published": "2024-10-31 04:00:00", "id": "19a4cacd-a627-4304-b80e-811c2ec8cfc5", "source": "arxiv", "section": "computerScience"}, {"title": "GPT-4o reads the mind in the eyes", "link": "https://arxiv.org/abs/2410.22309", "description": "arXiv:2410.22309v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are capable of reproducing human-like inferences, including inferences about emotions and mental states, from text. Whether this capability extends beyond text to other modalities remains unclear. Humans possess a sophisticated ability to read the mind in the eyes of other people. Here we tested whether this ability is also present in GPT-4o, a multimodal LLM. Using two versions of a widely used theory of mind test, the Reading the Mind in Eyes Test and the Multiracial Reading the Mind in the Eyes Test, we found that GPT-4o outperformed humans in interpreting mental states from upright faces but underperformed humans when faces were inverted. While humans in our sample showed no difference between White and Non-white faces, GPT-4o's accuracy was higher for White than for Non-white faces. GPT-4o's errors were not random but revealed a highly consistent, yet incorrect, processing of mental-state information across trials, with an orientation-dependent error structure that qualitatively differed from that of humans for inverted faces but not for upright faces. These findings highlight how advanced mental state inference abilities and human-like face processing signatures, such as inversion effects, coexist in GPT-4o alongside substantial differences in information processing compared to humans.", "published": "2024-10-31 04:00:00", "id": "2a75e5da-53c5-4be2-bc11-8a4c60514f97", "source": "arxiv", "section": "computerScience"}, {"title": "Robots Pre-train Robots: Manipulation-Centric Robotic Representation from Large-Scale Robot Datasets", "link": "https://arxiv.org/abs/2410.22325", "description": "arXiv:2410.22325v2 Announce Type: replace \nAbstract: The pre-training of visual representations has enhanced the efficiency of robot learning. Due to the lack of large-scale in-domain robotic datasets, prior works utilize in-the-wild human videos to pre-train robotic visual representation. Despite their promising results, representations from human videos are inevitably subject to distribution shifts and lack the dynamics information crucial for task completion. We first evaluate various pre-trained representations in terms of their correlation to the downstream robotic manipulation tasks (i.e., manipulation centricity). Interestingly, we find that the \"manipulation centricity\" is a strong indicator of success rates when applied to downstream tasks. Drawing from these findings, we propose Manipulation Centric Representation (MCR), a foundation representation learning framework capturing both visual features and the dynamics information such as actions and proprioceptions of manipulation tasks to improve manipulation centricity. Specifically, we pre-train a visual encoder on the DROID robotic dataset and leverage motion-relevant data such as robot proprioceptive states and actions. We introduce a novel contrastive loss that aligns visual observations with the robot's proprioceptive state-action dynamics, combined with a behavior cloning (BC)-like actor loss to predict actions during pre-training, along with a time contrastive loss. Empirical results across 4 simulation domains with 20 tasks verify that MCR outperforms the strongest baseline method by 14.8%. Moreover, MCR boosts the performance of data-efficient learning with a UR5e arm on 3 real-world tasks by 76.9%. Project website: https://robots-pretrain-robots.github.io/.", "published": "2024-10-31 04:00:00", "id": "a6565fc3-202d-4094-884a-4b075dbe2fd4", "source": "arxiv", "section": "computerScience"}, {"title": "Robustifying automatic speech recognition by extracting slowly varying features", "link": "https://arxiv.org/abs/2112.07400", "description": "arXiv:2112.07400v2 Announce Type: replace-cross \nAbstract: In the past few years, it has been shown that deep learning systems are highly vulnerable under attacks with adversarial examples. Neural-network-based automatic speech recognition (ASR) systems are no exception. Targeted and untargeted attacks can modify an audio input signal in such a way that humans still recognise the same words, while ASR systems are steered to predict a different transcription. In this paper, we propose a defense mechanism against targeted adversarial attacks consisting in removing fast-changing features from the audio signals, either by applying slow feature analysis, a low-pass filter, or both, before feeding the input to the ASR system. We perform an empirical analysis of hybrid ASR models trained on data pre-processed in such a way. While the resulting models perform quite well on benign data, they are significantly more robust against targeted adversarial attacks: Our final, proposed model shows a performance on clean data similar to the baseline model, while being more than four times more robust.", "published": "2024-10-31 04:00:00", "id": "f8fa0090-b469-48cb-a8b9-55f588205eae", "source": "arxiv", "section": "computerScience"}, {"title": "Limits of structures and Total NP Search Problems", "link": "https://arxiv.org/abs/2301.13603", "description": "arXiv:2301.13603v3 Announce Type: replace-cross \nAbstract: For an infinite class of finite graphs of unbounded size, we define a limit object, to be called a $\\textit{wide limit}$, relative to some computationally restricted class of functions. The limit object is a first order Boolean-valued structure. The first order properties of the wide limit then reflect how a computationally restricted viewer \"sees\" a generic member of the class. The construction uses arithmetic forcing with random variables [Kraj\\'i\\v{c}ek, Forcing with random variables and proof complexity 2011]. We give sufficient conditions for universal and existential sentences to be valid in the limit, provide several examples, and prove that such a limit object can then be expanded to a model of weak arithmetic.\n  To illustrate the concept we give an example in which the wide limit relates to total NP search problems. In particular, we take the wide limit of all maps from $\\{0,\\dots,k-1\\}$ to $\\{0,\\dots,\\lfloor k/2\\rfloor-1\\}$ to obtain a model of $\\forall \\text{PV}_1(f)$ where the problem $\\textbf{RetractionWeakPigeon}$ is total but $\\textbf{WeakPigeon}$, the complete problem for $\\textbf{PWPP}$, is not. Thus, we obtain a new proof of this unprovability and show it implies that $\\textbf{WeakPigeon}$ is not many-one reducible to $\\textbf{RetractionWeakPigeon}$ in the oracle setting.", "published": "2024-10-31 04:00:00", "id": "793852ae-974a-46da-be4c-f10a8356fa84", "source": "arxiv", "section": "computerScience"}, {"title": "Online Control with Adversarial Disturbance for Continuous-time Linear Systems", "link": "https://arxiv.org/abs/2306.01952", "description": "arXiv:2306.01952v4 Announce Type: replace-cross \nAbstract: We study online control for continuous-time linear systems with finite sampling rates, where the objective is to design an online procedure that learns under non-stochastic noise and performs comparably to a fixed optimal linear controller. We present a novel two-level online algorithm, by integrating a higher-level learning strategy and a lower-level feedback control strategy. This method offers a practical and robust solution for online control, which achieves sublinear regret. Our work provides the first nonasymptotic results for controlling continuous-time linear systems with finite number of interactions with the system. Moreover, we examine how to train an agent in domain randomization environments from a non-stochastic control perspective. By applying our method to the SAC (Soft Actor-Critic) algorithm, we achieved improved results in multiple reinforcement learning tasks within domain randomization environments. Our work provides new insights into non-asymptotic analyses of controlling continuous-time systems. Furthermore, our work brings practical intuition into controller learning under non-stochastic environments.", "published": "2024-10-31 04:00:00", "id": "7dfcc412-bd8e-41f6-8cf3-d820ed96bc2e", "source": "arxiv", "section": "computerScience"}, {"title": "Mixed variable structural optimization using mixed variable system Monte Carlo tree search formulation", "link": "https://arxiv.org/abs/2309.14231", "description": "arXiv:2309.14231v2 Announce Type: replace-cross \nAbstract: A novel method called mixed variable system Monte Carlo tree search (MVSMCTS) formulation is presented for optimization problems considering various types of variables with single and mixed continuous-discrete system. This method utilizes a reinforcement learning algorithm with improved Monte Carlo tree search (IMCTS) formulation. For sizing and shape optimization of truss structures, the design variables are the cross-sectional areas of the members and the nodal coordinates of the joints. MVSMCTS incorporates update process and accelerating technique for continuous variable and combined scheme for single and mixed system. Update process indicates that once a solution is determined by MCTS with automatic mesh generation in continuous space, it is used as the initial solution for next search tree. The search region should be expanded from the mid-point, which is the design variable for initial state. Accelerating technique is developed by decreasing the range of search region and the width of search tree based on the number of meshes during update process. Combined scheme means that various types of variables are coupled in only one search tree. Through several examples, it is demonstrated that this framework is suitable for mixed variable structural optimization. Moreover, the agent can find optimal solution in a reasonable time, stably generates an optimal design, and is applicable for practical engineering problems.", "published": "2024-10-31 04:00:00", "id": "9c14cb41-a18c-42b9-84d4-b9e11d8579af", "source": "arxiv", "section": "computerScience"}, {"title": "Fair Wasserstein Coresets", "link": "https://arxiv.org/abs/2311.05436", "description": "arXiv:2311.05436v4 Announce Type: replace-cross \nAbstract: Data distillation and coresets have emerged as popular approaches to generate a smaller representative set of samples for downstream learning tasks to handle large-scale datasets. At the same time, machine learning is being increasingly applied to decision-making processes at a societal level, making it imperative for modelers to address inherent biases towards subgroups present in the data. While current approaches focus on creating fair synthetic representative samples by optimizing local properties relative to the original samples, their impact on downstream learning processes has yet to be explored. In this work, we present fair Wasserstein coresets (FWC), a novel coreset approach which generates fair synthetic representative samples along with sample-level weights to be used in downstream learning tasks. FWC uses an efficient majority minimization algorithm to minimize the Wasserstein distance between the original dataset and the weighted synthetic samples while enforcing demographic parity. We show that an unconstrained version of FWC is equivalent to Lloyd's algorithm for k-medians and k-means clustering. Experiments conducted on both synthetic and real datasets show that FWC: (i) achieves a competitive fairness-utility tradeoff in downstream models compared to existing approaches, (ii) improves downstream fairness when added to the existing training data and (iii) can be used to reduce biases in predictions from large language models (GPT-3.5 and GPT-4).", "published": "2024-10-31 04:00:00", "id": "aaaf39ef-82e4-4da9-9c53-9652eb755217", "source": "arxiv", "section": "computerScience"}, {"title": "Fast algorithms for classical specifications of stabiliser states and Clifford gates", "link": "https://arxiv.org/abs/2311.10357", "description": "arXiv:2311.10357v4 Announce Type: replace-cross \nAbstract: The stabiliser formalism plays a central role in quantum computing, error correction, and fault tolerance. Conversions between and verifications of different specifications of stabiliser states and Clifford gates are important components of many classical algorithms in quantum information, e.g. for gate synthesis, circuit optimisation, and simulating quantum circuits. These core functions are also used in the numerical experiments critical to formulating and testing mathematical conjectures on the stabiliser formalism.\n  We develop novel mathematical insights concerning stabiliser states and Clifford gates that significantly clarify their descriptions. We then utilise these to provide ten new fast algorithms which offer asymptotic advantages over any existing implementations. We show how to rapidly verify that a vector is a stabiliser state, and interconvert between its specification as amplitudes, a quadratic form, and a check matrix. These methods are leveraged to rapidly check if a given unitary matrix is a Clifford gate and to interconvert between the matrix of a Clifford gate and its compact specification as a stabiliser tableau.\n  For example, we extract the stabiliser tableau of a $2^n \\times 2^n$ matrix, promised to be a Clifford gate, in $O(n 2^n)$ time. Remarkably, it is not necessary to read all the elements of a Clifford gate matrix to extract its stabiliser tableau. This is an asymptotic speedup over the best-known method that is exponential in the number of qubits.\n  We provide implementations of our algorithms in $\\texttt{Python}$ and $\\texttt{C++}$ that exhibit vastly improved practical performance over existing algorithms in the cases where they exist.", "published": "2024-10-31 04:00:00", "id": "fdd7e519-6388-4a46-aae0-387cffcdc8b9", "source": "arxiv", "section": "computerScience"}, {"title": "PAC-Bayes-Chernoff bounds for unbounded losses", "link": "https://arxiv.org/abs/2401.01148", "description": "arXiv:2401.01148v4 Announce Type: replace-cross \nAbstract: We introduce a new PAC-Bayes oracle bound for unbounded losses that extends Cram\\'er-Chernoff bounds to the PAC-Bayesian setting. The proof technique relies on controlling the tails of certain random variables involving the Cram\\'er transform of the loss. Our approach naturally leverages properties of Cram\\'er-Chernoff bounds, such as exact optimization of the free parameter in many PAC-Bayes bounds. We highlight several applications of the main theorem. Firstly, we show that our bound recovers and generalizes previous results. Additionally, our approach allows working with richer assumptions that result in more informative and potentially tighter bounds. In this direction, we provide a general bound under a new \\textit{model-dependent} assumption from which we obtain bounds based on parameter norms and log-Sobolev inequalities. Notably, many of these bounds can be minimized to obtain distributions beyond the Gibbs posterior and provide novel theoretical coverage to existing regularization techniques.", "published": "2024-10-31 04:00:00", "id": "657226b2-1d71-41a7-b25b-5d8bdff97710", "source": "arxiv", "section": "computerScience"}, {"title": "Unlocking the Power of Multi-institutional Data: Integrating and Harmonizing Genomic Data Across Institutions", "link": "https://arxiv.org/abs/2402.00077", "description": "arXiv:2402.00077v2 Announce Type: replace-cross \nAbstract: Cancer is a complex disease driven by genomic alterations, and tumor sequencing is becoming a mainstay of clinical care for cancer patients. The emergence of multi-institution sequencing data presents a powerful resource for learning real-world evidence to enhance precision oncology. GENIE BPC, led by the American Association for Cancer Research, establishes a unique database linking genomic data with clinical information for patients treated at multiple cancer centers. However, leveraging such multi-institutional sequencing data presents significant challenges. Variations in gene panels result in loss of information when the analysis is conducted on common gene sets. Additionally, differences in sequencing techniques and patient heterogeneity across institutions add complexity. High data dimensionality, sparse gene mutation patterns, and weak signals at the individual gene level further complicate matters. Motivated by these real-world challenges, we introduce the Bridge model. It uses a quantile-matched latent variable approach to derive integrated features to preserve information beyond common genes and maximize the utilization of all available data while leveraging information sharing to enhance both learning efficiency and the model's capacity to generalize. By extracting harmonized and noise-reduced lower-dimensional latent variables, the true mutation pattern unique to each individual is captured. We assess the model's performance and parameter estimation through extensive simulation studies. The extracted latent features from the Bridge model consistently excel in predicting patient survival across six cancer types in GENIE BPC data.", "published": "2024-10-31 04:00:00", "id": "f89942ed-14fe-4f9c-ac87-6044ac155c1d", "source": "arxiv", "section": "computerScience"}, {"title": "Parameter uncertainties for imperfect surrogate models in the low-noise regime", "link": "https://arxiv.org/abs/2402.01810", "description": "arXiv:2402.01810v4 Announce Type: replace-cross \nAbstract: Bayesian regression determines model parameters by minimizing the expected loss, an upper bound to the true generalization error. However, the loss ignores misspecification, where models are imperfect. Parameter uncertainties from Bayesian regression are thus significantly underestimated and vanish in the large data limit. This is particularly problematic when building models of low-noise, or near-deterministic, calculations, as the main source of uncertainty is neglected. We analyze the generalization error of misspecified, near-deterministic surrogate models, a regime of broad relevance in science and engineering. We show posterior distributions must cover every training point to avoid a divergent generalization error and design an ansatz that respects this constraint, which for linear models incurs minimal overhead. This is demonstrated on model problems before application to thousand dimensional datasets in atomistic machine learning. Our efficient misspecification-aware scheme gives accurate prediction and bounding of test errors where existing schemes fail, allowing this important source of uncertainty to be incorporated in computational workflows.", "published": "2024-10-31 04:00:00", "id": "8f6cc571-44ac-4891-a663-d16b4f45a663", "source": "arxiv", "section": "computerScience"}, {"title": "Beyond Strong labels: Weakly-supervised Learning Based on Gaussian Pseudo Labels for The Segmentation of Ellipse-like Vascular Structures in Non-contrast CTs", "link": "https://arxiv.org/abs/2402.03492", "description": "arXiv:2402.03492v3 Announce Type: replace-cross \nAbstract: Deep-learning-based automated segmentation of vascular structures in preoperative CT scans contributes to computer-assisted diagnosis and intervention procedure in vascular diseases. While CT angiography (CTA) is the common standard, non-contrast CT imaging is significant as a contrast-risk-free alternative, avoiding complications associated with contrast agents. However, the challenges of labor-intensive labeling and high labeling variability due to the ambiguity of vascular boundaries hinder conventional strong-label-based, fully-supervised learning in non-contrast CTs. This paper introduces a weakly-supervised framework using ellipses' topology in slices, including 1) an efficient annotation process based on predefined standards, 2) ellipse-fitting processing, 3) the generation of 2D Gaussian heatmaps serving as pseudo labels, 4) a training process through a combination of voxel reconstruction loss and distribution loss with the pseudo labels. We assess the effectiveness of the proposed method on one local and two public datasets comprising non-contrast CT scans, particularly focusing on the abdominal aorta. On the local dataset, our weakly-supervised learning approach based on pseudo labels outperforms strong-label-based fully-supervised learning (1.54\\% of Dice score on average), reducing labeling time by around 82.0\\%. The efficiency in generating pseudo labels allows the inclusion of label-agnostic external data in the training set, leading to an additional improvement in performance (2.74\\% of Dice score on average) with a reduction of 66.3\\% labeling time, where the labeling time remains considerably less than that of strong labels. On the public dataset, the pseudo labels achieve an overall improvement of 1.95\\% in Dice score for 2D models while a reduction of 11.65 voxel spacing in Hausdorff distance for 3D model.", "published": "2024-10-31 04:00:00", "id": "797dbecb-43dc-4f61-b739-de1676539d06", "source": "arxiv", "section": "computerScience"}, {"title": "Genetic-guided GFlowNets for Sample Efficient Molecular Optimization", "link": "https://arxiv.org/abs/2402.05961", "description": "arXiv:2402.05961v3 Announce Type: replace-cross \nAbstract: The challenge of discovering new molecules with desired properties is crucial in domains like drug discovery and material design. Recent advances in deep learning-based generative methods have shown promise but face the issue of sample efficiency due to the computational expense of evaluating the reward function. This paper proposes a novel algorithm for sample-efficient molecular optimization by distilling a powerful genetic algorithm into deep generative policy using GFlowNets training, the off-policy method for amortized inference. This approach enables the deep generative policy to learn from domain knowledge, which has been explicitly integrated into the genetic algorithm. Our method achieves state-of-the-art performance in the official molecular optimization benchmark, significantly outperforming previous methods. It also demonstrates effectiveness in designing inhibitors against SARS-CoV-2 with substantially fewer reward calls.", "published": "2024-10-31 04:00:00", "id": "8d3bef31-9206-4402-bc6b-4b86f270da02", "source": "arxiv", "section": "computerScience"}, {"title": "Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion", "link": "https://arxiv.org/abs/2402.17886", "description": "arXiv:2402.17886v4 Announce Type: replace-cross \nAbstract: This paper considers the problem of sampling from non-logconcave distribution, based on queries of its unnormalized density. It first describes a framework, Denoising Diffusion Monte Carlo (DDMC), based on the simulation of a denoising diffusion process with its score function approximated by a generic Monte Carlo estimator. DDMC is an oracle-based meta-algorithm, where its oracle is the assumed access to samples that generate a Monte Carlo score estimator. Then we provide an implementation of this oracle, based on rejection sampling, and this turns DDMC into a true algorithm, termed Zeroth-Order Diffusion Monte Carlo (ZOD-MC). We provide convergence analyses by first constructing a general framework, i.e. a performance guarantee for DDMC, without assuming the target distribution to be log-concave or satisfying any isoperimetric inequality. Then we prove that ZOD-MC admits an inverse polynomial dependence on the desired sampling accuracy, albeit still suffering from the curse of dimensionality. Consequently, for low dimensional distributions, ZOD-MC is a very efficient sampler, with performance exceeding latest samplers, including also-denoising-diffusion-based RDMC and RSDMC. Last, we experimentally demonstrate the insensitivity of ZOD-MC to increasingly higher barriers between modes or discontinuity in non-convex potential.", "published": "2024-10-31 04:00:00", "id": "9c7cf8e9-8e38-48c7-adbc-9592af480b4c", "source": "arxiv", "section": "computerScience"}, {"title": "Full Event Particle-Level Unfolding with Variable-Length Latent Variational Diffusion", "link": "https://arxiv.org/abs/2404.14332", "description": "arXiv:2404.14332v2 Announce Type: replace-cross \nAbstract: The measurements performed by particle physics experiments must account for the imperfect response of the detectors used to observe the interactions. One approach, unfolding, statistically adjusts the experimental data for detector effects. Recently, generative machine learning models have shown promise for performing unbinned unfolding in a high number of dimensions. However, all current generative approaches are limited to unfolding a fixed set of observables, making them unable to perform full-event unfolding in the variable dimensional environment of collider data. A novel modification to the variational latent diffusion model (VLD) approach to generative unfolding is presented, which allows for unfolding of high- and variable-dimensional feature spaces. The performance of this method is evaluated in the context of semi-leptonic top quark pair production at the Large Hadron Collider.", "published": "2024-10-31 04:00:00", "id": "982d0857-fe98-4ee1-8d2e-c2a858b36bf1", "source": "arxiv", "section": "computerScience"}, {"title": "Real-time multichannel deep speech enhancement in hearing aids: Comparing monaural and binaural processing in complex acoustic scenarios", "link": "https://arxiv.org/abs/2405.01967", "description": "arXiv:2405.01967v3 Announce Type: replace-cross \nAbstract: Deep learning has the potential to enhance speech signals and increase their intelligibility for users of hearing aids. Deep models suited for real-world application should feature a low computational complexity and low processing delay of only a few milliseconds. In this paper, we explore deep speech enhancement that matches these requirements and contrast monaural and binaural processing algorithms in two complex acoustic scenes. Both algorithms are evaluated with objective metrics and in experiments with hearing-impaired listeners performing a speech-in-noise test. Results are compared to two traditional enhancement strategies, i.e., adaptive differential microphone processing and binaural beamforming. While in diffuse noise, all algorithms perform similarly, the binaural deep learning approach performs best in the presence of spatial interferers. Through a post-analysis, this can be attributed to improvements at low SNRs and to precise spatial filtering.", "published": "2024-10-31 04:00:00", "id": "3143ce16-d659-4b0d-80e4-abc2f3e16b6d", "source": "arxiv", "section": "computerScience"}, {"title": "Is Transductive Learning Equivalent to PAC Learning?", "link": "https://arxiv.org/abs/2405.05190", "description": "arXiv:2405.05190v2 Announce Type: replace-cross \nAbstract: Much of learning theory is concerned with the design and analysis of probably approximately correct (PAC) learners. The closely related transductive model of learning has recently seen more scrutiny, with its learners often used as precursors to PAC learners. Our goal in this work is to understand and quantify the exact relationship between these two models. First, we observe that modest extensions of existing results show the models to be essentially equivalent for realizable learning for most natural loss functions, up to low order terms in the error and sample complexity. The situation for agnostic learning appears less straightforward, with sample complexities potentially separated by a $\\frac{1}{\\epsilon}$ factor. This is therefore where our main contributions lie. Our results are two-fold:\n  1. For agnostic learning with bounded losses (including, for example, multiclass classification), we show that PAC learning reduces to transductive learning at the cost of low-order terms in the error and sample complexity via an adaptation of the reduction of arXiv:2304.09167 to the agnostic setting.\n  2. For agnostic binary classification, we show the converse: transductive learning is essentially no more difficult than PAC learning. Together with our first result this implies that the PAC and transductive models are essentially equivalent for agnostic binary classification. This is our most technical result, and involves two steps: A symmetrization argument on the agnostic one-inclusion graph (OIG) of arXiv:2309.13692 to derive the worst-case agnostic transductive instance, and expressing the error of the agnostic OIG algorithm for this instance in terms of the empirical Rademacher complexity of the class.\n  We leave as an intriguing open question whether our second result can be extended beyond binary classification to show the transductive and PAC models equivalent more broadly.", "published": "2024-10-31 04:00:00", "id": "bfd580f9-6d8b-45ec-825f-a20c17dfca0d", "source": "arxiv", "section": "computerScience"}, {"title": "Entrywise error bounds for low-rank approximations of kernel matrices", "link": "https://arxiv.org/abs/2405.14494", "description": "arXiv:2405.14494v2 Announce Type: replace-cross \nAbstract: In this paper, we derive entrywise error bounds for low-rank approximations of kernel matrices obtained using the truncated eigen-decomposition (or singular value decomposition). While this approximation is well-known to be optimal with respect to the spectral and Frobenius norm error, little is known about the statistical behaviour of individual entries. Our error bounds fill this gap. A key technical innovation is a delocalisation result for the eigenvectors of the kernel matrix corresponding to small eigenvalues, which takes inspiration from the field of Random Matrix Theory. Finally, we validate our theory with an empirical study of a collection of synthetic and real-world datasets.", "published": "2024-10-31 04:00:00", "id": "9e339aea-54ba-430a-ab71-0e5a7bfdf7d7", "source": "arxiv", "section": "computerScience"}, {"title": "Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics", "link": "https://arxiv.org/abs/2405.14806", "description": "arXiv:2405.14806v3 Announce Type: replace-cross \nAbstract: Extracting scientific understanding from particle-physics experiments requires solving diverse learning problems with high precision and good data efficiency. We propose the Lorentz Geometric Algebra Transformer (L-GATr), a new multi-purpose architecture for high-energy physics. L-GATr represents high-energy data in a geometric algebra over four-dimensional space-time and is equivariant under Lorentz transformations, the symmetry group of relativistic kinematics. At the same time, the architecture is a Transformer, which makes it versatile and scalable to large systems. L-GATr is first demonstrated on regression and classification tasks from particle physics. We then construct the first Lorentz-equivariant generative model: a continuous normalizing flow based on an L-GATr network, trained with Riemannian flow matching. Across our experiments, L-GATr is on par with or outperforms strong domain-specific baselines.", "published": "2024-10-31 04:00:00", "id": "51ab2f8b-1b93-48ed-a85d-ff68ee5bab26", "source": "arxiv", "section": "computerScience"}, {"title": "Conformal Classification with Equalized Coverage for Adaptively Selected Groups", "link": "https://arxiv.org/abs/2405.15106", "description": "arXiv:2405.15106v2 Announce Type: replace-cross \nAbstract: This paper introduces a conformal inference method to evaluate uncertainty in classification by generating prediction sets with valid coverage conditional on adaptively chosen features. These features are carefully selected to reflect potential model limitations or biases. This can be useful to find a practical compromise between efficiency -- by providing informative predictions -- and algorithmic fairness -- by ensuring equalized coverage for the most sensitive groups. We demonstrate the validity and effectiveness of this method on simulated and real data sets.", "published": "2024-10-31 04:00:00", "id": "15bb57b7-2651-42f2-8b66-880827cd03cd", "source": "arxiv", "section": "computerScience"}, {"title": "Structured Learning of Compositional Sequential Interventions", "link": "https://arxiv.org/abs/2406.05745", "description": "arXiv:2406.05745v2 Announce Type: replace-cross \nAbstract: We consider sequential treatment regimes where each unit is exposed to combinations of interventions over time. When interventions are described by qualitative labels, such as \"close schools for a month due to a pandemic\" or \"promote this podcast to this user during this week\", it is unclear which appropriate structural assumptions allow us to generalize behavioral predictions to previously unseen combinations of interventions. Standard black-box approaches mapping sequences of categorical variables to outputs are applicable, but they rely on poorly understood assumptions on how reliable generalization can be obtained, and may underperform under sparse sequences, temporal variability, and large action spaces. To approach that, we pose an explicit model for composition, that is, how the effect of sequential interventions can be isolated into modules, clarifying which data conditions allow for the identification of their combined effect at different units and time steps. We show the identification properties of our compositional model, inspired by advances in causal matrix factorization methods. Our focus is on predictive models for novel compositions of interventions instead of matrix completion tasks and causal effect estimation. We compare our approach to flexible but generic black-box models to illustrate how structure aids prediction in sparse data conditions.", "published": "2024-10-31 04:00:00", "id": "b9361c57-1d4b-4932-9437-862379b9dcf0", "source": "arxiv", "section": "computerScience"}, {"title": "Extracting thin film structures of energy materials using transformers", "link": "https://arxiv.org/abs/2406.16741", "description": "arXiv:2406.16741v2 Announce Type: replace-cross \nAbstract: Neutron-Transformer Reflectometry and Advanced Computation Engine (N-TRACE ), a neural network model using transformer architecture, is introduced for neutron reflectometry data analysis. It offers fast, accurate initial parameter estimations and efficient refinements, improving efficiency and precision for real-time data analysis of lithium-mediated nitrogen reduction for electrochemical ammonia synthesis, with relevance to other chemical transformations and batteries. Despite limitations in generalizing across systems, it shows promises for the use of transformers as the basis for models that could replace trial-and-error approaches to modeling reflectometry data.", "published": "2024-10-31 04:00:00", "id": "8ad3937b-23c6-4558-a226-47a35f1d62ad", "source": "arxiv", "section": "computerScience"}, {"title": "Particle Semi-Implicit Variational Inference", "link": "https://arxiv.org/abs/2407.00649", "description": "arXiv:2407.00649v2 Announce Type: replace-cross \nAbstract: Semi-implicit variational inference (SIVI) enriches the expressiveness of variational families by utilizing a kernel and a mixing distribution to hierarchically define the variational distribution. Existing SIVI methods parameterize the mixing distribution using implicit distributions, leading to intractable variational densities. As a result, directly maximizing the evidence lower bound (ELBO) is not possible, so they resort to one of the following: optimizing bounds on the ELBO, employing costly inner-loop Markov chain Monte Carlo runs, or solving minimax objectives. In this paper, we propose a novel method for SIVI called Particle Variational Inference (PVI) which employs empirical measures to approximate the optimal mixing distributions characterized as the minimizer of a free energy functional. PVI arises naturally as a particle approximation of a Euclidean--Wasserstein gradient flow and, unlike prior works, it directly optimizes the ELBO whilst making no parametric assumption about the mixing distribution. Our empirical results demonstrate that PVI performs favourably compared to other SIVI methods across various tasks. Moreover, we provide a theoretical analysis of the behaviour of the gradient flow of a related free energy functional: establishing the existence and uniqueness of solutions as well as propagation of chaos results.", "published": "2024-10-31 04:00:00", "id": "36e75982-0476-4180-b24b-f74e52bd2614", "source": "arxiv", "section": "computerScience"}, {"title": "WildDESED: An LLM-Powered Dataset for Wild Domestic Environment Sound Event Detection System", "link": "https://arxiv.org/abs/2407.03656", "description": "arXiv:2407.03656v3 Announce Type: replace-cross \nAbstract: This work aims to advance sound event detection (SED) research by presenting a new large language model (LLM)-powered dataset namely wild domestic environment sound event detection (WildDESED). It is crafted as an extension to the original DESED dataset to reflect diverse acoustic variability and complex noises in home settings. We leveraged LLMs to generate eight different domestic scenarios based on target sound categories of the DESED dataset. Then we enriched the scenarios with a carefully tailored mixture of noises selected from AudioSet and ensured no overlap with target sound. We consider widely popular convolutional neural recurrent network to study WildDESED dataset, which depicts its challenging nature. We then apply curriculum learning by gradually increasing noise complexity to enhance the model's generalization capabilities across various noise levels. Our results with this approach show improvements within the noisy environment, validating the effectiveness on the WildDESED dataset promoting noise-robust SED advancements.", "published": "2024-10-31 04:00:00", "id": "61941270-14af-42ed-a2f0-69c90c37ba9c", "source": "arxiv", "section": "computerScience"}, {"title": "BUSClean: Open-source software for breast ultrasound image pre-processing and knowledge extraction for medical AI", "link": "https://arxiv.org/abs/2407.11316", "description": "arXiv:2407.11316v3 Announce Type: replace-cross \nAbstract: Development of artificial intelligence (AI) for medical imaging demands curation and cleaning of large-scale clinical datasets comprising hundreds of thousands of images. Some modalities, such as mammography, contain highly standardized imaging. In contrast, breast ultrasound imaging (BUS) can contain many irregularities not indicated by scan metadata, such as enhanced scan modes, sonographer annotations, or additional views. We present an open-source software solution for automatically processing clinical BUS datasets. The algorithm performs BUS scan filtering (flagging of invalid and non-B-mode scans), cleaning (dual-view scan detection, scan area cropping, and caliper detection), and knowledge extraction (BI-RADS Labeling and Measurement fields) from sonographer annotations. Its modular design enables users to adapt it to new settings. Experiments on an internal testing dataset of 430 clinical BUS images achieve >95% sensitivity and >98% specificity in detecting every type of text annotation, >98% sensitivity and specificity in detecting scans with blood flow highlighting, alternative scan modes, or invalid scans. A case study on a completely external, public dataset of BUS scans found that BUSClean identified text annotations and scans with blood flow highlighting with 88.6% and 90.9% sensitivity and 98.3% and 99.9% specificity, respectively. Adaptation of the lesion caliper detection method to account for a type of caliper specific to the case study demonstrates the intended use of BUSClean in new data distributions and improved performance in lesion caliper detection from 43.3% and 93.3% out-of-the-box to 92.1% and 92.3% sensitivity and specificity, respectively. Source code, example notebooks, and sample data are available at https://github.com/hawaii-ai/bus-cleaning.", "published": "2024-10-31 04:00:00", "id": "f8d4c8d9-ed24-4897-b4ad-ed367fcb2eef", "source": "arxiv", "section": "computerScience"}, {"title": "Noise-augmented Chaotic Ising Machines for Combinatorial Optimization and Sampling", "link": "https://arxiv.org/abs/2408.04744", "description": "arXiv:2408.04744v2 Announce Type: replace-cross \nAbstract: Ising machines, hardware accelerators for combinatorial optimization and probabilistic sampling problems, have gained significant interest recently. A key element is stochasticity, which enables a wide exploration of configurations, thereby helping avoid local minima. Here, we refine the previously proposed concept of coupled chaotic bits (c-bits) that operate without explicit stochasticity. We show that augmenting chaotic bits with stochasticity enhances performance in combinatorial optimization, achieving algorithmic scaling comparable to probabilistic bits (p-bits). We first demonstrate that c-bits follow the quantum Boltzmann law in a 1D transverse field Ising model. We then show that c-bits exhibit critical dynamics similar to stochastic p-bits in 2D Ising and 3D spin glass models, with promising potential to solve challenging optimization problems. Finally, we propose a noise-augmented version of coupled c-bits via the adaptive parallel tempering algorithm (APT). Our noise-augmented c-bit algorithm outperforms fully deterministic c-bits running versions of the simulated annealing algorithm. Other analog Ising machines with coupled oscillators could draw inspiration from the proposed algorithm. Running replicas at constant temperature eliminates the need for global modulation of coupling strengths. Mixing stochasticity with deterministic c-bits creates a powerful hybrid computing scheme that can bring benefits in scaled, asynchronous, and massively parallel hardware implementations.", "published": "2024-10-31 04:00:00", "id": "b49819d1-1ebe-4328-b745-1ba088d36498", "source": "arxiv", "section": "computerScience"}, {"title": "Vertex-critical graphs in co-gem-free graphs", "link": "https://arxiv.org/abs/2408.05027", "description": "arXiv:2408.05027v2 Announce Type: replace-cross \nAbstract: A graph $G$ is $k$-vertex-critical if $\\chi(G)=k$ but $\\chi(G-v)<k$ for all $v\\in V(G)$ and $(G,H)$-free if it contains no induced subgraph isomorphic to $G$ or $H$. We show that there are only finitely many $k$-vertex-critical (co-gem, $H$)-free graphs for all $k$ when $H$ is any graph of order $4$ by showing finiteness in the three remaining open cases, those are the cases when $H$ is $2P_2$, $K_3+P_1$, and $K_4$. For the first two cases we actually prove the stronger results:\n  $\\bullet$ There are only finitely many $k$-vertex-critical (co-gem, paw$+P_1$)-free graphs for all $k$ and that only finitely many $k$-vertex-critical (co-gem, paw$+P_1$)-free graphs for all $k\\ge 1$.\n  $\\bullet$ There are only finitely many $k$-vertex-critical (co-gem, $P_5$, $P_3+cP_2$)-free graphs for all $k\\ge 1$ and $c\\ge 0$.\n  To prove the latter result, we employ a novel application of Sperner's Theorem on the number of antichains in a partially ordered set. Our result for $K_4$ uses exhaustive computer search and is proved by showing the stronger result that every $(\\text{co-gem, }K_4)$-free graph is $4$-colourable. Our results imply the existence of simple polynomial-time certifying algorithms to decide the $k$-colourability of (co-gem, $H$)-free graphs for all $k$ and all $H$ of order $4$ by searching the vertex-critical graphs as induced subgraphs.", "published": "2024-10-31 04:00:00", "id": "5124c52c-dddd-43ab-af9f-e525f976f171", "source": "arxiv", "section": "computerScience"}, {"title": "CT-AGRG: Automated Abnormality-Guided Report Generation from 3D Chest CT Volumes", "link": "https://arxiv.org/abs/2408.11965", "description": "arXiv:2408.11965v4 Announce Type: replace-cross \nAbstract: The rapid increase of computed tomography (CT) scans and their time-consuming manual analysis have created an urgent need for robust automated analysis techniques in clinical settings. These aim to assist radiologists and help them managing their growing workload. Existing methods typically generate entire reports directly from 3D CT images, without explicitly focusing on observed abnormalities. This unguided approach often results in repetitive content or incomplete reports, failing to prioritize anomaly-specific descriptions. We propose a new anomaly-guided report generation model, which first predicts abnormalities and then generates targeted descriptions for each. Evaluation on a public dataset demonstrates significant improvements in report quality and clinical relevance. We extend our work by conducting an ablation study to demonstrate its effectiveness.", "published": "2024-10-31 04:00:00", "id": "912d90e5-7e9c-4718-abd4-3398d38dde7f", "source": "arxiv", "section": "computerScience"}, {"title": "A nonlinear elasticity model in computer vision", "link": "https://arxiv.org/abs/2408.17237", "description": "arXiv:2408.17237v2 Announce Type: replace-cross \nAbstract: The purpose of this paper is to analyze a nonlinear elasticity model previously introduced by the authors for comparing two images, regarded as bounded open subsets of $\\R^n$ together with associated vector-valued intensity maps. Optimal transformations between the images are sought as minimisers of an integral functional among orientation-preserving homeomorphisms. The existence of minimisers is proved under natural coercivity and polyconvexity conditions, assuming only that the intensity functions are bounded measurable. Variants of the existence theorem are also proved, first under the constraint that finite sets of landmark points in the two images are mapped one to the other, and second when one image is to be compared to an unknown part of another.\n  The question is studied as to whether for images related by a linear mapping the unique minimizer is given by that linear mapping. For a natural class of functional integrands an example is given guaranteeing that this property holds for pairs of images in which the second is a scaling of the first by a constant factor. However for the property to hold for arbitrary pairs of linearly related images it is shown that the integrand has to depend on the gradient of the transformation as a convex function of its determinant alone. This suggests a new model in which the integrand depends also on second derivatives of the transformation, and an example is given for which both existence of minimizers is assured and the above property holds for all pairs of linearly related images.", "published": "2024-10-31 04:00:00", "id": "beeebab7-83fb-4cf8-a3f4-e8275fadce1e", "source": "arxiv", "section": "computerScience"}, {"title": "New Upper bounds for KL-divergence Based on Integral Norms", "link": "https://arxiv.org/abs/2409.00934", "description": "arXiv:2409.00934v2 Announce Type: replace-cross \nAbstract: In this paper, some new upper bounds for Kullback-Leibler divergence(KL-divergence) based on $L^1, L^2$ and $L^\\infty$ norms of density functions are discussed. Our findings unveil that the convergence in KL-divergence sense sandwiches between the convergence of density functions in terms of $L^1$ and $L^2$ norms. Furthermore, we endeavor to apply our newly derived upper bounds to the analysis of the rate theorem of the entropic conditional central limit theorem.", "published": "2024-10-31 04:00:00", "id": "08072b82-09de-45ad-90d4-600ec85dcd02", "source": "arxiv", "section": "computerScience"}, {"title": "Reassessing Noise Augmentation Methods in the Context of Adversarial Speech", "link": "https://arxiv.org/abs/2409.01813", "description": "arXiv:2409.01813v2 Announce Type: replace-cross \nAbstract: In this study, we investigate if noise-augmented training can concurrently improve adversarial robustness in automatic speech recognition (ASR) systems. We conduct a comparative analysis of the adversarial robustness of four different state-of-the-art ASR architectures, where each of the ASR architectures is trained under three different augmentation conditions: one subject to background noise, speed variations, and reverberations, another subject to speed variations only, and a third without any form of data augmentation. The results demonstrate that noise augmentation not only improves model performance on noisy speech but also the model's robustness to adversarial attacks.", "published": "2024-10-31 04:00:00", "id": "0654c82d-692c-442a-9572-a8a94e499558", "source": "arxiv", "section": "computerScience"}, {"title": "WaveMixSR-V2: Enhancing Super-resolution with Higher Efficiency", "link": "https://arxiv.org/abs/2409.10582", "description": "arXiv:2409.10582v3 Announce Type: replace-cross \nAbstract: Recent advancements in single image super-resolution have been predominantly driven by token mixers and transformer architectures. WaveMixSR utilized the WaveMix architecture, employing a two-dimensional discrete wavelet transform for spatial token mixing, achieving superior performance in super-resolution tasks with remarkable resource efficiency. In this work, we present an enhanced version of the WaveMixSR architecture by (1) replacing the traditional transpose convolution layer with a pixel shuffle operation and (2) implementing a multistage design for higher resolution tasks ($4\\times$). Our experiments demonstrate that our enhanced model -- WaveMixSR-V2 -- outperforms other architectures in multiple super-resolution tasks, achieving state-of-the-art for the BSD100 dataset, while also consuming fewer resources, exhibits higher parameter efficiency, lower latency and higher throughput. Our code is available at https://github.com/pranavphoenix/WaveMixSR.", "published": "2024-10-31 04:00:00", "id": "1a509fae-7644-459c-9735-c4afd1f297c9", "source": "arxiv", "section": "computerScience"}, {"title": "GTSinger: A Global Multi-Technique Singing Corpus with Realistic Music Scores for All Singing Tasks", "link": "https://arxiv.org/abs/2409.13832", "description": "arXiv:2409.13832v4 Announce Type: replace-cross \nAbstract: The scarcity of high-quality and multi-task singing datasets significantly hinders the development of diverse controllable and personalized singing tasks, as existing singing datasets suffer from low quality, limited diversity of languages and singers, absence of multi-technique information and realistic music scores, and poor task suitability. To tackle these problems, we present GTSinger, a large global, multi-technique, free-to-use, high-quality singing corpus with realistic music scores, designed for all singing tasks, along with its benchmarks. Particularly, (1) we collect 80.59 hours of high-quality singing voices, forming the largest recorded singing dataset; (2) 20 professional singers across nine widely spoken languages offer diverse timbres and styles; (3) we provide controlled comparison and phoneme-level annotations of six commonly used singing techniques, helping technique modeling and control; (4) GTSinger offers realistic music scores, assisting real-world musical composition; (5) singing voices are accompanied by manual phoneme-to-audio alignments, global style labels, and 16.16 hours of paired speech for various singing tasks. Moreover, to facilitate the use of GTSinger, we conduct four benchmark experiments: technique-controllable singing voice synthesis, technique recognition, style transfer, and speech-to-singing conversion. The corpus and demos can be found at http://gtsinger.github.io. We provide the dataset and the code for processing data and conducting benchmarks at https://huggingface.co/datasets/GTSinger/GTSinger and https://github.com/GTSinger/GTSinger.", "published": "2024-10-31 04:00:00", "id": "20dd568d-f762-4125-8725-8f4d323359ff", "source": "arxiv", "section": "computerScience"}, {"title": "AMARO: All Heavy-Atom Transferable Neural Network Potentials of Protein Thermodynamics", "link": "https://arxiv.org/abs/2409.17852", "description": "arXiv:2409.17852v2 Announce Type: replace-cross \nAbstract: All-atom molecular simulations offer detailed insights into macromolecular phenomena, but their substantial computational cost hinders the exploration of complex biological processes. We introduce Advanced Machine-learning Atomic Representation Omni-force-field (AMARO), a new neural network potential (NNP) that combines an O(3)-equivariant message-passing neural network architecture, TensorNet, with a coarse-graining map that excludes hydrogen atoms. AMARO demonstrates the feasibility of training coarser NNP, without prior energy terms, to run stable protein dynamics with scalability and generalization capabilities.", "published": "2024-10-31 04:00:00", "id": "5dd3b470-5247-4518-8152-b19bd3ed8673", "source": "arxiv", "section": "computerScience"}, {"title": "Response Estimation and System Identification of Dynamical Systems via Physics-Informed Neural Networks", "link": "https://arxiv.org/abs/2410.01340", "description": "arXiv:2410.01340v2 Announce Type: replace-cross \nAbstract: The accurate modelling of structural dynamics is crucial across numerous engineering applications, such as Structural Health Monitoring (SHM), seismic analysis, and vibration control. Often, these models originate from physics-based principles and can be derived from corresponding governing equations, often of differential equation form. However, complex system characteristics, such as nonlinearities and energy dissipation mechanisms, often imply that such models are approximative and often imprecise. This challenge is further compounded in SHM, where sensor data is often sparse, making it difficult to fully observe the system's states. To address these issues, this paper explores the use of Physics-Informed Neural Networks (PINNs), a class of physics-enhanced machine learning (PEML) techniques, for the identification and estimation of dynamical systems. PINNs offer a unique advantage by embedding known physical laws directly into the neural network's loss function, allowing for simple embedding of complex phenomena, even in the presence of uncertainties. This study specifically investigates three key applications of PINNs: state estimation in systems with sparse sensing, joint state-parameter estimation, when both system response and parameters are unknown, and parameter estimation within a Bayesian framework to quantify uncertainties. The results demonstrate that PINNs deliver an efficient tool across all aforementioned tasks, even in presence of modelling errors. However, these errors tend to have a more significant impact on parameter estimation, as the optimization process must reconcile discrepancies between the prescribed model and the true system behavior. Despite these challenges, PINNs show promise in dynamical system modeling, offering a robust approach to handling uncertainties.", "published": "2024-10-31 04:00:00", "id": "efe61978-41bc-44ac-b0d5-56dd27cb95fb", "source": "arxiv", "section": "computerScience"}, {"title": "EG-SpikeFormer: Eye-Gaze Guided Transformer on Spiking Neural Networks for Medical Image Analysis", "link": "https://arxiv.org/abs/2410.09674", "description": "arXiv:2410.09674v2 Announce Type: replace-cross \nAbstract: Neuromorphic computing has emerged as a promising energy-efficient alternative to traditional artificial intelligence, predominantly utilizing spiking neural networks (SNNs) implemented on neuromorphic hardware. Significant advancements have been made in SNN-based convolutional neural networks (CNNs) and Transformer architectures. However, neuromorphic computing for the medical imaging domain remains underexplored. In this study, we introduce EG-SpikeFormer, an SNN architecture tailored for clinical tasks that incorporates eye-gaze data to guide the model's attention to the diagnostically relevant regions in medical images. Our developed approach effectively addresses shortcut learning issues commonly observed in conventional models, especially in scenarios with limited clinical data and high demands for model reliability, generalizability, and transparency. Our EG-SpikeFormer not only demonstrates superior energy efficiency and performance in medical image prediction tasks but also enhances clinical relevance through multi-modal information alignment. By incorporating eye-gaze data, the model improves interpretability and generalization, opening new directions for applying neuromorphic computing in healthcare.", "published": "2024-10-31 04:00:00", "id": "f72e6e2a-4240-4b32-b279-c0c2aff0dcc3", "source": "arxiv", "section": "computerScience"}, {"title": "Predicting Molecular Ground-State Conformation via Conformation Optimization", "link": "https://arxiv.org/abs/2410.09795", "description": "arXiv:2410.09795v2 Announce Type: replace-cross \nAbstract: Predicting ground-state conformation from the corresponding molecular graph is crucial for many chemical applications, such as molecular modeling, molecular docking, and molecular property prediction. Recently, many learning-based methods have been proposed to replace time-consuming simulations for this task. However, these methods are often inefficient and sub-optimal as they merely rely on molecular graph information to make predictions from scratch. In this work, considering that molecular low-quality conformations are readily available, we propose a novel framework called ConfOpt to predict molecular ground-state conformation from the perspective of conformation optimization. Specifically, ConfOpt takes the molecular graph and corresponding low-quality 3D conformation as inputs, and then derives the ground-state conformation by iteratively optimizing the low-quality conformation under the guidance of the molecular graph. During training, ConfOpt concurrently optimizes the predicted atomic 3D coordinates and the corresponding interatomic distances, resulting in a strong predictive model. Extensive experiments demonstrate that ConfOpt significantly outperforms existing methods, thus providing a new paradigm for efficiently and accurately predicting molecular ground-state conformation.", "published": "2024-10-31 04:00:00", "id": "ead56864-b62d-4882-8055-f1c24884c1bd", "source": "arxiv", "section": "computerScience"}, {"title": "Bayesian Optimisation with Unknown Hyperparameters: Regret Bounds Logarithmically Closer to Optimal", "link": "https://arxiv.org/abs/2410.10384", "description": "arXiv:2410.10384v2 Announce Type: replace-cross \nAbstract: Bayesian Optimization (BO) is widely used for optimising black-box functions but requires us to specify the length scale hyperparameter, which defines the smoothness of the functions the optimizer will consider. Most current BO algorithms choose this hyperparameter by maximizing the marginal likelihood of the observed data, albeit risking misspecification if the objective function is less smooth in regions we have not yet explored. The only prior solution addressing this problem with theoretical guarantees was A-GP-UCB, proposed by Berkenkamp et al. (2019). This algorithm progressively decreases the length scale, expanding the class of functions considered by the optimizer. However, A-GP-UCB lacks a stopping mechanism, leading to over-exploration and slow convergence. To overcome this, we introduce Length scale Balancing (LB) - a novel approach, aggregating multiple base surrogate models with varying length scales. LB intermittently adds smaller length scale candidate values while retaining longer scales, balancing exploration and exploitation. We formally derive a cumulative regret bound of LB and compare it with the regret of an oracle BO algorithm using the optimal length scale. Denoting the factor by which the regret bound of A-GP-UCB was away from oracle as $g(T)$, we show that LB is only $\\log g(T)$ away from oracle regret. We also empirically evaluate our algorithm on synthetic and real-world benchmarks and show it outperforms A-GP-UCB, maximum likelihood estimation and MCMC.", "published": "2024-10-31 04:00:00", "id": "f2f45eca-0512-4539-83b4-d45d84a98981", "source": "arxiv", "section": "computerScience"}, {"title": "Quantum Boltzmann machine learning of ground-state energies", "link": "https://arxiv.org/abs/2410.12935", "description": "arXiv:2410.12935v2 Announce Type: replace-cross \nAbstract: Estimating the ground-state energy of Hamiltonians is a fundamental task for which it is believed that quantum computers can be helpful. Several approaches have been proposed toward this goal, including algorithms based on quantum phase estimation and hybrid quantum-classical optimizers involving parameterized quantum circuits, the latter falling under the umbrella of the variational quantum eigensolver. Here, we analyze the performance of quantum Boltzmann machines for this task, which is a less explored ansatz based on parameterized thermal states and which is not known to suffer from the barren-plateau problem. We delineate a hybrid quantum-classical algorithm for this task and rigorously prove that it converges to an $\\varepsilon$-approximate stationary point of the energy function optimized over parameter space, while using a number of parameterized-thermal-state samples that is polynomial in $\\varepsilon^{-1}$, the number of parameters, and the norm of the Hamiltonian being optimized. Our algorithm estimates the gradient of the energy function efficiently by means of a novel quantum circuit construction that combines classical sampling, Hamiltonian simulation, and the Hadamard test, thus overcoming a key obstacle to quantum Boltzmann machine learning that has been left open since [Amin et al., Phys. Rev. X 8, 021050 (2018)]. Additionally supporting our main claims are calculations of the gradient and Hessian of the energy function, as well as an upper bound on the matrix elements of the latter that is used in the convergence analysis.", "published": "2024-10-31 04:00:00", "id": "104f1df4-c2d9-42e5-8c40-019a17d60ad0", "source": "arxiv", "section": "computerScience"}, {"title": "Cryogenic Control and Readout Integrated Circuits for Solid-State Quantum Computing", "link": "https://arxiv.org/abs/2410.15895", "description": "arXiv:2410.15895v2 Announce Type: replace-cross \nAbstract: In the pursuit of quantum computing, solid-state quantum systems, particularly superconducting ones, have made remarkable advancements over the past two decades. However, achieving fault-tolerant quantum computing for next-generation applications necessitates the integration of several million qubits, which presents significant challenges in terms of interconnection complexity and latency that are currently unsolvable with state-of-the-art room-temperature control and readout electronics. Recently, cryogenic integrated circuits (ICs), including CMOS radio-frequency ICs and rapid-single-flux-quantum-logic ICs, have emerged as potential alternatives to room-temperature electronics. Unlike their room-temperature counterparts, these ICs are deployed within cryostats to enhance scalability by reducing the number and length of transmission lines. Additionally, operating at cryogenic temperatures can suppress electronic noise and improve qubit control fidelity. However, for CMOS ICs specifically, circuit design uncertainties arise due to a lack of reliable models for cryogenic field effect transistors as well as issues related to severe fickle noises and power dissipation at cryogenic temperatures. This paper provides a comprehensive review of recent research on both types of cryogenic control and readout ICs but primarily focuses on the more mature CMOS technology. The discussion encompasses principles underlying control and readout techniques employed in cryogenic CMOS ICs along with their architectural designs; characterization and modeling approaches for field effect transistors under cryogenic conditions; as well as fundamental concepts pertaining to rapid single flux quantum circuits.", "published": "2024-10-31 04:00:00", "id": "4612b7a4-e6f5-4e46-b028-63e1dc4898d7", "source": "arxiv", "section": "computerScience"}, {"title": "A Generalized Framework for Multiscale State-Space Modeling with Nested Nonlinear Dynamics: An Application to Bayesian Learning under Switching Regimes", "link": "https://arxiv.org/abs/2410.19074", "description": "arXiv:2410.19074v2 Announce Type: replace-cross \nAbstract: In this work, we introduce a generalized framework for multiscale state-space modeling that incorporates nested nonlinear dynamics, with a specific focus on Bayesian learning under switching regimes. Our framework captures the complex interactions between fast and slow processes within systems, allowing for the analysis of how these dynamics influence each other across various temporal scales. We model these interactions through a hierarchical structure in which finer time-scale dynamics are nested within coarser ones, while facilitating feedback between the scales. To promote the practical application of our framework, we address the problem of identifying switching regimes and transient dynamics. In particular, we develop a Bayesian learning approach to estimate latent states and indicators corresponding to switching dynamics, enabling the model to adapt effectively to regime changes. We employ Sequential Monte Carlo, or particle filtering, for inference. We illustrate the utility of our framework through simulations. The results demonstrate that our Bayesian learning approach effectively tracks state transitions and achieves accurate identification of switching dynamics in multiscale systems.", "published": "2024-10-31 04:00:00", "id": "4ce3d033-b299-4c93-911b-f7fe28954ec6", "source": "arxiv", "section": "computerScience"}, {"title": "Spectra and pseudospectra in the evaluation of material stability", "link": "https://arxiv.org/abs/2410.20570", "description": "arXiv:2410.20570v2 Announce Type: replace-cross \nAbstract: We consider the dynamics of bodies with \"active\" microstructure described by vector valued phase fields. For waves with time-varying amplitude, the associated evolution equation involves a matrix that can be non-normal, depending on the constitutive choices adopted for the microstructural actions associated with the phase field. In the presence of non-normality, the spectral analysis of such a matrix when (unknown or uncertain or time-dependent) constitutive parameters vary is generically not decisive to evaluate the material stability. We thus need to look at the pseudospectrum, that is, the set of all possible eigenvalues of matrices in an {\\epsilon}-neighborhood of the matrix of interest. As a case study, we look at quasicrystals and evaluate through spectra and pseudospectra the influence of a microstructural self-action on the material stability. This approach allows us to reliably determine thresholds where stable-unstable transitions in the material behavior occur.", "published": "2024-10-31 04:00:00", "id": "9a462348-5756-48f3-8092-fcbb07875455", "source": "arxiv", "section": "computerScience"}, {"title": "Adaptive Transfer Clustering: A Unified Framework", "link": "https://arxiv.org/abs/2410.21263", "description": "arXiv:2410.21263v2 Announce Type: replace-cross \nAbstract: We propose a general transfer learning framework for clustering given a main dataset and an auxiliary one about the same subjects. The two datasets may reflect similar but different latent grouping structures of the subjects. We propose an adaptive transfer clustering (ATC) algorithm that automatically leverages the commonality in the presence of unknown discrepancy, by optimizing an estimated bias-variance decomposition. It applies to a broad class of statistical models including Gaussian mixture models, stochastic block models, and latent class models. A theoretical analysis proves the optimality of ATC under the Gaussian mixture model and explicitly quantifies the benefit of transfer. Extensive simulations and real data experiments confirm our method's effectiveness in various scenarios.", "published": "2024-10-31 04:00:00", "id": "9a11c01f-ef36-4dbb-ad4d-5917ff15450e", "source": "arxiv", "section": "computerScience"}, {"title": "Achilles, Neural Network to Predict the Gold Vs US Dollar Integration with Trading Bot for Automatic Trading", "link": "https://arxiv.org/abs/2410.21291", "description": "arXiv:2410.21291v2 Announce Type: replace-cross \nAbstract: Predicting the stock market is a big challenge for the machine learning world. It is known how difficult it is to have accurate and consistent predictions with ML models. Some architectures are able to capture the movement of stocks but almost never are able to be launched to the production world. We present Achilles, with a classical architecture of LSTM(Long Short Term Memory) neural network this model is able to predict the Gold vs USD commodity. With the predictions minute-per-minute of this model we implemented a trading bot to run during 23 days of testing excluding weekends. At the end of the testing period we generated $1623.52 in profit with the methodology used. The results of our method demonstrate Machine Learning can successfully be implemented to predict the Gold vs USD commodity.", "published": "2024-10-31 04:00:00", "id": "baad107b-b63a-4217-835c-573dfcc5be11", "source": "arxiv", "section": "computerScience"}, {"title": "Effective weak convergence and tightness of measures in computable Polish spaces", "link": "https://arxiv.org/abs/2410.21609", "description": "arXiv:2410.21609v2 Announce Type: replace-cross \nAbstract: Prokhorov's Theorem in probability theory states that a family $\\Gamma$ of probability measures on a Polish space is tight if and only if every sequence in $\\Gamma$ has a weakly convergent subsequence. Due to the highly non-constructive nature of (relative) sequential compactness, however, the effective content of this theorem has not been studied. To this end, we generalize the effective notions of weak convergence of measures on the real line due to McNicholl and Rojas to computable Polish spaces. Then, we introduce an effective notion of tightness for families of measures on computable Polish spaces. Finally, we prove an effective version of Prokhorov's Theorem for computable sequences of probability measures.", "published": "2024-10-31 04:00:00", "id": "b12e3ae2-ad0a-449e-a9b4-27168b1c486e", "source": "arxiv", "section": "computerScience"}, {"title": "PACER: Physics Informed Uncertainty Aware Climate Emulator", "link": "https://arxiv.org/abs/2410.21657", "description": "arXiv:2410.21657v2 Announce Type: replace-cross \nAbstract: Climate models serve as critical tools for evaluating the effects of climate change and projecting future climate scenarios. However, the reliance on numerical simulations of physical equations renders them computationally intensive and inefficient. While deep learning methodologies have made significant progress in weather forecasting, they are still unstable for climate emulation tasks. Here, we propose PACER, a lightweight 684K parameter Physics Informed Uncertainty Aware Climate Emulator. PACER emulates temperature and precipitation stably for 86 years while only being trained on greenhouse gas emissions data. We incorporate a fundamental physical law of advection-diffusion in PACER accounting for boundary conditions and empirically estimating the diffusion co-efficient and flow velocities from emissions data. PACER has been trained on 15 climate models provided by ClimateSet outperforming baselines across most of the climate models and advancing a new state of the art in a climate diagnostic task.", "published": "2024-10-31 04:00:00", "id": "c18e1425-3ca9-4df2-8ee6-0e26e3bde0ee", "source": "arxiv", "section": "computerScience"}, {"title": "Joint Estimation of Conditional Mean and Covariance for Unbalanced Panels", "link": "https://arxiv.org/abs/2410.21858", "description": "arXiv:2410.21858v2 Announce Type: replace-cross \nAbstract: We propose a novel nonparametric kernel-based estimator of cross-sectional conditional mean and covariance matrices for large unbalanced panels. We show its consistency and provide finite-sample guarantees. In an empirical application, we estimate conditional mean and covariance matrices for a large unbalanced panel of monthly stock excess returns given macroeconomic and firm-specific covariates from 1962 to 2021.The estimator performs well with respect to statistical measures. It is informative for empirical asset pricing, generating conditional mean-variance efficient portfolios with substantial out-of-sample Sharpe ratios far beyond equal-weighted benchmarks.", "published": "2024-10-31 04:00:00", "id": "f6fb60d0-dfd3-4bfc-be9a-388d392e76ec", "source": "arxiv", "section": "computerScience"}, {"title": "Identifiability Analysis of Linear ODE Systems with Hidden Confounders", "link": "https://arxiv.org/abs/2410.21917", "description": "arXiv:2410.21917v2 Announce Type: replace-cross \nAbstract: The identifiability analysis of linear Ordinary Differential Equation (ODE) systems is a necessary prerequisite for making reliable causal inferences about these systems. While identifiability has been well studied in scenarios where the system is fully observable, the conditions for identifiability remain unexplored when latent variables interact with the system. This paper aims to address this gap by presenting a systematic analysis of identifiability in linear ODE systems incorporating hidden confounders. Specifically, we investigate two cases of such systems. In the first case, latent confounders exhibit no causal relationships, yet their evolution adheres to specific functional forms, such as polynomial functions of time $t$. Subsequently, we extend this analysis to encompass scenarios where hidden confounders exhibit causal dependencies, with the causal structure of latent variables described by a Directed Acyclic Graph (DAG). The second case represents a more intricate variation of the first case, prompting a more comprehensive identifiability analysis. Accordingly, we conduct detailed identifiability analyses of the second system under various observation conditions, including both continuous and discrete observations from single or multiple trajectories. To validate our theoretical results, we perform a series of simulations, which support and substantiate our findings.", "published": "2024-10-31 04:00:00", "id": "6c082434-3e00-447f-98b9-ee85f904430f", "source": "arxiv", "section": "computerScience"}, {"title": "Analyzing Noise Models and Advanced Filtering Algorithms for Image Enhancement", "link": "https://arxiv.org/abs/2410.21946", "description": "arXiv:2410.21946v2 Announce Type: replace-cross \nAbstract: Noise, an unwanted component in an image, can be the reason for the degradation of Image at the time of transmission or capturing. Noise reduction from images is still a challenging task. Digital Image Processing is a component of Digital signal processing. A wide variety of algorithms can be used in image processing to apply to an image or an input dataset and obtain important outcomes. In image processing research, removing noise from images before further analysis is essential. Post-noise removal of images improves clarity, enabling better interpretation and analysis across medical imaging, satellite imagery, and radar applications. While numerous algorithms exist, each comes with its own assumptions, strengths, and limitations. The paper aims to evaluate the effectiveness of different filtering techniques on images with eight types of noise. It evaluates methodologies like Wiener, Median, Gaussian, Mean, Low pass, High pass, Laplacian and bilateral filtering, using the performance metric Peak signal to noise ratio. It shows us the impact of different filters on noise models by applying a variety of filters to various kinds of noise. Additionally, it also assists us in determining which filtering strategy is most appropriate for a certain noise model based on the circumstances.", "published": "2024-10-31 04:00:00", "id": "a9a92998-fba6-4206-a3a1-a730d273c46a", "source": "arxiv", "section": "computerScience"}, {"title": "$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources", "link": "https://arxiv.org/abs/2410.23261", "description": "arXiv:2410.23261v1 Announce Type: new \nAbstract: Pre-training is notoriously compute-intensive and academic researchers are notoriously under-resourced. It is, therefore, commonly assumed that academics can't pre-train models. In this paper, we seek to clarify this assumption. We first survey academic researchers to learn about their available compute and then empirically measure the time to replicate models on such resources. We introduce a benchmark to measure the time to pre-train models on given GPUs and also identify ideal settings for maximizing training speed. We run our benchmark on a range of models and academic GPUs, spending 2,000 GPU-hours on our experiments. Our results reveal a brighter picture for academic pre-training: for example, although Pythia-1B was originally trained on 64 GPUs for 3 days, we find it is also possible to replicate this model (with the same hyper-parameters) in 3x fewer GPU-days: i.e. on 4 GPUs in 18 days. We conclude with a cost-benefit analysis to help clarify the trade-offs between price and pre-training time. We believe our benchmark will help academic researchers conduct experiments that require training larger models on more data. We fully release our codebase at: https://github.com/apoorvkh/academic-pretraining.", "published": "2024-10-31 04:00:00", "id": "3acd4b35-cc69-4873-86ec-b292918e8da7", "source": "arxiv", "section": "computerScience"}, {"title": "小学一年级，卷起来", "link": "https://www.huxiu.com/article/3634070.html?f=rss", "description": "家庭变成了学校的延伸", "published": "2024-10-31 01:55:51", "id": "1058e5ac-bd9a-4b35-b7f3-d983b820c87c", "source": "虎嗅", "section": "默认"}, {"title": "Meta：彻底成 “AI狂徒”，高成长能架得住高投入吗？", "link": "https://www.huxiu.com/article/3635161.html?f=rss", "description": "一切“原罪”在于短期预期太过饱满和一致性", "published": "2024-10-31 05:18:14", "id": "b6d48f6d-af7d-4bb3-b1a6-bf926e750461", "source": "虎嗅", "section": "默认"}, {"title": "“消失”的微医：年营收近百亿，预计年底再冲上市", "link": "https://www.huxiu.com/article/3634543.html?f=rss", "description": "微医能走多远，取决于AI技术对健共体的赋能程度", "published": "2024-10-31 01:57:40", "id": "e966d8d0-5a00-4692-9ee6-e79ccf55002f", "source": "虎嗅", "section": "默认"}, {"title": "金价年内创39次新高", "link": "https://www.huxiu.com/article/3634959.html?f=rss", "description": "高盛称，2025年底，国际金价将涨至3000美元/盎司。", "published": "2024-10-31 03:13:39", "id": "65325007-08f4-4155-9a4f-68a3a28c1a6f", "source": "虎嗅", "section": "默认"}, {"title": "还在狂奔的新茶饮，今年有不少新品牌获融资？", "link": "https://www.huxiu.com/article/3635180.html?f=rss", "description": "新茶饮投资当下确实不再是主流VC们的选择了", "published": "2024-10-31 06:14:16", "id": "2d0473cb-5885-4d4b-a208-73743bd75a46", "source": "虎嗅", "section": "默认"}, {"title": "京东方：需求绵软无力，再等一轮周期？", "link": "https://www.huxiu.com/article/3635162.html?f=rss", "description": "价格端再现下滑", "published": "2024-10-31 08:10:11", "id": "04ba270c-606b-4745-b58f-e16d8f2be6e1", "source": "虎嗅", "section": "默认"}, {"title": "撺掇老板瞎折腾，苦的还是打工人", "link": "https://www.huxiu.com/article/3632170.html?f=rss", "description": "财经大V收获了真金白银，老板收获了心理按摩", "published": "2024-10-31 02:37:00", "id": "6642c98c-1c67-4464-adb1-1283f514176c", "source": "虎嗅", "section": "默认"}, {"title": "牛市靠什么因素主导？", "link": "https://www.huxiu.com/article/3635390.html?f=rss", "description": "经济增长与股市牛市之间并没有必然的联系", "published": "2024-10-31 07:12:18", "id": "36834c95-0aca-4301-b1a6-4fa92b12fdfe", "source": "虎嗅", "section": "默认"}, {"title": "“我在古着直播间掘金，几百块买一件奢牌”", "link": "https://www.huxiu.com/article/3633086.html?f=rss", "description": "洋垃圾、假货、无效消费", "published": "2024-10-31 00:24:51", "id": "3cd52521-2f4d-4bc3-9402-89e0e2e17f5a", "source": "虎嗅", "section": "默认"}, {"title": "隐匿贵州的七个宝藏地：从700年土司到浙大西迁", "link": "https://www.huxiu.com/article/3634527.html?f=rss", "description": "一位北大考古博士的文旅攻略", "published": "2024-10-31 05:50:00", "id": "62733a68-6292-4fd5-893f-166ccff384f0", "source": "虎嗅", "section": "默认"}, {"title": "股市板块轮动存在怎样的规律，当下的市场主线在哪里？", "link": "https://www.huxiu.com/article/3633088.html?f=rss", "description": "深入解读股市的轮动规律与主线", "published": "2024-10-31 02:06:57", "id": "91c48798-af6b-4e4b-a410-fde8ebb07cb1", "source": "虎嗅", "section": "默认"}, {"title": "AI的最大瓶颈是什么？", "link": "https://www.huxiu.com/article/3634536.html?f=rss", "description": "没有足够的算力支持，就无法在这场竞赛中立足", "published": "2024-10-31 00:32:16", "id": "7a372bad-3b58-4a69-9657-56941cb606b4", "source": "虎嗅", "section": "默认"}, {"title": "中国反击欧盟对华电动汽车关税案", "link": "https://www.huxiu.com/article/3634953.html?f=rss", "description": "中国车企需要以全球视野来规划其投资和运营。", "published": "2024-10-31 04:48:56", "id": "5705bf1b-f961-401c-8f3c-3c6637e73a1b", "source": "虎嗅", "section": "默认"}, {"title": "食物、女性与生命：从韩江到格丽克", "link": "https://www.huxiu.com/article/3634973.html?f=rss", "description": "食物的细微感受是通过厌恶来传达的。", "published": "2024-10-31 03:46:23", "id": "bc5ff568-d6ba-46a8-ab67-7909e4fb59eb", "source": "虎嗅", "section": "默认"}, {"title": "欧洲汽车产业的“中等技术陷阱”", "link": "https://www.huxiu.com/article/3633098.html?f=rss", "description": "欧洲整个汽车产业正在进入寒冬", "published": "2024-10-31 04:09:13", "id": "d87448b8-cd44-4d1b-8c56-d9b00ffc4185", "source": "虎嗅", "section": "默认"}, {"title": "停服2个月后，《星鸣特攻》开发组被解散", "link": "https://www.huxiu.com/article/3633598.html?f=rss", "description": "它的失败，不止来源于“政治正确”", "published": "2024-10-31 03:57:58", "id": "3976852a-67be-44b6-9502-8aef9c7566b4", "source": "虎嗅", "section": "默认"}, {"title": "天青色等烟雨，而我在等一场桂花雨", "link": "https://www.huxiu.com/article/3632172.html?f=rss", "description": "一夜桂花雨，满城桂花香", "published": "2024-10-31 07:59:59", "id": "c845740c-7619-4336-b46e-71a36a90d393", "source": "虎嗅", "section": "默认"}, {"title": "万卡集群的AI数据中心，到底是如何运作的？", "link": "https://www.huxiu.com/article/3635183.html?f=rss", "description": "智算机柜功率密度提升向基础设施提出四大挑战", "published": "2024-10-31 07:08:52", "id": "1779d531-6d38-4542-9d0d-0f011768c73d", "source": "虎嗅", "section": "默认"}, {"title": "程序员做副业的困境", "link": "https://www.huxiu.com/article/3635399.html?f=rss", "description": "开发一个好产品不等于开发一个能挣钱的产品。", "published": "2024-10-31 08:26:52", "id": "fb1f09b5-0265-40ba-b1c3-9779ebcd4cc0", "source": "虎嗅", "section": "默认"}, {"title": "一级市场人才开始流失", "link": "https://www.huxiu.com/article/3634548.html?f=rss", "description": "除了失业的压力，PEVC机构内部的工作环境也变得愈发苛刻", "published": "2024-10-31 00:58:17", "id": "9bffc806-f808-4f3a-8682-7dba3fee4f89", "source": "虎嗅", "section": "默认"}, {"title": "网红商业，只能以打卡为生？", "link": "https://www.huxiu.com/article/3633113.html?f=rss", "description": "开业时有多风光，后期的落寞就有多明显。", "published": "2024-10-31 02:24:09", "id": "ff54023c-2cfd-4b21-ba96-b30078c39b4e", "source": "虎嗅", "section": "默认"}, {"title": "OpenAI计划自研AI 芯片，以减少对英伟达的依赖", "link": "https://www.huxiu.com/article/3633602.html?f=rss", "description": "OpenAI正在与博通合作开发其首款定制AI推理芯片", "published": "2024-10-31 04:52:23", "id": "22668291-8e90-4a65-8ecc-8453f7efe6d5", "source": "虎嗅", "section": "默认"}, {"title": "不点外卖的年轻人，吃饭全靠糊弄", "link": "https://www.huxiu.com/article/3635378.html?f=rss", "description": "做饭不易，糊弄一下就行了", "published": "2024-10-31 07:03:39", "id": "f00eff16-a0be-421b-a672-156d0ff69bdd", "source": "虎嗅", "section": "默认"}, {"title": "第一批掌握“提示语”的打工人，已经患上AI依赖症？", "link": "https://www.huxiu.com/article/3634533.html?f=rss", "description": "AI创作也是无法完全取代人类创意的。", "published": "2024-10-31 06:44:01", "id": "dd844c97-1971-4d29-a5c0-465dc0014ee3", "source": "虎嗅", "section": "默认"}, {"title": "中国老板，卷不动墨西哥打工人", "link": "https://www.huxiu.com/article/3635393.html?f=rss", "description": "出海墨西哥的制造业中企，还处于漫长的磨合期里。", "published": "2024-10-31 08:25:49", "id": "e7d17df7-eabe-4013-9368-02ba47fe4567", "source": "虎嗅", "section": "默认"}, {"title": "雷军为什么深受年轻人追捧，成为掌管流量的“神”", "link": "https://www.huxiu.com/article/3632556.html?f=rss", "description": "雷军一年吸粉三千万？", "published": "2024-10-31 08:27:01", "id": "51b875fa-07fa-4951-a268-616396f0a124", "source": "虎嗅", "section": "默认"}, {"title": "美国少年迷恋“AI伴侣”后自杀，有何警示？", "link": "https://www.huxiu.com/article/3634553.html?f=rss", "description": "少年之死：为虚拟“爱人”脱离现实世界", "published": "2024-10-31 01:19:54", "id": "54a1db5e-2718-41f0-9f78-c2b99d51728d", "source": "虎嗅", "section": "默认"}, {"title": "漂在越南（一）", "link": "https://www.huxiu.com/article/3635381.html?f=rss", "description": "越南没有传说中那么物美价廉，房租直逼广州市区", "published": "2024-10-31 06:52:54", "id": "26b6e181-94e9-4e86-8519-48d667d4a378", "source": "虎嗅", "section": "默认"}, {"title": "甜啦啦，是不是蜜雪冰城的最强对手？", "link": "https://www.huxiu.com/article/3634540.html?f=rss", "description": "甜啦啦和蜜雪冰城，还差着好几个古茗。", "published": "2024-10-31 01:21:33", "id": "75605866-5298-48c6-b31a-3e7a4047a708", "source": "虎嗅", "section": "默认"}, {"title": "王某被拘留后，“找茬”东航", "link": "https://www.huxiu.com/article/3634980.html?f=rss", "description": "", "published": "2024-10-31 03:53:00", "id": "5086e799-8cc9-4397-a485-3d10d198587a", "source": "虎嗅", "section": "默认"}, {"title": "10块钱一份的拼好饭，磨平了外卖商家们最后一点棱角", "link": "https://www.huxiu.com/article/3632535.html?f=rss", "description": "拼好饭是外卖界的拼多多？", "published": "2024-10-31 04:02:00", "id": "03637043-c029-465a-9970-8de91991beac", "source": "虎嗅", "section": "默认"}, {"title": "和历史学家聊聊：婚姻在当代还是必需品吗？", "link": "https://www.huxiu.com/article/3632895.html?f=rss", "description": "人们仍渴望长期关系，只是他们对婚姻质量的要求更高了", "published": "2024-10-31 01:17:31", "id": "d9047113-9489-4f02-8222-e48cb57dc3ce", "source": "虎嗅", "section": "默认"}, {"title": "大模型解锁新型工业化“大脑”", "link": "https://www.huxiu.com/article/3628345.html?f=rss", "description": "工业大模型与工业互联网的融合", "published": "2024-10-31 07:43:44", "id": "49da35e7-b819-4d7e-a5d8-231cb1cda59f", "source": "虎嗅", "section": "默认"}, {"title": "年轻人为何沉迷“土嗨景区”？", "link": "https://www.huxiu.com/article/3634087.html?f=rss", "description": "越土的景区，越能收割年轻人。", "published": "2024-10-31 01:08:11", "id": "743237a6-328d-4f40-845e-3a142b3eadfd", "source": "虎嗅", "section": "默认"}, {"title": "伪造数千枚公章，股东再曝华云数据“欺诈”内幕", "link": "https://www.huxiu.com/article/3634950.html?f=rss", "description": "骗投超30亿元", "published": "2024-10-31 03:39:59", "id": "1034fbf5-c69d-4f15-9e4c-0a944cedb0e4", "source": "虎嗅", "section": "默认"}, {"title": "哈佛“哭穷”，芝大被传破产，美国大学没钱了？", "link": "https://www.huxiu.com/article/3635376.html?f=rss", "description": "美国大学的经济账，越挖越有意思", "published": "2024-10-31 07:41:00", "id": "26d95a54-4054-42b5-81c0-bb3bcb2c4955", "source": "虎嗅", "section": "默认"}, {"title": "一期B站百万爆款，得花叔叔多少预算？", "link": "https://www.huxiu.com/article/3634975.html?f=rss", "description": "视频画质问题到底能不能解决？", "published": "2024-10-31 04:03:23", "id": "c9d2bb71-8ae6-4119-a6d7-ba7b4667a0db", "source": "虎嗅", "section": "默认"}, {"title": "朝鲜31日试射洲际弹道导弹", "link": "https://www.huxiu.com/article/3635193.html?f=rss", "description": "该导弹最终落在日本专属经济区之外。", "published": "2024-10-31 06:21:57", "id": "7382f510-6410-43a4-9a25-4a0f0f3084f1", "source": "虎嗅", "section": "默认"}, {"title": "多家香港券商期权兑付违约，隐秘通道商浮现", "link": "https://www.huxiu.com/article/3635386.html?f=rss", "description": "有的卖车付本金，有的人去楼空", "published": "2024-10-31 07:26:54", "id": "c5523020-5c92-4f3f-8bef-f7ab5f2f3b1e", "source": "虎嗅", "section": "默认"}, {"title": "磅礴的企业家精神，何时回归？", "link": "https://www.huxiu.com/article/3633600.html?f=rss", "description": "企业家兴，则中国经济兴。", "published": "2024-10-31 06:30:30", "id": "736d8aa9-9762-46bb-a747-d0730fc0539f", "source": "虎嗅", "section": "默认"}, {"title": "大模型应用之困与异军突起的“埃森哲们”", "link": "https://www.huxiu.com/article/3634968.html?f=rss", "description": "在这轮生成式AI浪潮中最赚钱的公司，竟然是以埃森哲为代表的传统咨询公司", "published": "2024-10-31 05:47:51", "id": "849e2516-84b7-479f-9f63-12d63502a3eb", "source": "虎嗅", "section": "默认"}, {"title": "今年中国股票盈利增速或超过印度", "link": "https://www.huxiu.com/article/3635377.html?f=rss", "description": "印度的盈利增长似乎正失去动力", "published": "2024-10-31 06:31:58", "id": "2536974d-da38-4ea1-8c35-b34ae28d71ca", "source": "虎嗅", "section": "默认"}, {"title": "我跟万圣节的AI次元壁，看起来要被PixVerse V3打破了", "link": "https://www.huxiu.com/article/3635167.html?f=rss", "description": "", "published": "2024-10-31 04:09:00", "id": "1b4f7b79-7067-412c-a164-b69cfe26d33b", "source": "虎嗅", "section": "默认"}, {"title": "欧盟还是决定对中国电动汽车加征最高35.3%关税", "link": "https://www.huxiu.com/article/3632205.html?f=rss", "description": "欧盟加征关税短期内对欧洲竞争格局的影响有限", "published": "2024-10-31 03:14:06", "id": "cfa0aeac-473c-4a0b-a589-62110c5cd3be", "source": "虎嗅", "section": "默认"}, {"title": "ESG之E：评级背后的环境评分逻辑", "link": "https://www.huxiu.com/article/3632218.html?f=rss", "description": "企业为何要如此注重环境保护？", "published": "2024-10-31 05:38:00", "id": "546dfe9c-575a-4ba3-a08d-54bb24cf67c2", "source": "虎嗅", "section": "默认"}, {"title": "长得丑不予录用？面试“选美”背刺打工人", "link": "https://www.huxiu.com/article/3635387.html?f=rss", "description": "对颜值的高要求高标准，随之而来的是招聘的“泛颜值化”。", "published": "2024-10-31 07:33:00", "id": "0cb836fb-8b37-4f3e-85e8-4bef0a2b3a66", "source": "虎嗅", "section": "默认"}, {"title": "中西部的消费力，越来越猛", "link": "https://www.huxiu.com/article/3634550.html?f=rss", "description": "后发优势明显", "published": "2024-10-31 01:44:58", "id": "3fb8ef17-9383-47a2-84e3-ce2bdce2d8c0", "source": "虎嗅", "section": "默认"}, {"title": "“动漫+短剧”会是下一片创作蓝海吗？", "link": "https://www.huxiu.com/article/3628870.html?f=rss", "description": "短剧的风，吹到了动漫领域", "published": "2024-10-31 07:30:42", "id": "546c9c4d-025b-4ce6-aafa-a7da923abd31", "source": "虎嗅", "section": "默认"}, {"title": "为什么消费降级，买中高端运动品牌的人却变多了？", "link": "https://www.huxiu.com/article/3634074.html?f=rss", "description": "高端品牌擅长“造神”，而低端品牌善于“复刻”。", "published": "2024-10-31 01:08:00", "id": "4a96ba0a-d895-482e-b231-c1227d90e9dd", "source": "虎嗅", "section": "默认"}, {"title": "为了催婚，公园也能登记结婚了？", "link": "https://www.huxiu.com/article/3634554.html?f=rss", "description": "婚姻从来都是一笔经济账。", "published": "2024-10-31 04:58:31", "id": "e6cc1ae8-96fd-451f-b33a-2c0f9c718642", "source": "虎嗅", "section": "默认"}, {"title": "电商面临低质内卷新命题", "link": "https://www.huxiu.com/article/3635174.html?f=rss", "description": "堡垒，往往是从内部攻破的。", "published": "2024-10-31 06:16:02", "id": "da79c9b8-d490-4768-b7d4-a5611b2eef94", "source": "虎嗅", "section": "默认"}, {"title": "盛极而衰，剧本杀彻底凉了？", "link": "https://www.huxiu.com/article/3634974.html?f=rss", "description": "2022年开始，剧本杀就逐渐进入衰落期。", "published": "2024-10-31 04:12:00", "id": "5ea25078-cf2c-40ac-8ded-ae4ca6741d87", "source": "虎嗅", "section": "默认"}, {"title": "“为了传承传统文化，我要借你命用一下”", "link": "https://www.huxiu.com/article/3635192.html?f=rss", "description": "大象在远方，沉默不语", "published": "2024-10-31 06:48:00", "id": "9f6054e2-bd0f-473c-a233-3dbc675d41cc", "source": "虎嗅", "section": "默认"}, {"title": "大家还在睡觉的时候，中国航天又成功了", "link": "https://www.huxiu.com/article/3633611.html?f=rss", "description": "突出一个“新”字", "published": "2024-10-31 01:30:00", "id": "540c3fa5-6bdb-4188-acd9-839d1348f13b", "source": "虎嗅", "section": "默认"}, {"title": "这座边境寺庙里，咋还有个动物园啊？", "link": "https://www.huxiu.com/article/3633614.html?f=rss", "description": "沿着喜马拉雅山脉，探访大自然的“神迹”", "published": "2024-10-31 02:39:59", "id": "d5f7d323-1fe1-4eca-a49c-2608c10a1449", "source": "虎嗅", "section": "默认"}, {"title": "中国最适合看展的城市，一票难求", "link": "https://www.huxiu.com/article/3632850.html?f=rss", "description": "当“看展”成为上海人日常生活的一部分", "published": "2024-10-31 00:14:09", "id": "a6ec1251-058a-4df4-9ffd-68b2e1efbed7", "source": "虎嗅", "section": "默认"}, {"title": "不发论文的时候，科学家们都在晚上做什么？", "link": "https://www.huxiu.com/article/3634526.html?f=rss", "description": "“夜间”是创造性一面", "published": "2024-10-31 00:09:00", "id": "248ef53c-9fe5-4b36-b70f-00fc9beb7009", "source": "虎嗅", "section": "默认"}, {"title": "83家上市房企前三季业绩“出炉”", "link": "https://www.huxiu.com/article/3633099.html?f=rss", "description": "超三成营收同比增长，9家净利润超10亿元", "published": "2024-10-31 00:00:26", "id": "44258c79-c97a-4cf5-a69a-61184bb5ccd5", "source": "虎嗅", "section": "默认"}, {"title": "'Why I spent my university fees on Somali TikTok battles'", "link": "https://www.bbc.com/news/articles/cj0j47yrq15o", "description": "Somalis gamble big money during livestream events as ancient clan fights are waged on social media.", "published": "2024-10-31 00:51:44", "id": "2d3fe534-08c7-4ab8-8941-1c94273ee83c", "source": "bbc", "section": "world"}, {"title": "France jails ex-doctor for 27 years in Rwandan genocide trial", "link": "https://www.bbc.com/news/articles/cwy918gk20zo", "description": "Eugène Rwamucyo was found guilty of complicity in genocide and complicity in crimes against humanity.", "published": "2024-10-31 09:02:05", "id": "fa2fb624-553d-4b7f-a5ca-14d690f96d7b", "source": "bbc", "section": "world"}, {"title": "Deadliest weather made worse by climate change - scientists", "link": "https://www.bbc.com/news/articles/cdxvnk10xz2o", "description": "Human-caused climate change made recent extreme weather events more intense and more likely, new analysis finds.", "published": "2024-10-31 04:27:46", "id": "3cbba0e3-9ce3-4089-9cfe-13dd78bd262d", "source": "bbc", "section": "world"}, {"title": "Women raped in war-hit Sudan die by suicide, activists say", "link": "https://www.bbc.com/news/articles/c8xpqvz0e88o", "description": "Several women raped by paramilitary fighters in Gezira state have taken their own lives, activists say.", "published": "2024-10-31 00:46:40", "id": "de183855-a754-4091-8476-076005431f3c", "source": "bbc", "section": "world"}, {"title": "Russian drones hunt civilians in Ukraine, evidence suggests", "link": "https://www.bbc.com/news/articles/c207gz7key6o", "description": "Ukrainians tell of their fear as BBC Verify analyses videos appearing to show drone strikes on civilians.", "published": "2024-10-31 06:01:28", "id": "8b1033e7-af44-4981-af99-28368ef7868f", "source": "bbc", "section": "world"}, {"title": "Israel strikes historic Lebanese city of Baalbek after ordering evacuation", "link": "https://www.bbc.com/news/articles/crez85y20zvo", "description": "Tens of thousands flee as the Israeli military says it struck fuel depots belonging to Hezbollah.", "published": "2024-10-31 00:34:51", "id": "698570d4-56c5-4274-bca8-688d3592cf22", "source": "bbc", "section": "world"}, {"title": "Thom Yorke confronts Gaza protester at Australian gig", "link": "https://www.bbc.com/news/articles/c5yrv2zyd22o", "description": "Thom Yorke hit back at the fan after he heckled the singer over death numbers in Gaza during a performance in Melborne.", "published": "2024-10-31 06:23:22", "id": "8dbb9529-67f5-4d02-bdab-a62eb79c66a3", "source": "bbc", "section": "world"}, {"title": "Valencia floods aftermath 'like a disaster movie'", "link": "https://www.bbc.com/news/videos/c80l54vd7ezo", "description": "The BBC's Nicky Schiller reports from the scene of Spanish flooding where cars are piled up.", "published": "2024-10-31 09:33:57", "id": "979b196d-485f-46e9-82da-e9a657855686", "source": "bbc", "section": "world"}, {"title": "N Korea fires banned missile in longest flight yet", "link": "https://www.bbc.com/news/articles/ckgry8rpzn4o", "description": "The test shows that Pyongyang is building weapons that \"fire farther and higher\", Seoul says.", "published": "2024-10-31 04:43:48", "id": "95d1d343-0300-494b-8276-7dce9d13a967", "source": "bbc", "section": "world"}, {"title": "Why Canada wants more overseas tourists to visit", "link": "https://www.bbc.com/news/articles/cp396g01g6xo", "description": "The country has launched a campaign to encourage more international visitors.", "published": "2024-10-31 00:01:41", "id": "2f8af6ad-fea7-47e7-865f-1751200625c4", "source": "bbc", "section": "business"}, {"title": "'I take home £1,800 a month. I'm glad fuel prices aren't going up'", "link": "https://www.bbc.com/news/articles/cwyv8y68e25o", "description": "People tell the BBC how much they earn and what they made of the Budget.", "published": "2024-10-31 08:47:30", "id": "fccef89b-2dc4-47d2-a1e3-c6387b85bb55", "source": "bbc", "section": "business"}, {"title": "Warning more spending and tax rises to come", "link": "https://www.bbc.com/news/articles/cgj72wxw8jxo", "description": "The Institute for Fiscal Studies says spending pressures could lead to further tax rises within two years.", "published": "2024-10-31 08:42:47", "id": "148a280f-678e-4081-9051-22fd0bac0383", "source": "bbc", "section": "business"}, {"title": "'I take home £1,800 a month. I'm glad fuel prices aren't going up'", "link": "https://www.bbc.com/news/articles/cwyv8y68e25o", "description": "People tell the BBC how much they earn and what they made of the Budget.", "published": "2024-10-31 08:47:30", "id": "290712f0-f1d8-4680-a99d-7883703dbe43", "source": "bbc", "section": "business"}, {"title": "China's BYD overtakes Tesla revenue for first time", "link": "https://www.bbc.com/news/articles/c4gm9j11mvdo", "description": "The electric vehicle giant saw its revenues jump 24% as government subsidies boost China's car industry.", "published": "2024-10-31 04:21:38", "id": "ed37fb2e-9e5f-48c6-b8ef-caaf16d8b639", "source": "bbc", "section": "business"}, {"title": "China's BYD overtakes Tesla revenue for first time", "link": "https://www.bbc.com/news/articles/c4gm9j11mvdo", "description": "The electric vehicle giant saw its revenues jump 24% as government subsidies boost China's car industry.", "published": "2024-10-31 04:21:38", "id": "531e215b-fda4-4f17-8965-ed3705d053c0", "source": "bbc", "section": "technology"}, {"title": "Deadliest weather made worse by climate change - scientists", "link": "https://www.bbc.com/news/articles/cdxvnk10xz2o", "description": "Human-caused climate change made recent extreme weather events more intense and more likely, new analysis finds.", "published": "2024-10-31 04:27:46", "id": "a9fa2b48-c0f6-4153-8199-d9acd6d5f0c0", "source": "bbc", "section": "science"}, {"title": "'Right thing' for businesses and wealthiest to pay more - Reeves", "link": "https://www.bbc.co.uk/programmes/p0k1cqfl", "description": "'Right thing' for businesses and wealthiest to pay more - Reeves", "published": "2024-10-31 08:07:14", "id": "5e1636a2-1fb6-40be-a9c3-fe140210b3b7", "source": "bbc", "section": "politics"}, {"title": "Chris Mason: A change-making Budget but a moment of jeopardy", "link": "https://www.bbc.com/news/articles/c8rl5pnm47do", "description": "The government's fate will depend on whether it can make things better, says political editor Chris Mason.", "published": "2024-10-31 01:34:29", "id": "5218e6b9-1a64-45fe-b8ed-94d5da2a44fc", "source": "bbc", "section": "politics"}, {"title": "'I take home £1,800 a month. I'm glad fuel prices aren't going up'", "link": "https://www.bbc.com/news/articles/cwyv8y68e25o", "description": "People tell the BBC how much they earn and what they made of the Budget.", "published": "2024-10-31 08:47:30", "id": "63cb476e-0a32-47d5-aea8-241e7fc107a1", "source": "bbc", "section": "politics"}, {"title": "Warning more spending and tax rises to come", "link": "https://www.bbc.com/news/articles/cgj72wxw8jxo", "description": "The Institute for Fiscal Studies says spending pressures could lead to further tax rises within two years.", "published": "2024-10-31 08:42:47", "id": "52a892bd-0d44-4510-902b-c0811e0dc73a", "source": "bbc", "section": "politics"}]